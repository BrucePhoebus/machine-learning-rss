<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>新智元</title>
    <link>http://www.iwgc.cn/list/2322</link>
    <description>智能+中国的资讯社交平台,致力于推动中国从互联网+迈向智能+新纪元.重点关注人工智能、机器人、大数据、虚拟现实、量子计算、智能医疗等前沿领域发展,关注人机融合、人工智能和机器人革命对人类社会与文明进化...</description>
    <item>
      <title>【重磅】TensorFlow 1.0 官方正式发布，重大更新及5大亮点</title>
      <link>http://www.iwgc.cn/link/4723523</link>
      <description>&lt;div class="article-content"&gt;&lt;section style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; font-family: inherit; font-size: 1em; font-weight: inherit; white-space: normal; max-width: 100%; line-height: 28.4444px; border-style: solid none none; border-top-width: 1px; border-top-color: rgb(204, 204, 204); text-decoration: inherit; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-top: -1.2em; max-width: 100%; min-height: 1em; text-align: center; border-width: initial; border-style: none; border-color: initial; line-height: 1.4; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-size: 18px;"&gt;&lt;strong style="font-family: inherit; font-size: 1em; text-decoration: inherit;"&gt;&lt;span style="color: rgb(255, 255, 255); max-width: 100%; line-height: 1.4; font-family: inherit; font-weight: inherit; text-decoration: inherit; background-color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(127, 127, 127); line-height: 22.4px;"&gt;1&amp;nbsp;&lt;/span&gt;新智元编译 &amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;strong style="font-family: inherit; font-size: 1em; text-decoration: inherit;"&gt;&lt;span style="color: rgb(255, 255, 255); max-width: 100%; line-height: 1.4; font-family: inherit; font-weight: inherit; text-decoration: inherit; background-color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/span&gt;&lt;span style="max-width: 100%; line-height: 1.4; font-family: inherit; font-weight: inherit; text-decoration: inherit; background-color: rgb(127, 127, 127); color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/span&gt;&lt;strong style="color: rgb(136, 136, 136); font-size: 12px;"&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;/section&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;来源：Google Develops Blog&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;编译：刘小芹、张易、文强&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong style="font-size: 14px; max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;【&lt;span style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;新智元导读】&lt;/span&gt;&lt;/strong&gt;&lt;span style="font-size: 14px;"&gt;昨天凌晨谷歌正式发布了TensorFlow1.0版，改进了库中的机器学习功能，发布了XLA的实验版本，对Python和Java用户开放，提升了debugging，并且加入和改进了一些高级API，其中包括Keras。一系列新的改进，都会让目前这个最受欢迎的深度学习框架变得更快、更灵活、更实用。&lt;/span&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/14872116106ZojLJ.gif"/&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211610G5uZrp.jpg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;谷歌TensorFlow 开发者大会演讲笔记。来源：Virginia Poltrack (@VPoltrack) | Twitter&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;在发布第一年，TensorFlow 已经帮助研究者、工程师、艺术家、学生以及其他许多人在许多领域取得了进展，从机器翻译到检测皮肤癌早期症状到预防糖尿病致盲。我们很高兴看到人们在超过6000个开源在线存储库项目中使用 TensorFlow。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;今天，作为在山景城举办的首届年度TensorFlow开发者峰会的一部分，我们宣布正式发布 TensorFlow 1.0。它的新特性包括：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;更快：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;TensorFlow 1.0 运行速度之快令人难以置信！XLA 为未来更多的性能改进奠定了基础，而且 tensorflow.org 新提供“tips &amp;amp; tricks”帮助用户微调模型以实现最大速度。我们将很快发布一些常用模型的更新实现，以展示如何充分利用TensorFlow 1.0：包括基于 8 GPU 对 Inception v3 实现7.3倍加速，以及基于 64 GPU 对分布式 Inception v3 训练实现58倍加速！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;更灵活&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;TensorFlow 1.0 还加入了一些高级API，包括 tf.layers，tf.metrics 和 tf.losses 模块。此外，它还包含一个全新的 tf.keras 模块，能够与 Keras 完全兼容，Keras 是另一个流行的高级神经网络库。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;更实用&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;TensorFlow 1.0 还提供稳定的 Python API，这让获取新功能更容易，而且不必担心破坏现有的代码。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;TensorFlow 1.0的其他亮点：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: square;"&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Python APIs已经更多地向Numpy转型。对于此类和其他向后兼容的以支持API稳定发展的更改，请使用我们的迁移指南和转换脚本。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Java和Go的实验API&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;高级API模块tf.layers，tf.metrics和tf.losses - 在纳入skflow和TF Slim之后从tf.contrib.learn中提取&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;发布了面向CPU和GPU的TensorFlow图形的特定领域编译器XLA的实验版本。 XLA正在迅速发展 - 预计在未来的发布中将看到更多的进展。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;生成TensorFlow Debugger（tfdbg），一个用于调试实时TensorFlow程序的命令行界面和API。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;用于对象检测和本地化的新Android demos以及基于摄像头的图片样式化。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;安装改进：添加了Python 3 docker镜像，TensorFlow的pip包现在兼容PyPI。这意味着TensorFlow现在可以简单调用pip install tensorflow来安装。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&amp;nbsp;&lt;/span&gt;&lt;span style="font-size: 14px;"&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;我们很高兴地看到世界各地TensorFlow社区的发展速度。要了解有关TensorFlow 1.0及其使用方式的更多信息，可以在YouTube上观看TensorFlow Developer Summit talks，涵盖从高级API、TensorFlow（移动版）到新XLA编译器的最新更新，以及TensorFlow的令人激动的使用方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;strong style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;开发者大会的视频：https://www.youtube.com/watch?v=4n1AHvDvVvw&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;TensorFlow生态系统持续成长，包括Fold 动态批处理和Embedding Projector等工具以及我们现有工具（如TensorFlow Serving）的更新。 我们非常感谢社区贡献者、教育工作者和将深度学习的最新进展带给每个人的研究人员 。 我们期待在如GitHub issues, Stack Overflow, @TensorFlow, the discuss@tensorflow.org group等群组与未来各论坛上与您的合作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;section class="" style="font-size: 16px; white-space: normal; max-width: 100%; box-sizing: border-box; color: rgb(62, 62, 62); background-color: rgb(255, 255, 255); border-width: 0px; border-style: initial; border-color: initial; clear: both; word-wrap: break-word !important;"&gt;&lt;section class="" style="padding: 8px; max-width: 100%; box-sizing: border-box; border-left: 6px solid rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; font-weight: bold; text-decoration: inherit; color: rgb(10, 10, 10); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;Keras 成为 TensorFlow 默认API&amp;nbsp;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;实际上，在上个月，Keras 的作者、谷歌 AI 研究员 Francois Chollet 就宣布：Keras 将会成为第一个被添加到 TensorFlow 核心中的高级别框架，变成 Tensorflow 的默认 API。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;Keras 是一个高级别的 Python 神经网络框架，能在 TensorFlow 或者 Theano 上运行。此外，能用到 TensorFlow 上的还有一些高级别的 Python 神经网络框架，比如，TF-Slim，虽然它们发展更不完善，也不是 TensorFlow 的核心部分。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;神经网络研究者 Rachel Thomas 在&amp;nbsp;fast.ai 上撰文介绍了这一消息，并写下了他使用TensorFlow 的心得体会：&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;他说，使用 TensorFlow 给我的感觉就是我还不够聪明，但是，在使用 Keras 的时候我会觉得神经网络要比我想象的简单。这是因为，TensorFlow 的 API 过于冗长和混乱，也是因为 Keras 拥有我体验过的最贴心的、最具表达力的 API。对我来说，在刚开始使用TensorFlow 受挫后就来公开批评它有点尴尬，它让人觉得沉重、不自然。当然，其中有我自己的原因。但是，Keras 和 Theano 确实证实了我的想法：tensors 和 神经网络不一定都是那么折磨人的。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;在一次大学作业中，我曾经使用一个硬件描述语言，通过添加和改变 CPU 暂存器中的字节来编码除法（division）。这是一个很有趣的练习，但是我非常确定，我不想用这种方式对神经网络进行编码。使用一个更高级别的语言的好处是显而易见的：更快地编码、更少的bug，以及，更少的痛苦。Keras 的好处还有更多——它更适配神经网络的概念，能促进新的发现。Keras 让我更加擅长神经网络，因为语言抽象与神经网络的概念搭配得更加好。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;使用与我的思维相同的概念语言写程序，能让我把注意力集中在需要解决的难题上，而不是编程语言的伪迹上。因为，当我把更多的精力花在头脑中的思维与编程语言之间的概念转换的时候，我的思考就会变慢。TensorFlow 影响了我的生产力。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;正如 Chollet 所写：“如果你想要长期使用一个更高级别的面向对象的 TF API ，Karas 就是正确的道路。”&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211612SK95xv.jpg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 12px; color: rgb(136, 136, 136);"&gt;Keras 的作者、谷歌 AI 研究员 Francois Chollet 在谷歌TensorFlow 开发者大会上演讲。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;section class="" style="font-size: 16px; white-space: normal; max-width: 100%; box-sizing: border-box; color: rgb(62, 62, 62); background-color: rgb(255, 255, 255); border-width: 0px; border-style: initial; border-color: initial; clear: both; word-wrap: break-word !important;"&gt;&lt;section class="" style="padding: 8px; max-width: 100%; box-sizing: border-box; border-left: 6px solid rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; font-weight: bold; text-decoration: inherit; color: rgb(10, 10, 10); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;TensorFlow 1.0&amp;nbsp;&lt;strong&gt;重大功能及改善&lt;/strong&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="width: 528.188px; white-space: normal;"&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;XLA（实验版）：初始版本的XLA，针对TensorFlow图（graph）的专用编译器，面向CPU和GPU。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;TensorFlow Debugger（tfdbg）：命令行界面和API。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;添加了新的python 3 docker图像。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;使pip包兼容pypi。TensorFlow现在可以通过&amp;nbsp;pip install tensorflow&amp;nbsp;命令安装。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;更改了几个python API的调用方式，使其更类似 NumPy。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;新的（实验版）Java API。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Android：全新人物检测+跟踪演示实现——“Scalable Object Detection using DNN”（带有额外的YOLO对象检测器支持）。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Android：全新基于摄像头的图像风格转换演示，使用了神经网络艺术风格转换技术。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="white-space: normal;"&gt;&lt;span class="s1"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;section class="" style="font-size: 16px; white-space: normal; max-width: 100%; box-sizing: border-box; color: rgb(62, 62, 62); background-color: rgb(255, 255, 255); border-width: 0px; border-style: initial; border-color: initial; clear: both; word-wrap: break-word !important;"&gt;&lt;section class="" style="padding: 8px; max-width: 100%; box-sizing: border-box; border-left: 6px solid rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; font-weight: bold; text-decoration: inherit; color: rgb(10, 10, 10); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); word-wrap: break-word !important;"&gt;&lt;section&gt;&amp;nbsp;重大 API 变动&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;为了帮助你升级现有的TensorFlow Python代码匹配以下 API 更改，我们准备了一个转换脚本:&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;此工具让你升级现有的TensorFlow Python脚本。此脚本可以在单个Python文件上运行：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 12px;"&gt;tf_upgrade.py --infile foo.py --outfile foo-upgraded.py&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;如果无法修复，系统会打印一个错误列表。你还可以在目录树上运行它：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 12px;"&gt;tf_upgrade.py --intree coolcode -outtree coolcode-upgraded&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;在上述任一情况下，系统会将转储一份报告，详细记录变化情况：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 12px;"&gt;third_party/tensorflow/tools/compatibility/test_file_v0.11.py Line 125&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 12px;"&gt;Renamed keyword argument from `dim` to `axis`&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 12px;"&gt;Renamed keyword argument from `squeeze_dims` to `axis`&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 12px;"&gt;&amp;nbsp; &amp;nbsp; Old: &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; [[1, 2, 3]], dim=1), squeeze_dims=[1]).eval(),&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 12px;"&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; ~~~~ &amp;nbsp; &amp;nbsp;~~~~~~~~~~~~~&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 12px;"&gt;&amp;nbsp; &amp;nbsp; New: &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; [[1, 2, 3]], axis=1), axis=[1]).eval(),&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 12px;"&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; ~~~~~ &amp;nbsp; &amp;nbsp;~~~~~&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="width: 528.188px; white-space: normal;"&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;TensorFlow / models已经被移动到一个单独的github库。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;除法和模运算符（/，//，％）现在匹配 Python（flooring）语义。这也适用于 [tf.div] 和 [tf.mod]。要获取基于强制整数截断的行为，可以使用 [tf.truncatediv] 和 [tf.truncatemod]。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;现在推荐使用 [tf.divide()] 作为除法函数。[tf.div()] 将保留，但它的语义不会回应 Python 3 或 [from future] 机制。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;tf.reverse() 现在取轴的索引要反转。例如 [tf.reverse（a，[True，False，True]）] 现在必须写为 [tf.reverse（a，[0，2]）]。 [tf.reverse_v2（）] 将保持到 TensorFlow 1.0 最终版。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;[tf.mul，tf.sub ] 和 [tf.neg] 不再使用，改为 [tf.multiply]，[tf.subtract] 和 [tf.negative]。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;[tf.pack] 和 [tf.unpack] 弃用，改为 [tf.stack] 和 [tf.unstack]。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;[TensorArray.pack] 和 [TensorArray.unpack] 在弃用过程中，将来计划启用 [TensorArray.stack] 和 [TensorArray.unstack]。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;以下Python函数的参数在引用特定域时，全部改为使用 [axis]。目前仍将保持旧的关键字参数的兼容性，但计划在 1.0 最终版完成前删除。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-indent: 2em;"&gt;&lt;span style="font-size: 12px;"&gt;tf.argmax: dimension 变为 axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-indent: 2em;"&gt;&lt;span style="font-size: 12px;"&gt;tf.argmin: dimension 变为 axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-indent: 2em;"&gt;&lt;span style="font-size: 12px;"&gt;tf.count_nonzero: reduction_indices 变为 axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-indent: 2em;"&gt;&lt;span style="font-size: 12px;"&gt;tf.expand_dims: dim 变为 axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-indent: 2em;"&gt;&lt;span style="font-size: 12px;"&gt;tf.reduce_all: reduction_indices 变为 axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-indent: 2em;"&gt;&lt;span style="font-size: 12px;"&gt;tf.reduce_any: reduction_indices 变为 axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-indent: 2em;"&gt;&lt;span style="font-size: 12px;"&gt;tf.reduce_join: reduction_indices 变为 axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-indent: 2em;"&gt;&lt;span style="font-size: 12px;"&gt;tf.reduce_logsumexp: reduction_indices 变为 axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-indent: 2em;"&gt;&lt;span style="font-size: 12px;"&gt;tf.reduce_max: reduction_indices 变为 axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-indent: 2em;"&gt;&lt;span style="font-size: 12px;"&gt;tf.reduce_mean: reduction_indices 变为 axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-indent: 2em;"&gt;&lt;span style="font-size: 12px;"&gt;tf.reduce_min: reduction_indices 变为 axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-indent: 2em;"&gt;&lt;span style="font-size: 12px;"&gt;tf.reduce_prod: reduction_indices 变为 axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-indent: 2em;"&gt;&lt;span style="font-size: 12px;"&gt;tf.reduce_sum: reduction_indices 变为 axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-indent: 2em;"&gt;&lt;span style="font-size: 12px;"&gt;tf.reverse_sequence: batch_dim 变为 batch_axis, seq_dim 变为 seq_axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-indent: 2em;"&gt;&lt;span style="font-size: 12px;"&gt;tf.sparse_concat: concat_dim 变为 axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-indent: 2em;"&gt;&lt;span style="font-size: 12px;"&gt;tf.sparse_reduce_sum: reduction_axes 变为 axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-indent: 2em;"&gt;&lt;span style="font-size: 12px;"&gt;tf.sparse_reduce_sum_sparse: reduction_axes 变为 axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-indent: 2em;"&gt;&lt;span style="font-size: 12px;"&gt;tf.sparse_split: split_dim 变为 axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;tf.listdiff 已重命名为 tf.setdiff1d 以匹配 NumPy 命名。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;tf.inv 已被重命名为 tf.reciprocal（组件的倒数），以避免与 np.inv 的混淆，后者是矩阵求逆。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;tf.round 现在使用 banker 的舍入（round to even）语义来匹配 NumPy。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;tf.split现在以相反的顺序并使用不同的关键字接受参数。我们现在将NumPy order 匹配为tf.split（value，num_or_size_splits，axis）。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;tf.sparse_split现在采用相反顺序的参数，并使用不同的关键字。我们现在将NumPy order 匹配为tf.sparse_split（sp_input，num_split，axis）。注意：我们暂时要求 tf.sparse_split 需要关键字参数。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;tf.concat现在以相反的顺序并使用不同的关键字接受参数。特别地，我们现在将NumPy order匹配为tf.concat（values，axis，name）。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;默认情况下，tf.image.decode_jpeg使用更快的DCT方法，牺牲一点保真度来提高速度。通过指定属性dct_method ='INTEGER_ACCURATE'，可以恢复到旧版行为。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;tf.complex_abs已从Python界面中删除。 tf.abs支持复杂张量，现在应该使用 tf.abs。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Template.var_scope属性重命名为.variable_scope&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;SyncReplicasOptimizer已删除，SyncReplicasOptimizerV2重命名为SyncReplicasOptimizer。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;tf.zeros_initializer（）和tf.ones_initializer（）现在返回一个必须用initializer参数调用的可调用值，在代码中用tf.zeros_initializer（）替换tf.zeros_initializer。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;SparseTensor.shape已重命名为SparseTensor.dense_shape。与SparseTensorValue.shape相同。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;分别替换tf.scalar_summary，tf.histogram_summary，tf.audio_summary，tf.image_summary与tf.summary.scalar，tf.summary.histogram，tf.summary.audio，tf.summary.image。新的摘要ops以名字而不是标签作为它们的第一个参数，意味着摘要ops现在尊重TensorFlow名称范围。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;使用tf.summary.FileWriter和tf.summary.FileWriterCache替换tf.train.SummaryWriter和tf.train.SummaryWriterCache。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;从公共API中删除RegisterShape。使用C++形状函数注册。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Python API 中的 _ref dtypes 已经弃用。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;在C++ API（in tensorflow/cc）中，Input，Output等已经从tensorflow::ops命名空间移动到tensorflow。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;将{softmax，sparse_softmax，sigmoid} _cross_entropy_with_logits的arg order更改为（labels，predictions），并强制使用已命名的args。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;section class="" style="font-size: 16px; white-space: normal; max-width: 100%; box-sizing: border-box; color: rgb(62, 62, 62); background-color: rgb(255, 255, 255); border-width: 0px; border-style: initial; border-color: initial; clear: both; word-wrap: break-word !important;"&gt;&lt;section class="" style="padding: 8px; max-width: 100%; box-sizing: border-box; border-left: 6px solid rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; font-weight: bold; text-decoration: inherit; color: rgb(10, 10, 10); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&amp;nbsp; Bug 修改及其他变动&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="width: 528.188px; white-space: normal;"&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;大量 C++ API 更新。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;新的 op：parallel_stack。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;为RecordReader/RecordWriter 增加了 tf io 压缩选项常量。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;添加了 sparse_column_with_vocabulary_file，指定将字符串特征转换为ID的特征栏（feature column）。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;添加了index_to_string_table，返回一个将索引映射到字符串的查找表。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;添加string_to_index_table，返回一个将字符串与索引匹配的查找表。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;添加ParallelForWithWorkerId函数。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;添加string_to_index_table，返回一个将字符串与索引匹配的查找表。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;支持从contrib / session_bundle中的v2中的检查点文件恢复会话。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;添加了tf.contrib.image.rotate函数，进行任意大小角度旋转。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;添加了tf.contrib.framework.filter_variables函数，过滤基于正则表达式的变量列表。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;make_template（）可以添加 custom_getter_ param。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;添加了关于如何处理recursive_create_dir现有目录的注释。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;添加了QR因式分解的操作。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Python API中的分割和mod现在使用flooring（Python）语义。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Android：预构建的libs现在每晚构建。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Android： TensorFlow 推理库 cmake/gradle build 现在归在 contrib/android/cmake下面&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Android：更强大的会话初始化（Session initialization）代码。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Android：当调试模式激活时，TF stats现在直接显示在demo和日志中&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Android：全新/更好的 README.md 文档&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;saved_model可用作tf.saved_model。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Empty op 现在是有状态的。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;提高CPU上ASSIGN运算的scatter_update的速度。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;更改reduce_join，使其处理reduction_indices的方式与其他reduce_ops相同。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;将TensorForestEstimator移动到contrib/tensor_forest。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;默认情况下启用编译器优化，并允许在configure中进行配置。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;使指标权重 broadcasting 更加严格。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;添加新的类似队列的StagingArea和新运算 ops：stages 和 unstage。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;hr style="white-space: normal;"&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211613qjID53.jpg"/&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;strong style="color: rgb(123, 12, 0); font-size: 18px;"&gt;【寻找AI独角兽】新智元联手10大资本&lt;/strong&gt;&lt;br&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;strong style="color: rgb(123, 12, 0); font-size: 18px;"&gt;启动2017创业大赛&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;AI 创业大赛由新智元与10 家主流 AI 创投机构：蓝驰创投、红杉资本中国基金、高瓴智成人工智能基金、蓝湖资本、蓝象资本、IDG资本、高榕资本、中信建投证券、明势资本、松禾远望基金携手发起，由新智元主办，北京市中关村科技园区管理委员会、中关村科技园区海淀园管理委员会支持，是一场聚合了 AI 技术领袖和投资领袖的盛会。新智元向满怀雄心的未来AI独角兽提供强大的创投资源对接机会，顶级风投 TS 等你来拿。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;strong&gt;http://form.mikecrm.com/gthejw&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;点击文章下方阅读原文，在线填写报名申请报名表。该报名表为参与评选必填资料。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p class="p11" style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;如有更多介绍资料（例如BP等），可发送至&amp;nbsp;&lt;span style="color: rgb(123, 12, 0);"&gt;xzy100@aiera.com.cn&lt;/span&gt;，邮件标题请注明公司名称。如有任何咨询问题，也欢迎向该邮箱发信联系。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p class="p11" style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;大赛咨询，请添加新智元微信号：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211613JC1Wom.jpg"/&gt;&lt;/p&gt;&lt;/div&gt;</description>
      <pubDate>Thu, 16 Feb 2017 10:16:48 +0800</pubDate>
    </item>
    <item>
      <title>DeepMind 是全球 AI 领域 No. 1？一文看懂巨头实力</title>
      <link>http://www.iwgc.cn/link/4723524</link>
      <description>&lt;div class="article-content"&gt;&lt;section style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; font-family: inherit; font-size: 1em; font-weight: inherit; white-space: normal; max-width: 100%; line-height: 28.4444px; border-style: solid none none; border-top-width: 1px; border-top-color: rgb(204, 204, 204); text-decoration: inherit; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-top: -1.2em; max-width: 100%; min-height: 1em; text-align: center; border-width: initial; border-style: none; border-color: initial; line-height: 1.4; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-size: 18px;"&gt;&lt;strong style="font-family: inherit; font-size: 1em; text-decoration: inherit;"&gt;&lt;span style="color: rgb(255, 255, 255); max-width: 100%; line-height: 1.4; font-family: inherit; font-weight: inherit; text-decoration: inherit; background-color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(127, 127, 127); line-height: 22.4px;"&gt;1&amp;nbsp;&lt;/span&gt;新智元编译 &amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;strong style="font-family: inherit; font-size: 1em; text-decoration: inherit;"&gt;&lt;span style="color: rgb(255, 255, 255); max-width: 100%; line-height: 1.4; font-family: inherit; font-weight: inherit; text-decoration: inherit; background-color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/span&gt;&lt;span style="max-width: 100%; line-height: 1.4; font-family: inherit; font-weight: inherit; text-decoration: inherit; background-color: rgb(127, 127, 127); color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/span&gt;&lt;strong style="color: rgb(136, 136, 136); font-size: 12px;"&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;/section&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;来源：Quora&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;编译：刘小芹&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;【新智元导读】&lt;/span&gt;&lt;/strong&gt;&lt;span style="font-size: 14px;"&gt;Google Brain的Eric Jiang昨天在Quora回答提问，分析了谷歌、&lt;span style="font-size: 14px;"&gt;微软、&lt;/span&gt;Facebook、IBM等巨头间的AI实力，引用最新例子（比如 ICLR论文接收）。结合之前Yann LeCun关于几家公司谁的AI最强的回答，可以对全球 AI 实力分布有一个比较好的理解。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211615e7wrTR.gif"/&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;section class="tn-Powered-by-XIUMI" style="white-space: normal; line-height: 25.6px; border-width: 0px; border-style: initial; border-color: initial; clear: both; box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="padding: 8px; border-left: 6px solid rgb(255, 202, 0); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; text-decoration: inherit; color: rgb(10, 10, 10); box-sizing: border-box;"&gt;&lt;section&gt;&lt;strong&gt;谷歌大脑研究工程师 Eric Jang 的回答：DeepMind 是第一，谷歌大脑很快将升到第一梯队&lt;/strong&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;首先，我需要声明我的回答会有一些偏见，因为我在谷歌大脑工作，而且我很喜欢谷歌大脑。我的观点仅代表我自己，不代表我的其他同事或 Alphabet 公司。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;我对“AI研究领域的佼佼者”的科技公司的排名如下：&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;梯队1. DeepMind&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;我认为就现在来说，DeepMind 是 No.1 的。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;他们发表的论文在研究界里很受推崇，而且涉及的领域非常广，例如深度增强学习，贝叶斯神经网络，机器人学，迁移学习，等等。他们从牛津大学和剑桥大学招揽了大量人才，这两所大学是欧洲最好的 ML 研究学府。他们也有一个多元化的团队专注于通用 AI 的研究，包括有专门打造基础设施和工具的软件工程师，帮助设计研究工具的 UX 设计师，甚至有生态学家（Drew Purves）专门研究其他领域，例如生态和智能之间的关系。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;在 PR 和吸引公众目光方面，Deepmind 也是首屈一指的，例如 DQN-Atari 和创造历史的 AlphaGo 时的 PR。每当 Deepmind 发一篇论文，很快就会出现在 Reddit 机器学习板块和 Hacker News 的顶部，表明他们在技术社区多么受到推崇。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;strong style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;梯队&lt;/span&gt;&lt;/strong&gt;2. Google&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;虽然我把两家 Alphabet 的子公司放在这个排名的顶端，但我得声明 Facebook 和 OpenAI 和 Google 是并列处于第二梯队的。&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;Yann LeCun 此前回答过一个类似问题，但我认为他错估了谷歌大脑在研究界的贡献。他说：&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;但它（谷歌大脑）大部分研究是专注于应用程序和产品开发，而不是长期的 AI 研究。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;完全不是这样！错了！&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;TensorFlow（谷歌大脑团队的主要产品）只是谷歌大脑众多项目中的一个，据我所知也是唯一面向外部的产品。谷歌大脑刚成立时，第一个研究项目确实偏向工程，但今天谷歌大脑团队已经有很多员工，关注 AI 每个子领域的长期的 AI 研究，就类似于 FAIR 和 Deepmind。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;举例说来，FAIR 在 ICLR 2017 会议上有16篇论文被收录，其中3篇被录为 Oral（即非常杰出的论文）。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;谷歌大脑今年在 ICLR 上被收录的论文实际上比 FB 还稍微多一些，有20篇，其中4篇被录为 Oral。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;这还不包括 Deepmind 或谷歌其他团队（搜索团队、VR、Photos团队等）的论文。虽然比较被接收的论文数量不是很好的指标，但我想消除那些暗示谷歌大脑不是深度学习研究的好地方的说法。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;谷歌大脑也是拥有很强协作灵活性的产业研究组织。我想世界上没有其他企业或研究机构同时与伯克利、斯坦福、CMU、OpenAI、Deepmind、Google X 以及谷歌内部的无数产品团队在进行合作。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;我相信在不久的将来，谷歌大脑能够升到第一梯队。我个人有接到谷歌大脑和 Deepmind 的 offer，并选择了前者，因为我觉得谷歌大脑能给我更多灵活性来设计自己的研究项目，并且与谷歌内部的其他团队的合作更紧密，而且我加入了目前还不能公开的一些非常有趣的机器人项目。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;strong style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;梯队&lt;/span&gt;&lt;/strong&gt;2. Facebook&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;FAIR 的论文很强，在我印象中他们重点关注的是语言领域的问题，例如问题回答，动态记忆，图灵测试，等等。偶尔他们也会发一些统计学、物理学和深度学习结合的论文。他们在计算机视觉方面也很强。不过除了他们的声誉非常好之外，我对 FAIR 了解不多。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;由于 TensorFlow 的广泛采用，FAIR 几乎已经输掉了深度学习框架方面的竞争，但 Pytorch 是否能夺回市场份额值得观察。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;strong style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;梯队&lt;/span&gt;&lt;/strong&gt;2. OpenAI&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;OpenAI 的成员阵容很强大：Ilya Sutskever（全面的深度学习牛人），John Schulman（TRPO的发明者，硕士方向是策略梯度），Pieter Abbeel（机器人学），Andrej Karpathy（Char-RNN，CNN），Durk Kingma（VAE 的发明者之一），Ian Goodfellow（GAN 的发明者），等等。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;尽管 OpenAI 是一个只有约50人的小团队，但他们有一个顶尖的工程团队，研发一流的、真正有用的研究工具，例如 Gym 和 Unverse。他们也通过提供以前只有大科技公司能用的软件，为更多研究团体提供帮助。这也为其他公司增加了压力，使得他们开始开源代码和工具。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;我差点想把 OpenAI 列为第一梯队，因为在拥有顶级研究人员方面他们不输 Deepmind，但他们成立不久，尚没有经历足够长的时间来证明这一点。他们也还没有发布与 AlphaGo 相当的成果，虽然我认为 Gym 和 Universe 对研究社区的意义非常重要。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;作为一个所有基础设施都完全从头建起的小型非盈利研究团队，他们没有像大科技公司那么多的 GPU 资源、机器人或软件基础设施。拥有大量算力对研究，甚至对一个人能够想到的点子产生很大影响。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;初创公司很艰难，我们可以观察他们在未来几年是否能够继续吸引顶尖的人才。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;strong style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;梯队&lt;/span&gt;&lt;/strong&gt;3. 百度&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;百度 SVAIL 和百度深度学习研究院是做 AI 研究的很好的地方，他们正在开发许多有前景的技术，如家庭助理，盲人助理，自动驾驶汽车等。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;虽然百度存在很多问题，但他们绝对是中国研究AI最厉害的企业。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;strong style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;梯队&lt;/span&gt;&lt;/strong&gt;3. 微软研究院&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;在深度学习的革命之前，微软研究院曾经是最负盛名的地方。他们的成员中多为多年 AI 研究经验的教授，这可能也解释了为什么他们错过了深度学习（因为深度学习的革命主要是由博士生们驱动的）。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;而且，他们几乎所有的深度学习研究都是在 Linux 平台上进行的，他们的深度学习框架 CNTK 得到的关注不及 TensorFlow，torch，Chainer 等。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;strong style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;梯队&lt;/span&gt;&lt;/strong&gt;5. 苹果&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;苹果在招揽人才方面确实有些艰难，因为研究人员通常都想公开出版自己的研究成果。苹果也做一些产品驱动的研究，但这无法吸引哪些想要解决通用 AI 问题的研究人员，或那些希望自己的研究成果被学术圈关注的研究者。我认为他们的设计根基与研究有很多相似之处，尤其是涉及创造力时，但我也认为发布新产品对长期的基础研究会是一种阻碍。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;strong style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;梯队&lt;/span&gt;&lt;/strong&gt;10. IBM&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;我认识一位 IBM Watson 项目的前成员，他把 IBM 的“认知计算工作”描述为完全是一场灾难。这个项目由管理层推动，但这群人完全不懂机器学习能做什么，不能做什么，只是拿这个热词做卖点。Watson 使用深度学习做图像理解，但是据我所知，它的信息检索系统的其余部分并没有真正用到最新的深度学习技术。基本上，我认为IBM是在瞎搞，对初创企业来说，在二级市场有很多应用机器学习的机会。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;备注&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;说实话，所有上述公司（也许除了IBM之外）都是做深度学习研究的好地方，而且鉴于开源软件和现在整个领域的快速发展，我不认为有任何一家科技公司在“领导 AI 研究“。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;我对深度学习研究者的建议是找到一个你感兴趣的团队/项目，不用管别人对声誉的评价，而且专注于将工作做到最好，让你所在的机构成为AI研究的佼佼者。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;section class="tn-Powered-by-XIUMI" style="white-space: normal; line-height: 25.6px; border-width: 0px; border-style: initial; border-color: initial; clear: both; box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="padding: 8px; border-left: 6px solid rgb(255, 202, 0); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; text-decoration: inherit; color: rgb(10, 10, 10); box-sizing: border-box;"&gt;&lt;section&gt;&lt;strong&gt;如何评价苹果、微软、谷歌和Facebook之间的人工智能实力？&lt;strong style="color: rgb(10, 10, 10); font-size: 18px; white-space: normal;"&gt;LeCun 的回答&lt;/strong&gt;&lt;/strong&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;关于这一点，我的立场让我无法做出公平的回答，但有几点我可以说一下：&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px; color: rgb(123, 12, 0);"&gt;苹果不是人工智能研究圈子里的玩家，因为他们的公司文化很隐秘。&lt;/span&gt;&lt;/strong&gt;&lt;span style="font-size: 14px;"&gt;你不可能在隐秘的氛围下做前沿研究。不发表则算不是研究，顶多也就是技术进步。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;微软&lt;/span&gt;&lt;/strong&gt;&lt;span style="font-size: 14px;"&gt;一直都在做一些很好的工作，但有很多人才都在从微软流向Facebook和谷歌。微软过去做了一些很厉害的语音相关的深度学习研究（2000年左右在手写识别方面取得了很好的成果）。但从他们最近的一些项目可以看出，微软研究院的目标相比FAIR或DeepMind要逊色很多。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;谷歌（具体是Google Brain等研究组）&lt;/span&gt;&lt;/strong&gt;&lt;span style="font-size: 14px;"&gt;无论是在深度学习产品还是服务方面都可以算是领先的，因为谷歌在这方面起步最早。他们在基础设施（比如TensorFlow和TPU）上有很多积累。&lt;span style="font-size: 14px; color: rgb(123, 12, 0);"&gt;&lt;strong&gt;但谷歌 AI 研究的关注点是应用及产品开发，而非长期 AI 研究。证据就是Google Brain 的一些顶尖研究人员离开了那里，去了DeepMind、OpenAI，或者到了FAIR。&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;DeepMind&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;span style="font-size: 14px;"&gt;在基于学习的 AI（learning-based AI）方面一直都做得很好。他们的长期目标跟FAIR的有些类似，研究的课题重合度也挺高：无监督/生成模型，规划（planning）、RL、游戏、记忆增强网络、差分编程（differentiable programming）。DeepMind的一个问题在于，他们从地理位置和组织结构上都远离谷歌（Alphabet）。这样就不太方便为其所有者盈利，不过他们现在看来做得挺好的。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;Facebook&lt;/span&gt;&lt;/strong&gt;&lt;span style="font-size: 14px;"&gt;的人工智能研究所FAIR成立于2.5年前，在这么短的时间内在业界树立起自身领导者的地位。我自己都为FAIR能吸引这么多世界顶尖AI研究员而感到震惊（FAIR有60多个研究员和工程师，现在分布在纽约、Menlo Park、巴黎和西雅图）。同样，我也为我们在过去两年半时间里取得的成果感到震惊。我们的目标远大，在FAIR我们从长期着眼，在公司里也有一定的影响力，因此存在不会受质疑（不出成果）。最关键的，我们非常开放：我们所有的研究员一年都会发表多篇论文。没有什么比看见一位前景大好的研究员加入一家不那么开放的公司或者一家初创企业，然后从研究圈子里消失更令人当头一棒的了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 12px;"&gt;原文链接：https://www.quora.com/Who-is-leading-in-AI-research-among-big-players-like-IBM-Google-Facebook-Apple-and-Microsoft/answer/Eric-Jang?srid=zhKS&lt;/span&gt;&lt;/p&gt;&lt;hr style="white-space: normal;"&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211615d6vqSQ.jpg"/&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;strong style="color: rgb(123, 12, 0); font-size: 18px;"&gt;【寻找AI独角兽】新智元联手10大资本&lt;/strong&gt;&lt;br&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;strong style="color: rgb(123, 12, 0); font-size: 18px;"&gt;启动2017创业大赛&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;AI 创业大赛由新智元与10 家主流 AI 创投机构：蓝驰创投、红杉资本中国基金、高瓴智成人工智能基金、蓝湖资本、蓝象资本、IDG资本、高榕资本、中信建投证券、明势资本、松禾远望基金携手发起，由新智元主办，北京市中关村科技园区管理委员会、中关村科技园区海淀园管理委员会支持，是一场聚合了 AI 技术领袖和投资领袖的盛会。新智元向满怀雄心的未来AI独角兽提供强大的创投资源对接机会，顶级风投 TS 等你来拿。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;strong&gt;http://form.mikecrm.com/gthejw&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;点击文章下方阅读原文，在线填写报名申请报名表。该报名表为参与评选必填资料。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p class="p11" style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;如有更多介绍资料（例如BP等），可发送至&amp;nbsp;&lt;span style="color: rgb(123, 12, 0);"&gt;xzy100@aiera.com.cn&lt;/span&gt;，邮件标题请注明公司名称。如有任何咨询问题，也欢迎向该邮箱发信联系。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p class="p11" style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;大赛咨询，请添加新智元微信号：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211616GyYTlj.jpg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;/div&gt;</description>
      <pubDate>Thu, 16 Feb 2017 10:16:48 +0800</pubDate>
    </item>
    <item>
      <title>微软郑宇再谈“上海踩踏事件”，用时空残差网络解决公共安全问题</title>
      <link>http://www.iwgc.cn/link/4723525</link>
      <description>&lt;div class="article-content"&gt;&lt;section style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; font-family: inherit; font-size: 1em; font-weight: inherit; white-space: normal; max-width: 100%; line-height: 28.4444px; border-style: solid none none; border-top-width: 1px; border-top-color: rgb(204, 204, 204); text-decoration: inherit; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-top: -1.2em; max-width: 100%; min-height: 1em; text-align: center; border-width: initial; border-style: none; border-color: initial; line-height: 1.4; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-size: 18px;"&gt;&lt;strong style="font-family: inherit; font-size: 1em; text-decoration: inherit;"&gt;&lt;span style="color: rgb(255, 255, 255); max-width: 100%; line-height: 1.4; font-family: inherit; font-weight: inherit; text-decoration: inherit; background-color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(127, 127, 127); line-height: 22.4px;"&gt;1&amp;nbsp;&lt;/span&gt;新智元报道 &amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;strong style="font-family: inherit; font-size: 1em; text-decoration: inherit;"&gt;&lt;span style="color: rgb(255, 255, 255); max-width: 100%; line-height: 1.4; font-family: inherit; font-weight: inherit; text-decoration: inherit; background-color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/span&gt;&lt;span style="max-width: 100%; line-height: 1.4; font-family: inherit; font-weight: inherit; text-decoration: inherit; background-color: rgb(127, 127, 127); color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/span&gt;&lt;strong style="color: rgb(136, 136, 136); font-size: 12px;"&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;/section&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;作者：零夏&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: left;"&gt;&lt;strong style="font-size: 14px; max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: left;"&gt;&lt;strong style="font-size: 14px; max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;【新智元导读&lt;/span&gt;】&lt;/strong&gt;&lt;span style="font-size: 14px;"&gt;近日微软亚洲研究院主管研究员郑宇发在 AAAI 2017 发布了其团队用深度时空残差网络预测城市人流量的论文。他在微博上称这是兑现了“上海踩踏事件”后的承诺。本文结合郑宇演讲和论文，介绍该项目训练数据获取及整合、如何融合外部因素和时间空间相关性、为什么选择深度残差网络等方面，并且讨论该技术在实际应用中的成本，以及深度学习对其它社会公共问题的解决方案。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: left;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211617unMH97.gif"/&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;【人物简介】&lt;/span&gt;&lt;/strong&gt;&lt;span style="font-size: 14px;"&gt;郑宇 (博士、教授、博导)，微软亚洲研究院主管研究员、美国计算机学会杰出科学家(ACM Distinguished Scientist)、上海交通大学讲座教授（Chair Professor）、香港科技大学和香港理工大学客座教授。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/14872116175XmiKI.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;span style="font-size: 12px; color: rgb(136, 136, 136);"&gt;郑宇&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: left;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;郑宇团队一直从事城市计算的相关研究，之前他们利用机器学习对雾霾进行预测。&lt;strong&gt;&lt;span style="font-size: 14px; color: rgb(171, 25, 66);"&gt;这篇关于城市人流量预测的AAAI论文也是首次（在国际知名学术会议上）公开发表的把深度学习用于城市大数据的研究成果，并开启了深度学习在时空数据中的探索之路（以往的深度学习的研究通常集中在视频、图像和文本数据上）。&lt;/span&gt;&lt;/strong&gt;新智元于2月9日参加郑宇对论文的分享，并且对郑宇进行了访谈。本文将结合郑宇演讲和论文，从训练数据获取及整合、如何融合外部因素和时间空间相关性、为什么选择深度残差网络等方面进行讲解，并且讨论该技术在实际应用中的问题，以及深度学习对其它社会公共问题的解决方案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/14872116184XmhJH.jpg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;section class="tn-Powered-by-XIUMI" style="white-space: normal; border-width: 0px; border-style: initial; border-color: initial; clear: both; box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="padding: 8px; border-left: 6px solid rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; font-weight: bold; text-decoration: inherit; color: rgb(10, 10, 10); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="box-sizing: border-box;"&gt;&lt;span style=""&gt;起因——上海外滩踩踏事件&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;2014到2015的跨年之夜，在上海外滩发生的一起踩踏事故，事故造成多人伤亡。事故发生前外滩地区人流量超过100万人、超出该地区人流容量上限（30万人）达2倍多。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/14872116181UjeGE.jpg"/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;悲剧发生后，郑宇在微博上表示：“上海的踩踏悲剧完全可以通过基于手机数据的城市异常检测来避免。当发现人流过于聚集并且移动滞留，就可以提前预警和疏散... 是时候加快城市计算的产业化了。”&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;他认为，如果我们能够在提前几个小时就知道外滩会有多少人进去，多少人出来，如果我们知道，进去的人远远大于出来的人，而且知道这个地方的存在容量不足以支撑这么多人停留的时候，&lt;strong&gt;我们就应该提前做管控，发布一些疏导信息，&lt;/strong&gt;甚至提前倡导不要进入该区域。因为这么多人一旦聚集在一个地方，上百万人，仅靠一两百个警察或管理人员来维护秩序是很难做到的，那个时候就为时太晚了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit&gt;&lt;br&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;所以当时郑宇就有了这个想法。他说，这次也算兑现了自己的承诺。当时在说这个的时候，有很多人不太理解，因为他们对技术背景可能并不是那么熟悉，觉得这是不可能做到的。但现在我们真的把它做出来了，还结合一些实际的案例，证明这个技术是可行的，其实可以推广到很多城市，对我们的城市公共安全和交通等管理都有很大的价值和帮助。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;section class="tn-Powered-by-XIUMI" style="white-space: normal; border-width: 0px; border-style: initial; border-color: initial; clear: both; box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="padding: 8px; border-left: 6px solid rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; font-weight: bold; text-decoration: inherit; color: rgb(10, 10, 10); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="box-sizing: border-box;"&gt;&lt;span style=""&gt;时空深度残差网络预测城市人流量技术解读&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span class="author-2682522 font-size-3" style="font-size: 11pt;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span class="author-2682522 font-size-3" style="font-size: 11pt;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;郑宇表示，传统的预测人流量是从个人出发，把每个人的运动轨迹预测来，然后再按区域对进出的人流进行整合，从而得到各个区域的人流量。这不仅涉及到个人的隐私问题，而且准确性也很低（要准确预测每个人的活动是一件非常困难事情）。也有通过基于物理学模型、交通动力学模型之类的经典模型的方法，但这些方法难以应对大范围（整个城市范围）、高密度(上千万人口）和细粒度时空范围（每平方公里、每小时）的集成、同时预测（即不是每个区域单独预测，而是所有区域同时预测，因为各个区域的人流量有关联性）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;而他们这次研究是第一次将深度残差网络用于时空数据，提出了时空深度残差网络模型（ST-ResNet），把整个城市，比如说北京地区，划成很多个网格，多个网格进行同时分析，所以它是一种整体性的预测。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span class="author-2682522 font-size-3" style="font-size: 11pt;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span class="author-2682522 font-size-3" style="font-size: 11pt;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-weight: 700; font-size: 16px;"&gt;城市人流量预测三大挑战&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span class="author-2682522 font-size-3" style="font-size: 11pt;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;郑宇提到城市人流量预测三大挑战：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;1.影响到人流量的因素非常之多，与区域里面前一个小时，有多少人进和出有关系，与周边区域有多少人进和出也有关系，甚至很远的地方，有多少人进和出对这个地方的人流量也会有影响。一旦一个大型事件发生的时候，很多人会从很远的地方坐地铁，或者通过高速公路前往，并不直接经过该周边区域，就直接达到，所以一个地方的人流量不光只是取决于周边有多少人。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;2. 外部的影响因素多：天气、事件；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;3. 时间、空间属性导致其他的深度学习方法如 CNN、RNN、LSTM 在这里无效。空间特点：距离和层次；时间特点：相近的时间人流量是平滑的，但还要看它的周期性和趋势。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span class="author-2682522 font-size-3" style="font-size: 11pt;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211618IB0Vnl.jpg"/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit style="display: block;"&gt;&lt;span style="font-weight: 700; font-size: 16px;"&gt;训练数据的获取和整合&lt;/span&gt;&lt;/inherit&gt;&lt;inherit style="display: block;"&gt;&lt;span style="font-weight: 700; font-size: 16px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;该论文中所用的数据来自北京近几年的出租车数据和纽约的自信车租赁信息。新智元请郑宇介绍数据经验，包括如何拿到这些数据并且如何把这些数据变成可以训练、可以评测的数据。郑宇表示，BikeNYC 是公开数据，北京和贵阳的数据是跟政府进行合作获得。数据大小是TB级。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;数据其实是一个很重要很关键的问题，特别是现实中我们面临多元异构异源的融合问题，可用的方法包括拼接技术、通过语义等方法融合。在郑宇另外一篇发在 IEEE Transaction on BigData 创刊的文章 “Methodologies for cross-domain data fusion: AnOverview”主要就是讲数据的整合。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span class="author-2682522 font-size-3" style="font-size: 11pt;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211619d5uqRQ.jpg"/&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span class="author-2682522 font-size-3" style="font-size: 11pt;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;郑宇团队在贵阳市做了一个真实的系统，这个系统现在正在实实在在的运转中。大家看到系统现在每分每秒都在不停的进来数据，然后系统也在不停的去预测。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;在这个项目中城市被划分成1km*1km的格子。然后人流量数据也好，或者是出租车轨迹也好，把它投射在这个网格里面，生成一些简单的热度图。比如说红的网格就说明这地方人越多。然后系统会同时有对应的事件和天气信息，这些内容相结合就构成了现在的一个数据输入。把以前的时空数据转换成这样一个模式，生成很多帧，这样就是一个序列了。然后去预测，每个格子里面未来会有多少出租车的进和出。如果可以给系统人流量的数据，系统就能预测对应这个数据的人流量。比如通过手机信号，系统就可以预测，比如有多少人进出地铁的刷卡记录，系统就能预测地铁站有多少人进和出。&lt;strong&gt;这个模型是通用的，使用时只需要在数据上面去验证这个模型的准确性和有效性。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px; font-weight: 700;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span class="author-2682522 b" style="font-weight: 700;"&gt;把时间和空间特点融合进训练过程&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span class="author-2682522 b" style="font-weight: 700;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;有了这些数据之后是不是直接用深度学习就可以了呢？答案是否定的。那怎么来做呢？郑宇说，首先把最近几个小时的数据，比如说最近这几帧的数据输入到一个深度残差网络里面，我们叫时空残差网络里面来模拟。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit style="display: block;"&gt;&lt;br&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;首先，模拟相邻时刻，对应最近的这段，它应该是一个平滑的过程，比如晚上六点跟七点流量变化不会很大。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit style="display: block;"&gt;&lt;br&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;第二，把对应时间点昨天这个时刻，比如说昨天的两点钟，前天两点钟以及再往前面同一时刻的这个数据，作为输入来模拟周期性。把前面这几个对应时间点的数据拿来作为参考，就相当于把周期属性考虑进来了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit style="display: block;"&gt;&lt;br&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 11pt;"&gt;第三&lt;/span&gt;&lt;span style="font-size: 14px;"&gt;，把更远时间点相同时间点（比如上个月、以及上上个月礼拜三下午2点钟）的数据拿进来，然后模拟趋势性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;所以这边分别是模拟刚才说的那3个时间属性，平滑性、周期性以及趋势性，这3个残差网络结构都是一样的，都是深度残差网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span class="author-2682522 font-size-3" style="font-size: 11pt;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/14872116195XniKI.jpg"/&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span class="author-2682522 font-size-3" style="font-size: 11pt;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;这3个结果出来之后，系统会做一个融合。第一部分融合，就是只考虑它的时间空间属性。再把外部因素拿过来做2次融合得到一个结果。因为外部因素，比如世界的天气情况，可能也是整个全局的、广域的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit style="display: block;"&gt;&lt;br&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;刚刚是讲怎么模拟时间3个特性，那空间特性怎么模拟的呢？就看着里面的一个结构，它抓的正是空间属性。我们就进去看看这个深度残差网络到底是怎么个结构。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span class="author-2682522 font-size-3" style="font-size: 11pt;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span class="author-2682522 font-size-3" style="font-size: 11pt;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211619zrQMdc.jpg"/&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;我们都知道深度卷积神经网络，是这样一个过程，它把一些区域划成格子之后，把相关的区域做一个卷积运算再合并到一个值。你可以认为，通过卷积之后，我们把周围地区的这种人流量的相关性给抓住了，卷积多次之后，相当于把很远地方的属性都卷积到一起了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span class="author-2682522 b" style="font-weight: 700;"&gt;为什么要用深度残差网络？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;如果你想捕捉很远的地方跟你这个地方的相关性的话，网络层次就必须比较深。如果只有一层的话，你根本抓不到很远的地方的相关性。可一旦网络层次比较深，我们的训练会变得非常复杂、非常困难。&lt;strong&gt;为了保证训练效果，提高训练精度，我们引入了深度残差网络，来做这个事情&lt;/strong&gt;&lt;strong&gt;。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;span style="font-size: 14px; font-weight: 700;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 11pt;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;这就是为什么我们要用残差网络来解决这个问题。&lt;strong&gt;为了能够捕捉距离不同的区域之间的人流量的空间相关性，我们需要很深的卷积神经网络，但是一旦卷积神经网络很深，训练效果就变得很差，所以另一方面需要借助深度残差网络这个结构来使训练效果变得更好。&lt;/strong&gt;这部分其实是抓住了空间的属性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit style="display: block;"&gt;&lt;br&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 11pt;"&gt;&lt;/span&gt;&lt;span style="font-size: 14px;"&gt;而前面刚刚说的这个结构就是时间，这3个是时间的平滑性、周期性和趋势性，而每一个内部就抓住了空间的特性，就是在相邻的此刻，他们的是空间怎么样的，在周期上，空间是怎么样的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;因为有了之前对时空数据深刻的理解，我们才能设计出这样一个网络结构来，这网络结构的优势是什么呢？为什么不直接用深度神经网络，为什么不用RNN的网络？LSTM为什么不能直接用呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;郑宇说，直接用传统的RNN和LSTM，如果你希望数据里面包含周期性和趋势性，那你输入的数据就必须很长，如果你只用了最近两个小时的数据进行输入，你不可能从里面体现周期性，也不可能体现趋势性。但如果你把过去3个月的数据做了RNN输入的话，这个模型就会变得非常大，非常复杂，最后是很难训练的，效果也很不好。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit style="display: block;"&gt;&lt;br&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 11pt;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;在我们的模型里，我们根据先验知识，只需要抽取一些关键帧，比如说昨天同一时刻，前天同一时刻，其他时间可以不做输入。这样的话，大概只要用几十帧的关键帧，就可以体现出我们几个月里面所包含的周期性和趋势性，使得我们的网络结构大大简化，训练的质量和效果也大大提高，这就是很关键的一个地方。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;新智元记者问道，&lt;/span&gt;&lt;span style="font-size: 11pt;"&gt;这次的神经网络做到多少层呢？郑宇表示&lt;/span&gt;&lt;span style="font-size: 14px;"&gt;，这个项目采用了不同的参数做实验，现在得到最好的结果是24层。具体多少层效果最好，跟不同的应用和数据规模都有关系。&lt;strong&gt;对于不同的问题，最好效果的层次是不一样的。&lt;/strong&gt;如果现在换成上海市的数据训练，可能效果最好的层数又不一样了。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;section class="tn-Powered-by-XIUMI" style="white-space: normal; border-width: 0px; border-style: initial; border-color: initial; clear: both; box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="padding: 8px; border-left: 6px solid rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; font-weight: bold; text-decoration: inherit; color: rgb(10, 10, 10); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="box-sizing: border-box;"&gt;&lt;span style=""&gt;实际应用成本高吗？&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 11pt;"&gt;&lt;span style="font-size: 14px; font-weight: 700;"&gt;新智元&lt;/span&gt;：训练需要多长时间？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px; font-weight: 700;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 11pt;"&gt;&lt;span style="font-size: 14px; font-weight: 700;"&gt;郑宇&lt;/span&gt;：&lt;/span&gt;&lt;span style="font-size: 14px;"&gt;训练时间大概一两天，根据具体问题有所不同，使用的计算资源不同而不同，总体说来不会太慢。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 11pt;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 11pt;"&gt;&lt;span style="font-size: 14px; font-weight: 700;"&gt;新智元&lt;/span&gt;：如果应用的话，需要很多算力嘛，成本是否是这些公共部门可以承担的？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit style="display: block;"&gt;&lt;br&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 11pt;"&gt;&lt;span style="font-size: 14px; font-weight: 700;"&gt;郑宇&lt;/span&gt;：&lt;/span&gt;&lt;span style="font-size: 14px;"&gt;线上运行花的钱不多，但是你要接入在线的数据。成本方面最大的成本是数据接入成本，第二才是离线训练，最后是线上的运行，其实花不了太多钱，几块GPU就搞定了。我相信这是一个可以承担的合理数字。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 11pt;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;span style="font-size: 14px; font-weight: 700;"&gt;新智元&lt;/span&gt;：有没有跟政府合作应用？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit style="display: block;"&gt;&lt;br&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 11pt;"&gt;&lt;span style="font-size: 14px; font-weight: 700;"&gt;郑宇&lt;/span&gt;：&lt;/span&gt;&lt;span style="font-size: 14px;"&gt;目前我们与贵阳政府有合作，贵阳政府的大数据基地目前是唯一可以接入实时数据的，但是因为城市规模以及出租车数量相对一线城市有差异，所以数据量不大。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;section class="tn-Powered-by-XIUMI" style="white-space: normal; border-width: 0px; border-style: initial; border-color: initial; clear: both; box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="padding: 8px; border-left: 6px solid rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; font-weight: bold; text-decoration: inherit; color: rgb(10, 10, 10); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="box-sizing: border-box;"&gt;&lt;span style=""&gt;在雾霾、反恐等其它方面的应用&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit style="display: block;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;strong&gt;新智元&lt;/strong&gt;：您觉得这次的研究成果接下来会在哪些领域得到最快的应用？&lt;/span&gt;&lt;/inherit&gt;&lt;inherit style="display: block;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;strong&gt;郑宇&lt;/strong&gt;：在交通管理和公共安全部门会最先应用。之后地铁调度也可以用到。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;span style="font-size: 11pt; font-weight: 700;"&gt;新智元&lt;/span&gt;：您还做过雾霾的预测，请问这方面用到的技术又是什么？是否也是深度残差网络？雾霾预测有什么新的进展吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;郑宇&lt;/span&gt;&lt;/strong&gt;&lt;span style="font-size: 14px;"&gt;：雾霾跟这个问题不一样，。雾霾以前根本不能用深度学习做，因为数据量不够大。我们中国是2012年才开始对外公布pm2.5浓度，站点也不是很多，且每个小时才公布一次空气质量读数，因此样本不是很多。随着时间越来越久，慢慢的就可以开始引入深度学习的方法来做。即便要用深度学习也得有讲究，要考虑数据的时空属性，以及样本的不充裕。因此，这个网络结构怎么优化，怎么利用时空数据的特性，怎么降低这个层次，同时保证精度，还是有一定难度的。深度学习在时空数据上的探索，绝对不是直接的拿来主义，还有很多问题有待解决和深挖。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;span style="font-size: 11pt; font-weight: 700;"&gt;新智元&lt;/span&gt;：反恐方面，人工智能有些什么样的解决方案？论文提到的技术，在反恐方面有应用前景吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;span class="author-2682522 b font-size-3" style="font-size: 11pt; font-weight: 700;"&gt;郑宇&lt;/span&gt;：反恐也是完全不一样的问题，它属于异常检测，是否能提前知道可能发生的事情，并不是大样本的数据。可以通过机器学习来做。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;hr style="white-space: normal;"&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211619ExWRjh.jpg"/&gt;&lt;strong style="text-align: center; color: rgb(123, 12, 0); font-size: 18px;"&gt;【寻找AI独角兽】新智元联手10大资本&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;strong style="color: rgb(123, 12, 0); font-size: 18px;"&gt;启动2017创业大赛&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;AI 创业大赛由新智元与10 家主流 AI 创投机构：蓝驰创投、红杉资本中国基金、高瓴智成人工智能基金、蓝湖资本、蓝象资本、IDG资本、高榕资本、中信建投证券、明势资本、松禾远望基金携手发起，由新智元主办，北京市中关村科技园区管理委员会、中关村科技园区海淀园管理委员会支持，是一场聚合了 AI 技术领袖和投资领袖的盛会。新智元向满怀雄心的未来AI独角兽提供强大的创投资源对接机会，顶级风投 TS 等你来拿。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;strong&gt;http://form.mikecrm.com/gthejw&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;点击文章下方阅读原文，在线填写报名申请报名表。该报名表为参与评选必填资料。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p class="p11" style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;如有更多介绍资料（例如BP等），可发送至&amp;nbsp;&lt;span style="color: rgb(123, 12, 0);"&gt;xzy100@aiera.com.cn&lt;/span&gt;，邮件标题请注明公司名称。如有任何咨询问题，也欢迎向该邮箱发信联系。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p class="p11" style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;大赛咨询，请添加新智元微信号：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211620UNc7zx.jpg"/&gt;&lt;/p&gt;&lt;/div&gt;</description>
      <pubDate>Thu, 16 Feb 2017 10:16:48 +0800</pubDate>
    </item>
    <item>
      <title>AI 派系争斗如火如荼：概率编程技术能彻底取代神经网络吗？</title>
      <link>http://www.iwgc.cn/link/4723526</link>
      <description>&lt;div class="article-content"&gt;&lt;section style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; font-family: inherit; font-size: 1em; font-weight: inherit; white-space: normal; max-width: 100%; line-height: 28.4444px; border-style: solid none none; border-top-width: 1px; border-top-color: rgb(204, 204, 204); text-decoration: inherit; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-top: -1.2em; max-width: 100%; min-height: 1em; text-align: center; border-width: initial; border-style: none; border-color: initial; line-height: 1.4; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-size: 18px;"&gt;&lt;strong style="font-family: inherit; font-size: 1em; text-decoration: inherit;"&gt;&lt;span style="color: rgb(255, 255, 255); max-width: 100%; line-height: 1.4; font-family: inherit; font-weight: inherit; text-decoration: inherit; background-color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(127, 127, 127); line-height: 22.4px;"&gt;1&amp;nbsp;&lt;/span&gt;新智元报道 &amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;strong style="font-family: inherit; font-size: 1em; text-decoration: inherit;"&gt;&lt;span style="color: rgb(255, 255, 255); max-width: 100%; line-height: 1.4; font-family: inherit; font-weight: inherit; text-decoration: inherit; background-color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/span&gt;&lt;span style="max-width: 100%; line-height: 1.4; font-family: inherit; font-weight: inherit; text-decoration: inherit; background-color: rgb(127, 127, 127); color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/span&gt;&lt;strong style="color: rgb(136, 136, 136); font-size: 12px;"&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;/section&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;作者：张易&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong style="font-size: 14px; max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong style="font-size: 14px; max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;【新智元导读&lt;/span&gt;】&lt;/strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;span style="font-size: 14px;"&gt;Gamalon的CEO和创始人Ben Vigoda近日放出豪言，说他和他的团队所采用的概率编程的技术， 终将在所有的应用中彻底取代神经网络——这有可能吗？&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211621mfEz1Z.gif"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;AI非指一物，它涵盖了数个思想流派。Pedro Domingos在他的专著《终极算法》中，把它们称为AI部落。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;如这位华盛顿大学的计算机学家所说，每个部落都采用了看上去非常不同的技术。比如进化论者，相信他们能够在数码世界中重现自然选择。符号论者则一条规则一条规则地把具体的知识编码到计算机中。&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;眼下，联结主义者吸引了全部眼球。他们培育了深度神经网络和模式识别系统，给Google、Facebook和微软等企业带来了勃勃生机。但不管媒体说什么，其他部落仍然会在AI崛起的进程中起到自己的作用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211622yqPLdb.jpg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;符号学派（symbolists）更多关注哲学、逻辑学和心理学，并将学习视为逆向演绎（inverse of deduction）；联结学派（connectionists）专注物理学和神经科学，并相信大脑的逆向工程；进化学派，正如其名称所示，在遗传学和进化生物学的基础上得出结论。贝叶斯学派（Bayesians）注重统计学和概率推理；类推学派（analogizers）更多是关注心理学和数学优化来推断相似性判断。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;就拿Gamalon的CEO和创始人Ben Vigoda来说，他属于贝叶斯学派，主张通过科学方法构建AI。Vigoda 获得了麻省理工学院统计物理学和机器学习的博士学位。相比于建设自主分析数据并得出结论的神经网络，他和他的团队选择使用概率编程，程序基于他们自己的一些假设，然后用数据不断去修正。他的新兴公司得到了Darpa（Defense Advanced Research Projects Agency）的扶持，今晨浮出水面。&lt;/span&gt;&lt;/p&gt;&lt;p style="max-width: 100%; min-height: 1em; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;br style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="max-width: 100%; min-height: 1em; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211622CvUPhf.gif"/&gt;&lt;br style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/p&gt;&lt;p style="max-width: 100%; min-height: 1em; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-size: 12px; color: rgb(136, 136, 136);"&gt;《福布斯》对Gamalon公司的报道，里面提到使用 Bayesian Program Synthesis，系统能够自行编写代码，用最优的方法解释收集到的数据，相比传统机器学习需要的数据量更少，训练的速度也更快。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Gamalon的技术可以应用于机器翻译，同时公司也在开发企业级文本语义抽取的工具。Vigoda声称他的概率编程能够产出比神经网络学习速度更快的AI，而所需数据却小得多。“你可以慎重选择你教给它的东西，”他说，“也可以编辑你已经教它的东西。”&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;如一些人指出的那样，要想催生真正像人类那样思考的机器，方法是关键。神经网络需要巨量的经过仔细标注的数据，而这并非随时可得。Vigoda甚至放出豪言，说他的技术终将在所有的应用中彻底取代神经网络，“这是再清楚不过的。”他说。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;此前基于概率统计的贝叶斯算法最常见的应用就是反垃圾邮件功能，贝叶斯分类的运作是借着使用标记与垃圾邮件、非垃圾邮件的关连，然后搭配贝叶斯推断来计算一封邮件为垃圾邮件的可能性。如果你使用电子邮件超过10年，应该能感觉到垃圾邮件过滤系统的改进。 贝叶斯学派专注于研究概率推理和用贝叶斯定理解决问题。贝叶斯学派从一个信念开始，他们称之为“先验”（prior）。然后，他们收集一些数据，并基于该数据更新先验；得到的结果他们称之为“后验”（posterior）。然后，他们用更多的数据来处理后验，并使之变成先验。这个过程不断循环往复，知道得到最终的答案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;加州大学洛杉矶分校计算机科学系的 Judea Pearl 是贝叶斯方法的著名研究者之一。微软 Genomics Group 的负责人 David Heckerman 也是著名的贝叶斯方法研究者，他帮助微软在 Outlook 和 Hotmail 邮件系统中开发了不同的数据挖掘工具和垃圾邮件过滤工具。加州大学伯克利分校的 Michael Jordan 也是这一领域的主要研究者。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211622phGC42.jpg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;但就如同深度学习不是人工智能的唯一路径一样，概率编程也不是。高斯法、进化算法、强化学习也是一样。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;有些时候，AI部落之间会恶语相向；有些时候，他们会为了抬高自身技术而压低别人。但现实是，AI将诞生于许多技术的合力。尽管存在着竞争，所有人都是在向同一个目标努力。&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;概率编程让研究者如同程序员编程那样构建机器学习算法。但其技术的真正优势在于处理不确定性的能力。这就允许AI在较少的数据量上进行学习，同时也能帮助研究者理解AI为何会做出某些特定的决策，而如果他们不同意这些决策，也更易于对AI进行调整。所有这些都是真正的AI所不可或缺的，无论是在它和人类对话时还是在无人驾驶中规避一次事故时。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;但神经网络已经在图像和语音识别中证明了自己的价值，他们不必和像概率编程这样的技术竞争。实际上，Google的研发人员正在努力建造融合两者的系统。二者优势互补。哥伦比亚大学计算机学家、Gamalon顾问David Blei曾参加过此类混合模型的研究，他说：“深度神经网络和概率模型是紧密关联的，有许多概率建模就发生在神经网络之中。”&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;最好的AI不可避免地综合了多种技术。比如AlphaGo，Google DeepMind 实验室的突破性系统。它将神经网络、强化学习和其他技术融合到一起。在Blei的眼中，AI的世界不存在部落，而是每个人都在追寻同样的终极算法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;hr&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211623BuTOge.jpg"/&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;strong style="color: rgb(123, 12, 0); font-size: 18px;"&gt;【寻找AI独角兽】新智元联手10大资本&lt;/strong&gt;&lt;br&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;strong style="color: rgb(123, 12, 0); font-size: 18px;"&gt;启动2017创业大赛&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;AI 创业大赛由新智元与10 家主流 AI 创投机构：蓝驰创投、红杉资本中国基金、高瓴智成人工智能基金、蓝湖资本、蓝象资本、IDG资本、高榕资本、中信建投证券、明势资本、松禾远望基金携手发起，由新智元主办，北京市中关村科技园区管理委员会、中关村科技园区海淀园管理委员会支持，是一场聚合了 AI 技术领袖和投资领袖的盛会。新智元向满怀雄心的未来AI独角兽提供强大的创投资源对接机会，顶级风投 TS 等你来拿。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;strong&gt;http://form.mikecrm.com/gthejw&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;点击文章下方阅读原文，在线填写报名申请报名表。该报名表为参与评选必填资料。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p class="p11" style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;如有更多介绍资料（例如BP等），可发送至&amp;nbsp;&lt;span style="color: rgb(123, 12, 0);"&gt;xzy100@aiera.com.cn&lt;/span&gt;，邮件标题请注明公司名称。如有任何咨询问题，也欢迎向该邮箱发信联系。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p class="p11" style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;大赛咨询，请添加新智元微信号：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211623wpOJb9.jpg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;/div&gt;</description>
      <pubDate>Thu, 16 Feb 2017 10:16:48 +0800</pubDate>
    </item>
    <item>
      <title>条条大路通罗马之 LS-GAN：限制 GAN 的无限建模能力</title>
      <link>http://www.iwgc.cn/link/4723527</link>
      <description>&lt;div class="article-content"&gt;&lt;section style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; font-family: inherit; font-size: 1em; font-weight: inherit; white-space: normal; max-width: 100%; line-height: 28.4444px; border-style: solid none none; border-top-width: 1px; border-top-color: rgb(204, 204, 204); text-decoration: inherit; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-top: -1.2em; max-width: 100%; min-height: 1em; text-align: center; border-width: initial; border-style: none; border-color: initial; line-height: 1.4; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-size: 18px;"&gt;&lt;strong style="font-family: inherit; font-size: 1em; text-decoration: inherit;"&gt;&lt;span style="color: rgb(255, 255, 255); max-width: 100%; line-height: 1.4; font-family: inherit; font-weight: inherit; text-decoration: inherit; background-color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(127, 127, 127); line-height: 22.4px;"&gt;1&amp;nbsp;&lt;/span&gt;新智元推荐 &amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;strong style="font-family: inherit; font-size: 1em; text-decoration: inherit;"&gt;&lt;span style="color: rgb(255, 255, 255); max-width: 100%; line-height: 1.4; font-family: inherit; font-weight: inherit; text-decoration: inherit; background-color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/span&gt;&lt;span style="max-width: 100%; line-height: 1.4; font-family: inherit; font-weight: inherit; text-decoration: inherit; background-color: rgb(127, 127, 127); color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/span&gt;&lt;strong style="color: rgb(136, 136, 136); font-size: 12px;"&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;/section&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;来源：知乎 &amp;nbsp;作者授权转载&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;作者： 齐国君&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;【新智元导读】&lt;/span&gt;&lt;/strong&gt;&lt;span style="font-size: 14px;"&gt;近期备受关注的 &amp;nbsp;Wasserstein GAN&amp;nbsp;被推出的同时，还有一种新的GAN——损失敏感GAN（Loss Sensitive GAN）也发布在 arxiv 上，它&amp;nbsp;以“按需分配”建模能力来解决无限建模能力带来的过拟合和无泛化性问题。论文的作者在这里从建模能力、目标函数、梯度消失问题等方面对比这两种 GAN ，并且对梯度消失问题进行了分析，最后对LS-GAN进行了有监督和半监督的推广。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211625WOd9Az.gif"/&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;最近很多关心深度学习最新进展、特别是生成对抗网络的朋友可能注意到了一种新的 GAN — Wasserstein GAN。其实在WGAN 推出的同时，一种新的 LS-GAN (Loss Sensitive GAN，损失敏感GAN)也发表在预印本&amp;nbsp;[1701.06264]&amp;nbsp;Loss-Sensitive Generative Adversarial Networks on Lipschitz Densities 上。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;那这两种 GAN 有没有什么联系呢？作为LS-GAN的作者，笔者就带大家一览WGAN和LS-GAN本质和联系。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;h2 style="white-space: normal;"&gt;&lt;span style="font-size: 18px;"&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;section class="tn-Powered-by-XIUMI" style="white-space: normal; border-width: 0px; border-style: initial; border-color: initial; clear: both; box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="padding: 8px; border-left: 6px solid rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; font-weight: bold; text-decoration: inherit; color: rgb(10, 10, 10); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); box-sizing: border-box;"&gt;&lt;section&gt;GAN前传和“无限的建模能力”&lt;br&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;h2 style="white-space: normal;"&gt;&lt;br&gt;&lt;/h2&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;熟悉经典GAN的读者都知道，GAN是一种通过对输入的随机噪声z（比如高斯分布或者均匀分布），运用一个深度网络函数G(z)，从而希望得到一个新样本，该样本的分布，我们希望能够尽可能和真实数据的分布一致（比如图像、视频等）。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;在证明GAN能够做得拟合真实分布时，Goodfellow做了一个很大胆的假设：用来评估样本真实度的Discriminator网络（下文称D-网络）&lt;strong&gt;具有无限的建模能力&lt;/strong&gt;，也就是说不管真实样本和生成的样本有多复杂，D-网络都能把他们区分开。这个假设呢，也叫做&lt;strong&gt;非参数假设&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;span style="font-size: 14px;"&gt;当然，对于深度网络来说，咱只要不断的加高加深，这还不是小菜一碟吗？深度网络擅长的就是干这个的么。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;但是，正如WGAN的作者所指出的，一旦真实样本和生成样本之间重叠可以忽略不计（这非常可能发生，特别当这两个分布是低维流型的时候），而又由于D-网络具有非常强大的无限区分能力，可以完美地分割这两个无重叠的分布，这时候，经典GAN用来优化其生成网络（下文称G-网络）的目标函数--JS散度-- 就会变成一个常数！&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;我们知道，深度学习算法，基本都是用梯度下降法来优化网络的。一旦优化目标为常数，其梯度就会消失，也就会使得无法对G-网络进行持续的更新，从而这个训练过程就停止了。这个难题一直一来都困扰这GAN的训练，称为&lt;strong&gt;梯度消失问题&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;h2 style="white-space: normal;"&gt;&lt;span style="font-size: 18px;"&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;section class="tn-Powered-by-XIUMI" style="white-space: normal; border-width: 0px; border-style: initial; border-color: initial; clear: both; box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="padding: 8px; border-left: 6px solid rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; font-weight: bold; text-decoration: inherit; color: rgb(10, 10, 10); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); box-sizing: border-box;"&gt;&lt;section&gt;WGAN 来袭&lt;br&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;为解决这个问题，WGAN 提出了取代 JS 散度的 Earth-Mover（EM）来度量真实和生成样本密度之间的距离。该距离的特点就是，即便用具有无限能力的 D-网络完美分割真实样本和生成样本，这个距离也不会退化成常数，仍然可以提供梯度来优化 G-网络。不过 WGAN 的作者给出的是定性的解释，缺少定量分析，这个我们在后面解释 LS-GAN 时会有更多的分析。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;现在，我们把这个 WGAN 的优化目标记下来，下文我们会把它跟本文的主角 LS-GAN 做一番比较。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211625b4toQO.jpg"/&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;这里 f-函数和 g-函数 分别是 WGAN 的批评函数(critics)和对应的 G-网络。批评函数是WGAN里的一个概念，对应 GAN 里的 Discriminator。该数值越高，代表对应的样本真实度越大。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;好了，对 WGAN 就暂时说到这里。总结下，由于假设中的&lt;strong&gt;无限建模能力&lt;/strong&gt;，使得 D-网络可以完美分开真实样本和生成样本，进而 JS 散度为常数；而 WGAN 换 JS 散度为 EM 距离，解决了优化目标的梯度为零的问题。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;不过细心的读者注意到了，WGAN 在上面的优化目标（12）里，有个对 f-函数的限定：它被限定到所谓的 Lipschitz 连续的函数上的。那这个会不会影响到上面对模型无限建模能力的假设呢？&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;其实，这个对f-函数的 Lipschitz 连续假设，就是沟通 LS-GAN 和 WGAN 的关键，因为 LS-GAN 就是为了限制 GAN 的无限建模能力而提出的。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;熟悉机器学习原理的朋友会知道，一提到无限建模能力，第一反应就应该是条件反应式的反感。为什么呢？无限建模能力往往是和过拟合，无泛化性联系在一起的。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;仔细研究Goodfellow对经典GAN的证明后，大家就会发现，之所以有这种无限建模能力假设，一个根本原因就是GAN没有对其建模的对象--真实样本的分布--做任何限定。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;换言之，GAN设定了一个及其有野心的目标：就是希望能够对各种可能的真实分布都适用。结果呢，就是它的优化目标JS散度，在真实和生成样本可分时，变得不连续，才使得WGAN有了上场的机会，用EM距离取而代之。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;所以，某种意义上，无限建模能力正是一切麻烦的来源。LS-GAN就是希望去掉这个麻烦，取而代之以“按需分配”建模能力。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;h2 style="white-space: normal;"&gt;&lt;/h2&gt;&lt;p&gt;&lt;section class="tn-Powered-by-XIUMI" style="white-space: normal; border-width: 0px; border-style: initial; border-color: initial; clear: both; box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="padding: 8px; border-left: 6px solid rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; font-weight: bold; text-decoration: inherit; color: rgb(10, 10, 10); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); box-sizing: border-box;"&gt;&lt;section&gt;LS-GAN和“按需分配”的建模能力&amp;nbsp;&lt;br&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;好，让我们换个思路，直接通过限定的GAN的建模能力，得到一种新的GAN模型。这个就是LS-GAN了。我们先看看LS-GAN的真容&lt;/span&gt;：&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/14872116250TidFD.png"/&gt;&lt;span style="color: rgb(51, 51, 51); font-size: 14px;"&gt;这个是用来学习损失函数的目标函数。我们将通过最小化这个目标来得到一个“损失函数" (&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211625phGC42.png"/&gt;&lt;span style="color: rgb(51, 51, 51); font-size: 14px;"&gt;，下文称之为L-函数)。L-函数在真实样本上越小越好，在生成的样本上越大越好。&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-top: 20px; margin-bottom: 20px; white-space: normal; color: rgb(51, 51, 51);"&gt;&lt;span style="font-size: 14px;"&gt;另外，对应的G-网络，通过最小化下面这个目标实现：&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/14872116262VkfHF.png"/&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;span style="color: rgb(51, 51, 51);"&gt;&lt;br&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;span style="color: rgb(51, 51, 51);"&gt;这里注意到，在公式（6）中，对L-函数的学习目标 S中的第二项，它是以真实样本&lt;/span&gt;&lt;span style="font-weight: 700; color: rgb(51, 51, 51);"&gt;x&lt;/span&gt;&lt;span style="color: rgb(51, 51, 51);"&gt;和生成样本&lt;/span&gt;&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211626h9yuWU.png"/&gt;&lt;span style="color: rgb(51, 51, 51); font-size: 14px;"&gt;的一个度量&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/14872116262UkfHF.png"/&gt;&lt;span style="font-size: 14px;"&gt;&lt;span style="color: rgb(51, 51, 51);"&gt;为各自L-函数的目标间隔，把&lt;/span&gt;&lt;span style="font-weight: 700; color: rgb(51, 51, 51);"&gt;x&lt;/span&gt;&lt;span style="color: rgb(51, 51, 51);"&gt;和&lt;/span&gt;&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211626slKF75.png"/&gt;&lt;span style="color: rgb(51, 51, 51); font-size: 14px;"&gt;分开。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;这有一个很大的好处：如果生成的样本和真实样本已经很接近，我们就不必要求他们的L-函数非得有个固定间隔，因为，这个时候生成的样本已经非常好了，接近或者达到了真实样本水平。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;这样呢，LS-GAN就可以集中力量提高那些距离真实样本还很远，真实度不那么高的样本上了。这样就可以更合理使用LS-GAN的建模能力。在后面我们一旦限定了建模能力后，也不用担心模型的生成能力有损失了。这个我们称为“&lt;strong&gt;按需分配&lt;/strong&gt;”。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211626zsRMec.jpg"/&gt;&lt;/p&gt;&lt;p style="margin-top: 20px; margin-bottom: 20px; white-space: normal; color: rgb(51, 51, 51);"&gt;&lt;span style="font-size: 14px;"&gt;上图就是对LS-GAN这种对建模能力”按需“分配的图示。&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-top: 20px; margin-bottom: 20px; white-space: normal; color: rgb(51, 51, 51);"&gt;&lt;span style="font-size: 14px;"&gt;有了上面的准备，我们先把LS-GAN要建模的样本分布限定在Lipschitz 密度上，即如下的一个假设：&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211627TMb6yw.png"/&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;那么什么是Lipschitz密度了？简而言之，Lipschitz密度就是要求真实的密度分布不能变化的太快。密度的变化随着样本的变化不能无限地大，要有个度。不过这个度可以非常非常地大，只要不是无限大就好。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;好了，这个条件还是很弱地，大部分分布都是满足地。比如，你把一个图像调得稍微亮一些，它看上去仍然应该是真实的图像，在真实图像中的密度在Lipschitz假设下不应该会有突然地、剧烈地变化。不是吗？&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;span style="font-size: 14px;"&gt;然后，有了这个假设，我就能证明LS-GAN，当&lt;strong&gt;把L-函数限定在Lipschitz连续的函数类&lt;/strong&gt;上，它得到地生成样本地分布和真实样本是完全一致！&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211627jLa6xw.jpg"/&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;前面我们说了，经典GAN事实上对它生成的样本密度没有做任何假设，结果就是必须给D-网络引入无限建模能力，正是这种能力，在完美分割真实和生成样本，导致了梯度消失，结果是引出了WGAN。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;现在，我们把LS-GAN限定在Lipschitz密度上，同时限制住L-函数的建模能力到Lipschitz连续的函数类上，从而证明了LS-GAN得到的生成样本密度与真实密度的一致性。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;那LS-GAN和WGAN又有什么关系呢？&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 12px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;细心的朋友可能早注意到了，WGAN在学习f-函数是，也限定了其f-函数必须是Lipschitz连续的。不过WGAN导出这个的原因呢，是因为EM距离不容易直接优化，而用它的共轭函数作为目标代替之。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;也就是说，这个对f-函数的Lipschitz连续性的约束，完全是“技术”上的考虑，没有太多物理意义上的考量。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;而且，WGAN的作者也&lt;strong&gt;没有&lt;/strong&gt;在他们的论文中证明：WGAN得到的生成样本分布，是和真实数据的分布是一致的。不过，这点在我们更新的预印本中给出了明确的证明，如下：&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211627QfEA10.jpg"/&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;strong&gt;&lt;br&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;strong&gt;换言之：我们证明了，WGAN在对f-函数做出Lipschitz连续的约束后，其实也是将生成样本的密度假设为了Lipschiz 密度。这点上，和LS-GAN是一致的！两者都是建立在Lipschitz密度基础上的生成对抗网络。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;好了，让我们把LS-GAN和WGAN对L-函数和f-函数的学习目标放在一起仔细再看一看：&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;span style="font-weight: 700; color: rgb(51, 51, 51);"&gt;LS-GAN&lt;/span&gt;&lt;span style="color: rgb(51, 51, 51);"&gt;：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;span style="color: rgb(51, 51, 51);"&gt;&lt;br&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(51, 51, 51); font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211627kdCyZY.png"/&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;span style="color: rgb(51, 51, 51);"&gt;&lt;/span&gt;&lt;span style="font-weight: 700; color: rgb(51, 51, 51);"&gt;WGAN&lt;/span&gt;&lt;span style="color: rgb(51, 51, 51);"&gt;：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;span style="color: rgb(51, 51, 51);"&gt;&lt;br&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(51, 51, 51); font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211628g9ytVT.png"/&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px; color: rgb(51, 51, 51); font-weight: 700;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px; color: rgb(51, 51, 51); font-weight: 700;"&gt;形式上&lt;/span&gt;&lt;span style="font-size: 14px; color: rgb(51, 51, 51);"&gt;来看，LS-GAN和WGAN也有很大区别。WGAN是通过最大化f-函数在真实样本和生成样本上的期望之差实现学习的，这种意义上，它可以看做是一种使用“一阶统计量"的方法。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px; color: rgb(51, 51, 51);"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;LS-GAN则不同。观察LS-GAN优化目标的第二项，由于&lt;span style="font-weight: 700;"&gt;非线性&lt;/span&gt;&lt;/span&gt;&lt;span style="font-size: 14px;"&gt;的&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211628slK975.png"/&gt;&lt;span style="font-size: 14px; color: rgb(51, 51, 51);"&gt;函数的存在，使得我们无法把L-函数分别与期望结合，像WGAN那样得到一阶统计量。因为如此，才使得LS-GAN与WGAN非常不同。&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-top: 20px; margin-bottom: 20px; white-space: normal; color: rgb(51, 51, 51);"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;LS-GAN可以看成是使用&lt;strong&gt;成对&lt;/strong&gt;的（Pairwise）“真实/生成样本对”上的统计量来学习f-函数。这点迫使真实样本和生成样本必须相互配合，从而更高效的学习LS-GAN。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;如上文所述，这种配合，使得LS-GAN能够按需分配其建模能力：当一个生成样本非常接近某个真实样本时，LS-GAN就不会在过度地最大化他们之间L-函数地差值，从而LS-GAN可以更有效地集中优化那些距离真实样本还非常远地生成样本，提高LS-GAN模型优化和使用地效率。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;section class="tn-Powered-by-XIUMI" style="white-space: normal; border-width: 0px; border-style: initial; border-color: initial; clear: both; box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="padding: 8px; border-left: 6px solid rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; font-weight: bold; text-decoration: inherit; color: rgb(10, 10, 10); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); box-sizing: border-box;"&gt;&lt;section&gt;梯度消失问题&lt;br&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;那LS-GAN是否也能解决经典GAN中的&lt;strong&gt;梯度消失&lt;/strong&gt;问题呢？即当它的L-函数被充分训练后，是否对应的G-网络训练目标仍然可以提供足够的梯度信息呢？&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;我们回顾下，在WGAN里，其作者给出G-网络的训练梯度，并证明了这种梯度在对应的f-函数被充分优化后，仍然存在。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;不过，仅仅梯度存在这点并不能保证WGAN可以提供足够的梯度信息训练 G-网络。为了说明WGAN可以解决梯度消失问题，WGAN的作者宣称：“G-网络的训练目标函数”在对其网络链接权重做限定后， 是&lt;strong&gt;接近或者最多线性&lt;/strong&gt;的。这样就可以避免训练目标函数饱和，从而保证其能够提供充足的梯度训练G-网络。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;span style="font-size: 14px;"&gt;好了，问题的关键时为什么G-网络的训练目标函数是接近或者最多&lt;strong&gt;线性&lt;/strong&gt;的，这点WGAN里并没有给出定量的分析，而只有大致的定性描述，这里我们引用如下：&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;“&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211628jcBwYW.jpg"/&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;”&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;span style="color: rgb(51, 51, 51);"&gt;现在，让我们回到LS-GAN，看看如何给出一直定量的形式化的分析。在LS-GAN里，我们给出了最优的L-函数的一种&lt;/span&gt;&lt;span style="font-weight: 700; color: rgb(51, 51, 51);"&gt;非参数化的解&lt;/span&gt;&lt;span style="color: rgb(51, 51, 51);"&gt;：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;span style="color: rgb(51, 51, 51);"&gt;&lt;br&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211629iazvXV.jpg"/&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;span style="color: rgb(51, 51, 51);"&gt;&lt;br&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;span style="color: rgb(51, 51, 51);"&gt;这个定理比较长，简单的来说，就是所有的最优 L-GAN的解，都是在两个&lt;/span&gt;&lt;span style="font-weight: 700; color: rgb(51, 51, 51);"&gt;分段线性&lt;/span&gt;&lt;span style="color: rgb(51, 51, 51);"&gt;的上界和下界L-函数之间。如下图所示：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;span style="color: rgb(51, 51, 51);"&gt;&lt;br&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211629MF4Zrp.jpg"/&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;红线是上界，绿线是下界。任何解出来最优L-函数，一定在这两个分段线性的上下界之间，包括用一个深度网络解出来L-函数。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;也就是说，LS-GAN解出的结果，只要上下界不饱和，它的得到的L-函数就不会饱和。而这里看到这个L-函数的上下界是分段线性的。这种分段线性的函数几乎处处存在非消失的梯度，这样适当地控制L-函数地学习过程，在这两个上下界之间地最优L-函数也不会出现饱和现象。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;好了，这样我们就给出了WGAN分析梯度消失时候，缺失的哪个定量分析了。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;最后，我们看看LS-GAN合成图像的例子，以及和DCGAN的对比。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;看看在CelebA上的结果：&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211629voNIa8.jpg"/&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;span style="color: rgb(51, 51, 51);"&gt;如果我们把DCGAN和LS-GAN中Batch Normalization 层都去掉，我们可以看到DCGAN模型取崩溃，&lt;/span&gt;&lt;span style="font-weight: 700; color: rgb(51, 51, 51);"&gt;而LS-GAN仍然可以得到非常好的合成效果&lt;/span&gt;&lt;span style="color: rgb(51, 51, 51);"&gt;：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;span style="color: rgb(51, 51, 51);"&gt;&lt;br&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211630JC1Wom.jpg"/&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;不仅如此，LS-GAN在去掉batch normalization后，如上图（b）所示，&lt;strong&gt;也没有看到任何mode collapse现象&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;我们进一步通过实验看看、在LS-GAN中L-函数网络过训练后，模型还能不能提供足够的梯度来训练G-网络。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;下图是L-网络每次都训练，而G-网络每个1次、3次、5次才训练时，对应的用来更新G-网络的梯度大小(在log scale上)：&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/14872116303WlgIG.jpg"/&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;我们可以看到：即便当L-网络相对G-网络多训练若干次后，更新G-网络的梯度仍然充分大，而&lt;strong&gt;没有出现梯度消失&lt;/strong&gt;的问题。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;不仅如此，随着训练的进行，我们可以看到，G-网络的梯度逐渐增大，一直到一个相对比较稳定的水平。相对固定强度的梯度说明了，&lt;strong&gt;G-网络的训练目标函数，最终非常可能是达到一个接近线性的函数&lt;/strong&gt;（这是因为线性函数的梯度是固定的）。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;这个也进一步说明了，&lt;strong&gt;LS-GAN定义的G-网络的训练目标函数没有发生饱和&lt;/strong&gt;，其定义是合理的，也是足以避免梯度消失问题的。&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;h2 style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;section class="tn-Powered-by-XIUMI" style="white-space: normal; border-width: 0px; border-style: initial; border-color: initial; clear: both; box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="padding: 8px; border-left: 6px solid rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; font-weight: bold; text-decoration: inherit; color: rgb(10, 10, 10); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); box-sizing: border-box;"&gt;&lt;section&gt;对LS-GAN进行有监督和半监督的推广&lt;br&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;LS-GAN和GAN一样，本身是一种无监督的学习算法。LS-GAN的另一个突出优点是，通过定义适当的损失函数，它可以非常容易的推广到有监督和半监督的学习问题。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;比如，我们可以定义一个有条件的损失函数&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211630woNJa9.png"/&gt;&lt;span style="font-size: 14px; color: rgb(51, 51, 51);"&gt;，这个条件&lt;/span&gt;&lt;span style="font-size: 14px;"&gt;y&lt;/span&gt;&lt;span style="font-size: 14px; color: rgb(51, 51, 51);"&gt;可以是输入样本&lt;/span&gt;&lt;span style="font-size: 14px;"&gt;x&lt;/span&gt;&lt;span style="font-size: 14px; color: rgb(51, 51, 51);"&gt;的类别。当类别和样本一致的时候，这个损失函数会比类别不一致的时候小。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(51, 51, 51); font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(51, 51, 51); font-size: 14px;"&gt;于是，我们可以得到如下的Conditional LS-GAN (CLS-GAN)&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(51, 51, 51); font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211631JC1Wom.jpg"/&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(51, 51, 51); font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(51, 51, 51); font-size: 14px;"&gt;这样，一旦得到损失函数&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211630woNJa9.png"/&gt;&lt;span style="color: rgb(51, 51, 51); font-size: 14px;"&gt;，在给定一个样本&lt;/span&gt;&lt;span style="color: rgb(51, 51, 51); font-size: 14px; font-weight: 700;"&gt;x&lt;/span&gt;&lt;span style="color: rgb(51, 51, 51); font-size: 14px;"&gt;后，我们可以用最小化损失函数的那个类别来对样本进行分类，即&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(51, 51, 51); font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211631f7wsTS.png"/&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px; color: rgb(51, 51, 51);"&gt;我们可以看看在MNIST, CIFAR-10和SVHN上，针对不同类别给出的合成图像的效果：&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px; color: rgb(51, 51, 51);"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(51, 51, 51); font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211632yrQMKI.jpg"/&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;半监督的训练是需要使用完全标注的训练数据集。当已标注的数据样本比较有限时，会使得训练相应模型比较困难。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;进一步，我们可以把CLS-GAN推广到半监督的情形，即把已标记数据和未标记数据联合起来使用，利用未标记数据提供的相关分布信息来指导数据的分类。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;为此，我们定义一个特别的半监督的损失函数：&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211632TLa6xw.png"/&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px; color: rgb(51, 51, 51);"&gt;对给定样本&lt;/span&gt;&lt;span style="font-size: 14px; color: rgb(51, 51, 51); font-weight: 700;"&gt;x&lt;/span&gt;&lt;span style="font-size: 14px; color: rgb(51, 51, 51);"&gt;，我们不知道它的具体类别，所以我们在所有可能的类别上对损失函数取最小，作为对该样本真实类别的一个&lt;/span&gt;&lt;span style="font-size: 14px; color: rgb(51, 51, 51); font-weight: 700;"&gt;最佳的猜测&lt;/span&gt;&lt;span style="font-size: 14px; color: rgb(51, 51, 51);"&gt;。这与上面的公式（7）是一致的。&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-top: 20px; margin-bottom: 20px; white-space: normal; color: rgb(51, 51, 51);"&gt;&lt;span style="font-size: 14px;"&gt;这样，我们可以相应的推广CLS-GAN，得到如下的训练目标 最优化损失函数&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/14872116324XmhJH.png"/&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;该训练目标可以通过挖掘各个类别中可能的变化，帮助CLS-GAN模型合成某类中的更多的“新”的样本，来丰富训练数据集。这样，即便标注的数据集比较有限，通过那些合成出来已标记数据，也可以有效的训练模型。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;比如，在下面图中，CLS-GAN模型通过对未标记MNIST数据进行分析，可以按类别合成出更多不同书写风格的数字。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211632mfEz1Z.jpg"/&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;这些数字可以增加已标注的训练数据量，进一步提供模型准确度；而更准确的模型可以进一步提供CLS-GAN的合成图像的准确性。通过这种彼此不断的提高，半监督的CLS-GAN在只有很少已标注训练数据下，仍然可以做到准确的分类。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;我们可以看下在SVHN上，当只有1000张已标注训练数据时分类的准确度：&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211633OG51tr.jpg"/&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(51, 51, 51); font-size: 14px;"&gt;下面是在CIFAR-10上，4000张已标记数据下的分类准确度。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(51, 51, 51); font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211633VNc8Ay.jpg"/&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;section class="tn-Powered-by-XIUMI" style="white-space: normal; border-width: 0px; border-style: initial; border-color: initial; clear: both; box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="padding: 8px; border-left: 6px solid rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; font-weight: bold; text-decoration: inherit; color: rgb(10, 10, 10); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); box-sizing: border-box;"&gt;&lt;section&gt;结论&lt;br&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;那么究竟GAN，WGAN和LS-GAN谁更好呢？&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;持平而论，笔者认为是各有千秋。究竟谁更好，还是要在不同问题上具体分析。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;这三种方法只是提供了一个大体的框架，对于不同的具体研究对象(图像、视频、文本等)、数据类型(连续、离散)、结构（序列、矩阵、张量），应用这些框架，对具体问题可以做出很多不同的新模型。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;当然，在具体实现时，也有非常多的要考虑的细节，这些对不同方法的效果都会起到很大的影响。毕竟，&lt;strong&gt;细节是魔鬼&lt;/strong&gt;！&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;笔者在实现LS-GAN也很多的具体细致的问题要克服。一直到现在，我们还在不断持续的完善相关代码。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;对LS-GAN有兴趣的读者，可以参看我们分享的&lt;/span&gt;&lt;a class=" wrap external" target="_blank" rel="nofollow noreferrer" style="text-decoration: underline; font-size: 14px;"&gt;代码&lt;em class="icon-external"&gt;&lt;/em&gt;&lt;/a&gt;&lt;span style="font-size: 14px;"&gt;，并提出改进的建议。&amp;nbsp;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;对研究GAN感兴趣的读者，也欢迎联系笔者： guojunq@gmail.com，一起探讨相关算法、理论。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;最后，欢迎大家访问我的&lt;/span&gt;&lt;a class=" wrap external" target="_blank" rel="nofollow noreferrer" style="text-decoration: underline; font-size: 14px;"&gt;个人主页&lt;em class="icon-external"&gt;&lt;/em&gt;&lt;/a&gt;&lt;span style="font-size: 14px;"&gt;，我们会分享更多的研究信息&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;论文链接：https://arxiv.org/abs/1701.06264&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;hr style="white-space: normal;"&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211633YQfbCB.jpg"/&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;strong style="color: rgb(123, 12, 0); font-size: 18px;"&gt;【寻找AI独角兽】新智元联手10大资本&lt;/strong&gt;&lt;br&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;strong style="color: rgb(123, 12, 0); font-size: 18px;"&gt;启动2017创业大赛&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;AI 创业大赛由新智元与10 家主流 AI 创投机构：蓝驰创投、红杉资本中国基金、高瓴智成人工智能基金、蓝湖资本、蓝象资本、IDG资本、高榕资本、中信建投证券、明势资本、松禾远望基金携手发起，由新智元主办，北京市中关村科技园区管理委员会、中关村科技园区海淀园管理委员会支持，是一场聚合了 AI 技术领袖和投资领袖的盛会。新智元向满怀雄心的未来AI独角兽提供强大的创投资源对接机会，顶级风投 TS 等你来拿。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;strong&gt;http://form.mikecrm.com/gthejw&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;点击文章下方阅读原文，在线填写报名申请报名表。该报名表为参与评选必填资料。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p class="p11" style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;如有更多介绍资料（例如BP等），可发送至&amp;nbsp;&lt;span style="color: rgb(123, 12, 0);"&gt;xzy100@aiera.com.cn&lt;/span&gt;，邮件标题请注明公司名称。如有任何咨询问题，也欢迎向该邮箱发信联系。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p class="p11" style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;大赛咨询，请添加新智元微信号：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211633wpOJb9.jpg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;/div&gt;</description>
      <pubDate>Thu, 16 Feb 2017 10:16:48 +0800</pubDate>
    </item>
    <item>
      <title>人工智能产品管理：CEO 的工作 25% 可以由机器完成</title>
      <link>http://www.iwgc.cn/link/4723528</link>
      <description>&lt;div class="article-content"&gt;&lt;section style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; font-family: inherit; font-size: 1em; font-weight: inherit; white-space: normal; max-width: 100%; line-height: 28.4444px; border-style: solid none none; border-top-width: 1px; border-top-color: rgb(204, 204, 204); text-decoration: inherit; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-top: -1.2em; max-width: 100%; min-height: 1em; text-align: center; border-width: initial; border-style: none; border-color: initial; line-height: 1.4; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-size: 18px;"&gt;&lt;strong style="font-family: inherit; font-size: 1em; text-decoration: inherit;"&gt;&lt;span style="color: rgb(255, 255, 255); max-width: 100%; line-height: 1.4; font-family: inherit; font-weight: inherit; text-decoration: inherit; background-color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(127, 127, 127); line-height: 22.4px;"&gt;1&amp;nbsp;&lt;/span&gt;新智元编译 &amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;strong style="font-family: inherit; font-size: 1em; text-decoration: inherit;"&gt;&lt;span style="color: rgb(255, 255, 255); max-width: 100%; line-height: 1.4; font-family: inherit; font-weight: inherit; text-decoration: inherit; background-color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/span&gt;&lt;span style="max-width: 100%; line-height: 1.4; font-family: inherit; font-weight: inherit; text-decoration: inherit; background-color: rgb(127, 127, 127); color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/span&gt;&lt;strong style="color: rgb(136, 136, 136); font-size: 12px;"&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;/section&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;&amp;nbsp;来源：哈佛商业评论&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="font-size: 12px; color: rgb(136, 136, 136);"&gt;编译：张易&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong style="font-size: 14px;"&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong style="font-size: 14px;"&gt;&lt;br&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong style="font-size: 14px;"&gt;【新智元导读】&lt;/strong&gt;&lt;span style="font-size: 14px;"&gt;《哈佛商业评论》日前就自动化发表评论文章，称现在CEO们大约25%的工作时间都花在了可以让机器替代的活动上，例如分析报告和数据以做出决策。文章提出，企业应该拥抱机会，从自动化带来的生产力增长潜力中获益，并且制定政策和激励措施，鼓励对持续进步和创新的投资。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211635skKF75.gif"/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;上任后不久，新总统成立了一个国家委员会，以检视自动化的影响。任何家庭都不应该为进步付出不公正的代价，他宣布，但自动化不应该被视为敌人。“如果我们理解它，如果我们周密计划，如果我们应用得当，自动化不会变成一个岗位剥夺者或家庭取代者。相反，它可以把人从工作的沉闷中解脱出来，并为他提供前所未有的东西。”&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;说这番话的是美国总统林登·贝恩斯·约翰逊，时间是1964年。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;半个世纪后的今天，技术以惊人的速度在发展。除了科幻作家之外，当时谁能想象亚马逊的无人机送货，今天在制造业中使用的机器人军团，还有现在用于检测癌症的算法？然而对自动化的焦虑仍然如影随形。关于技术对经济尤其是对未来工作影响的争论一直持续到今天。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;即使工作场所本身已经通过技术重塑，从60年代开始经济的持续繁荣和工作机会的持续存在，仍然很有启发性。当时无法想象的新工作，例如app开发者或MRI技术员，已经取代了过时的工作，例如总机接线员。这是我们从两个世纪前工业革命开始以来就看到的一种模式，当时超过60％的美国人以土地为生； 今天则不到2％。但是，我们仍不禁要问：这一次会不同吗？&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;我们刚刚发布了关于自动化的潜在影响的新研究，基于对800个职业的2,000多个工作场所活动的深入分析。我们把考察的焦点放在“活动”上，因为每个职业都包括许多活动，每个活动都可以在不同程度上自动化。例如在营销中，一些任务可以轻易地自动化，但另一些任务则不是这样。&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;我们发现，全球经济中一半的有酬活动都有利用现有技术进行自动化的潜力。最可进行自动化的活动包括数据采集、数据处理和可预测环境中的体力工作，比如工厂，这占据了美国51％的雇佣活动（不是职位）和2.7万亿美元的工资。这些活动主要存在于诸如制造业、食品服务、运输、仓储以及零售版块。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;就短期到中期而言，更多的职业将发生变革，而非自动化。在未来十年中，全部职业中只有一小部分（约5％）可以利用这些展示出的技术完全自动化，尽管这一比例在中等技能工作类别中可能更高。但我们发现，在60％的职业中，有30%的活动可以被自动化——这将影响到从焊工、景观园丁、抵押经纪人到CEO的每个人。我们估计，&lt;strong&gt;目前CEO们大约有25%的工作时间花在了机器可以替代的活动上，例如分析报告和数据来做出决策。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;自动化的应用前景比以前更广泛，因为包括机器人、人工智能和机器学习等内容的技术越来越能够完成不仅仅是体力活动，而且包括那些涉及到认知能力的活动&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;，从唇语阅读到驾驶。&lt;/span&gt;&lt;/strong&gt;&lt;span style="font-size: 14px;"&gt;随着企业的自动化布局，我们需要更多地考虑大规模重新部署，而非裁员。我们需要为人们提供他们未来需要的技能，包括能够与工作场所中的机器进行更紧密的交互。 还有一些技能要求那些被认为是人类固有的能力，包括对人的管理和发展，与之相伴的是社交和情感方面的推理。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;与20世纪60年代的约翰逊总统一样，我们看到自动化可以为生产力和繁荣做出重大贡献。&amp;nbsp;&lt;strong&gt;我们的研究表明，未来的自动化可以每年提高全球生产率0.8％-1.4％，这对全球经济增长有显著意义，并能补偿人口老龄化带来的阻力。&lt;/strong&gt;对于世界各地的企业来说，自动化将提供获得巨大价值的潜力——而不仅仅是劳动力替代。这些技术实现了更大的产量，更高的质量，更好的结果，更高的安全性，以及扩展或采用新的业务模型的机会。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;然而，仅仅因为存在技术潜力，可以让一个工作场所的活动被自动化，并不意味着它很快就会发生。自动化的速度和程度将取决于一系列因素，技术可行性只是其中之一；还有重要的障碍要克服，包括计算机生成和理解自然语言的能力。其他因素包括劳动力供给和需求的动态。例如，如果低工资的厨师的劳动力市场不缺乏，那么用昂贵的机器替代他们可能没有商业意义。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;商业利益是比较明确的：更好、更聪明、没有错误的结果，以及创新、生产力和增长&lt;/span&gt;&lt;/strong&gt;&lt;span style="font-size: 14px;"&gt;。对于决策者来说，问题更复杂。他们应该拥抱机会，以从自动化带来的生产力增长潜力中获益，并且制定政策和刺激性措施，鼓励对持续进步和创新的投资。与此同时，他们必须颁布政策，帮助工人和机构适应就业的变化。这可能包括对教育和培训的重新思考、收入支持、安全的网络，以及为那些在这一进程中受到影响的人提供过渡支持。最重要的是，把注意力放到在这个新时代茁壮成长所需要的技能上，这一点非常关键。历史的经验告诉我们，创新、投资和增长会创造出那些可能本来只在科幻小说中出现过的需求和工作。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 12px;"&gt;原文地址：https://hbr.org/2017/02/25-percent-of-ceos-time-is-spent-on-tasks-machines-could-do&lt;/span&gt;&lt;/p&gt;&lt;hr style="white-space: normal;"&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211635PH62ts.jpg"/&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;strong style="color: rgb(123, 12, 0); font-size: 18px;"&gt;【寻找AI独角兽】新智元联手10大资本&lt;/strong&gt;&lt;br&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;strong style="color: rgb(123, 12, 0); font-size: 18px;"&gt;启动2017创业大赛&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;AI 创业大赛由新智元与10 家主流 AI 创投机构：蓝驰创投、红杉资本中国基金、高瓴智成人工智能基金、蓝湖资本、蓝象资本、IDG资本、高榕资本、中信建投证券、明势资本、松禾远望基金携手发起，由新智元主办，北京市中关村科技园区管理委员会、中关村科技园区海淀园管理委员会支持，是一场聚合了 AI 技术领袖和投资领袖的盛会。新智元向满怀雄心的未来AI独角兽提供强大的创投资源对接机会，顶级风投 TS 等你来拿。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;strong&gt;http://form.mikecrm.com/gthejw&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;点击文章下方阅读原文，在线填写报名申请报名表。该报名表为参与评选必填资料。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p class="p11" style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;如有更多介绍资料（例如BP等），可发送至&amp;nbsp;&lt;span style="color: rgb(123, 12, 0);"&gt;xzy100@aiera.com.cn&lt;/span&gt;，邮件标题请注明公司名称。如有任何咨询问题，也欢迎向该邮箱发信联系。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p class="p11" style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;大赛咨询，请添加新智元微信号：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211635VNc8zy.jpg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;/div&gt;</description>
      <pubDate>Thu, 16 Feb 2017 10:16:48 +0800</pubDate>
    </item>
    <item>
      <title>【专访】CMU 德州扑克幕后英雄，AI 将在一对多比赛完胜人类</title>
      <link>http://www.iwgc.cn/link/4709778</link>
      <description>&lt;div class="article-content"&gt;&lt;section style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; font-family: inherit; font-size: 1em; font-weight: inherit; white-space: normal; max-width: 100%; line-height: 28.4444px; border-style: solid none none; border-top-width: 1px; border-top-color: rgb(204, 204, 204); text-decoration: inherit; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-top: -1.2em; max-width: 100%; min-height: 1em; text-align: center; border-width: initial; border-style: none; border-color: initial; line-height: 1.4; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-size: 18px;"&gt;&lt;strong style="font-family: inherit; font-size: 1em; text-decoration: inherit;"&gt;&lt;span style="color: rgb(255, 255, 255); max-width: 100%; line-height: 1.4; font-family: inherit; font-weight: inherit; text-decoration: inherit; background-color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(127, 127, 127); line-height: 22.4px;"&gt;1&amp;nbsp;&lt;/span&gt;新智元编译 &amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;strong style="font-family: inherit; font-size: 1em; text-decoration: inherit;"&gt;&lt;span style="color: rgb(255, 255, 255); max-width: 100%; line-height: 1.4; font-family: inherit; font-weight: inherit; text-decoration: inherit; background-color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/span&gt;&lt;span style="max-width: 100%; line-height: 1.4; font-family: inherit; font-weight: inherit; text-decoration: inherit; background-color: rgb(127, 127, 127); color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/span&gt;&lt;strong style="color: rgb(136, 136, 136); font-size: 12px;"&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;/section&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;来源：cardplayer.com&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;编译：刘小芹、胡祥杰、文强&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;【新智元导读】&lt;/span&gt;&lt;/strong&gt;&lt;span style="font-size: 14px;"&gt;AI在人机德扑大战中压倒性胜利的影响还未散去，&lt;/span&gt;&lt;span style="font-size: 14px;"&gt;Card Player网站日前采访了程序开发者、CMU 博士 Noam Brown，回顾比赛并评析对战中的技术亮点。Brown 指出，Libratus 获胜的原因是它没有任何能被人类利用的弱点，训练时 Libratus 从未使用过人类数据。Brown 还表示，&lt;span style="font-size: 14px;"&gt;稍作增强的 Libratus 有望在两年内赢得&lt;span style="font-size: 14px;"&gt;无限手德州扑克 6 人桌（Six-Max）的比赛&lt;/span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487134537ibAwXW.gif"/&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;上个月月末，卡耐基梅隆大学的 AI 程序在“一对一不限注”的扑克比赛中，击败了一组世界级的德州扑克职业选手。出乎所有人的意外，这一程序对人类专业扑克手的胜利几乎是压倒性的：14bb/h。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;（注，德州扑克中，线下按bb/h，超过15bb/h，你已经完全统治这个级别的桌子了，能打到5bb/h-10bb/h已经很不错了。线上按bb/100手，超过5bb/100已经非常厉害了。）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;比赛一共打了12万手，最后 AI 程序赢得170万筹码，也就是约 1.7 万大盲注，接近 90 个买入。对职业扑克玩家来说，还好这不是真正的钱，虽然他们在这场比赛中溃不成军。团队里每个人都败给了机器。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;这个 AI 程序被称为 Libratus，它的开发者之一，CMU 博士生 Noam Brown 称它是“扑克AI的圣杯”。Libratus 是 Noam Brown 和 CMU 教授 Tuomas Sandholm 一起开发的，而它只是 CMU 研发的一系列扑克 AI 程序中最新的一个。此前，从来没有机器能在一对一不限注德州扑克游戏中击败世界级的人类职业玩家。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487134537KcBwYW.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;卡耐基梅隆大学的 AI 程序&amp;nbsp;Libratus 的开发者Tuomas Sandholm 教授（右）与 Noam Brown 博士&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;根据 Brown 的说法，后续版本的 Libratus 还能有很大的提升空间，升级后的程序理论上能赢 50bb/h。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;Card Player 网站就这场历史性的比赛以及今后的扑克 AI 研究专访了 Noam Brown。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;section class="tn-Powered-by-XIUMI" style="white-space: normal; border-width: 0px; border-style: initial; border-color: initial; clear: both; box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="padding: 8px; border-left: 6px solid rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; font-weight: bold; text-decoration: inherit; color: rgb(10, 10, 10); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); box-sizing: border-box;"&gt;&lt;section&gt;Libratus 获胜原因及算法关键&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;Brian Pempus：&lt;/span&gt;&lt;span style="font-size: 14px;"&gt;你对比赛的结果有感到惊讶吗？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;Noam Brown：&lt;/span&gt;&lt;/strong&gt;&lt;span style="font-size: 14px;"&gt;有的，实际上我对这个 AI 如此之厉害感到惊讶。在比赛前，我们用它跟此前的 AI 程序对打来做测试，然后我们就预感它能赢。Libratus 以10~12bb/h赢了 Claudico，这比人类赢得多（2015年 Claudico 输给了人类），但差别没有很大。所以，在比赛前，我们认为 AI 能稍微赢过人类。我们不确定能赢多少。所以 AI 的表现如此之好，令我们印象非常深刻。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;span style="font-size: 14px; font-weight: bold;"&gt;Brian Pempus：&lt;/span&gt;当时你们还不认为 AI 能够以14bb/h击败人类？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;strong style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;Noam Brown：&lt;/span&gt;&lt;/strong&gt;是啊，鉴于人类赢过了 Claudico，我们不知道人类的潜力有多大。人类选手能够发现 Claudico 的弱点，并且利用这些弱点。例如，提升 Claudico 的跛入（limp）是相当有效的，是他们获胜的关键。Libratus 不会利用对手。事实上，Libratus 不会利用 Claudico 的弱点还能以 10~12bb/h 赢过 Claudico，说明 Libratus 如果没有弱点的话，那么它在一对一游戏中比人类更厉害。&lt;span style="font-size: 14px; color: rgb(123, 12, 0);"&gt;&lt;strong&gt;Libratus 获胜的原因就是它没有任何能被人类利用的弱点。&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;span style="font-size: 14px; font-weight: bold;"&gt;Brian Pempus：&lt;/span&gt;在人类玩家将局面带到接近平分时，你们有没有认为人类已经发现了 AI 的弱点，还是你们仍然有信心？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;strong style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;Noam Brown：&lt;/span&gt;&lt;/strong&gt;是的，在第一周结束时，比分几乎接近平局。在比赛的第一周，人类选手对 Libratus 会如何调整，Libratus 强项的地方在哪里这些问题进行了很多推测。他们没有全部告诉我，但从我所了解到的，他们在寻找数据的模式，AI 的弱点和强项。所以，大多数时候我是不担心的。他们认为 AI 有缺陷，但其实没有。例如，有一天的比赛中他们80%都是三倍下注（3-bet），因为根据数据，他们认为 AI 对特定的 3-bet 打法较弱。但我认为这不是真的弱，只是因为数据中存在噪音，因为迄今为止所玩的牌令他们形成了那样的想法。但他们看到了存在一些模式。例如，他们注意到AI对特定的开局下注的大小对应不好。这些弱点在比赛前我们没有认为是大事，但事实证明这是相当大的漏洞。幸运的是，AI 对此早有准备，并且在人们睡觉的时候，它在不断地进行训练以填补这些差距，防止演变成一个长期的问题。这就是为什么第二周时局势转变了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;span style="font-size: 14px; font-weight: bold;"&gt;Brian Pempus：&lt;/span&gt;在一局之后进行微调对 AI 来说非常重要吗？人类团队之间会讨论战略，这是否将比赛难度提升了？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;strong style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;Noam Brown：&lt;/span&gt;&lt;/strong&gt;这里面存在很多误解。AI 进行了微调不是说我们告诉它要更频繁、更多地 4-bet。是人类在每次翻牌前和翻牌时使用不同的下注大小。我们有一堆编程好的下注大小，所以 AI 能够知道如何应对 2 倍，2.5倍，3 倍的开局下注。但是假如说人类开局下2.75 倍，AI 就会跟到 3 倍。所以它的对应是相当好的。对 2.75 倍跟到 3 倍虽然不是不合理，但假如它不必四舍五入到接近的大小会更好。于是一夜之间，它能训练如何回应 2.75倍，并且训练的大小是由一个算法决定的。所以，这就是唯一进行的微调。&lt;span style="font-size: 14px; color: rgb(123, 12, 0);"&gt;&lt;strong&gt;AI 会学习如何更好地应对不同的翻牌前和翻牌时的下注大小。这是算法的关键部分，让 AI 随着时间的推移适应人类的打牌风格，而不是像人类以为的那样在利用人类的弱点。&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;span style="font-size: 14px; font-weight: bold;"&gt;Brian Pempus：&lt;/span&gt;那么，这是否表示 AI 在翻牌前和翻牌中的适应比在转牌圈和河牌圈时更重要？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;strong style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;Noam Brown：&lt;/span&gt;&lt;/strong&gt;对于转牌圈和河牌圈，你会注意到在遇到转牌圈时 AI 需要一些时间思考。它实际上需要一些时间思考在转牌圈和河牌圈之后的动作。有些人没有注意到，因为这实际上的时间非常短，它实际上是在每次人类玩家在转牌圈和河牌圈下注时都要重新计算策略。这样做是为了对人类在转牌圈和河牌圈时的任何下注大小计算最佳策略。所以，这个问题是必须预先计算一系列的不同下注大小并放入到游戏树中，但预先计算的不能应对转牌圈和河牌圈，因为那是实时计算的策略。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;span style="font-size: 14px; font-weight: bold;"&gt;Brian Pempus：&lt;/span&gt;Libratus 中是不是有一些 Claudico 不具备的能力？或者说，它就是不完美的？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;strong style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;Noam Brown：&lt;/span&gt;&lt;/strong&gt;Claudico 对于河牌圈有一个实时的解算器（solver），但是，在下面几个方面，它表现得更弱一些。首先，没有考虑阻断牌（blockers）。为了能实现快速地运转，它需要把多手牌组合起来，然后再区分对待。所以，处于这一原因，它可能会认为，手牌带 A 和三个黑桃的牌和另一外一个手牌带A附带三个黑桃的牌是一样的，即便这两种牌应该区分对待。Claudico 的终局解算器会对大量的实时下注进行计算，但是，它不会对人类的每次下注进行再计算。我认为，这种对人类每次下注进行再计算，对于我们的AI 在本次比赛中获得胜利是至关重要的。同样的，这次，我们能对这种计算进行扩展，在转牌圈开始的时候就进行，这是一种更加密集的计算，因为现在需要处理大约50种可能出现的不同河牌圈，并且在游戏结束（每手牌）前可能出现的行动数量也在呈指数级地增长。所以，&lt;span style="font-size: 14px; color: rgb(123, 12, 0);"&gt;&lt;strong&gt;在计算成本上，要有效地扩展这种新算法，新程序的成本也比 Claudico 要贵1000倍。&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487134537skJF75.jpg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 12px; color: rgb(136, 136, 136);"&gt;2017 年 1月底，卡耐基梅隆大学的 AI 程序 Libratus&amp;nbsp;在“一对一不限注”的扑克比赛中与人类玩家对战现场。最终 Libratus 以绝对的优势战胜了四名人类职业玩家。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;section class="tn-Powered-by-XIUMI" style="white-space: normal; border-width: 0px; border-style: initial; border-color: initial; clear: both; box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="padding: 8px; border-left: 6px solid rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; font-weight: bold; text-decoration: inherit; color: rgb(10, 10, 10); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); box-sizing: border-box;"&gt;&lt;section&gt;Libratus 没有使用人类数据，训练时从未与人类交手&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;strong style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;Brian Pempus：&lt;/span&gt;&lt;/strong&gt;Libratus 距离玩一个完全的 GTO（距离博弈理论中的最优化策略）还有多远？诸如此类的机器，你们还有多少版本？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;strong style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;Noam Brown：&lt;/span&gt;&lt;/strong&gt;没有人可以准确地知道，Libratus与博弈理论中的最优化策略相比还有多大的差距。我们知道如何计算这一数值，但是，这是极为昂贵的。现在也还没有实现。这是我们期望在下一个十年或更长的时间内解决的问题。如果必须要推测一个准确的时间，我认为，一个博弈理论中的最优化策略可以15bb/h 的优势战胜Libratus。这是我的粗略估计，范围应该是在5-50bb/h。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;strong style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;Brian Pempus：&lt;/span&gt;&lt;/strong&gt;那在这一方面，AI 还有很大的提升空间？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;strong style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;Noam Brown：&lt;/span&gt;&lt;/strong&gt;很难说。过去很多的 AI 程序都有一个最关键的弱点：它们在转牌圈&lt;span style="font-size: 14px;"&gt;（the turn）&lt;/span&gt;和河牌圈（the river）不会考虑阻断牌（blockers）。这在高级别的比赛中是至关重要的。Libratus 并没有这一问题。它会在转牌圈和河牌圈中，对每一手牌进行独特的衡量。与此前的很多 AI 程序相比，这是一个关键的进步，带来了表现上的巨大飞跃。现在，在这一方向上有了更多的提升空间，也就是如何更好地区分阻断牌。但是，在如何选择下注的多少上，也许也有一些提升的空间。对我来说，很难去推测具体会有多大的提升。但是，大约是15bb。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;strong style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;Brian Pempus：&lt;/span&gt;&lt;/strong&gt;有人说，Libratus 在转牌圈和河牌圈的超大下注（Over Bet）是非常具有侵略性的。在你看来，AI 是不是已经具备了一些可以称之为完美的能力，或者说，如何在当下底牌的范围（ranges）中平衡这一方向上，AI 仍有改进空间？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;strong style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;Noam Brown：&lt;/span&gt;&lt;/strong&gt;&lt;span style="font-size: 14px; color: rgb(123, 12, 0);"&gt;&lt;strong&gt;在比赛中，Libratus 在超大下注上的表现真的是一个让我们感到震惊的事。Libratus 并没有使用人类数据进行训练，它从未跟人类扑克手打过交道。&lt;/strong&gt;&lt;/span&gt;所以，在参赛时，它带来的是一种独特的博弈策略，与人类认为的最优方法有很大的不一样。超大下注是它的策略中的一个重要部分，另外还有donk bets（作为翻牌前的跟注者进入翻牌圈以后，在没位置情况下采用向翻牌前的公开加注者反主动下注的打法）策略。对我来说，看到AI 实现了此前人类也没有做到的一些事，这真的是让人难以忘记，我非常满意。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;我认为，早在Claudico（CMU 此前的德州扑克AI 程序）身上，我们已经看到了这种侵略性。Claudico有一个被人嘲笑的经典行为：它总是在底池还很小的情况下就开始 All-in。我认为，Caudico的这种策略明显是用错了。它作出这些大的押注的背后，隐含了许多的不平衡。我认为，在Libratus 身上，我们看到平衡的侵略性，这也是它能赢得比赛的一个关键因素。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;strong style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;Brian Pempus：&lt;/span&gt;&lt;/strong&gt;很多人开始担心，Libratus 的胜利对于线上扑克的未来发展意味着什么。你能否谈谈，你开发的AI程序如何才不会破坏这些游戏的本质？至少在当前。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;strong style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;Noam Brown：&lt;/span&gt;&lt;/strong&gt;至少我现在可以向人们保证，我们不会把 Libratus 放到网上，也从来没有相关计划。但是，显然，我们也不阻止一些人利用我们发布的技术，把它做成 bot，然后放到网上。我不打算对bot会对线上扑克产生多大的影响进行推测。我对线上扑克知之甚少。但是，我知道目前已经有一些bot 得到了使用，并且，许多扑克网站做了很大的努力希望能抓到这些bot。我不知道，最终谁会是最大的受益者。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;section class="tn-Powered-by-XIUMI" style="white-space: normal; border-width: 0px; border-style: initial; border-color: initial; clear: both; box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="padding: 8px; border-left: 6px solid rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; font-weight: bold; text-decoration: inherit; color: rgb(10, 10, 10); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); box-sizing: border-box;"&gt;&lt;section&gt;Libratus 有望在两年内赢得&lt;span style="color: rgb(10, 10, 10); font-size: 18px; font-weight: bold;"&gt;无限手德扑 6 人桌&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;Brian Pempus：&lt;/span&gt;&lt;/strong&gt;&lt;span style="font-size: 14px;"&gt;如果比赛中牌的数量减少或增加对比赛结果有什么影响？机器能应付一叠有 500 到 1000 手的盲注吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;Noam Brown：&lt;/span&gt;&lt;/strong&gt;&lt;span style="font-size: 14px;"&gt;我们选择 200 手盲注的原因是年度计算机扑克竞赛采用的是这个规制。每年，做扑克的 AI 研究者都会聚集起来相互对战。200 手盲注一直被认为对 AI 特别困难，因为牌越多，AI 需要应对的选项就越多。就我的理解，200 手盲注的难度处于人类能玩的上限。我认为保持公平对等是很有必要的，但同时也应该让 AI 玩起来有难度。要是牌的数量变少，比如 100 手，我认为 AI 玩起来结果跟现在一样（如果不是更好的话）。要是牌的数量增多，比如 500 或 1000……坦白说，我认为 AI 玩起来结果还是跟现在一样（如果不是更好的话）。这不是因为对 AI 来说情况变简单了，而是因为牌数增多，对人类来说变复杂了。我不认为人类能习惯 500 手或 1000 手的盲注。到了那个数量级，Libratus 真正擅长的大规模超大投注（over-bets）的重要性就会凸显出来。我不认为人类在［超大投注］方面能比 Libratus 强。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;Brian Pempus：&lt;/span&gt;&lt;/strong&gt;&lt;span style="font-size: 14px;"&gt;除了无限手德州扑克，还有什么扑克是 AI 研究者可以让 bot 再跟多一个人类玩家对战的？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;Noam Brown：&lt;/span&gt;&lt;/strong&gt;&lt;span style="font-size: 14px;"&gt;在三人扑克方面有一些研究。总的来说，就算要对战超过两个人类玩家，Libratus 现在使用的技术也是很有效的。&lt;span style="font-size: 14px; color: rgb(123, 12, 0);"&gt;&lt;strong&gt;问题并不在于技术，而是在于如何评估选手的表现。&lt;/strong&gt;&lt;/span&gt;因为当你有超过两个对手时，你完全可以在使用 GTO 策略的情况下输钱——其他选手在暗处或明处串通好了。所以，很难在一个 AI 对战 5 个人类的情况下确认 AI 是否比人类更好，要做出这种衡量几乎是不可能的。这也是为什么计算机扑克竞赛要采用一个AI 对战一个人类的形式，也是为什么研究者都十分关注 AI 和人类玩家打二人扑克的结果。我认为目前玩无限德州扑克 6 人桌（Six-Max）稍微超出了 Libratus 和其他类似 AI 程序的能力。但话虽如此，年度计算机扑克竞赛现在正计划增加 6 人桌的比赛，所以这方面的研究应该进展得非常快。&lt;span style="font-size: 14px; color: rgb(123, 12, 0);"&gt;&lt;strong&gt;我认为现在的 Libratus 再增强一些，两年内就能在无限手德州扑克 6 人桌里赢过人类。&lt;/strong&gt;&lt;/span&gt;玩 6 人桌的时候，相比 GTO，针对比较弱的玩家进行攻击的策略可能更有效。AI 扑克研究圈子里有这方面的讨论，目前还没有得出答案。人类在针对弱者并且攻击他们的弱点方面更有优势。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 12px;"&gt;编译来源：http://www.cardplayer.com/poker-news/21333-poker-bot-that-dominated-humans-in-heads-up-could-soon-win-at-six-max-computer-scientist-says&lt;span style="text-align: center;"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;hr style="white-space: normal;"&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487134538AsRNfd.jpg"/&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;strong style="color: rgb(123, 12, 0); font-size: 18px;"&gt;【寻找AI独角兽】新智元联手10大资本&lt;/strong&gt;&lt;br&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;strong style="color: rgb(123, 12, 0); font-size: 18px;"&gt;启动2017创业大赛&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;AI 创业大赛由新智元与10 家主流 AI 创投机构：蓝驰创投、红杉资本中国基金、高瓴智成人工智能基金、蓝湖资本、蓝象资本、IDG资本、高榕资本、中信建投证券、明势资本、松禾远望基金携手发起，由新智元主办，北京市中关村科技园区管理委员会、中关村科技园区海淀园管理委员会支持，是一场聚合了 AI 技术领袖和投资领袖的盛会。新智元向满怀雄心的未来AI独角兽提供强大的创投资源对接机会，顶级风投 TS 等你来拿。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;strong&gt;http://form.mikecrm.com/gthejw&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;点击文章下方阅读原文，在线填写报名申请报名表。该报名表为参与评选必填资料。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p class="p11" style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;如有更多介绍资料（例如BP等），可发送至&amp;nbsp;&lt;span style="color: rgb(123, 12, 0);"&gt;xzy100@aiera.com.cn&lt;/span&gt;，邮件标题请注明公司名称。如有任何咨询问题，也欢迎向该邮箱发信联系。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p class="p11" style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;大赛咨询，请添加新智元微信号：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/14871345387wVQig.jpg"/&gt;&lt;/p&gt;&lt;/div&gt;</description>
      <pubDate>Wed, 15 Feb 2017 12:43:06 +0800</pubDate>
    </item>
    <item>
      <title>GAN 作者 Ian Goodfellow 最新论文：对神经网络策略的对抗性攻击</title>
      <link>http://www.iwgc.cn/link/4709779</link>
      <description>&lt;div class="article-content"&gt;&lt;section style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; font-family: inherit; font-size: 1em; font-weight: inherit; white-space: normal; max-width: 100%; line-height: 28.4444px; border-style: solid none none; border-top-width: 1px; border-top-color: rgb(204, 204, 204); text-decoration: inherit; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-top: -1.2em; max-width: 100%; min-height: 1em; text-align: center; border-width: initial; border-style: none; border-color: initial; line-height: 1.4; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-size: 18px;"&gt;&lt;strong style="font-family: inherit; font-size: 1em; text-decoration: inherit;"&gt;&lt;span style="color: rgb(255, 255, 255); max-width: 100%; line-height: 1.4; font-family: inherit; font-weight: inherit; text-decoration: inherit; background-color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(127, 127, 127); line-height: 22.4px;"&gt;1&amp;nbsp;&lt;/span&gt;新智元编译 &amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;来源：arXiv&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;编译：张易&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;【新智元导读】&lt;/span&gt;&lt;/strong&gt;&lt;span style="font-size: 14px;"&gt;迄今为止，多数对于对抗样本的研究是关于对抗样本对监督式学习算法影响的。一个最新的技术报告研究了对抗性攻击干扰代理训练，使其无法学到任何有意义的事情的设想情况。这篇最新的论文则首次研究了测试时使用对抗样本来干扰强化学习运行的效果。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487134540ogFB31.gif"/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487134540EwWRjh.jpg"/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;机器学习分类器在故意引发误分类的输入面前具有脆弱性。在计算机视觉应用的环境中，对这种对抗样本已经有了充分研究。论文中，我们证明了对于强化学习中的神经网络策略，对抗性攻击依然有效。我们特别论证了，现有的制作样本的技术可以显著降低训练策略在测试时的性能。我们的威胁模型认为对抗攻击会为神经网络策略的原始输入引入小的干扰。针对对抗样本攻击，我们通过白盒测试和黑盒测试， 描述了任务和训练算法中体现的脆弱程度。 无论是学习任务还是训练算法，我们都观测到了性能的显著下降，即使对抗干扰微小到无法被人类察觉的程度。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;深度学习和深度强化学习最近的进展使得涵盖了从原始输入到动作输出的end-to-end学习策略变为可能。深度强化学习算法的训练策略已经在Atari 游戏和围棋中取得了骄人的成绩，展现出复杂的机器操纵技巧，学习执行了运动任务，并在显示世界中进行了无人驾驶。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;这些策略由神经网络赋予了参数，并在监督式学习中表现出对于对抗性攻击的脆弱性。例如，对训练用于分类图像的卷积神经网络，添加进入输入图像的干扰可能会引起网络对图像的误分，而人类却看不出加入干扰前后的图像有何不同。论文中，我们会研究经过深度强化学习训练的神经网络策略，是否会受到这样的对抗样本的影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;不同于在学习过程中处理修正后的训练数据集的监督式学习，在增强式学习中，这些训练数据是在整个训练过程中逐渐被收集起来的。换句话说，用于训练策略的算法，甚至是策略网络加权的随机初始态，都会影响到训练中的状态和动作。不难想象，根据初始化和训练方式的不同，被训练做相同任务的策略，可能大相径庭（比如从原始数据中提取高级特征）。因此，某些特定的学习算法可能导致出现较为不受对抗样本影响的策略。可以想象，监督式学习和增强式学习的不同可能会防止对抗性攻击在黑盒测试环境下发生作用，因为攻击无法进入目标策略网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487134540UkJE64.jpg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 12px; color: rgb(136, 136, 136);"&gt;图表1：产生对抗样本的两种方法，适用于借助DQN算法玩PONG游戏来进行策略训练。点形箭头从小球开始，表明了其运动方向，绿色的箭头则强调了对于特定输入来说最大化Q值的action。两种情况下，对于原始输入，策略都采取了好的action，但对抗性干扰都造成了小球和点的遗失。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;上图：对抗性样本使用FGSM构造，对抗干扰带有l∞-norm constraint；转化为8-bit的图像编码率后，对抗性输入和原始输入相等，但仍然影响了性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;下图：对抗性样本使用FGSM构造，对抗干扰带有l∞-norm constraint；最优干扰是在真实的小球下方创造一个“假的”小球。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;我们的主要贡献是描写了两个因素对于对抗样本的作用效果：用于学习策略的深度强化学习算法，以及对抗性攻击自己是否能进入策略网络（白盒测试vs.黑盒测试）。我们首先分析了对4种Atari games的3类白盒攻击，其中游戏是经过3种深度强化学习算法训练过的（DQN、TRPO和A3C）。我们论证了，整体上来说，这些经训练的策略对于对抗样本是脆弱的。然而，经过TRPO和A3C训练的策略似乎对于对抗样本的抵抗性更好。图表1显示了在测试时的特定一刻，两个对经过DQN训练的Pong策略的对抗性攻击样本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;接着，我们考察了对于相同策略的黑盒攻击，前提是我们假设对抗性攻击进入到了训练环境（例如模拟器），但不是目标策略的随机初始态，而且不知道学习策略是什么。在计算机视觉方面，Szegedy等人观测到了可传递特性：一个设计用于被一种模型误分的对抗样本经常会被其他经过训练来解决相同问题的模型误分。我们观测到在强化学习应用中，整个数据集里也存在这样的可传递特性，即一个设计用于干扰某种策略运行的对抗样本也会干扰另一种策略的运行，只要这些策略是训练用于解决同样的问题。特别的，我们观测到对抗样本会在使用不同trajectory rollouts算法进行训练的模型之间传递，会在使用不同训练算法进行训练的模型之间传递。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;下面介绍一下关于实验的基本情况。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;我们在 Arcade Learning Environment 模拟器中评估了针对4种Atari 2600游戏的对抗性攻击，四种游戏是：Chopper Command, Pong, Seaquest, and Space Invaders.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;我们用3种深度强化学习算法对每个游戏进行了训练：A3C、TRPO和DQN。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;对于DQN，我们使用了与附录1相同的前处理和神经网络结构。我们也把这一结构用于经A3C和TRPO训练的随机策略。需要指出，对神经网络策略的输入是最后4副图像的连续体，从RGB转换为Luminance（Y），大小修改为to 84 × 84。Luminance value被定义为从0到1。策略的输出所有可能的action的分布。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;对于每个游戏和训练算法，我们从不同的随机初始态开始训练了5个策略。我们主要关注了表现最好的训练策略（我们的定义是那些在最后10次训练迭代中拿到最大分数的80%的策略）。我们最终为每个游戏和训练算法选取了3个策略。有一些特定组合（比如Seaquest和A3C）仅有一条策略达到要求。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;我们在rllab框架内部进行了实验，使用了TRPO的rllab 平行版本，并整合了DQN和A3C。我们使用OpenAI Gym enviroments作为Arcade Learning Environment的交互界面。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;我们在 Amazon EC2 c4.8x large machines上用TRPO和A3C进行了策略训练。运行TRPO时每100，000步有2000次迭代，用时1.5到2天。KL散度设在0.01；运行A3C时，我们使用了18 actor-learner threads，learning rate是0.0004。对于每个策略，每1,000,000步进行200次迭代，耗时1.5到2天；运行DQN时，我们在Amazon EC2 p2.xlarge machines上进行策略训练。每代 100000步，训练2天。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;这一研究方向对于神经网络策略在线上和现实世界的布局都有显著意义。我们的实验证明，即使在黑盒测试中，使用特定对抗样本仍然可以较轻易地“愚弄”神经网络策略。这些对抗性干扰在现实世界中也可能发生作用，比如在路面上特意添加的色块可能会搞晕遵循车道策略的无人驾驶汽车。因此，未来工作的一个重要方向就是发展和对抗性攻击相抵抗的防范措施，这可能包括在训练时增加对抗性干扰的样本，或者在测试时侦测对抗性输入。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;论文地址：https://arxiv.org/pdf/1702.02284.pdf&lt;/span&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 12px;"&gt;参考文献&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 12px;"&gt;[1] V. Mnih, K. Kavukcuoglu, D. Silver, A. Graves, I. Antonoglou, D. Wierstra, and M. Riedmiller. Playing atari with deep reinforcement learning. In NIPS Workshop on Deep Learning, 2013.&lt;/span&gt;&lt;/p&gt;&lt;hr&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487134540hazuWU.jpg"/&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;strong style="color: rgb(123, 12, 0); font-size: 18px;"&gt;【寻找AI独角兽】新智元联手10大资本&lt;/strong&gt;&lt;br&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;strong style="color: rgb(123, 12, 0); font-size: 18px;"&gt;启动2017创业大赛&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;AI 创业大赛由新智元与10 家主流 AI 创投机构：蓝驰创投、红杉资本中国基金、高瓴智成人工智能基金、蓝湖资本、蓝象资本、IDG资本、高榕资本、中信建投证券、明势资本、松禾远望基金携手发起，由新智元主办，北京市中关村科技园区管理委员会、中关村科技园区海淀园管理委员会支持，是一场聚合了 AI 技术领袖和投资领袖的盛会。新智元向满怀雄心的未来AI独角兽提供强大的创投资源对接机会，顶级风投 TS 等你来拿。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;strong&gt;http://form.mikecrm.com/gthejw&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;点击文章下方阅读原文，在线填写报名申请报名表。该报名表为参与评选必填资料。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p class="p11" style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;如有更多介绍资料（例如BP等），可发送至&amp;nbsp;&lt;span style="color: rgb(123, 12, 0);"&gt;xzy100@aiera.com.cn&lt;/span&gt;，邮件标题请注明公司名称。如有任何咨询问题，也欢迎向该邮箱发信联系。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p class="p11" style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;大赛咨询，请添加新智元微信号：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487134540piHC42.jpg"/&gt;&lt;/p&gt;&lt;/div&gt;</description>
      <pubDate>Wed, 15 Feb 2017 12:43:06 +0800</pubDate>
    </item>
    <item>
      <title>生成算法让机器人在真实世界中演化，全程无需人类介入（视频）</title>
      <link>http://www.iwgc.cn/link/4709780</link>
      <description>&lt;div class="article-content"&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;section style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; font-family: inherit; font-size: 1em; font-weight: inherit; white-space: normal; max-width: 100%; line-height: 28.4444px; border-style: solid none none; border-top-width: 1px; border-top-color: rgb(204, 204, 204); text-decoration: inherit; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-top: -1.2em; max-width: 100%; min-height: 1em; text-align: center; border-width: initial; border-style: none; border-color: initial; line-height: 1.4; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-size: 18px;"&gt;&lt;strong style="font-family: inherit; font-size: 1em; text-decoration: inherit;"&gt;&lt;span style="color: rgb(255, 255, 255); max-width: 100%; line-height: 1.4; font-family: inherit; font-weight: inherit; text-decoration: inherit; background-color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(127, 127, 127); line-height: 22.4px;"&gt;1&amp;nbsp;&lt;/span&gt;新智元编译 &amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;strong style="font-family: inherit; font-size: 1em; text-decoration: inherit;"&gt;&lt;span style="color: rgb(255, 255, 255); max-width: 100%; line-height: 1.4; font-family: inherit; font-weight: inherit; text-decoration: inherit; background-color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/span&gt;&lt;span style="max-width: 100%; line-height: 1.4; font-family: inherit; font-weight: inherit; text-decoration: inherit; background-color: rgb(127, 127, 127); color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/span&gt;&lt;strong style="color: rgb(136, 136, 136); font-size: 12px;"&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;/section&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;来源：globalfuturist.org&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;编译：王楠&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;【新智元导读】&lt;/span&gt;&lt;/strong&gt;&lt;span style="font-size: 14px;"&gt;挪威奥斯陆大学研究者让机器人使用“生成设计”算法和3D打印机，自我设计、发展和制造，全程无需人类输入。在生成设计中，具有创造力并且能够创造的机器设计自己并且根据环境迭代，是人工演化的一种方式。研究人员表示，这种自我设计和演化机器人有望救灾机器人研发。他们的下一个目标是开发机器人制造自己并将部件自己组装起来的能力，也即所谓的“4D打印”，从而实现真正意义上的AI演化。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487134543VNc8Ay.gif"/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;挪威奥斯陆大学的研究人员发现了一种让机器人自我设计、演化和使用 3D 打印机制造自己的方法，全过程没有人类输入，使用一种名为“生成设计”（Generative design）的人工演化形式——不过，研究人员坦承，至少目前该过程的最终产品，也即机器人本身，（在各个部件被 3D 打印出以后）仍然需要由人工组装完成。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;在生成设计中，具有创造力的机器（而不是人类）发明新的产品。现在已经有机器设计椅子，还有设计运动鞋的新结构。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;奥斯陆大学实验室的最新机器人——第四号（Number Four）外观像香肠，是塑料制成的，各节“香肠”之间由伺服电机连接在一起。第四号会尝试不同的步态，努力从中找出从地板一端移动到另一端的最佳方式。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;iframe class="video_iframe" data-vidtype="2" allowfullscreen="" frameborder="0" height="417" width="556" data-src="https://v.qq.com/iframe/preview.html?vid=z1313mm752r&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0"&gt;&lt;/iframe&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 12px; color: rgb(136, 136, 136);"&gt;这项研究的负责人、奥斯陆大学机器人和智能系统研究小组副教授 Kyrre Glette 说：“它现在正在测试原始运动模式的几种变化版本。”&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;你看上面这个视频可能会觉得它很奇怪或很好笑，但需要记住一点，那就是这只是一个开始。今天，这个机器人在学着如何用最有效的方式从 A 移动到 B，明天它就有可能“进化”成任何东西，并且速度比人类演化要快得多。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;section class="tn-Powered-by-XIUMI" style="white-space: normal; border-width: 0px; border-style: initial; border-color: initial; clear: both; box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="padding: 8px; border-left: 6px solid rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; font-weight: bold; text-decoration: inherit; color: rgb(10, 10, 10); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); box-sizing: border-box;"&gt;&lt;section&gt;使用生成设计进行人工演化&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;通过不断监测自己的进度并将其与以前的尝试做比较，随着时间的推移，在这个简单的任务中，第四号的表现明显越来越好。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;当然，第四号的运动不是完美的。说到底，它在努力进化，或者说“演化”，而演化绝非简单的任务。要知道，在自然界中，大约有 99.9％的“演化”是走上一条死路，最终物种迎来灭绝。但这也正是演化的本质——不断尝试新的事物、失败，再次尝试，直到有什么事情发生。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="font-size: 12px; color: rgb(136, 136, 136);"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487134543XQfaCA.jpg"/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 12px; color: rgb(136, 136, 136);"&gt;使用生成设计算法，计算机模拟先将机器人模拟出来，而后会指示 3D打印机将这些部件打印出来。上图&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;为&lt;span style="color: rgb(136, 136, 136);"&gt;第四号在演化初期的样子。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 12px; color: rgb(136, 136, 136);"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 12px; color: rgb(136, 136, 136);"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487134544FxWSki.jpg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;经过迭代，第四号演化出比之前稍微先进一些的结构。尽管看上去仍然很粗糙，但需要记住这只是机器人第四号演化的第一步。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487134544LE3Yqo.jpg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 12px; color: rgb(136, 136, 136);"&gt;完成模拟找到最佳结构后，计算机会指示 3D打印机，将自己的部件打印出来。上图为研究人员组装完成的机器人第四号。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;奥斯陆大学机器人和智能系统研究小组副教授 Kyrre Glette&amp;nbsp;表示，机器人第四号的指令由计算机模拟生成，由于计算机模拟器不可能完美地对真实世界建模，所以在虚拟世界和现实世界之间难免会有一些不匹配。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;生成设计程序就像一个“虚拟子宫”，它会尝试数以千计的不同模拟和解决方案，想法设法让机器人最好地适应周围给定的环境——在这里，也就是Glette实验室的地板。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;Glette和他的团队不会告诉计算机如何解决问题，他们只设置一些参数，比如机器人应该从 A 移动到 B，剩下的全部由 AI 完成。这这一过程中，这台拥有创造力的机器会经历上万次迭代，保持最佳版本并再次迭代。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;“这就是人工进化。它从这些‘香肠’和简单电动机非常简单的组合开始。” Glette 看着屏幕上的可视化演变过程解释说。渐渐地，会出现一些解决方案，这些解决方案会带来一些微小的进步。然后，这些带来进步的解决方案会被保存下来，用于下一代的演化，并且再做轻微修改。最终，你会得到越来越好的解决方案。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;通过让 1000个单独的虚拟机器人经历1000代的运算，计算机可以在几个小时内拿出一个有用的模型，然后它会将信息发送给一台3D打印机，让后者将“演化的顶峰”在真实世界中制造出来。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;研究人员所做的，就只是将各个部件用伺服电机结合在一起。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/14871345442VkfHF.jpg"/&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;同系列结构不一样的机器人&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;section class="tn-Powered-by-XIUMI" style="white-space: normal; border-width: 0px; border-style: initial; border-color: initial; clear: both; box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="padding: 8px; border-left: 6px solid rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; font-weight: bold; text-decoration: inherit; color: rgb(10, 10, 10); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); box-sizing: border-box;"&gt;&lt;section&gt;4D 打印：3D 打印出材料供自己生长&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;虽然现在还处在十分原始的阶段，我们已经看到了 4D 打印的兴起——打印机不仅可以打印，还能自动组装新打印的产品。所以，将来有一天，机器人完全可以设计自己、打印自己并且将自己组装起来。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;自此基础上再向前一步，机器人也许很快就能在实验室里生长，就像英国宇航系统（BAE）使用新的分子组装工具生产无人机一样。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;iframe class="video_iframe" data-vidtype="2" allowfullscreen="" frameborder="0" height="417" width="556" data-src="https://v.qq.com/iframe/preview.html?vid=r1313zpquuw&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0"&gt;&lt;/iframe&gt;&lt;br&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;“Chemputer”是一种分子水平的3D 打印机，可以生长，也就是在分子水平上实现自组装。Chemputer 的概念最初在 2012 年被提出，它可以被简单视为一种新型的 3D 打印机，打印出来的是对环境而言可持续且稳定的分子（而不是物体或分层结构）。在添加剂和营养素的帮助下，这些被打印出的分子可以生长（或者说组装）成为任何形状。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;虽然这些系统看上去很厉害，但它们仍然受制于我们人类给他们设定的参数。将来，类似的机器人可能会想出如何避开意想不到的障碍，甚至当场就打印出新的身体部位来解决这些问题。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;这也是为什么包括一些有名科学家在内的人都担心“杀人机器”会出现。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;不过，Glette 对此并没有过分担心。Glette 说，“这是一个非常复杂的挑战，我不认为现在我们取得了任何真正的突破。我认为会有更聪明和更好的解决方案出现，但很长一段时间内，还不会有什么能够接近真正的人类智能。”&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 12px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 12px; color: rgb(0, 0, 0);"&gt;编译来源：http://www.globalfuturist.org/2017/01/norwegian-robot-learns-to-self-evolve-and-3d-print-itself-in-the-lab/（作者&amp;nbsp;&lt;span style="font-size: 12px; text-align: center;"&gt;Matthew Griffin）&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;hr style="white-space: normal;"&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487134544d6vqSQ.jpg"/&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;strong style="color: rgb(123, 12, 0); font-size: 18px;"&gt;【寻找AI独角兽】新智元联手10大资本&lt;/strong&gt;&lt;br&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;strong style="color: rgb(123, 12, 0); font-size: 18px;"&gt;启动2017创业大赛&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;AI 创业大赛由新智元与10 家主流 AI 创投机构：蓝驰创投、红杉资本中国基金、高瓴智成人工智能基金、蓝湖资本、蓝象资本、IDG资本、高榕资本、中信建投证券、明势资本、松禾远望基金携手发起，由新智元主办，北京市中关村科技园区管理委员会、中关村科技园区海淀园管理委员会支持，是一场聚合了 AI 技术领袖和投资领袖的盛会。新智元向满怀雄心的未来AI独角兽提供强大的创投资源对接机会，顶级风投 TS 等你来拿。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;strong&gt;http://form.mikecrm.com/gthejw&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;点击文章下方阅读原文，在线填写报名申请报名表。该报名表为参与评选必填资料。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p class="p11" style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;如有更多介绍资料（例如BP等），可发送至&amp;nbsp;&lt;span style="color: rgb(123, 12, 0);"&gt;xzy100@aiera.com.cn&lt;/span&gt;，邮件标题请注明公司名称。如有任何咨询问题，也欢迎向该邮箱发信联系。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p class="p11" style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;大赛咨询，请添加新智元微信号：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/14871345456ZokLK.jpg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;/div&gt;</description>
      <pubDate>Wed, 15 Feb 2017 12:43:06 +0800</pubDate>
    </item>
    <item>
      <title>深度学习增强毫米级计算机，288 微瓦运行神经网络</title>
      <link>http://www.iwgc.cn/link/4709781</link>
      <description>&lt;div class="article-content"&gt;&lt;section style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; font-family: inherit; font-size: 1em; font-weight: inherit; white-space: normal; max-width: 100%; line-height: 28.4444px; border-style: solid none none; border-top-width: 1px; border-top-color: rgb(204, 204, 204); text-decoration: inherit; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-top: -1.2em; max-width: 100%; min-height: 1em; text-align: center; border-width: initial; border-style: none; border-color: initial; line-height: 1.4; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-size: 18px;"&gt;&lt;strong style="font-family: inherit; font-size: 1em; text-decoration: inherit;"&gt;&lt;span style="color: rgb(255, 255, 255); max-width: 100%; line-height: 1.4; font-family: inherit; font-weight: inherit; text-decoration: inherit; background-color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(127, 127, 127); line-height: 22.4px;"&gt;1&amp;nbsp;&lt;/span&gt;新智元编译 &amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;strong style="font-family: inherit; font-size: 1em; text-decoration: inherit;"&gt;&lt;span style="color: rgb(255, 255, 255); max-width: 100%; line-height: 1.4; font-family: inherit; font-weight: inherit; text-decoration: inherit; background-color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/span&gt;&lt;span style="max-width: 100%; line-height: 1.4; font-family: inherit; font-weight: inherit; text-decoration: inherit; background-color: rgb(127, 127, 127); color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/span&gt;&lt;strong style="color: rgb(136, 136, 136); font-size: 12px;"&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;/section&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;来源：IEEE Spectrum&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;作者：Katherine Bourzac&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;编译：李静怡&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;strong style="font-size: 14px; max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;【新智元导读&lt;/span&gt;】&lt;/strong&gt;密歇根大学两位计算机科学家，在本月初于旧金山举行的IEEE国际固态电路会议（ISSCC）上，介绍了仅有毫米大小的微型计算机。不仅体积小，原型产品仅使用几纳瓦的功率就能在本地运行神经网络，其产品有望让物联网和其他智能设备更加智能。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;PDF：https://reconfigdeeplearning.files.wordpress.com/2017/02/isscc2017-14-7visuals.pdf&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487134547mfEz1Z.gif"/&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;计算机科学家David Blaauw从他的包里拿出一个小塑料盒。他小心翼翼地用手指甲拿起里面的小黑点，把它放在酒店的咖啡桌上。体积仅为一立方毫米，这个小黑点就是世界上最小的计算机之一。我不得不小心忍住不要咳嗽或打喷嚏，以免把这台袖珍计算机吹走，弄进垃圾桶里。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;Blaauw和他的同事Dennis Sylvester 是IEEE Fellow、密歇根大学的计算机科学家。他们在今年2月，旧金山举行的IEEE国际固态电路会议（ISSCC）上介绍了与刚刚说的那些“微尘”计算机相关的十篇论文。在过去几年，他们也提交了类似的微型设备研究。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487134547kdCyZY.jpg"/&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;这些微型计算机主要用于为医疗设备和物联网提供更加智能、更小的传感器。像麦克风、摄像头这些传感器，一般是用作其他智能设备的眼睛和耳朵，必须保持时刻警觉，因此对能耗的要求很高。此外，这类设备也大多将数据上传到云中，因为它们不能在本地分析。有些人预测到2035年，全球将有1万亿个这样的设备。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;“如果你有一个万亿的设备在不断产生数据，我们将被淹没在数据的海洋里，”Blaauw说。通过开发能够在本地进行分析的小型、高能效的计算传感器，Blaauw和Sylvester希望使未来的智能设备更加安全，同时还节省能源。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;在会议上，他们展示了自己的微尘设计，仅使用几纳瓦的功率执行任务，比如区分开过去的汽车的声音，或测量温度和光照等级。他们展示了一个小型收音机，可以将数据从小型计算机发送到距离20米的接收机——相比去年他们在ISSCC汇报的50厘米范围有了很大的提升。Blaauw和Sylvester还描述了他们在TSMC上将闪存嵌入到设备中的工作，以及深度神经网络专用的低功耗硬件研发项目。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;Blaauw和Sylvester说，他们采取一体化方法添加新功能，这样就不会增加功耗。目前，业界尚没有统一的方法实现这样一点，硬要说有的话，就是“智能电路设计”。&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487134547EwVRih.jpg"/&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;Sylvester表示，在内存方面研究是如何权衡提升性能的一个很好的例子。以前的微尘计算机使用8千字节的SRAM，性能相当低。要录制视频和声音，微型计算机需要更多的内存。因此，他们与台积电合作，在电路板上嵌入闪存。现在，他们可以制造具有1兆字节存储空间的小型计算机。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;闪存可以在比SRAM小的占用空间中存储更多的数据，但是需要大量的电力来写入存储器。使用TSMC，他们设计了一个新的存储器阵列，使用更有效的电荷泵来进行写入。存储器阵列比TSMC的商业产品密度小一点，但仍然比SRAM好得多。Sylvester：“我们以很小的牺牲获取了巨大的收益。”&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;他们在ISSCC上展示的另一个微尘设计包括了一个深度学习处理器，上面可以运行一个神经网络，只使用288微瓦的能耗。神经网络通常需要大型内存组和强大的处理能力，因此通常运行在由高级GPU供电的服务器上。有部分研究人员一直试图通过专门设计用于运行这些算法的专用硬件来减小深度学习AI的体积和功率需求。但就算是这些处理器，仍然使用超过50毫瓦的功率——对于微尘计算机而言承受不起。密歇根研究人员通过重新设计芯片架构降低了电源要求，比如在存储器（SRAM）内设置四个处理元件以最小化数据移动。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;研究人员希望把神经网络带到物联网上。“很多运动检测摄像机拍摄到的是在风中移动的树枝，这对安防而言并没有什么帮助，”Blaauw说。安保摄像机和其他连接的设备不够聪明，无法区分盗贼和移动的树枝之间的区别，所以浪费了能量，而且将一些无关的画面送到云端进行分析。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;能够在本地运行的深度学习处理器可以做出更好的决策，但只有当它们不使用太多计算资源的时候才有实际应用意义。密歇根研究小组认为，深度学习处理器可以被集成到许多其他互联网联网设备中，不仅仅局限于安保系统。例如，如果HVAC系统看到多个人穿上外套，就可以决定降低空调。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;除了在学术会议展示他们的作品，密歇根大学的研究人员希望能在未来几年将其研究成果推广上市。Blaauw和Sylvester说，他们的创业公司CubeWorks目前正在开发和研究投放市场的原型。CubeWorks公司成立于2013年底。去年10月，英特尔投资公司宣布投资这家公司，具体金额未披露。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 12px;"&gt;原文地址：http://spectrum.ieee.org/tech-talk/robotics/artificial-intelligence/millimeterscale-computers-now-with-deep-learning-neural-networks-on-board&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;hr style="white-space: normal;"&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487134548ZRgcEC.jpg"/&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;strong style="color: rgb(123, 12, 0); font-size: 18px;"&gt;【寻找AI独角兽】新智元联手10大资本&lt;/strong&gt;&lt;br&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;strong style="color: rgb(123, 12, 0); font-size: 18px;"&gt;启动2017创业大赛&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;AI 创业大赛由新智元与10 家主流 AI 创投机构：蓝驰创投、红杉资本中国基金、高瓴智成人工智能基金、蓝湖资本、蓝象资本、IDG资本、高榕资本、中信建投证券、明势资本、松禾远望基金携手发起，由新智元主办，北京市中关村科技园区管理委员会、中关村科技园区海淀园管理委员会支持，是一场聚合了 AI 技术领袖和投资领袖的盛会。新智元向满怀雄心的未来AI独角兽提供强大的创投资源对接机会，顶级风投 TS 等你来拿。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;strong&gt;http://form.mikecrm.com/gthejw&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;点击文章下方阅读原文，在线填写报名申请报名表。该报名表为参与评选必填资料。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p class="p11" style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;如有更多介绍资料（例如BP等），可发送至&amp;nbsp;&lt;span style="color: rgb(123, 12, 0);"&gt;xzy100@aiera.com.cn&lt;/span&gt;，邮件标题请注明公司名称。如有任何咨询问题，也欢迎向该邮箱发信联系。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p class="p11" style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;大赛咨询，请添加新智元微信号：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487134548a2rnom.jpg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;/div&gt;</description>
      <pubDate>Wed, 15 Feb 2017 12:43:06 +0800</pubDate>
    </item>
  </channel>
</rss>
