<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>新智元</title>
    <link>http://www.iwgc.cn/list/2322</link>
    <description>智能+中国的资讯社交平台,致力于推动中国从互联网+迈向智能+新纪元.重点关注人工智能、机器人、大数据、虚拟现实、量子计算、智能医疗等前沿领域发展,关注人机融合、人工智能和机器人革命对人类社会与文明进化...</description>
    <item>
      <title>《大西洋月刊》盘点中国人工智能崛起，AAAI前主席评周志华组论文</title>
      <link>http://www.iwgc.cn/link/4740903</link>
      <description>&lt;div class="article-content"&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; font-family: inherit; font-size: 1em; font-weight: inherit; white-space: normal; max-width: 100%; line-height: 28.4444px; border-style: solid none none; border-top-width: 1px; border-top-color: rgb(204, 204, 204); text-decoration: inherit; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-top: -1.2em; max-width: 100%; min-height: 1em; text-align: center; border-width: initial; border-style: none; border-color: initial; line-height: 1.4; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;span style="font-size: 18px;"&gt;&lt;span style="color: rgb(255, 255, 255); max-width: 100%; line-height: 1.4; font-family: inherit; font-weight: inherit; text-decoration: inherit; background-color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(127, 127, 127); line-height: 22.4px;"&gt;1&amp;nbsp;&lt;/span&gt;新智元原创 &amp;nbsp;&lt;/span&gt;&lt;span style="max-width: 100%; line-height: 1.4; font-family: inherit; font-weight: inherit; text-decoration: inherit; background-color: rgb(127, 127, 127); color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/span&gt;&lt;strong style="color: rgb(136, 136, 136); font-size: 12px;"&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="font-size: 12px;"&gt;作者：胡祥杰 &amp;nbsp; 零夏 &amp;nbsp; 刘小芹 &amp;nbsp;文强&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;strong&gt;【新智元导读】&amp;nbsp;&lt;/strong&gt;中国人工智能的发展态势已经受到国外媒体和政府的强烈关注。《大西洋月刊》认为，中国有许多得天独厚的优势：政府企业大量投资、技术落地快、生态高度竞争化以及对英语世界的深入了解。AAAI 前主席 Thomas 也对新智元表示，中国有很多非常优秀的研究者，比如在今年AAAI 接收的论文中，南京大学周志华的文章就非常优秀，堪称“世界级”。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&amp;nbsp;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;strong&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487305532a3soPO.gif"/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;人工智能领域的顶级会议 AAAI -17近日落下帷幕，本届大会上被提及最多的一个话题就是“中国力量的崛起”。近日，美国著名杂志《大西洋月刊》网站上刊发了一篇名为《中国人工智能走向繁荣》（China’s Artificial-Intelligence Boom）的文章，以在美国举行的AAAI-17大会为例，盘点了中国人工智能研究力量的崛起，进而延展到介绍中国人工智能产业的持续繁荣。&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;文章认为，除了研究力量的不断进步，中国&amp;nbsp;AI&amp;nbsp;迅速崛起几大原因还包括：政府和企业大量投资、技术落地快、生态高度竞争化以及对英语世界的深入了解。&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;AAAI 前主席&amp;nbsp;Thomas Dietterich 也于近日接受新智元专访，谈到了今年的AAAI 和去年一些人工智能顶级会议上中国学术实力的崛起。他评价说：中国的AI 实力不是靠某一篇伟大论文，而是需要通过不断高质量贡献积累的。&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;section class="tn-Powered-by-XIUMI" style="white-space: normal; border-width: 0px; border-style: initial; border-color: initial; clear: both; box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="padding: 8px; border-left: 6px solid rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; font-weight: bold; text-decoration: inherit; color: rgb(10, 10, 10); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); box-sizing: border-box;"&gt;&lt;section&gt;“没有了他们&lt;span class="s1"&gt;，&lt;/span&gt;会议将无法进行”&lt;/section&gt;&lt;/section&gt;&lt;section style="width: 0px; height: 0px; clear: both;"&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;每年冬天，上千名世界各地的 AI 研究者都会汇聚一堂，参加人工智能促进协会（AAAI）的年会。2017 年的 AAAI 原定于 1 月底在新奥尔良举行。选址没什么问题，但时间恰好撞上了中国的春节。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;这个节日在过去不会有什么影响，但如今中国研究者已经成为会议的重要组成部分，没有了他们，会议将无法进行。AAAI 不得不改期举行。“参考美国，没有人会把 AAAI 设在圣诞节期间，”现任 AAAI 主席 Subbarao Kambhampati 表示：“我们几乎立即改变计划，将会议往后挪了一个星期。”&lt;/span&gt;&lt;/p&gt;&lt;p class="p2" style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;2017 年的 AAAI 最终在旧金山举行，上周刚刚结束。不出预料，中国研究者在历来由美国人主导的会议中表现强劲。在接收的论文中，来自中美两国的数量十分接近。“考虑到三四年前的情况，这算是相当惊人的表现。”Rao 表示。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;根据南京大学教授周志华发布的统计结果：本届AAAI大会，论文投稿上中国数量多于美国，但是在被接收论文数量上，中国还是低于美国的。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;strong&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487305532zsRMec.jpg"/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="font-size: 14px;"&gt;图片来源：周志华微博@南大周志华&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;strong&gt;&lt;br&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;Thomas 在 Twitter 转发了AAAI 现任主席 Rao 的统计结果：&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487305532f8xsUS.png"/&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;本届AAAI 大会只是中国AI 研究力量的一次集中爆发，这种现象其实从去年就已经发生，并被美国政府注意到。在去年 10 月，奥巴马政府推出了一份 AI 研究“战略规划”——《为人工智能的未来做好准备》，其中指出美国在“深度学习”论文发表数量上已经不再是世界领先。那么超越美国的是谁呢？是中国。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;section class="tn-Powered-by-XIUMI" style="white-space: normal; border-width: 0px; border-style: initial; border-color: initial; clear: both; box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="padding: 8px; border-left: 6px solid rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; font-weight: bold; text-decoration: inherit; color: rgb(10, 10, 10); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); box-sizing: border-box;"&gt;&lt;section&gt;AI 顶会程序主席开始出现“中国面孔”&lt;/section&gt;&lt;/section&gt;&lt;section style="width: 0px; height: 0px; clear: both;"&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487305532f7wsUS.jpg"/&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="font-size: 14px;"&gt;图片来源@Wilson_NJUer&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;2017年的AAAI 大会宣布：中国本土AI 学者的代表——南京大学教授周志华当选 2019 年 AAAI的 程序委员会主席。这在 AAAI 历史上尚属首次，充分表明了中国 AI 影响力。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;对此，周志华老师在朋友圈发信息表示，“争取利用这个机会为华人特别是国内学者多做点事。第一件事是把春节时间告诉他们，请会议避开。”周志华教授还表示：“欢迎老师同学们到时多发表优秀成果，欢迎工业界同仁们多展示优秀产品。”&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487305533b3soQO.jpg"/&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;另外，来自微软亚洲研究院的消息，微软亚洲研究院资深研究员，现任微软亚洲研究院计算视觉组负责人华刚将担任 CVPR 2019 的程序主席，以及CVPR 2017 和ACM MM 2017的领域主席。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;section class="tn-Powered-by-XIUMI" style="white-space: normal; border-width: 0px; border-style: initial; border-color: initial; clear: both; box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="padding: 8px; border-left: 6px solid rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; font-weight: bold; text-decoration: inherit; color: rgb(10, 10, 10); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); box-sizing: border-box;"&gt;&lt;section&gt;中国研究者在 AAAI 上的真实表现&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;针对中国的AI研究实力和学者们在本届AAAI大会上的表现，AAAI 前主席大会论文评审委员&amp;nbsp;Thomas Dietterich&amp;nbsp;在接受新智元专访时表示：他个人比较关注强 AI 方面的论文，针对中国的论文，他读了不少，其中一篇是来自南京大学的论文《Construct Safe Prediction from Multiple Regressors》给他留下深刻印象，论文作者是李宇峰、 Han-Wen Zha 和周志华。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;他说：“我认为这项研究是世界级的。当然，也有许多美国团队的论文中有来自中国的研究生。毫无疑问，中国有许多优秀的研究人员，做出了很大的研究贡献。”&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;不过，他也提醒到，中国在这个领域的影响不是通过某一篇伟大的论文，或某一个杰出的成就体现的，而是像其他国家的研究人员一样，是通过许多高质量的贡献不断积累的。&amp;nbsp;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;他提到的另一篇论文来自朱越，Kai Ming Ting 和周志华，是有关在MIML（多示例多标签）学习中发现多个新标签的论文（Discover multiple novel labels in multi-instance multi-label learning）。Thomas 评价说 ，周志华教授所在的南京大学实验室不断有高质量的机器学习论文出现。论文探讨了如何创建可以在开放的世界中表现良好的机器学习算法以及如何利用良好的聚类方法找到对应标签结构的聚类，这在许多领域都是一种合理的设想。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;section class="tn-Powered-by-XIUMI" style="white-space: normal; border-width: 0px; border-style: initial; border-color: initial; clear: both; box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="padding: 8px; border-left: 6px solid rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; font-weight: bold; text-decoration: inherit; color: rgb(10, 10, 10); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); box-sizing: border-box;"&gt;&lt;section&gt;中国&lt;span class="s1"&gt;&amp;nbsp;AI&amp;nbsp;&lt;/span&gt;迅速崛起一大原因&lt;span class="s1"&gt;：&lt;/span&gt;政府和企业大量投资&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;不仅是学术研究，中国的技术公司也在&amp;nbsp;AI&amp;nbsp;领域赶超了上来。中国的搜索巨擘百度（常被比作谷歌）、滴滴出行（常被比作&amp;nbsp;Uber）和腾讯（微信的创建者）都建立了自己的&amp;nbsp;AI&amp;nbsp;研究实验室。坐拥上千万的客户，这些公司能够获取超大规模的数据量用于训练&amp;nbsp;AI&amp;nbsp;识别模式。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;就像微软和谷歌一样，中国技术公司也看中了&amp;nbsp;AI&amp;nbsp;所拥有的巨大潜力。在接下来几十年，AI&amp;nbsp;能衍生出一系列革新技术，从人脸识别到自动驾驶汽车。“我很难想象出一个&amp;nbsp;AI&amp;nbsp;变革不了的产业，”百度首席科学家吴恩达说。吴恩达与人联合创立了&amp;nbsp;Coursera&amp;nbsp;和谷歌大脑，现在掌管百度的&amp;nbsp;AI&amp;nbsp;研究，工作的地点就在硅谷。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;中国 AI 的成功部分归因于政府对高校科研的大规模投资。在过去的十年里，政府的科研支出每年都平均增长两位数。根据 2016 年 3 月公布的“十三五计划”，科研资金仍然是一个主要优先事项。&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;Rao 回忆说，他第一次在国际 AI 会议上看到中国研究人员时，他们通常来自清华和北大，这两所学校分别被视为中国的 MIT 和哈佛。现在，Rao 看到来自全中国各地的研究人员的文章，而不仅仅是最精英的学校。机器学习——包括深度学习——是近来特别热门的研究方向。“在中国，对机器学习有兴趣的人数大幅增加，”Rao说。当然，白宫关于人工智能研究的战略计划报告中也注意到了这一点。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;中国的科技公司也是高校研究经费的一大来源。香港科技大学的计算机科学家杨强与腾讯合作，后者为杨强实验室的学生提供奖学金。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;学生可以从微信获得大量的数据。杨强表示，做 AI 必须要有大规模的数据和测试的平台。这也是与产业界合作如此顺利的原因。作为回报，腾讯能够得到实验室产出的最新研究成果。当然，还有一些学生在毕业后直接加入腾讯工作。&lt;/span&gt;&lt;/p&gt;&lt;p class="p2" style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;section class="tn-Powered-by-XIUMI" style="white-space: normal; border-width: 0px; border-style: initial; border-color: initial; clear: both; box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="padding: 8px; border-left: 6px solid rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; font-weight: bold; text-decoration: inherit; color: rgb(10, 10, 10); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); box-sizing: border-box;"&gt;&lt;section&gt;中外&lt;span class="s1"&gt;&amp;nbsp;AI&amp;nbsp;&lt;/span&gt;研究圈信息不对等&lt;span class="s1"&gt;：&lt;/span&gt;中国对英语世界了解更多&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;中国人工智能研究的数量急剧增长，但很多开创性的基础工作仍然是由美国的研究人员完成。“我在美国看到了关于改变网络架构的巧妙想法，”吴恩达说。中国研究人员擅长的是抓住一个想法（比如机器学习），然后不断输出关于机器学习不同的应用的论文。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;然而，吴恩达表示，随着机器学习研究在中国成熟，就会形成自己独特的圈子。吴恩达以在最近在巴塞罗那举行的国际会议 NIPS 为例，他回忆说，他几乎立即就在会后看到了中文的会议报道——这时候还没有任何英语报道出来。语言问题造成了一种不对称：中国研究人员通常会说英语，因此他们可以获得以英语传播的所有研究信息。另一方面，英语研究界不大可能作者中国 AI 圈子中工作。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;“中国对英语世界发生的事情有相当深入的认识，但反过来不是这样的。”吴恩达指出，百度也推出了由 AI 提供的机器翻译和语音识别服务，但谷歌和微软这样做时得到了更多的宣传。&lt;/span&gt;&lt;/p&gt;&lt;p class="p2" style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;section class="tn-Powered-by-XIUMI" style="white-space: normal; border-width: 0px; border-style: initial; border-color: initial; clear: both; box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="padding: 8px; border-left: 6px solid rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; font-weight: bold; text-decoration: inherit; color: rgb(10, 10, 10); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); box-sizing: border-box;"&gt;&lt;section&gt;中国&lt;span class="s1"&gt;&amp;nbsp;AI&amp;nbsp;&lt;/span&gt;独特优势&lt;span class="s1"&gt;：&lt;/span&gt;技术落地快&lt;span class="s1"&gt;，&lt;/span&gt;生态高度竞争&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;当&lt;span style="font-size: 14px;"&gt;涉及到上线新的功能时，中国公司的行动更快。“中国的工作速度比大多数硅谷快得多。”吴恩达说：“当你在中国找到一个商机时，你的时间窗口一般要比美国短。”&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;杨强将这称之为中国高度竞争的生态系统。微信围绕二维码建立起了一系列功能，包括聊天、付款和朋友发现，使自己在中国的日常生活中不可或缺。美国社交媒体公司要是能获得这样的用户忠诚度，那简直不敢想象。&lt;strong&gt;“腾讯的产品经理非常了解客户的需求，他们可以迅速将技术转化为现实，”杨强说：“而且这个周期很短。”为了保持竞争力，中国的产品经理致力于整合 AI 改进产品。中国科技公司是否会借助这一波 AI 热潮进入国际市场仍有待观察，但他们已经在使用 AI 争抢中国的客户。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;strong&gt;&lt;img src="http://wxrss.b0.upaiyun.com/148730553381qmNM.jpg"/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;em style="font-size: 14px;"&gt;图：Thomas Dietterich 参加新智元世界人工智能大会并发表演讲&lt;/em&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;Thomas 对新智元介绍说，AAAI 是覆盖 AI 所有相关领域的学术会议，欢迎所有领域的论文。从历史上来说，AAAI 在计算机视觉和机器人学方面的论文相对较少，但在搜索和推理（例如 SAT 解析器、约束满足），知识表征，以及机器学习方面的论文数量很多。机器学习已经成为 AAAI 增长最大的一个子领域（大约占总论文数量的 1/3）。今年，有几篇论文涉及计算机视觉和深度学习。AAAI 是一个高质量的学术会议，作者在这里发表论文能触达广泛的受众，而其他大多数会议只针对特定的子领域（如机器学习、自然语言处理、计算机视觉、机器人学等）。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;在学术界，AAAI 现在已经采取措施确保中国的研究人员对会议有所投入。农历新年的确切日期每年都在变化，但几乎都是在 1 月或 2 月，也就是 AAAI 会议按惯例举行的日子。这两者可不能再冲突了。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;section class="tn-Powered-by-XIUMI" style="white-space: normal; border-width: 0px; border-style: initial; border-color: initial; clear: both; box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="padding: 8px; border-left: 6px solid rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; font-weight: bold; text-decoration: inherit; color: rgb(10, 10, 10); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); box-sizing: border-box;"&gt;&lt;section&gt;美国的一个不确定性：特朗普&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;Thomas G. Dietterich 是机器学习领域的创始人之一。他是俄勒冈大学的教授，同时是美国军方研究机构DARPA的顾问。此外，Dietterich 教授也参与撰写了白宫日前推出的两份重磅 AI 报告《为人工智能的未来做准备》和美国《国家人工智能研究与发展策略规划》。特朗普上任后的一系列政策在美国科技区掀起层层波澜，作为美国军方和政府的顾问，Thomas 如何看待美国新任总统？&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;在接受新智元的采访时，Thomas 说，现在还是特朗普政府的初期，所以我们也不知道他优先看中的是什么研究领域。任何总统候选人在竞选期间都没有提及研究。特朗普对基础设施感兴趣，因此也许在数字基础设施和物理基础设施方面会有比较多的投资。特朗普对创造更多高薪工作很感兴趣。过去，新技术破坏了就工作，但带来了新的工作。但我们不知道新政府会如何处理这些问题。&lt;strong&gt;中国政府现在对人工智能的研究和开发非常重视，投资也很多，这让美国政府和行业的人们注意到了。&lt;/strong&gt;因此将来两国可能会出现一些友好的竞争，我们可以观察哪国在推进人工智能技术方面更迅速。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;section class="tn-Powered-by-XIUMI" style="white-space: normal; border-width: 0px; border-style: initial; border-color: initial; clear: both; box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="padding: 8px; border-left: 6px solid rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; font-weight: bold; text-decoration: inherit; color: rgb(10, 10, 10); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); box-sizing: border-box;"&gt;&lt;section&gt;AI 火热背后，警惕骗子公司&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;2017年以来，随着 Master 横扫各路世界围棋冠军、Libratus 在德州扑克手碾压人类棋手，人与机器的PK被看成是人工智能界甚至整个社会津津乐道的话题，AI 在社会和媒体上呈现一片火热的发展态势。&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;在 AAAI 2017 有一个特别的研讨会是专门关于扑克的，这方面顶尖的两个研究团队（Michael Bowling 和 Tuomas Sandholm）介绍了他们的研究工作。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;Thomas 说，听这些研究人员如何寻找应对扑克游戏中的巨大搜索空间的方法非常令人着迷。游戏方面最新的成果令人印象深刻。对于围棋，我认为有意思的是，AlphaGo 的方法结合了深度神经网络（我们知道它在计算机视觉方面表现出色）和蒙特卡洛树搜索（我们现在知道它非常适合围棋）。长期以来人们都认为视觉感知和“直觉”对于人类下围棋是至关重要的，这些实验表明，它们对于计算机下围棋也很重要。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;有一个争论是这些在游戏方面取得的成就是否会对 AI 在现实世界里的应用产生影响。&lt;strong&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;计算机下棋方面取得的进步对 AI 的实际应用基本上没有影响&lt;/span&gt;&lt;/strong&gt;，因为现实世界是嘈杂的，不完全观察的，以及开放的；而围棋和象棋的世界是没有噪声的，完全观察的，封闭的。扑克方面的研究肯定更有更多的实际应用，因为这种困难的不完美信息博弈也出现在许多现实世界的设计中。Sandholm 打算将他的方法应用到自动谈判方面。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;strong&gt;&lt;br&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;strong&gt;Thomas 在接受新智元的采访时，提到了NIPS上出现的一家公司&lt;strong&gt;rocket.ai 。他说，这家公司&lt;strong&gt;去年在 NIPS 上搞开业聚会，号称他们有革命性的技术。&lt;/strong&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;其实这是个假的公司&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;。&lt;/strong&gt;&lt;strong&gt;有几位风险投资人被愚弄了，以为 rocket.ai 是一个真正的初创公司。这也表明了投资者急切地想把钱投入 AI 公司。&lt;/strong&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;br&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;不过，他也提到，AI 确实已经取得了许多重要的进步，我们确实在搜索、推理和感知等方面实现了一些重要的新功能。机器人变得成本越来越低，能力越来越强。因此，将 AI 技术应用到新产品的开发上的机会也很多。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;计算机现在已经能很好地识别物体和人，也开始能识别人的动作，并且能够进行短期的预测。但是我们的 AI 系统在人类语言和人类行为方面的理解仍然非常浅薄。不过，我认为仍然有很多机会能应用现有的计算机视觉技术。举一个小的例子，有人在 Twitter 上提到我们可以使用计算机视觉技术使非接触式水龙头的功能变得更好。举例来说，可以检测和跟踪水龙头下方手的位置，并且能检测手上是否还有肥皂泡。然后推断用户是否想要冲水。这是一个很简单的应用程序。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;随着计算机视觉技术的成本越来越低，也许以后所有的运动检测系统（例如，用于灯、门、水龙头、安全系统等）都将被更智能的视觉技术取代。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;hr style="white-space: normal;"&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487305533KazuWU.jpg"/&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;strong style="color: rgb(123, 12, 0); font-size: 18px;"&gt;【寻找AI独角兽】新智元联手10大资本&lt;/strong&gt;&lt;br&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;strong style="color: rgb(123, 12, 0); font-size: 18px;"&gt;启动2017创业大赛&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;AI 创业大赛由新智元与10 家主流 AI 创投机构：蓝驰创投、红杉资本中国基金、高瓴智成人工智能基金、蓝湖资本、蓝象资本、IDG资本、高榕资本、中信建投证券、明势资本、松禾远望基金携手发起，由新智元主办，北京市中关村科技园区管理委员会、中关村科技园区海淀园管理委员会支持，是一场聚合了 AI 技术领袖和投资领袖的盛会。新智元向满怀雄心的未来AI独角兽提供强大的创投资源对接机会，顶级风投 TS 等你来拿。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;strong&gt;http://form.mikecrm.com/gthejw&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;点击文章下方阅读原文，在线填写报名申请报名表。该报名表为参与评选必填资料。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p class="p11" style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;如有更多介绍资料（例如BP等），可发送至&amp;nbsp;&lt;span style="color: rgb(123, 12, 0);"&gt;xzy100@aiera.com.cn&lt;/span&gt;，邮件标题请注明公司名称。如有任何咨询问题，也欢迎向该邮箱发信联系。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p class="p11" style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;大赛咨询，请添加新智元微信号：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487305533slKG76.jpg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;/section&gt;&lt;/div&gt;</description>
      <pubDate>Fri, 17 Feb 2017 12:03:58 +0800</pubDate>
    </item>
    <item>
      <title>【资源】深度学习 Top100：近 5 年被引用次数最高论文（下载）</title>
      <link>http://www.iwgc.cn/link/4740904</link>
      <description>&lt;div class="article-content"&gt;&lt;section style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; font-family: inherit; font-size: 1em; font-weight: inherit; white-space: normal; max-width: 100%; line-height: 28.4444px; border-style: solid none none; border-top-width: 1px; border-top-color: rgb(204, 204, 204); text-decoration: inherit; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-top: -1.2em; max-width: 100%; min-height: 1em; text-align: center; border-width: initial; border-style: none; border-color: initial; line-height: 1.4; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-size: 18px;"&gt;&lt;strong style="font-family: inherit; font-size: 1em; text-decoration: inherit;"&gt;&lt;span style="color: rgb(255, 255, 255); max-width: 100%; line-height: 1.4; font-family: inherit; font-weight: inherit; text-decoration: inherit; background-color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(127, 127, 127); line-height: 22.4px;"&gt;1&amp;nbsp;&lt;/span&gt;新智元编译 &amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;strong style="font-family: inherit; font-size: 1em; text-decoration: inherit;"&gt;&lt;span style="color: rgb(255, 255, 255); max-width: 100%; line-height: 1.4; font-family: inherit; font-weight: inherit; text-decoration: inherit; background-color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/span&gt;&lt;span style="max-width: 100%; line-height: 1.4; font-family: inherit; font-weight: inherit; text-decoration: inherit; background-color: rgb(127, 127, 127); color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/span&gt;&lt;strong style="color: rgb(136, 136, 136); font-size: 12px;"&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;/section&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;来源：Github&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;作者：Terry T. Um&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;译者：张易&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;【新智元导读】&lt;/span&gt;&lt;/strong&gt;&lt;span style="font-size: 14px;"&gt;这里是近5年100篇被引用次数最多的深度学习论文，覆盖了优化/训练方法、无监督/生成模型、卷积网络模型和图像分割/目标检测等十大子领域。&lt;span style="font-size: 14px;"&gt;重要的论文能够超越其应用领域让人获益。新智元在每个领域都选择了一篇论文重点介绍，这将是你&lt;span style="font-size: 14px;"&gt;纵览深度学习研究绝好的开始。&lt;span style="font-size: 14px; color: rgb(123, 12, 0);"&gt;&lt;strong&gt;【进入新智元公众号，在对话框输入“论文100”下载这份经典资料】&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487305535RK94wu.gif"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;这里是100篇被引用次数最多的深度学习论文，从海量的相关论文中脱颖而出。无论其应用领域是什么，都值得一读，而在其各自的领域，它们是必读之作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;此前已经有一些很棒的深度学习论文的榜单了，比如说Deep Vision和Awesome Recurrent Neural Networks。而在我们这份list诞生之后，另一份面对深度学习初学者的榜单Deep Learning Papers Reading Roadmap也问世并得到了许多深度学习研究者的喜爱。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;虽然这份Roadmap List囊括了许多重要的深度学习论文，对我来说还是有些太多了。正如我在导读中所说，我相信重要的论文能够超越其应用领域，让我们获益。因此，作为纵览深度学习研究的开始，我向大家推荐这100篇深度学习论文。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;收录标准：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="list-style-type: decimal;"&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;收录2012—2016年发表的Top100深度学习论文；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;当list里增加一篇论文时，一般来说，我们会从“2016年的更多论文”里去掉一篇，以保证总数为100篇；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;重要而未列入list的论文，会收入“100篇之外”；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;最近6个月内发表的论文，或是2012年以前的论文，收入到“最新论文”或“老论文”中。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;引用次数标准：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&amp;lt; 6个月 : 新论文(讨论决定)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;2016 : +60 引用 或 "2016年的更多论文"&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;2015 : +200 引用&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;2014 : +400 引用&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;2013 : +600 引用&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;2012 : +800 引用&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;~2012 : 老论文(讨论决定)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;比起某一应用领域内的论文，我们更倾向于选择适用于多个研究领域的开创性深度学习论文。基于此，有些达到了收录标准的论文可能没有被收入，而有些论文则相反。这取决于论文的影响力以及其对其他研究的适用性，等等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;section class="tn-Powered-by-XIUMI" style="white-space: normal; border-width: 0px; border-style: initial; border-color: initial; clear: both; box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="padding: 8px; border-left: 6px solid rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; font-weight: bold; text-decoration: inherit; color: rgb(10, 10, 10); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); box-sizing: border-box;"&gt;&lt;section&gt;目录&lt;br&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;理解/概括/传递&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;优化/训练方法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;无监督/生成模型&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;卷积网络模型&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;图像分割/目标检测&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;图像/视频/其他&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;递归神经网络模型&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;自然语言处理&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;语音/其他领域&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;强化学习&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;2016年的更多论文&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;（100篇之外）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;新论文：最近6个月以内的&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;老论文：2012年以前的&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;HW/SW/数据集：技术报告&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;专著/调查报告/回顾&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;附录：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;未收录的其他优秀论文&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;section class="tn-Powered-by-XIUMI" style="white-space: normal; border-width: 0px; border-style: initial; border-color: initial; clear: both; box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="padding: 8px; border-left: 6px solid rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; font-weight: bold; text-decoration: inherit; color: rgb(10, 10, 10); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); box-sizing: border-box;"&gt;&lt;section&gt;理解/概括/传递&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;在神经网络中提取知识&lt;/span&gt;&lt;br&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;Distilling the knowledge in a neural network (2015)&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;作者 G. Hinton et al.&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;摘要：&lt;/span&gt;&lt;/strong&gt;&lt;span style="font-size: 14px;"&gt;一个很简单的能改善几乎所有机器学习算法表现的办法，就是训练许多基于相同数据集的模型，并取这些模型的预测平均值。问题是，使用全部模型来进行预测是个笨办法，且允许大量用户部署的计算成本过于昂贵，特别是当个体模型是大规模神经网络时。Caruana和他的合作者已经论证，有可能将一个集合中的知识压缩到一个单独模型中，部署起来也容易得多，而且我们使用了不同压缩技巧进一步扩展了这一方法。在MNIST上，我们取得了一些令人吃惊的成功，并展示了可以显著改善一个重度使用商业系统的声学模型，方法就是将集合中的知识概括进一个单独模型。我们也介绍了一个新型集合，由一个或更多的全模型以及许多学会了区分识别细粒度类别（全模型做不到）的专家模型组成，可以对这些专家模型进行快速、并行训练。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;深度神经网络容易被骗：高信度预测无法识别的图片&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Deep neural networks are easily fooled: High confidence predictions for unrecognizable images (2015)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者A. Nguyen et al.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;深度神经网络特征的可迁移性如何？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;How transferable are features in deep neural networks? (2014)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者J. Yosinski et al.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;卷积神经网络现成的一些特性，对识别来说是令人惊奇的起点&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;CNN features off-the-Shelf: An astounding baseline for recognition (2014)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者 A. Razavian et al.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;使用卷积神经网络学习和迁移中层图像表征&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Learning and transferring mid-Level image representations using convolutional neural networks (2014)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者M. Oquab et al.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;卷积网络的可视化和理解&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Visualizing and understanding convolutional networks (2014)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者 M. Zeiler and R. Fergus&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;DeCAF:一个应用于通用视觉识别的深度卷积激活特征&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Decaf: A deep convolutional activation feature for generic visual recognition (2014)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者 J. Donahue et al.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;section class="tn-Powered-by-XIUMI" style="white-space: normal; border-width: 0px; border-style: initial; border-color: initial; clear: both; box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="padding: 8px; border-left: 6px solid rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; font-weight: bold; text-decoration: inherit; color: rgb(10, 10, 10); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); box-sizing: border-box;"&gt;&lt;section&gt;优化/训练方法&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;Batch normalization算法：通过减少内部协变量转化加速深度网络的训练&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;Batch normalization: Accelerating deep network training by reducing internal covariate shift (2015)&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;作者S. Loffe and C. Szegedy&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;摘要：&lt;/span&gt;&lt;/strong&gt;&lt;span style="font-size: 14px;"&gt;训练深层神经网络由于在训练期间每个层的输入的分布改变而变得复杂，因为先前层的参数发生了改变。由于要求较低的学习速率和仔细的参数初始化，它减慢了训练，并且使得训练具有饱和非线性的模型变得非常困难。我们将这种现象称为内部协变量移位（internal covariate shift ），并通过归一化层输入（normalizing layer in- puts&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;）来解决问题。我们的方法将归一化作为模型架构的一部分，并对每个训练迷你批次（each training mini-batch）执行归一化，从而强化其强度。批量正规化允许我们使用高得多的学习速率，并且不用太考虑初始化的问题。 作为一个调节器，在某些情况下，它也消除了对dropout的需要。应用于最先进的图像分类模型，批量归一化在减少了14倍的训练步骤的情况下实现了相同的精度，并且以显著的余量击败原始模型。凭借一个批量归一化网络的集合，我们改进了ImageNet分类已发布的最好结果：达到4.9％的Top5验证错误（以及4.8％的测试误差），超过人类评估者的准确性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;深度探入纠正器：在 Imagenet 分类中超过人类表现&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Delving deep into rectifiers: Surpassing human-level performance on imagenet classification (2015)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者 K. He et al.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Dropout：一个预防神经网络过拟合的简单方式&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Dropout: A simple way to prevent neural networks from overfitting (2014)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者N. Srivastava et al.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Adam：一个随机优化的方法&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Adam: A method for stochastic optimization (2014)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者 D. Kingma and J. Ba&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;通过预防特征检测器的互相适应改善神经网络&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Improving neural networks by preventing co-adaptation of feature detectors (2012)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者G. Hinton et al.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;超参数最优化的随机搜索&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Random search for hyper-parameter optimization (2012) 作者J. Bergstra and Y. Bengio&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;section class="tn-Powered-by-XIUMI" style="white-space: normal; border-width: 0px; border-style: initial; border-color: initial; clear: both; box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="padding: 8px; border-left: 6px solid rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; font-weight: bold; text-decoration: inherit; color: rgb(10, 10, 10); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); box-sizing: border-box;"&gt;&lt;section&gt;无监督/生成模型&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;像素循环神经网络&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Pixel recurrent neural networks (2016)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者 A. Oord et al.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;训练GANs的改善性技巧&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;Improved techniques for training GANs (2016)&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;作者T. Salimans et al.&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;摘要：&lt;/span&gt;&lt;/strong&gt;&lt;span style="font-size: 14px;"&gt;近年来，利用卷积网络（CNN）的监督学习已经在计算机视觉应用中被广泛采用。 相比之下，使用CNN的无监督学习得到的关注较少。 在这项工作中，我们希望帮助弥合CNN的监督学习和无监督学习的成功之间的差距。 我们引入一类称为深层卷积生成对抗网络（DCGAN）的CNN，它们具有某些架构约束，已显示出它们是无监督学习的强有力的候选者。 对各种图像数据集的训练，我们展示了令人信服的证据，表明我们的深层卷积对抗组件从发生器和鉴别器中的对象到场景里面都学习了表征层次。此外，我们使用学习到的特性去完成新任务 – 这显示了它们像一般图像表征一样具有适用性。&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;使用深度卷积生成对抗网络进行无监督表征学习&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Unsupervised representation learning with deep convolutional generative adversarial networks (2015)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者A. Radford et al.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;DRAW：一个用于图像生成的循环神经网络&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;DRAW: A recurrent neural network for image generation (2015)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者K. Gregor et al.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;生成对抗网络&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Generative adversarial nets (2014)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者I. Goodfellow et al.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;自编码变量贝叶斯&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Auto-encoding variational Bayes (2013)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者D. Kingma and M. Welling&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;用大规模无监督学习构建高水平特征&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Building high-level features using large scale unsupervised learning (2013)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者Q. Le et al.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;section class="tn-Powered-by-XIUMI" style="white-space: normal; border-width: 0px; border-style: initial; border-color: initial; clear: both; box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="padding: 8px; border-left: 6px solid rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; font-weight: bold; text-decoration: inherit; color: rgb(10, 10, 10); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); box-sizing: border-box;"&gt;&lt;section&gt;卷积网络模型&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;再思考计算机视觉的Inception结构&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;Rethinking the inception architecture for computer vision (2016)&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;作者C. Szegedy et al.&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;摘要：&lt;/span&gt;&lt;/strong&gt;&lt;span style="font-size: 14px;"&gt;对于多种任务来说，卷及网络处于最先进的计算机视觉解决方案的核心。自2014年以来，超深度卷积网络开始成为主流，在各种benchmark中产生了巨大的收获。虽然对大多数任务来说，增加的模型大小和计算成本往往转化为直接增益（只要提供足够的标记数据用于训练），计算效率和低参数计数仍然是各种用例的有利因素，例如移动视觉和大数据场景。在这里，我们将探讨通过适当的因式分解卷积和积极正则化的方式，尽可能有效地利用增加的算力来扩大网络规模。我们在ILSVRC 2012分类挑战验证集上的benchmark了我们的方法，展示了相对于现有技术的实质性增益：每次推理使用50亿multiply-adds的计算成本及使用少于2500万个参数，每单帧错位率为21.2％top-1和5.6％top-5。综合使用4种模型和multi-crop 评估的综合，我们在验证集上报告3.5％的top-5错误和17.3％的top-1错误，以及正式测试集上3.6％的top-5 错误。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Inception-v4, inception-resnet以及残差连接对学习的影响&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Inception-v4, inception-resnet and the impact of residual connections on learning (2016)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者C. Szegedy et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;在深度残差网络中识别映射&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Identity Mappings in Deep Residual Networks (2016)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者K. He et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;图像识别中的深度残差学习&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Deep residual learning for image recognition (2016)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者K. He et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;深入卷积网络&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Going deeper with convolutions (2015)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者C. Szegedy et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;大规模图像识别的超深度卷积网络&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Very deep convolutional networks for large-scale image recognition (2014)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者K. Simonyan and A. Zisserman&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;用于视觉识别的深度卷积网络的空间金字塔池化&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Spatial pyramid pooling in deep convolutional networks for visual recognition (2014)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者K. He et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;细节魔鬼的回归：深挖卷积网络&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Return of the devil in the details: delving deep into convolutional nets (2014)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者K. Chatfield et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;OverFeat：使用卷积网络融合识别、本地化和检测&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;OverFeat: Integrated recognition, localization and detection using convolutional networks (2013)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者P. Sermanet et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Maxout网络&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Maxout networks (2013)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者I. Goodfellow et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;深度网络架构&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Network in network (2013)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者M. Lin et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;使用深度卷积神经网络进行ImageNet 分类&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;ImageNet classification with deep convolutional neural networks (2012)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者A. Krizhevsky et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;section class="tn-Powered-by-XIUMI" style="white-space: normal; border-width: 0px; border-style: initial; border-color: initial; clear: both; box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="padding: 8px; border-left: 6px solid rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; font-weight: bold; text-decoration: inherit; color: rgb(10, 10, 10); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); box-sizing: border-box;"&gt;&lt;section&gt;图像分割/目标检测&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;你只看一次：统一、实时的目标检测&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;You only look once: Unified, real-time object detection (2016)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者J. Redmon et al.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;用于物体精准检测和分割的基于区域的卷积网络&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Region-based convolutional networks for accurate object detection and segmentation (2016)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者R. Girshick et al.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;用于语义分割的饱和卷积网络&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Fully convolutional networks for semantic segmentation (2015)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者J. Long et al.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;更快速的 R-CNN网络：使用区域建议网络的实时物体检测&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks (2015)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者S. Ren et al.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;快速R-CNN网络&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Fast R-CNN (2015)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者R. Girshick&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;对精确的物体检测和语义切割更为丰富的特征分层&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Rich feature hierarchies for accurate object detection and semantic segmentation (2014)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者R. Girshick et al.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;使用深度卷积网络和完全连接的CRF进行语义图像分割&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Semantic image segmentation with deep convolutional nets and fully connected CRFs&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者L. Chen et al.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;用于场景标注的层级特征学习&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Learning hierarchical features for scene labeling (2013)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者C. Farabet et al.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;section class="tn-Powered-by-XIUMI" style="white-space: normal; border-width: 0px; border-style: initial; border-color: initial; clear: both; box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="padding: 8px; border-left: 6px solid rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; font-weight: bold; text-decoration: inherit; color: rgb(10, 10, 10); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); box-sizing: border-box;"&gt;&lt;section&gt;图像/视频/其他&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;利用深度卷积网络的图像超分辨率&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;Image Super-Resolution Using Deep Convolutional Networks (2016)&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;作者C. Dong et al.&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;摘要：&lt;/span&gt;&lt;/strong&gt;&lt;span style="font-size: 14px;"&gt;我们提出了一种用于单图像超分辨率（SR）的深度学习方法。 我们的方法直接学习低/高分辨率图像之间的端对端映射。 该映射被表示为以低分辨率图像作为输入并输出高分辨率图像的深度卷积神经网络（CNN）。 我们进一步表明，传统的基于稀疏编码的SR方法也可以看作是一个深层卷积网络。 但不同于传统的分别处理每个组件方法，我们的方法联合优化了所有层。 我们的深度CNN具有轻量的结构，但展示了最先进的恢复能力，并实现实际在线使用的高速度。 我们探索不同的网络结构和参数设置，以实现性能和速度之间的权衡。此外，我们扩展我们的网络，以同时处理三个color channels，并显示了更好的整体重建质量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;基于DNN的艺术风格生成算法&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;A neural algorithm of artistic style (2015)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者 L. Gatys et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;可生成图像说明的深度视觉-语义校准模型&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Deep visual-semantic alignments for generating image descriptions (2015)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者A. Karpathy and L. Fei-Fei&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;显示、注意以及说明：带有视觉注意模型的神经图像说明生成&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Show, attend and tell: Neural image caption generation with visual attention (2015)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者K. Xu et al.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;显示和说明：一个神经图像说明生成器&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Show and tell: A neural image caption generator (2015)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者O. Vinyals et al.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;用于视觉识别和描述的长期循环卷积网络&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Long-term recurrent convolutional networks for visual recognition and description (2015)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者J. Donahue et al.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;VQA：视觉问答&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;VQA: Visual question answering (2015)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者S. Antol et al.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;DeepFace：在面部验证任务中接近人类表现&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;DeepFace: Closing the gap to human-level performance in face verification (2014)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者Y. Taigman et al.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;利用卷积神经网络进行大规模视频分类&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Large-scale video classification with convolutional neural networks (2014)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者A. Karpathy et al.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;DeepPose：利用深度神经网络评估人类姿势&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;DeepPose: Human pose estimation via deep neural networks (2014)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者A. Toshev and C. Szegedy&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;用于视频中动作识别的双流卷积网络&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Two-stream convolutional networks for action recognition in videos (2014)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者K. Simonyan et al.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;用于人类动作识别的3D 卷积神经网络&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;3D convolutional neural networks for human action recognition (2013)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者S. Ji et al.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;section class="tn-Powered-by-XIUMI" style="white-space: normal; border-width: 0px; border-style: initial; border-color: initial; clear: both; box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="padding: 8px; border-left: 6px solid rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; font-weight: bold; text-decoration: inherit; color: rgb(10, 10, 10); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); box-sizing: border-box;"&gt;&lt;section&gt;递归神经网络模型&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;递归神经网络的条件随机场&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Conditional random fields as recurrent neural networks (2015)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者S. Zheng and S. Jayasumana.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;记忆网络&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Memory networks (2014)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者J. Weston et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;神经网络图灵机&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Neural turing machines (2014)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者A. Graves et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;递归神经网络生成序列&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Generating sequences with recurrent neural networks (2013)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者A. Graves.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;section class="tn-Powered-by-XIUMI" style="white-space: normal; border-width: 0px; border-style: initial; border-color: initial; clear: both; box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="padding: 8px; border-left: 6px solid rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; font-weight: bold; text-decoration: inherit; color: rgb(10, 10, 10); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); box-sizing: border-box;"&gt;&lt;section&gt;自然语言处理&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;应用于神经网络机器翻译的无显式分割字符级解码器&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;A character-level decoder without explicit segmentation for neural machine translation (2016)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者J. Chung et al.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;探索语言建模的局限性&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Exploring the limits of language modeling (2016)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者R. Jozefowicz et al.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;教机器阅读和理解&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;Teaching machines to read and comprehend (2015)&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;作者 K. Hermann et al.&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;摘要：教机器阅读自然语言文档仍然是一个难以应付的挑战。对于看到的文档内容，我们可以测试机器阅读系统回答相关问题的能力，但是到目前为止，对于这种类型的评估仍缺少大规模的训练和测试数据集。在这项工作中，我们定义了一种新的方法来解决这个瓶颈，并提供了大规模的监督阅读理解数据。 这允许我们开发一类基于attention的深层神经网络，凭借最少的语言结构的先验知识来学习阅读真实文档和回答复杂的问题 。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;attended-based神经网络机器翻译有效策略&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Effective approaches to attention-based neural machine translation (2015)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者 M. Luong et al.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;通过共同学习对齐和翻译实现神经机器翻译&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Neural machine translation by jointly learning to align and translate (2014)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者 D. Bahdanau et al.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;利用神经网络进行序列到序列的学习&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Sequence to sequence learning with neural networks (2014)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者I. Sutskever et al.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;用 RNN 编码——解码器学习短语表征，实现统计机器翻译&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Learning phrase representations using RNN encoder-decoder for statistical machine translation (2014)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者K. Cho et al.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;一个为句子建模的卷积神经网络&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;A convolutional neural network for modelling sentences (2014)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者 N. Kalchbrenner et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;用于句子分类的卷积神经网络&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Convolutional neural networks for sentence classification (2014)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者Y. Kim&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Glove: 用于词表征的全局向量&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Glove: Global vectors for word representation (2014)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者 J. Pennington et al.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;句子和文档的分布式表示&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Distributed representations of sentences and documents (2014)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者Q. Le and T. Mikolov&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;词、短语及其合成性的分布式表征&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Distributed representations of words and phrases and their compositionality (2013)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者T. Mikolov et al.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;有效评估词在向量空间中的表征&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Efficient estimation of word representations in vector space (2013)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者T. Mikolov et al.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;基于情感树库应用于情感组合研究的递归深度网络模型&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Recursive deep models for semantic compositionality over a sentiment treebank (2013)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者R. Socher et al.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;section class="tn-Powered-by-XIUMI" style="white-space: normal; border-width: 0px; border-style: initial; border-color: initial; clear: both; box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="padding: 8px; border-left: 6px solid rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; font-weight: bold; text-decoration: inherit; color: rgb(10, 10, 10); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); box-sizing: border-box;"&gt;&lt;section&gt;语音/其他领域&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;端到端attention-based大规模词表语音识别&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;End-to-end attention-based large vocabulary speech recognition (2016)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者 D. Bahdanau et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Deep speech 2：中英文端到端语音识别&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Deep speech 2: End-to-end speech recognition in English and Mandarin (2015)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者 D. Amodei et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;使用深度循环网络进行语音识别&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Speech recognition with deep recurrent neural networks (2013)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者A. Graves&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;用于语音识别中声学建模的深度神经网络：四个研究小组的观点分享&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups (2012)&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;作者G. Hinton et al.&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;摘要：&lt;/span&gt;&lt;/strong&gt;&lt;span style="font-size: 14px;"&gt;大多数当前的语音识别系统都使用隐马尔科夫模型（HMMs）来解决语音中的时间变化问题，用混合高斯模型（GMMs）来评价每一个HMM拟合声音输入表示帧或者小窗口帧系数的效果。存在一种替代评价方法是使用前馈神经网络来将多个帧系数作为输入，将HMM状态的后验概率作为输出。深度神经网络有很多隐藏层，通过新的方法进行训练，在很多语音识别任务上都比GMM模型更加出众，有时甚至会好非常多。本文将会做一个综述，分别对四家研究机构在最近语音识别的声学建模领域取得的成功进行介绍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;基于上下文预训练的深度神经网络在大规模词表语音识别中的应用&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Context-dependent pre-trained deep neural networks for large-vocabulary speech recognition (2012)&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者G. Dahl et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;使用深度置信网络进行声学建模&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Acoustic modeling using deep belief networks (2012)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者A. Mohamed et al.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;section class="tn-Powered-by-XIUMI" style="white-space: normal; border-width: 0px; border-style: initial; border-color: initial; clear: both; box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="padding: 8px; border-left: 6px solid rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; font-weight: bold; text-decoration: inherit; color: rgb(10, 10, 10); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); box-sizing: border-box;"&gt;&lt;section&gt;强化学习&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;深度视觉运动策略的端到端训练&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;End-to-end training of deep visuomotor policies (2016),&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者S. Levine et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;利用深度学习和大规模数据搜集，学习眼手协调的机器人抓取&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Learning Hand-Eye Coordination for Robotic Grasping with Deep Learning and Large-Scale Data Collection (2016)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者 S. Levine et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;深度强化学习的异步方法&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Asynchronous methods for deep reinforcement learning (2016)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者V. Mnih et al.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;使用双Q学习的深度强化学习&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Deep Reinforcement Learning with Double Q-Learning (2016)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者 H. Hasselt et al.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;通过深度神经网络和树搜索来掌控围棋游戏&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;Mastering the game of Go with deep neural networks and tree search (2016)&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;作者 D. Silver et al.&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;摘要&lt;/span&gt;&lt;/strong&gt;&lt;span style="font-size: 14px;"&gt;：围棋被视为人工智能挑战经典游戏中最难的一个，因为其巨大的搜索空间和对位置和移动的评价难度。本文提出了一种新方法使用“值网络”来评价位置，用“策略网络”来选择移动。这些深度神经网络是从人类专家棋局中进行有监督学习，然后在从自对弈中进行强化学习。如果不考虑前向搜索的话，当前最好的神经网路模型是蒙特卡洛树搜索，这种方法通过进行上千局的自对弈来进行仿真。我们也介绍了一种新点的搜索算法，将蒙特卡洛仿真与值网络和策略网络进行了综合。使用这种搜索算法，我们的项目AlphaGo有99.8%的胜率，并且以5：0的比分打败了来自欧洲的人类冠军。这也是计算机第一次在真实围棋比赛中击败人类专业选手，将10年后的目标提前完成了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;采用深度强化学习进行持续控制&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Continuous control with deep reinforcement learning (2015)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者T. Lillicrap et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;通过深度强化学习实现人类水平控制&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Human-level control through deep reinforcement learning (2015)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者V. Mnih et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;侦测机器人抓取的深度学习&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Deep learning for detecting robotic grasps (2015)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者 I. Lenz et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;用强化学习玩atari游戏&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Playing atari with deep reinforcement learning (2013)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;作者V. Mnih et al.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;section class="tn-Powered-by-XIUMI" style="white-space: normal; border-width: 0px; border-style: initial; border-color: initial; clear: both; box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="padding: 8px; border-left: 6px solid rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; font-weight: bold; text-decoration: inherit; color: rgb(10, 10, 10); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); box-sizing: border-box;"&gt;&lt;section&gt;理解/概括/传递2016年的更多论文&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Layer Normalization (2016), J. Ba et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Learning to learn by gradient descent by gradient descent (2016), M. Andrychowicz et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Domain-adversarial training of neural networks (2016), Y. Ganin et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;WaveNet: A Generative Model for Raw Audio (2016), A. Oord et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Colorful image colorization (2016), R. Zhang et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Generative visual manipulation on the natural image manifold (2016), J. Zhu et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Texture networks: Feed-forward synthesis of textures and stylized images (2016), D Ulyanov et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;SSD: Single shot multibox detector (2016), W. Liu et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and&amp;lt; 1MB model size (2016), F. Iandola et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Eie: Efficient inference engine on compressed deep neural network (2016), S. Han et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Binarized neural networks: Training deep neural networks with weights and activations constrained to+ 1 or-1 (2016), M. Courbariaux et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Dynamic memory networks for visual and textual question answering (2016), C. Xiong et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Stacked attention networks for image question answering (2016), Z. Yang et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Hybrid computing using a neural network with dynamic external memory (2016), A. Graves et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation (2016), Y. Wu et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;section class="tn-Powered-by-XIUMI" style="white-space: normal; border-width: 0px; border-style: initial; border-color: initial; clear: both; box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="padding: 8px; border-left: 6px solid rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; font-weight: bold; text-decoration: inherit; color: rgb(10, 10, 10); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); box-sizing: border-box;"&gt;&lt;section&gt;100篇之外&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;新论文：最近6个月以内的&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: square;"&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Batch Renormalization: Towards Reducing Minibatch Dependence in Batch-Normalized Models, S. Ioffe.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Wasserstein GAN, M. Arjovsky et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Understanding deep learning requires rethinking generalization, C. Zhang et al. [pdf]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;老论文：2012年以前的&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: square;"&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;An analysis of single-layer networks in unsupervised feature learning (2011), A. Coates et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Deep sparse rectifier neural networks (2011), X. Glorot et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Natural language processing (almost) from scratch (2011), R. Collobert et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Recurrent neural network based language model (2010), T. Mikolov et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion (2010), P. Vincent et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Learning mid-level features for recognition (2010), Y. Boureau&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;A practical guide to training restricted boltzmann machines (2010), G. Hinton&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Understanding the difficulty of training deep feedforward neural networks (2010), X. Glorot and Y. Bengio&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Why does unsupervised pre-training help deep learning (2010), D. Erhan et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Recurrent neural network based language model (2010), T. Mikolov et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Learning deep architectures for AI (2009), Y. Bengio.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations (2009), H. Lee et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Greedy layer-wise training of deep networks (2007), Y. Bengio et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Reducing the dimensionality of data with neural networks, G. Hinton and R. Salakhutdinov.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;A fast learning algorithm for deep belief nets (2006), G. Hinton et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Gradient-based learning applied to document recognition (1998), Y. LeCun et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Long short-term memory (1997), S. Hochreiter and J. Schmidhuber.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;section class="tn-Powered-by-XIUMI" style="white-space: normal; border-width: 0px; border-style: initial; border-color: initial; clear: both; box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="padding: 8px; border-left: 6px solid rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; font-weight: bold; text-decoration: inherit; color: rgb(10, 10, 10); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); box-sizing: border-box;"&gt;&lt;section&gt;HW/SW/数据集：技术报告&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: square;"&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;OpenAI gym (2016), G. Brockman et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;TensorFlow: Large-scale machine learning on heterogeneous distributed systems (2016), M. Abadi et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Theano: A Python framework for fast computation of mathematical expressions, R. Al-Rfou et al.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;MatConvNet: Convolutional neural networks for matlab (2015), A. Vedaldi and K. Lenc&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Imagenet large scale visual recognition challenge (2015), O. Russakovsky et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Caffe: Convolutional architecture for fast feature embedding (2014), Y. Jia et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;section class="tn-Powered-by-XIUMI" style="white-space: normal; border-width: 0px; border-style: initial; border-color: initial; clear: both; box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="padding: 8px; border-left: 6px solid rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; font-weight: bold; text-decoration: inherit; color: rgb(10, 10, 10); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); box-sizing: border-box;"&gt;&lt;section&gt;专著/调查报告/综述&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: square;"&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Deep learning (Book, 2016), Goodfellow et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;LSTM: A search space odyssey (2016), K. Greff et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Deep learning (2015), Y. LeCun, Y. Bengio and G. Hinton&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Deep learning in neural networks: An overview (2015), J. Schmidhuber&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Representation learning: A review and new perspectives (2013), Y. Bengio et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;section class="tn-Powered-by-XIUMI" style="white-space: normal; border-width: 0px; border-style: initial; border-color: initial; clear: both; box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="padding: 8px; border-left: 6px solid rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; font-weight: bold; text-decoration: inherit; color: rgb(10, 10, 10); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); box-sizing: border-box;"&gt;&lt;section&gt;附录：未收录的其他优秀论文&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 12px;"&gt;Dermatologist-level classification of skin cancer with deep neural networks (2017), A. Esteva et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 12px;"&gt;Weakly supervised object localization with multi-fold multiple instance learning (2017), R. Gokberk et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 12px;"&gt;Brain tumor segmentation with deep neural networks (2017), M. Havaei et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 12px;"&gt;(2016)&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 12px;"&gt;Professor Forcing: A New Algorithm for Training Recurrent Networks (2016), A. Lamb et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 12px;"&gt;Adversarially learned inference (2016), V. Dumoulin et al.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 12px;"&gt;Understanding convolutional neural networks (2016), J. Koushik&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 12px;"&gt;Taking the human out of the loop: A review of bayesian optimization (2016), B. Shahriari et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 12px;"&gt;Adaptive computation time for recurrent neural networks (2016), A. Graves&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 12px;"&gt;Densely connected convolutional networks (2016), G. Huang et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 12px;"&gt;Continuous deep q-learning with model-based acceleration (2016), S. Gu et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 12px;"&gt;A thorough examination of the cnn/daily mail reading comprehension task (2016), D. Chen et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 12px;"&gt;Achieving open vocabulary neural machine translation with hybrid word-character models, M. Luong and C. Manning.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 12px;"&gt;Very Deep Convolutional Networks for Natural Language Processing (2016), A. Conneau et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 12px;"&gt;Bag of tricks for efficient text classification (2016), A. Joulin et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 12px;"&gt;Efficient piecewise training of deep structured models for semantic segmentation (2016), G. Lin et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 12px;"&gt;Learning to compose neural networks for question answering (2016), J. Andreas et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 12px;"&gt;Perceptual losses for real-time style transfer and super-resolution (2016), J. Johnson et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 12px;"&gt;Reading text in the wild with convolutional neural networks (2016), M. Jaderberg et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 12px;"&gt;What makes for effective detection proposals? (2016), J. Hosang et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 12px;"&gt;Inside-outside net: Detecting objects in context with skip pooling and recurrent neural networks (2016), S. Bell et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 12px;"&gt;Instance-aware semantic segmentation via multi-task network cascades (2016), J. Dai et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 12px;"&gt;Conditional image generation with pixelcnn decoders (2016), A. van den Oord et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 12px;"&gt;Deep networks with stochastic depth (2016), G. Huang et al.,&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 12px;"&gt;由于微信字数限制，要浏览 2015 年（含）前的论文，请访问：https://github.com/terryum/awesome-deep-learning-papers/blob/master/README.md&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 12px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 12px;"&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;【在新智元后台输入“论文100”下载这份经典资料】&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;hr style="white-space: normal;"&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487305535JC1Wom.jpg"/&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;strong style="color: rgb(123, 12, 0); font-size: 18px;"&gt;【寻找AI独角兽】新智元联手10大资本&lt;/strong&gt;&lt;br&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;strong style="color: rgb(123, 12, 0); font-size: 18px;"&gt;启动2017创业大赛&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;AI 创业大赛由新智元与10 家主流 AI 创投机构：蓝驰创投、红杉资本中国基金、高瓴智成人工智能基金、蓝湖资本、蓝象资本、IDG资本、高榕资本、中信建投证券、明势资本、松禾远望基金携手发起，由新智元主办，北京市中关村科技园区管理委员会、中关村科技园区海淀园管理委员会支持，是一场聚合了 AI 技术领袖和投资领袖的盛会。新智元向满怀雄心的未来AI独角兽提供强大的创投资源对接机会，顶级</description>
      <pubDate>Fri, 17 Feb 2017 12:03:58 +0800</pubDate>
    </item>
    <item>
      <title>陆奇亲掌度秘事业部，前小冰负责人百度再相逢</title>
      <link>http://www.iwgc.cn/link/4740905</link>
      <description>&lt;div class="article-content"&gt;&lt;section style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; font-family: inherit; font-size: 1em; font-weight: inherit; white-space: normal; max-width: 100%; line-height: 28.4444px; border-style: solid none none; border-top-width: 1px; border-top-color: rgb(204, 204, 204); text-decoration: inherit; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-top: -1.2em; max-width: 100%; min-height: 1em; text-align: center; border-width: initial; border-style: none; border-color: initial; line-height: 1.4; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="font-family: inherit; font-size: 1em; text-decoration: inherit;"&gt;&lt;span style="font-size: 18px; color: rgb(255, 255, 255); max-width: 100%; line-height: 1.4; font-family: inherit; font-weight: inherit; text-decoration: inherit; background-color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(127, 127, 127); line-height: 22.4px;"&gt;1&amp;nbsp;&lt;/span&gt;新智元报道 &amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;来源：百度、度秘官方微信公众号&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;整理：文越&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;【新智元导读】&lt;/span&gt;&lt;/strong&gt;&lt;span style="font-size: 14px;"&gt;今年初刚刚上任的百度集团总裁兼首席运营官陆奇，昨日发布了一个重大通告：百度成立度秘事业部，同时百度高级总监景鲲升任该事业部总经理，朱凯华升任事业部首席技术官。其中景鲲曾是微软小冰的首席研发官。本文讲述了陆奇和景鲲从微软小冰到百度度秘之路，同时分析了当前语音交互战场稍占有利地位的亚马逊和百度、微软的在语音交互的布局。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487305537voNIa8.gif"/&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;section class="tn-Powered-by-XIUMI" style="white-space: normal; border-width: 0px; border-style: initial; border-color: initial; clear: both; box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="padding: 8px; border-left: 6px solid rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; font-weight: bold; text-decoration: inherit; color: rgb(10, 10, 10); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="box-sizing: border-box;"&gt;陆奇上任一把火，成立度秘事业部&lt;/section&gt;&lt;/section&gt;&lt;section style="width: 0px; height: 0px; clear: both;"&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;2月16日，百度集团总裁兼COO陆奇发出通告，宣布自即日起将原度秘团队升级为度秘事业部，直接向其汇报，以加速人工智能布局，及其产品化和市场化。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487305537WPe9Bz.jpg"/&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;span style="font-size: 12px; color: rgb(136, 136, 136);"&gt;百度集团总裁兼COO陆奇&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="font-size: 12px; color: rgb(136, 136, 136);"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;通告还显示，百度高级总监景鲲和首席架构师朱凯华将担任事业部的核心管理层。景鲲担任事业部总经理，朱凯华担任事业部首席技术官。度秘业务直接向百度集团总裁和首席运营官陆奇汇报。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487305538c5upRP.jpg"/&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="font-size: 12px; color: rgb(136, 136, 136);"&gt;度秘事业部总经理景鲲&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;在这份通告中，陆奇充分肯定了度秘事业部管理层景鲲与朱凯华此前所做的工作。他表示，景鲲是百度培养的优秀管理者，带领度秘团队依托百度人工智能技术，做了很多开创式的探索并积累了丰富的经验。通告还感谢了百度首席科学家吴恩达和其带领的人工智能团队对度秘发展的支持。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/148730553881qlNL.jpg"/&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;span style="font-size: 12px;"&gt;度秘事业部首席技术官朱凯华&lt;/span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;inherit&gt;&lt;span style="font-size: 14px;"&gt;业内公认，语音交互是下一代人机交互方式。度秘作为百度人工智能的集大成者，独立事业部的成立将为度秘带来更多资源与空间。而度秘在产品化和商业化方面的突破尝试，或许将为百度带来新的增长点。&lt;/span&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;inherit&gt;&lt;/inherit&gt;&lt;inherit&gt;&lt;span style="font-size: 14px;"&gt;陆奇曾说，今后百度对人工智能的研究将与产品结合得更加紧密，他的目标是将百度打造为人工智能时代全球领先的高科技公司。度秘团队升级为独立事业部的同一天百度还宣布全资收购渡鸦科技，90后公司创始人吕骋和团队加盟百度，向陆奇直接汇报。陆奇正在有力执行和推进百度的人工智能战略，快速落实成业务行动，实践他百度人工智能战略发展承诺的第一步。&lt;/span&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;section class="tn-Powered-by-XIUMI" style="white-space: normal; border-width: 0px; border-style: initial; border-color: initial; clear: both; box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="padding: 8px; border-left: 6px solid rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; font-weight: bold; text-decoration: inherit; color: rgb(10, 10, 10); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="box-sizing: border-box;"&gt;前小冰负责人“相聚”百度，从微软小冰到百度度秘&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;陆奇此前层是微软的全球执行副总裁，是微软中职务最高的华人。去年下半年，陆奇因为骑自行车受伤而从微软离职。今年一月份，&lt;a href="http://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&amp;amp;mid=2651992217&amp;amp;idx=1&amp;amp;sn=e905fe498bcf2ee5ff84318ecc40b9f7&amp;amp;chksm=f1214468c656cd7ee2ffc5de659cb19dfa800b924284044399499ec020ada58ae71120438237&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&amp;amp;mid=2651992217&amp;amp;idx=1&amp;amp;sn=e905fe498bcf2ee5ff84318ecc40b9f7&amp;amp;chksm=f1214468c656cd7ee2ffc5de659cb19dfa800b924284044399499ec020ada58ae71120438237&amp;amp;scene=21#wechat_redirect"&gt;百度宣布陆奇确认加盟百度&lt;/a&gt;，出任百度集团总裁兼首席运营官，可谓一人之下万人之上，百度现有各业务群组及负责人都将直接向陆奇汇报工作。业界对陆奇对百度带来什么样的影响都持期待的心态。此次成立度秘事业部可以说是陆奇上任的“第一把火”。值得注意的是，陆奇此前在微软的核心项目之一就是Cortana业务，其中包括微软亚洲研究院的“小冰”项目，当时也是因为陆奇看到“小冰”整个实际的运作过程之后，正式拍板立项。看起来陆奇一向对语音技术和产品情有独钟。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;景鲲历任百度人工智能产品委员会主席、百度搜索公司产品委员会主席、大搜索总产品架构师。加入百度之前担任微软首席研发总监，是微软小冰的创造者。陆奇之前经过跟国内研发小冰的团队讨论项目，包括景鲲。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;但是以陆奇之前在微软的级别之高，他并不是景鲲在微软时的直属老板。其中还有前微软亚洲互联网工程院院长王永东负责小冰项目，景鲲当时为小冰技术负责人。王永东前段时间升任为微软全球资深副总裁，目前领导微软人工智能与研究事业部以及Office产品事业部在亚洲的团队，负责微软在亚太地区的互联网产品与服务的研发。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;section class="tn-Powered-by-XIUMI" style="white-space: normal; border-width: 0px; border-style: initial; border-color: initial; clear: both; box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="padding: 8px; border-left: 6px solid rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; font-weight: bold; text-decoration: inherit; color: rgb(10, 10, 10); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="box-sizing: border-box;"&gt;各巨头加大语音投入，人机交互硝烟四起&lt;/section&gt;&lt;/section&gt;&lt;section style="width: 0px; height: 0px; clear: both;"&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;2016年，亚马逊的 Echo 系列设备销量很好，价格不高的 Echo Dot 智能音箱已经成为购物季时亚马逊网站最畅销的商品。Forrester 的研究估计，到2016年年底，亚马逊卖出了 600 万台 Echo 设备。&lt;/span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&amp;amp;mid=2651992210&amp;amp;idx=1&amp;amp;sn=63a1de158bd89a0ada46faba3c3dff9a&amp;amp;chksm=f1214463c656cd753fc20c7667738136babbffa042b52d1f79207049379a8282f9050254ee25&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&amp;amp;mid=2651992210&amp;amp;idx=1&amp;amp;sn=63a1de158bd89a0ada46faba3c3dff9a&amp;amp;chksm=f1214463c656cd753fc20c7667738136babbffa042b52d1f79207049379a8282f9050254ee25&amp;amp;scene=21#wechat_redirect"&gt;&lt;span style="font-size: 14px;"&gt;亚马逊的Alexa在今年一月CES上大放异彩&lt;/span&gt;&lt;/a&gt;&lt;span style="font-size: 14px;"&gt;，低调的亚马逊不知不觉似乎已经在这一潜力巨大的市场上完成了布局。&lt;strong&gt;大家的共识是， 智能语音助理将成为下一代计算平台。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;语音识别技术领域的领军者微软向来对语音交互非常重视。微软小冰在中国知名度很高，其卖萌的形象深入人心。虽然曾经一度被微信以安全问题为理由而封杀，但是小冰还是获取了不少用户，去年七月份有数据表示微软小冰有4200万用户，甚至美国版、日本版小冰都纷纷上线，形成了小冰姐妹团。总的来说微软小冰的形象非常鲜明且深入人心，但是对于帮助微软在语音交互领域立足还有差距，期待微软小冰的下一步发展。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;在今年 1 月的 CES 大会上，&lt;/span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&amp;amp;mid=2651991948&amp;amp;idx=2&amp;amp;sn=06715bfd027e10c1d30fcd1cd6e07a56&amp;amp;chksm=f1215b7dc656d26b7cda0372ca1eac4b016bb949d57898c575f6fa0f672e18f5cb8770d8c858&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&amp;amp;mid=2651991948&amp;amp;idx=2&amp;amp;sn=06715bfd027e10c1d30fcd1cd6e07a56&amp;amp;chksm=f1215b7dc656d26b7cda0372ca1eac4b016bb949d57898c575f6fa0f672e18f5cb8770d8c858&amp;amp;scene=21#wechat_redirect"&gt;&lt;span style="font-size: 14px;"&gt;百度正式推出了由度秘团队研发的首款 AI 操作系统 DuerOS&lt;/span&gt;&lt;/a&gt;&lt;span style="font-size: 14px;"&gt;，并宣布与北京小鱼儿科技有限公司合作推出“小鱼在家”。这也被 CNN 评选为 CES 年度 14 项最酷产品技术之一，CNN 称，小鱼在家就是中国版的亚马逊 Echo。百度希望这款操作系统未来可以成为广泛搭载于手机、电视、汽车、机器人等硬件设备的基础架构平台，同时还能支持第三方开发者的接入。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;inherit&gt;&lt;br&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;百度首席科学家吴恩达曾表示 2017 年将是 “对话机器” 元年。通过自然语言进行语音对话的DuerOS，可以通过云端大脑时刻进行自动学习，&lt;strong&gt;是目前全球最 “聪明” 的对话式人工智能系统之一&lt;/strong&gt;，也将成为百度在语音交互领域重要。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;李彦宏在上周的亚布力论坛上说：移动互联网时代已经结束了，2016年到2017年是从移动互联网时代转向人工智能时代的转型阶段。PC互联网是人与计算机的交互，移动互联网是人与触摸屏的交互，&lt;strong&gt;到了人工智能时代，人机交互的方式会变成自然语言&lt;/strong&gt;，带来很大变化。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;如今百度成立度秘事业部，更说明百度这一重磅级玩家着力语音交互的决心。战场已硝烟四起……&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;hr style="white-space: normal;"&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487305538SLa5xv.jpg"/&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;strong style="text-align: center; color: rgb(123, 12, 0); font-size: 18px;"&gt;【寻找AI独角兽】新智元联手10大资本&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;strong style="color: rgb(123, 12, 0); font-size: 18px;"&gt;启动2017创业大赛&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;AI 创业大赛由新智元与10 家主流 AI 创投机构：蓝驰创投、红杉资本中国基金、高瓴智成人工智能基金、蓝湖资本、蓝象资本、IDG资本、高榕资本、中信建投证券、明势资本、松禾远望基金携手发起，由新智元主办，北京市中关村科技园区管理委员会、中关村科技园区海淀园管理委员会支持，是一场聚合了 AI 技术领袖和投资领袖的盛会。新智元向满怀雄心的未来AI独角兽提供强大的创投资源对接机会，顶级风投 TS 等你来拿。http://form.mikecrm.com/gthejw&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;点击文章下方阅读原文，在线填写报名申请报名表。该报名表为参与评选必填资料。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p class="p11" style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;如有更多介绍资料（例如BP等），可发送至&amp;nbsp;&lt;span style="color: rgb(123, 12, 0);"&gt;xzy100@aiera.com.cn&lt;/span&gt;，邮件标题请注明公司名称。如有任何咨询问题，也欢迎向该邮箱发信联系。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p class="p11" style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;大赛咨询，请添加新智元微信号：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487305538zsRMec.jpg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;/div&gt;</description>
      <pubDate>Fri, 17 Feb 2017 12:03:58 +0800</pubDate>
    </item>
    <item>
      <title>【干货】谷歌 TensorFlow Fold 以静制动，称霸动态计算图</title>
      <link>http://www.iwgc.cn/link/4740906</link>
      <description>&lt;div class="article-content"&gt;&lt;section style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; font-family: inherit; font-size: 1em; font-weight: inherit; white-space: normal; max-width: 100%; line-height: 28.4444px; border-style: solid none none; border-top-width: 1px; border-top-color: rgb(204, 204, 204); text-decoration: inherit; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-top: -1.2em; max-width: 100%; min-height: 1em; text-align: center; border-width: initial; border-style: none; border-color: initial; line-height: 1.4; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-size: 18px;"&gt;&lt;strong style="font-family: inherit; font-size: 1em; text-decoration: inherit;"&gt;&lt;span style="color: rgb(255, 255, 255); max-width: 100%; line-height: 1.4; font-family: inherit; font-weight: inherit; text-decoration: inherit; background-color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(127, 127, 127); line-height: 22.4px;"&gt;1&amp;nbsp;&lt;/span&gt;新智元推荐 &amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;strong style="font-family: inherit; font-size: 1em; text-decoration: inherit;"&gt;&lt;span style="color: rgb(255, 255, 255); max-width: 100%; line-height: 1.4; font-family: inherit; font-weight: inherit; text-decoration: inherit; background-color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/span&gt;&lt;span style="max-width: 100%; line-height: 1.4; font-family: inherit; font-weight: inherit; text-decoration: inherit; background-color: rgb(127, 127, 127); color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/span&gt;&lt;strong style="color: rgb(136, 136, 136); font-size: 12px;"&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;/section&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;来源：知乎专栏 &amp;nbsp; 作者授权转载&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;作者：刘思聪&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;【新智元导读】&lt;/span&gt;&lt;/strong&gt;&lt;span style="font-size: 14px;"&gt;谷歌日前推出深度学习动态图计算工具 TensorFlow Fold，可以&lt;/span&gt;&lt;span style="font-size: 14px;"&gt;根据不同结构的输入数据建立动态的计算图，简化训练阶段输入数据的预处理过程，提升系统运行效率。&lt;span style="font-size: 14px;"&gt;为了方便大家了解 TensorFlow Fold 的特性，本文将会为大家厘清有关动态图计算的一些概念，对比介绍 DyNet、PyTorch 和 TensorFlow 等框架的特性，重点讲解TensorFlow Fold 的核心算法和接口。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487305540VNc8zy.gif"/&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;随着深度学习的发展，深度学习框架之间竞争也日益激烈，新老框架纷纷各显神通，想要在广大 DeepLearner 的服务器上占据一席之地。近日它们交锋的战场就是动态计算图，谁能在这场战争中取得优势，谁就把握住了未来用户的流向。作为一名 DeepLearner，如果能选中最适合的框架，就能在学习、研究和生产中提高自己的效率，步步领先。但要是上错了船，文档、性能、灵活性四处漏水，跳船之后还得游一段时间，这段时间可能都够别人开到新大陆了。所以说了解框架发展，掌握最新形式，可谓是每个不甘人后的 DeepLearner 的必修课。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;近期各大框架发展的趋势主要有两个，一个是增加对动态图计算的支持，另一个是在主编程语言上适应广大用户的需求。最近比较火热的动态计算图相关的框架主要有 DyNet、 PyTorch 和 TensorFlow Fold，就是围绕着这其中一个点或两个点进行的。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;目前在这场竞争中，TensorFlow Fold 以其先进的 Dynamic Batching 算法走在了其他框架的前面。为了方便大家了解 TensorFlow Fold 的特性，本文将会为大家厘清有关动态图计算的一些概念，对比介绍 DyNet、PyTorch 和 TensorFlow 等框架的特性，重点讲解TensorFlow Fold 的核心算法和接口。&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;本文分为五个部分：&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="width: 528.188px; white-space: normal;"&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;一、当我们说动态计算图的时候，我们指的是什么？&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;二、框架竞争的焦点：编程语言与动态计算图&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;三、以静制动：巧妙的Dynamic Batching算法&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;四、TensorFlow Fold：封装在静态框架上的动态接口&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;五、总结&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section class="tn-Powered-by-XIUMI" style="white-space: normal; border-width: 0px; border-style: initial; border-color: initial; clear: both; box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="padding: 8px; border-left: 6px solid rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; font-weight: bold; text-decoration: inherit; color: rgb(10, 10, 10); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); box-sizing: border-box;"&gt;&lt;section&gt;当我们说动态计算图的时候，我们指的是什么？&lt;br&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;首先，我们要搞清楚深度学习框架所谓的“动态”和“静态”究竟是按照什么标准划分的。为了大家的直观理解，我这里要引入一个系列比喻，房地产商（框架使用者）通过电子邮件（编程语言代码）请建筑公司（深度学习框架）帮忙建造房子（计算图） 。&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;在静态框架使用的是&lt;strong&gt;静态声明&lt;/strong&gt;（static declaration）策略，计算图的声明和执行是分开的，换成比喻的说法就是：建筑设计师画建筑设计图（声明）和施工队建造房子（执行）是分开进行的。画设计图的时候施工队的建筑工人、材料和机器都还没动，这也就是我们说的静态。这个整个声明和执行的过程中涉及到两个图，这里我们分别给它们一个名字，声明阶段构建的图叫&lt;strong&gt;虚拟计算图&lt;/strong&gt;，在这个过程中框架需要将用户的代码转化为可以一份详细的计算图，这份计算图一般会包含计算执行顺序和内存空间分配的策略，这些策略的制定一般是这个过程最消耗时间的部分；执行阶段构建的图叫&lt;strong&gt;实体计算图&lt;/strong&gt;，这个过程包括为参数和中间结果实际分配内存空间，并按照当前需求进行计算等，数据就在这张实体计算图中计算和传递。不过这里要注意一点的是，虚拟计算图中的部件并不需要在每一次执行中都转化为实体计算图。像建筑设计图上画了三层别墅的规划，但建筑队可以在按客户的要求只建下面的两层。另外一张设计图可以用多少次也没有规定死，所以说静态只是相对于下面的动态框架而言，并不是说静态框架就只能按部就班。常见的静态框架有 TensorFlow、MXNet、Theano 等。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;而动态框架则不同，使用的是&lt;strong&gt;动态声明&lt;/strong&gt;（dynamic declaration）策略，声明和执行一起进行的。比喻一下就是设计师和施工队是一起工作的，设计师看邮件的第一句如“要有一个二十平方米的卧室”，马上画出这个卧室的设计图交给施工队建造，然后再去看第二句。这样虚拟计算图和实体计算图的构建就是同步进行的了。因为可以实时的计划，动态框架可以根据实时需求构建对应的计算图，在灵活性上，动态框架会更胜一筹。Torch、DyNet、Chainer 等就是动态框架。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;灵活很好，但也不是没有代价的。不然的话现在流行的框架中，就不会是静态框架占比更高了。静态框架将声明和执行分开有什么好处呢？最大的好处就是在执行前就知道了所有的需要进行操作，所以可以对图中各节点计算顺序和内存分配进行合理的规划，这样就可以就较快的执行所需的计算。就像房地产商邮件里说，“建一个栋大楼，楼顶建个花园，大楼旁边建一个游泳馆”，但这个顺序并不是最优的，设计师画完图之后，发现大楼的选址旁边要预留游泳馆的空间，游泳馆和大楼可以同时开工，并不用等到大楼的楼顶花园建完，就在图上把这些信息标注了出来，施工队就可以更高效地施工。这样一来，静态框架的执行效率相对来说就更高一些。这一点是动态框架的劣势，因为它每次规划、分配内存、执行的时候，都只能看到局部的需求，所以并不能做出全局最优的规划和内存分配。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;另外的好处是对于建筑公司的管理层（框架开发者），因为一张设计图可以被反复施工，所以设计师画图的快慢影响就小地多了，对于一个要建几年的工程设计师画图的时间是三天还是五天影响不大，静态建筑公司不用花费太多资源去培训设计师的画图速度（缩短构建虚拟计算图的时间，主要是规划计算顺序和分配内存空间的时间）。而动态建筑公司就不同了，因为每建一套房子或一排房子就要重新画一遍设计图，对于一个几周的子项目来说，花三天画图还是五天就影响比较大了。所以动态框架对虚拟计算图的构建速度有较高的要求。当然因为动态框架每步构建和计算只是虚拟计算图的一个局部，需要策略不会太复杂，所以制定策略也快得多。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;在过去的大部分的深度学习项目中，不管使用的是静态框架还是动态框架，我们实际上都只用到了构建静态实际计算图的能力。为什么这样说呢？因为在一般在将数据投入模型进行训练或预测之前，往往会有一个预处理的步奏。在预处理的时候，我们会将图片缩放裁剪，将句子拼接截断，使他们变为同样的形状大小，然后将集成一个个批次（min-batch），等待批次训练或预测。这些不同的输入到模型中其实运行的是同一个计算图。换成房地产的说法，就是说用户的需求虽然略有区别，但经过房地产商的努力，他们都同意要同一款房子。不管是房地产商选的是静态建筑公司还是动态建筑公司，建造的房子都是统一的小区样式。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;这样作的好处是可以充分利用GPU和多核CPU的并行计算能力。这种能力可以怎么理解呢？建筑施工队里面有很多的砌墙工人，100个人取砌一堵1米的墙并不会比10个人快上10倍（能实际工作的可能还是只有10个人），而让他们同时砌十堵1米的墙，可能所花的时间可能和砌一堵墙几乎一样快。如果有很多可以通过这样并行来加速的工作，那整个工程所需要的时间也就可以大大缩短。GPU能够几十倍上百倍地提高计算速度是现代深度学习发展的一个关键，毕竟现在的深度模型很大程度上还是很依赖调参，需要快速地迭代。能否利用这种加速能力常常就是一次训练几个小时还是几周的区别，也是决定一个项目能不能做的关键。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;然而，并不是所有项目的数据都可以预处理成相同的形状和尺寸。例如自然语言处理中的语法解析树，源代码中的抽象语法树，以及网页中的DOM树等，形状的不同本身就是非常重要的特征，不可剥离。这些数据就像充满个性的艺术家，每个人对房子该是什么样的都有自己的想法，买房的主要目的就是想彰显个性，你想让他们买一样的房子，对不起，做不到。&amp;nbsp;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;这样一来，对于每一个样例，我们都需要一个新的计算图，这种问题我们需要使用构建动态计算图的能力才能够解决。这种问题我们可以叫它多结构输入问题，因为这个问题中计算图的动态需求是输入带来的。不同框架这个问题的求解能力可以分为三个程度：第一层，无法计算，对于所有样本都要求同样的结构，在 TensorFlow Fold 出来之前所有正常使用的静态框架处于这个层次。第二层，能计算但不够高效，不同批次的样本之间可以有不同的结构，但同一个批次样本都是同一个结构，因为无法利用GPU和多核CPU的并行计算能力，不能高效计算，目前所有的动态框架属于这个层次。第三层，能高效计算，能够在同一个批次里包含不同结构的样本，这个层次的多结构输入问题有些论坛上也叫Dynamic Batching问题， TensorFlow Fold 的核心算法 Dynamic Batching 算法刚好同名，TensorFlow Fold 和以后实现 Dynamic Batching 算法的框架处于这个层次。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;多结构输入问题早已存在，可用的模型诸如递归神经网络（Recursive Neural Networks）也提出许久，但因为没有办法高效实现，研究和使用者寥寥无几。因此，当我们说各大框架的动态计算图的时候，我们关心的不仅仅是他们谁更容易做到，更重要的是能不能高效地做到。动态计算图问题之一的多结构输入问题的高效计算问题一旦解决，就会大大促进树状网络甚至更复杂模型和数据集的发展。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;但多结构输入问题并不是唯一的动态图计算问题，这里给大家举另外一个例子，即计算图的结构要依赖于自身的计算结果的情况，类比就是后面房子怎么建要看前面建得怎么样，这种问题更加复杂，所有的动态框架都可以轻松解决，而静态框架目前是做不到，不过目前还没发现有具体问题需要这样操作，我们这里不作仔细讨论。&lt;/span&gt;&lt;/p&gt;&lt;h2 style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;section class="tn-Powered-by-XIUMI" style="white-space: normal; border-width: 0px; border-style: initial; border-color: initial; clear: both; box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="padding: 8px; border-left: 6px solid rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; font-weight: bold; text-decoration: inherit; color: rgb(10, 10, 10); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); box-sizing: border-box;"&gt;&lt;section&gt;框架竞争的焦点：编程语言与动态计算图&lt;br&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;在动态计算图争锋下面，还隐含着另外一重较量，编程语言的支持。上文我们将代码比作电子邮件，那编程语言就是像英语、中文这样的语言。当前深度学习界最受欢迎的语言莫过于Python了，此外C++也因为其本身的高效在工业界颇得青睐。现在大多主流框架都支持这两种语言，他们是就像机器学习界的中英文。不过Torch是一个例外，它使用的是比较小众的Lua，这实际上是它最大一块短板，因为使用Lua做一些数据处理并不方便，使用者经常要使用Python之类的语言进行数据清洗等操作，然后在转化为Lua可以读取的形式。这一点使得无数使用者在不同语言的切换中纷纷投向TensorFlow、MXNet的怀抱。即使去年年中Facebook推出TorchNet这个Torch升级版也没有挽回太多的人气，因为TorchNet用的也是Lua。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;在DyNet出现前，Python和C++上还没有一个比较高效的动态计算框架（如Chainer效率并不高）。这个由多所大学和公司的二十多位研究者共同发布新框架，一下子就找准了自己的定位，即在深度学习框架中语言最好（Python/C++）且动态计算最强。他们通过对动态声明的图构建流程的优化，大大提高了构建虚拟计算图的速度，也就是说他们的建筑设计师画图和规划做得飞起。该框架在LSTM和BiLSTM等部分测试中超过了Chainer、Theano和TensorFlow，并且在当时Theano和TensorFlow难以实现的树状模型TreeLSTM的测试中也远远打败了Chainer，所以DyNet一出来吸引住了不少使用者。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;然而好景不长，Torch不愧是有Facebook支持的公司，很快就推出了据说内部使用已久的PyTorch，将Torch移植到了Python，补足了自己最后一块短板。这下子就厉害了，不仅挽留住了人气，借助Python的力量甚至有机会从TensorFlow这位老大手里夺下一块蛋糕。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;但是不管是DyNet还是PyTorch，没有解决多结构输入问题的高效计算。它们虽然对不同的批次（mini-batch）可以给出不同的计算图。但同一个批次内部的样本的形状还是要求一致，并没有一个成熟的解决方案来应对这种情况。就是说他们每建一栋楼或一批楼的可以重新设计，但同时开工的同一批楼的样式一定是一样的。&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;面对新老对手的挑战，TensorFlow作为深度学习框架界的霸主也不能无动于衷，终于给出了自己关于动态计算图高效计算的答案——TensorFlow Fold，也就是我们今天要讲的主角。这主角出场瞬时就hold住了场面，在Reddit上就有人立马评论“... pip uninstall pytorch!”。从上一部分我们知道，TensorFlow其实是一个静态框架，天生在解决动态计算图问题上处于劣势。你说它一个静态的框架，怎么就解决了动态计算图的问题呢？（其实只是解决了多结构输入的问题）这中间究竟有什么奥秘，让笔者为大家娓娓道来。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;section class="tn-Powered-by-XIUMI" style="white-space: normal; border-width: 0px; border-style: initial; border-color: initial; clear: both; box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="padding: 8px; border-left: 6px solid rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; font-weight: bold; text-decoration: inherit; color: rgb(10, 10, 10); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); box-sizing: border-box;"&gt;&lt;section&gt;以静制动：巧妙的Dynamic Batching算法&lt;br&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;TensorFlow Fold解决问题的核心技术叫Dynamic Batching，这个技术能够构建一个能够模拟任意形状和大小的动态计算图的静态图，原本不同样本的动态计算图都会被重写成能够被这个计算图高效计算的形式。这样就巧妙地解决了动态计算图的高效计算问题。打比喻就是，建筑公司请了一位计算机科学家写了一个自动化办公软件，每当房地产商提出一个个性社区问题的时候，这个软件就会把一张通用的设计图告诉设计师去设计；然后对于每一批楼的需求这个软件都会生成对应的施工指南，只要按照这个指南的指示，施工就可以通过多次建造通用设计图中的一部分来完成这批楼的建造；在施工指南中软件已经合并每次建造时重复的工作，这样施工队可以并行施工，高效地完成工程。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;更妙的是，这个技术并不仅在TensorFlow上能够使用，对于其他深度学习框架完全能够适用。可以预见的是，如果短期内没有更好的解决方案，这个技术很可能会被其他框架的开发者移植到他们自己的框架上，变成MXNet Fold，PyTorch Fold等。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;那为什么用静态计算图模拟动态计算图是可能的？因为虽然动态计算图的形状和大小千变万化，但对于一个模型来说它们的基本组件却可以简单划分为两种：Tensor（张量）和Operation（操作）。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;Tensor，可以看做各种各样的数据块，主要包括输入的样本和计算结果，Tensor的类型可以按照shape（形状）和data type（数据类型）划分，具有相同shape和data type的Tensor可以被划分为一类，就像相同大小和材质的砖头；这里的shape并不包括batch size，它就像砖头的个数，一叠不管是十块还是五块，只要砖头的大小材质一样，我们认为是同一个类。&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;Operation，并不是是指加减乘除这样最底层的操作，而是指一块小的计算子图，一块计算子图接受某种确定类型的Tensor作为输入，并输出某种确定类型的Tensor。这块计算子图在动态构建图的过程中并不会被拆开，而是作为一个整体被适用，比如RNN的Cell或其他用户自己定义的一些固定的操作组合。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;对于某一个模型如树状RNN来说，但它只会有限种Operation和Tensor类型，当我们将这些Operation和Tensor类型放到一起，我们就有了一个通用子图，这时候只需要一些控制部件控制这个每次子图执行的部分（上文有提到每次执行的实体计算图可以只是虚拟计算图的一部分）以及组合方式，我们就可以模拟对应模型所有可能的计算图。达成这种控制只需TensorFlow的三个部件：tf.gather、tf.concat和tf.while_loop。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;说完通用子图的组成，我们再说说Dynamic Batching怎么将不同结构的计算图重写成可以用通用子图计算的形式。Dynamic Batching是一个贪婪（greedy）的算法，它接受一个有向无环计算图作为输入:&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="width: 528.188px; white-space: normal;"&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;给图中的每一个节点（操作）标注一个深度，所有没有任何依赖的节点标注为深度0，依赖的节点深度最大为d的节点的深度标注为d+1；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;在图中插入pass-through（直通）的操作，使得第d+1层只依赖于第d层；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;将同一深度涉及相同操作的节点合并到一起，方便并行计算；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;将同一深度的计算结果按Tensor类型（包括Tensor的形状和数值类型）有序拼接在一起；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;将输入原始计算图中的每条边标记上（深度，数据类型，序号），对应它们可以获取上一层计算结果的位置。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;对于一批不同结构的计算图，我们可以把它们看做不连通的大图同样处理。上面算法的第三步会将这批图中同一深度的相同操作进行合并，方便并行计算。说完图的构建，我们再说说怎么执行：算法在每次迭代中执行一个深度的计算，使用tf.while_loop从深度0一直执行到最大深度。在每一个深度中，tf.gather根据上面第五步的标记为各个Operation获取当前深度各条输入边的Tensor，如果某个Operation没有获取到任何Tensor，说明当前深度这个Operation不需要执行计算。Operation执行完后tf.concat将相同Tensor类型的计算结果拼接在一起，提供给下一个深度的计算。&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487305540woNJa9.png"/&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;上面这一幅图来着官方论文，左边是Dynamic Batching为二叉TreeRNN构建的通用计算图。右边是一颗简单的语法解析树。通用计算图中有两种Tensor，代表单词的编码整数、词向量/hidden向量的128维向量。Operation也只有两个一个词向量查表操作（embed lookup）和一个RNN的Cell。图中gather和concat之间的直连表示直通（pass-through）操作。右边的语法解析树可以分为三层计算被执行：第一层，将1、3、5通过词向量查表操作，输出3个128维的词向量；第二层，1和3对应的词向量通过RNN Cell输出一个128维的隐含层向量，5对应的词向量直通输出；第三层，上一层计算的隐含层向量和5对应的词向量通过RNN Cell，输出一个128维的隐含层向量。计算完毕。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;那这个算法的效果怎么样呢？它在TreeLSTM的实验中，8核英特尔CPU的可以加速20多倍，而英伟达GTX-1080上可以加速100倍左右。这个加速比是采用Dynamic Batching算法批处理中平均每个样本执行的平均时间和单个样本不作批处理的执行时间之比。这里不包含构建虚拟图所需要的时间。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;section class="tn-Powered-by-XIUMI" style="white-space: normal; border-width: 0px; border-style: initial; border-color: initial; clear: both; box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="padding: 8px; border-left: 6px solid rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; font-weight: bold; text-decoration: inherit; color: rgb(10, 10, 10); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); box-sizing: border-box;"&gt;&lt;section&gt;TensorFlow Fold：封装在静态框架上的动态接口&lt;br&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;上面的Dynamic Batching的算法很繁琐，但不用当心，这个过程是由框架自动完成的，作为框架的使用者，我们只要知道怎么调用官方给出来的接口就可以了。新推出的TensorFlow Fold就是一个TensorFlow的封装，设计参考了函数式编程的一些思想，目的就是方便用户快速地构建动态计算图。下面我们来简单地浏览一下，要进一步了解可以去看官方的教学文档。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;TensorFlow Fold提供了一些函数专门用来处理序列&amp;nbsp;&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/14873055405YniKI.png"/&gt;：&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="margin-bottom: 10px; white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="width: 528.188px; white-space: normal;"&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&amp;nbsp;&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/14873055412VkfHG.png"/&gt;&lt;span style="font-size: 14px;"&gt;：计算&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487305541QJ83vt.png"/&gt;&lt;span style="font-size: 14px;"&gt;将函数f应用到每一个序列的元素，比如将句子中的每一个词转化为词向量；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&amp;nbsp;&lt;img src="http://wxrss.b0.upaiyun.com/1487305541tlKG86.png"/&gt;&lt;span style="font-size: 14px;"&gt;：计算&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487305541BtSOge.png"/&gt;&lt;span style="font-size: 14px;"&gt;，比如说展开一个RNN（循环神经网络）；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&amp;nbsp;&lt;img src="http://wxrss.b0.upaiyun.com/1487305542b4tpQP.png"/&gt;&lt;span style="font-size: 14px;"&gt;：计算&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/14873055423WlgIG.png"/&gt;&lt;span style="font-size: 14px;"&gt;，将函数g应用到一颗平衡二叉树上，比如对序列中的元素作max或sum-pooling。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;由于TensorFlow原本的基本单元Tensor不适合用于构建动态图，所以Fold引入新的基本组件Block。Block有明确的一个输入类型和一个输出类型，包括：&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="width: 528.188px; white-space: normal;"&gt;&lt;li&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487305542NF40rq.png"/&gt;&lt;span style="font-size: 14px;"&gt;：来着编程语言如Python中元素，比如字典等；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487305543xpPKca.png"/&gt;&lt;span style="font-size: 14px;"&gt;：拥有数据类型和形状的TensorFlow基本模块；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487305543c5upRP.png"/&gt;&lt;span style="font-size: 14px;"&gt;：括号中的每一个t表示对应位置的类型；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/14873055434XmhJH.png"/&gt;&lt;span style="font-size: 14px;"&gt;：一个不定长的拥有类型为t的元素的序列；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487305544d6vqSQ.png"/&gt;&lt;span style="font-size: 14px;"&gt;：单元类型。这些基本类型可以相互嵌套，比如一个Block的输入类型可以是Input类型的Tuple。&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;用来创建Block的基本函数有：&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="width: 528.188px; white-space: normal;"&gt;&lt;li&gt;&lt;p style="margin-bottom: 10px;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487305544EwVRjh.png"/&gt;&lt;span style="font-size: 14px;"&gt;：将Python标量转化为Tensor；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="margin-bottom: 10px;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487305544tmkgIG.png"/&gt;&lt;span style="font-size: 14px;"&gt;：将Numpy数组转化为Tensor；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="margin-bottom: 10px;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/14873055445YniKI.png"/&gt;&lt;span style="font-size: 14px;"&gt;：创建一个Operation；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="margin-bottom: 10px;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487305544yXmiJI.png"/&gt;&lt;span style="font-size: 14px;"&gt;：用于预处理Python类型。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;用来组合Block的基本函数有：&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="width: 528.188px; white-space: normal;"&gt;&lt;li&gt;&lt;p style="margin-bottom: 10px;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/14873055440TidFD.png"/&gt;&lt;span style="font-size: 14px;"&gt;，流水线（pipeline）：将b₁的输出作为b₂的输入；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="margin-bottom: 10px;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487305545JC1Wom.png"/&gt;&lt;span style="font-size: 14px;"&gt;： 接受一个Python字典为输入，对字典中key值为&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487305545OH6B31.png"/&gt;&lt;span style="font-size: 14px;"&gt;的value应用&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487305545HAZUmk.png"/&gt;&lt;span style="font-size: 14px;"&gt;；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="margin-bottom: 10px;"&gt;&lt;img data-s="300,640" data-type="png" data-src="http://mmbiz.qpic.cn/mmbiz_png/UicQ7HgWiaUb1j5ZXO9p40OHccZHHc5iczEzrCas2IhXrrxIHZFODV7GD3ZORlfloTFAf32jjkHMvxNiaFcuHN6mwg/0?wx_fmt=png" data-ratio="0.17796610169491525" data-w="118"&gt;&lt;span style="font-size: 14px;"&gt;：根据输入条件应用&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487305546e7wrTR.png"/&gt;&lt;span style="font-size: 14px;"&gt;中的一个；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="margin-bottom: 10px;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487305546xqPKca.png"/&gt;&lt;span style="font-size: 14px;"&gt;：OneOf的特例，如果输入不为None，应用b；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="margin-bottom: 10px;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487305546kcBxYX.png"/&gt;&lt;span style="font-size: 14px;"&gt;：输入应用&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487305546TLa6yw.png"/&gt;&lt;span style="font-size: 14px;"&gt;中的每一个。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;用来组合Block的高级函数有：&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="width: 528.188px; white-space: normal;"&gt;&lt;li&gt;&lt;p style="margin-bottom: 10px;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487305546nfEA20.png"/&gt;&lt;span style="font-size: 14px;"&gt;：流水线的升级版，流水线只能处理串行的流程，Composition()创建一个Scope对象，在这个Scope的缩进范围内，采用来读取多个数据流，可以用于构建多分支结构；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="margin-bottom: 10px;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487305546KD2Xpn.png"/&gt;&lt;span style="font-size: 14px;"&gt;：用来创建递归结构，这个函数可以先定义一个预先占位的表达式expr，等这个表达式定义完再用expr.resolve_to(expr_def)，将表达式递归地代入，这是用来创建树结构计算图必不可少的工具。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;h2 style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;section class="tn-Powered-by-XIUMI" style="white-space: normal; border-width: 0px; border-style: initial; border-color: initial; clear: both; box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="padding: 8px; border-left: 6px solid rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; font-weight: bold; text-decoration: inherit; color: rgb(10, 10, 10); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); box-sizing: border-box;"&gt;&lt;section&gt;总结&lt;br&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;在动态图计算领域TensorFlow Fold目前领先一步，却也不是高枕无忧，只要MXNet， PyTorch等竞争对手抓紧把Dynamic Batching算法实现出来，或进一步想出更好的解决方案，就能很快赶上。而且TensorFlow Fold目前只支持TensorFlow 1.0版本，但只有尽快支持所有版本，才能让更多的用户使用上。另外工具的发展也会带动学科的进步，随着动态计算图的实现难度的下降和计算效率的提高，研究者们会越来越多地进入这个领域，可以预期的是接下来一段时间肯定会有更多复杂结构的模型和数据集涌现出来。未来将会如何，诸君尽请期待。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 12px; color: rgb(136, 136, 136);"&gt;原文链接：https://zhuanlan.zhihu.com/p/25216368&lt;/span&gt;&lt;/p&gt;&lt;hr style="white-space: normal;"&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487305547SLa5xv.jpg"/&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;strong style="color: rgb(123, 12, 0); font-size: 18px;"&gt;【寻找AI独角兽】新智元联手10大资本&lt;/strong&gt;&lt;br&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;strong style="color: rgb(123, 12, 0); font-size: 18px;"&gt;启动2017创业大赛&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;AI 创业大赛由新智元与10 家主流 AI 创投机构：蓝驰创投、红杉资本中国基金、高瓴智成人工智能基金、蓝湖资本、蓝象资本、IDG资本、高榕资本、中信建投证券、明势资本、松禾远望基金携手发起，由新智元主办，北京市中关村科技园区管理委员会、中关村科技园区海淀园管理委员会支持，是一场聚合了 AI 技术领袖和投资领袖的盛会。新智元向满怀雄心的未来AI独角兽提供强大的创投资源对接机会，顶级风投 TS 等你来拿。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;strong&gt;http://form.mikecrm.com/gthejw&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;点击文章下方阅读原文，在线填写报名申请报名表。该报名表为参与评选必填资料。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p class="p11" style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;如有更多介绍资料（例如BP等），可发送至&amp;nbsp;&lt;span style="color: rgb(123, 12, 0);"&gt;xzy100@aiera.com.cn&lt;/span&gt;，邮件标题请注明公司名称。如有任何咨询问题，也欢迎向该邮箱发信联系。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p class="p11" style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;大赛咨询，请添加新智元微信号：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487305547d6vqSQ.jpg"/&gt;&lt;/p&gt;&lt;/div&gt;</description>
      <pubDate>Fri, 17 Feb 2017 12:03:58 +0800</pubDate>
    </item>
    <item>
      <title>CVPR-17：谷歌大规模视频理解 Kaggle 挑战赛，首次加入音频特征</title>
      <link>http://www.iwgc.cn/link/4740907</link>
      <description>&lt;div class="article-content"&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;section style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; font-family: inherit; font-size: 1em; font-weight: inherit; white-space: normal; max-width: 100%; line-height: 28.4444px; border-style: solid none none; border-top-width: 1px; border-top-color: rgb(204, 204, 204); text-decoration: inherit; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-top: -1.2em; max-width: 100%; min-height: 1em; text-align: center; border-width: initial; border-style: none; border-color: initial; line-height: 1.4; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-size: 18px;"&gt;&lt;strong style="font-family: inherit; font-size: 1em; text-decoration: inherit;"&gt;&lt;span style="color: rgb(255, 255, 255); max-width: 100%; line-height: 1.4; font-family: inherit; font-weight: inherit; text-decoration: inherit; background-color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(127, 127, 127); line-height: 22.4px;"&gt;1&amp;nbsp;&lt;/span&gt;新智元编译 &amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;strong style="font-family: inherit; font-size: 1em; text-decoration: inherit;"&gt;&lt;span style="color: rgb(255, 255, 255); max-width: 100%; line-height: 1.4; font-family: inherit; font-weight: inherit; text-decoration: inherit; background-color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/span&gt;&lt;span style="max-width: 100%; line-height: 1.4; font-family: inherit; font-weight: inherit; text-decoration: inherit; background-color: rgb(127, 127, 127); color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/span&gt;&lt;strong style="color: rgb(136, 136, 136); font-size: 12px;"&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;/section&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;来源：Google Research&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;作者：Paul Natsev，软件工程师&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="color:#888888"&gt;&lt;span style="font-size: 12px;"&gt;编译：李静怡&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;【新智元导读】&lt;/span&gt;&lt;/strong&gt;&lt;span style="font-size: 14px;"&gt;谷歌昨天发布消息，更新了此前开源的含上万个视频的大规模数据集 Youtube-8M，新的数据集除了标签升级，还首次包含了预计算的音频特征（pre-computed audio features），有助于&lt;span style="font-size: 14px;"&gt;联合视听（时间）建模。此外，谷歌还联合Kaggle举办了视频理解竞赛，邀请参与者使用Youtube-8M作为训练数据，利用&lt;span style="font-size: 14px;"&gt;谷&lt;/span&gt;&lt;span style="font-size: 14px;"&gt;歌云机器学习平台&lt;/span&gt;构建&lt;/span&gt;&lt;/span&gt;&lt;span style="font-size: 14px;"&gt;视听内容分类模型。相关内容会在今年的CVPR会议上作为Workshop 展出。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487305548RJ84wu.gif"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;去年9月，我们发布了YouTube-8M数据集，该数据集涵盖上千万个代表标记的视频，包括数千个类型，为了促进大规模视频理解的创新和进步。最近，Google的其他团队发布了数据集，比如 Open Images和YouTube-BoundingBoxes 用于加速图像和视频的理解。为了实现这些目标，今天，我们发布了YouTube-8M数据集的更新，并与Google Cloud Machine Learning 和 kaggle.com 合作，组织了一个视频理解比赛，这也是CVPR'17的一个研讨会内容。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;section class="tn-Powered-by-XIUMI" style="white-space: normal; border-width: 0px; border-style: initial; border-color: initial; clear: both; box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="padding: 8px; border-left: 6px solid rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; font-weight: bold; text-decoration: inherit; color: rgb(10, 10, 10); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); box-sizing: border-box;"&gt;&lt;section&gt;更新的YouTube-8M，首次纳入预计算音频特征&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;全新改进的 YouTube-8M 包括更干净和更详细的标签（平均每个视频的标签数量的两倍），清理过的视频集，以及包括预先计算的音频功能，&lt;span style="font-size: 14px; color: rgb(123, 12, 0);"&gt;&lt;strong&gt;基于除了先前发布的视觉特征之外，还首次将与计算的音频特征（pre-computed audio features）包括了进来，&lt;/strong&gt;&lt;/span&gt;这些特征是基于最先进的音频建模架构。音频和视觉特征在时间上以1秒的时间粒度同步，这使得YouTube-8M成为大规模多模态数据集，并为联合视听（时间）建模（joint audio-visual (temporal) modeling）的新研究打开了机会。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;新版本的主要统计信息如下所示。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487305549leDy0Y.jpg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 12px; color: rgb(136, 136, 136);"&gt;更新后的YouTube-8M数据集的tree-map可视化，分为24个高级垂直类别，包括前200个最常见的实体，以及每个类别的前5个实体。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487305549TLa6yw.jpg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 12px; color: rgb(136, 136, 136);"&gt;YouTube-8M数据集中前18个高级类别里的视频示例。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;section class="tn-Powered-by-XIUMI" style="white-space: normal; border-width: 0px; border-style: initial; border-color: initial; clear: both; box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="padding: 8px; border-left: 6px solid rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; font-weight: bold; text-decoration: inherit; color: rgb(10, 10, 10); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); box-sizing: border-box;"&gt;&lt;section&gt;Google Cloud和YouTube-8M视频理解挑战&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;与Google Cloud和kaggle.com合作，我们还举办了Google Cloud和YouTube-8M视频理解挑战。&lt;span style="font-size: 14px; color: rgb(123, 12, 0);"&gt;&lt;strong&gt;挑战邀请参与者使用YouTube-8M作为训练数据，构建视听内容分类模型，然后标记大约700K的测试视频&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="font-size: 14px;"&gt;（&lt;/span&gt;&lt;span style="font-size: 14px;"&gt;用做测试的视频是系统没有见过的）。这是一个由Google Cloud赞助的Kaggle比赛，表现最佳的玩家将获得10万美元奖金。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Google Cloud还提供“credit”，方便参与者选择使用Google Cloud Machine Learning进行模型培训和探索。开源TensorFlow代码为YouTube-8M实现了一些基线分类模型和培训和评估脚本，这些都可以在Github上找到。有关开始本地或基于云的培训的详细信息，请参阅我们的README和Kaggle入门指南。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;section class="tn-Powered-by-XIUMI" style="white-space: normal; border-width: 0px; border-style: initial; border-color: initial; clear: both; box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="padding: 8px; border-left: 6px solid rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; font-weight: bold; text-decoration: inherit; color: rgb(10, 10, 10); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); box-sizing: border-box;"&gt;&lt;section&gt;CVPR 2017 研讨会介绍&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;我们将在2017年7月26日举行的第一届YouTube-8M研讨会上，在CVPR 2017会议上宣布挑战的结果。研讨会还将邀请挑战赛第一名做演示报告。欢迎提交基于YouTube-8M数据集的新颖研究、实验或应用的论文。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;我们希望这个大规模、多样化的数据集能够推广到许多视频域（YouTube-8M捕获超过20个不同的视频域）。我们相信这一挑战赛也可以加速视频理解研究发展和创新。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 12px;"&gt;编译原文：https://research.googleblog.com/2017/02/an-updated-youtube-8m-video.html&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;hr&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487305549WPeaBA.jpg"/&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;strong style="color: rgb(123, 12, 0); font-size: 18px;"&gt;【寻找AI独角兽】新智元联手10大资本&lt;/strong&gt;&lt;br&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;strong style="color: rgb(123, 12, 0); font-size: 18px;"&gt;启动2017创业大赛&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;AI 创业大赛由新智元与10 家主流 AI 创投机构：蓝驰创投、红杉资本中国基金、高瓴智成人工智能基金、蓝湖资本、蓝象资本、IDG资本、高榕资本、中信建投证券、明势资本、松禾远望基金携手发起，由新智元主办，北京市中关村科技园区管理委员会、中关村科技园区海淀园管理委员会支持，是一场聚合了 AI 技术领袖和投资领袖的盛会。新智元向满怀雄心的未来AI独角兽提供强大的创投资源对接机会，顶级风投 TS 等你来拿。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;strong&gt;http://form.mikecrm.com/gthejw&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;点击文章下方阅读原文，在线填写报名申请报名表。该报名表为参与评选必填资料。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p class="p11" style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;如有更多介绍资料（例如BP等），可发送至&amp;nbsp;&lt;span style="color: rgb(123, 12, 0);"&gt;xzy100@aiera.com.cn&lt;/span&gt;，邮件标题请注明公司名称。如有任何咨询问题，也欢迎向该邮箱发信联系。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p class="p11" style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;大赛咨询，请添加新智元微信号：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487305549FyXSki.jpg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;/div&gt;</description>
      <pubDate>Fri, 17 Feb 2017 12:03:58 +0800</pubDate>
    </item>
    <item>
      <title>【重磅】TensorFlow 1.0 官方正式发布，重大更新及5大亮点</title>
      <link>http://www.iwgc.cn/link/4723523</link>
      <description>&lt;div class="article-content"&gt;&lt;section style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; font-family: inherit; font-size: 1em; font-weight: inherit; white-space: normal; max-width: 100%; line-height: 28.4444px; border-style: solid none none; border-top-width: 1px; border-top-color: rgb(204, 204, 204); text-decoration: inherit; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-top: -1.2em; max-width: 100%; min-height: 1em; text-align: center; border-width: initial; border-style: none; border-color: initial; line-height: 1.4; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-size: 18px;"&gt;&lt;strong style="font-family: inherit; font-size: 1em; text-decoration: inherit;"&gt;&lt;span style="color: rgb(255, 255, 255); max-width: 100%; line-height: 1.4; font-family: inherit; font-weight: inherit; text-decoration: inherit; background-color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(127, 127, 127); line-height: 22.4px;"&gt;1&amp;nbsp;&lt;/span&gt;新智元编译 &amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;strong style="font-family: inherit; font-size: 1em; text-decoration: inherit;"&gt;&lt;span style="color: rgb(255, 255, 255); max-width: 100%; line-height: 1.4; font-family: inherit; font-weight: inherit; text-decoration: inherit; background-color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/span&gt;&lt;span style="max-width: 100%; line-height: 1.4; font-family: inherit; font-weight: inherit; text-decoration: inherit; background-color: rgb(127, 127, 127); color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/span&gt;&lt;strong style="color: rgb(136, 136, 136); font-size: 12px;"&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;/section&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;来源：Google Develops Blog&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;编译：刘小芹、张易、文强&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong style="font-size: 14px; max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;【&lt;span style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;新智元导读】&lt;/span&gt;&lt;/strong&gt;&lt;span style="font-size: 14px;"&gt;昨天凌晨谷歌正式发布了TensorFlow1.0版，改进了库中的机器学习功能，发布了XLA的实验版本，对Python和Java用户开放，提升了debugging，并且加入和改进了一些高级API，其中包括Keras。一系列新的改进，都会让目前这个最受欢迎的深度学习框架变得更快、更灵活、更实用。&lt;/span&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/14872116106ZojLJ.gif"/&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211610G5uZrp.jpg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;谷歌TensorFlow 开发者大会演讲笔记。来源：Virginia Poltrack (@VPoltrack) | Twitter&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;在发布第一年，TensorFlow 已经帮助研究者、工程师、艺术家、学生以及其他许多人在许多领域取得了进展，从机器翻译到检测皮肤癌早期症状到预防糖尿病致盲。我们很高兴看到人们在超过6000个开源在线存储库项目中使用 TensorFlow。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;今天，作为在山景城举办的首届年度TensorFlow开发者峰会的一部分，我们宣布正式发布 TensorFlow 1.0。它的新特性包括：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;更快：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;TensorFlow 1.0 运行速度之快令人难以置信！XLA 为未来更多的性能改进奠定了基础，而且 tensorflow.org 新提供“tips &amp;amp; tricks”帮助用户微调模型以实现最大速度。我们将很快发布一些常用模型的更新实现，以展示如何充分利用TensorFlow 1.0：包括基于 8 GPU 对 Inception v3 实现7.3倍加速，以及基于 64 GPU 对分布式 Inception v3 训练实现58倍加速！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;更灵活&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;TensorFlow 1.0 还加入了一些高级API，包括 tf.layers，tf.metrics 和 tf.losses 模块。此外，它还包含一个全新的 tf.keras 模块，能够与 Keras 完全兼容，Keras 是另一个流行的高级神经网络库。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;更实用&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;TensorFlow 1.0 还提供稳定的 Python API，这让获取新功能更容易，而且不必担心破坏现有的代码。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;TensorFlow 1.0的其他亮点：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: square;"&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Python APIs已经更多地向Numpy转型。对于此类和其他向后兼容的以支持API稳定发展的更改，请使用我们的迁移指南和转换脚本。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Java和Go的实验API&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;高级API模块tf.layers，tf.metrics和tf.losses - 在纳入skflow和TF Slim之后从tf.contrib.learn中提取&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;发布了面向CPU和GPU的TensorFlow图形的特定领域编译器XLA的实验版本。 XLA正在迅速发展 - 预计在未来的发布中将看到更多的进展。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;生成TensorFlow Debugger（tfdbg），一个用于调试实时TensorFlow程序的命令行界面和API。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;用于对象检测和本地化的新Android demos以及基于摄像头的图片样式化。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;安装改进：添加了Python 3 docker镜像，TensorFlow的pip包现在兼容PyPI。这意味着TensorFlow现在可以简单调用pip install tensorflow来安装。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&amp;nbsp;&lt;/span&gt;&lt;span style="font-size: 14px;"&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;我们很高兴地看到世界各地TensorFlow社区的发展速度。要了解有关TensorFlow 1.0及其使用方式的更多信息，可以在YouTube上观看TensorFlow Developer Summit talks，涵盖从高级API、TensorFlow（移动版）到新XLA编译器的最新更新，以及TensorFlow的令人激动的使用方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;strong style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;开发者大会的视频：https://www.youtube.com/watch?v=4n1AHvDvVvw&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;TensorFlow生态系统持续成长，包括Fold 动态批处理和Embedding Projector等工具以及我们现有工具（如TensorFlow Serving）的更新。 我们非常感谢社区贡献者、教育工作者和将深度学习的最新进展带给每个人的研究人员 。 我们期待在如GitHub issues, Stack Overflow, @TensorFlow, the discuss@tensorflow.org group等群组与未来各论坛上与您的合作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;section class="" style="font-size: 16px; white-space: normal; max-width: 100%; box-sizing: border-box; color: rgb(62, 62, 62); background-color: rgb(255, 255, 255); border-width: 0px; border-style: initial; border-color: initial; clear: both; word-wrap: break-word !important;"&gt;&lt;section class="" style="padding: 8px; max-width: 100%; box-sizing: border-box; border-left: 6px solid rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; font-weight: bold; text-decoration: inherit; color: rgb(10, 10, 10); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;Keras 成为 TensorFlow 默认API&amp;nbsp;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;实际上，在上个月，Keras 的作者、谷歌 AI 研究员 Francois Chollet 就宣布：Keras 将会成为第一个被添加到 TensorFlow 核心中的高级别框架，变成 Tensorflow 的默认 API。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;Keras 是一个高级别的 Python 神经网络框架，能在 TensorFlow 或者 Theano 上运行。此外，能用到 TensorFlow 上的还有一些高级别的 Python 神经网络框架，比如，TF-Slim，虽然它们发展更不完善，也不是 TensorFlow 的核心部分。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;神经网络研究者 Rachel Thomas 在&amp;nbsp;fast.ai 上撰文介绍了这一消息，并写下了他使用TensorFlow 的心得体会：&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;他说，使用 TensorFlow 给我的感觉就是我还不够聪明，但是，在使用 Keras 的时候我会觉得神经网络要比我想象的简单。这是因为，TensorFlow 的 API 过于冗长和混乱，也是因为 Keras 拥有我体验过的最贴心的、最具表达力的 API。对我来说，在刚开始使用TensorFlow 受挫后就来公开批评它有点尴尬，它让人觉得沉重、不自然。当然，其中有我自己的原因。但是，Keras 和 Theano 确实证实了我的想法：tensors 和 神经网络不一定都是那么折磨人的。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;在一次大学作业中，我曾经使用一个硬件描述语言，通过添加和改变 CPU 暂存器中的字节来编码除法（division）。这是一个很有趣的练习，但是我非常确定，我不想用这种方式对神经网络进行编码。使用一个更高级别的语言的好处是显而易见的：更快地编码、更少的bug，以及，更少的痛苦。Keras 的好处还有更多——它更适配神经网络的概念，能促进新的发现。Keras 让我更加擅长神经网络，因为语言抽象与神经网络的概念搭配得更加好。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;使用与我的思维相同的概念语言写程序，能让我把注意力集中在需要解决的难题上，而不是编程语言的伪迹上。因为，当我把更多的精力花在头脑中的思维与编程语言之间的概念转换的时候，我的思考就会变慢。TensorFlow 影响了我的生产力。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;正如 Chollet 所写：“如果你想要长期使用一个更高级别的面向对象的 TF API ，Karas 就是正确的道路。”&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211612SK95xv.jpg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 12px; color: rgb(136, 136, 136);"&gt;Keras 的作者、谷歌 AI 研究员 Francois Chollet 在谷歌TensorFlow 开发者大会上演讲。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;section class="" style="font-size: 16px; white-space: normal; max-width: 100%; box-sizing: border-box; color: rgb(62, 62, 62); background-color: rgb(255, 255, 255); border-width: 0px; border-style: initial; border-color: initial; clear: both; word-wrap: break-word !important;"&gt;&lt;section class="" style="padding: 8px; max-width: 100%; box-sizing: border-box; border-left: 6px solid rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; font-weight: bold; text-decoration: inherit; color: rgb(10, 10, 10); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;TensorFlow 1.0&amp;nbsp;&lt;strong&gt;重大功能及改善&lt;/strong&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="width: 528.188px; white-space: normal;"&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;XLA（实验版）：初始版本的XLA，针对TensorFlow图（graph）的专用编译器，面向CPU和GPU。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;TensorFlow Debugger（tfdbg）：命令行界面和API。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;添加了新的python 3 docker图像。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;使pip包兼容pypi。TensorFlow现在可以通过&amp;nbsp;pip install tensorflow&amp;nbsp;命令安装。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;更改了几个python API的调用方式，使其更类似 NumPy。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;新的（实验版）Java API。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Android：全新人物检测+跟踪演示实现——“Scalable Object Detection using DNN”（带有额外的YOLO对象检测器支持）。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Android：全新基于摄像头的图像风格转换演示，使用了神经网络艺术风格转换技术。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="white-space: normal;"&gt;&lt;span class="s1"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;section class="" style="font-size: 16px; white-space: normal; max-width: 100%; box-sizing: border-box; color: rgb(62, 62, 62); background-color: rgb(255, 255, 255); border-width: 0px; border-style: initial; border-color: initial; clear: both; word-wrap: break-word !important;"&gt;&lt;section class="" style="padding: 8px; max-width: 100%; box-sizing: border-box; border-left: 6px solid rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; font-weight: bold; text-decoration: inherit; color: rgb(10, 10, 10); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); word-wrap: break-word !important;"&gt;&lt;section&gt;&amp;nbsp;重大 API 变动&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;为了帮助你升级现有的TensorFlow Python代码匹配以下 API 更改，我们准备了一个转换脚本:&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;此工具让你升级现有的TensorFlow Python脚本。此脚本可以在单个Python文件上运行：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 12px;"&gt;tf_upgrade.py --infile foo.py --outfile foo-upgraded.py&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;如果无法修复，系统会打印一个错误列表。你还可以在目录树上运行它：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 12px;"&gt;tf_upgrade.py --intree coolcode -outtree coolcode-upgraded&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;在上述任一情况下，系统会将转储一份报告，详细记录变化情况：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 12px;"&gt;third_party/tensorflow/tools/compatibility/test_file_v0.11.py Line 125&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 12px;"&gt;Renamed keyword argument from `dim` to `axis`&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 12px;"&gt;Renamed keyword argument from `squeeze_dims` to `axis`&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 12px;"&gt;&amp;nbsp; &amp;nbsp; Old: &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; [[1, 2, 3]], dim=1), squeeze_dims=[1]).eval(),&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 12px;"&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; ~~~~ &amp;nbsp; &amp;nbsp;~~~~~~~~~~~~~&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 12px;"&gt;&amp;nbsp; &amp;nbsp; New: &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; [[1, 2, 3]], axis=1), axis=[1]).eval(),&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 12px;"&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; ~~~~~ &amp;nbsp; &amp;nbsp;~~~~~&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="width: 528.188px; white-space: normal;"&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;TensorFlow / models已经被移动到一个单独的github库。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;除法和模运算符（/，//，％）现在匹配 Python（flooring）语义。这也适用于 [tf.div] 和 [tf.mod]。要获取基于强制整数截断的行为，可以使用 [tf.truncatediv] 和 [tf.truncatemod]。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;现在推荐使用 [tf.divide()] 作为除法函数。[tf.div()] 将保留，但它的语义不会回应 Python 3 或 [from future] 机制。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;tf.reverse() 现在取轴的索引要反转。例如 [tf.reverse（a，[True，False，True]）] 现在必须写为 [tf.reverse（a，[0，2]）]。 [tf.reverse_v2（）] 将保持到 TensorFlow 1.0 最终版。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;[tf.mul，tf.sub ] 和 [tf.neg] 不再使用，改为 [tf.multiply]，[tf.subtract] 和 [tf.negative]。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;[tf.pack] 和 [tf.unpack] 弃用，改为 [tf.stack] 和 [tf.unstack]。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;[TensorArray.pack] 和 [TensorArray.unpack] 在弃用过程中，将来计划启用 [TensorArray.stack] 和 [TensorArray.unstack]。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;以下Python函数的参数在引用特定域时，全部改为使用 [axis]。目前仍将保持旧的关键字参数的兼容性，但计划在 1.0 最终版完成前删除。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-indent: 2em;"&gt;&lt;span style="font-size: 12px;"&gt;tf.argmax: dimension 变为 axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-indent: 2em;"&gt;&lt;span style="font-size: 12px;"&gt;tf.argmin: dimension 变为 axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-indent: 2em;"&gt;&lt;span style="font-size: 12px;"&gt;tf.count_nonzero: reduction_indices 变为 axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-indent: 2em;"&gt;&lt;span style="font-size: 12px;"&gt;tf.expand_dims: dim 变为 axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-indent: 2em;"&gt;&lt;span style="font-size: 12px;"&gt;tf.reduce_all: reduction_indices 变为 axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-indent: 2em;"&gt;&lt;span style="font-size: 12px;"&gt;tf.reduce_any: reduction_indices 变为 axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-indent: 2em;"&gt;&lt;span style="font-size: 12px;"&gt;tf.reduce_join: reduction_indices 变为 axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-indent: 2em;"&gt;&lt;span style="font-size: 12px;"&gt;tf.reduce_logsumexp: reduction_indices 变为 axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-indent: 2em;"&gt;&lt;span style="font-size: 12px;"&gt;tf.reduce_max: reduction_indices 变为 axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-indent: 2em;"&gt;&lt;span style="font-size: 12px;"&gt;tf.reduce_mean: reduction_indices 变为 axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-indent: 2em;"&gt;&lt;span style="font-size: 12px;"&gt;tf.reduce_min: reduction_indices 变为 axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-indent: 2em;"&gt;&lt;span style="font-size: 12px;"&gt;tf.reduce_prod: reduction_indices 变为 axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-indent: 2em;"&gt;&lt;span style="font-size: 12px;"&gt;tf.reduce_sum: reduction_indices 变为 axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-indent: 2em;"&gt;&lt;span style="font-size: 12px;"&gt;tf.reverse_sequence: batch_dim 变为 batch_axis, seq_dim 变为 seq_axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-indent: 2em;"&gt;&lt;span style="font-size: 12px;"&gt;tf.sparse_concat: concat_dim 变为 axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-indent: 2em;"&gt;&lt;span style="font-size: 12px;"&gt;tf.sparse_reduce_sum: reduction_axes 变为 axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-indent: 2em;"&gt;&lt;span style="font-size: 12px;"&gt;tf.sparse_reduce_sum_sparse: reduction_axes 变为 axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-indent: 2em;"&gt;&lt;span style="font-size: 12px;"&gt;tf.sparse_split: split_dim 变为 axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;tf.listdiff 已重命名为 tf.setdiff1d 以匹配 NumPy 命名。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;tf.inv 已被重命名为 tf.reciprocal（组件的倒数），以避免与 np.inv 的混淆，后者是矩阵求逆。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;tf.round 现在使用 banker 的舍入（round to even）语义来匹配 NumPy。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;tf.split现在以相反的顺序并使用不同的关键字接受参数。我们现在将NumPy order 匹配为tf.split（value，num_or_size_splits，axis）。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;tf.sparse_split现在采用相反顺序的参数，并使用不同的关键字。我们现在将NumPy order 匹配为tf.sparse_split（sp_input，num_split，axis）。注意：我们暂时要求 tf.sparse_split 需要关键字参数。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;tf.concat现在以相反的顺序并使用不同的关键字接受参数。特别地，我们现在将NumPy order匹配为tf.concat（values，axis，name）。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;默认情况下，tf.image.decode_jpeg使用更快的DCT方法，牺牲一点保真度来提高速度。通过指定属性dct_method ='INTEGER_ACCURATE'，可以恢复到旧版行为。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;tf.complex_abs已从Python界面中删除。 tf.abs支持复杂张量，现在应该使用 tf.abs。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Template.var_scope属性重命名为.variable_scope&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;SyncReplicasOptimizer已删除，SyncReplicasOptimizerV2重命名为SyncReplicasOptimizer。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;tf.zeros_initializer（）和tf.ones_initializer（）现在返回一个必须用initializer参数调用的可调用值，在代码中用tf.zeros_initializer（）替换tf.zeros_initializer。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;SparseTensor.shape已重命名为SparseTensor.dense_shape。与SparseTensorValue.shape相同。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;分别替换tf.scalar_summary，tf.histogram_summary，tf.audio_summary，tf.image_summary与tf.summary.scalar，tf.summary.histogram，tf.summary.audio，tf.summary.image。新的摘要ops以名字而不是标签作为它们的第一个参数，意味着摘要ops现在尊重TensorFlow名称范围。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;使用tf.summary.FileWriter和tf.summary.FileWriterCache替换tf.train.SummaryWriter和tf.train.SummaryWriterCache。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;从公共API中删除RegisterShape。使用C++形状函数注册。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Python API 中的 _ref dtypes 已经弃用。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;在C++ API（in tensorflow/cc）中，Input，Output等已经从tensorflow::ops命名空间移动到tensorflow。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;将{softmax，sparse_softmax，sigmoid} _cross_entropy_with_logits的arg order更改为（labels，predictions），并强制使用已命名的args。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;section class="" style="font-size: 16px; white-space: normal; max-width: 100%; box-sizing: border-box; color: rgb(62, 62, 62); background-color: rgb(255, 255, 255); border-width: 0px; border-style: initial; border-color: initial; clear: both; word-wrap: break-word !important;"&gt;&lt;section class="" style="padding: 8px; max-width: 100%; box-sizing: border-box; border-left: 6px solid rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; font-weight: bold; text-decoration: inherit; color: rgb(10, 10, 10); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&amp;nbsp; Bug 修改及其他变动&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="width: 528.188px; white-space: normal;"&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;大量 C++ API 更新。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;新的 op：parallel_stack。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;为RecordReader/RecordWriter 增加了 tf io 压缩选项常量。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;添加了 sparse_column_with_vocabulary_file，指定将字符串特征转换为ID的特征栏（feature column）。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;添加了index_to_string_table，返回一个将索引映射到字符串的查找表。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;添加string_to_index_table，返回一个将字符串与索引匹配的查找表。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;添加ParallelForWithWorkerId函数。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;添加string_to_index_table，返回一个将字符串与索引匹配的查找表。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;支持从contrib / session_bundle中的v2中的检查点文件恢复会话。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;添加了tf.contrib.image.rotate函数，进行任意大小角度旋转。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;添加了tf.contrib.framework.filter_variables函数，过滤基于正则表达式的变量列表。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;make_template（）可以添加 custom_getter_ param。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;添加了关于如何处理recursive_create_dir现有目录的注释。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;添加了QR因式分解的操作。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Python API中的分割和mod现在使用flooring（Python）语义。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Android：预构建的libs现在每晚构建。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Android： TensorFlow 推理库 cmake/gradle build 现在归在 contrib/android/cmake下面&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Android：更强大的会话初始化（Session initialization）代码。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Android：当调试模式激活时，TF stats现在直接显示在demo和日志中&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Android：全新/更好的 README.md 文档&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;saved_model可用作tf.saved_model。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Empty op 现在是有状态的。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;提高CPU上ASSIGN运算的scatter_update的速度。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;更改reduce_join，使其处理reduction_indices的方式与其他reduce_ops相同。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;将TensorForestEstimator移动到contrib/tensor_forest。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;默认情况下启用编译器优化，并允许在configure中进行配置。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;使指标权重 broadcasting 更加严格。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;添加新的类似队列的StagingArea和新运算 ops：stages 和 unstage。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;hr style="white-space: normal;"&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211613qjID53.jpg"/&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;strong style="color: rgb(123, 12, 0); font-size: 18px;"&gt;【寻找AI独角兽】新智元联手10大资本&lt;/strong&gt;&lt;br&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;strong style="color: rgb(123, 12, 0); font-size: 18px;"&gt;启动2017创业大赛&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;AI 创业大赛由新智元与10 家主流 AI 创投机构：蓝驰创投、红杉资本中国基金、高瓴智成人工智能基金、蓝湖资本、蓝象资本、IDG资本、高榕资本、中信建投证券、明势资本、松禾远望基金携手发起，由新智元主办，北京市中关村科技园区管理委员会、中关村科技园区海淀园管理委员会支持，是一场聚合了 AI 技术领袖和投资领袖的盛会。新智元向满怀雄心的未来AI独角兽提供强大的创投资源对接机会，顶级风投 TS 等你来拿。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;strong&gt;http://form.mikecrm.com/gthejw&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;点击文章下方阅读原文，在线填写报名申请报名表。该报名表为参与评选必填资料。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p class="p11" style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;如有更多介绍资料（例如BP等），可发送至&amp;nbsp;&lt;span style="color: rgb(123, 12, 0);"&gt;xzy100@aiera.com.cn&lt;/span&gt;，邮件标题请注明公司名称。如有任何咨询问题，也欢迎向该邮箱发信联系。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p class="p11" style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;大赛咨询，请添加新智元微信号：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211613JC1Wom.jpg"/&gt;&lt;/p&gt;&lt;/div&gt;</description>
      <pubDate>Thu, 16 Feb 2017 10:16:48 +0800</pubDate>
    </item>
    <item>
      <title>DeepMind 是全球 AI 领域 No. 1？一文看懂巨头实力</title>
      <link>http://www.iwgc.cn/link/4723524</link>
      <description>&lt;div class="article-content"&gt;&lt;section style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; font-family: inherit; font-size: 1em; font-weight: inherit; white-space: normal; max-width: 100%; line-height: 28.4444px; border-style: solid none none; border-top-width: 1px; border-top-color: rgb(204, 204, 204); text-decoration: inherit; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-top: -1.2em; max-width: 100%; min-height: 1em; text-align: center; border-width: initial; border-style: none; border-color: initial; line-height: 1.4; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-size: 18px;"&gt;&lt;strong style="font-family: inherit; font-size: 1em; text-decoration: inherit;"&gt;&lt;span style="color: rgb(255, 255, 255); max-width: 100%; line-height: 1.4; font-family: inherit; font-weight: inherit; text-decoration: inherit; background-color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(127, 127, 127); line-height: 22.4px;"&gt;1&amp;nbsp;&lt;/span&gt;新智元编译 &amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;strong style="font-family: inherit; font-size: 1em; text-decoration: inherit;"&gt;&lt;span style="color: rgb(255, 255, 255); max-width: 100%; line-height: 1.4; font-family: inherit; font-weight: inherit; text-decoration: inherit; background-color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/span&gt;&lt;span style="max-width: 100%; line-height: 1.4; font-family: inherit; font-weight: inherit; text-decoration: inherit; background-color: rgb(127, 127, 127); color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/span&gt;&lt;strong style="color: rgb(136, 136, 136); font-size: 12px;"&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;/section&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;来源：Quora&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;编译：刘小芹&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;【新智元导读】&lt;/span&gt;&lt;/strong&gt;&lt;span style="font-size: 14px;"&gt;Google Brain的Eric Jiang昨天在Quora回答提问，分析了谷歌、&lt;span style="font-size: 14px;"&gt;微软、&lt;/span&gt;Facebook、IBM等巨头间的AI实力，引用最新例子（比如 ICLR论文接收）。结合之前Yann LeCun关于几家公司谁的AI最强的回答，可以对全球 AI 实力分布有一个比较好的理解。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211615e7wrTR.gif"/&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;section class="tn-Powered-by-XIUMI" style="white-space: normal; line-height: 25.6px; border-width: 0px; border-style: initial; border-color: initial; clear: both; box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="padding: 8px; border-left: 6px solid rgb(255, 202, 0); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; text-decoration: inherit; color: rgb(10, 10, 10); box-sizing: border-box;"&gt;&lt;section&gt;&lt;strong&gt;谷歌大脑研究工程师 Eric Jang 的回答：DeepMind 是第一，谷歌大脑很快将升到第一梯队&lt;/strong&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;首先，我需要声明我的回答会有一些偏见，因为我在谷歌大脑工作，而且我很喜欢谷歌大脑。我的观点仅代表我自己，不代表我的其他同事或 Alphabet 公司。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;我对“AI研究领域的佼佼者”的科技公司的排名如下：&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;梯队1. DeepMind&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;我认为就现在来说，DeepMind 是 No.1 的。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;他们发表的论文在研究界里很受推崇，而且涉及的领域非常广，例如深度增强学习，贝叶斯神经网络，机器人学，迁移学习，等等。他们从牛津大学和剑桥大学招揽了大量人才，这两所大学是欧洲最好的 ML 研究学府。他们也有一个多元化的团队专注于通用 AI 的研究，包括有专门打造基础设施和工具的软件工程师，帮助设计研究工具的 UX 设计师，甚至有生态学家（Drew Purves）专门研究其他领域，例如生态和智能之间的关系。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;在 PR 和吸引公众目光方面，Deepmind 也是首屈一指的，例如 DQN-Atari 和创造历史的 AlphaGo 时的 PR。每当 Deepmind 发一篇论文，很快就会出现在 Reddit 机器学习板块和 Hacker News 的顶部，表明他们在技术社区多么受到推崇。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;strong style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;梯队&lt;/span&gt;&lt;/strong&gt;2. Google&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;虽然我把两家 Alphabet 的子公司放在这个排名的顶端，但我得声明 Facebook 和 OpenAI 和 Google 是并列处于第二梯队的。&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;Yann LeCun 此前回答过一个类似问题，但我认为他错估了谷歌大脑在研究界的贡献。他说：&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;但它（谷歌大脑）大部分研究是专注于应用程序和产品开发，而不是长期的 AI 研究。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;完全不是这样！错了！&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;TensorFlow（谷歌大脑团队的主要产品）只是谷歌大脑众多项目中的一个，据我所知也是唯一面向外部的产品。谷歌大脑刚成立时，第一个研究项目确实偏向工程，但今天谷歌大脑团队已经有很多员工，关注 AI 每个子领域的长期的 AI 研究，就类似于 FAIR 和 Deepmind。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;举例说来，FAIR 在 ICLR 2017 会议上有16篇论文被收录，其中3篇被录为 Oral（即非常杰出的论文）。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;谷歌大脑今年在 ICLR 上被收录的论文实际上比 FB 还稍微多一些，有20篇，其中4篇被录为 Oral。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;这还不包括 Deepmind 或谷歌其他团队（搜索团队、VR、Photos团队等）的论文。虽然比较被接收的论文数量不是很好的指标，但我想消除那些暗示谷歌大脑不是深度学习研究的好地方的说法。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;谷歌大脑也是拥有很强协作灵活性的产业研究组织。我想世界上没有其他企业或研究机构同时与伯克利、斯坦福、CMU、OpenAI、Deepmind、Google X 以及谷歌内部的无数产品团队在进行合作。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;我相信在不久的将来，谷歌大脑能够升到第一梯队。我个人有接到谷歌大脑和 Deepmind 的 offer，并选择了前者，因为我觉得谷歌大脑能给我更多灵活性来设计自己的研究项目，并且与谷歌内部的其他团队的合作更紧密，而且我加入了目前还不能公开的一些非常有趣的机器人项目。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;strong style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;梯队&lt;/span&gt;&lt;/strong&gt;2. Facebook&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;FAIR 的论文很强，在我印象中他们重点关注的是语言领域的问题，例如问题回答，动态记忆，图灵测试，等等。偶尔他们也会发一些统计学、物理学和深度学习结合的论文。他们在计算机视觉方面也很强。不过除了他们的声誉非常好之外，我对 FAIR 了解不多。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;由于 TensorFlow 的广泛采用，FAIR 几乎已经输掉了深度学习框架方面的竞争，但 Pytorch 是否能夺回市场份额值得观察。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;strong style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;梯队&lt;/span&gt;&lt;/strong&gt;2. OpenAI&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;OpenAI 的成员阵容很强大：Ilya Sutskever（全面的深度学习牛人），John Schulman（TRPO的发明者，硕士方向是策略梯度），Pieter Abbeel（机器人学），Andrej Karpathy（Char-RNN，CNN），Durk Kingma（VAE 的发明者之一），Ian Goodfellow（GAN 的发明者），等等。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;尽管 OpenAI 是一个只有约50人的小团队，但他们有一个顶尖的工程团队，研发一流的、真正有用的研究工具，例如 Gym 和 Unverse。他们也通过提供以前只有大科技公司能用的软件，为更多研究团体提供帮助。这也为其他公司增加了压力，使得他们开始开源代码和工具。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;我差点想把 OpenAI 列为第一梯队，因为在拥有顶级研究人员方面他们不输 Deepmind，但他们成立不久，尚没有经历足够长的时间来证明这一点。他们也还没有发布与 AlphaGo 相当的成果，虽然我认为 Gym 和 Universe 对研究社区的意义非常重要。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;作为一个所有基础设施都完全从头建起的小型非盈利研究团队，他们没有像大科技公司那么多的 GPU 资源、机器人或软件基础设施。拥有大量算力对研究，甚至对一个人能够想到的点子产生很大影响。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;初创公司很艰难，我们可以观察他们在未来几年是否能够继续吸引顶尖的人才。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;strong style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;梯队&lt;/span&gt;&lt;/strong&gt;3. 百度&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;百度 SVAIL 和百度深度学习研究院是做 AI 研究的很好的地方，他们正在开发许多有前景的技术，如家庭助理，盲人助理，自动驾驶汽车等。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;虽然百度存在很多问题，但他们绝对是中国研究AI最厉害的企业。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;strong style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;梯队&lt;/span&gt;&lt;/strong&gt;3. 微软研究院&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;在深度学习的革命之前，微软研究院曾经是最负盛名的地方。他们的成员中多为多年 AI 研究经验的教授，这可能也解释了为什么他们错过了深度学习（因为深度学习的革命主要是由博士生们驱动的）。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;而且，他们几乎所有的深度学习研究都是在 Linux 平台上进行的，他们的深度学习框架 CNTK 得到的关注不及 TensorFlow，torch，Chainer 等。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;strong style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;梯队&lt;/span&gt;&lt;/strong&gt;5. 苹果&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;苹果在招揽人才方面确实有些艰难，因为研究人员通常都想公开出版自己的研究成果。苹果也做一些产品驱动的研究，但这无法吸引哪些想要解决通用 AI 问题的研究人员，或那些希望自己的研究成果被学术圈关注的研究者。我认为他们的设计根基与研究有很多相似之处，尤其是涉及创造力时，但我也认为发布新产品对长期的基础研究会是一种阻碍。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;strong style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;梯队&lt;/span&gt;&lt;/strong&gt;10. IBM&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;我认识一位 IBM Watson 项目的前成员，他把 IBM 的“认知计算工作”描述为完全是一场灾难。这个项目由管理层推动，但这群人完全不懂机器学习能做什么，不能做什么，只是拿这个热词做卖点。Watson 使用深度学习做图像理解，但是据我所知，它的信息检索系统的其余部分并没有真正用到最新的深度学习技术。基本上，我认为IBM是在瞎搞，对初创企业来说，在二级市场有很多应用机器学习的机会。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;备注&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;说实话，所有上述公司（也许除了IBM之外）都是做深度学习研究的好地方，而且鉴于开源软件和现在整个领域的快速发展，我不认为有任何一家科技公司在“领导 AI 研究“。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;我对深度学习研究者的建议是找到一个你感兴趣的团队/项目，不用管别人对声誉的评价，而且专注于将工作做到最好，让你所在的机构成为AI研究的佼佼者。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;section class="tn-Powered-by-XIUMI" style="white-space: normal; line-height: 25.6px; border-width: 0px; border-style: initial; border-color: initial; clear: both; box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="padding: 8px; border-left: 6px solid rgb(255, 202, 0); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; text-decoration: inherit; color: rgb(10, 10, 10); box-sizing: border-box;"&gt;&lt;section&gt;&lt;strong&gt;如何评价苹果、微软、谷歌和Facebook之间的人工智能实力？&lt;strong style="color: rgb(10, 10, 10); font-size: 18px; white-space: normal;"&gt;LeCun 的回答&lt;/strong&gt;&lt;/strong&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;关于这一点，我的立场让我无法做出公平的回答，但有几点我可以说一下：&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px; color: rgb(123, 12, 0);"&gt;苹果不是人工智能研究圈子里的玩家，因为他们的公司文化很隐秘。&lt;/span&gt;&lt;/strong&gt;&lt;span style="font-size: 14px;"&gt;你不可能在隐秘的氛围下做前沿研究。不发表则算不是研究，顶多也就是技术进步。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;微软&lt;/span&gt;&lt;/strong&gt;&lt;span style="font-size: 14px;"&gt;一直都在做一些很好的工作，但有很多人才都在从微软流向Facebook和谷歌。微软过去做了一些很厉害的语音相关的深度学习研究（2000年左右在手写识别方面取得了很好的成果）。但从他们最近的一些项目可以看出，微软研究院的目标相比FAIR或DeepMind要逊色很多。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;谷歌（具体是Google Brain等研究组）&lt;/span&gt;&lt;/strong&gt;&lt;span style="font-size: 14px;"&gt;无论是在深度学习产品还是服务方面都可以算是领先的，因为谷歌在这方面起步最早。他们在基础设施（比如TensorFlow和TPU）上有很多积累。&lt;span style="font-size: 14px; color: rgb(123, 12, 0);"&gt;&lt;strong&gt;但谷歌 AI 研究的关注点是应用及产品开发，而非长期 AI 研究。证据就是Google Brain 的一些顶尖研究人员离开了那里，去了DeepMind、OpenAI，或者到了FAIR。&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;DeepMind&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;span style="font-size: 14px;"&gt;在基于学习的 AI（learning-based AI）方面一直都做得很好。他们的长期目标跟FAIR的有些类似，研究的课题重合度也挺高：无监督/生成模型，规划（planning）、RL、游戏、记忆增强网络、差分编程（differentiable programming）。DeepMind的一个问题在于，他们从地理位置和组织结构上都远离谷歌（Alphabet）。这样就不太方便为其所有者盈利，不过他们现在看来做得挺好的。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;Facebook&lt;/span&gt;&lt;/strong&gt;&lt;span style="font-size: 14px;"&gt;的人工智能研究所FAIR成立于2.5年前，在这么短的时间内在业界树立起自身领导者的地位。我自己都为FAIR能吸引这么多世界顶尖AI研究员而感到震惊（FAIR有60多个研究员和工程师，现在分布在纽约、Menlo Park、巴黎和西雅图）。同样，我也为我们在过去两年半时间里取得的成果感到震惊。我们的目标远大，在FAIR我们从长期着眼，在公司里也有一定的影响力，因此存在不会受质疑（不出成果）。最关键的，我们非常开放：我们所有的研究员一年都会发表多篇论文。没有什么比看见一位前景大好的研究员加入一家不那么开放的公司或者一家初创企业，然后从研究圈子里消失更令人当头一棒的了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 12px;"&gt;原文链接：https://www.quora.com/Who-is-leading-in-AI-research-among-big-players-like-IBM-Google-Facebook-Apple-and-Microsoft/answer/Eric-Jang?srid=zhKS&lt;/span&gt;&lt;/p&gt;&lt;hr style="white-space: normal;"&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211615d6vqSQ.jpg"/&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;strong style="color: rgb(123, 12, 0); font-size: 18px;"&gt;【寻找AI独角兽】新智元联手10大资本&lt;/strong&gt;&lt;br&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;strong style="color: rgb(123, 12, 0); font-size: 18px;"&gt;启动2017创业大赛&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;AI 创业大赛由新智元与10 家主流 AI 创投机构：蓝驰创投、红杉资本中国基金、高瓴智成人工智能基金、蓝湖资本、蓝象资本、IDG资本、高榕资本、中信建投证券、明势资本、松禾远望基金携手发起，由新智元主办，北京市中关村科技园区管理委员会、中关村科技园区海淀园管理委员会支持，是一场聚合了 AI 技术领袖和投资领袖的盛会。新智元向满怀雄心的未来AI独角兽提供强大的创投资源对接机会，顶级风投 TS 等你来拿。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;strong&gt;http://form.mikecrm.com/gthejw&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;点击文章下方阅读原文，在线填写报名申请报名表。该报名表为参与评选必填资料。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p class="p11" style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;如有更多介绍资料（例如BP等），可发送至&amp;nbsp;&lt;span style="color: rgb(123, 12, 0);"&gt;xzy100@aiera.com.cn&lt;/span&gt;，邮件标题请注明公司名称。如有任何咨询问题，也欢迎向该邮箱发信联系。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p class="p11" style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;大赛咨询，请添加新智元微信号：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211616GyYTlj.jpg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;/div&gt;</description>
      <pubDate>Thu, 16 Feb 2017 10:16:48 +0800</pubDate>
    </item>
    <item>
      <title>微软郑宇再谈“上海踩踏事件”，用时空残差网络解决公共安全问题</title>
      <link>http://www.iwgc.cn/link/4723525</link>
      <description>&lt;div class="article-content"&gt;&lt;section style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; font-family: inherit; font-size: 1em; font-weight: inherit; white-space: normal; max-width: 100%; line-height: 28.4444px; border-style: solid none none; border-top-width: 1px; border-top-color: rgb(204, 204, 204); text-decoration: inherit; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-top: -1.2em; max-width: 100%; min-height: 1em; text-align: center; border-width: initial; border-style: none; border-color: initial; line-height: 1.4; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-size: 18px;"&gt;&lt;strong style="font-family: inherit; font-size: 1em; text-decoration: inherit;"&gt;&lt;span style="color: rgb(255, 255, 255); max-width: 100%; line-height: 1.4; font-family: inherit; font-weight: inherit; text-decoration: inherit; background-color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(127, 127, 127); line-height: 22.4px;"&gt;1&amp;nbsp;&lt;/span&gt;新智元报道 &amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;strong style="font-family: inherit; font-size: 1em; text-decoration: inherit;"&gt;&lt;span style="color: rgb(255, 255, 255); max-width: 100%; line-height: 1.4; font-family: inherit; font-weight: inherit; text-decoration: inherit; background-color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/span&gt;&lt;span style="max-width: 100%; line-height: 1.4; font-family: inherit; font-weight: inherit; text-decoration: inherit; background-color: rgb(127, 127, 127); color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/span&gt;&lt;strong style="color: rgb(136, 136, 136); font-size: 12px;"&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;/section&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;作者：零夏&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: left;"&gt;&lt;strong style="font-size: 14px; max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: left;"&gt;&lt;strong style="font-size: 14px; max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;【新智元导读&lt;/span&gt;】&lt;/strong&gt;&lt;span style="font-size: 14px;"&gt;近日微软亚洲研究院主管研究员郑宇发在 AAAI 2017 发布了其团队用深度时空残差网络预测城市人流量的论文。他在微博上称这是兑现了“上海踩踏事件”后的承诺。本文结合郑宇演讲和论文，介绍该项目训练数据获取及整合、如何融合外部因素和时间空间相关性、为什么选择深度残差网络等方面，并且讨论该技术在实际应用中的成本，以及深度学习对其它社会公共问题的解决方案。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: left;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211617unMH97.gif"/&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;【人物简介】&lt;/span&gt;&lt;/strong&gt;&lt;span style="font-size: 14px;"&gt;郑宇 (博士、教授、博导)，微软亚洲研究院主管研究员、美国计算机学会杰出科学家(ACM Distinguished Scientist)、上海交通大学讲座教授（Chair Professor）、香港科技大学和香港理工大学客座教授。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/14872116175XmiKI.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;span style="font-size: 12px; color: rgb(136, 136, 136);"&gt;郑宇&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: left;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;郑宇团队一直从事城市计算的相关研究，之前他们利用机器学习对雾霾进行预测。&lt;strong&gt;&lt;span style="font-size: 14px; color: rgb(171, 25, 66);"&gt;这篇关于城市人流量预测的AAAI论文也是首次（在国际知名学术会议上）公开发表的把深度学习用于城市大数据的研究成果，并开启了深度学习在时空数据中的探索之路（以往的深度学习的研究通常集中在视频、图像和文本数据上）。&lt;/span&gt;&lt;/strong&gt;新智元于2月9日参加郑宇对论文的分享，并且对郑宇进行了访谈。本文将结合郑宇演讲和论文，从训练数据获取及整合、如何融合外部因素和时间空间相关性、为什么选择深度残差网络等方面进行讲解，并且讨论该技术在实际应用中的问题，以及深度学习对其它社会公共问题的解决方案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/14872116184XmhJH.jpg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;section class="tn-Powered-by-XIUMI" style="white-space: normal; border-width: 0px; border-style: initial; border-color: initial; clear: both; box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="padding: 8px; border-left: 6px solid rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; font-weight: bold; text-decoration: inherit; color: rgb(10, 10, 10); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="box-sizing: border-box;"&gt;&lt;span style=""&gt;起因——上海外滩踩踏事件&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;2014到2015的跨年之夜，在上海外滩发生的一起踩踏事故，事故造成多人伤亡。事故发生前外滩地区人流量超过100万人、超出该地区人流容量上限（30万人）达2倍多。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/14872116181UjeGE.jpg"/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;悲剧发生后，郑宇在微博上表示：“上海的踩踏悲剧完全可以通过基于手机数据的城市异常检测来避免。当发现人流过于聚集并且移动滞留，就可以提前预警和疏散... 是时候加快城市计算的产业化了。”&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;他认为，如果我们能够在提前几个小时就知道外滩会有多少人进去，多少人出来，如果我们知道，进去的人远远大于出来的人，而且知道这个地方的存在容量不足以支撑这么多人停留的时候，&lt;strong&gt;我们就应该提前做管控，发布一些疏导信息，&lt;/strong&gt;甚至提前倡导不要进入该区域。因为这么多人一旦聚集在一个地方，上百万人，仅靠一两百个警察或管理人员来维护秩序是很难做到的，那个时候就为时太晚了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit&gt;&lt;br&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;所以当时郑宇就有了这个想法。他说，这次也算兑现了自己的承诺。当时在说这个的时候，有很多人不太理解，因为他们对技术背景可能并不是那么熟悉，觉得这是不可能做到的。但现在我们真的把它做出来了，还结合一些实际的案例，证明这个技术是可行的，其实可以推广到很多城市，对我们的城市公共安全和交通等管理都有很大的价值和帮助。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;section class="tn-Powered-by-XIUMI" style="white-space: normal; border-width: 0px; border-style: initial; border-color: initial; clear: both; box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="padding: 8px; border-left: 6px solid rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; font-weight: bold; text-decoration: inherit; color: rgb(10, 10, 10); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="box-sizing: border-box;"&gt;&lt;span style=""&gt;时空深度残差网络预测城市人流量技术解读&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span class="author-2682522 font-size-3" style="font-size: 11pt;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span class="author-2682522 font-size-3" style="font-size: 11pt;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;郑宇表示，传统的预测人流量是从个人出发，把每个人的运动轨迹预测来，然后再按区域对进出的人流进行整合，从而得到各个区域的人流量。这不仅涉及到个人的隐私问题，而且准确性也很低（要准确预测每个人的活动是一件非常困难事情）。也有通过基于物理学模型、交通动力学模型之类的经典模型的方法，但这些方法难以应对大范围（整个城市范围）、高密度(上千万人口）和细粒度时空范围（每平方公里、每小时）的集成、同时预测（即不是每个区域单独预测，而是所有区域同时预测，因为各个区域的人流量有关联性）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;而他们这次研究是第一次将深度残差网络用于时空数据，提出了时空深度残差网络模型（ST-ResNet），把整个城市，比如说北京地区，划成很多个网格，多个网格进行同时分析，所以它是一种整体性的预测。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span class="author-2682522 font-size-3" style="font-size: 11pt;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span class="author-2682522 font-size-3" style="font-size: 11pt;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-weight: 700; font-size: 16px;"&gt;城市人流量预测三大挑战&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span class="author-2682522 font-size-3" style="font-size: 11pt;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;郑宇提到城市人流量预测三大挑战：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;1.影响到人流量的因素非常之多，与区域里面前一个小时，有多少人进和出有关系，与周边区域有多少人进和出也有关系，甚至很远的地方，有多少人进和出对这个地方的人流量也会有影响。一旦一个大型事件发生的时候，很多人会从很远的地方坐地铁，或者通过高速公路前往，并不直接经过该周边区域，就直接达到，所以一个地方的人流量不光只是取决于周边有多少人。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;2. 外部的影响因素多：天气、事件；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;3. 时间、空间属性导致其他的深度学习方法如 CNN、RNN、LSTM 在这里无效。空间特点：距离和层次；时间特点：相近的时间人流量是平滑的，但还要看它的周期性和趋势。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span class="author-2682522 font-size-3" style="font-size: 11pt;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211618IB0Vnl.jpg"/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit style="display: block;"&gt;&lt;span style="font-weight: 700; font-size: 16px;"&gt;训练数据的获取和整合&lt;/span&gt;&lt;/inherit&gt;&lt;inherit style="display: block;"&gt;&lt;span style="font-weight: 700; font-size: 16px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;该论文中所用的数据来自北京近几年的出租车数据和纽约的自信车租赁信息。新智元请郑宇介绍数据经验，包括如何拿到这些数据并且如何把这些数据变成可以训练、可以评测的数据。郑宇表示，BikeNYC 是公开数据，北京和贵阳的数据是跟政府进行合作获得。数据大小是TB级。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;数据其实是一个很重要很关键的问题，特别是现实中我们面临多元异构异源的融合问题，可用的方法包括拼接技术、通过语义等方法融合。在郑宇另外一篇发在 IEEE Transaction on BigData 创刊的文章 “Methodologies for cross-domain data fusion: AnOverview”主要就是讲数据的整合。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span class="author-2682522 font-size-3" style="font-size: 11pt;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211619d5uqRQ.jpg"/&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span class="author-2682522 font-size-3" style="font-size: 11pt;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;郑宇团队在贵阳市做了一个真实的系统，这个系统现在正在实实在在的运转中。大家看到系统现在每分每秒都在不停的进来数据，然后系统也在不停的去预测。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;在这个项目中城市被划分成1km*1km的格子。然后人流量数据也好，或者是出租车轨迹也好，把它投射在这个网格里面，生成一些简单的热度图。比如说红的网格就说明这地方人越多。然后系统会同时有对应的事件和天气信息，这些内容相结合就构成了现在的一个数据输入。把以前的时空数据转换成这样一个模式，生成很多帧，这样就是一个序列了。然后去预测，每个格子里面未来会有多少出租车的进和出。如果可以给系统人流量的数据，系统就能预测对应这个数据的人流量。比如通过手机信号，系统就可以预测，比如有多少人进出地铁的刷卡记录，系统就能预测地铁站有多少人进和出。&lt;strong&gt;这个模型是通用的，使用时只需要在数据上面去验证这个模型的准确性和有效性。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px; font-weight: 700;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span class="author-2682522 b" style="font-weight: 700;"&gt;把时间和空间特点融合进训练过程&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span class="author-2682522 b" style="font-weight: 700;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;有了这些数据之后是不是直接用深度学习就可以了呢？答案是否定的。那怎么来做呢？郑宇说，首先把最近几个小时的数据，比如说最近这几帧的数据输入到一个深度残差网络里面，我们叫时空残差网络里面来模拟。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit style="display: block;"&gt;&lt;br&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;首先，模拟相邻时刻，对应最近的这段，它应该是一个平滑的过程，比如晚上六点跟七点流量变化不会很大。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit style="display: block;"&gt;&lt;br&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;第二，把对应时间点昨天这个时刻，比如说昨天的两点钟，前天两点钟以及再往前面同一时刻的这个数据，作为输入来模拟周期性。把前面这几个对应时间点的数据拿来作为参考，就相当于把周期属性考虑进来了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit style="display: block;"&gt;&lt;br&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 11pt;"&gt;第三&lt;/span&gt;&lt;span style="font-size: 14px;"&gt;，把更远时间点相同时间点（比如上个月、以及上上个月礼拜三下午2点钟）的数据拿进来，然后模拟趋势性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;所以这边分别是模拟刚才说的那3个时间属性，平滑性、周期性以及趋势性，这3个残差网络结构都是一样的，都是深度残差网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span class="author-2682522 font-size-3" style="font-size: 11pt;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/14872116195XniKI.jpg"/&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span class="author-2682522 font-size-3" style="font-size: 11pt;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;这3个结果出来之后，系统会做一个融合。第一部分融合，就是只考虑它的时间空间属性。再把外部因素拿过来做2次融合得到一个结果。因为外部因素，比如世界的天气情况，可能也是整个全局的、广域的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit style="display: block;"&gt;&lt;br&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;刚刚是讲怎么模拟时间3个特性，那空间特性怎么模拟的呢？就看着里面的一个结构，它抓的正是空间属性。我们就进去看看这个深度残差网络到底是怎么个结构。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span class="author-2682522 font-size-3" style="font-size: 11pt;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span class="author-2682522 font-size-3" style="font-size: 11pt;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211619zrQMdc.jpg"/&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;我们都知道深度卷积神经网络，是这样一个过程，它把一些区域划成格子之后，把相关的区域做一个卷积运算再合并到一个值。你可以认为，通过卷积之后，我们把周围地区的这种人流量的相关性给抓住了，卷积多次之后，相当于把很远地方的属性都卷积到一起了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span class="author-2682522 b" style="font-weight: 700;"&gt;为什么要用深度残差网络？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;如果你想捕捉很远的地方跟你这个地方的相关性的话，网络层次就必须比较深。如果只有一层的话，你根本抓不到很远的地方的相关性。可一旦网络层次比较深，我们的训练会变得非常复杂、非常困难。&lt;strong&gt;为了保证训练效果，提高训练精度，我们引入了深度残差网络，来做这个事情&lt;/strong&gt;&lt;strong&gt;。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;span style="font-size: 14px; font-weight: 700;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 11pt;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;这就是为什么我们要用残差网络来解决这个问题。&lt;strong&gt;为了能够捕捉距离不同的区域之间的人流量的空间相关性，我们需要很深的卷积神经网络，但是一旦卷积神经网络很深，训练效果就变得很差，所以另一方面需要借助深度残差网络这个结构来使训练效果变得更好。&lt;/strong&gt;这部分其实是抓住了空间的属性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit style="display: block;"&gt;&lt;br&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 11pt;"&gt;&lt;/span&gt;&lt;span style="font-size: 14px;"&gt;而前面刚刚说的这个结构就是时间，这3个是时间的平滑性、周期性和趋势性，而每一个内部就抓住了空间的特性，就是在相邻的此刻，他们的是空间怎么样的，在周期上，空间是怎么样的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;因为有了之前对时空数据深刻的理解，我们才能设计出这样一个网络结构来，这网络结构的优势是什么呢？为什么不直接用深度神经网络，为什么不用RNN的网络？LSTM为什么不能直接用呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;郑宇说，直接用传统的RNN和LSTM，如果你希望数据里面包含周期性和趋势性，那你输入的数据就必须很长，如果你只用了最近两个小时的数据进行输入，你不可能从里面体现周期性，也不可能体现趋势性。但如果你把过去3个月的数据做了RNN输入的话，这个模型就会变得非常大，非常复杂，最后是很难训练的，效果也很不好。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit style="display: block;"&gt;&lt;br&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 11pt;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;在我们的模型里，我们根据先验知识，只需要抽取一些关键帧，比如说昨天同一时刻，前天同一时刻，其他时间可以不做输入。这样的话，大概只要用几十帧的关键帧，就可以体现出我们几个月里面所包含的周期性和趋势性，使得我们的网络结构大大简化，训练的质量和效果也大大提高，这就是很关键的一个地方。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;新智元记者问道，&lt;/span&gt;&lt;span style="font-size: 11pt;"&gt;这次的神经网络做到多少层呢？郑宇表示&lt;/span&gt;&lt;span style="font-size: 14px;"&gt;，这个项目采用了不同的参数做实验，现在得到最好的结果是24层。具体多少层效果最好，跟不同的应用和数据规模都有关系。&lt;strong&gt;对于不同的问题，最好效果的层次是不一样的。&lt;/strong&gt;如果现在换成上海市的数据训练，可能效果最好的层数又不一样了。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;section class="tn-Powered-by-XIUMI" style="white-space: normal; border-width: 0px; border-style: initial; border-color: initial; clear: both; box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="padding: 8px; border-left: 6px solid rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; font-weight: bold; text-decoration: inherit; color: rgb(10, 10, 10); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="box-sizing: border-box;"&gt;&lt;span style=""&gt;实际应用成本高吗？&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 11pt;"&gt;&lt;span style="font-size: 14px; font-weight: 700;"&gt;新智元&lt;/span&gt;：训练需要多长时间？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px; font-weight: 700;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 11pt;"&gt;&lt;span style="font-size: 14px; font-weight: 700;"&gt;郑宇&lt;/span&gt;：&lt;/span&gt;&lt;span style="font-size: 14px;"&gt;训练时间大概一两天，根据具体问题有所不同，使用的计算资源不同而不同，总体说来不会太慢。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 11pt;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 11pt;"&gt;&lt;span style="font-size: 14px; font-weight: 700;"&gt;新智元&lt;/span&gt;：如果应用的话，需要很多算力嘛，成本是否是这些公共部门可以承担的？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit style="display: block;"&gt;&lt;br&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 11pt;"&gt;&lt;span style="font-size: 14px; font-weight: 700;"&gt;郑宇&lt;/span&gt;：&lt;/span&gt;&lt;span style="font-size: 14px;"&gt;线上运行花的钱不多，但是你要接入在线的数据。成本方面最大的成本是数据接入成本，第二才是离线训练，最后是线上的运行，其实花不了太多钱，几块GPU就搞定了。我相信这是一个可以承担的合理数字。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 11pt;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;span style="font-size: 14px; font-weight: 700;"&gt;新智元&lt;/span&gt;：有没有跟政府合作应用？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit style="display: block;"&gt;&lt;br&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 11pt;"&gt;&lt;span style="font-size: 14px; font-weight: 700;"&gt;郑宇&lt;/span&gt;：&lt;/span&gt;&lt;span style="font-size: 14px;"&gt;目前我们与贵阳政府有合作，贵阳政府的大数据基地目前是唯一可以接入实时数据的，但是因为城市规模以及出租车数量相对一线城市有差异，所以数据量不大。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;section class="tn-Powered-by-XIUMI" style="white-space: normal; border-width: 0px; border-style: initial; border-color: initial; clear: both; box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="padding: 8px; border-left: 6px solid rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; font-weight: bold; text-decoration: inherit; color: rgb(10, 10, 10); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="box-sizing: border-box;"&gt;&lt;span style=""&gt;在雾霾、反恐等其它方面的应用&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;inherit style="display: block;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;strong&gt;新智元&lt;/strong&gt;：您觉得这次的研究成果接下来会在哪些领域得到最快的应用？&lt;/span&gt;&lt;/inherit&gt;&lt;inherit style="display: block;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/inherit&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;strong&gt;郑宇&lt;/strong&gt;：在交通管理和公共安全部门会最先应用。之后地铁调度也可以用到。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;span style="font-size: 11pt; font-weight: 700;"&gt;新智元&lt;/span&gt;：您还做过雾霾的预测，请问这方面用到的技术又是什么？是否也是深度残差网络？雾霾预测有什么新的进展吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;郑宇&lt;/span&gt;&lt;/strong&gt;&lt;span style="font-size: 14px;"&gt;：雾霾跟这个问题不一样，。雾霾以前根本不能用深度学习做，因为数据量不够大。我们中国是2012年才开始对外公布pm2.5浓度，站点也不是很多，且每个小时才公布一次空气质量读数，因此样本不是很多。随着时间越来越久，慢慢的就可以开始引入深度学习的方法来做。即便要用深度学习也得有讲究，要考虑数据的时空属性，以及样本的不充裕。因此，这个网络结构怎么优化，怎么利用时空数据的特性，怎么降低这个层次，同时保证精度，还是有一定难度的。深度学习在时空数据上的探索，绝对不是直接的拿来主义，还有很多问题有待解决和深挖。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;span style="font-size: 11pt; font-weight: 700;"&gt;新智元&lt;/span&gt;：反恐方面，人工智能有些什么样的解决方案？论文提到的技术，在反恐方面有应用前景吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;span class="author-2682522 b font-size-3" style="font-size: 11pt; font-weight: 700;"&gt;郑宇&lt;/span&gt;：反恐也是完全不一样的问题，它属于异常检测，是否能提前知道可能发生的事情，并不是大样本的数据。可以通过机器学习来做。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;hr style="white-space: normal;"&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211619ExWRjh.jpg"/&gt;&lt;strong style="text-align: center; color: rgb(123, 12, 0); font-size: 18px;"&gt;【寻找AI独角兽】新智元联手10大资本&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;strong style="color: rgb(123, 12, 0); font-size: 18px;"&gt;启动2017创业大赛&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;AI 创业大赛由新智元与10 家主流 AI 创投机构：蓝驰创投、红杉资本中国基金、高瓴智成人工智能基金、蓝湖资本、蓝象资本、IDG资本、高榕资本、中信建投证券、明势资本、松禾远望基金携手发起，由新智元主办，北京市中关村科技园区管理委员会、中关村科技园区海淀园管理委员会支持，是一场聚合了 AI 技术领袖和投资领袖的盛会。新智元向满怀雄心的未来AI独角兽提供强大的创投资源对接机会，顶级风投 TS 等你来拿。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;strong&gt;http://form.mikecrm.com/gthejw&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;点击文章下方阅读原文，在线填写报名申请报名表。该报名表为参与评选必填资料。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p class="p11" style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;如有更多介绍资料（例如BP等），可发送至&amp;nbsp;&lt;span style="color: rgb(123, 12, 0);"&gt;xzy100@aiera.com.cn&lt;/span&gt;，邮件标题请注明公司名称。如有任何咨询问题，也欢迎向该邮箱发信联系。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p class="p11" style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;大赛咨询，请添加新智元微信号：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211620UNc7zx.jpg"/&gt;&lt;/p&gt;&lt;/div&gt;</description>
      <pubDate>Thu, 16 Feb 2017 10:16:48 +0800</pubDate>
    </item>
    <item>
      <title>AI 派系争斗如火如荼：概率编程技术能彻底取代神经网络吗？</title>
      <link>http://www.iwgc.cn/link/4723526</link>
      <description>&lt;div class="article-content"&gt;&lt;section style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; font-family: inherit; font-size: 1em; font-weight: inherit; white-space: normal; max-width: 100%; line-height: 28.4444px; border-style: solid none none; border-top-width: 1px; border-top-color: rgb(204, 204, 204); text-decoration: inherit; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-top: -1.2em; max-width: 100%; min-height: 1em; text-align: center; border-width: initial; border-style: none; border-color: initial; line-height: 1.4; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-size: 18px;"&gt;&lt;strong style="font-family: inherit; font-size: 1em; text-decoration: inherit;"&gt;&lt;span style="color: rgb(255, 255, 255); max-width: 100%; line-height: 1.4; font-family: inherit; font-weight: inherit; text-decoration: inherit; background-color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(127, 127, 127); line-height: 22.4px;"&gt;1&amp;nbsp;&lt;/span&gt;新智元报道 &amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;strong style="font-family: inherit; font-size: 1em; text-decoration: inherit;"&gt;&lt;span style="color: rgb(255, 255, 255); max-width: 100%; line-height: 1.4; font-family: inherit; font-weight: inherit; text-decoration: inherit; background-color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/span&gt;&lt;span style="max-width: 100%; line-height: 1.4; font-family: inherit; font-weight: inherit; text-decoration: inherit; background-color: rgb(127, 127, 127); color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/span&gt;&lt;strong style="color: rgb(136, 136, 136); font-size: 12px;"&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;/section&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;作者：张易&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong style="font-size: 14px; max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong style="font-size: 14px; max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;【新智元导读&lt;/span&gt;】&lt;/strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;span style="font-size: 14px;"&gt;Gamalon的CEO和创始人Ben Vigoda近日放出豪言，说他和他的团队所采用的概率编程的技术， 终将在所有的应用中彻底取代神经网络——这有可能吗？&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211621mfEz1Z.gif"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;AI非指一物，它涵盖了数个思想流派。Pedro Domingos在他的专著《终极算法》中，把它们称为AI部落。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;如这位华盛顿大学的计算机学家所说，每个部落都采用了看上去非常不同的技术。比如进化论者，相信他们能够在数码世界中重现自然选择。符号论者则一条规则一条规则地把具体的知识编码到计算机中。&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;眼下，联结主义者吸引了全部眼球。他们培育了深度神经网络和模式识别系统，给Google、Facebook和微软等企业带来了勃勃生机。但不管媒体说什么，其他部落仍然会在AI崛起的进程中起到自己的作用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211622yqPLdb.jpg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;符号学派（symbolists）更多关注哲学、逻辑学和心理学，并将学习视为逆向演绎（inverse of deduction）；联结学派（connectionists）专注物理学和神经科学，并相信大脑的逆向工程；进化学派，正如其名称所示，在遗传学和进化生物学的基础上得出结论。贝叶斯学派（Bayesians）注重统计学和概率推理；类推学派（analogizers）更多是关注心理学和数学优化来推断相似性判断。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;就拿Gamalon的CEO和创始人Ben Vigoda来说，他属于贝叶斯学派，主张通过科学方法构建AI。Vigoda 获得了麻省理工学院统计物理学和机器学习的博士学位。相比于建设自主分析数据并得出结论的神经网络，他和他的团队选择使用概率编程，程序基于他们自己的一些假设，然后用数据不断去修正。他的新兴公司得到了Darpa（Defense Advanced Research Projects Agency）的扶持，今晨浮出水面。&lt;/span&gt;&lt;/p&gt;&lt;p style="max-width: 100%; min-height: 1em; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;br style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="max-width: 100%; min-height: 1em; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211622CvUPhf.gif"/&gt;&lt;br style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/p&gt;&lt;p style="max-width: 100%; min-height: 1em; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-size: 12px; color: rgb(136, 136, 136);"&gt;《福布斯》对Gamalon公司的报道，里面提到使用 Bayesian Program Synthesis，系统能够自行编写代码，用最优的方法解释收集到的数据，相比传统机器学习需要的数据量更少，训练的速度也更快。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Gamalon的技术可以应用于机器翻译，同时公司也在开发企业级文本语义抽取的工具。Vigoda声称他的概率编程能够产出比神经网络学习速度更快的AI，而所需数据却小得多。“你可以慎重选择你教给它的东西，”他说，“也可以编辑你已经教它的东西。”&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;如一些人指出的那样，要想催生真正像人类那样思考的机器，方法是关键。神经网络需要巨量的经过仔细标注的数据，而这并非随时可得。Vigoda甚至放出豪言，说他的技术终将在所有的应用中彻底取代神经网络，“这是再清楚不过的。”他说。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;此前基于概率统计的贝叶斯算法最常见的应用就是反垃圾邮件功能，贝叶斯分类的运作是借着使用标记与垃圾邮件、非垃圾邮件的关连，然后搭配贝叶斯推断来计算一封邮件为垃圾邮件的可能性。如果你使用电子邮件超过10年，应该能感觉到垃圾邮件过滤系统的改进。 贝叶斯学派专注于研究概率推理和用贝叶斯定理解决问题。贝叶斯学派从一个信念开始，他们称之为“先验”（prior）。然后，他们收集一些数据，并基于该数据更新先验；得到的结果他们称之为“后验”（posterior）。然后，他们用更多的数据来处理后验，并使之变成先验。这个过程不断循环往复，知道得到最终的答案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;加州大学洛杉矶分校计算机科学系的 Judea Pearl 是贝叶斯方法的著名研究者之一。微软 Genomics Group 的负责人 David Heckerman 也是著名的贝叶斯方法研究者，他帮助微软在 Outlook 和 Hotmail 邮件系统中开发了不同的数据挖掘工具和垃圾邮件过滤工具。加州大学伯克利分校的 Michael Jordan 也是这一领域的主要研究者。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211622phGC42.jpg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;但就如同深度学习不是人工智能的唯一路径一样，概率编程也不是。高斯法、进化算法、强化学习也是一样。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;有些时候，AI部落之间会恶语相向；有些时候，他们会为了抬高自身技术而压低别人。但现实是，AI将诞生于许多技术的合力。尽管存在着竞争，所有人都是在向同一个目标努力。&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;概率编程让研究者如同程序员编程那样构建机器学习算法。但其技术的真正优势在于处理不确定性的能力。这就允许AI在较少的数据量上进行学习，同时也能帮助研究者理解AI为何会做出某些特定的决策，而如果他们不同意这些决策，也更易于对AI进行调整。所有这些都是真正的AI所不可或缺的，无论是在它和人类对话时还是在无人驾驶中规避一次事故时。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;但神经网络已经在图像和语音识别中证明了自己的价值，他们不必和像概率编程这样的技术竞争。实际上，Google的研发人员正在努力建造融合两者的系统。二者优势互补。哥伦比亚大学计算机学家、Gamalon顾问David Blei曾参加过此类混合模型的研究，他说：“深度神经网络和概率模型是紧密关联的，有许多概率建模就发生在神经网络之中。”&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;最好的AI不可避免地综合了多种技术。比如AlphaGo，Google DeepMind 实验室的突破性系统。它将神经网络、强化学习和其他技术融合到一起。在Blei的眼中，AI的世界不存在部落，而是每个人都在追寻同样的终极算法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;hr&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211623BuTOge.jpg"/&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;strong style="color: rgb(123, 12, 0); font-size: 18px;"&gt;【寻找AI独角兽】新智元联手10大资本&lt;/strong&gt;&lt;br&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;strong style="color: rgb(123, 12, 0); font-size: 18px;"&gt;启动2017创业大赛&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;AI 创业大赛由新智元与10 家主流 AI 创投机构：蓝驰创投、红杉资本中国基金、高瓴智成人工智能基金、蓝湖资本、蓝象资本、IDG资本、高榕资本、中信建投证券、明势资本、松禾远望基金携手发起，由新智元主办，北京市中关村科技园区管理委员会、中关村科技园区海淀园管理委员会支持，是一场聚合了 AI 技术领袖和投资领袖的盛会。新智元向满怀雄心的未来AI独角兽提供强大的创投资源对接机会，顶级风投 TS 等你来拿。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;strong&gt;http://form.mikecrm.com/gthejw&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;点击文章下方阅读原文，在线填写报名申请报名表。该报名表为参与评选必填资料。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p class="p11" style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;如有更多介绍资料（例如BP等），可发送至&amp;nbsp;&lt;span style="color: rgb(123, 12, 0);"&gt;xzy100@aiera.com.cn&lt;/span&gt;，邮件标题请注明公司名称。如有任何咨询问题，也欢迎向该邮箱发信联系。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p class="p11" style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;大赛咨询，请添加新智元微信号：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211623wpOJb9.jpg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;/div&gt;</description>
      <pubDate>Thu, 16 Feb 2017 10:16:48 +0800</pubDate>
    </item>
    <item>
      <title>条条大路通罗马之 LS-GAN：限制 GAN 的无限建模能力</title>
      <link>http://www.iwgc.cn/link/4723527</link>
      <description>&lt;div class="article-content"&gt;&lt;section style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; font-family: inherit; font-size: 1em; font-weight: inherit; white-space: normal; max-width: 100%; line-height: 28.4444px; border-style: solid none none; border-top-width: 1px; border-top-color: rgb(204, 204, 204); text-decoration: inherit; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-top: -1.2em; max-width: 100%; min-height: 1em; text-align: center; border-width: initial; border-style: none; border-color: initial; line-height: 1.4; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-size: 18px;"&gt;&lt;strong style="font-family: inherit; font-size: 1em; text-decoration: inherit;"&gt;&lt;span style="color: rgb(255, 255, 255); max-width: 100%; line-height: 1.4; font-family: inherit; font-weight: inherit; text-decoration: inherit; background-color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(127, 127, 127); line-height: 22.4px;"&gt;1&amp;nbsp;&lt;/span&gt;新智元推荐 &amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;strong style="font-family: inherit; font-size: 1em; text-decoration: inherit;"&gt;&lt;span style="color: rgb(255, 255, 255); max-width: 100%; line-height: 1.4; font-family: inherit; font-weight: inherit; text-decoration: inherit; background-color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/span&gt;&lt;span style="max-width: 100%; line-height: 1.4; font-family: inherit; font-weight: inherit; text-decoration: inherit; background-color: rgb(127, 127, 127); color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/span&gt;&lt;strong style="color: rgb(136, 136, 136); font-size: 12px;"&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;/section&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;来源：知乎 &amp;nbsp;作者授权转载&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;作者： 齐国君&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;【新智元导读】&lt;/span&gt;&lt;/strong&gt;&lt;span style="font-size: 14px;"&gt;近期备受关注的 &amp;nbsp;Wasserstein GAN&amp;nbsp;被推出的同时，还有一种新的GAN——损失敏感GAN（Loss Sensitive GAN）也发布在 arxiv 上，它&amp;nbsp;以“按需分配”建模能力来解决无限建模能力带来的过拟合和无泛化性问题。论文的作者在这里从建模能力、目标函数、梯度消失问题等方面对比这两种 GAN ，并且对梯度消失问题进行了分析，最后对LS-GAN进行了有监督和半监督的推广。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211625WOd9Az.gif"/&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;最近很多关心深度学习最新进展、特别是生成对抗网络的朋友可能注意到了一种新的 GAN — Wasserstein GAN。其实在WGAN 推出的同时，一种新的 LS-GAN (Loss Sensitive GAN，损失敏感GAN)也发表在预印本&amp;nbsp;[1701.06264]&amp;nbsp;Loss-Sensitive Generative Adversarial Networks on Lipschitz Densities 上。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;那这两种 GAN 有没有什么联系呢？作为LS-GAN的作者，笔者就带大家一览WGAN和LS-GAN本质和联系。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;h2 style="white-space: normal;"&gt;&lt;span style="font-size: 18px;"&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;section class="tn-Powered-by-XIUMI" style="white-space: normal; border-width: 0px; border-style: initial; border-color: initial; clear: both; box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="padding: 8px; border-left: 6px solid rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; font-weight: bold; text-decoration: inherit; color: rgb(10, 10, 10); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); box-sizing: border-box;"&gt;&lt;section&gt;GAN前传和“无限的建模能力”&lt;br&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;h2 style="white-space: normal;"&gt;&lt;br&gt;&lt;/h2&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;熟悉经典GAN的读者都知道，GAN是一种通过对输入的随机噪声z（比如高斯分布或者均匀分布），运用一个深度网络函数G(z)，从而希望得到一个新样本，该样本的分布，我们希望能够尽可能和真实数据的分布一致（比如图像、视频等）。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;在证明GAN能够做得拟合真实分布时，Goodfellow做了一个很大胆的假设：用来评估样本真实度的Discriminator网络（下文称D-网络）&lt;strong&gt;具有无限的建模能力&lt;/strong&gt;，也就是说不管真实样本和生成的样本有多复杂，D-网络都能把他们区分开。这个假设呢，也叫做&lt;strong&gt;非参数假设&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;span style="font-size: 14px;"&gt;当然，对于深度网络来说，咱只要不断的加高加深，这还不是小菜一碟吗？深度网络擅长的就是干这个的么。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;但是，正如WGAN的作者所指出的，一旦真实样本和生成样本之间重叠可以忽略不计（这非常可能发生，特别当这两个分布是低维流型的时候），而又由于D-网络具有非常强大的无限区分能力，可以完美地分割这两个无重叠的分布，这时候，经典GAN用来优化其生成网络（下文称G-网络）的目标函数--JS散度-- 就会变成一个常数！&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;我们知道，深度学习算法，基本都是用梯度下降法来优化网络的。一旦优化目标为常数，其梯度就会消失，也就会使得无法对G-网络进行持续的更新，从而这个训练过程就停止了。这个难题一直一来都困扰这GAN的训练，称为&lt;strong&gt;梯度消失问题&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;h2 style="white-space: normal;"&gt;&lt;span style="font-size: 18px;"&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;section class="tn-Powered-by-XIUMI" style="white-space: normal; border-width: 0px; border-style: initial; border-color: initial; clear: both; box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="padding: 8px; border-left: 6px solid rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; font-weight: bold; text-decoration: inherit; color: rgb(10, 10, 10); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); box-sizing: border-box;"&gt;&lt;section&gt;WGAN 来袭&lt;br&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;为解决这个问题，WGAN 提出了取代 JS 散度的 Earth-Mover（EM）来度量真实和生成样本密度之间的距离。该距离的特点就是，即便用具有无限能力的 D-网络完美分割真实样本和生成样本，这个距离也不会退化成常数，仍然可以提供梯度来优化 G-网络。不过 WGAN 的作者给出的是定性的解释，缺少定量分析，这个我们在后面解释 LS-GAN 时会有更多的分析。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;现在，我们把这个 WGAN 的优化目标记下来，下文我们会把它跟本文的主角 LS-GAN 做一番比较。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211625b4toQO.jpg"/&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;这里 f-函数和 g-函数 分别是 WGAN 的批评函数(critics)和对应的 G-网络。批评函数是WGAN里的一个概念，对应 GAN 里的 Discriminator。该数值越高，代表对应的样本真实度越大。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;好了，对 WGAN 就暂时说到这里。总结下，由于假设中的&lt;strong&gt;无限建模能力&lt;/strong&gt;，使得 D-网络可以完美分开真实样本和生成样本，进而 JS 散度为常数；而 WGAN 换 JS 散度为 EM 距离，解决了优化目标的梯度为零的问题。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;不过细心的读者注意到了，WGAN 在上面的优化目标（12）里，有个对 f-函数的限定：它被限定到所谓的 Lipschitz 连续的函数上的。那这个会不会影响到上面对模型无限建模能力的假设呢？&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;其实，这个对f-函数的 Lipschitz 连续假设，就是沟通 LS-GAN 和 WGAN 的关键，因为 LS-GAN 就是为了限制 GAN 的无限建模能力而提出的。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;熟悉机器学习原理的朋友会知道，一提到无限建模能力，第一反应就应该是条件反应式的反感。为什么呢？无限建模能力往往是和过拟合，无泛化性联系在一起的。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;仔细研究Goodfellow对经典GAN的证明后，大家就会发现，之所以有这种无限建模能力假设，一个根本原因就是GAN没有对其建模的对象--真实样本的分布--做任何限定。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;换言之，GAN设定了一个及其有野心的目标：就是希望能够对各种可能的真实分布都适用。结果呢，就是它的优化目标JS散度，在真实和生成样本可分时，变得不连续，才使得WGAN有了上场的机会，用EM距离取而代之。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;所以，某种意义上，无限建模能力正是一切麻烦的来源。LS-GAN就是希望去掉这个麻烦，取而代之以“按需分配”建模能力。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;h2 style="white-space: normal;"&gt;&lt;/h2&gt;&lt;p&gt;&lt;section class="tn-Powered-by-XIUMI" style="white-space: normal; border-width: 0px; border-style: initial; border-color: initial; clear: both; box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="padding: 8px; border-left: 6px solid rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; font-weight: bold; text-decoration: inherit; color: rgb(10, 10, 10); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); box-sizing: border-box;"&gt;&lt;section&gt;LS-GAN和“按需分配”的建模能力&amp;nbsp;&lt;br&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;好，让我们换个思路，直接通过限定的GAN的建模能力，得到一种新的GAN模型。这个就是LS-GAN了。我们先看看LS-GAN的真容&lt;/span&gt;：&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/14872116250TidFD.png"/&gt;&lt;span style="color: rgb(51, 51, 51); font-size: 14px;"&gt;这个是用来学习损失函数的目标函数。我们将通过最小化这个目标来得到一个“损失函数" (&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211625phGC42.png"/&gt;&lt;span style="color: rgb(51, 51, 51); font-size: 14px;"&gt;，下文称之为L-函数)。L-函数在真实样本上越小越好，在生成的样本上越大越好。&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-top: 20px; margin-bottom: 20px; white-space: normal; color: rgb(51, 51, 51);"&gt;&lt;span style="font-size: 14px;"&gt;另外，对应的G-网络，通过最小化下面这个目标实现：&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/14872116262VkfHF.png"/&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;span style="color: rgb(51, 51, 51);"&gt;&lt;br&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;span style="color: rgb(51, 51, 51);"&gt;这里注意到，在公式（6）中，对L-函数的学习目标 S中的第二项，它是以真实样本&lt;/span&gt;&lt;span style="font-weight: 700; color: rgb(51, 51, 51);"&gt;x&lt;/span&gt;&lt;span style="color: rgb(51, 51, 51);"&gt;和生成样本&lt;/span&gt;&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211626h9yuWU.png"/&gt;&lt;span style="color: rgb(51, 51, 51); font-size: 14px;"&gt;的一个度量&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/14872116262UkfHF.png"/&gt;&lt;span style="font-size: 14px;"&gt;&lt;span style="color: rgb(51, 51, 51);"&gt;为各自L-函数的目标间隔，把&lt;/span&gt;&lt;span style="font-weight: 700; color: rgb(51, 51, 51);"&gt;x&lt;/span&gt;&lt;span style="color: rgb(51, 51, 51);"&gt;和&lt;/span&gt;&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211626slKF75.png"/&gt;&lt;span style="color: rgb(51, 51, 51); font-size: 14px;"&gt;分开。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;这有一个很大的好处：如果生成的样本和真实样本已经很接近，我们就不必要求他们的L-函数非得有个固定间隔，因为，这个时候生成的样本已经非常好了，接近或者达到了真实样本水平。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;这样呢，LS-GAN就可以集中力量提高那些距离真实样本还很远，真实度不那么高的样本上了。这样就可以更合理使用LS-GAN的建模能力。在后面我们一旦限定了建模能力后，也不用担心模型的生成能力有损失了。这个我们称为“&lt;strong&gt;按需分配&lt;/strong&gt;”。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211626zsRMec.jpg"/&gt;&lt;/p&gt;&lt;p style="margin-top: 20px; margin-bottom: 20px; white-space: normal; color: rgb(51, 51, 51);"&gt;&lt;span style="font-size: 14px;"&gt;上图就是对LS-GAN这种对建模能力”按需“分配的图示。&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-top: 20px; margin-bottom: 20px; white-space: normal; color: rgb(51, 51, 51);"&gt;&lt;span style="font-size: 14px;"&gt;有了上面的准备，我们先把LS-GAN要建模的样本分布限定在Lipschitz 密度上，即如下的一个假设：&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211627TMb6yw.png"/&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;那么什么是Lipschitz密度了？简而言之，Lipschitz密度就是要求真实的密度分布不能变化的太快。密度的变化随着样本的变化不能无限地大，要有个度。不过这个度可以非常非常地大，只要不是无限大就好。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;好了，这个条件还是很弱地，大部分分布都是满足地。比如，你把一个图像调得稍微亮一些，它看上去仍然应该是真实的图像，在真实图像中的密度在Lipschitz假设下不应该会有突然地、剧烈地变化。不是吗？&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;span style="font-size: 14px;"&gt;然后，有了这个假设，我就能证明LS-GAN，当&lt;strong&gt;把L-函数限定在Lipschitz连续的函数类&lt;/strong&gt;上，它得到地生成样本地分布和真实样本是完全一致！&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211627jLa6xw.jpg"/&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;前面我们说了，经典GAN事实上对它生成的样本密度没有做任何假设，结果就是必须给D-网络引入无限建模能力，正是这种能力，在完美分割真实和生成样本，导致了梯度消失，结果是引出了WGAN。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;现在，我们把LS-GAN限定在Lipschitz密度上，同时限制住L-函数的建模能力到Lipschitz连续的函数类上，从而证明了LS-GAN得到的生成样本密度与真实密度的一致性。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;那LS-GAN和WGAN又有什么关系呢？&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 12px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;细心的朋友可能早注意到了，WGAN在学习f-函数是，也限定了其f-函数必须是Lipschitz连续的。不过WGAN导出这个的原因呢，是因为EM距离不容易直接优化，而用它的共轭函数作为目标代替之。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;也就是说，这个对f-函数的Lipschitz连续性的约束，完全是“技术”上的考虑，没有太多物理意义上的考量。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;而且，WGAN的作者也&lt;strong&gt;没有&lt;/strong&gt;在他们的论文中证明：WGAN得到的生成样本分布，是和真实数据的分布是一致的。不过，这点在我们更新的预印本中给出了明确的证明，如下：&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211627QfEA10.jpg"/&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;strong&gt;&lt;br&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;strong&gt;换言之：我们证明了，WGAN在对f-函数做出Lipschitz连续的约束后，其实也是将生成样本的密度假设为了Lipschiz 密度。这点上，和LS-GAN是一致的！两者都是建立在Lipschitz密度基础上的生成对抗网络。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;好了，让我们把LS-GAN和WGAN对L-函数和f-函数的学习目标放在一起仔细再看一看：&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;span style="font-weight: 700; color: rgb(51, 51, 51);"&gt;LS-GAN&lt;/span&gt;&lt;span style="color: rgb(51, 51, 51);"&gt;：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;span style="color: rgb(51, 51, 51);"&gt;&lt;br&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(51, 51, 51); font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211627kdCyZY.png"/&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;span style="color: rgb(51, 51, 51);"&gt;&lt;/span&gt;&lt;span style="font-weight: 700; color: rgb(51, 51, 51);"&gt;WGAN&lt;/span&gt;&lt;span style="color: rgb(51, 51, 51);"&gt;：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;span style="color: rgb(51, 51, 51);"&gt;&lt;br&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(51, 51, 51); font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211628g9ytVT.png"/&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px; color: rgb(51, 51, 51); font-weight: 700;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px; color: rgb(51, 51, 51); font-weight: 700;"&gt;形式上&lt;/span&gt;&lt;span style="font-size: 14px; color: rgb(51, 51, 51);"&gt;来看，LS-GAN和WGAN也有很大区别。WGAN是通过最大化f-函数在真实样本和生成样本上的期望之差实现学习的，这种意义上，它可以看做是一种使用“一阶统计量"的方法。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px; color: rgb(51, 51, 51);"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;LS-GAN则不同。观察LS-GAN优化目标的第二项，由于&lt;span style="font-weight: 700;"&gt;非线性&lt;/span&gt;&lt;/span&gt;&lt;span style="font-size: 14px;"&gt;的&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211628slK975.png"/&gt;&lt;span style="font-size: 14px; color: rgb(51, 51, 51);"&gt;函数的存在，使得我们无法把L-函数分别与期望结合，像WGAN那样得到一阶统计量。因为如此，才使得LS-GAN与WGAN非常不同。&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-top: 20px; margin-bottom: 20px; white-space: normal; color: rgb(51, 51, 51);"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;LS-GAN可以看成是使用&lt;strong&gt;成对&lt;/strong&gt;的（Pairwise）“真实/生成样本对”上的统计量来学习f-函数。这点迫使真实样本和生成样本必须相互配合，从而更高效的学习LS-GAN。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;如上文所述，这种配合，使得LS-GAN能够按需分配其建模能力：当一个生成样本非常接近某个真实样本时，LS-GAN就不会在过度地最大化他们之间L-函数地差值，从而LS-GAN可以更有效地集中优化那些距离真实样本还非常远地生成样本，提高LS-GAN模型优化和使用地效率。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;section class="tn-Powered-by-XIUMI" style="white-space: normal; border-width: 0px; border-style: initial; border-color: initial; clear: both; box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="padding: 8px; border-left: 6px solid rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; font-weight: bold; text-decoration: inherit; color: rgb(10, 10, 10); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); box-sizing: border-box;"&gt;&lt;section&gt;梯度消失问题&lt;br&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;那LS-GAN是否也能解决经典GAN中的&lt;strong&gt;梯度消失&lt;/strong&gt;问题呢？即当它的L-函数被充分训练后，是否对应的G-网络训练目标仍然可以提供足够的梯度信息呢？&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;我们回顾下，在WGAN里，其作者给出G-网络的训练梯度，并证明了这种梯度在对应的f-函数被充分优化后，仍然存在。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;不过，仅仅梯度存在这点并不能保证WGAN可以提供足够的梯度信息训练 G-网络。为了说明WGAN可以解决梯度消失问题，WGAN的作者宣称：“G-网络的训练目标函数”在对其网络链接权重做限定后， 是&lt;strong&gt;接近或者最多线性&lt;/strong&gt;的。这样就可以避免训练目标函数饱和，从而保证其能够提供充足的梯度训练G-网络。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;span style="font-size: 14px;"&gt;好了，问题的关键时为什么G-网络的训练目标函数是接近或者最多&lt;strong&gt;线性&lt;/strong&gt;的，这点WGAN里并没有给出定量的分析，而只有大致的定性描述，这里我们引用如下：&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;“&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211628jcBwYW.jpg"/&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;”&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;span style="color: rgb(51, 51, 51);"&gt;现在，让我们回到LS-GAN，看看如何给出一直定量的形式化的分析。在LS-GAN里，我们给出了最优的L-函数的一种&lt;/span&gt;&lt;span style="font-weight: 700; color: rgb(51, 51, 51);"&gt;非参数化的解&lt;/span&gt;&lt;span style="color: rgb(51, 51, 51);"&gt;：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;span style="color: rgb(51, 51, 51);"&gt;&lt;br&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211629iazvXV.jpg"/&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;span style="color: rgb(51, 51, 51);"&gt;&lt;br&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;span style="color: rgb(51, 51, 51);"&gt;这个定理比较长，简单的来说，就是所有的最优 L-GAN的解，都是在两个&lt;/span&gt;&lt;span style="font-weight: 700; color: rgb(51, 51, 51);"&gt;分段线性&lt;/span&gt;&lt;span style="color: rgb(51, 51, 51);"&gt;的上界和下界L-函数之间。如下图所示：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;span style="color: rgb(51, 51, 51);"&gt;&lt;br&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211629MF4Zrp.jpg"/&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;红线是上界，绿线是下界。任何解出来最优L-函数，一定在这两个分段线性的上下界之间，包括用一个深度网络解出来L-函数。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;也就是说，LS-GAN解出的结果，只要上下界不饱和，它的得到的L-函数就不会饱和。而这里看到这个L-函数的上下界是分段线性的。这种分段线性的函数几乎处处存在非消失的梯度，这样适当地控制L-函数地学习过程，在这两个上下界之间地最优L-函数也不会出现饱和现象。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;好了，这样我们就给出了WGAN分析梯度消失时候，缺失的哪个定量分析了。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;最后，我们看看LS-GAN合成图像的例子，以及和DCGAN的对比。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;看看在CelebA上的结果：&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211629voNIa8.jpg"/&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;span style="color: rgb(51, 51, 51);"&gt;如果我们把DCGAN和LS-GAN中Batch Normalization 层都去掉，我们可以看到DCGAN模型取崩溃，&lt;/span&gt;&lt;span style="font-weight: 700; color: rgb(51, 51, 51);"&gt;而LS-GAN仍然可以得到非常好的合成效果&lt;/span&gt;&lt;span style="color: rgb(51, 51, 51);"&gt;：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;span style="color: rgb(51, 51, 51);"&gt;&lt;br&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211630JC1Wom.jpg"/&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;不仅如此，LS-GAN在去掉batch normalization后，如上图（b）所示，&lt;strong&gt;也没有看到任何mode collapse现象&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;我们进一步通过实验看看、在LS-GAN中L-函数网络过训练后，模型还能不能提供足够的梯度来训练G-网络。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;下图是L-网络每次都训练，而G-网络每个1次、3次、5次才训练时，对应的用来更新G-网络的梯度大小(在log scale上)：&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/14872116303WlgIG.jpg"/&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;我们可以看到：即便当L-网络相对G-网络多训练若干次后，更新G-网络的梯度仍然充分大，而&lt;strong&gt;没有出现梯度消失&lt;/strong&gt;的问题。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;不仅如此，随着训练的进行，我们可以看到，G-网络的梯度逐渐增大，一直到一个相对比较稳定的水平。相对固定强度的梯度说明了，&lt;strong&gt;G-网络的训练目标函数，最终非常可能是达到一个接近线性的函数&lt;/strong&gt;（这是因为线性函数的梯度是固定的）。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;这个也进一步说明了，&lt;strong&gt;LS-GAN定义的G-网络的训练目标函数没有发生饱和&lt;/strong&gt;，其定义是合理的，也是足以避免梯度消失问题的。&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;h2 style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;section class="tn-Powered-by-XIUMI" style="white-space: normal; border-width: 0px; border-style: initial; border-color: initial; clear: both; box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="padding: 8px; border-left: 6px solid rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; font-weight: bold; text-decoration: inherit; color: rgb(10, 10, 10); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); box-sizing: border-box;"&gt;&lt;section&gt;对LS-GAN进行有监督和半监督的推广&lt;br&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;LS-GAN和GAN一样，本身是一种无监督的学习算法。LS-GAN的另一个突出优点是，通过定义适当的损失函数，它可以非常容易的推广到有监督和半监督的学习问题。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;比如，我们可以定义一个有条件的损失函数&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211630woNJa9.png"/&gt;&lt;span style="font-size: 14px; color: rgb(51, 51, 51);"&gt;，这个条件&lt;/span&gt;&lt;span style="font-size: 14px;"&gt;y&lt;/span&gt;&lt;span style="font-size: 14px; color: rgb(51, 51, 51);"&gt;可以是输入样本&lt;/span&gt;&lt;span style="font-size: 14px;"&gt;x&lt;/span&gt;&lt;span style="font-size: 14px; color: rgb(51, 51, 51);"&gt;的类别。当类别和样本一致的时候，这个损失函数会比类别不一致的时候小。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(51, 51, 51); font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(51, 51, 51); font-size: 14px;"&gt;于是，我们可以得到如下的Conditional LS-GAN (CLS-GAN)&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(51, 51, 51); font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211631JC1Wom.jpg"/&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(51, 51, 51); font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(51, 51, 51); font-size: 14px;"&gt;这样，一旦得到损失函数&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211630woNJa9.png"/&gt;&lt;span style="color: rgb(51, 51, 51); font-size: 14px;"&gt;，在给定一个样本&lt;/span&gt;&lt;span style="color: rgb(51, 51, 51); font-size: 14px; font-weight: 700;"&gt;x&lt;/span&gt;&lt;span style="color: rgb(51, 51, 51); font-size: 14px;"&gt;后，我们可以用最小化损失函数的那个类别来对样本进行分类，即&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(51, 51, 51); font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211631f7wsTS.png"/&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px; color: rgb(51, 51, 51);"&gt;我们可以看看在MNIST, CIFAR-10和SVHN上，针对不同类别给出的合成图像的效果：&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px; color: rgb(51, 51, 51);"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(51, 51, 51); font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211632yrQMKI.jpg"/&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;半监督的训练是需要使用完全标注的训练数据集。当已标注的数据样本比较有限时，会使得训练相应模型比较困难。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;进一步，我们可以把CLS-GAN推广到半监督的情形，即把已标记数据和未标记数据联合起来使用，利用未标记数据提供的相关分布信息来指导数据的分类。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;为此，我们定义一个特别的半监督的损失函数：&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211632TLa6xw.png"/&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px; color: rgb(51, 51, 51);"&gt;对给定样本&lt;/span&gt;&lt;span style="font-size: 14px; color: rgb(51, 51, 51); font-weight: 700;"&gt;x&lt;/span&gt;&lt;span style="font-size: 14px; color: rgb(51, 51, 51);"&gt;，我们不知道它的具体类别，所以我们在所有可能的类别上对损失函数取最小，作为对该样本真实类别的一个&lt;/span&gt;&lt;span style="font-size: 14px; color: rgb(51, 51, 51); font-weight: 700;"&gt;最佳的猜测&lt;/span&gt;&lt;span style="font-size: 14px; color: rgb(51, 51, 51);"&gt;。这与上面的公式（7）是一致的。&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-top: 20px; margin-bottom: 20px; white-space: normal; color: rgb(51, 51, 51);"&gt;&lt;span style="font-size: 14px;"&gt;这样，我们可以相应的推广CLS-GAN，得到如下的训练目标 最优化损失函数&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/14872116324XmhJH.png"/&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;该训练目标可以通过挖掘各个类别中可能的变化，帮助CLS-GAN模型合成某类中的更多的“新”的样本，来丰富训练数据集。这样，即便标注的数据集比较有限，通过那些合成出来已标记数据，也可以有效的训练模型。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;比如，在下面图中，CLS-GAN模型通过对未标记MNIST数据进行分析，可以按类别合成出更多不同书写风格的数字。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211632mfEz1Z.jpg"/&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;这些数字可以增加已标注的训练数据量，进一步提供模型准确度；而更准确的模型可以进一步提供CLS-GAN的合成图像的准确性。通过这种彼此不断的提高，半监督的CLS-GAN在只有很少已标注训练数据下，仍然可以做到准确的分类。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;我们可以看下在SVHN上，当只有1000张已标注训练数据时分类的准确度：&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211633OG51tr.jpg"/&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(51, 51, 51); font-size: 14px;"&gt;下面是在CIFAR-10上，4000张已标记数据下的分类准确度。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(51, 51, 51); font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211633VNc8Ay.jpg"/&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;section class="tn-Powered-by-XIUMI" style="white-space: normal; border-width: 0px; border-style: initial; border-color: initial; clear: both; box-sizing: border-box;"&gt;&lt;section class="tn-Powered-by-XIUMI" style="padding: 8px; border-left: 6px solid rgb(255, 202, 0); font-size: 18px; line-height: 1.4; font-family: inherit; font-weight: bold; text-decoration: inherit; color: rgb(10, 10, 10); border-top-color: rgb(255, 202, 0); border-right-color: rgb(255, 202, 0); border-bottom-color: rgb(255, 202, 0); box-sizing: border-box;"&gt;&lt;section&gt;结论&lt;br&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;那么究竟GAN，WGAN和LS-GAN谁更好呢？&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;持平而论，笔者认为是各有千秋。究竟谁更好，还是要在不同问题上具体分析。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;这三种方法只是提供了一个大体的框架，对于不同的具体研究对象(图像、视频、文本等)、数据类型(连续、离散)、结构（序列、矩阵、张量），应用这些框架，对具体问题可以做出很多不同的新模型。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;当然，在具体实现时，也有非常多的要考虑的细节，这些对不同方法的效果都会起到很大的影响。毕竟，&lt;strong&gt;细节是魔鬼&lt;/strong&gt;！&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;笔者在实现LS-GAN也很多的具体细致的问题要克服。一直到现在，我们还在不断持续的完善相关代码。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;对LS-GAN有兴趣的读者，可以参看我们分享的&lt;/span&gt;&lt;a class=" wrap external" target="_blank" rel="nofollow noreferrer" style="text-decoration: underline; font-size: 14px;"&gt;代码&lt;em class="icon-external"&gt;&lt;/em&gt;&lt;/a&gt;&lt;span style="font-size: 14px;"&gt;，并提出改进的建议。&amp;nbsp;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;对研究GAN感兴趣的读者，也欢迎联系笔者： guojunq@gmail.com，一起探讨相关算法、理论。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;最后，欢迎大家访问我的&lt;/span&gt;&lt;a class=" wrap external" target="_blank" rel="nofollow noreferrer" style="text-decoration: underline; font-size: 14px;"&gt;个人主页&lt;em class="icon-external"&gt;&lt;/em&gt;&lt;/a&gt;&lt;span style="font-size: 14px;"&gt;，我们会分享更多的研究信息&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="font-size: 14px;"&gt;论文链接：https://arxiv.org/abs/1701.06264&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;hr style="white-space: normal;"&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211633YQfbCB.jpg"/&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;strong style="color: rgb(123, 12, 0); font-size: 18px;"&gt;【寻找AI独角兽】新智元联手10大资本&lt;/strong&gt;&lt;br&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;strong style="color: rgb(123, 12, 0); font-size: 18px;"&gt;启动2017创业大赛&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;AI 创业大赛由新智元与10 家主流 AI 创投机构：蓝驰创投、红杉资本中国基金、高瓴智成人工智能基金、蓝湖资本、蓝象资本、IDG资本、高榕资本、中信建投证券、明势资本、松禾远望基金携手发起，由新智元主办，北京市中关村科技园区管理委员会、中关村科技园区海淀园管理委员会支持，是一场聚合了 AI 技术领袖和投资领袖的盛会。新智元向满怀雄心的未来AI独角兽提供强大的创投资源对接机会，顶级风投 TS 等你来拿。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;strong&gt;http://form.mikecrm.com/gthejw&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;点击文章下方阅读原文，在线填写报名申请报名表。该报名表为参与评选必填资料。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p class="p11" style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;如有更多介绍资料（例如BP等），可发送至&amp;nbsp;&lt;span style="color: rgb(123, 12, 0);"&gt;xzy100@aiera.com.cn&lt;/span&gt;，邮件标题请注明公司名称。如有任何咨询问题，也欢迎向该邮箱发信联系。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p class="p11" style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;大赛咨询，请添加新智元微信号：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: center;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487211633wpOJb9.jpg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;/div&gt;</description>
      <pubDate>Thu, 16 Feb 2017 10:16:48 +0800</pubDate>
    </item>
  </channel>
</rss>
