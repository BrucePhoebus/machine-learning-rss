<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>深度 | DeepMind官方年度总结：除了AlphaGo，我们还应该关注什么？</title>
      <link>http://www.iwgc.cn/link/4193468</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自DeepMind&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;作者：Demis Hassabis、Mustafa Suleyman、Shane Legg&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;参与：微胖、曹瑞、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;今日，DeepMind 的 CEO Demis Hassabis 等三人在其官方博客发表文章，总结 DeepMind 过去一年中所取的的研究成果，可谓是硕果累累。非常荣幸的是作为最早关注 DeepMind 研究的媒体之一，机器之心几乎全部报道过这些研究，及时为大家输送了好的人工智能研究成果，读者可点击文中的链接详细了解这些研究。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibc6yDDz4kPttFbcs6G6vQKBJAcOCr07I9NUib7uAlCg2PDZ9hQLlY5MFOyK74qhV5BYhugDdiac6PQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们所处的世界是一个极端复杂、紧急和难以掌控的系统——从气候变迁到意图征服的疾病——我们相信，智能系统将有助于揭开新的、促进社会公共善的科学知识。为此，我们需要一个具有通用目的、能够从零开始不断加深对问题理解的系统，该系统能借助这一能力识别出模式以及否则可能错失的科学突破。这也是 DeepMind 长期研究所关注的焦点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然距离所谓的智能仍路漫漫兮，但是，2016 年，我们仍然在许多核心基础问题上取得了振奋人心的进步，也首次得以见识这些进步可能给真实世界带来的积极影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们的 &lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=402115604&amp;amp;idx=1&amp;amp;sn=f6edd2013badc51fa2a3fd2d751e780d&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=402115604&amp;amp;idx=1&amp;amp;sn=f6edd2013badc51fa2a3fd2d751e780d&amp;amp;scene=21#wechat_redirect"&gt;AlphaGo&lt;/a&gt;——很幸运第二次登上《Nature》封面——在古老的围棋比赛中击败了世界冠军李世乭。许多专家认为，人类提前十年实现了这一壮举。于我们——也包括全世界围棋界——而言，最激动人心的莫过于 AlphaGo 博弈过程中所呈现出来的创造力，有时，它的棋招甚至挑战了古老的围棋智慧。围棋，这一古往今来最富深谋远虑的游戏之一，AlphaGO 可以识别并分享其中洞见，也昭示着人工智能有望为人类带来的价值。另外，我们也期待在新的一年能够玩转更多的游戏。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在生成模型领域，我们也取得了有意义的进步，搭建出能自己想象新构造和场景的程序。发表了有关图像生成的 PixelCNN 论文之后，我们发表了&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719022&amp;amp;idx=1&amp;amp;sn=3eeb1958e695388817dd32b0d228ced9&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719022&amp;amp;idx=1&amp;amp;sn=3eeb1958e695388817dd32b0d228ced9&amp;amp;scene=21#wechat_redirect"&gt; WaveNet&lt;/a&gt; 的研究论文。研究展示了这一程序在生成音频上的有用性，WaveNet 不是将录下的语音样本拼接起来，而是创造出的新的音频波形，可以实现世界上目前最生动的语音合成。我们正计划将这一成果融入谷歌产品中，能够提升百万用户的产品体验，我们对此感到很兴奋。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2016 年，我们的另一重要研究领域是记忆（memory），特别是如何将神经网络的决策智能和有关复杂结构化数据的存储、推理能力结合起来的难题。我们研究了 &lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719745&amp;amp;idx=2&amp;amp;sn=242eda88fa9a5572e60b43e451a1549b&amp;amp;chksm=871b027fb06c8b693cff17f43553625f008fcb7965582119b651dbbd17e116e35dc801ebeec3&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719745&amp;amp;idx=2&amp;amp;sn=242eda88fa9a5572e60b43e451a1549b&amp;amp;chksm=871b027fb06c8b693cff17f43553625f008fcb7965582119b651dbbd17e116e35dc801ebeec3&amp;amp;scene=21#wechat_redirect"&gt;Differentiable Neural Computers&lt;/a&gt;，也因此收获了 18 个月来第三篇发表在《Nature》上的文章。研究展示了能够同时像神经网络一样学习，也能像计算机一样存储数据的模型。这些模型已经能学会回答关于数据结构（从家谱到地铁交通地图）的问题，也让我们距离在复杂数据组中使用人工智能进行科学发现更近了一步。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在推进这些系统所能做的事情边界的同时，我们也投入大量时间提升它们的学习方式。一篇名为《&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720561&amp;amp;idx=1&amp;amp;sn=ef09af7ff21f7b61bed28076c349e6ec&amp;amp;chksm=871b0d4fb06c845965a37c5cdcfd2fae46b38bf42478423564e06021c02d37aeb33e53eea2ef&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720561&amp;amp;idx=1&amp;amp;sn=ef09af7ff21f7b61bed28076c349e6ec&amp;amp;chksm=871b0d4fb06c845965a37c5cdcfd2fae46b38bf42478423564e06021c02d37aeb33e53eea2ef&amp;amp;scene=21#wechat_redirect"&gt;Reinforcement Learning with Unsupervised Auxiliary Tasks&lt;/a&gt;》的论文就描述了将学习某种任务速度提升一个量级的方法，而且考虑到高质量训练环境对智能体的重要性，我们也开源了旗舰研究环境&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721081&amp;amp;idx=2&amp;amp;sn=fb1b2ba31d256c08e3c93e813deabc73&amp;amp;chksm=871b0f47b06c86510e447bd4c366d1d5c78bbffe3b92903eff2e8f5a6b2df67f5c440dc822e9&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721081&amp;amp;idx=2&amp;amp;sn=fb1b2ba31d256c08e3c93e813deabc73&amp;amp;chksm=871b0f47b06c86510e447bd4c366d1d5c78bbffe3b92903eff2e8f5a6b2df67f5c440dc822e9&amp;amp;scene=21#wechat_redirect"&gt; DeepMind Lab&lt;/a&gt;, 我们也正在和暴雪合作，为 &lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720302&amp;amp;idx=3&amp;amp;sn=756e17424570ea713a15b4a5e4a97666&amp;amp;chksm=871b0c50b06c8546c49e53fd9454846ce6928ce45449726af775f11546c6f27c5b40d2c4a700&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720302&amp;amp;idx=3&amp;amp;sn=756e17424570ea713a15b4a5e4a97666&amp;amp;chksm=871b0c50b06c8546c49e53fd9454846ce6928ce45449726af775f11546c6f27c5b40d2c4a700&amp;amp;scene=21#wechat_redirect"&gt;StarCraft II&lt;/a&gt; 研发为人工智能准备的训练环境。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然，这只是冰山一角，你可以通过阅读我们在众多顶级期刊上发表的的论文来了解我们的工作，从 Neuron 到 PNAS，再到一些像是&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715855&amp;amp;idx=1&amp;amp;sn=1668f4717e666850029502015a2d4db8&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715855&amp;amp;idx=1&amp;amp;sn=1668f4717e666850029502015a2d4db8&amp;amp;scene=21#wechat_redirect"&gt; ICLR&lt;/a&gt; 和 &lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721102&amp;amp;idx=2&amp;amp;sn=cbc44a149457d31ed9a8bbe825f09378&amp;amp;chksm=871b0f30b06c8626bb94cbd7a08fd4a5c8bec747082f49280fbd27e9c87c965de983a279796c&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721102&amp;amp;idx=2&amp;amp;sn=cbc44a149457d31ed9a8bbe825f09378&amp;amp;chksm=871b0f30b06c8626bb94cbd7a08fd4a5c8bec747082f49280fbd27e9c87c965de983a279796c&amp;amp;scene=21#wechat_redirect"&gt;NIPS &lt;/a&gt;这样重量级机器学习大会。我们也惊喜地看到社区中的其他成员已经在积极实现这些论文成果或者在此基础之上继续研究——只要看看 2016 年下半年围棋计算机程序的复兴即可！我们也很兴奋见证了人工智能和机器学习走向更为广阔的领域，变得越来越强大。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;同样，我们也非常惊喜地看到我们的工作对现实世界的影响。我们与谷歌数据中心团队合作使用了与 AlphaGo 相类似的科技，以&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717202&amp;amp;idx=3&amp;amp;sn=cbed5925a1c2c7150911c929db084162&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717202&amp;amp;idx=3&amp;amp;sn=cbed5925a1c2c7150911c929db084162&amp;amp;scene=21#wechat_redirect"&gt;研发一种冷却系统用电的新方法&lt;/a&gt;，此次合作将谷歌数据中心的电源使用效率显著提升了 15%。如果将这类技术规模化到另一个大规模产业系统被证实确实可行，那么，就真的有望显著改善全球环境和成本收益。我们正在和不同的谷歌团队合作，将前沿研究应用到全世界都在使用的产品和基础架构中，这只是其中的一个例子。另外，我们正在与两家英国（也是我们的家乡）&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720693&amp;amp;idx=2&amp;amp;sn=7986218c29a01d545205c1e7e33af396&amp;amp;chksm=871b0dcbb06c84dd6cfd7273a9c2f3ba8e4f0473ee70648bc08ffd6b706789e6599b3b70e124&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720693&amp;amp;idx=2&amp;amp;sn=7986218c29a01d545205c1e7e33af396&amp;amp;chksm=871b0dcbb06c84dd6cfd7273a9c2f3ba8e4f0473ee70648bc08ffd6b706789e6599b3b70e124&amp;amp;scene=21#wechat_redirect"&gt;国家医疗服务体系（NHS）&lt;/a&gt;内的医疗集团积极合作，探索如何用我们的技术改善影响着数以百万患者的诊断和治疗条件，我们也通过我们开发的移动应用和基础设施改善临床一线的护理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然，我们对现实世界所带来的影响不仅仅体现在对现实问题的解决上，还体现在算法和模型设计、训练和一般部署方式上。我们非常骄傲地看到，DeepMind已经参与成立&lt;/span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719494&amp;amp;idx=4&amp;amp;sn=0e371842af8ca4c3a17ef0cc3d8241fa&amp;amp;chksm=871b0178b06c886e25583a80815e0baf7193a4e5eb8e5e3007810dffce74c6c7956e6331236e&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719494&amp;amp;idx=4&amp;amp;sn=0e371842af8ca4c3a17ef0cc3d8241fa&amp;amp;chksm=871b0178b06c886e25583a80815e0baf7193a4e5eb8e5e3007810dffce74c6c7956e6331236e&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;AI合作组织（Partnership on AI）&lt;/span&gt;&lt;/a&gt;&lt;span&gt;，这一组织是一个非营利组织，汇聚了顶尖的研究实验室、社会团体、学术组织，旨在在诸如算法的透明性和安全性等领域探索出最好的实践方式。通过培育经验和洞见的多样性，我们也希望能够助力解决其中的一些难题，并找到将社会利益置于全世界人工智能社区核心的方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们仍是一家年轻的公司，处于公司愿景的早期阶段。但如果在 2017 年，我们能进一步在算法突破、社会影响与最佳道德实践三个方面同时做出进展，那我们就处于非常好的状态了，可为科学社区以及整个世界做出持续的、有价值的贡献。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 04 Jan 2017 11:22:02 +0800</pubDate>
    </item>
    <item>
      <title>前沿 | Nature：量子计算机或将在2017年走向实用化</title>
      <link>http://www.iwgc.cn/link/4193469</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Nature&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：蒋思源、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;谷歌、微软以及一众的实验室和创业公司正在竞相努力将量子计算从单纯的科研项目变成可以投入生产应用的产品。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibc6yDDz4kPttFbcs6G6vQKdd9a3pxngnnhIyzLJEYsJe7Jia2IhZTMagXTIZghQjCzY0fia6tMoKew/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;在实现量子计算的道路上，使用被囚禁于真空中的单个离子的量子计算是发展得最快的方法之一&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;很长时间以来，人们都普遍认为量子计算是一种至少还需要 20 年发展才能实现应用的技术，而且这种看法似乎一直以来都没改变过。但 2017 年这项技术将有望开始延伸到单纯的科研领域之外了！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌和微软这样的计算巨头最近聘请了一些这一领域内一些领先的头脑，并且为今年设定了一些有挑战性的目标。他们的勃勃雄心反映出了正发生在包含&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720969&amp;amp;idx=1&amp;amp;sn=d5723c205f594616932624684d3a1327&amp;amp;chksm=871b0eb7b06c87a1d4d9809b35c361a4d8a4bf75315eaa9502a051058b184fb233e5b2d2695c&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720969&amp;amp;idx=1&amp;amp;sn=d5723c205f594616932624684d3a1327&amp;amp;chksm=871b0eb7b06c87a1d4d9809b35c361a4d8a4bf75315eaa9502a051058b184fb233e5b2d2695c&amp;amp;scene=21#wechat_redirect"&gt;创业公司和学术研究实验室的一场范围更广的转变：量子计算从纯科研向工程应用的转变。&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「人们真的造出了东西，」马里兰大学帕克分校的物理学家 Christopher Monroe 说，他在 2015 年联合创立了创业公司 IonQ，「这是前所未见的，它不再只是研究了。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌在 2014 年开始了对超导量子计算的研究。该公司希望在今年（甚至不久之后）就实现超过最强大的「经典」超级计算机的量子计算机——这也被视为实现「量子霸权（quantum supremacy）」的里程碑（参阅《&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718798&amp;amp;idx=1&amp;amp;sn=3f6bbc60ab65501074c58d6881271b4a&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718798&amp;amp;idx=1&amp;amp;sn=3f6bbc60ab65501074c58d6881271b4a&amp;amp;scene=21#wechat_redirect"&gt;重磅 | 深度揭秘谷歌「量子霸权」计划：有望明年底突破经典计算极限&lt;/a&gt;》）。其竞争对手微软则押注了一种有趣但仍未经证实的概念——拓扑量子计算（topological quantum computing），微软希望能够实现该计算的首次演示。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此外，量子计算创业也在升温。Monroe 今年一开始就计划开始招聘了。联合创立了 Quantum Circuits 的耶鲁大学物理学家 Robert Schoelkopf 和在加州伯克利创立了 Rigetti 的前 IBM 应用物理学家 Chad Rigetti 都表示他们预期他们很快就将达到关键的技术里程碑。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;学术实验室也是类似。「我们已经证实了我们所需的所有组件和所有功能。」Schoelkopf 说，他继续在耶鲁大学带领着一个研发量子计算机的团队。他和其他研究者都表示：尽管还需要很多物理实验才能找到将这些组件结合一起的方法，但现在的主要挑战已经是工程上的了。目前带有最多量子比特（qubit）的量子计算机（带有 20 个量子比特）正在奥地利因斯布鲁克大学 Rainer Blatt 领导的一个学术实验室里面接受测试。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;经典计算机将信息编码成以两种状态（0 和 1）表示的比特，而构成量子计算机的量子比特则可以以「叠加（superpositions）」的形式同时处于这两种状态。此外，量子比特还有一种被称为「纠缠（entanglement）」的能力——可以实现量子状态的共享。这些能力让量子计算机可以同时执行大量计算。而且理论上，每增加一个量子比特，这些同时执行的计算的数量就会翻倍，这可以带来指数级的加速。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种快速性（rapidity）应该让量子计算机能够执行特定的任务，比如搜索大型数据库或大数因子分解——对于速度更慢的经典计算机来说，这样的任务有时候是不可能完成的。量子计算机也可以作为研究工具用于执行量子模拟（quantum simulations），从而让化学家可以以前所未有的详细程度理解化学反应或让物理学家可以设计出室温超导材料。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如今对如何建造量子比特有许多相竞争的设计，但还是有两个领跑者。尽管量子态因外部干扰很容易去相干，但它们都证实了量子比特具有长期储存信息的能力，并能执行逻辑计算。Schoelkopf 帮助量子计算先锋的一个方法就是将量子状态编码为超导环路中的振荡电流，这个方法也广泛被谷歌、IBM、Rigetti 和 Quantum Circuits 接受。IonQ 和几个主要的学术实验室追求的另一个方法是在真空阱（vacuum traps）中通过电磁场编码单个离子的量子比特。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;John Martinis 在加州大学圣巴巴拉分校（University of California, Santa Barbara）工作，在谷歌 2014 年聘请他和他的研究团队时，他说超导技术的成熟使他的团队设定了量子霸权（quantum supremacy）的雄伟目标。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他们团队计划使用「混沌（chaotic）」量子算法来实现这一点，该算法产生如同随机输出的结果（S. Boixo et al. Preprint at https://arxiv.org/abs/1608.00263; 2016）。如果算法在由相对较少量子比特组成的量子计算机上运行，那么经典计算机就能预测其输出。该小组预测一旦量子计算机拥有接近 50 个量子比特数，那么即使是最强大的经典超级计算机也完全跟不上它的步伐。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然计算结果没有任何用处，但是他们将证明在有些任务上量子计算机是无可匹敌的。Martinis 说这是一个重要的的心理阀值，它会吸引潜在客户的注意力。他说：「我认为这是一个开创性的实验。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是 Schoelkopf 并不把量子霸权看作「很有意思和有用的目标」，部分原因是因为它避开了纠错的挑战：系统具有在受到轻微扰动后恢复其信息到量子比特的能力，这要比量子比特数量增多还要困难。相反 Quantum Circuits 关注于从一开始就搭建完全错误矫正（fully error-corrected）的机器。这就需要建造更多的量子比特数，不过机器也能够运行更复杂的量子算法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Monroe 希望在近期实现量子霸权，但那并不是 IonQ 的主要目标。他说，这家创业公司的目标是构建带有 32 个或 64 个量子比特的机器，离子阱（ion-trap）技术让他们的设计可以比超导电路更灵活和更具扩展性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;同时，微软则押注一种仍待验证的技术。拓扑量子计算（topological quantum computing）依赖于处于激发态的物质——其通过像辫子一样互相缠绕来编码信息。和其它技术相比，存储在这种量子比特中的信息对外部扰动的抵抗力更强，使得纠错（error correction）更简单。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;到目前为止，还没有人创造出这种激发所需的这种物质状态，更不要说拓扑量子比特了。但微软已经聘请了这一领域的四位领先专家，包括荷兰代尔夫特大学的 Leo Kouwenhoven——他已经创造出了貌似正确的激发类型。「我告诉我的学生 2017 年是 braiding 的一年。」Kouwenhoven 说，他将在代尔夫特大学建立一个微软实验室。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其他研究者则更为谨慎。Blatt 说：「我不做关于未来的任何新闻发布。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;位于科罗拉多州博尔德的国家标准与技术研究所的物理学家 David Wineland 领导着一个研究离子阱的实验室，他也不愿意给出明确的预测：「我对长期未来持乐观态度，但『长期』是什么意思，我不知道。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 04 Jan 2017 11:22:02 +0800</pubDate>
    </item>
    <item>
      <title>学界 | 机器能有意识吗？新论文提出一种用于机器意识的情感计算模型</title>
      <link>http://www.iwgc.cn/link/4193470</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自arxiv.org&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：Terrence、沈泽江、李泽南&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;人类对于意识本质的探索一直在不断发展的过程中，随着近年来人工智能的进步，此类研究的进展正在加快。理解和建模意识不仅能够使人了解自身，更能为构建先进的机器系统提供帮助。最近，Software Foundation的一项研究提出了用于机器意识的情感模型。论文可点击阅读原文进行下载。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibc6yDDz4kPttFbcs6G6vQKCYVicdmhmJjBUTnCALPlq8Ojn12swiciatxelIxTpIycKYdqPSrBNfteA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;摘要&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在过去，有几种意识模型已经变得流行，并且已被用于机器意识的模型的开发，在模拟和实现中，一些研究成果已经出现。涉及情绪，行为和个性的情感计算属性并不是这些意识模型的重点，因为它们缺乏在软件应用程序和机器人中部署的动机。但情感属性是机器意识在未来的重要组成部分，情感属性或许可以帮助人工智能助理技术兴起。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人格和感情可以给予机器人除计算模型以外的额外意识成分。机器学习领域的最近的发展集中于深度学习，它可以帮助我们在能够更好地复制人类感觉知觉（例如语音识别和视觉）的方面进一步开发机器意识。随着这些技术的进步，在开发同步情感计算的不同方面的模型中，我们必将遇到更多的挑战。在本文中，我们回顾了一些现有的意识模型，并展示了一个情感计算模型，可以在机器人系统上实现人类的触摸和感受。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;导语&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如何定义意识一直是对人类意识模拟或建模的主要挑战。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;无论如何，意识的广义定义是意识的状态或质量，其特征在于感知，主体性，通过感觉知觉体验的能力，觉醒状态，自我意识，以及心理的控制，同时意识到思维过程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;意识的定义和模型中的挑战会影响意识的实现或模拟研究。在过去，人们已经针对某些意识模型进行了模拟研究，例如来自全局工作空间理论的信息流模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Shanahan 进行了一项研究，通过与环境的相互作用的内部模拟来实现预期和规划的认知功能。一种基于失重神经元的实现也被用于控制模拟机器人。人们也进一步尝试通过暴力搜索启发式来模拟特定形式的智力，以再现人类感知和认知的特征，包括情感。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此外，小规模的实现可以考虑基于动物的意识的模型，意识是动物生存所需。虽然在任务解决的过程中表现的智力不同，但限制人类的意识的定义并不严谨，因为所有生物都倾向于具有与人类意识重叠的某些属性。一些未被驯化的动物，如啮齿动物，可以生存在具有挑战性和广泛变化的气候和环境中。有一些研究表明，如老鼠这类的动物似乎会表达意识的某些方面，这不仅仅是为了生存。它们具有社会属性，例如与人类相似的认同感。高度的好奇心和创造力是意识的主要属性，这可能是区分人类和其余动物的因素。虽然智力也是意识的一个基础方面，但一些研究已经表明，智力是必要的，但不是创造力的充分条件。然而，除了人类，其他动物也显示出了一定的创造力水平。人们已经在尝试通过研究近死亡经验，通过吸纳意识的非物质主义方面，以非常规方式增强现有模型。此外，心理学和量子力学的思路也被纳入一项物质意识的研究。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了通过实证研究意识，Tononi 提出了意识信息整合理论，它可以量化实体拥有的决定其意识水平的综合信息量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该理论完全取决于系统集成信息的能力，无论被观测者是否具有强烈的自我意识，语言、情感、身体或身处环境如何。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此外，它试图解释为什么意识在例如睡眠状态的情况下既不需要感觉输入也不需要行为输出。在此基础上，进一步的研究是令其作为动力学和因果结构的函数，将集成信息应用于离散网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;信息综合理论 3.0（Information integrated theory 3.0）通过现象学公理和假设进一步细化了意识的性质，以便设计出满足这些公理的机制系统，从而产生意识。有人建议，具有纯前馈结构的系统不能产生意识，而某些性质的反馈或递归可能是意识的一个重要组成部分。这是基于以前的研究的结论，其中确定反馈的存在与否可以直接等价于存在或不存在意识。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;David Chalmers 强调了在定义意识方面的「解释鸿沟」，并指出问题难处来自于尝试以纯物理术语解释「意识」。综合信息理论是基于现象学公理。它从意识开始，表明具有一些反馈状态的复杂系统可能具有不同的意识水平。然而，这并不完全支持 Chalmers 所定义的意识经验的动机。Chalmers 从第一和第三人的视角和他们之间的关系来看待「意识经验」和「感觉」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;情感计算领域，致力于发展处可以模拟、识别和处理人类情感的系统——这本质上就是创造感觉或情感的体验。情感计算可以让人和人工系统更好的交流，能够促进人与人工系统的情感信任，增强两者联系。让人工意识拥有情感模型，是在未来的人类日常活动中引入移动技术和机器人的一大目标。例如，家庭厨房机器人利用情感计算的特性，能进一步从建立连接和通信。在不久的将来，性机器人、治疗和护理机器人的需求量也将越来越大，这类机器人都需要情感计算功能。此外，智能玩具和机器人宠物的出现可能有助于养育孩子和赡养老人。尽管基于移动应用的支持和学习系统已成功被部署，但是他们常常因缺乏实体交互性而被批评。在如压力管理和咨询等些领域，机器人的情感可以进一步地帮助人类。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;个性是潜意识的一个独立部分。但是过去提出的关于潜意识的模型，并没有很好的处理」个性「的特性。先前的一项研究提出了不同个性在工作绩效的选择、培训和发展、以及工作表现方面的影响。Nazir 等人进一步提出了基于文化个性的情感模型，包括人格的五个维度。Carver 和 Scheier 使用控制理论作为个性的概念框架，从社会、临床和健康心理学三方面进行解读。虽然这些研究在心理学领域非常受欢迎，但是在机器意识模型中，关于如何整融合对个性的理解，却并没有被广泛地研究。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们注意到，饥饿与疼痛，作为最重要的生存方面的生物元素，帮助人们形成了性格及情感。Starzyk 等人提出了动机学习模型，以研发某种自动系统，使之能够在动态改变的疼痛信号之间做出响应。这些信号，能够反映出外在的驱动力及内在的控制信号的相互作用。&lt;/span&gt;&lt;span&gt;将疼痛作为一种对某种目标（如食物）的抽象符号，也许会成为机器意识情感模型中的某种特性。尽管已经有不少著名的机器意识的模型被提出，但他们在处理人类情感的特性方面仍面临着局限性，而这些特性很有可能在机器人系统及其他相关的即将出现的科技中（为它们）带来情感与意识。这些拥有人类情感的系统将会带来广泛的社会影响力，包括社会认同、信任及可靠性方面的内容。同时，人类本身的局限也将会成为威胁。我们将自己的发展目标局限于发展「机器情感」，这也许会导致人造意识所产生的个性，并不会注重逻辑或是社会认同等积极因素。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本文将回顾一些现有的潜意识模型，并提出了一个高效的机器意识计算模型，它意图融合人的个性及情感。随后，本文将进一步讨论如何使用最新的科技及机器学习中的进展来研发这个高效的计算模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本文的余下部分按照如下内容组织：第二节给出了关于潜意识的背景知识及现有的模型；第三节展示了新提出的模型；第四节对新提出模型的进一步研究方向进行了讨论；第五节总结了全文。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibc6yDDz4kPttFbcs6G6vQKtf8NsPrTP4xnlCj5hVZ5sL0Hr0xh129wAN3bhQAA8yuAic8ibL0EyebA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;物理层面（硬件层面）及超物理层面（软件层面）的差异对比图&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibc6yDDz4kPttFbcs6G6vQKToAibHwtDf9eRw4tJW5ZdBsusF66MpM62oT3r5A0micreQmz07CHGZ3Q/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 2 机器意识与动物之间在处理如「疼痛」、「饥饿」、「疲倦」等情感元素的示意&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibc6yDDz4kPttFbcs6G6vQKyOZqNJiaYicbuwJxdYPzvPhicn58yES7zA0ibZTmk7eib7091cTrIwGw3jg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 7 在机器意识领域使用的机器学习及人工智能概念&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 04 Jan 2017 11:22:02 +0800</pubDate>
    </item>
    <item>
      <title>招聘 | 和旷视(Face++)一起开创人工智能黄金时代！</title>
      <link>http://www.iwgc.cn/link/4193471</link>
      <description>&lt;p&gt;&lt;strong&gt;&lt;span&gt;关于旷视 (Face++)&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;北京旷视科技有限公司 (Face++) 成立于 2011 年，是一家以计算机视觉为核心的人工智能企业，致力于为企业级用户和开发者提供全方位的行业智能解决方案和智能数据服务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;旷视 (Face++) 以智能云和智能互联为产品核心，深耕移动互联网、金融、安防、地产、机器人等多个行业，如今已成为人脸识别领域最具有影响力的品牌。截至 2016 年 12 月，旷视的 FaceID 产品已为全球 1.12 亿人完成了在线实名验证服务；且在公共安全领域实现了全国 25 省业务覆盖，累积协助公安破获各类案件超过 500 起，同时为 276 个园区、企业提供日均 124.9 万次人员出入通行管理数据服务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;工作在旷视&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8Mskm4jqawnibY3Hsk8TxIuRkbq4gztZyqF2GATibW0gicC4jPBlpeU4ffg/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8MqAwu6DtQ7hBh8OBibUSTI41iaYIDA9oZFoAfcB15iaO5LS3DdkxgV5Rgg/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8MmENFa3iaxdM54VsSiccBUq9HcySpOcNoYVy7uZUG7Thq2661XVpry2ew/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8MVoJMbGibGY07BBCOywwbCaS2IWwwTyctpmHZia04Vnwq01uaLUHX8gFA/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;团队情况&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;旷视的核心团队由来自清华大学、美国哥伦比亚大学、微软亚洲研究院等国际顶级院校、科研机构的技术极客，与来自谷歌、阿里巴巴、华为、微软等跨国企业的一流产品、商务人员组成，累计获得国际人工智能技术评测冠军 10 余项，获得国家、国际级信息学金奖人员超过 70 人次，产出国家、国际级发明专利超过 300 件。此外，旷视曾多次代表行业领先技术提供方参与多个人工智能国家及行业标准制定。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;热招岗位：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;算法研究员 、算法软件开发工程师&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;工作地点：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;北京&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;具体岗位要求&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1.算法研究员&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;岗位职责&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;推进计算机视觉和深度学习领域的核心算法；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;构建计算机视觉或深度学习领域的关键应用；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;将最好的算法在有趣有用的商业场景中落地。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;希望你具备&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="list-style-type: decimal;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;扎实的编程基础；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;有很强的自学能力和独立思考能力，善于思考和表达自己的想法；同时又具备良好的团队合作精神；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;使用过 Caffe，TensorFlow，MXNet，Torch，Theano 等开源深度学习框架优先；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;有深度模型训练、图像分类、物体检测与分割、文本分析与识别、视频分析、三维重建、计算摄影学、计算机图形学等相关科研经历者（例如顶级会议第一作者）优先。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2.算法软件开发工程师&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;岗位职责&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;与算法研发员一起工作，提出、实现、改进和测试算法；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;将算法运行在不同平台（例如手机客户端、云计算平台或服务器等），负责相关算法 SDK 的开发、优化和维护；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;针对要解决的应用问题搭建系统、设计方案、性能调优、与产品对接。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;希望你具备&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="list-style-type: decimal;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;扎实的编程基础，具有良好代码质量；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;有很强的自学能力和独立思考能力，善于思考和表达自己的想法；同时又具备良好的团队合作精神；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;了解软件工程的流程，有较好的系统设计和软件架构能力优先；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;有计算机视觉、深度学习、机器学习工程项目经历优先。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投递简历：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;career@megvii.com&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其他在招岗位请点击【阅读原文】查看&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 04 Jan 2017 11:22:02 +0800</pubDate>
    </item>
    <item>
      <title>机器学习初学者入门实践：怎样轻松创造高精度分类网络</title>
      <link>http://www.iwgc.cn/link/4179109</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Github&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是一个为没有人工智能背景的程序员提供的机器学习上手指南。使用神经网络不需要博士学位，你也不需要成为实现人工智能下一个突破的人，你只需要使用现有的技术就行了——毕竟我们现在已经实现的东西已经很突破了，而且还非常有用。我认为我们越来越多的人将会和机器学习打交道就像我们之前越来越多地使用开源技术一样——而不再仅仅将其看作是一个研究主题。在这份指南中，我们的目标是编写一个可以进行高准确度预测的程序——仅使用图像本身来分辨 data/untrained-samples 中程序未见过的样本图像中是海豚还是海马。下面是两张图像样本：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8M105rSLT1BfsDJJO4eiaDwWQEiamkGmCPtQskHiceq32SmeXePf7Rdc0gA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8McfumnibfyFuzWxEmzpcOx2V3czsiajEFDtbA2Luia0nWicvHcGObuBOshw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了实现我们的目标，我们将训练和应用一个卷积神经网络（CNN）。我们将从实践的角度来接近我们的目标，而不是阐释其基本原理。目前人们对人工智能有很大的热情，但其中很多都更像是让物理学教授来教你自行车技巧，而不是让公园里你的朋友来教你。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为此，我（GitHub 用户 humphd/David Humphrey）决定在 GitHub 上写下我的指南，而不是直接发在博客上，因为我知道我下面的写的一切可能会有些误导、天真或错误。我目前仍在自学，我发现现在还很缺乏可靠的初学者文档。如果你觉得文章有错误或缺失了某些重要的细节，请发送一个 pull 请求。下面就让我教你「自行车的技巧」吧！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;指南地址：https://github.com/humphd&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;概述&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们将在这里探索以下内容：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;设置和使用已有的、开源的机器学习技术，尤其是 Caffe 和 DIDITS&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;创建一个图像数据集&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;从头开始训练一个神经网络&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在我们的神经网络从未见过的图像上对其进行测试&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;通过微调已有的神经网络（AlexNet 和 GoogLeNet）来提升我们的神经网络的准确度&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;部署和使用我们的神经网络&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：我知道你说过我们不会谈论神经网络理论，但我觉得在我们开始动手之前至少应该来一点总体概述。我们应该从哪里开始？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于神经网络的理论问题，你能在网上找到海量的介绍文章——从短帖子到长篇论述到在线课程。根据你喜欢的学习形式，这里推荐了三个比较好的起点选择：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;J Alammar 的博客《A Visual and Interactive Guide to the Basics of Neural Networks》非常赞，使用直观的案例介绍了神经网络的概念：https://jalammar.github.io/visual-interactive-guide-basics-neural-networks/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Brandon Rohrer 的这个视频是非常好的卷积神经网络介绍：https://www.youtube.com/watch?v=FmpDIaiMIeA&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如果你想了解更多理论上的知识，我推荐 Michael Nielsen 的在线书籍《Neural Networks and Deep Learning》：http://neuralnetworksanddeeplearning.com/index.html&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;设置&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;安装 Caffe&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Caffe 地址：http://caffe.berkeleyvision.org/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先，我们要使用来自伯克利视觉和学习中心（Berkely Vision and Learning Center）的 Caffe 深度学习框架（BSD 授权）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;问：稍等一下，为什么选择 Caffe？为什么不选现在人人都在谈论的 TensorFlow？&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;没错，我们有很多选择，你也应该了解一下所有的选项。TensorFlow 确实很棒，你也应该试一试。但是这里选择 Caffe 是基于以下原因：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;这是为计算机视觉问题定制的&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;支持 C++ 和 Python（即将支持 node.js：https://github.com/silklabs/node-caffe）(https://github.com/silklabs/node-caffe%EF%BC%89)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;快速且稳定&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是我选择 Caffe 的头号原因是不需要写任何代码就能使用它。你可以声明性地完成所有工作（Caffe 使用结构化的文本文件来定义网络架构），并且也可以使用命令行工具。另外，你也可以为 Caffe 使用一些漂亮的前端，这能让你的训练和验证过程简单很多。基于同样的原因，下面我们会选择 NVIDIA 的 DIGITS。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Caffe 的安装有点麻烦。这里有不同平台的安装说明，包括一些预构建的 Docker 或 AWS 配置：http://caffe.berkeleyvision.org/installation.html&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;注：当我在进行练习的时候，我使用了来自 GitHub 的尚未发布的 Caffe 版本：https://github.com/BVLC/caffe/commit/5a201dd960840c319cefd9fa9e2a40d2c76ddd73&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 Mac 要配置成功则难得多，这个版本有一些版本问题会在不同的步骤终止你的进度。我用了好几天时间来试错，我看了十几个指南，每一个都有一些不同的问题。最后发现这个最为接近：https://gist.github.com/doctorpangloss/f8463bddce2a91b949639522ea1dcbe4。另外我还推荐：https://eddiesmo.wordpress.com/2016/12/20/how-to-set-up-caffe-environment-and-pycaffe-on-os-x-10-12-sierra/，这篇文章比较新而且链接了许多类似的讨论。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;到目前为止，安装 Caffe 就是我们做的最难的事情，这相当不错，因为你可能原来还以为人工智能方面会更难呢！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果安装遇到问题请不要放弃，痛苦是值得的。如果我会再来一次，我可能会使用一个 Ubuntu 虚拟机，而不是直接在 Mac 上安装。如果你有问题要问，可以到 Caffe 用户讨论组：https://groups.google.com/forum/#!forum/caffe-users&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：我需要一个强大的硬件来训练神经网络吗？要是我没法获取一个强大的 GPU 怎么办？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;是的，深度神经网络确实需要大量的算力和能量……但那是在从头开始训练并且使用了巨型数据集的情况。我们不需要那么做。我们可以使用一个预训练好的网络（其它人已经为其投入了数百小时的计算和训练），然后根据你的特定数据进行微调即可。我们后面会介绍如何实现这一目标，但首先我要向你说明：后面的一切工作都是在一台没有强大 GPU 的一年前的 MacBook 上完成的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外说明一点，因为我有一块集成英特尔显卡，而不是英伟达的 GPU，所以我决定使用 OpenCL Caffe 分支：https://github.com/BVLC/caffe/tree/opencl，它在我的笔记本电脑上效果良好！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当你安装完 Caffe 之后，你应该有或能够做下列事情：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;一个包含了你构建的 Caffe 的目录。如果你是按标准方式做的，应该会有一个 build/ 目录包含了运行 Caffe 所需的一切、捆绑的 Python 等等，build/ 的父目录将是你的 CAFFE_ROOT（后面我们会用到它）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;运行 make test &amp;amp;&amp;amp; make runtest，应该会通过&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;安装了所有的 Python 依赖包之后（在 python/ 中执行 for req in $(cat requirements.txt); do pip install $req; done；运行 make pycaffe &amp;amp;&amp;amp; make pytest 应该会通过&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;你也应该运行 make distribute 以在 distribute/ 中创建一个带有所有必要的头文件、二进制文件等的可分发的 Caffe 版本&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在我的机器上，Caffe 完全构建后，我的 CAFFE_ROOT 目录有以下基本布局：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;caffe/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;build/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;python/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;lib/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;tools/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;caffe ← this is our main binary&amp;nbsp;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;distribute/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;python/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;lib/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;include/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;bin/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;proto/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;到现在，我们有了训练、测试和编程神经网络所需的一切。下一节我们会为 Caffe 增加一个用户友好的基于网页的前端 DIGITS，这能让我们对网络的训练和测试变得更加简单。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;安装 DIGITS&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;DIGITS 地址：https://github.com/NVIDIA/DIGITS&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;英伟达的深度学习 GPU 训练系统（Deep Learning GPU Training System/DIGITS）是一个用于训练神经网络的 BSD 授权的 Python 网页应用。尽管我们可以在 Caffe 中用命令行或代码做到 DIGITS 所能做到的一切，但使用 DIGITS 能让我们的工作变得更加简单。而且因为 DIGITS 有很好的可视化、实时图表等图形功能，我觉得使用它也能更有乐趣。因为你正在尝试和探索学习，所以我强烈推荐你从 DIGITS 开始。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 https://github.com/NVIDIA/DIGITS/tree/master/docs 有一些非常好的文档，包括一些安装、配置和启动的页面。我强烈建议你在继续之前通读一下。我并不是一个使用 DIGITS 的专家，如果有问题可以在公开的 DIGITS 用户组查询或询问：https://groups.google.com/forum/#!forum/digits-users&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;安装 DIGITS 的方式有很多种，从 Docker 到 Linux 上的 pre-baked package，或者你也可以从源代码构建。我用的 Mac，所以我就是从源代码构建的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;注：在我的实践中，我使用了 GitHub 上未发布的 DIGITS 版本：https://github.com/NVIDIA/DIGITS/commit/81be5131821ade454eb47352477015d7c09753d9&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因为 DIGITS 只是一些 Python 脚本，所以让它们工作起来很简单。在启动服务器之前你要做的事情是设置一个环境变量，告诉 DIGITS 你的 CAFFE_ROOT 的位置在哪里：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;export CAFFE_ROOT=/path/to/caffe&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;./digits-devserver&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;注：在 Mac 上，这些服务器脚本出现了一些问题，可能是因为我的 Python 二进制文件叫做 python2，其中我只有 python2.7。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你可以在 /usr/bin 中 symlink 它或在你的系统上修改 DIGITS 启动脚本以使用合适的二进制文件。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一旦服务器启动，你可以在你的浏览器中通过 http://localhost:5000 来完成一切后续工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;训练一个神经网络&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;训练神经网络涉及到几个步骤：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 准备一个带有分类图像的数据集&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 定义网络架构&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 使用准备好的数据集训练和验证这个网络&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面我们会做这三个步骤，以体现从头开始和使用预训练的网络之间的差异，同时也展示如何使用 Caffe 和 DIGITS 上最常用的两个预训练的网络 AlexNet、 GoogLeNet。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于我们的训练，我们将使用一个海豚（Dolphins）和海马（Seahorses）图像的小数据集。这些图像放置在 data/dolphins-and-seahorses。你至少需要两个类别，可以更多（有些我们将使用的网络在 1000 多个类别上进行了训练）。我们的目标是：给我们的网络展示一张图像，它能告诉我们图像中的是海豚还是海马。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;准备数据集&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;dolphins-and-seahorses/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;dolphin/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;image_0001.jpg&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;image_0002.jpg&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;image_0003.jpg&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;...&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;seahorse/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;image_0001.jpg&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;image_0002.jpg&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;image_0003.jpg&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;...&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最简单的开始方式就是将你的图片按不同类别建立目录：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在上图中的每一个目录都是按将要分类的类别建立的，所建文件夹目录下是将以用于训练和验证的图片。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：所有待分类和验证的图片必须是同样大小吗？文件夹的命名有影响吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;回答都是「否」。图片的大小会在图片输入神经网络之前进行规范化处理，我们最终需要的图片大小为 256×256 像素的彩色图片，但是 DIGITS 可以很快地自动裁切或缩放（我们采用缩放）我们的图像。文件夹的命名没有任何影响——重要的是其所包含的图片种类。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：我能对这些类别做更精细的区分吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然可以。详见 https://github.com/NVIDIA/DIGITS/blob/digits-4.0/docs/ImageFolderFormat.md。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们要用这些图片来创建一个新的数据集，准确的说是一个分类数据集（Classification Dataset）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8MY1HgtW6jENNiaibicxwvZSvzupCpeVDewVcS5bIF2AgtLNPZoMLHdJ32w/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们会使用 DIGITS 的默认设置，并把我们的训练图片文件路径设置到 data/dolphins-and-seahorses 文件夹。如此一来，DIGITS 将会使用这些标签（dolphin 和 seahorse）来创建一个图像缩放过的数据集——图片的大小将会是 256×256，其中 75% 的为训练图片，25% 的为测试图片。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;给你的数据集起一个名字，如 dolphins-and-seahorses，然后鼠标点击创建（Create）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8MXbiclBUec8a5cYGGT1Abv3j52orMJHgXJoM8Hbuk0c5VEecibxMZHpgQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过上面的步骤我们已经创建了一个数据集了，在我的笔记本上只需要 4 秒就可以完成。最终在所建的数据集里有 2 个类别的 92 张训练图片（其中 49 张 dolphin，43 张 seahorse），另外还有 30 张验证图片（16 张 dolphin 和 14 张 seahorse）。不得不说这的确是一个非常小的数据集，但是对我们的示范试验和 DIGITS 操作学习来说已经足够了，因为这样网络的训练和验证就不会用掉太长的时间了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你可以在这个数据库文件夹里查看压缩之后的图片。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8Mzl6VFp6ib3y8WnaDPCfpWDrbNnHyMjJ2vZgSGmcc9YRicBun17DYKFIg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;训练尝试 1：从头开始&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;回到 DIGITS 的主页，我们需要创建一个新的分类模型（Classification Model）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8MRnf8rhpGfO7zWdgzOBibK3ddRia27ibQlqO0E3lDpiaWsUIKwY9Uibraodg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们将开始用上一步所建立的 dolphins-and-seahorses 数据集来训练模型，仍然使用 DIGITS 的默认设置。对于第一个神经网络模型，我们可以从提供的神经网络架构中选取一个既有的标准模型，即 AlexNet。AlexNet 的网络结构在 2012 年的计算机视觉竞赛 ImageNet 中获胜过（ImageNet 为计算机视觉顶级比赛）。在 ImageNet 竞赛里需要完成 120 万张图片中 1000 多类图片的分类。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8M9Zqj3EHbvA0WVfsu6U7ibQibdlURPazWqZLQ2OgBbRVqWhpr39XNdlpg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Caffe 使用结构化文本文件（structured text files）来定义网络架构，其所使用的文本文件是基于谷歌的 Protocol Buffer。你可以阅读 Caffe 采用的方案：https://github.com/BVLC/caffe/blob/master/src/caffe/proto/caffe.proto。其中大部分内容在这一部分的神经网络训练的时候都不会用到，但是了解这些构架对于使用者还是很有用的，因为在后面的步骤里我们将会对它们进行调整。AlexNet 的 prototxt 文件是这样的，一个实例： https://github.com/BVLC/caffe/blob/master/models/bvlc_alexnet/train_val.prototxt。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们将会对这个神经网络进行 30 次 epochs，这意味着网络将会进行学习（运用我们的训练图片）并自行测试（运用我们的测试图片），然后根据训练的结果调整网络中各项参数的权重值，如此重复 30 次。每一次 epoch 都会输出一个分类准确值（Accuracy，介于 0% 到 100% 之间，当然值越大越好）和一个损失度（Loss，所有错误分类的比率，值越小越好）。理想的情况是我们希望所训练的网络能够有较高的准确率（Accuracy）和较小的损失度（Loss）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;初始训练的时候，所训练网络的准确率低于 50%。这是情理之中的，因为第一次 epoch，网络只是在随意猜测图片的类别然后任意设置权重值。经过多次 epochs 之后，最后能够有 87.5% 的准确率，和 0.37 的损失度。完成 30 次的 epochs 只需不到 6 分钟的时间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8Mym2wHnhU0kR7XTE0qHWib4RNhjtBbia9n1f2b1bPZGKZBFJiaBWqqicL6g/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们可以上传一张图片或者用一个 URL 地址的图片来测试训练完的网络。我们来测试一些出现在我们训练和测试数据集中的图片：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8MKxAmcyqlGfHZSSSzMW4WQfEcWcs1XpnX1at779uBbRL9wlwBlxq9uQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8ME5mdcsax7IdAxcy96p0Dl17mvticTq0WgU8s8w8ad5T8iczyks5Tk0jA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;网络的分类结果非常完美，当我们测试一些不属于我们训练和测试数据集的其他图片时：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8M4PaXzhcexmBG2DPKsvylnZ4wvx7PkGWU0DEqdO11axS9sGcEIuGbpQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;分类的准确率直接掉下来了，误把 seahorse 分类为 dolphin，更糟糕的是网络对这样的错误分类有很高的置信度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;事实是我们的数据集太小了，根本无法用来训练一个足够好的神经网络。我们需要数万乃至数百万张图片才能训练一个有用的神经网络，用这么多的图片也意味着需要很强劲的计算能力来完成所有的计算过程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;训练尝试 2：微调 AlexNet&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;怎么微调网络&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从头设计一个神经网络，收集足量的用以训练这个网络的数据（如，海量的图片），并在 GPU 上运行数周来完成网络的训练，这些条件远非我们大多数人可以拥有。能够以更加实际——用较小一些的数据集来进行训练，我们运用一个称为迁移学习（Transfer Learning）或者说微调（Fine Tuning）的技术。Fine tuning 借助深度学习网络的输出，运用已训练好的神经网络来完成最初的目标识别。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;试想使用神经网络的过程就好比使用一个双目望远镜看远处的景物。那么当你第一次把双目望远镜放到眼前的时候，你看到的是一片模糊。当你开始调焦的时候，你慢慢可以看出颜色、线、形状，然后最终你可以分辨出鸟的外形，在此之上你进一步调试从而可以识别出鸟的种类。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在一个多层网络中，最开始的几层是用于特征提取的（如，边线），之后的网络层通过这些提取的特征来识别外形「shape」（如，一个轮子，一只眼睛），然后这些输出将会输入到最后的分类层，分类层将会根据之前所有层的特征积累来确定待分类目标的种类（如，判断为猫还是狗）。一个神经网络从像素、线形、眼睛、两只眼睛的确定位置，这样的步骤来一步步确立分类目标的种类（这里是猫）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们在这里所做的就是给新的分类图片指定一个已训练好的网络用于初始化网络的权重值，而不是用新构建网络自己的初始权重。因为已训练好的网络已经具备「看」图片特征的功能的，我们所需要的是这个已训练的网络能「看」我们所建图片数据集——这一具体任务中特定类型的图片。我们不需要从头开始训练大部分的网络层——我们只需要将已训练网络中已经学习的层转接到我们新建的分类任务上来。不同于我们的上一次的实验，在上次实验中网络的初始权重值是随机赋予的，这次实验中我们直接使用已经训练网络的最终权重值作为我们新建网络的初始权重值。但是，必须去除已经训练好的网络的最后分类层并用我们自己的图片数据集再次训练这个网络，即在我们自己的图片类上微调已训练的网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于这次实验，我们需要一个与经由与我们训练数据足够相似的数据集所训练的网络，只有这样已训练网络的权重值才对我们有用。幸运的是，我们下面所使用的网络是在海量数据集（自然图片集 ImageNet）上训练得到的，这样的已训练网络能满足大部分分类任务的需要。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种技术已经被用来做一些很有意思的任务如医学图像的眼疾筛查，从海里收集到的显微图像中识别浮游生物物种，给 Flickr 上的图片进行艺术风格分类。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;完美的完成这些任务，就像所有的机器学习一样，你需要很好的理解数据以及神经网络结构——你必须对数据的过拟合格外小心，你或许需要调整一些层的设置，也很有可能需要插入一些新的网络层，等等类似的调整。但是，我们的经验表明大部分时候还是可以完成任务的「Just work」，而且用我们这么原始的方法去简单尝试一下看看结果如何是很值得的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;上传预训练网络&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在我们的第一次尝试中，我们使用了 AlexNet 的架构，但是网络各层的权重是随机分布的。我们需要做的就是需要下载使用一个已经经过大量数据集训练的 AlexNet。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;AlexNet 的快照（Snapshots）如下，可供下载：https://github.com/BVLC/caffe/tree/master/models/bvlc_alexnet。我们需要一个二进制文件 .caffemodel，含有训练好的权重，可供下载 http://dl.caffe.berkeleyvision.org/bvlc_alexnet.caffemodel。在你下载这些与训练模型的时候，让我们来趁机多学点东西。2014 年的 ImageNet 大赛中，谷歌利用其开源的 GoogLeNet (https://research.google.com/pubs/pub43022.html)（一个 22 层的神经网络）赢得了比赛。GoogLeNet 的快照如下，可供下载： https://github.com/BVLC/caffe/tree/master/models/bvlc_googlenet。在具备了所有的预训练权重之后，我们还需要.caffemodel 文件，可供下载：http://dl.caffe.berkeleyvision.org/bvlc_googlenet.caffemodel&lt;span&gt;.&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有了 .caffemodel 文件之后，我们既可以将它们上传到 DIGITS 当中。在 DIGITS 的主页当中找到预训练模型（Pretrained Models）的标签，选择上传预训练模型（Upload Pretrained Model）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8MHG09h1ZdGlWNuU51icOiaVk9PzicA8hIicR8wlCo1rqEKAYicNMEicx1EFNQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于这些预训练的模型，我们可以使用 DIGITS 的默认值（例如，大小为 256×256 像素的彩色图片）。我们只需要提供 Weights (.caffemodel) 和 Model Definition (original.prototxt)。点击这些按钮来选择文件。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;模型的定义，GoogLeNet 我们可以使用 https://github.com/BVLC/caffe/blob/master/models/bvlc_googlenet/train_val.prototxt，AlexNet 可以使用 https://github.com/BVLC/caffe/blob/master/models/bvlc_alexnet/train_val.prototxt。我们不打算使用这些网络的分类标签，所以我们可以直接添加一个 labels.txt 文件：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8MfibrDes2l5qDkagdHL8FTYOLVyltoNiazwe1WqqQkq8o4E1YfX9yzPJg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 AlexNet 和 GoogLeNet 都重复这一过程，因为我们在之后的步骤当中两者我们都会用到。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问题：有其他的神经网络能作为微调的基础吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;回答：Caffe Model Zoo 有许多其他预训练神经网络可供使用，详情请查看 https://github.com/BVLC/caffe/wiki/Model-Zoo&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使用预训练 Caffe 模型进行人工神经网络训练就类似于从头开始实现，虽然我们只需要做一些调整。首先我们需要将学习速率由 0.01 调整到 0.001，因为我们下降步长不需要这么大（我们会进行微调）。我们还将使用预训练网络（Pretrained Network）并根据实际修改它。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8MxQj98Uhq6XCzjAR9pPTepUVxxibdrWicOKXGYErrpTiaKF81WIzoHuoTw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在预训练模型的定义（如原文本）中，我们需要对最终完全连接层（输出结果分类的地方）的所有 references 重命名。我们这样做是因为我们希望模型能从现在的数据集重新学习新的分类，而不是使用以前最原始的训练数据（我们想将当前最后一层丢弃）。我们必须将最后的全连接层由「fc8」重命名为一些其他的（如 fc9）。最后我们还需要将分类类别从 1000 调整为 2，这里需要调整 num_output 为 2。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面是我们需要做的一些调整代码：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;@@ -332,8 +332,8 @@&lt;/span&gt;
 }
 layer {&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp;name: "fc8"&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp;name: "fc9"&lt;/span&gt;
   type: "InnerProduct"
   bottom: "fc7"&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp;top: "fc8"&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp;top: "fc9"&lt;/span&gt;
   param {
     lr_mult: 1&lt;span&gt;@@ -345,5 +345,5 @@&lt;/span&gt;
   }
   inner_product_param {&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp; &amp;nbsp;num_output: 1000&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp; &amp;nbsp;num_output: 2&lt;/span&gt;
     weight_filler {
       type: "gaussian"&lt;span&gt;@@ -359,5 +359,5 @@&lt;/span&gt;
   name: "accuracy"
   type: "Accuracy"&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp;bottom: "fc8"&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp;bottom: "fc9"&lt;/span&gt;
   bottom: "label"
   top: "accuracy"&lt;span&gt;@@ -367,5 +367,5 @@&lt;/span&gt;
   name: "loss"
   type: "SoftmaxWithLoss"&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp;bottom: "fc8"&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp;bottom: "fc9"&lt;/span&gt;
   bottom: "label"
   top: "loss"&lt;span&gt;@@ -375,5 +375,5 @@&lt;/span&gt;
   name: "softmax"
   type: "Softmax"&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp;bottom: "fc8"&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp;bottom: "fc9"&lt;/span&gt;
   top: "softmax"
   include { stage: "deploy" }&lt;/pre&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我已经将所有的改进文件放在 src/alexnet-customized.prototxt 里面。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这一次，我们的准确率由 60% 多先是上升到 87.5%，然后到 96% 一路到 100%，同时损失度也稳步下降。五分钟后，我们的准确率到达了 100%，损失也只有 0.0009。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8M2VjGABJsyuCDtdZNUB3E2TDRQiael63c4s558PknnZgibSlB5LNSDdaA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;测试海马图像时以前的网络会出错，现在我们看到完全相反的结果，即使是小孩画的海马，系统也 100% 确定是海马，海豚的情况也一样。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8MwsP8X4UI9felfnvB2FptkApHOj9tUjiccd3wPfkeYlTqU7dw8JEKBuA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8MDDcRiaWq9icf9Yia4z6r01XrgBhpSkSxZTrNwNCZyZn9XXfM3PxcdMJZQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8ME7JicVZOHOL4L2katPvsib29KvpuavJBCsCywLY4N14JMQlxqTXP4icfA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;即使你认为可能很困难的图像，如多个海豚挤在一起，并且它们的身体大部分在水下，系统还是能识别。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8MvR2ErERZawZOcFdaDdFcvVpibqgicGsRE2RNftuVAc2tNm06rYE0Ldyw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;训练尝试 3：微调 GoogLeNet&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;像前面我们微调 AlexNet 模型那样，同样我们也能用 GoogLeNet。修改这个网络会有点棘手，因为你已经定义了三层全连接层而不是只有一层。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8MboCrlBN8GmexazlrsYBAlyz9RtxicgxJic92icIY20hftU7fN7oosq3pw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这个案例中微调 GoogLeNet，我们需要再次创建一个新的分类模型：我们需要重命名三个全连接分类层的所有 references，即 loss1/classifier、loss2/classifier 和 loss3/classifier，并重新定义结果类别数（num_output: 2）。下面是我们需要将三个分类层重新命名和从 1000 改变输出类别数为 2 的一些代码实现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;@@ -917,10 +917,10 @@&lt;/span&gt;
   exclude { stage: "deploy" }
 }
 layer {&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp;name: "loss1/classifier"&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp;name: "loss1a/classifier"&lt;/span&gt;
   type: "InnerProduct"
   bottom: "loss1/fc"&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp;top: "loss1/classifier"&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp;top: "loss1a/classifier"&lt;/span&gt;
   param {
     lr_mult: 1
     decay_mult: 1&lt;span&gt;@@ -930,7 +930,7 @@&lt;/span&gt;
     decay_mult: 0
   }
   inner_product_param {&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp; &amp;nbsp;num_output: 1000&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp; &amp;nbsp;num_output: 2&lt;/span&gt;
     weight_filler {
       type: "xavier"
       std: 0.0009765625&lt;span&gt;@@ -945,7 +945,7 @@&lt;/span&gt;
 layer {
   name: "loss1/loss"
   type: "SoftmaxWithLoss"&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp;bottom: "loss1/classifier"&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp;bottom: "loss1a/classifier"&lt;/span&gt;
   bottom: "label"
   top: "loss1/loss"
   loss_weight: 0.3&lt;span&gt;@@ -954,7 +954,7 @@&lt;/span&gt;
 layer {
   name: "loss1/top-1"
   type: "Accuracy"&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp;bottom: "loss1/classifier"&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp;bottom: "loss1a/classifier"&lt;/span&gt;
   bottom: "label"
   top: "loss1/accuracy"
   include { stage: "val" }&lt;span&gt;@@ -962,7 +962,7 @@&lt;/span&gt;
 layer {
   name: "loss1/top-5"
   type: "Accuracy"&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp;bottom: "loss1/classifier"&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp;bottom: "loss1a/classifier"&lt;/span&gt;
   bottom: "label"
   top: "loss1/accuracy-top5"
   include { stage: "val" }&lt;span&gt;@@ -1705,10 +1705,10 @@&lt;/span&gt;
   exclude { stage: "deploy" }
 }
 layer {&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp;name: "loss2/classifier"&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp;name: "loss2a/classifier"&lt;/span&gt;
   type: "InnerProduct"
   bottom: "loss2/fc"&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp;top: "loss2/classifier"&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp;top: "loss2a/classifier"&lt;/span&gt;
   param {
     lr_mult: 1
     decay_mult: 1&lt;span&gt;@@ -1718,7 +1718,7 @@&lt;/span&gt;
     decay_mult: 0
   }
   inner_product_param {&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp; &amp;nbsp;num_output: 1000&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp; &amp;nbsp;num_output: 2&lt;/span&gt;
     weight_filler {
       type: "xavier"
       std: 0.0009765625&lt;span&gt;@@ -1733,7 +1733,7 @@&lt;/span&gt;
 layer {
   name: "loss2/loss"
   type: "SoftmaxWithLoss"&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp;bottom: "loss2/classifier"&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp;bottom: "loss2a/classifier"&lt;/span&gt;
   bottom: "label"
   top: "loss2/loss"
   loss_weight: 0.3&lt;span&gt;@@ -1742,7 +1742,7 @@&lt;/span&gt;
 layer {
   name: "loss2/top-1"
   type: "Accuracy"&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp;bottom: "loss2/classifier"&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp;bottom: "loss2a/classifier"&lt;/span&gt;
   bottom: "label"
   top: "loss2/accuracy"
   include { stage: "val" }&lt;span&gt;@@ -1750,7 +1750,7 @@&lt;/span&gt;
 layer {
   name: "loss2/top-5"
   type: "Accuracy"&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp;bottom: "loss2/classifier"&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp;bottom: "loss2a/classifier"&lt;/span&gt;
   bottom: "label"
   top: "loss2/accuracy-top5"
   include { stage: "val" }&lt;span&gt;@@ -2435,10 +2435,10 @@&lt;/span&gt;
   }
 }
 layer {&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp;name: "loss3/classifier"&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp;name: "loss3a/classifier"&lt;/span&gt;
   type: "InnerProduct"
   bottom: "pool5/7x7_s1"&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp;top: "loss3/classifier"&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp;top: "loss3a/classifier"&lt;/span&gt;
   param {
     lr_mult: 1
     decay_mult: 1&lt;span&gt;@@ -2448,7 +2448,7 @@&lt;/span&gt;
     decay_mult: 0
   }
   inner_product_param {&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp; &amp;nbsp;num_output: 1000&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp; &amp;nbsp;num_output: 2&lt;/span&gt;
     weight_filler {
       type: "xavier"
     }&lt;span&gt;@@ -2461,7 +2461,7 @@&lt;/span&gt;
 layer {
   name: "loss3/loss"
   type: "SoftmaxWithLoss"&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp;bottom: "loss3/classifier"&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp;bottom: "loss3a/classifier"&lt;/span&gt;
   bottom: "label"
   top: "loss"
   loss_weight: 1&lt;span&gt;@@ -2470,7 +2470,7 @@&lt;/span&gt;
 layer {
   name: "loss3/top-1"
   type: "Accuracy"&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp;bottom: "loss3/classifier"&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp;bottom: "loss3a/classifier"&lt;/span&gt;
   bottom: "label"
   top: "accuracy"
   include { stage: "val" }&lt;span&gt;@@ -2478,7 +2478,7 @@&lt;/span&gt;
 layer {
   name: "loss3/top-5"
   type: "Accuracy"&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp;bottom: "loss3/classifier"&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp;bottom: "loss3a/classifier"&lt;/span&gt;
   bottom: "label"
   top: "accuracy-top5"
   include { stage: "val" }&lt;span&gt;@@ -2489,7 +2489,7 @@&lt;/span&gt;
 layer {
   name: "softmax"
   type: "Softmax"&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp;bottom: "loss3/classifier"&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp;bottom: "loss3a/classifier"&lt;/span&gt;
   top: "softmax"
   include { stage: "deploy" }
 }&lt;/pre&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我己经将完整的文件放在 src/googlenet-customized.prototxt 里面。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问题：这些神经网络的原文本（prototext）定义需要做什么修改吗？我们修改了全连接层名和输出结果分类类别数，那么在什么情况下其它参数也能或也需要修改的？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;回答：问得好，这也是我有一些疑惑的地方。例如，我知道我们能「固定」确切的神经网络层级，并保证层级之间的权重不改变。但是要做其它的一些改变就涉及到理解我们的神经网络层级是如何起作用的，这已经超出了这份入门向导的范围，同样也超出了这份向导作者现有的能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;就像我们对 AlexNet 进行微调，将下降的学习速率由 0.01 减少十倍到 0.001 一样。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：还有什么修改是对这些网络微调有意义的？遍历所有数据的次数（numbers of epochs）不同怎么样，改变批量梯度下降的大小（batch sizes）怎么样，求解器的类型（Adam、 AdaDelta 和 AdaGrad 等）呢？还有下降学习速率、策略（Exponential Decay、Inverse Decay 和 Sigmoid Decay 等）、步长和 gamma 值呢？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;问得好，这也是我有所疑惑的。我对这些只有一个模糊的理解，如果你知道在训练中如何修改这些值，那么我们很可能做出些改进，并且这需要更好的文档。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因为 GoogLeNet 比 AlexNet 有更复杂的网络构架，所以微调需要更多的时间。在我的笔记本电脑上，用我们的数据集重新训练 GoogLeNet 需要 10 分钟，这样才能实现 100% 的准确率，同时损失函数值只有 0.0070。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8McDVjtX1ayvNm8lQtmKVEicdJdev7GoLdLQOrBAfthqhyKkkHtpp085g/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;正如我们看到的 AlexNet 微调版本，我们修改过的 GoogLeNet 表现得十分惊人，是我们目前最好的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8MgbEicwKcW0E8QjK3EQ72QVdIoJbwePPQwhiaYk1SAUYibv0Iic8yzSAoibw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8MkDU08FiabKsEmYgkGh3zrrfosZ4p0iaUiaZUHAmGkEWHA4Vpibr5VMpwTg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8M7TfanqTgnyzrnVfnLBoDJlmao0ZKjic04BjT7LQuAmSOMsBECeTC9MQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;使用我们的模型&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们的网络在训练和检测之后，就可以下载并且使用了。我们利用 DIGITS 训练的每一个模型都有了一下载模型（Download Model）键，这也是我们在训练过程中选择不同 snapshots 的一种方法（例如 Epoch #30）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8MNB55cvRg1CnkLNjR752MV5N6X4HKAHh5iayWuxoa9pJtticuj77Cd6BA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在点击 Download Model 之后，你就会下载一个 tar.gz 的文档，里面包含以下文件：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;code style=" box-sizing: border-box; ; ; ; ; ; ; ; ; ; ; ; ; ; "&gt;deploy.prototxt
mean.binaryproto
solver.prototxt
info.json
original.prototxt
labels.txt
snapshot_iter_90.caffemodel
train_val.prototxt&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;在 Caffe 文档中对我们所建立的模型使用有一段非常好的描述。如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;一个网络是由其设计，也就是设计（prototxt）和权重（.caffemodel）决定。在网络被训练的过程中，网络权重的当前状态被存储在一个.caffemodel 中。这些东西我们可以从训练/检测阶段移到生产阶段。在它的当前状态中，网络的设计并不是为了部署的目的。在我们可以将我们的网络作为产品发布之前，我们通常需要通过几种方法对它进行修改：&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;1. 移除用来训练的数据层，因为在分类时，我们已经不再为数据提供标签了。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;2. 移除所有依赖于数据标签的层。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;3. 设置接收数据的网络。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;4. 让网络输出结果。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;DIGITS 已经为我们做了这些工作，它已经将我们 prototxt 文件中所有不同的版本都分离了出来。这些文档我们在使用网络时会用到：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;deploy.prototxt -是关于网络的定义，准备接收图像输入数据&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;mean.binaryproto - 我们的模型需要我们减去它处理的每张图像的图像均值，所产生的就是平均图像（mean image）。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;labels.txt - 标签列表 (dolphin, seahorse)，以防我们想要把它们打印出来，否则只有类别编号。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;snapshot_iter_90.caffemodel -这些是我们网络的训练权重。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;利用这些文件，我们可以通过多种方式对新的图像进行分类。例如，在 CAFFE_ROOT 中，我们可以使用 build/examples/cpp_classification/classification.bin 来对一个图像进行分类：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;$ cd $CAFFE_ROOT/build/examples/cpp_classification&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;$ ./classification.bin deploy.prototxt snapshot_iter_90.caffemodel mean.binaryproto labels.txt dolphin1.jpg&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这会产生很多的调试文本，后面会跟着对这两种分类的预测结果：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;0.9997 -「dolphin」&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;0.0003 -「seahorse」&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你可以在这个 Caffe 案例中查看完整的 C++ 源码：https://github.com/BVLC/caffe/tree/master/examples&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使用 Python 界面和 DIGITS 进行分类的案例：https://github.com/NVIDIA/DIGITS/tree/master/examples/classification&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，Caffe 的案例中还有一个非常好的 Python 演示：https://github.com/BVLC/caffe/blob/master/examples/00-classification.ipynb&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我希望可以有更多更好的代码案例、API 和预先建立的模型等呈现给大家。老实说，我找到的大多数代码案例都非常的简短，并且文档介绍很少——Caffe 的文档虽然有很多，但也有好有坏。对我来说，这似乎意味着会有人为初学者建立比 Caffe 更高级的工具。如果说在高级语言中出现了更加简单的模型，我可以用我们的模型「做正确的事情」；应该有人将这样的设想付诸行动，让使用 Caffe 模型变得像使用 DIGITS 训练它们一样简单。当然我们不需要对这个模型或是 Caffe 的内部了解那么多。虽然目前我还没有使用过 DeepDetect，但是它看起来非常的有趣，另外仍然还有其他我不知道的工具。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;结果&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;文章开头提到，我们的目标是编写一个使用神经网络对 data/untrained-samples 中所有的图像进行高准确度预测的程序。这些海豚和海马的图像是在训练数据或是验证数据时候从未使用过的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;未被训练过的海豚图像&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8M105rSLT1BfsDJJO4eiaDwWQEiamkGmCPtQskHiceq32SmeXePf7Rdc0gA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8Mx8rQzvwricOzO4ibS62RGTuU20WL9HhIh0kK5XibZWVjvV6DBhe3jabqg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8MOiaC8thCPvY1eNhYfnhVIDX8pqvUmVvHHAciafqBmJRSe83aH4P0iasHQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;未被训练过的海马图像&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8McfumnibfyFuzWxEmzpcOx2V3czsiajEFDtbA2Luia0nWicvHcGObuBOshw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8M8icCODwPZc2tBL6YWjMsicJldpOwOw0Iiarl3Fht2suNo8YtbFKRLuDLQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8MncqtxTlqxdwPaLxBUHJOEW9mZVsp6XAZ3vPugjCN31LzTNI60ZWK6Q/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;接下来，让我们一起来看看在这一挑战当中存在的三次尝试的结果：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;模型尝试 1： 从零开始构建 AlexNet（第 3 位）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;table width="888" style="width: 737px;"&gt;&lt;thead style="box-sizing: border-box;"&gt;&lt;tr style="box-sizing: border-box; background-color: rgb(255, 255, 255); border-top: 1px solid rgb(204, 204, 204);"&gt;&lt;th style="box-sizing: border-box; padding: 6px 13px; border-top-width: 1px; border-top-color: rgb(221, 221, 221);"&gt;Image&lt;/th&gt;&lt;th style="box-sizing: border-box; padding: 6px 13px; border-top-width: 1px; border-top-color: rgb(221, 221, 221);"&gt;Dolphin&lt;/th&gt;&lt;th style="box-sizing: border-box; padding: 6px 13px; border-top-width: 1px; border-top-color: rgb(221, 221, 221);"&gt;Seahorse&lt;/th&gt;&lt;th style="box-sizing: border-box; padding: 6px 13px; border-top-width: 1px; border-top-color: rgb(221, 221, 221);"&gt;Result&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody style="box-sizing: border-box;"&gt;&lt;tr style="box-sizing: border-box; background-color: rgb(255, 255, 255); border-top: 1px solid rgb(204, 204, 204);"&gt;&lt;td style="box-sizing: border-box; padding: 6px 13px;"&gt;&lt;a style="box-sizing: border-box; background-color: transparent; color: rgb(64, 120, 192);"&gt;dolphin1.jpg&lt;/a&gt;&lt;/td&gt;&lt;td style="box-sizing: border-box; padding: 6px 13px;"&gt;71.11%&lt;/td&gt;&lt;td style="box-sizing: border-box; padding: 6px 13px;"&gt;28.89%&lt;/td&gt;&lt;td style="box-sizing: border-box; padding: 6px 13px;"&gt;&lt;g-emoji alias="expressionless" fallback-src="https://assets-cdn.github.com/images/icons/emoji/unicode/1f611.png" ios-version="6.0" style=" box-sizing: border-box ; ; ; ; ; ; ; ;; font-size: 18px; line-height: 20px; vertical-align: middle; "&gt;</description>
      <pubDate>Tue, 03 Jan 2017 13:30:23 +0800</pubDate>
    </item>
    <item>
      <title>资源 | NIPS 2016上22篇论文的实现汇集</title>
      <link>http://www.iwgc.cn/link/4179110</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自niut-blanche&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;日前，LightOn CEO 兼联合创始人 Igor Carron 在其博客上放出了其收集到的 NIPS 2016 论文的实现（一共 22 个）。他写道：「在 Reddit 上，peterkuharvarduk 决定编译所有来自 NIPS 2016 的可用实现，我很高兴他使用了『实现（ implementation）』这个词，因为这让我可以快速搜索到这些项目。」除了 peterkuharvarduk 的推荐，这里的项目还包括 Reddit 其他用户和 Carron 额外添加的一些新公布的实现。最终他还重点推荐了 GitXiv：http://www.gitxiv.com 。另外，在本文后面还附带了机器之心关于 NIPS 2016 的文章列表，千万不要错过。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;1. 使用快速权重关注最近的过去（Using Fast Weights to Attend to the Recent Past）&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：https://arxiv.org/abs/1610.06258&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GitHub：https://github.com/ajarai/fast-weights&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;2. 通过梯度下降来学习通过梯度下降的学习（Learning to learn by gradient descent by gradient descent）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：https://arxiv.org/abs/1606.04474&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GitHub：https://github.com/deepmind/learning-to-learn&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;3. R-FCN：通过基于区域的全卷积网络的目标检测（R-FCN: Object Detection via Region-based Fully Convolutional Networks）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：https://arxiv.org/abs/1605.06409&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GitHub：https://github.com/Orpine/py-R-FCN&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4. 用于 k-均值的快速和可证明的 Good Seedings（Fast and Provably Good Seedings for k-Means）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：https://las.inf.ethz.ch/files/bachem16fast.pdf.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GitHub：https://github.com/obachem/kmc2&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;5. 如何训练生成对抗网络（How to Train a GAN）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GitHub：https://github.com/soumith/ganhacks&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;6. Phased LSTM：为长的或基于事件的序列加速循环网络训练（Phased LSTM: Accelerating Recurrent Network Training for Long or Event-based Sequences）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：https://arxiv.org/abs/1610.09513&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GitHub: https://github.com/dannyneil/public_plstm&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;7. 生成对抗式模仿学习（Generative Adversarial Imitation Learning）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：https://arxiv.org/abs/1606.03476&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GitHub：https://github.com/openai/imitation&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;8. 对抗式多类分类：一个风险最小化的角度（Adversarial Multiclass Classification: A Risk Minimization Perspective）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：https://www.cs.uic.edu/~rfathony/pdf/fathony2016adversarial.pdf&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GitHub：https://github.com/rizalzaf/adversarial-multiclass&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;9. 通过视频预测的用于物理交互的无监督学习（Unsupervised Learning for Physical Interaction through Video Prediction）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：https://arxiv.org/abs/1605.07157&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GitHub: https://github.com/tensorflow/models/tree/master/video_prediction&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;10.权重规范化：一种加速深度神经网络训练的简单重新参数化（ Weight Normalization: A Simple Reparameterization to Accelerate Training of Deep Neural Networks）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：https://arxiv.org/abs/1602.07868&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GitHub：https://github.com/openai/weightnorm&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;11. 全容量整体循环神经网络（Full-Capacity Unitary Recurrent Neural Networks）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：https://arxiv.org/abs/1611.00035&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GitHub：https://github.com/stwisdom/urnn&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;12. 带有随机层的序列神经模型（Sequential Neural Models with Stochastic Layers）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：https://arxiv.org/pdf/1605.07571.pdf&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GitHub：https://github.com/marcofraccaro/srnn&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;13. 带有快速局部化谱过滤的图上的卷积神经网络（Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：https://arxiv.org/abs/1606.09375&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GitHub：https://github.com/mdeff/cnn_graph&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;14. Interpretable Distribution Features with Maximum Testing Power&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：https://papers.nips.cc/paper/6148-interpretable-distribution-features-with-maximum-testing-power.pdf&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GitHub：https://github.com/wittawatj/interpretable-test/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;15. 使用神经网络组成图模型，用于结构化表征和快速推理(Composing graphical models with neural networks for structured representations and fast inference )&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：https://arxiv.org/abs/1603.06277&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GitHub：https://github.com/mattjj/svae&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;16. 使用张量网络的监督学习（Supervised Learning with Tensor Networks）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：https://arxiv.org/abs/1605.05775&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GitHub：https://github.com/emstoudenmire/TNML&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;17. 使用贝叶斯条件密度估计的模拟模型的快速无ε推理（Fast ε-free Inference of Simulation Models with Bayesian Conditional Density Estimation）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：https://arxiv.org/abs/1605.06376&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GitHub：https://github.com/gpapamak/epsilon_free_inference&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;18. 用于概率程序的贝叶斯优化（Bayesian Optimization for Probabilistic Programs）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：http://www.robots.ox.ac.uk/~twgr/assets/pdf/rainforth2016BOPP.pdf&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GitHub：https://github.com/probprog/bopp&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;19. PVANet：用于实施目标检测的轻权重深度神经网络（PVANet: Lightweight Deep Neural Networks for Real-time Object Detection）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：https://arxiv.org/abs/1611.08588&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GitHub：https://github.com/sanghoon/pva-faster-rcnn&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;20. 数据编程：快速创建大训练集（Data Programming: Creating Large Training Sets Quickly）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：https://arxiv.org/abs/1605.07723&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;代码： snorkel.stanford.edu&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;21. 用于架构学习的卷积神经结构（Convolutional Neural Fabrics for Architecture Learning）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：https://arxiv.org/pdf/1606.02492.pdf&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GitHub：https://github.com/shreyassaxena/convolutional-neural-fabrics&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;22. 价值迭代网络（Value Iteration Networks）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：https://arxiv.org/abs/1602.02867&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;TensorFlow 实现：https://github.com/TheAbhiKumar/tensorflow-value-iteration-networks&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;原作者的 Theano 实现：https://github.com/avivt/VIN&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;blockquote&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;机器之心 NIPS 2016 文章列表&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721406&amp;amp;idx=1&amp;amp;sn=8251dfebd3c360d180339c34c4710fa7&amp;amp;chksm=871b0800b06c81160244fcda78d7816da8ec31d5fbec546ba6e36241e6d32c0ca943ce9ce73d&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721406&amp;amp;idx=1&amp;amp;sn=8251dfebd3c360d180339c34c4710fa7&amp;amp;chksm=871b0800b06c81160244fcda78d7816da8ec31d5fbec546ba6e36241e6d32c0ca943ce9ce73d&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;"&gt;&lt;span&gt;深度 | NIPS 2016最全盘点：主题详解、前沿论文及下载资源（附会场趣闻）&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721081&amp;amp;idx=1&amp;amp;sn=d557968703d4af879b5cf6461069dacd&amp;amp;chksm=871b0f47b06c865185865fcd5ef92af7726e84ae9e689b7ced9986a08c9fe3113df296a8469a&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;"&gt;&lt;span&gt;独家 | 吴恩达 NIPS 2016 演讲现场直击：如何使用深度学习开发人工智能应用？&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721198&amp;amp;idx=1&amp;amp;sn=accdd701751ab9678285f3cdf073304f&amp;amp;chksm=871b0fd0b06c86c6fa49bbae856898920e26c4456bc02be42a947d23fe2b593110e911bf54da&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;"&gt;&lt;span&gt;独家 | 机器之心对话 NIPS 2016 最佳论文作者：如何打造新型强化学习观？&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721284&amp;amp;idx=1&amp;amp;sn=427e7f45c8253ab22a3960978409f5d1&amp;amp;chksm=871b087ab06c816c424ad03810be3e1b3aa9d6e99a5f325047796f110d178a07736f667d1a10&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;"&gt;&lt;span&gt;独家 | GAN 之父 NIPS 2016 演讲现场直击：全方位解读生成对抗网络的原理及未来&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721325&amp;amp;idx=4&amp;amp;sn=d570f04d737d09c1b1cebd962755af3f&amp;amp;chksm=871b0853b06c8145985f8c2c5ac7445118f18ce35532c0389b0e5ec24a7a1c4b841fe81280de&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;"&gt;&lt;span&gt;资源 | Bengio 和 LeCun 在 NIPS 2016 上的演讲&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718527&amp;amp;idx=2&amp;amp;sn=8d054db2eca7a0b25190a6cc050fc1d7&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;"&gt;&lt;span&gt;学界 | NIPS 2016 公布 571 篇接收论文&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721033&amp;amp;idx=2&amp;amp;sn=d0d143e72cf4a637a617be356008b323&amp;amp;chksm=871b0f77b06c86615ed6a59ede1bee6cbff68b6ec08fb9b300e347d9c34b931aabdc3d0fee4e&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;"&gt;&lt;span&gt;学界 | NIPS 2016 论文 SpotlightVideo 精选，三分钟了解一项最新研究进展&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721081&amp;amp;idx=3&amp;amp;sn=111d844d50c98582695d04fa2b252c89&amp;amp;chksm=871b0f47b06c86514ac934c44fe4df92f5d4209f209b94b4c89d1f138492dbaf7e47479803a3&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;"&gt;&lt;span&gt;学界 | NIPS 2016 现场：谷歌发布 28 篇机器学习论文&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720969&amp;amp;idx=2&amp;amp;sn=d1fae404486906125e01b5def7e26d94&amp;amp;chksm=871b0eb7b06c87a1d3e7d0b29e8c8f9e4c86f4949d04b0485df1b45823555a6c88a25ccf4dc4&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;"&gt;&lt;span&gt;学界 | DeepMind NIPS 2016 论文盘点（Part1）：强化学习正大步向前&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721102&amp;amp;idx=2&amp;amp;sn=cbc44a149457d31ed9a8bbe825f09378&amp;amp;chksm=871b0f30b06c8626bb94cbd7a08fd4a5c8bec747082f49280fbd27e9c87c965de983a279796c&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;"&gt;&lt;span&gt;学界 | DeepMind NIPS 2016 论文盘点（Part2）：无监督学习的新进展&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721081&amp;amp;idx=4&amp;amp;sn=af93b221818ff9f564b372de5fc1958f&amp;amp;chksm=871b0f47b06c8651744e4b2819322f4026b248f4474f619c7248f604dafe8490405d70d3d1f3&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;"&gt;&lt;span&gt;业界 | NIPS 2016 现场：LeCun 联同英伟达，推深度学习教学工具包&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721198&amp;amp;idx=4&amp;amp;sn=b2f6412538b2458116cd40f53bcdc23b&amp;amp;chksm=871b0fd0b06c86c6866c3e682aa9a15187154a67ae4b7df3d319cc2233fb5761c53da45abed1&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;"&gt;&lt;span&gt;业界 | 波士顿动力最新机器人亮相 NIPS 2016，但还未用到机器学习&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 03 Jan 2017 13:30:23 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 日本保险公司引入IBM Watson，这次人工智能代替了34名白领</title>
      <link>http://www.iwgc.cn/link/4179113</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Quartz&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李泽南、蒋思源&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8MZjFajRSpffAMibVU4akH0O7ibib7ibkexkK6TRxibHO773lPovySFQrnznw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在人们对于自动化的大部分注意力正集中在工业机器人、自动驾驶汽车等领域，很多学者们认为它们将从根本上改变劳动力的形式，有可能会代替数百万现有低技术工作岗位，一些国家的政府已经在为此&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721644&amp;amp;idx=1&amp;amp;sn=bfb26761cf5d118d4ed1dbafd04319f4&amp;amp;chksm=871b0912b06c8004ce420b78d657b9eee138c0e2990100ecfd759925804a0d248189b6014ba8&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721644&amp;amp;idx=1&amp;amp;sn=bfb26761cf5d118d4ed1dbafd04319f4&amp;amp;chksm=871b0912b06c8004ce420b78d657b9eee138c0e2990100ecfd759925804a0d248189b6014ba8&amp;amp;scene=21#wechat_redirect"&gt;制定政策&lt;/a&gt;。但对于人工智能而言，需要知识背景的白领工作似乎更加容易，在机器人客服、&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720780&amp;amp;idx=2&amp;amp;sn=cc64372d82354d3212baf84fce230928&amp;amp;chksm=871b0e72b06c8764cfe09654fa457da0fd764c0684d83b7fcd887c19401b3b4d623a07ab2bb9&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720780&amp;amp;idx=2&amp;amp;sn=cc64372d82354d3212baf84fce230928&amp;amp;chksm=871b0e72b06c8764cfe09654fa457da0fd764c0684d83b7fcd887c19401b3b4d623a07ab2bb9&amp;amp;scene=21#wechat_redirect"&gt;律师&lt;/a&gt;之后，自动化已经开始席卷金融行业。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;日本富国生命保险（Fukoku Mutual Life Insurance）近日宣布他们将要从 2017 年 1 月开始使用「IBM Watson Explorer」，代替 34 位保险索赔业务员的职位。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「人工智能将扫描被保险人的医疗记录与其他信息来决定保险赔付的金额，」富国生命在一份新闻稿中写道。「受伤定性、患者病史和治疗形式都将纳入理赔金额的考量。人工智能系统将自动搜索数据，完成数据计算任务，帮助该公司剩余的员工更快地处理理赔事宜。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;根据日本《每日新闻》的报道，在此项目中，富国生命将斥资 170 万美元（约合 2 亿日元）引入 IBM 公司的人工智能系统，随后每年的维持费用约为 12.8 万美元。通过使用人工智能系统，该公司将在未来每年节约 110 万美元的开支，这意味着此项投资两年后即可收回成本。「Watson AI 的效率预计会比人类员工高 30%，」富国生命保险的发言人表示。「本公司已经受益于 IBM 的新技术，类似的人工智能系统正被用于处理客户投诉电话等任务。如使用软件识别客户语音，将语音转换为文字，而后分析这些话的内容。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一些美国公司也在使用情绪分析软件来为顾客提供服务。这类软件一大优势就是可以获知顾客的情绪，当顾客对自助服务系统不满意，系统将自动转接到人工服务上去。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;《每日新闻》报告称，另有三家日本保险公司正在测试或引入人工智能系统，它们希望通过智能系统自动完成一些技术性工作，如为顾客提供合理的金融计划。以色列一家保险初创公司 Lemonade 已经募集了 6000 万美元，其 CEO Daniel Schreiber 称他们的未来目标是「用机器人和机器学习替代经纪人与文书工作」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;像 IBM Watson 这样的人工智能系统正自信满满地准备倾覆众多知识技术职位，如保险和金融服务。对此，哈佛商业评论（Harvard Business Review）在一篇报道中认为，这是因为许多工作能「由可以编纂成标准步骤的工作流程和基于标准格式的数据进行决策组成。」引入人工智能意味着提高现有员工生产力，还是机器完全替换人类工作岗位？一切还有待观察。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「几乎所有的工作都面临计算机在短期内无法处理的关键问题，」哈佛商业评论写道。「但是，我们不得不承认越来越多的知识型工作正在屈服于人工智能的崛起。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文链接：http://qz.com/875491/japanese-white-collar-workers-are-already-being-replaced-by-artificial-intelligence/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 03 Jan 2017 13:30:23 +0800</pubDate>
    </item>
    <item>
      <title>总结 | 2016年最值得读的自然语言处理领域Paper</title>
      <link>http://www.iwgc.cn/link/4179114</link>
      <description>&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;引言&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;经过大家的投票和补充，paperweekly选出了15篇2016年最值得读的自然语言处理领域相关Paper，排序按照时间顺序，覆盖了几大热门研究方向。&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/h1&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;1、Learning to Compose Neural Networks for Question Answering&lt;/strong&gt;&lt;/h1&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="作者" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Jacob Andreas, Marcus Rohrbach, Trevor Darrell, Dan Klein&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="单位" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;单位&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Department of Electrical Engineering and Computer Sciences&lt;br/&gt;University of California, Berkeley&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="关键词" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;关键词&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Question Answering&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="Text understanding with the attention sum reader network" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;2、Text understanding with the attention sum reader network&lt;/strong&gt;&lt;/h1&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="作者" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Rudolf Kadlec, Martin Schmid, Ondrej Bajgar, Jan Kleindienst&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="单位" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;单位&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;IBM Watson&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="关键词" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;关键词&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Machine Reading Comprehension&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="Improving Information Extraction by Acquiring External Evidence with Reinforcement Learning" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;3、Improving Information Extraction by Acquiring External Evidence with Reinforcement Learning&lt;/strong&gt;&lt;/h1&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="作者" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Karthik Narasimhan, Adam Yala, Regina Barzilay&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="单位" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;单位&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;CSAIL, MIT&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="关键词" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;关键词&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Information Extraction; Reinforcement Learning&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="Pointing the Unknown Words" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;4、Pointing the Unknown Words&lt;/strong&gt;&lt;/h1&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="作者" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Caglar Gulcehre, Sungjin Ahn, Ramesh Nallapati, Bowen Zhou, Yoshua Bengio&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="单位" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;单位&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Universite de Montr´eal&lt;br/&gt;IBM T.J. Watson Research&lt;br/&gt;CIFAR Senior Fellow&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="关键词" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;关键词&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Unknown Words&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="Sequence-to-Sequence Learning as Beam-Search Optimization" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;5、Sequence-to-Sequence Learning as Beam-Search Optimization&lt;/strong&gt;&lt;/h1&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="作者" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Sam Wiseman, Alexander M. Rush&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="单位" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;单位&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;School of Engineering and Applied Sciences, Harvard University&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="关键词" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;关键词&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Seq2Seq; Beam Search&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="SQuAD: 100,000+ Questions for Machine Comprehension of Text" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;6、SQuAD: 100,000+ Questions for Machine Comprehension of Text&lt;/strong&gt;&lt;/h1&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="作者" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, Percy Liang&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="单位" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;单位&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Computer Science Department&lt;br/&gt;Stanford University&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="关键词" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;关键词&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Machine Reading Comprehension; Dataset&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="End-to-End Reinforcement Learning of Dialogue Agents for Information Access" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;7、End-to-End Reinforcement Learning of Dialogue Agents for Information Access&lt;/strong&gt;&lt;/h1&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="作者" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Bhuwan Dhingra, Lihong Li, Xiujun Li, Jianfeng Gao, Yun-Nung Chen, Faisal Ahmed, Li Deng&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="单位" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;单位&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;School of Computer Science, Carnegie Mellon University&lt;br/&gt;Microsoft Research&lt;br/&gt;National Taiwan University&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="关键词" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;关键词&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Reinforcement Learning; Dialogue System&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="ReasoNet: Learning to Stop Reading in Machine Comprehension" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;8、ReasoNet: Learning to Stop Reading in Machine Comprehension&lt;/strong&gt;&lt;/h1&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="作者" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Yelong Shen, Po-Sen Huang, Jianfeng Gao, Weizhu Chen&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="单位" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;单位&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Microsoft Research Redmond&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="关键词" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;关键词&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Machine Reading Comprehension&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="Personalizing a Dialogue System with Transfer Learning" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;9、Personalizing a Dialogue System with Transfer Learning&lt;/strong&gt;&lt;/h1&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="作者" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Kaixiang Mo, Shuangyin Li, Yu Zhang, Jiajun Li, Qiang Yang&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="单位" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;单位&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;The Hong Kong University of Science and Technology&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="关键词" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;关键词&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Dialogue System; Transfer Learning&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="LightRNN Memory and Computation-Efficient Recurrent Neural Network" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;10、LightRNN Memory and Computation-Efficient Recurrent Neural Network&lt;/strong&gt;&lt;/h1&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="作者" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Xiang Li, Tao Qin, Jian Yang, Tie-Yan Liu&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="单位" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;单位&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Nanjing University of Science and Technology&lt;br/&gt;Microsoft Research Asia&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="关键词" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;关键词&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;New Recurrent Neural Network&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;11、Dual Learning for Machine Translation&lt;/strong&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="作者" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Yingce Xia, Di He, Tao Qin, Liwei Wang, Nenghai Yu, Tie-Yan Liu, Wei-Ying Ma&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="单位" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;单位&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;University of Science and Technology of China&lt;br/&gt;Key Laboratory of Machine Perception (MOE), School of EECS, Peking University&lt;br/&gt;Microsoft Research&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="关键词" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;关键词&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Dual Learning; Neural Machine Translation&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="Neural Machine Translation with Reconstruction" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;12、Neural Machine Translation with Reconstruction&lt;/strong&gt;&lt;/h1&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="作者" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Zhaopeng Tu, Yang Liu, Lifeng Shang, Xiaohua Liu, Hang Li&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="单位" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;单位&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Noah’s Ark Lab, Huawei Technologies&lt;br/&gt;Department of Computer Science and Technology, Tsinghua University&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="关键词" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;关键词&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Neural Machine Translation&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="Linguistically Regularized LSTMs for Sentiment Classification" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;13、Linguistically Regularized LSTMs for Sentiment Classification&lt;/strong&gt;&lt;/h1&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="作者" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Qiao Qian, Minlie Huang, Xiaoyan Zhu&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="单位" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;单位&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;State Key Lab. of Intelligent Technology and Systems, National Lab. for Information Science and Technology&lt;br/&gt;Dept. of Computer Science and Technology, Tsinghua University&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="关键词" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;关键词&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Sentiment Classification; LSTM&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="Google’s Multilingual Neural Machine Translation System: Enabling Zero-Shot Translation" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;14、Google’s Multilingual Neural Machine Translation System: Enabling Zero-Shot Translation&lt;/strong&gt;&lt;/h1&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="作者" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Melvin Johnson, Mike Schuster, Quoc V. Le, Maxim Krikun, Yonghui Wu, Zhifeng Chen, Nikhil Thorat, Fernanda Viégas, Martin Wattenberg, Greg Corrado, Macduff Hughes, Jeffrey Dean&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="单位" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;单位&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Google&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="关键词" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;关键词&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Multilingual Neural Machine Translation; Zero-Shot&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;br/&gt;&lt;/h1&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="Language Modeling with Gated Convolutional Networks" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;15、Language Modeling with Gated Convolutional Networks&lt;/strong&gt;&lt;/h1&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="作者" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Yann N. Dauphin, Angela Fan, Michael Auli, David Grangier&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="单位" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;单位&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Facebook AI Research&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="关键词" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;关键词&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Language Modeling; Gated CNN&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;如果您觉得还有非常不错的NLP Paper没有出现在这个list中，请留言或移步到此处进行补充或评论&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnS1GUib7okSxFQF1fQwc5xLtCEp2FncdcyYwOJ5EZTuTS24gictT5rahQMYRhaJLJIaQJvkCibJdcng/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;下载&lt;/strong&gt;&lt;/span&gt;所有Paper请戳这里&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnS1GUib7okSxFQF1fQwc5xLAN8KauGFCvk06rMLP05gCW2tXBob9icLDWXichbOOWIs83uxViaBP7Yzw/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;关于PaperWeekly&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;PaperWeekly是一个分享知识和交流学问的学术组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;微信公众号：PaperWeekly&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkSMlEJFo90NY8rCXr3mJMBibduVHxMKSHzQtVkHz8kNwpjCKBiccGuqLE0WpPuAbdtEs6cTF5iabpAQ/640?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;微博账号：PaperWeekly（&lt;a target="_blank" rel="external" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;http://weibo.com/u/2678093863&lt;/a&gt;&amp;nbsp;）&lt;br/&gt;微信交流群：微信+ zhangjun168305（请备注：加群交流或参与写paper note）&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 03 Jan 2017 13:30:23 +0800</pubDate>
    </item>
    <item>
      <title>深度 | 对比深度学习十大框架：TensorFlow最流行但并不是最好</title>
      <link>http://www.iwgc.cn/link/4167586</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Medium&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀、朱思颖、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;2016 年已经过去，BEEVA Labs 数据分析师 Ricardo Guerrero Gomez-Ol 近日在 Medium 上发表了一篇文章，盘点了目前最流行的深度学习框架。为什么要做这一个盘点呢？他写道：「我常听到人们谈论深度学习——我该从哪里开始呢？TensorFlow 是现在最流行的吧？我听说 Caffe 很常用，但会不会太难了？在 BEEVA Labs，我们常常需要应对许多不同的深度学习库，所以我希望能够将我们的发现和感想分享出来，帮助那些刚刚进入深度学习这一美丽世界的人。」&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;TensorFlow&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://www.tensorflow.org/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于那些听说过深度学习但还没有太过专门深入的人来说，TensorFlow 是他们最喜欢的深度学习框架，但在这里我要澄清一些事实。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 TensorFlow 的官网上，它被定义为「一个用于机器智能的开源软件库」，但我觉得应该这么定义：TensorFlow 是一个使用数据流图（data flow graphs）进行数值计算的开源软件库。在这里，他们没有将 TensorFlow 包含在「深度学习框架」范围内，而是和 Theano 一起被包含在「图编译器（graph compilers）」类别中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在结束了 Udacity 的 Deep Learning 课程（https://www.udacity.com/course/deep-learning--ud730）之后，我的感觉是 TensorFlow 是一个非常好的框架，但是却非常低层。使用 TensorFlow 需要编写大量的代码，你必须一遍又一遍地重新发明轮子。而且我并不是唯一一个这么想的人。Andrej Karpathy 在 Twitter 上就多次吐过槽：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8L6gHxjMvmaS6FWuRBT09iclGVaiaibuJKa679nxARLzR4bVjTxTvicl27s3DYOUv9dmGnZNzWh7icm4g/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;推文：我希望 TensorFlow 能标准化我们的代码，但它是低层面的，所以我们在其上面的层上分道扬镳了：Slim、PrettyTensor、Keras、TFLearn ...&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8L6gHxjMvmaS6FWuRBT09icZotWP3DpTVYxCy3Rhq9HLCjTW2lAl3wFnUs4VMs1BjIeG4LF4fsfMA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;比如：我们在 OpenAI 使用 TensorFlow，但我们似乎都更喜欢其它框架，我们有些人还写自定义代码。叹&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;几个月前，我去参加了「Google Experts Summit: TensorFlow, Machine Learning for everyone, with Sergio Guadarrama」。Sergio 是开发 TensorFlow 的一位工程师，但他在会上没有展示 TensorFlow，而是展示了一个在 TensorFlow 上工作的更高层的库 tf.contrib：https://www.tensorflow.org/tutorials/tflearn/。我的看法是：他们内部已经意识到如果要让更多人使用 TensorFlow，他们就需要以更高的抽象水平在其上创建一些层，从而简化 TensorFlow 的使用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;TensorFlow 支持 Python 和 C++，也允许在 CPU 和 GPU 上的计算分布，甚至支持使用 gRPC 进行水平扩展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;总结：TensorFlow 非常好，但你必须了解它好在哪里。如果你不想什么事都自己手动去做和重新发明轮子，你可以使用更简单的库（安利一下 Keras）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Theano&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：http://deeplearning.net/software/theano/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Theano 是最老牌和最稳定的库之一。据我所知，深度学习库的开端不是 Caffe 就是 Theano。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;和 TensorFlow 类似，Theano 是一个比较低层的库。也因此它并不适合深度学习，而更适合数值计算优化。它支持自动的函数梯度计算，带有 Python 接口并集成了 Numpy，这使得它从一开始就成为了通用深度学习领域最常使用的库之一。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今天，Theano 依然效果良好，但由于它不支持多 GPU 和水平扩展，在 TensorFlow 的热潮下（它们针对同一个领域），Theano 已然开始被遗忘了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Keras&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://keras.io/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「You have just found Keras.」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;上面这句话是你打开文档页面时看到的第一句话。我还记得我第一次发现 Keras 的时候。那时候我正在柏林解决 Data Science Retreat 的最后一个项目，为此我努力进入了深度学习库的世界。我在起步时就已经有了足够的深度学习知识，但我没有时间自己手动编写功能，也没有时间探索和学习一个新的库（截止时间不到 2 个月，而我还有课要上）。然后我发现了 Keras。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我真的很喜欢 Keras，因为它的句法是相当明晰的，它的文档也非常好（尽管相对较新），而且它支持我已经掌握的语言 Python。它的使用非常简单轻松；我们也能很直观地了解它的指令、函数和每个模块之间的链接方式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Keras 是一个非常高层的库，可以工作在 Theano 和 TensorFlow（可以配置）之上。另外，Keras 强调极简主义——你只需几行代码就能构建一个神经网络。在这里你可以比较一下 Keras 和 TensorFlow 实现相同功能时所需的代码：https://gist.github.com/ricgu8086/0ba44ce3aab19ec50425383a4d778b50&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Lasagne&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：http://lasagne.readthedocs.io/en/latest/index.html&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Lasagne 是一个工作在 Theano 之上的库。它的使命是简化一点深度学习算法之下的复杂计算，同时也提供了一个更加友好的接口（也是 Python 的）。这是一个老牌的库，并且很长时间以来它都是一个扩展能力很强的工具；但在我看来，它的发展速度赶不上 Keras。它们的适用领域都差不多，但 Keras 有更好的文档、也更完整。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Caffe&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：http://caffe.berkeleyvision.org/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Caffe 不只是最老牌的框架之一，而是老牌中的老牌。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在我看来，Caffe 有非常好的特性，但也有一些小缺点。起初的时候它并不是一个通用框架，而仅仅关注计算机视觉，但它具有非常好的通用性。在我们实验室的实验中，CaffeNet 架构的训练时间在 Caffe 中比在 Keras 中（使用了 Theano 后端）少 5 倍。Caffe 的缺点是它不够灵活。如果你想给它来一点新改变，那你就需要使用 C++ 和 CUDA 编程，不过你也可以使用 Python 或 Matlab 接口进行一些小改变。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Caffe 的文档非常贫乏。你需要花大量时间检查代码才能理解它（Xavier 初始化有什么用？Glorot 是什么？）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Caffe 的最大缺点之一是它的安装。它需要解决大量的依赖包……我曾经安装过 Caffe 两次，真正痛苦至极。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但要清楚，Caffe 并不是一无是处。在投入了生产的计算机视觉系统的工具上，Caffe 是无可争议的领导者。它非常稳健非常快速。我的建议是：用 Keras 进行实验和测试，然后迁移到 Caffe 中进行生产。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;DSSTNE&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://github.com/amznlabs/amazon-dsstne&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;DSSTNE 的发音同 Destiny，是一个酷劲十足的框架却总是被忽略。为什么？除去其他的因素不谈，原因在于这个框架不具有普适性，不是为一般常见任务所设计的。DSSTNE 框架只做一件事——推荐系统，但把这件事做到了极致。既不是为研究而设计，也不是为测试 idea 而设计（来源其官方网站的宣传语），DSSTNE 框架是为量产而设计。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们已在 BEEVA 上做一些实验测试了，目前我已经感觉到这是一个运行非常快的工具并且能够得到非常好的运行结果（平均准确率均值——mAP 很高）。为了达到这一速度，DSSTNE 框架用 GPU 运行，这也是它的弊端之一：不同于篇中分析的其他框架或者库，这个框架不支持使用者随意在 CPU 和 GPU 中切换，而这可能会对有些尝试有用，但我们在 DSSTNE 里做这样的尝试时是不被框架所允许的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其他的感受就是迄今为止 DSSTNE 还不是一个足够成熟的项目，而且它封装的太严密了（「black box」）。如果我们想深入了解这个框架的运行机制是什么，我们必须且只能去看它的源码，并且你需要完成很多必须完成的设置（「TODO」）才可以看到。同时，关于这个框架的在线教程不多，而能让开发者进行操作尝试的指导就更少了。我的意见是再等 4 个月看看 DSSTNE 的最新版本。不能不说 DSSTEN 的确是一个很有意思的项目但还需要一点成长空间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;还想说明一点，这个框架对编程能力没有要求。DSSTNE 框架通过其终端的命令行来执行相关操作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;到目前为止，很多我知道也很流行的框架和库我还没有用过，我不能给出更多具体的细节。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Torch&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：http://torch.ch/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这个世界上每天仍有很多战争，但是一个优秀的「勇士」（西班牙语「Guerrero」）必须熟知哪些战争是需要去参加作战的，哪些是可以选择不参与的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Torch 是一个很著名的框架，因巨头 Facebook 的人工智能研究所用的框架是 Torch，并且在被谷歌收购之前 DeepMind 也是用的 Torch（收购之后 DeepMind 转向了 TensorFlow）。Torch 的编程语言是 Lua，这就是我刚才所谈的「战争」的具体所指。在目前深度学习编程语言绝大部分以 Python 实现为主的大趋势下，一个以 Lua 为编程语言的框架的最大劣势莫过于此。我从未用使用过这个语言，如果我想使用 Torch 这个工具，毫无疑问我需要先学习 Lua 语言然后才能使用 Torch。这固然是一个合理的过程，但就我个人情况来说，我偏向于用 Python、Matlab 或者 C++的实现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;MXNet&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://github.com/dmlc/mxnet&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;mxnet 是一个支持大多数编程语言的框架之一，包括 Python，R，C++，Julia 等。但我觉得使用 R 语言的开发者会特别偏爱 mxnet，因为至今为止还是 Python 以不可置疑的态势称霸深度学习语言的（Python 与 R 的对决，猜猜我会站哪边？:-p）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;老实说，在此之前我并没有很关注 mxnet。但是当亚马逊 AWS 宣布选择 mxnet 作为其深度学习 AMI 的库时触发我开始关注 mxnet。我必须去了解一下。后来我获知亚马逊把 mxnet 列为其深度学习的参考库并宣称其巨大的横向扩展能力。我感觉到这里面有一些新的改变发生而且我必须深入了解。这也是为什么我们 2017 的 BEEVA 的技术测试名单里有 mnxet 的原因。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我对多 GPU 的扩展能力有点疑虑并且我很原意去了解这样实验的更多细节，但目前我还是对 mxnet 持怀疑态度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;DL4J&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://deeplearning4j.org/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我接触这一库，是因为它的 documentation。当时我正在寻找受限玻尔兹曼机、自编码器，在 DL4J 中找到了这两个 documentation。里面的文件很清楚，有理论，有代码案例。我必须得说 DL4J 的 documentation 简直是艺术品，其他库在记录代码的时候需要向它学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;DL4J 背后的公司 Skymind 意识到，虽然在深度学习圈内 Python 是老大，但大部分程序员起自 Java，所以需要找到一个解决方案。DL4J 兼容 JVM，也适用 Java、Clojure 和 Scala，随着 Scala 的起起落落，它也被很多有潜力的创业公司使用，所以我还会继续紧追这个库。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此外，Skymind 的 twitter 账户非常活跃，不断公开最新的科学论文、案例和教程，及其推荐大家关注。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Cognitive Toolkit&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://github.com/Microsoft/CNTK&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;认知工具包（Cognitive Toolkit）之前被大家所知的缩略是 CNTK，但是最近又重命名回归到 Cognitive Toolkit，很可能是想沾最近微软认知服务（Microsoft Cognitive services）的光。在公开的基准测试上的表现来看，这个工具似乎很强劲，支持纵向和横向的推移。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前为止，Cognitive Toolkit 似乎不是很流行。我并没有读到很多关于使用这个库的博客、在线实验案例或者在 Kaggle 里的相关评论。但是对我来说，一个背靠微软研究的框架特别强调自己的推移能力让我觉得有些奇怪，毕竟微软研究团队可是在语音识别上打破世界纪录并逼近人类水准。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我在查看他们项目百科的一个范例的时候了解到 Cognitive Toolkit 在 Python 上的语法和 Keras 是非常相类似的（Cognitive Toolkit 也支持 C++），这不禁让我在想（并不是确认）Keras 才是正确的方式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;结论&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我的结论是：如果你想进入这一领域，你应该首先学习 Python。尽管这一领域还支持其它很多语言，但 Python 是应用范围最广而且最简单的一个。但是为什么要选择 Python 呢——毕竟 Python 速度这么慢？因为大多数的库都使用的是符号式语言（symbolic language）方法而非命令式语言（imperative language）方法。解释一下也就是说：不是一条接一条地执行你的指令，而是根据你给出的所有指令创建一个计算图（computing graph）。这个图被内部优化和编译成可执行的 C++ 代码。这样你就能同时利用上两个世界的最优之处：Python 带来的开发速度和 C++ 带来的执行速度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人们对深度学习的兴趣越来越大了，但人们并不愿意等待算法训练所需的大量计算时间（而且我说的是 GPU，想都不要想只使用 CPU）。这也是多 GPU 支持、多机器上的水平扩展甚至定制硬件最近开始得势的原因。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深度学习领域非常活跃、易变。很可能我现在所说的在 2017 年的中旬就变了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我的建议是，如果你是初学者，使用 Keras，如果不是初学者，也可以使用它。如果你参加过 Kaggle 比赛，你肯定注意到了 Kaggle 的两大巨星：Keras 和 XGBoost。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文链接：&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;https://medium.com/@ricardo.guerrero/deep-learning-frameworks-a-review-before-finishing-2016-5b3ab4010b06#.z8zuthuwm&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 02 Jan 2017 12:52:58 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 中国担前锋：外媒谈亚洲人工智能的潜力</title>
      <link>http://www.iwgc.cn/link/4167587</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自SCMP&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：蒋思源、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote style="color: rgb(62, 62, 62); font-size: 16px; white-space: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/blockquote&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;在取得突破性进展后的一年，专家们认为通过人工智能人们日常生活正处于濒临变革的边缘，亚洲能在这个变革中取得领导地位。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8L6gHxjMvmaS6FWuRBT09iceibiaK2wp8VzzIhEOSibS3iaWuh5gyJKCT9YcIKbCcVKod8hkU1HOYlaicQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;由中国大学生设计的一种人形双足机器人在北京世界机器人会议展示。领先技术专家说，今年可能在智能机器模拟人类的发展上实现突破性的一年。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尝试在谷歌搜索框中输入「机器」，这个人工智能驱动的搜索引擎中最可能出现在搜索结果前几位的可能就是「机器智能来了（The Machines are Coming）」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能在 2016 年取得备受瞩目的进步后，领先技术专家说，今年可能是智能机器在模拟人类上实现突破性发展的一年。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;专家说亚洲虽然现在在人工智能领域上还落后于硅谷，但是与该领域的技术前列结合在一起，亚洲将在 2017 年发挥更重要的作用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能是涉及通过大量数据分析来预测结果和模式的计算领域，它几乎和现代计算机一样古老，但是它深奥的本质使它长期以来都难以实现实际的应用。例如 20 世纪 60 年代的以太空时代为题材的漫画 The Jetsons，它里面有一个有感情的女仆机器人和自动飞行汽车，这些在 50 年后的今天仍然只是想象。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8L6gHxjMvmaS6FWuRBT09ic4vDmAT3NNKrcx5Td75xcJm7Jj7367v8xQoZFyMUkDS4tYNwpjTMWeA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;来自 The Jetsons 中 Rosie 机器人的模型，照片：AFP&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而三月份 AlphaGo 的成功又重新在公共意识中唤起了对人工智能的热情。AlphaGo 是一个复杂的谷歌人工智能程序，其上演了在古老的中国围棋上战胜围棋大师的惊人一幕，它甚至超越了我们对最先进计算机的理解。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;瞬时，硅谷最大的公司连同中国最大的三家科技公司「BAT——百度、阿里巴巴和腾讯」就像人工智能研究投入了数十亿美元。由于人工智能的发展涉及到迅猛发展的大数据和计算能力，这一领域终于从计算机荒野中走出来了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能研究者说该技术有可能彻底改变全球经济和人类生活的每一个方面，从检测和治疗癌症到管理咨询和投资银行指导。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Facebook 的人工智能研究工程师 Soumith Chintala 表示：「我们预计未来几年内，驱动自动驾驶汽车的技术和推动 AlphaGo 的技术将被整合到不同领域，如交通和医疗保健」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2016 年，人工智能引起狂热主要是由于在「机器学习」和「深度学习」子领域的进步。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8L6gHxjMvmaS6FWuRBT09icWBVOy5Q3jvGavIAriaBZm4khJ2UynyRgya1AncUGlgt9D8pqR6wLyDA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;韩国的围棋大师李世乭对战 AlphaGo 丢掉了最后一局，最终以 1 比 4 不敌人工智能系统。图片：AP&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器学习是一个训练算法来执行它没有被明确编程任务的过程，在这过程中需要使用与该任务相关的大量数据进行训练。深度学习技术是机器学习的一个子领域。它的目的是模仿人类大脑中的神经网络，从而通过人工神经元矩阵传递大量的数据，并且在人工神经元矩阵中高速处理与分析数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;香港科技大学的人工智能研究员 Pascale Fung 表示，在开发类似人类大脑计算机的方面已经有几个里程碑了。语音识别和情绪分析就是「到达了新里程碑」的领域。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;聚焦亚洲的人工智能专家也表示虽然该地区在研究方面落后于西方国家，但其技术公司和大学有巨大的潜力弥补这段差距。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8L6gHxjMvmaS6FWuRBT09icibLYH8KeuvDRu4Tia94iaLZtISwDp6ibphE8DXS174XBemicDxpOib09tGicg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;百度高级数据科学家吴海山在北京百度技术园区，百度被公认为是亚洲人工智能研究的前沿。照片：Bloomberg&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;百度是中国顶尖的搜索引擎，被广泛认为是亚洲人工智能的最前沿，它在北京和硅谷都有人工智能实验室。早在 2014 年，百度就聘请了吴恩达——他以前领导过谷歌的人工智能业务，并联合创立了网上学习平台 Coursera。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Zeroth.ai（一个亚洲人工智能初创公司孵化器）的香港常务董事 Tak Lo 说：「BAT 公司知道他们必须与谷歌和 Facebook 那样的公司争夺人工智能人才，我们很可能在未来几年看到这种情况急剧升温。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Tak 说，在中国、日本和韩国等国的国家战略中存在创业生态系统，与西方的整体式发展相比，这种创业生态系统可能是亚洲在人工智能领域增长的绊脚石。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Facebook 的印度裔专家 Chintala 说，亚洲人是全球人工智能和深度学习研究社区的重要组成部分。他说：「作为个人，我们已经对该领域产生良好的影响。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这位位于纽约的研究者说，但是在像印度这样的地方研究更倾向「比顶级美国与欧洲大学或实验室的研究低层次的研究。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「这是缓慢但稳步变化的过程，弥合这一差距的关键是为年轻研究人员提供良好的培养指导计划，这种情况正在迅速发生。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;领先的亚洲枢纽新加坡和香港已经孵化了几家关注于深度学习的初创公司，它们是在部分业务需要技术提供支持的浪潮下建立的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;技术数据和研究公司 CB Insights 在 12 月表示，自 2011 年以来，全球共收购了 137 家人工智能关联的初创企业，光是今年就有 40 家。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中有专门从事人工智能「聊天机器人」公司。聊天机器人是一种基于深度学习技术的软件，它能帮助用户使用语音或文字执行如点餐、支付或叫车等任务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8L6gHxjMvmaS6FWuRBT09icwEKvqVPsedvX8CnaCSPf2mybrsPyJLPh5ibOCBBncnraOrXHicO4crfA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;聊天机器人是一种基于深度学习技术的软件，它能帮助用户使用语音或文字执行如点餐、支付或叫车等任务。照片：Edward Wong&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Active.ai 就是一家在新加坡这样的公司。它开发的聊天机&lt;/span&gt;&lt;span&gt;器人能通过与人工智能驱动平台的对话能给银行客户提供业务上的指导。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该公司的联合创始人 Shankar Narayanan 说：「我们以前有网络银行，然后是移动银行和移动优先的时代。现在我们正在进入一个人工智能银行和人工智能优先的时代。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在香港，早期阶段的创业公司 Clare.ai 正在开发类似的智能聊天机器人技术，除了英语和其它主要语言之外，它还支持粤语。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这家香港公司的联合创始人 Ken Leung 说：「在 2017 年，我们将看到银行、保险公司和零售公司等企业进一步使用这种技术。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8L6gHxjMvmaS6FWuRBT09icxWyOQmXup2XYnI2mP3pibicag0XNzXpaxEAY77Bqey8vFRHynyiaW0xmQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;电视机正展示谷歌人工智能系统 AlphaGo 打败韩国围棋大师李世乭。照片：AP&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;香港科技大学研究员 Fung 表示，中国有世界上最重要的制造业基地，并且因为「研究、开发和制造之间的合作可以快速完成」，所以中国在人工智能产业开发上有独一无二的优势。中国 BAT 互联网三巨头的数据宝库也可以看到这些公司正使用「最新的机器学习算法来利用这些数据改善他们的服务」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在人工智能令人眼花缭乱的潜力下，专家们强调需要抑制过高期望和对人工智能可能对人类生活不利的恐惧。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2016 年 9 月，美国几家主要科技公司达成了一项合作关系 Partnership on Artificial Intelligence to Benefit People and Society——这是一个非营利性质的联盟，将主要从事人工智能道德伦理方面的研究以及「推进公众对技术的理解和认知」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「理解人工智能到底什么是非常重要的，因为如果我们不理解它到底是什么，那么我们就可以高估当前人工智能技术的能力，从而导致出现错误的投资和决策。」Facebook 的研究者 Chintala 说。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他还补充说：「听起来不好但却实际的问题是我们目前只是处在人工智能增量的时刻。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;英国布里斯托尔大学人工智能教授 Nello Cristianini 说，但用户和监管者有必要识别人工智能技术的潜在危害：个人数据的安全、适应性技术的依赖、关于个人财务行为预测的无授权泄漏等等。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Cristianini 说：「如果 2017 年这些领域在带来技术发展的同时也能带来文化上的进展就好了，这样我们才能在太晚了之前觉察到问题。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些专家并不认同可能会出现《终结者》电影里面的「天网（Skynet）」——一种会主宰人类的恶意的计算机网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Fung 说：「其中一些恐惧，比如机器人取代人类，实际上是遥不可及的……我们确实已经取得了很大的进展和突破，但我们离实现通用智能机器还非常遥远。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;原文链接：http://www.scmp.com/week-asia/society/article/2058278/machines-are-coming-chinas-role-future-artificial-intelligence&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 02 Jan 2017 12:52:58 +0800</pubDate>
    </item>
  </channel>
</rss>
