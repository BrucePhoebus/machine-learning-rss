<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>机器学习初学者入门实践：怎样轻松创造高精度分类网络</title>
      <link>http://www.iwgc.cn/link/4179109</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Github&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是一个为没有人工智能背景的程序员提供的机器学习上手指南。使用神经网络不需要博士学位，你也不需要成为实现人工智能下一个突破的人，你只需要使用现有的技术就行了——毕竟我们现在已经实现的东西已经很突破了，而且还非常有用。我认为我们越来越多的人将会和机器学习打交道就像我们之前越来越多地使用开源技术一样——而不再仅仅将其看作是一个研究主题。在这份指南中，我们的目标是编写一个可以进行高准确度预测的程序——仅使用图像本身来分辨 data/untrained-samples 中程序未见过的样本图像中是海豚还是海马。下面是两张图像样本：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8M105rSLT1BfsDJJO4eiaDwWQEiamkGmCPtQskHiceq32SmeXePf7Rdc0gA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8McfumnibfyFuzWxEmzpcOx2V3czsiajEFDtbA2Luia0nWicvHcGObuBOshw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了实现我们的目标，我们将训练和应用一个卷积神经网络（CNN）。我们将从实践的角度来接近我们的目标，而不是阐释其基本原理。目前人们对人工智能有很大的热情，但其中很多都更像是让物理学教授来教你自行车技巧，而不是让公园里你的朋友来教你。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为此，我（GitHub 用户 humphd/David Humphrey）决定在 GitHub 上写下我的指南，而不是直接发在博客上，因为我知道我下面的写的一切可能会有些误导、天真或错误。我目前仍在自学，我发现现在还很缺乏可靠的初学者文档。如果你觉得文章有错误或缺失了某些重要的细节，请发送一个 pull 请求。下面就让我教你「自行车的技巧」吧！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;指南地址：https://github.com/humphd&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;概述&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们将在这里探索以下内容：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;设置和使用已有的、开源的机器学习技术，尤其是 Caffe 和 DIDITS&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;创建一个图像数据集&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;从头开始训练一个神经网络&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在我们的神经网络从未见过的图像上对其进行测试&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;通过微调已有的神经网络（AlexNet 和 GoogLeNet）来提升我们的神经网络的准确度&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;部署和使用我们的神经网络&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：我知道你说过我们不会谈论神经网络理论，但我觉得在我们开始动手之前至少应该来一点总体概述。我们应该从哪里开始？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于神经网络的理论问题，你能在网上找到海量的介绍文章——从短帖子到长篇论述到在线课程。根据你喜欢的学习形式，这里推荐了三个比较好的起点选择：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;J Alammar 的博客《A Visual and Interactive Guide to the Basics of Neural Networks》非常赞，使用直观的案例介绍了神经网络的概念：https://jalammar.github.io/visual-interactive-guide-basics-neural-networks/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Brandon Rohrer 的这个视频是非常好的卷积神经网络介绍：https://www.youtube.com/watch?v=FmpDIaiMIeA&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如果你想了解更多理论上的知识，我推荐 Michael Nielsen 的在线书籍《Neural Networks and Deep Learning》：http://neuralnetworksanddeeplearning.com/index.html&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;设置&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;安装 Caffe&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Caffe 地址：http://caffe.berkeleyvision.org/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先，我们要使用来自伯克利视觉和学习中心（Berkely Vision and Learning Center）的 Caffe 深度学习框架（BSD 授权）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;问：稍等一下，为什么选择 Caffe？为什么不选现在人人都在谈论的 TensorFlow？&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;没错，我们有很多选择，你也应该了解一下所有的选项。TensorFlow 确实很棒，你也应该试一试。但是这里选择 Caffe 是基于以下原因：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;这是为计算机视觉问题定制的&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;支持 C++ 和 Python（即将支持 node.js：https://github.com/silklabs/node-caffe）(https://github.com/silklabs/node-caffe%EF%BC%89)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;快速且稳定&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是我选择 Caffe 的头号原因是不需要写任何代码就能使用它。你可以声明性地完成所有工作（Caffe 使用结构化的文本文件来定义网络架构），并且也可以使用命令行工具。另外，你也可以为 Caffe 使用一些漂亮的前端，这能让你的训练和验证过程简单很多。基于同样的原因，下面我们会选择 NVIDIA 的 DIGITS。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Caffe 的安装有点麻烦。这里有不同平台的安装说明，包括一些预构建的 Docker 或 AWS 配置：http://caffe.berkeleyvision.org/installation.html&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;注：当我在进行练习的时候，我使用了来自 GitHub 的尚未发布的 Caffe 版本：https://github.com/BVLC/caffe/commit/5a201dd960840c319cefd9fa9e2a40d2c76ddd73&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 Mac 要配置成功则难得多，这个版本有一些版本问题会在不同的步骤终止你的进度。我用了好几天时间来试错，我看了十几个指南，每一个都有一些不同的问题。最后发现这个最为接近：https://gist.github.com/doctorpangloss/f8463bddce2a91b949639522ea1dcbe4。另外我还推荐：https://eddiesmo.wordpress.com/2016/12/20/how-to-set-up-caffe-environment-and-pycaffe-on-os-x-10-12-sierra/，这篇文章比较新而且链接了许多类似的讨论。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;到目前为止，安装 Caffe 就是我们做的最难的事情，这相当不错，因为你可能原来还以为人工智能方面会更难呢！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果安装遇到问题请不要放弃，痛苦是值得的。如果我会再来一次，我可能会使用一个 Ubuntu 虚拟机，而不是直接在 Mac 上安装。如果你有问题要问，可以到 Caffe 用户讨论组：https://groups.google.com/forum/#!forum/caffe-users&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：我需要一个强大的硬件来训练神经网络吗？要是我没法获取一个强大的 GPU 怎么办？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;是的，深度神经网络确实需要大量的算力和能量……但那是在从头开始训练并且使用了巨型数据集的情况。我们不需要那么做。我们可以使用一个预训练好的网络（其它人已经为其投入了数百小时的计算和训练），然后根据你的特定数据进行微调即可。我们后面会介绍如何实现这一目标，但首先我要向你说明：后面的一切工作都是在一台没有强大 GPU 的一年前的 MacBook 上完成的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外说明一点，因为我有一块集成英特尔显卡，而不是英伟达的 GPU，所以我决定使用 OpenCL Caffe 分支：https://github.com/BVLC/caffe/tree/opencl，它在我的笔记本电脑上效果良好！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当你安装完 Caffe 之后，你应该有或能够做下列事情：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;一个包含了你构建的 Caffe 的目录。如果你是按标准方式做的，应该会有一个 build/ 目录包含了运行 Caffe 所需的一切、捆绑的 Python 等等，build/ 的父目录将是你的 CAFFE_ROOT（后面我们会用到它）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;运行 make test &amp;amp;&amp;amp; make runtest，应该会通过&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;安装了所有的 Python 依赖包之后（在 python/ 中执行 for req in $(cat requirements.txt); do pip install $req; done；运行 make pycaffe &amp;amp;&amp;amp; make pytest 应该会通过&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;你也应该运行 make distribute 以在 distribute/ 中创建一个带有所有必要的头文件、二进制文件等的可分发的 Caffe 版本&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在我的机器上，Caffe 完全构建后，我的 CAFFE_ROOT 目录有以下基本布局：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;caffe/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;build/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;python/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;lib/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;tools/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;caffe ← this is our main binary&amp;nbsp;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;distribute/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;python/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;lib/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;include/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;bin/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;proto/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;到现在，我们有了训练、测试和编程神经网络所需的一切。下一节我们会为 Caffe 增加一个用户友好的基于网页的前端 DIGITS，这能让我们对网络的训练和测试变得更加简单。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;安装 DIGITS&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;DIGITS 地址：https://github.com/NVIDIA/DIGITS&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;英伟达的深度学习 GPU 训练系统（Deep Learning GPU Training System/DIGITS）是一个用于训练神经网络的 BSD 授权的 Python 网页应用。尽管我们可以在 Caffe 中用命令行或代码做到 DIGITS 所能做到的一切，但使用 DIGITS 能让我们的工作变得更加简单。而且因为 DIGITS 有很好的可视化、实时图表等图形功能，我觉得使用它也能更有乐趣。因为你正在尝试和探索学习，所以我强烈推荐你从 DIGITS 开始。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 https://github.com/NVIDIA/DIGITS/tree/master/docs 有一些非常好的文档，包括一些安装、配置和启动的页面。我强烈建议你在继续之前通读一下。我并不是一个使用 DIGITS 的专家，如果有问题可以在公开的 DIGITS 用户组查询或询问：https://groups.google.com/forum/#!forum/digits-users&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;安装 DIGITS 的方式有很多种，从 Docker 到 Linux 上的 pre-baked package，或者你也可以从源代码构建。我用的 Mac，所以我就是从源代码构建的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;注：在我的实践中，我使用了 GitHub 上未发布的 DIGITS 版本：https://github.com/NVIDIA/DIGITS/commit/81be5131821ade454eb47352477015d7c09753d9&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因为 DIGITS 只是一些 Python 脚本，所以让它们工作起来很简单。在启动服务器之前你要做的事情是设置一个环境变量，告诉 DIGITS 你的 CAFFE_ROOT 的位置在哪里：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;export CAFFE_ROOT=/path/to/caffe&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;./digits-devserver&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;注：在 Mac 上，这些服务器脚本出现了一些问题，可能是因为我的 Python 二进制文件叫做 python2，其中我只有 python2.7。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你可以在 /usr/bin 中 symlink 它或在你的系统上修改 DIGITS 启动脚本以使用合适的二进制文件。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一旦服务器启动，你可以在你的浏览器中通过 http://localhost:5000 来完成一切后续工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;训练一个神经网络&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;训练神经网络涉及到几个步骤：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 准备一个带有分类图像的数据集&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 定义网络架构&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 使用准备好的数据集训练和验证这个网络&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面我们会做这三个步骤，以体现从头开始和使用预训练的网络之间的差异，同时也展示如何使用 Caffe 和 DIGITS 上最常用的两个预训练的网络 AlexNet、 GoogLeNet。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于我们的训练，我们将使用一个海豚（Dolphins）和海马（Seahorses）图像的小数据集。这些图像放置在 data/dolphins-and-seahorses。你至少需要两个类别，可以更多（有些我们将使用的网络在 1000 多个类别上进行了训练）。我们的目标是：给我们的网络展示一张图像，它能告诉我们图像中的是海豚还是海马。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;准备数据集&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;dolphins-and-seahorses/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;dolphin/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;image_0001.jpg&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;image_0002.jpg&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;image_0003.jpg&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;...&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;seahorse/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;image_0001.jpg&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;image_0002.jpg&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;image_0003.jpg&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;...&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最简单的开始方式就是将你的图片按不同类别建立目录：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在上图中的每一个目录都是按将要分类的类别建立的，所建文件夹目录下是将以用于训练和验证的图片。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：所有待分类和验证的图片必须是同样大小吗？文件夹的命名有影响吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;回答都是「否」。图片的大小会在图片输入神经网络之前进行规范化处理，我们最终需要的图片大小为 256×256 像素的彩色图片，但是 DIGITS 可以很快地自动裁切或缩放（我们采用缩放）我们的图像。文件夹的命名没有任何影响——重要的是其所包含的图片种类。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：我能对这些类别做更精细的区分吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然可以。详见 https://github.com/NVIDIA/DIGITS/blob/digits-4.0/docs/ImageFolderFormat.md。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们要用这些图片来创建一个新的数据集，准确的说是一个分类数据集（Classification Dataset）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8MY1HgtW6jENNiaibicxwvZSvzupCpeVDewVcS5bIF2AgtLNPZoMLHdJ32w/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们会使用 DIGITS 的默认设置，并把我们的训练图片文件路径设置到 data/dolphins-and-seahorses 文件夹。如此一来，DIGITS 将会使用这些标签（dolphin 和 seahorse）来创建一个图像缩放过的数据集——图片的大小将会是 256×256，其中 75% 的为训练图片，25% 的为测试图片。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;给你的数据集起一个名字，如 dolphins-and-seahorses，然后鼠标点击创建（Create）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8MXbiclBUec8a5cYGGT1Abv3j52orMJHgXJoM8Hbuk0c5VEecibxMZHpgQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过上面的步骤我们已经创建了一个数据集了，在我的笔记本上只需要 4 秒就可以完成。最终在所建的数据集里有 2 个类别的 92 张训练图片（其中 49 张 dolphin，43 张 seahorse），另外还有 30 张验证图片（16 张 dolphin 和 14 张 seahorse）。不得不说这的确是一个非常小的数据集，但是对我们的示范试验和 DIGITS 操作学习来说已经足够了，因为这样网络的训练和验证就不会用掉太长的时间了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你可以在这个数据库文件夹里查看压缩之后的图片。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8Mzl6VFp6ib3y8WnaDPCfpWDrbNnHyMjJ2vZgSGmcc9YRicBun17DYKFIg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;训练尝试 1：从头开始&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;回到 DIGITS 的主页，我们需要创建一个新的分类模型（Classification Model）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8MRnf8rhpGfO7zWdgzOBibK3ddRia27ibQlqO0E3lDpiaWsUIKwY9Uibraodg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们将开始用上一步所建立的 dolphins-and-seahorses 数据集来训练模型，仍然使用 DIGITS 的默认设置。对于第一个神经网络模型，我们可以从提供的神经网络架构中选取一个既有的标准模型，即 AlexNet。AlexNet 的网络结构在 2012 年的计算机视觉竞赛 ImageNet 中获胜过（ImageNet 为计算机视觉顶级比赛）。在 ImageNet 竞赛里需要完成 120 万张图片中 1000 多类图片的分类。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8M9Zqj3EHbvA0WVfsu6U7ibQibdlURPazWqZLQ2OgBbRVqWhpr39XNdlpg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Caffe 使用结构化文本文件（structured text files）来定义网络架构，其所使用的文本文件是基于谷歌的 Protocol Buffer。你可以阅读 Caffe 采用的方案：https://github.com/BVLC/caffe/blob/master/src/caffe/proto/caffe.proto。其中大部分内容在这一部分的神经网络训练的时候都不会用到，但是了解这些构架对于使用者还是很有用的，因为在后面的步骤里我们将会对它们进行调整。AlexNet 的 prototxt 文件是这样的，一个实例： https://github.com/BVLC/caffe/blob/master/models/bvlc_alexnet/train_val.prototxt。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们将会对这个神经网络进行 30 次 epochs，这意味着网络将会进行学习（运用我们的训练图片）并自行测试（运用我们的测试图片），然后根据训练的结果调整网络中各项参数的权重值，如此重复 30 次。每一次 epoch 都会输出一个分类准确值（Accuracy，介于 0% 到 100% 之间，当然值越大越好）和一个损失度（Loss，所有错误分类的比率，值越小越好）。理想的情况是我们希望所训练的网络能够有较高的准确率（Accuracy）和较小的损失度（Loss）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;初始训练的时候，所训练网络的准确率低于 50%。这是情理之中的，因为第一次 epoch，网络只是在随意猜测图片的类别然后任意设置权重值。经过多次 epochs 之后，最后能够有 87.5% 的准确率，和 0.37 的损失度。完成 30 次的 epochs 只需不到 6 分钟的时间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8Mym2wHnhU0kR7XTE0qHWib4RNhjtBbia9n1f2b1bPZGKZBFJiaBWqqicL6g/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们可以上传一张图片或者用一个 URL 地址的图片来测试训练完的网络。我们来测试一些出现在我们训练和测试数据集中的图片：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8MKxAmcyqlGfHZSSSzMW4WQfEcWcs1XpnX1at779uBbRL9wlwBlxq9uQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8ME5mdcsax7IdAxcy96p0Dl17mvticTq0WgU8s8w8ad5T8iczyks5Tk0jA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;网络的分类结果非常完美，当我们测试一些不属于我们训练和测试数据集的其他图片时：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8M4PaXzhcexmBG2DPKsvylnZ4wvx7PkGWU0DEqdO11axS9sGcEIuGbpQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;分类的准确率直接掉下来了，误把 seahorse 分类为 dolphin，更糟糕的是网络对这样的错误分类有很高的置信度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;事实是我们的数据集太小了，根本无法用来训练一个足够好的神经网络。我们需要数万乃至数百万张图片才能训练一个有用的神经网络，用这么多的图片也意味着需要很强劲的计算能力来完成所有的计算过程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;训练尝试 2：微调 AlexNet&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;怎么微调网络&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从头设计一个神经网络，收集足量的用以训练这个网络的数据（如，海量的图片），并在 GPU 上运行数周来完成网络的训练，这些条件远非我们大多数人可以拥有。能够以更加实际——用较小一些的数据集来进行训练，我们运用一个称为迁移学习（Transfer Learning）或者说微调（Fine Tuning）的技术。Fine tuning 借助深度学习网络的输出，运用已训练好的神经网络来完成最初的目标识别。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;试想使用神经网络的过程就好比使用一个双目望远镜看远处的景物。那么当你第一次把双目望远镜放到眼前的时候，你看到的是一片模糊。当你开始调焦的时候，你慢慢可以看出颜色、线、形状，然后最终你可以分辨出鸟的外形，在此之上你进一步调试从而可以识别出鸟的种类。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在一个多层网络中，最开始的几层是用于特征提取的（如，边线），之后的网络层通过这些提取的特征来识别外形「shape」（如，一个轮子，一只眼睛），然后这些输出将会输入到最后的分类层，分类层将会根据之前所有层的特征积累来确定待分类目标的种类（如，判断为猫还是狗）。一个神经网络从像素、线形、眼睛、两只眼睛的确定位置，这样的步骤来一步步确立分类目标的种类（这里是猫）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们在这里所做的就是给新的分类图片指定一个已训练好的网络用于初始化网络的权重值，而不是用新构建网络自己的初始权重。因为已训练好的网络已经具备「看」图片特征的功能的，我们所需要的是这个已训练的网络能「看」我们所建图片数据集——这一具体任务中特定类型的图片。我们不需要从头开始训练大部分的网络层——我们只需要将已训练网络中已经学习的层转接到我们新建的分类任务上来。不同于我们的上一次的实验，在上次实验中网络的初始权重值是随机赋予的，这次实验中我们直接使用已经训练网络的最终权重值作为我们新建网络的初始权重值。但是，必须去除已经训练好的网络的最后分类层并用我们自己的图片数据集再次训练这个网络，即在我们自己的图片类上微调已训练的网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于这次实验，我们需要一个与经由与我们训练数据足够相似的数据集所训练的网络，只有这样已训练网络的权重值才对我们有用。幸运的是，我们下面所使用的网络是在海量数据集（自然图片集 ImageNet）上训练得到的，这样的已训练网络能满足大部分分类任务的需要。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种技术已经被用来做一些很有意思的任务如医学图像的眼疾筛查，从海里收集到的显微图像中识别浮游生物物种，给 Flickr 上的图片进行艺术风格分类。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;完美的完成这些任务，就像所有的机器学习一样，你需要很好的理解数据以及神经网络结构——你必须对数据的过拟合格外小心，你或许需要调整一些层的设置，也很有可能需要插入一些新的网络层，等等类似的调整。但是，我们的经验表明大部分时候还是可以完成任务的「Just work」，而且用我们这么原始的方法去简单尝试一下看看结果如何是很值得的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;上传预训练网络&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在我们的第一次尝试中，我们使用了 AlexNet 的架构，但是网络各层的权重是随机分布的。我们需要做的就是需要下载使用一个已经经过大量数据集训练的 AlexNet。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;AlexNet 的快照（Snapshots）如下，可供下载：https://github.com/BVLC/caffe/tree/master/models/bvlc_alexnet。我们需要一个二进制文件 .caffemodel，含有训练好的权重，可供下载 http://dl.caffe.berkeleyvision.org/bvlc_alexnet.caffemodel。在你下载这些与训练模型的时候，让我们来趁机多学点东西。2014 年的 ImageNet 大赛中，谷歌利用其开源的 GoogLeNet (https://research.google.com/pubs/pub43022.html)（一个 22 层的神经网络）赢得了比赛。GoogLeNet 的快照如下，可供下载： https://github.com/BVLC/caffe/tree/master/models/bvlc_googlenet。在具备了所有的预训练权重之后，我们还需要.caffemodel 文件，可供下载：http://dl.caffe.berkeleyvision.org/bvlc_googlenet.caffemodel&lt;span&gt;.&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有了 .caffemodel 文件之后，我们既可以将它们上传到 DIGITS 当中。在 DIGITS 的主页当中找到预训练模型（Pretrained Models）的标签，选择上传预训练模型（Upload Pretrained Model）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8MHG09h1ZdGlWNuU51icOiaVk9PzicA8hIicR8wlCo1rqEKAYicNMEicx1EFNQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于这些预训练的模型，我们可以使用 DIGITS 的默认值（例如，大小为 256×256 像素的彩色图片）。我们只需要提供 Weights (.caffemodel) 和 Model Definition (original.prototxt)。点击这些按钮来选择文件。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;模型的定义，GoogLeNet 我们可以使用 https://github.com/BVLC/caffe/blob/master/models/bvlc_googlenet/train_val.prototxt，AlexNet 可以使用 https://github.com/BVLC/caffe/blob/master/models/bvlc_alexnet/train_val.prototxt。我们不打算使用这些网络的分类标签，所以我们可以直接添加一个 labels.txt 文件：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8MfibrDes2l5qDkagdHL8FTYOLVyltoNiazwe1WqqQkq8o4E1YfX9yzPJg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 AlexNet 和 GoogLeNet 都重复这一过程，因为我们在之后的步骤当中两者我们都会用到。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问题：有其他的神经网络能作为微调的基础吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;回答：Caffe Model Zoo 有许多其他预训练神经网络可供使用，详情请查看 https://github.com/BVLC/caffe/wiki/Model-Zoo&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使用预训练 Caffe 模型进行人工神经网络训练就类似于从头开始实现，虽然我们只需要做一些调整。首先我们需要将学习速率由 0.01 调整到 0.001，因为我们下降步长不需要这么大（我们会进行微调）。我们还将使用预训练网络（Pretrained Network）并根据实际修改它。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8MxQj98Uhq6XCzjAR9pPTepUVxxibdrWicOKXGYErrpTiaKF81WIzoHuoTw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在预训练模型的定义（如原文本）中，我们需要对最终完全连接层（输出结果分类的地方）的所有 references 重命名。我们这样做是因为我们希望模型能从现在的数据集重新学习新的分类，而不是使用以前最原始的训练数据（我们想将当前最后一层丢弃）。我们必须将最后的全连接层由「fc8」重命名为一些其他的（如 fc9）。最后我们还需要将分类类别从 1000 调整为 2，这里需要调整 num_output 为 2。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面是我们需要做的一些调整代码：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;@@ -332,8 +332,8 @@&lt;/span&gt;
 }
 layer {&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp;name: "fc8"&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp;name: "fc9"&lt;/span&gt;
   type: "InnerProduct"
   bottom: "fc7"&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp;top: "fc8"&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp;top: "fc9"&lt;/span&gt;
   param {
     lr_mult: 1&lt;span&gt;@@ -345,5 +345,5 @@&lt;/span&gt;
   }
   inner_product_param {&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp; &amp;nbsp;num_output: 1000&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp; &amp;nbsp;num_output: 2&lt;/span&gt;
     weight_filler {
       type: "gaussian"&lt;span&gt;@@ -359,5 +359,5 @@&lt;/span&gt;
   name: "accuracy"
   type: "Accuracy"&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp;bottom: "fc8"&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp;bottom: "fc9"&lt;/span&gt;
   bottom: "label"
   top: "accuracy"&lt;span&gt;@@ -367,5 +367,5 @@&lt;/span&gt;
   name: "loss"
   type: "SoftmaxWithLoss"&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp;bottom: "fc8"&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp;bottom: "fc9"&lt;/span&gt;
   bottom: "label"
   top: "loss"&lt;span&gt;@@ -375,5 +375,5 @@&lt;/span&gt;
   name: "softmax"
   type: "Softmax"&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp;bottom: "fc8"&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp;bottom: "fc9"&lt;/span&gt;
   top: "softmax"
   include { stage: "deploy" }&lt;/pre&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我已经将所有的改进文件放在 src/alexnet-customized.prototxt 里面。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这一次，我们的准确率由 60% 多先是上升到 87.5%，然后到 96% 一路到 100%，同时损失度也稳步下降。五分钟后，我们的准确率到达了 100%，损失也只有 0.0009。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8M2VjGABJsyuCDtdZNUB3E2TDRQiael63c4s558PknnZgibSlB5LNSDdaA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;测试海马图像时以前的网络会出错，现在我们看到完全相反的结果，即使是小孩画的海马，系统也 100% 确定是海马，海豚的情况也一样。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8MwsP8X4UI9felfnvB2FptkApHOj9tUjiccd3wPfkeYlTqU7dw8JEKBuA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8MDDcRiaWq9icf9Yia4z6r01XrgBhpSkSxZTrNwNCZyZn9XXfM3PxcdMJZQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8ME7JicVZOHOL4L2katPvsib29KvpuavJBCsCywLY4N14JMQlxqTXP4icfA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;即使你认为可能很困难的图像，如多个海豚挤在一起，并且它们的身体大部分在水下，系统还是能识别。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8MvR2ErERZawZOcFdaDdFcvVpibqgicGsRE2RNftuVAc2tNm06rYE0Ldyw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;训练尝试 3：微调 GoogLeNet&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;像前面我们微调 AlexNet 模型那样，同样我们也能用 GoogLeNet。修改这个网络会有点棘手，因为你已经定义了三层全连接层而不是只有一层。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8MboCrlBN8GmexazlrsYBAlyz9RtxicgxJic92icIY20hftU7fN7oosq3pw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这个案例中微调 GoogLeNet，我们需要再次创建一个新的分类模型：我们需要重命名三个全连接分类层的所有 references，即 loss1/classifier、loss2/classifier 和 loss3/classifier，并重新定义结果类别数（num_output: 2）。下面是我们需要将三个分类层重新命名和从 1000 改变输出类别数为 2 的一些代码实现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;@@ -917,10 +917,10 @@&lt;/span&gt;
   exclude { stage: "deploy" }
 }
 layer {&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp;name: "loss1/classifier"&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp;name: "loss1a/classifier"&lt;/span&gt;
   type: "InnerProduct"
   bottom: "loss1/fc"&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp;top: "loss1/classifier"&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp;top: "loss1a/classifier"&lt;/span&gt;
   param {
     lr_mult: 1
     decay_mult: 1&lt;span&gt;@@ -930,7 +930,7 @@&lt;/span&gt;
     decay_mult: 0
   }
   inner_product_param {&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp; &amp;nbsp;num_output: 1000&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp; &amp;nbsp;num_output: 2&lt;/span&gt;
     weight_filler {
       type: "xavier"
       std: 0.0009765625&lt;span&gt;@@ -945,7 +945,7 @@&lt;/span&gt;
 layer {
   name: "loss1/loss"
   type: "SoftmaxWithLoss"&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp;bottom: "loss1/classifier"&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp;bottom: "loss1a/classifier"&lt;/span&gt;
   bottom: "label"
   top: "loss1/loss"
   loss_weight: 0.3&lt;span&gt;@@ -954,7 +954,7 @@&lt;/span&gt;
 layer {
   name: "loss1/top-1"
   type: "Accuracy"&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp;bottom: "loss1/classifier"&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp;bottom: "loss1a/classifier"&lt;/span&gt;
   bottom: "label"
   top: "loss1/accuracy"
   include { stage: "val" }&lt;span&gt;@@ -962,7 +962,7 @@&lt;/span&gt;
 layer {
   name: "loss1/top-5"
   type: "Accuracy"&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp;bottom: "loss1/classifier"&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp;bottom: "loss1a/classifier"&lt;/span&gt;
   bottom: "label"
   top: "loss1/accuracy-top5"
   include { stage: "val" }&lt;span&gt;@@ -1705,10 +1705,10 @@&lt;/span&gt;
   exclude { stage: "deploy" }
 }
 layer {&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp;name: "loss2/classifier"&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp;name: "loss2a/classifier"&lt;/span&gt;
   type: "InnerProduct"
   bottom: "loss2/fc"&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp;top: "loss2/classifier"&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp;top: "loss2a/classifier"&lt;/span&gt;
   param {
     lr_mult: 1
     decay_mult: 1&lt;span&gt;@@ -1718,7 +1718,7 @@&lt;/span&gt;
     decay_mult: 0
   }
   inner_product_param {&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp; &amp;nbsp;num_output: 1000&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp; &amp;nbsp;num_output: 2&lt;/span&gt;
     weight_filler {
       type: "xavier"
       std: 0.0009765625&lt;span&gt;@@ -1733,7 +1733,7 @@&lt;/span&gt;
 layer {
   name: "loss2/loss"
   type: "SoftmaxWithLoss"&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp;bottom: "loss2/classifier"&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp;bottom: "loss2a/classifier"&lt;/span&gt;
   bottom: "label"
   top: "loss2/loss"
   loss_weight: 0.3&lt;span&gt;@@ -1742,7 +1742,7 @@&lt;/span&gt;
 layer {
   name: "loss2/top-1"
   type: "Accuracy"&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp;bottom: "loss2/classifier"&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp;bottom: "loss2a/classifier"&lt;/span&gt;
   bottom: "label"
   top: "loss2/accuracy"
   include { stage: "val" }&lt;span&gt;@@ -1750,7 +1750,7 @@&lt;/span&gt;
 layer {
   name: "loss2/top-5"
   type: "Accuracy"&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp;bottom: "loss2/classifier"&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp;bottom: "loss2a/classifier"&lt;/span&gt;
   bottom: "label"
   top: "loss2/accuracy-top5"
   include { stage: "val" }&lt;span&gt;@@ -2435,10 +2435,10 @@&lt;/span&gt;
   }
 }
 layer {&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp;name: "loss3/classifier"&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp;name: "loss3a/classifier"&lt;/span&gt;
   type: "InnerProduct"
   bottom: "pool5/7x7_s1"&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp;top: "loss3/classifier"&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp;top: "loss3a/classifier"&lt;/span&gt;
   param {
     lr_mult: 1
     decay_mult: 1&lt;span&gt;@@ -2448,7 +2448,7 @@&lt;/span&gt;
     decay_mult: 0
   }
   inner_product_param {&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp; &amp;nbsp;num_output: 1000&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp; &amp;nbsp;num_output: 2&lt;/span&gt;
     weight_filler {
       type: "xavier"
     }&lt;span&gt;@@ -2461,7 +2461,7 @@&lt;/span&gt;
 layer {
   name: "loss3/loss"
   type: "SoftmaxWithLoss"&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp;bottom: "loss3/classifier"&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp;bottom: "loss3a/classifier"&lt;/span&gt;
   bottom: "label"
   top: "loss"
   loss_weight: 1&lt;span&gt;@@ -2470,7 +2470,7 @@&lt;/span&gt;
 layer {
   name: "loss3/top-1"
   type: "Accuracy"&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp;bottom: "loss3/classifier"&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp;bottom: "loss3a/classifier"&lt;/span&gt;
   bottom: "label"
   top: "accuracy"
   include { stage: "val" }&lt;span&gt;@@ -2478,7 +2478,7 @@&lt;/span&gt;
 layer {
   name: "loss3/top-5"
   type: "Accuracy"&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp;bottom: "loss3/classifier"&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp;bottom: "loss3a/classifier"&lt;/span&gt;
   bottom: "label"
   top: "accuracy-top5"
   include { stage: "val" }&lt;span&gt;@@ -2489,7 +2489,7 @@&lt;/span&gt;
 layer {
   name: "softmax"
   type: "Softmax"&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp;bottom: "loss3/classifier"&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp;bottom: "loss3a/classifier"&lt;/span&gt;
   top: "softmax"
   include { stage: "deploy" }
 }&lt;/pre&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我己经将完整的文件放在 src/googlenet-customized.prototxt 里面。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问题：这些神经网络的原文本（prototext）定义需要做什么修改吗？我们修改了全连接层名和输出结果分类类别数，那么在什么情况下其它参数也能或也需要修改的？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;回答：问得好，这也是我有一些疑惑的地方。例如，我知道我们能「固定」确切的神经网络层级，并保证层级之间的权重不改变。但是要做其它的一些改变就涉及到理解我们的神经网络层级是如何起作用的，这已经超出了这份入门向导的范围，同样也超出了这份向导作者现有的能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;就像我们对 AlexNet 进行微调，将下降的学习速率由 0.01 减少十倍到 0.001 一样。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：还有什么修改是对这些网络微调有意义的？遍历所有数据的次数（numbers of epochs）不同怎么样，改变批量梯度下降的大小（batch sizes）怎么样，求解器的类型（Adam、 AdaDelta 和 AdaGrad 等）呢？还有下降学习速率、策略（Exponential Decay、Inverse Decay 和 Sigmoid Decay 等）、步长和 gamma 值呢？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;问得好，这也是我有所疑惑的。我对这些只有一个模糊的理解，如果你知道在训练中如何修改这些值，那么我们很可能做出些改进，并且这需要更好的文档。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因为 GoogLeNet 比 AlexNet 有更复杂的网络构架，所以微调需要更多的时间。在我的笔记本电脑上，用我们的数据集重新训练 GoogLeNet 需要 10 分钟，这样才能实现 100% 的准确率，同时损失函数值只有 0.0070。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8McDVjtX1ayvNm8lQtmKVEicdJdev7GoLdLQOrBAfthqhyKkkHtpp085g/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;正如我们看到的 AlexNet 微调版本，我们修改过的 GoogLeNet 表现得十分惊人，是我们目前最好的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8MgbEicwKcW0E8QjK3EQ72QVdIoJbwePPQwhiaYk1SAUYibv0Iic8yzSAoibw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8MkDU08FiabKsEmYgkGh3zrrfosZ4p0iaUiaZUHAmGkEWHA4Vpibr5VMpwTg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8M7TfanqTgnyzrnVfnLBoDJlmao0ZKjic04BjT7LQuAmSOMsBECeTC9MQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;使用我们的模型&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们的网络在训练和检测之后，就可以下载并且使用了。我们利用 DIGITS 训练的每一个模型都有了一下载模型（Download Model）键，这也是我们在训练过程中选择不同 snapshots 的一种方法（例如 Epoch #30）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8MNB55cvRg1CnkLNjR752MV5N6X4HKAHh5iayWuxoa9pJtticuj77Cd6BA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在点击 Download Model 之后，你就会下载一个 tar.gz 的文档，里面包含以下文件：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;code style=" box-sizing: border-box; ; ; ; ; ; ; ; ; ; ; ; ; ; "&gt;deploy.prototxt
mean.binaryproto
solver.prototxt
info.json
original.prototxt
labels.txt
snapshot_iter_90.caffemodel
train_val.prototxt&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;在 Caffe 文档中对我们所建立的模型使用有一段非常好的描述。如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;一个网络是由其设计，也就是设计（prototxt）和权重（.caffemodel）决定。在网络被训练的过程中，网络权重的当前状态被存储在一个.caffemodel 中。这些东西我们可以从训练/检测阶段移到生产阶段。在它的当前状态中，网络的设计并不是为了部署的目的。在我们可以将我们的网络作为产品发布之前，我们通常需要通过几种方法对它进行修改：&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;1. 移除用来训练的数据层，因为在分类时，我们已经不再为数据提供标签了。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;2. 移除所有依赖于数据标签的层。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;3. 设置接收数据的网络。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;4. 让网络输出结果。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;DIGITS 已经为我们做了这些工作，它已经将我们 prototxt 文件中所有不同的版本都分离了出来。这些文档我们在使用网络时会用到：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;deploy.prototxt -是关于网络的定义，准备接收图像输入数据&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;mean.binaryproto - 我们的模型需要我们减去它处理的每张图像的图像均值，所产生的就是平均图像（mean image）。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;labels.txt - 标签列表 (dolphin, seahorse)，以防我们想要把它们打印出来，否则只有类别编号。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;snapshot_iter_90.caffemodel -这些是我们网络的训练权重。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;利用这些文件，我们可以通过多种方式对新的图像进行分类。例如，在 CAFFE_ROOT 中，我们可以使用 build/examples/cpp_classification/classification.bin 来对一个图像进行分类：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;$ cd $CAFFE_ROOT/build/examples/cpp_classification&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;$ ./classification.bin deploy.prototxt snapshot_iter_90.caffemodel mean.binaryproto labels.txt dolphin1.jpg&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这会产生很多的调试文本，后面会跟着对这两种分类的预测结果：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;0.9997 -「dolphin」&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;0.0003 -「seahorse」&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你可以在这个 Caffe 案例中查看完整的 C++ 源码：https://github.com/BVLC/caffe/tree/master/examples&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使用 Python 界面和 DIGITS 进行分类的案例：https://github.com/NVIDIA/DIGITS/tree/master/examples/classification&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，Caffe 的案例中还有一个非常好的 Python 演示：https://github.com/BVLC/caffe/blob/master/examples/00-classification.ipynb&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我希望可以有更多更好的代码案例、API 和预先建立的模型等呈现给大家。老实说，我找到的大多数代码案例都非常的简短，并且文档介绍很少——Caffe 的文档虽然有很多，但也有好有坏。对我来说，这似乎意味着会有人为初学者建立比 Caffe 更高级的工具。如果说在高级语言中出现了更加简单的模型，我可以用我们的模型「做正确的事情」；应该有人将这样的设想付诸行动，让使用 Caffe 模型变得像使用 DIGITS 训练它们一样简单。当然我们不需要对这个模型或是 Caffe 的内部了解那么多。虽然目前我还没有使用过 DeepDetect，但是它看起来非常的有趣，另外仍然还有其他我不知道的工具。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;结果&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;文章开头提到，我们的目标是编写一个使用神经网络对 data/untrained-samples 中所有的图像进行高准确度预测的程序。这些海豚和海马的图像是在训练数据或是验证数据时候从未使用过的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;未被训练过的海豚图像&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8M105rSLT1BfsDJJO4eiaDwWQEiamkGmCPtQskHiceq32SmeXePf7Rdc0gA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8Mx8rQzvwricOzO4ibS62RGTuU20WL9HhIh0kK5XibZWVjvV6DBhe3jabqg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8MOiaC8thCPvY1eNhYfnhVIDX8pqvUmVvHHAciafqBmJRSe83aH4P0iasHQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;未被训练过的海马图像&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8McfumnibfyFuzWxEmzpcOx2V3czsiajEFDtbA2Luia0nWicvHcGObuBOshw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8M8icCODwPZc2tBL6YWjMsicJldpOwOw0Iiarl3Fht2suNo8YtbFKRLuDLQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8MncqtxTlqxdwPaLxBUHJOEW9mZVsp6XAZ3vPugjCN31LzTNI60ZWK6Q/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;接下来，让我们一起来看看在这一挑战当中存在的三次尝试的结果：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;模型尝试 1： 从零开始构建 AlexNet（第 3 位）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;table width="888" style="width: 737px;"&gt;&lt;thead style="box-sizing: border-box;"&gt;&lt;tr style="box-sizing: border-box; background-color: rgb(255, 255, 255); border-top: 1px solid rgb(204, 204, 204);"&gt;&lt;th style="box-sizing: border-box; padding: 6px 13px; border-top-width: 1px; border-top-color: rgb(221, 221, 221);"&gt;Image&lt;/th&gt;&lt;th style="box-sizing: border-box; padding: 6px 13px; border-top-width: 1px; border-top-color: rgb(221, 221, 221);"&gt;Dolphin&lt;/th&gt;&lt;th style="box-sizing: border-box; padding: 6px 13px; border-top-width: 1px; border-top-color: rgb(221, 221, 221);"&gt;Seahorse&lt;/th&gt;&lt;th style="box-sizing: border-box; padding: 6px 13px; border-top-width: 1px; border-top-color: rgb(221, 221, 221);"&gt;Result&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody style="box-sizing: border-box;"&gt;&lt;tr style="box-sizing: border-box; background-color: rgb(255, 255, 255); border-top: 1px solid rgb(204, 204, 204);"&gt;&lt;td style="box-sizing: border-box; padding: 6px 13px;"&gt;&lt;a style="box-sizing: border-box; background-color: transparent; color: rgb(64, 120, 192);"&gt;dolphin1.jpg&lt;/a&gt;&lt;/td&gt;&lt;td style="box-sizing: border-box; padding: 6px 13px;"&gt;71.11%&lt;/td&gt;&lt;td style="box-sizing: border-box; padding: 6px 13px;"&gt;28.89%&lt;/td&gt;&lt;td style="box-sizing: border-box; padding: 6px 13px;"&gt;&lt;g-emoji alias="expressionless" fallback-src="https://assets-cdn.github.com/images/icons/emoji/unicode/1f611.png" ios-version="6.0" style=" box-sizing: border-box ; ; ; ; ; ; ; ;; font-size: 18px; line-height: 20px; vertical-align: middle; "&gt;</description>
      <pubDate>Tue, 03 Jan 2017 13:30:23 +0800</pubDate>
    </item>
    <item>
      <title>资源 | NIPS 2016上22篇论文的实现汇集</title>
      <link>http://www.iwgc.cn/link/4179110</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自niut-blanche&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;日前，LightOn CEO 兼联合创始人 Igor Carron 在其博客上放出了其收集到的 NIPS 2016 论文的实现（一共 22 个）。他写道：「在 Reddit 上，peterkuharvarduk 决定编译所有来自 NIPS 2016 的可用实现，我很高兴他使用了『实现（ implementation）』这个词，因为这让我可以快速搜索到这些项目。」除了 peterkuharvarduk 的推荐，这里的项目还包括 Reddit 其他用户和 Carron 额外添加的一些新公布的实现。最终他还重点推荐了 GitXiv：http://www.gitxiv.com 。另外，在本文后面还附带了机器之心关于 NIPS 2016 的文章列表，千万不要错过。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;1. 使用快速权重关注最近的过去（Using Fast Weights to Attend to the Recent Past）&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：https://arxiv.org/abs/1610.06258&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GitHub：https://github.com/ajarai/fast-weights&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;2. 通过梯度下降来学习通过梯度下降的学习（Learning to learn by gradient descent by gradient descent）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：https://arxiv.org/abs/1606.04474&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GitHub：https://github.com/deepmind/learning-to-learn&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;3. R-FCN：通过基于区域的全卷积网络的目标检测（R-FCN: Object Detection via Region-based Fully Convolutional Networks）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：https://arxiv.org/abs/1605.06409&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GitHub：https://github.com/Orpine/py-R-FCN&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4. 用于 k-均值的快速和可证明的 Good Seedings（Fast and Provably Good Seedings for k-Means）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：https://las.inf.ethz.ch/files/bachem16fast.pdf.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GitHub：https://github.com/obachem/kmc2&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;5. 如何训练生成对抗网络（How to Train a GAN）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GitHub：https://github.com/soumith/ganhacks&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;6. Phased LSTM：为长的或基于事件的序列加速循环网络训练（Phased LSTM: Accelerating Recurrent Network Training for Long or Event-based Sequences）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：https://arxiv.org/abs/1610.09513&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GitHub: https://github.com/dannyneil/public_plstm&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;7. 生成对抗式模仿学习（Generative Adversarial Imitation Learning）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：https://arxiv.org/abs/1606.03476&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GitHub：https://github.com/openai/imitation&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;8. 对抗式多类分类：一个风险最小化的角度（Adversarial Multiclass Classification: A Risk Minimization Perspective）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：https://www.cs.uic.edu/~rfathony/pdf/fathony2016adversarial.pdf&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GitHub：https://github.com/rizalzaf/adversarial-multiclass&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;9. 通过视频预测的用于物理交互的无监督学习（Unsupervised Learning for Physical Interaction through Video Prediction）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：https://arxiv.org/abs/1605.07157&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GitHub: https://github.com/tensorflow/models/tree/master/video_prediction&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;10.权重规范化：一种加速深度神经网络训练的简单重新参数化（ Weight Normalization: A Simple Reparameterization to Accelerate Training of Deep Neural Networks）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：https://arxiv.org/abs/1602.07868&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GitHub：https://github.com/openai/weightnorm&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;11. 全容量整体循环神经网络（Full-Capacity Unitary Recurrent Neural Networks）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：https://arxiv.org/abs/1611.00035&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GitHub：https://github.com/stwisdom/urnn&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;12. 带有随机层的序列神经模型（Sequential Neural Models with Stochastic Layers）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：https://arxiv.org/pdf/1605.07571.pdf&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GitHub：https://github.com/marcofraccaro/srnn&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;13. 带有快速局部化谱过滤的图上的卷积神经网络（Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：https://arxiv.org/abs/1606.09375&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GitHub：https://github.com/mdeff/cnn_graph&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;14. Interpretable Distribution Features with Maximum Testing Power&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：https://papers.nips.cc/paper/6148-interpretable-distribution-features-with-maximum-testing-power.pdf&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GitHub：https://github.com/wittawatj/interpretable-test/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;15. 使用神经网络组成图模型，用于结构化表征和快速推理(Composing graphical models with neural networks for structured representations and fast inference )&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：https://arxiv.org/abs/1603.06277&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GitHub：https://github.com/mattjj/svae&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;16. 使用张量网络的监督学习（Supervised Learning with Tensor Networks）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：https://arxiv.org/abs/1605.05775&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GitHub：https://github.com/emstoudenmire/TNML&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;17. 使用贝叶斯条件密度估计的模拟模型的快速无ε推理（Fast ε-free Inference of Simulation Models with Bayesian Conditional Density Estimation）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：https://arxiv.org/abs/1605.06376&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GitHub：https://github.com/gpapamak/epsilon_free_inference&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;18. 用于概率程序的贝叶斯优化（Bayesian Optimization for Probabilistic Programs）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：http://www.robots.ox.ac.uk/~twgr/assets/pdf/rainforth2016BOPP.pdf&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GitHub：https://github.com/probprog/bopp&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;19. PVANet：用于实施目标检测的轻权重深度神经网络（PVANet: Lightweight Deep Neural Networks for Real-time Object Detection）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：https://arxiv.org/abs/1611.08588&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GitHub：https://github.com/sanghoon/pva-faster-rcnn&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;20. 数据编程：快速创建大训练集（Data Programming: Creating Large Training Sets Quickly）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：https://arxiv.org/abs/1605.07723&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;代码： snorkel.stanford.edu&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;21. 用于架构学习的卷积神经结构（Convolutional Neural Fabrics for Architecture Learning）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：https://arxiv.org/pdf/1606.02492.pdf&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GitHub：https://github.com/shreyassaxena/convolutional-neural-fabrics&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;22. 价值迭代网络（Value Iteration Networks）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：https://arxiv.org/abs/1602.02867&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;TensorFlow 实现：https://github.com/TheAbhiKumar/tensorflow-value-iteration-networks&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;原作者的 Theano 实现：https://github.com/avivt/VIN&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;blockquote&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;机器之心 NIPS 2016 文章列表&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721406&amp;amp;idx=1&amp;amp;sn=8251dfebd3c360d180339c34c4710fa7&amp;amp;chksm=871b0800b06c81160244fcda78d7816da8ec31d5fbec546ba6e36241e6d32c0ca943ce9ce73d&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721406&amp;amp;idx=1&amp;amp;sn=8251dfebd3c360d180339c34c4710fa7&amp;amp;chksm=871b0800b06c81160244fcda78d7816da8ec31d5fbec546ba6e36241e6d32c0ca943ce9ce73d&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;"&gt;&lt;span&gt;深度 | NIPS 2016最全盘点：主题详解、前沿论文及下载资源（附会场趣闻）&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721081&amp;amp;idx=1&amp;amp;sn=d557968703d4af879b5cf6461069dacd&amp;amp;chksm=871b0f47b06c865185865fcd5ef92af7726e84ae9e689b7ced9986a08c9fe3113df296a8469a&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;"&gt;&lt;span&gt;独家 | 吴恩达 NIPS 2016 演讲现场直击：如何使用深度学习开发人工智能应用？&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721198&amp;amp;idx=1&amp;amp;sn=accdd701751ab9678285f3cdf073304f&amp;amp;chksm=871b0fd0b06c86c6fa49bbae856898920e26c4456bc02be42a947d23fe2b593110e911bf54da&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;"&gt;&lt;span&gt;独家 | 机器之心对话 NIPS 2016 最佳论文作者：如何打造新型强化学习观？&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721284&amp;amp;idx=1&amp;amp;sn=427e7f45c8253ab22a3960978409f5d1&amp;amp;chksm=871b087ab06c816c424ad03810be3e1b3aa9d6e99a5f325047796f110d178a07736f667d1a10&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;"&gt;&lt;span&gt;独家 | GAN 之父 NIPS 2016 演讲现场直击：全方位解读生成对抗网络的原理及未来&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721325&amp;amp;idx=4&amp;amp;sn=d570f04d737d09c1b1cebd962755af3f&amp;amp;chksm=871b0853b06c8145985f8c2c5ac7445118f18ce35532c0389b0e5ec24a7a1c4b841fe81280de&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;"&gt;&lt;span&gt;资源 | Bengio 和 LeCun 在 NIPS 2016 上的演讲&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718527&amp;amp;idx=2&amp;amp;sn=8d054db2eca7a0b25190a6cc050fc1d7&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;"&gt;&lt;span&gt;学界 | NIPS 2016 公布 571 篇接收论文&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721033&amp;amp;idx=2&amp;amp;sn=d0d143e72cf4a637a617be356008b323&amp;amp;chksm=871b0f77b06c86615ed6a59ede1bee6cbff68b6ec08fb9b300e347d9c34b931aabdc3d0fee4e&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;"&gt;&lt;span&gt;学界 | NIPS 2016 论文 SpotlightVideo 精选，三分钟了解一项最新研究进展&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721081&amp;amp;idx=3&amp;amp;sn=111d844d50c98582695d04fa2b252c89&amp;amp;chksm=871b0f47b06c86514ac934c44fe4df92f5d4209f209b94b4c89d1f138492dbaf7e47479803a3&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;"&gt;&lt;span&gt;学界 | NIPS 2016 现场：谷歌发布 28 篇机器学习论文&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720969&amp;amp;idx=2&amp;amp;sn=d1fae404486906125e01b5def7e26d94&amp;amp;chksm=871b0eb7b06c87a1d3e7d0b29e8c8f9e4c86f4949d04b0485df1b45823555a6c88a25ccf4dc4&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;"&gt;&lt;span&gt;学界 | DeepMind NIPS 2016 论文盘点（Part1）：强化学习正大步向前&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721102&amp;amp;idx=2&amp;amp;sn=cbc44a149457d31ed9a8bbe825f09378&amp;amp;chksm=871b0f30b06c8626bb94cbd7a08fd4a5c8bec747082f49280fbd27e9c87c965de983a279796c&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;"&gt;&lt;span&gt;学界 | DeepMind NIPS 2016 论文盘点（Part2）：无监督学习的新进展&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721081&amp;amp;idx=4&amp;amp;sn=af93b221818ff9f564b372de5fc1958f&amp;amp;chksm=871b0f47b06c8651744e4b2819322f4026b248f4474f619c7248f604dafe8490405d70d3d1f3&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;"&gt;&lt;span&gt;业界 | NIPS 2016 现场：LeCun 联同英伟达，推深度学习教学工具包&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721198&amp;amp;idx=4&amp;amp;sn=b2f6412538b2458116cd40f53bcdc23b&amp;amp;chksm=871b0fd0b06c86c6866c3e682aa9a15187154a67ae4b7df3d319cc2233fb5761c53da45abed1&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;"&gt;&lt;span&gt;业界 | 波士顿动力最新机器人亮相 NIPS 2016，但还未用到机器学习&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 03 Jan 2017 13:30:23 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 日本保险公司引入IBM Watson，这次人工智能代替了34名白领</title>
      <link>http://www.iwgc.cn/link/4179113</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Quartz&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李泽南、蒋思源&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8MZjFajRSpffAMibVU4akH0O7ibib7ibkexkK6TRxibHO773lPovySFQrnznw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在人们对于自动化的大部分注意力正集中在工业机器人、自动驾驶汽车等领域，很多学者们认为它们将从根本上改变劳动力的形式，有可能会代替数百万现有低技术工作岗位，一些国家的政府已经在为此&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721644&amp;amp;idx=1&amp;amp;sn=bfb26761cf5d118d4ed1dbafd04319f4&amp;amp;chksm=871b0912b06c8004ce420b78d657b9eee138c0e2990100ecfd759925804a0d248189b6014ba8&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721644&amp;amp;idx=1&amp;amp;sn=bfb26761cf5d118d4ed1dbafd04319f4&amp;amp;chksm=871b0912b06c8004ce420b78d657b9eee138c0e2990100ecfd759925804a0d248189b6014ba8&amp;amp;scene=21#wechat_redirect"&gt;制定政策&lt;/a&gt;。但对于人工智能而言，需要知识背景的白领工作似乎更加容易，在机器人客服、&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720780&amp;amp;idx=2&amp;amp;sn=cc64372d82354d3212baf84fce230928&amp;amp;chksm=871b0e72b06c8764cfe09654fa457da0fd764c0684d83b7fcd887c19401b3b4d623a07ab2bb9&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720780&amp;amp;idx=2&amp;amp;sn=cc64372d82354d3212baf84fce230928&amp;amp;chksm=871b0e72b06c8764cfe09654fa457da0fd764c0684d83b7fcd887c19401b3b4d623a07ab2bb9&amp;amp;scene=21#wechat_redirect"&gt;律师&lt;/a&gt;之后，自动化已经开始席卷金融行业。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;日本富国生命保险（Fukoku Mutual Life Insurance）近日宣布他们将要从 2017 年 1 月开始使用「IBM Watson Explorer」，代替 34 位保险索赔业务员的职位。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「人工智能将扫描被保险人的医疗记录与其他信息来决定保险赔付的金额，」富国生命在一份新闻稿中写道。「受伤定性、患者病史和治疗形式都将纳入理赔金额的考量。人工智能系统将自动搜索数据，完成数据计算任务，帮助该公司剩余的员工更快地处理理赔事宜。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;根据日本《每日新闻》的报道，在此项目中，富国生命将斥资 170 万美元（约合 2 亿日元）引入 IBM 公司的人工智能系统，随后每年的维持费用约为 12.8 万美元。通过使用人工智能系统，该公司将在未来每年节约 110 万美元的开支，这意味着此项投资两年后即可收回成本。「Watson AI 的效率预计会比人类员工高 30%，」富国生命保险的发言人表示。「本公司已经受益于 IBM 的新技术，类似的人工智能系统正被用于处理客户投诉电话等任务。如使用软件识别客户语音，将语音转换为文字，而后分析这些话的内容。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一些美国公司也在使用情绪分析软件来为顾客提供服务。这类软件一大优势就是可以获知顾客的情绪，当顾客对自助服务系统不满意，系统将自动转接到人工服务上去。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;《每日新闻》报告称，另有三家日本保险公司正在测试或引入人工智能系统，它们希望通过智能系统自动完成一些技术性工作，如为顾客提供合理的金融计划。以色列一家保险初创公司 Lemonade 已经募集了 6000 万美元，其 CEO Daniel Schreiber 称他们的未来目标是「用机器人和机器学习替代经纪人与文书工作」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;像 IBM Watson 这样的人工智能系统正自信满满地准备倾覆众多知识技术职位，如保险和金融服务。对此，哈佛商业评论（Harvard Business Review）在一篇报道中认为，这是因为许多工作能「由可以编纂成标准步骤的工作流程和基于标准格式的数据进行决策组成。」引入人工智能意味着提高现有员工生产力，还是机器完全替换人类工作岗位？一切还有待观察。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「几乎所有的工作都面临计算机在短期内无法处理的关键问题，」哈佛商业评论写道。「但是，我们不得不承认越来越多的知识型工作正在屈服于人工智能的崛起。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文链接：http://qz.com/875491/japanese-white-collar-workers-are-already-being-replaced-by-artificial-intelligence/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 03 Jan 2017 13:30:23 +0800</pubDate>
    </item>
    <item>
      <title>总结 | 2016年最值得读的自然语言处理领域Paper</title>
      <link>http://www.iwgc.cn/link/4179114</link>
      <description>&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;引言&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;经过大家的投票和补充，paperweekly选出了15篇2016年最值得读的自然语言处理领域相关Paper，排序按照时间顺序，覆盖了几大热门研究方向。&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/h1&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;1、Learning to Compose Neural Networks for Question Answering&lt;/strong&gt;&lt;/h1&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="作者" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Jacob Andreas, Marcus Rohrbach, Trevor Darrell, Dan Klein&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="单位" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;单位&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Department of Electrical Engineering and Computer Sciences&lt;br/&gt;University of California, Berkeley&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="关键词" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;关键词&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Question Answering&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="Text understanding with the attention sum reader network" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;2、Text understanding with the attention sum reader network&lt;/strong&gt;&lt;/h1&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="作者" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Rudolf Kadlec, Martin Schmid, Ondrej Bajgar, Jan Kleindienst&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="单位" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;单位&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;IBM Watson&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="关键词" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;关键词&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Machine Reading Comprehension&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="Improving Information Extraction by Acquiring External Evidence with Reinforcement Learning" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;3、Improving Information Extraction by Acquiring External Evidence with Reinforcement Learning&lt;/strong&gt;&lt;/h1&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="作者" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Karthik Narasimhan, Adam Yala, Regina Barzilay&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="单位" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;单位&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;CSAIL, MIT&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="关键词" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;关键词&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Information Extraction; Reinforcement Learning&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="Pointing the Unknown Words" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;4、Pointing the Unknown Words&lt;/strong&gt;&lt;/h1&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="作者" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Caglar Gulcehre, Sungjin Ahn, Ramesh Nallapati, Bowen Zhou, Yoshua Bengio&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="单位" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;单位&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Universite de Montr´eal&lt;br/&gt;IBM T.J. Watson Research&lt;br/&gt;CIFAR Senior Fellow&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="关键词" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;关键词&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Unknown Words&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="Sequence-to-Sequence Learning as Beam-Search Optimization" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;5、Sequence-to-Sequence Learning as Beam-Search Optimization&lt;/strong&gt;&lt;/h1&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="作者" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Sam Wiseman, Alexander M. Rush&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="单位" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;单位&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;School of Engineering and Applied Sciences, Harvard University&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="关键词" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;关键词&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Seq2Seq; Beam Search&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="SQuAD: 100,000+ Questions for Machine Comprehension of Text" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;6、SQuAD: 100,000+ Questions for Machine Comprehension of Text&lt;/strong&gt;&lt;/h1&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="作者" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, Percy Liang&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="单位" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;单位&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Computer Science Department&lt;br/&gt;Stanford University&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="关键词" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;关键词&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Machine Reading Comprehension; Dataset&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="End-to-End Reinforcement Learning of Dialogue Agents for Information Access" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;7、End-to-End Reinforcement Learning of Dialogue Agents for Information Access&lt;/strong&gt;&lt;/h1&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="作者" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Bhuwan Dhingra, Lihong Li, Xiujun Li, Jianfeng Gao, Yun-Nung Chen, Faisal Ahmed, Li Deng&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="单位" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;单位&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;School of Computer Science, Carnegie Mellon University&lt;br/&gt;Microsoft Research&lt;br/&gt;National Taiwan University&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="关键词" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;关键词&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Reinforcement Learning; Dialogue System&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="ReasoNet: Learning to Stop Reading in Machine Comprehension" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;8、ReasoNet: Learning to Stop Reading in Machine Comprehension&lt;/strong&gt;&lt;/h1&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="作者" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Yelong Shen, Po-Sen Huang, Jianfeng Gao, Weizhu Chen&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="单位" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;单位&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Microsoft Research Redmond&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="关键词" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;关键词&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Machine Reading Comprehension&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="Personalizing a Dialogue System with Transfer Learning" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;9、Personalizing a Dialogue System with Transfer Learning&lt;/strong&gt;&lt;/h1&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="作者" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Kaixiang Mo, Shuangyin Li, Yu Zhang, Jiajun Li, Qiang Yang&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="单位" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;单位&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;The Hong Kong University of Science and Technology&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="关键词" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;关键词&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Dialogue System; Transfer Learning&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="LightRNN Memory and Computation-Efficient Recurrent Neural Network" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;10、LightRNN Memory and Computation-Efficient Recurrent Neural Network&lt;/strong&gt;&lt;/h1&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="作者" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Xiang Li, Tao Qin, Jian Yang, Tie-Yan Liu&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="单位" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;单位&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Nanjing University of Science and Technology&lt;br/&gt;Microsoft Research Asia&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="关键词" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;关键词&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;New Recurrent Neural Network&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;11、Dual Learning for Machine Translation&lt;/strong&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="作者" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Yingce Xia, Di He, Tao Qin, Liwei Wang, Nenghai Yu, Tie-Yan Liu, Wei-Ying Ma&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="单位" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;单位&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;University of Science and Technology of China&lt;br/&gt;Key Laboratory of Machine Perception (MOE), School of EECS, Peking University&lt;br/&gt;Microsoft Research&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="关键词" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;关键词&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Dual Learning; Neural Machine Translation&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="Neural Machine Translation with Reconstruction" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;12、Neural Machine Translation with Reconstruction&lt;/strong&gt;&lt;/h1&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="作者" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Zhaopeng Tu, Yang Liu, Lifeng Shang, Xiaohua Liu, Hang Li&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="单位" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;单位&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Noah’s Ark Lab, Huawei Technologies&lt;br/&gt;Department of Computer Science and Technology, Tsinghua University&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="关键词" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;关键词&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Neural Machine Translation&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="Linguistically Regularized LSTMs for Sentiment Classification" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;13、Linguistically Regularized LSTMs for Sentiment Classification&lt;/strong&gt;&lt;/h1&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="作者" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Qiao Qian, Minlie Huang, Xiaoyan Zhu&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="单位" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;单位&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;State Key Lab. of Intelligent Technology and Systems, National Lab. for Information Science and Technology&lt;br/&gt;Dept. of Computer Science and Technology, Tsinghua University&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="关键词" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;关键词&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Sentiment Classification; LSTM&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="Google’s Multilingual Neural Machine Translation System: Enabling Zero-Shot Translation" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;14、Google’s Multilingual Neural Machine Translation System: Enabling Zero-Shot Translation&lt;/strong&gt;&lt;/h1&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="作者" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Melvin Johnson, Mike Schuster, Quoc V. Le, Maxim Krikun, Yonghui Wu, Zhifeng Chen, Nikhil Thorat, Fernanda Viégas, Martin Wattenberg, Greg Corrado, Macduff Hughes, Jeffrey Dean&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="单位" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;单位&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Google&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="关键词" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;关键词&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Multilingual Neural Machine Translation; Zero-Shot&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;br/&gt;&lt;/h1&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="Language Modeling with Gated Convolutional Networks" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;15、Language Modeling with Gated Convolutional Networks&lt;/strong&gt;&lt;/h1&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="作者" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Yann N. Dauphin, Angela Fan, Michael Auli, David Grangier&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="单位" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;单位&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Facebook AI Research&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a title="关键词" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;关键词&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Language Modeling; Gated CNN&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;如果您觉得还有非常不错的NLP Paper没有出现在这个list中，请留言或移步到此处进行补充或评论&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnS1GUib7okSxFQF1fQwc5xLtCEp2FncdcyYwOJ5EZTuTS24gictT5rahQMYRhaJLJIaQJvkCibJdcng/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;下载&lt;/strong&gt;&lt;/span&gt;所有Paper请戳这里&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnS1GUib7okSxFQF1fQwc5xLAN8KauGFCvk06rMLP05gCW2tXBob9icLDWXichbOOWIs83uxViaBP7Yzw/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;关于PaperWeekly&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;PaperWeekly是一个分享知识和交流学问的学术组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;微信公众号：PaperWeekly&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkSMlEJFo90NY8rCXr3mJMBibduVHxMKSHzQtVkHz8kNwpjCKBiccGuqLE0WpPuAbdtEs6cTF5iabpAQ/640?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;微博账号：PaperWeekly（&lt;a target="_blank" rel="external" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;http://weibo.com/u/2678093863&lt;/a&gt;&amp;nbsp;）&lt;br/&gt;微信交流群：微信+ zhangjun168305（请备注：加群交流或参与写paper note）&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 03 Jan 2017 13:30:23 +0800</pubDate>
    </item>
    <item>
      <title>深度 | 对比深度学习十大框架：TensorFlow最流行但并不是最好</title>
      <link>http://www.iwgc.cn/link/4167586</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Medium&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀、朱思颖、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;2016 年已经过去，BEEVA Labs 数据分析师 Ricardo Guerrero Gomez-Ol 近日在 Medium 上发表了一篇文章，盘点了目前最流行的深度学习框架。为什么要做这一个盘点呢？他写道：「我常听到人们谈论深度学习——我该从哪里开始呢？TensorFlow 是现在最流行的吧？我听说 Caffe 很常用，但会不会太难了？在 BEEVA Labs，我们常常需要应对许多不同的深度学习库，所以我希望能够将我们的发现和感想分享出来，帮助那些刚刚进入深度学习这一美丽世界的人。」&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;TensorFlow&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://www.tensorflow.org/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于那些听说过深度学习但还没有太过专门深入的人来说，TensorFlow 是他们最喜欢的深度学习框架，但在这里我要澄清一些事实。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 TensorFlow 的官网上，它被定义为「一个用于机器智能的开源软件库」，但我觉得应该这么定义：TensorFlow 是一个使用数据流图（data flow graphs）进行数值计算的开源软件库。在这里，他们没有将 TensorFlow 包含在「深度学习框架」范围内，而是和 Theano 一起被包含在「图编译器（graph compilers）」类别中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在结束了 Udacity 的 Deep Learning 课程（https://www.udacity.com/course/deep-learning--ud730）之后，我的感觉是 TensorFlow 是一个非常好的框架，但是却非常低层。使用 TensorFlow 需要编写大量的代码，你必须一遍又一遍地重新发明轮子。而且我并不是唯一一个这么想的人。Andrej Karpathy 在 Twitter 上就多次吐过槽：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8L6gHxjMvmaS6FWuRBT09iclGVaiaibuJKa679nxARLzR4bVjTxTvicl27s3DYOUv9dmGnZNzWh7icm4g/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;推文：我希望 TensorFlow 能标准化我们的代码，但它是低层面的，所以我们在其上面的层上分道扬镳了：Slim、PrettyTensor、Keras、TFLearn ...&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8L6gHxjMvmaS6FWuRBT09icZotWP3DpTVYxCy3Rhq9HLCjTW2lAl3wFnUs4VMs1BjIeG4LF4fsfMA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;比如：我们在 OpenAI 使用 TensorFlow，但我们似乎都更喜欢其它框架，我们有些人还写自定义代码。叹&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;几个月前，我去参加了「Google Experts Summit: TensorFlow, Machine Learning for everyone, with Sergio Guadarrama」。Sergio 是开发 TensorFlow 的一位工程师，但他在会上没有展示 TensorFlow，而是展示了一个在 TensorFlow 上工作的更高层的库 tf.contrib：https://www.tensorflow.org/tutorials/tflearn/。我的看法是：他们内部已经意识到如果要让更多人使用 TensorFlow，他们就需要以更高的抽象水平在其上创建一些层，从而简化 TensorFlow 的使用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;TensorFlow 支持 Python 和 C++，也允许在 CPU 和 GPU 上的计算分布，甚至支持使用 gRPC 进行水平扩展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;总结：TensorFlow 非常好，但你必须了解它好在哪里。如果你不想什么事都自己手动去做和重新发明轮子，你可以使用更简单的库（安利一下 Keras）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Theano&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：http://deeplearning.net/software/theano/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Theano 是最老牌和最稳定的库之一。据我所知，深度学习库的开端不是 Caffe 就是 Theano。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;和 TensorFlow 类似，Theano 是一个比较低层的库。也因此它并不适合深度学习，而更适合数值计算优化。它支持自动的函数梯度计算，带有 Python 接口并集成了 Numpy，这使得它从一开始就成为了通用深度学习领域最常使用的库之一。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今天，Theano 依然效果良好，但由于它不支持多 GPU 和水平扩展，在 TensorFlow 的热潮下（它们针对同一个领域），Theano 已然开始被遗忘了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Keras&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://keras.io/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「You have just found Keras.」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;上面这句话是你打开文档页面时看到的第一句话。我还记得我第一次发现 Keras 的时候。那时候我正在柏林解决 Data Science Retreat 的最后一个项目，为此我努力进入了深度学习库的世界。我在起步时就已经有了足够的深度学习知识，但我没有时间自己手动编写功能，也没有时间探索和学习一个新的库（截止时间不到 2 个月，而我还有课要上）。然后我发现了 Keras。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我真的很喜欢 Keras，因为它的句法是相当明晰的，它的文档也非常好（尽管相对较新），而且它支持我已经掌握的语言 Python。它的使用非常简单轻松；我们也能很直观地了解它的指令、函数和每个模块之间的链接方式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Keras 是一个非常高层的库，可以工作在 Theano 和 TensorFlow（可以配置）之上。另外，Keras 强调极简主义——你只需几行代码就能构建一个神经网络。在这里你可以比较一下 Keras 和 TensorFlow 实现相同功能时所需的代码：https://gist.github.com/ricgu8086/0ba44ce3aab19ec50425383a4d778b50&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Lasagne&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：http://lasagne.readthedocs.io/en/latest/index.html&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Lasagne 是一个工作在 Theano 之上的库。它的使命是简化一点深度学习算法之下的复杂计算，同时也提供了一个更加友好的接口（也是 Python 的）。这是一个老牌的库，并且很长时间以来它都是一个扩展能力很强的工具；但在我看来，它的发展速度赶不上 Keras。它们的适用领域都差不多，但 Keras 有更好的文档、也更完整。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Caffe&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：http://caffe.berkeleyvision.org/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Caffe 不只是最老牌的框架之一，而是老牌中的老牌。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在我看来，Caffe 有非常好的特性，但也有一些小缺点。起初的时候它并不是一个通用框架，而仅仅关注计算机视觉，但它具有非常好的通用性。在我们实验室的实验中，CaffeNet 架构的训练时间在 Caffe 中比在 Keras 中（使用了 Theano 后端）少 5 倍。Caffe 的缺点是它不够灵活。如果你想给它来一点新改变，那你就需要使用 C++ 和 CUDA 编程，不过你也可以使用 Python 或 Matlab 接口进行一些小改变。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Caffe 的文档非常贫乏。你需要花大量时间检查代码才能理解它（Xavier 初始化有什么用？Glorot 是什么？）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Caffe 的最大缺点之一是它的安装。它需要解决大量的依赖包……我曾经安装过 Caffe 两次，真正痛苦至极。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但要清楚，Caffe 并不是一无是处。在投入了生产的计算机视觉系统的工具上，Caffe 是无可争议的领导者。它非常稳健非常快速。我的建议是：用 Keras 进行实验和测试，然后迁移到 Caffe 中进行生产。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;DSSTNE&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://github.com/amznlabs/amazon-dsstne&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;DSSTNE 的发音同 Destiny，是一个酷劲十足的框架却总是被忽略。为什么？除去其他的因素不谈，原因在于这个框架不具有普适性，不是为一般常见任务所设计的。DSSTNE 框架只做一件事——推荐系统，但把这件事做到了极致。既不是为研究而设计，也不是为测试 idea 而设计（来源其官方网站的宣传语），DSSTNE 框架是为量产而设计。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们已在 BEEVA 上做一些实验测试了，目前我已经感觉到这是一个运行非常快的工具并且能够得到非常好的运行结果（平均准确率均值——mAP 很高）。为了达到这一速度，DSSTNE 框架用 GPU 运行，这也是它的弊端之一：不同于篇中分析的其他框架或者库，这个框架不支持使用者随意在 CPU 和 GPU 中切换，而这可能会对有些尝试有用，但我们在 DSSTNE 里做这样的尝试时是不被框架所允许的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其他的感受就是迄今为止 DSSTNE 还不是一个足够成熟的项目，而且它封装的太严密了（「black box」）。如果我们想深入了解这个框架的运行机制是什么，我们必须且只能去看它的源码，并且你需要完成很多必须完成的设置（「TODO」）才可以看到。同时，关于这个框架的在线教程不多，而能让开发者进行操作尝试的指导就更少了。我的意见是再等 4 个月看看 DSSTNE 的最新版本。不能不说 DSSTEN 的确是一个很有意思的项目但还需要一点成长空间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;还想说明一点，这个框架对编程能力没有要求。DSSTNE 框架通过其终端的命令行来执行相关操作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;到目前为止，很多我知道也很流行的框架和库我还没有用过，我不能给出更多具体的细节。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Torch&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：http://torch.ch/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这个世界上每天仍有很多战争，但是一个优秀的「勇士」（西班牙语「Guerrero」）必须熟知哪些战争是需要去参加作战的，哪些是可以选择不参与的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Torch 是一个很著名的框架，因巨头 Facebook 的人工智能研究所用的框架是 Torch，并且在被谷歌收购之前 DeepMind 也是用的 Torch（收购之后 DeepMind 转向了 TensorFlow）。Torch 的编程语言是 Lua，这就是我刚才所谈的「战争」的具体所指。在目前深度学习编程语言绝大部分以 Python 实现为主的大趋势下，一个以 Lua 为编程语言的框架的最大劣势莫过于此。我从未用使用过这个语言，如果我想使用 Torch 这个工具，毫无疑问我需要先学习 Lua 语言然后才能使用 Torch。这固然是一个合理的过程，但就我个人情况来说，我偏向于用 Python、Matlab 或者 C++的实现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;MXNet&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://github.com/dmlc/mxnet&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;mxnet 是一个支持大多数编程语言的框架之一，包括 Python，R，C++，Julia 等。但我觉得使用 R 语言的开发者会特别偏爱 mxnet，因为至今为止还是 Python 以不可置疑的态势称霸深度学习语言的（Python 与 R 的对决，猜猜我会站哪边？:-p）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;老实说，在此之前我并没有很关注 mxnet。但是当亚马逊 AWS 宣布选择 mxnet 作为其深度学习 AMI 的库时触发我开始关注 mxnet。我必须去了解一下。后来我获知亚马逊把 mxnet 列为其深度学习的参考库并宣称其巨大的横向扩展能力。我感觉到这里面有一些新的改变发生而且我必须深入了解。这也是为什么我们 2017 的 BEEVA 的技术测试名单里有 mnxet 的原因。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我对多 GPU 的扩展能力有点疑虑并且我很原意去了解这样实验的更多细节，但目前我还是对 mxnet 持怀疑态度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;DL4J&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://deeplearning4j.org/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我接触这一库，是因为它的 documentation。当时我正在寻找受限玻尔兹曼机、自编码器，在 DL4J 中找到了这两个 documentation。里面的文件很清楚，有理论，有代码案例。我必须得说 DL4J 的 documentation 简直是艺术品，其他库在记录代码的时候需要向它学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;DL4J 背后的公司 Skymind 意识到，虽然在深度学习圈内 Python 是老大，但大部分程序员起自 Java，所以需要找到一个解决方案。DL4J 兼容 JVM，也适用 Java、Clojure 和 Scala，随着 Scala 的起起落落，它也被很多有潜力的创业公司使用，所以我还会继续紧追这个库。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此外，Skymind 的 twitter 账户非常活跃，不断公开最新的科学论文、案例和教程，及其推荐大家关注。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Cognitive Toolkit&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://github.com/Microsoft/CNTK&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;认知工具包（Cognitive Toolkit）之前被大家所知的缩略是 CNTK，但是最近又重命名回归到 Cognitive Toolkit，很可能是想沾最近微软认知服务（Microsoft Cognitive services）的光。在公开的基准测试上的表现来看，这个工具似乎很强劲，支持纵向和横向的推移。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前为止，Cognitive Toolkit 似乎不是很流行。我并没有读到很多关于使用这个库的博客、在线实验案例或者在 Kaggle 里的相关评论。但是对我来说，一个背靠微软研究的框架特别强调自己的推移能力让我觉得有些奇怪，毕竟微软研究团队可是在语音识别上打破世界纪录并逼近人类水准。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我在查看他们项目百科的一个范例的时候了解到 Cognitive Toolkit 在 Python 上的语法和 Keras 是非常相类似的（Cognitive Toolkit 也支持 C++），这不禁让我在想（并不是确认）Keras 才是正确的方式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;结论&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我的结论是：如果你想进入这一领域，你应该首先学习 Python。尽管这一领域还支持其它很多语言，但 Python 是应用范围最广而且最简单的一个。但是为什么要选择 Python 呢——毕竟 Python 速度这么慢？因为大多数的库都使用的是符号式语言（symbolic language）方法而非命令式语言（imperative language）方法。解释一下也就是说：不是一条接一条地执行你的指令，而是根据你给出的所有指令创建一个计算图（computing graph）。这个图被内部优化和编译成可执行的 C++ 代码。这样你就能同时利用上两个世界的最优之处：Python 带来的开发速度和 C++ 带来的执行速度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人们对深度学习的兴趣越来越大了，但人们并不愿意等待算法训练所需的大量计算时间（而且我说的是 GPU，想都不要想只使用 CPU）。这也是多 GPU 支持、多机器上的水平扩展甚至定制硬件最近开始得势的原因。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深度学习领域非常活跃、易变。很可能我现在所说的在 2017 年的中旬就变了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我的建议是，如果你是初学者，使用 Keras，如果不是初学者，也可以使用它。如果你参加过 Kaggle 比赛，你肯定注意到了 Kaggle 的两大巨星：Keras 和 XGBoost。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文链接：&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;https://medium.com/@ricardo.guerrero/deep-learning-frameworks-a-review-before-finishing-2016-5b3ab4010b06#.z8zuthuwm&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 02 Jan 2017 12:52:58 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 中国担前锋：外媒谈亚洲人工智能的潜力</title>
      <link>http://www.iwgc.cn/link/4167587</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自SCMP&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：蒋思源、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote style="color: rgb(62, 62, 62); font-size: 16px; white-space: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/blockquote&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;在取得突破性进展后的一年，专家们认为通过人工智能人们日常生活正处于濒临变革的边缘，亚洲能在这个变革中取得领导地位。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8L6gHxjMvmaS6FWuRBT09iceibiaK2wp8VzzIhEOSibS3iaWuh5gyJKCT9YcIKbCcVKod8hkU1HOYlaicQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;由中国大学生设计的一种人形双足机器人在北京世界机器人会议展示。领先技术专家说，今年可能在智能机器模拟人类的发展上实现突破性的一年。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尝试在谷歌搜索框中输入「机器」，这个人工智能驱动的搜索引擎中最可能出现在搜索结果前几位的可能就是「机器智能来了（The Machines are Coming）」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能在 2016 年取得备受瞩目的进步后，领先技术专家说，今年可能是智能机器在模拟人类上实现突破性发展的一年。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;专家说亚洲虽然现在在人工智能领域上还落后于硅谷，但是与该领域的技术前列结合在一起，亚洲将在 2017 年发挥更重要的作用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能是涉及通过大量数据分析来预测结果和模式的计算领域，它几乎和现代计算机一样古老，但是它深奥的本质使它长期以来都难以实现实际的应用。例如 20 世纪 60 年代的以太空时代为题材的漫画 The Jetsons，它里面有一个有感情的女仆机器人和自动飞行汽车，这些在 50 年后的今天仍然只是想象。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8L6gHxjMvmaS6FWuRBT09ic4vDmAT3NNKrcx5Td75xcJm7Jj7367v8xQoZFyMUkDS4tYNwpjTMWeA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;来自 The Jetsons 中 Rosie 机器人的模型，照片：AFP&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而三月份 AlphaGo 的成功又重新在公共意识中唤起了对人工智能的热情。AlphaGo 是一个复杂的谷歌人工智能程序，其上演了在古老的中国围棋上战胜围棋大师的惊人一幕，它甚至超越了我们对最先进计算机的理解。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;瞬时，硅谷最大的公司连同中国最大的三家科技公司「BAT——百度、阿里巴巴和腾讯」就像人工智能研究投入了数十亿美元。由于人工智能的发展涉及到迅猛发展的大数据和计算能力，这一领域终于从计算机荒野中走出来了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能研究者说该技术有可能彻底改变全球经济和人类生活的每一个方面，从检测和治疗癌症到管理咨询和投资银行指导。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Facebook 的人工智能研究工程师 Soumith Chintala 表示：「我们预计未来几年内，驱动自动驾驶汽车的技术和推动 AlphaGo 的技术将被整合到不同领域，如交通和医疗保健」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2016 年，人工智能引起狂热主要是由于在「机器学习」和「深度学习」子领域的进步。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8L6gHxjMvmaS6FWuRBT09icWBVOy5Q3jvGavIAriaBZm4khJ2UynyRgya1AncUGlgt9D8pqR6wLyDA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;韩国的围棋大师李世乭对战 AlphaGo 丢掉了最后一局，最终以 1 比 4 不敌人工智能系统。图片：AP&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器学习是一个训练算法来执行它没有被明确编程任务的过程，在这过程中需要使用与该任务相关的大量数据进行训练。深度学习技术是机器学习的一个子领域。它的目的是模仿人类大脑中的神经网络，从而通过人工神经元矩阵传递大量的数据，并且在人工神经元矩阵中高速处理与分析数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;香港科技大学的人工智能研究员 Pascale Fung 表示，在开发类似人类大脑计算机的方面已经有几个里程碑了。语音识别和情绪分析就是「到达了新里程碑」的领域。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;聚焦亚洲的人工智能专家也表示虽然该地区在研究方面落后于西方国家，但其技术公司和大学有巨大的潜力弥补这段差距。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8L6gHxjMvmaS6FWuRBT09icibLYH8KeuvDRu4Tia94iaLZtISwDp6ibphE8DXS174XBemicDxpOib09tGicg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;百度高级数据科学家吴海山在北京百度技术园区，百度被公认为是亚洲人工智能研究的前沿。照片：Bloomberg&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;百度是中国顶尖的搜索引擎，被广泛认为是亚洲人工智能的最前沿，它在北京和硅谷都有人工智能实验室。早在 2014 年，百度就聘请了吴恩达——他以前领导过谷歌的人工智能业务，并联合创立了网上学习平台 Coursera。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Zeroth.ai（一个亚洲人工智能初创公司孵化器）的香港常务董事 Tak Lo 说：「BAT 公司知道他们必须与谷歌和 Facebook 那样的公司争夺人工智能人才，我们很可能在未来几年看到这种情况急剧升温。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Tak 说，在中国、日本和韩国等国的国家战略中存在创业生态系统，与西方的整体式发展相比，这种创业生态系统可能是亚洲在人工智能领域增长的绊脚石。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Facebook 的印度裔专家 Chintala 说，亚洲人是全球人工智能和深度学习研究社区的重要组成部分。他说：「作为个人，我们已经对该领域产生良好的影响。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这位位于纽约的研究者说，但是在像印度这样的地方研究更倾向「比顶级美国与欧洲大学或实验室的研究低层次的研究。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「这是缓慢但稳步变化的过程，弥合这一差距的关键是为年轻研究人员提供良好的培养指导计划，这种情况正在迅速发生。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;领先的亚洲枢纽新加坡和香港已经孵化了几家关注于深度学习的初创公司，它们是在部分业务需要技术提供支持的浪潮下建立的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;技术数据和研究公司 CB Insights 在 12 月表示，自 2011 年以来，全球共收购了 137 家人工智能关联的初创企业，光是今年就有 40 家。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中有专门从事人工智能「聊天机器人」公司。聊天机器人是一种基于深度学习技术的软件，它能帮助用户使用语音或文字执行如点餐、支付或叫车等任务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8L6gHxjMvmaS6FWuRBT09icwEKvqVPsedvX8CnaCSPf2mybrsPyJLPh5ibOCBBncnraOrXHicO4crfA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;聊天机器人是一种基于深度学习技术的软件，它能帮助用户使用语音或文字执行如点餐、支付或叫车等任务。照片：Edward Wong&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Active.ai 就是一家在新加坡这样的公司。它开发的聊天机&lt;/span&gt;&lt;span&gt;器人能通过与人工智能驱动平台的对话能给银行客户提供业务上的指导。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该公司的联合创始人 Shankar Narayanan 说：「我们以前有网络银行，然后是移动银行和移动优先的时代。现在我们正在进入一个人工智能银行和人工智能优先的时代。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在香港，早期阶段的创业公司 Clare.ai 正在开发类似的智能聊天机器人技术，除了英语和其它主要语言之外，它还支持粤语。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这家香港公司的联合创始人 Ken Leung 说：「在 2017 年，我们将看到银行、保险公司和零售公司等企业进一步使用这种技术。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8L6gHxjMvmaS6FWuRBT09icxWyOQmXup2XYnI2mP3pibicag0XNzXpaxEAY77Bqey8vFRHynyiaW0xmQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;电视机正展示谷歌人工智能系统 AlphaGo 打败韩国围棋大师李世乭。照片：AP&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;香港科技大学研究员 Fung 表示，中国有世界上最重要的制造业基地，并且因为「研究、开发和制造之间的合作可以快速完成」，所以中国在人工智能产业开发上有独一无二的优势。中国 BAT 互联网三巨头的数据宝库也可以看到这些公司正使用「最新的机器学习算法来利用这些数据改善他们的服务」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在人工智能令人眼花缭乱的潜力下，专家们强调需要抑制过高期望和对人工智能可能对人类生活不利的恐惧。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2016 年 9 月，美国几家主要科技公司达成了一项合作关系 Partnership on Artificial Intelligence to Benefit People and Society——这是一个非营利性质的联盟，将主要从事人工智能道德伦理方面的研究以及「推进公众对技术的理解和认知」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「理解人工智能到底什么是非常重要的，因为如果我们不理解它到底是什么，那么我们就可以高估当前人工智能技术的能力，从而导致出现错误的投资和决策。」Facebook 的研究者 Chintala 说。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他还补充说：「听起来不好但却实际的问题是我们目前只是处在人工智能增量的时刻。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;英国布里斯托尔大学人工智能教授 Nello Cristianini 说，但用户和监管者有必要识别人工智能技术的潜在危害：个人数据的安全、适应性技术的依赖、关于个人财务行为预测的无授权泄漏等等。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Cristianini 说：「如果 2017 年这些领域在带来技术发展的同时也能带来文化上的进展就好了，这样我们才能在太晚了之前觉察到问题。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些专家并不认同可能会出现《终结者》电影里面的「天网（Skynet）」——一种会主宰人类的恶意的计算机网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Fung 说：「其中一些恐惧，比如机器人取代人类，实际上是遥不可及的……我们确实已经取得了很大的进展和突破，但我们离实现通用智能机器还非常遥远。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;原文链接：http://www.scmp.com/week-asia/society/article/2058278/machines-are-coming-chinas-role-future-artificial-intelligence&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 02 Jan 2017 12:52:58 +0800</pubDate>
    </item>
    <item>
      <title>「人工智能研学社· 强化学习组」第二期：超越职业玩家的算法 - Deep Q-network</title>
      <link>http://www.iwgc.cn/link/4167588</link>
      <description>&lt;p&gt;&lt;strong&gt;&lt;span&gt;本期研读论文：Human-level control through deep reinforcement learning&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这篇 Nature 论文可以说引爆了深度强化学习。它介绍了 Deep Q-Networks (DQN) 算法，并且在 49 个 Atari 游戏上取得了很好的性能：基本都超越了以前的算法，大部分比职业玩家要好。这一算法的突出贡献是，在 Q-learning 中引入了深度神经网络，并且通过 experience replay 和 target network 技术稳定学习过程。而在此之前，普遍认为非线性函数近似与 Q-learning 结合就会有不收敛等问题。DQN 使用了端到端机制：输入是游戏几帧的像素，输出是操作策略，中间不需要人为进行特征标记工程。更令人惊讶的是，它用一个神经网络结构，一套超参数设置，就可以玩好 49 个游戏。DQN 算法出现之后，许多改进版本和其它 Deep RL 工作也相继出现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Andrei A. Rusu, Joel Veness, Marc G. Bellemare, Alex Graves, Martin Riedmiller, Andreas K. Fidjeland, Georg Ostrovski, Stig Pe- tersen, Charles Beattie, Amir Sadik, Ioannis Antonoglou, Helen King, Dharshan Kumaran, Daan Wierstra, Shane Legg, and Demis Hassabis. Human-level control through deep reinforcement learning. Nature, 518(7540):529–533, 02 2015. URL http://dx.doi.org/10.1038/ nature14236.&amp;nbsp;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;点击链接阅读：http://www.nature.com/nature/journal/v518/n7540/full/nature14236.html&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;摘要：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;强化学习理论为动物行为提供了一个根植于心理学和神经科学视角的规范化解释，它告诉我们主体（agent）是如何优化他们对环境的控制。然而，为了在接近现实复杂性的情况下成功地使用强化学习，主体面临着一个艰巨的任务：他们必须从高维的感官输入的环境中获得有效的表征，并使用这些表征来将过去的经验应用到新的情境中。值得注意的是，人类和其他动物看起来已经通过结合强化学习和等级知觉处理系统解决了这个问题。人类身上体现出的强化学习理论被丰富的神经数据证实，这些神经数据揭示了多巴胺能神经元释放的相位信号与时域差分强化学习算法之间的显着相似之处。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然强化学习的主体已经在多个领域实现了一些成功，但是它们的应用一直局限于只能指定有用表征的领域，或者能被完全观察的低维状态空间中。我们使用了最近在神经元训练上取得了一些进展，开发出一个新型人工主体，称为 deep Q-network，它可以使用端到端的强化学习，直接从高维知觉输入中学习成功的策略。我们用经典 Atari2600 游戏中具有挑战性的领域测试了这个主体。我们证明，只接收像素和游戏得分作为输入的 deep Q-network 的表现，能超越之前所有算法，并在一组 49 场比赛中达到了相当于专业人类游戏测试者的水平。DQN 使用同样的算法、网络架构和超参数。这个成果在高维知觉输入和行为之间架起了一座桥梁，创造出了世界上第一个具备学习执行多元化的挑战任务能力的人工主体。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;参考资料:&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;h3 style="text-align: justify; line-height: 1.75em;"&gt;&lt;span&gt;Demystifying Deep Reinforcement Learning：https://www.nervanasys.com/demystifying-deep-reinforcement-learning/&lt;/span&gt;&lt;/h3&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Going Deeper Into Reinforcement Learning: Understanding Deep-Q-Networks：https://danieltakeshi.github.io/2016/12/01/going-deeper-into-reinforcement-learning-understanding-dqn/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Frame Skipping and Pre-Processing for Deep Q-Networks on Atari 2600 Games：https://danieltakeshi.github.io/2016/11/25/frame-skipping-and-preprocessing-for-deep-q-networks-on-atari-2600-games/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;https://github.com/spragunr/deep_q_rl&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Using Deep Q-Network to Learn How To Play Flappy Bird：https://github.com/yenchenlin/DeepLearningFlappyBird&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;strong&gt;&lt;span&gt;一些对DQN的扩展&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;h3 style="text-align: justify; line-height: 1.75em;"&gt;&lt;span&gt;Deep Reinforcement Learning with Double Q-learning：https://arxiv.org/abs/1509.06461&lt;/span&gt;&lt;/h3&gt;&lt;/li&gt;&lt;li&gt;&lt;h3 style="text-align: justify; line-height: 1.75em;"&gt;&lt;span&gt;Prioritized Experience Replay：https://arxiv.org/pdf/1511.05952.pdf&lt;/span&gt;&lt;/h3&gt;&lt;/li&gt;&lt;li&gt;&lt;h3 style="text-align: justify; line-height: 1.75em;"&gt;&lt;span&gt;Dueling Network Architectures for Deep Reinforcement Learning：http://jmlr.org/proceedings/papers/v48/wangf16.pdf&lt;/span&gt;&lt;/h3&gt;&lt;/li&gt;&lt;li&gt;&lt;h3 style="text-align: justify; line-height: 1.75em;"&gt;&lt;span&gt;Continuous control with deep reinforcement learning：https://arxiv.org/abs/1509.02971&lt;/span&gt;&lt;/h3&gt;&lt;/li&gt;&lt;li&gt;&lt;h3 style="text-align: justify; line-height: 1.75em;"&gt;&lt;span&gt;Asynchronous Methods for Deep Reinforcement Learning：https://arxiv.org/abs/1509.02971&lt;/span&gt;&lt;/h3&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;推荐者介绍:&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本期研习材料由 Yuxi Li 博士推荐。Yuxi Li 博士是加拿大阿尔伯塔大学（University of Alberta）计算机系博士、博士后。致力于深度学习、强化学习、机器学习、人工智能等前沿技术及其应用。曾任电子科技大学副教授；在美国波士顿任资深数据科学家等。目前在筹备深度学习相关的创业项目。Yuxi Li 博士也将在组内参与专家答疑。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器之心曾经发表过的介绍强化学习的文章：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719294&amp;amp;idx=1&amp;amp;sn=f1a01cd6710e6ea9629619cd3324d102&amp;amp;chksm=871b0040b06c895642ff961a6fe81f05c5e9776aff5da4845f2d3d874f88213863afd2059833&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719294&amp;amp;idx=1&amp;amp;sn=f1a01cd6710e6ea9629619cd3324d102&amp;amp;chksm=871b0040b06c895642ff961a6fe81f05c5e9776aff5da4845f2d3d874f88213863afd2059833&amp;amp;scene=21#wechat_redirect"&gt;深度学习漫游指南：强化学习概览&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718527&amp;amp;idx=1&amp;amp;sn=04db4fc59cc23c079a17573657d2b1c7&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718527&amp;amp;idx=1&amp;amp;sn=04db4fc59cc23c079a17573657d2b1c7&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;ACM 最新月刊文章：强化学习的复兴&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716246&amp;amp;idx=2&amp;amp;sn=2c328097a95839871c8c91c5c5af9de5&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716246&amp;amp;idx=2&amp;amp;sn=2c328097a95839871c8c91c5c5af9de5&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;谷歌总结深度强化学习，人工智能代理表现已达人类水平&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=402228099&amp;amp;idx=1&amp;amp;sn=a8e664d332f7d28250fbbf357c773f62&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=402228099&amp;amp;idx=1&amp;amp;sn=a8e664d332f7d28250fbbf357c773f62&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;神经网络和深度学习简史（三）：强化学习与递归神经网络&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心强化学习小组：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于强化学习这样一个既有历史沉淀又有未来前景的技术领域，你一定充满了好奇和想要学习的渴望。也许你在机器学习和计算机方面已经有了一定的技术积累，但要进入一个新的领域，你可能还是常常感到：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 找不到合适的学习资料&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 有学习动力，但无法坚持&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 学习效果无法评估&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4. 遇到问题缺乏讨论和解答的途径&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此，为了帮助「强化学习新手」进入这一领域，机器之心发起了一个互助式学习小组——「人工智能研学社· 强化学习组」。本小组将通过优质资料分享、教材研习、论文阅读、群组讨论、专家答疑、讲座与分享等形式加强参与者对强化学习和深度学习的理解和认知。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;面向人群：有一定的机器学习技术基础，在强化学习方面处于学习阶段的学习者&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;学习形式：学习资料推荐、统一进度学习（教材或论文）、群组讨论、专家答疑、讲座等。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入方式：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1）添加机器之心小助手微信，并注明：加入强化学习组&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2）完成小助手发送的入群测试（题目会根据每期内容变化），并提交答案，以及其他相关资料（教育背景 、从事行业和职务 、人工智能学习经历等）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3）小助手将邀请成功通过测试的朋友进入「人工智能研学社· 强化学习组」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8L6gHxjMvmaS6FWuRBT09ic199gvWGVJtfW79ePfAsXU6nW8feBzHqDgUibSXFnIZ6icKv0ztJ4bicsg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;入群测试 QUIZ&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1）教育背景 2）从事行业和职务 3）人工智能学习经历 4）强化学习学习经历&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 监督学习与强化学习的区别是什么？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 为什么 Q-learning 与函数近似结合会发散？如何解决？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. What are the differences between supervised learning and reinforcement learning?&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. Why Q-learning tends to be divergent when combined with function approximation? How to solve it?&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;点击阅读原文可填写入群QUIZ表格&lt;/span&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 02 Jan 2017 12:52:58 +0800</pubDate>
    </item>
    <item>
      <title>学界 | 谷歌新论文提出预测器架构：端到端的学习与规划</title>
      <link>http://www.iwgc.cn/link/4167589</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自arxiv.org&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：Jane W&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;论文：预测器：端到端的学习和规划（The Predictron: End-To-End Learning and Planning）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8L6gHxjMvmaS6FWuRBT09icBiaUyaeuIiaUYOKn2JMNIYLAKLuhYP0K9WmNNEKu9QicmSFlk71VH9lnw/0?wx_fmt=jpeg"/&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;摘要&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工&lt;/span&gt;&lt;span&gt;智能的主要挑战之一是在有规划的情况下有效地学习模型。在本文中，我们介绍了一种叫预测器（predictron）的架构。预测器包含一个完全抽象的模型，由带有奖励的马尔可夫过程（Markov reward process）表示，可以向前「想象」多个规划步骤。预测器的每个正向传递（forward pass）在多个规划深度上累积内部奖励（reward）和值。预测器由端对端的方式训练，以使这些累积值准确地近似于真实的价值函数（value function）。我们将预测器应用于程序生成的随机迷宫（maze）和模拟器游戏池（game of pool）。预测器产生比常规深度神经网络架构明显更准确的预测。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;导语&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;基于模型的增强学习（reinforcement learning/RL）的核心思想是将 RL 问题分解为两个子问题：学习环境模型，然后用这个模型进行规划。该模型通常由带有奖励的马尔科夫过程（MRP）或决策过程（decision process/MDP）表示。规划步骤利用此模型来评估和选择可能的策略。这通常通过向前推演模型以构建估计累积奖励的价值函数来实现。之前的研究把模型的训练与使用在规划器的范围内基本上独立分开。因此，训练的模型与 agent 主体的总体目标并不匹配。先前的深度强化学习方法已经成功构建了可以实现接近像素级完美呈现（pixel-perfect）的重建模型（Oh 等人 2015；Chiappa 等人 2016）。但在充满挑战的 RL 领域，用原始数据时，尚未超越最先进的无模型（modelfree method）方法（例如，Mnih 等人 2015；2016；Lillicrap 等人 2016）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在本文中，我们介绍一种新的架构，我们称之为预测器，它将学习和规划步骤集成到一个端到端的训练过程中。agent 每进行一步，模型会基于当前的内部状态（internal state）产生下一状态，估计奖励（reward）、折扣因子（discount）和该状态具有的价值（value）。这个模型是完全抽象的，其唯一的目标是构建准确的价值预测。例如，为了在游戏中有效地计划，agent 必须能够预测得分。如果我们的模型能够做出准确的预测，那么基于这个模型的最佳规划也将是全局最佳规划——即使该模型使用不同的状态空间（state space）（例如，抽象表示的敌人位置，忽略了形状和颜色）、行动空间（action space）（例如，向远离敌人方向移动的高级动作）、奖励（reward）（例如，单个抽象步骤可以具有比任何真实奖励更高的值）、甚至时间步长（timestep）（例如，单个抽象步骤可以让 agent「跳」到走廊的尽头）。我们的目的是通过抽象模型的轨迹产生的分数与通过真实环境的轨迹产生的分数一致。这通过端对端地训练预测器来实现，以使得其值估计尽可能准确。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;理想模型可以推广到许多不同的预测任务，而不是过度拟合单个任务；并且可以从丰富多样的反馈信号（feedback signal）中学习，而不仅仅是外在奖励。因此，我们训练预测器来预测大量不同的价值函数，这些价值函数具有不同的拟奖励函数（pseudoreward function）和折扣因子（discount factor）。这些拟奖励可以用于估计 agent 可能碰到的任何事件或环境，例如，不休眠或进入下一个房间。该模型专注于预测任务：估计在动力不受控制的 MRP 环境中的价值函数。在这种情况下，预测器可以当作具有 MRP 循环核（recurrent core）的深度神经网络。预测器将该循环核展开为多个步骤，并累积所有奖励的值作为价值的总体估计。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们将预测器应用于程序生成的随机迷宫和模拟器游泳池并直接传入像素级的输入数据（pixel input）。在这两种情况下，预测器显著优于传统深度神经网络架构的无模型算法（model-free algorithm）；并且在诸如深度（depth）等架构参数的选择上更加鲁棒。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8L6gHxjMvmaS6FWuRBT09icia3eSiaTFByb8590hiaGmpkvVHokaDbiaYiaHf2KEoPhY1D3aUMiczRO6rbQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 1：a) 预测器架构。前 3 列图分别展现了 0、1、2 步的预测器的路径。0 步的 preturn 退化为标准无模型的价值函数的近似形式；其它 preturn 通过一个内部模型「想象」额外的步骤。每个路径输出 k 步的 preturn（g_k）, 这个 preturn 包含了累积折扣奖励（discounted reward）和最终价值函数的估计值。在实践中，所有 k 步的 preturn 都只在向前路径中计算。b) 第 4 列显示了λ-预测器的架构。不同的λ参数阈值对应不同的 preturn。输出是λ-preturn 记为 g_λ，它是 k 步 preturn 的组合值。例如，如果λ_0=I，λ_1=I，λ_2=0，那么我们将 2 步的 preturn 修正为 g_λ=g_2。折扣因子γ_k 和λ参数λ_k 取决于状态 s_k；这种相关性在图中未示出。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 02 Jan 2017 12:52:58 +0800</pubDate>
    </item>
    <item>
      <title>机器之心独家盘点：2016人工智能领域十大焦点回顾</title>
      <link>http://www.iwgc.cn/link/4157510</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;吴攀、李泽南&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;刚刚过去的 2016 年，这个世界发生了很多大事：从越搅越乱的中东乱局到出人意料的英国退欧、再从戏剧性十足的美国大选到毫无疑问的中国继续崛起……这个世界似乎正在发生着什么翻天覆地的变化。不管这些变化是否符合我们的期待，我们都可以确信在这些变化之后，科学技术的持续进步无疑是其中最大的推动力量之一。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这方面，随着深度学习在最近几年的突然高速崛起，人工智能的发展已经成为了科技发展中一股不可忽视的巨大力量，甚至有许多学术界和产业界的专业人士将其看作是未来技术进步的最底层的技术革命之一。粗略估计，在可预见的时间内，人工智能将带来颠覆性影响的领域将包括但不仅限于：翻译、广告、通信、运输、图像……甚至有些眼光长远的「预言家」还认为人工智能不仅将改变我们的生活方式，还将改变我们对人类、智能乃至宇宙的本质的理解。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;和这个世界一样，过去的一年的人工智能也发现了很多重大的事件。现在就让我们站在新一年的起点回顾一下过去这人工智能高速发展的一年：人工智能成长为了游戏高手、围棋大师、语音转录专家、司机、翻译家、图像艺术家、鉴黄师、武器……机器之心对 2016 年的人工智能领域内的事件进行了盘点，从中选取了我们心中的十大最具里程碑意义和最引人关注的焦点事件。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;iframe class="video_iframe" data-vidtype="1" allowfullscreen="" frameborder="0" height="417" width="556" data-src="https://v.qq.com/iframe/preview.html?vid=i03618p1efw&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0"&gt;&lt;/iframe&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心年度视频：3分钟带你回顾2016人工智能大事件&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;No.1 人机世纪大战：李世石 vs. AlphaGo&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;里程碑意义：★★★★★&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;社会关注度：★★★★★&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9ib7qeAzkJbnskHfbTEctNsgjt6Cryd5xelKqHcGcDVZLkW9pAwwKqKA6eQp3a41bd0xSrEQTR8Lw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2016 年 3 月，人类在棋盘游戏上的最后一块保留地被机器攻陷：世界围棋大师在韩国首尔以 1:4 的成绩不敌 Google DeepMind 开发的人工智能程序 AlphaGo，引起了世界各地人民的广泛关注和热议。赛后韩国棋院授予 AlphaGo 荣誉九段的段位，赛后不久 AlphaGo 的世界排名 (https://www.goratings.org/) 就升至了第二。到 7 月 17 日，原本世界排名第一的围棋大师柯洁由于在海峡两岸世界冠军争霸赛中表现不佳，积分下跌，AlphaGo 反超柯洁，排名在世界第一的位置维持了一段时间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;AlphaGo 的开发团队是英国人工智能研究公司 DeepMind，该公司在 2014 年被谷歌收购之后迅速成长为了人工智能研究领域的一大重镇。在天才研究者 Demis Hassabis 的带领下，DeepMind 的规模不断扩张，吸引了大量来自世界各地的人工智能人才，也在许多研究领域实现了很多重要的突破。其中包括掌握 Atari 游戏、&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719022&amp;amp;idx=1&amp;amp;sn=3eeb1958e695388817dd32b0d228ced9&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719022&amp;amp;idx=1&amp;amp;sn=3eeb1958e695388817dd32b0d228ced9&amp;amp;scene=21#wechat_redirect"&gt;语音合成&lt;/a&gt;、&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720335&amp;amp;idx=1&amp;amp;sn=b030d7f82d10acde0378035c900264df&amp;amp;chksm=871b0c31b06c852746f35e16814808ceb13e91b091732afa48b2bb8c6d6f2f542df26e7f5575&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720335&amp;amp;idx=1&amp;amp;sn=b030d7f82d10acde0378035c900264df&amp;amp;chksm=871b0c31b06c852746f35e16814808ceb13e91b091732afa48b2bb8c6d6f2f542df26e7f5575&amp;amp;scene=21#wechat_redirect"&gt;解读唇语&lt;/a&gt;、&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715835&amp;amp;idx=1&amp;amp;sn=9d4f052cf1468b167c7c56bf631ef789&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715835&amp;amp;idx=1&amp;amp;sn=9d4f052cf1468b167c7c56bf631ef789&amp;amp;scene=21#wechat_redirect"&gt;规划地铁路径&lt;/a&gt;、提出重量级的&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719745&amp;amp;idx=2&amp;amp;sn=242eda88fa9a5572e60b43e451a1549b&amp;amp;chksm=871b027fb06c8b693cff17f43553625f008fcb7965582119b651dbbd17e116e35dc801ebeec3&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719745&amp;amp;idx=2&amp;amp;sn=242eda88fa9a5572e60b43e451a1549b&amp;amp;chksm=871b027fb06c8b693cff17f43553625f008fcb7965582119b651dbbd17e116e35dc801ebeec3&amp;amp;scene=21#wechat_redirect"&gt;可微神经计算机&lt;/a&gt;等等。不仅在研究上，DeepMind 也在尝试将其研究成果产品化，7 月份的时候，谷歌就表示 DeepMind 的深度学习技术可以帮助谷歌的服务器&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717202&amp;amp;idx=3&amp;amp;sn=cbed5925a1c2c7150911c929db084162&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717202&amp;amp;idx=3&amp;amp;sn=cbed5925a1c2c7150911c929db084162&amp;amp;scene=21#wechat_redirect"&gt;节省数亿美元的电费&lt;/a&gt;。除此之外，DeepMind 和英国国家医疗服务体系（NHS）的合作也堪称人工智能在医疗应用上典范代表。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外还有值得一提的是，DeepMind 在棋盘游戏上「将人类踩在脚下」之后，又看上了更复杂的即时战略游戏。11 月份，DeepMind 宣布与著名游戏公司暴雪&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720302&amp;amp;idx=3&amp;amp;sn=756e17424570ea713a15b4a5e4a97666&amp;amp;chksm=871b0c50b06c8546c49e53fd9454846ce6928ce45449726af775f11546c6f27c5b40d2c4a700&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720302&amp;amp;idx=3&amp;amp;sn=756e17424570ea713a15b4a5e4a97666&amp;amp;chksm=871b0c50b06c8546c49e53fd9454846ce6928ce45449726af775f11546c6f27c5b40d2c4a700&amp;amp;scene=21#wechat_redirect"&gt;建立了合作关系&lt;/a&gt;，要让人工智能在基于人类视角和操作速度的基础上征服经典即时战略游戏《星际争霸》。也许不久之后，我们就会看到 DeepMind 实现新的传奇了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;参考阅读：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=402713485&amp;amp;idx=1&amp;amp;sn=eeee4534a1021db9ab06d328b462bea1&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=402713485&amp;amp;idx=1&amp;amp;sn=eeee4534a1021db9ab06d328b462bea1&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;重磅｜AlphaGo 3:0 战胜李世石，机器与人类的共同胜利&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=402734410&amp;amp;idx=1&amp;amp;sn=226cd686358f3c115001d9057445cbb6&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=402734410&amp;amp;idx=1&amp;amp;sn=226cd686358f3c115001d9057445cbb6&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;深度 | AlphaGo 并非革命性突破，但让我们看到了通用人工智能的希望&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;No.2 终结马路杀手，无人驾驶汽车纷纷上路&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;里程碑意义：★★★★★&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;社会关注度：★★★★★&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2016 年，除了时不时就霸占头条的谷歌无人驾驶汽车，也有更多的企业和机构开始在无人驾驶技术的研究和应用上崭露头角，这其中既包括谷歌这样的互联网和技术公司百度、Uber 和 IBM 等，也有通用和本田等传统的汽车制造商，另外也还有特斯拉这样的新一代汽车公司；当然，MIT 和哈佛大学等学术研究重镇也都或多或少有自己的无人驾驶相关的研究项目（包括无人驾驶技术和背后涉及到的社会学、伦理学和法律学问题）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2016 年年初，世界首款无人驾驶公交车在荷兰小镇 Wageningen 正式上路，这款名为 WePod 的电动汽车是由法国机动车制造商 EasyMile 和欧盟运输计划 Citymobil2 设计的，可搭载 6 名乘客，不过其运营路线长度只有 200 米，时速仅有 8 公里。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;去年 8 月，世界首个无人驾驶出租车 nuTonomy 在新加坡正式开始上路测试，参与乘客可以通过智能手机预约。这家从麻省理工学院分离出来的创业公司专门从事开发无人驾驶出租车。虽然谷歌和沃尔沃等的多家公司早已在马路上进行了自动驾驶测试，但 nuTonomy 却成了第一家向公众开放自动驾驶汽车的公司。到年底时，Alphabet/谷歌旗下的无人驾驶项目也终于修成正果，开始以独立公司 Waymo 的形式运营。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9ib7qeAzkJbnskHfbTEctNs9WcretXO6AJHKSFgafPzplrwtQHcyXhmllOicJsfDeJXtxMh2XLbSwA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;无人驾驶的飞速发展也引发了一些问题。过去的一年，特斯拉汽车报告了好几起与其自动驾驶辅助技术 Autopilot 相关的事故，其中一起事故更是造成了车毁人亡的后果（之后特斯拉还为此发表声明警告驾驶者不要完全依赖现在还并不完美的自动驾驶功能）。尽管有这些挫折，但毫无疑问，无人驾驶在过去的一年中确实得到了很大的发展。按照中国和美国 发布的无人驾驶路线图，如果进展顺利，那么也许在未来不到十年之内我们就能用上完全自动驾驶的汽车了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;参考阅读：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717365&amp;amp;idx=1&amp;amp;sn=6b27b788e69daafe1381fad5f5158900&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717365&amp;amp;idx=1&amp;amp;sn=6b27b788e69daafe1381fad5f5158900&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;重磅 | 波士顿咨询报告：自动驾驶汽车、自动驾驶出租车以及城市交通革命（附报告）&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716988&amp;amp;idx=1&amp;amp;sn=65ad0b7c47c2b6c3f1b0b89e6fab1ff5&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716988&amp;amp;idx=1&amp;amp;sn=65ad0b7c47c2b6c3f1b0b89e6fab1ff5&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;深度 | 特斯拉巡航系统供应商 Mobileye 创始人详解自动驾驶三大支柱&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718429&amp;amp;idx=1&amp;amp;sn=46214968459af95e85efe12b8a26b11b&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718429&amp;amp;idx=1&amp;amp;sn=46214968459af95e85efe12b8a26b11b&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;深度 | 英伟达自动驾驶技术解读：用于自动驾驶汽车的端到端深度学习（附论文）&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;No.3 人工智能真的危险吗？持续一整年的人工智能威胁论&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;里程碑意义：★★★★☆&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;社会关注度：★★★★★&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;又过了一年，霍金和马斯克等世界名人的「人工智能威胁」警告继续发酵。尤其是在三月份 AlphaGo 击败了世界围棋大师李世石之后，这些警告也竟开始变得有些说服力了，至少确实有很多人开始认为人工智能存在威胁了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外还有一件事也引起了人们极大的关注，2016 年 3 月份，微软在 Twitter 平台上推出了一个人工智能聊天机器人 Tay；这个机器人的最初设计目的是模仿一位 19 岁美国青少年女性的说话方式，同时它还具有从对话中进行学习的能力。结果上线还不到一天，Tay 就「堕落」成了一个满口纳粹言论的种族主义者。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9ib7qeAzkJbnskHfbTEctNsNkO3THOickIVyIWIl5yNtALmfnsTZBa1wN0hqNOaApVJMOayhWJibpZQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Tay 的一些不当言论&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而此前还有谷歌的图像识别程序将黑人识别成猩猩、给男性和女性推荐有差别的职业广告等等问题和后来发生的美国达拉斯警方用拆弹机器人炸死嫌犯、社交网络上的新闻推荐可能影响了美国大选等等事件。这些问题和事件在媒体的鼓吹下不仅和好莱坞一起进一步渲染了人工智能威胁论，也让一些研究者看到了人工智能可能会具有的不平等乃至威胁（不管是来自有偏见的算法本身还是来自所使用的数据）。但与此同时，这些报道也让研究者看到了公众对人工智能技术的不理解，进而让很多业内的人士和机构看到了向公众科普人工智能的重要性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这一系列事件的背景下，很多机构和研究者也做了很多工作，包括 9 月底的时候，谷歌携旗下公司 DeepMind，联合微软、亚马逊、Facebook 和 IBM 成立了名为 Partnership on AI 的组织，以共同探索人工智能技术的安全研发之路和促进公众对人工智能的正确理解。除了这些合作之外，有很多学界、产业界以及喜欢夸大其实的媒体界的人士都针对这一主题写过一些报道，其中机器之心报道过的有《&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716578&amp;amp;idx=3&amp;amp;sn=e5869321632cfeb2a84e8d896edab810&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716578&amp;amp;idx=3&amp;amp;sn=e5869321632cfeb2a84e8d896edab810&amp;amp;scene=21#wechat_redirect"&gt;微软 CEO 的「人工智能法则」：不得伤害人类，必须透明&lt;/a&gt;》、《&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718761&amp;amp;idx=2&amp;amp;sn=6f3c550a29161d6001851338b965233a&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718761&amp;amp;idx=2&amp;amp;sn=6f3c550a29161d6001851338b965233a&amp;amp;scene=21#wechat_redirect"&gt;ACM 月刊 | 艾伦人工智能研究所 CEO：设计遵循人类法律和价值观的人工智能系统&lt;/a&gt; 》、《&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719346&amp;amp;idx=2&amp;amp;sn=18de4b1e1aff0a30b6899538a1ea0774&amp;amp;chksm=871b000cb06c891aaf1763eec3922522090e34356ef521dcf909c71ca37d9ac6a12ef47d762b&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719346&amp;amp;idx=2&amp;amp;sn=18de4b1e1aff0a30b6899538a1ea0774&amp;amp;chksm=871b000cb06c891aaf1763eec3922522090e34356ef521dcf909c71ca37d9ac6a12ef47d762b&amp;amp;scene=21#wechat_redirect"&gt;Nature：对抗偏见，大数据算法需要更多责任&lt;/a&gt;》等等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能与人类的未来究竟将走向何方不是靠争论就能解决问题的，毕竟实践才是检验真理的唯一标准。对于人工智能相关法律问题和社会影响等议题也已经被提上了许多政府机关的议事日程。但不管我们商讨的结果如何，技术的发展终究是势不可挡的，而且就像美国经济顾问委员会主席 Jason Furman 说的那样：「未来我们需要人工智能」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;参考阅读：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716375&amp;amp;idx=1&amp;amp;sn=b4eaa0e0bcdfaf7b2d47ab95e91c1358&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716375&amp;amp;idx=1&amp;amp;sn=b4eaa0e0bcdfaf7b2d47ab95e91c1358&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;《经济学人》封面专题：从技术、就业、教育、政策、道德五大维度剖析人工智能革命&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;No.4 全球政府开始关注人工智能：一边鼓励一边寻求管制方法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;里程碑意义：★★★★☆&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;社会关注度：★★★★★&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果非要给人工智能时代的到来选一个标志，还有什么比世界上最强大的国家的政府对人工智能的关注更合适呢？2016 年 10 月，美国白宫发布了《为未来人工智能做好准备》和《美国国家人工智能研究与发展策略规划》两份重磅报告，详细阐述了美国未来的人工智能发展规划以及人工智能给政府工作带来的挑战与机遇。VentureBeat 对这两份报告进行了总结，得出了 7 个浅显易懂的要点：1. 人工智能应当被用于造福人类、2. 政府应该拥抱人工智能、3. 需要对自动汽车和无人机进行管制、4. 要让所有孩子都跟上技术的发展、5. 使用人工智能补充而非取代人类工作者、6. 消除数据中的偏见或不要使用有偏见的数据、7. 考虑安全和全球影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9ib7qeAzkJbnskHfbTEctNs7h0uMqyKSBwKEM5s6dHI3F3QbQjKzV890jhr8uUa47957ib9T1I0y2w/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;美国总统奥巴马在接受 Wired 专访时谈论了人工智能、自动驾驶汽车和人类的未来&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;到 12 月份，白宫还跟进发布了一份《&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721644&amp;amp;idx=1&amp;amp;sn=bfb26761cf5d118d4ed1dbafd04319f4&amp;amp;chksm=871b0912b06c8004ce420b78d657b9eee138c0e2990100ecfd759925804a0d248189b6014ba8&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721644&amp;amp;idx=1&amp;amp;sn=bfb26761cf5d118d4ed1dbafd04319f4&amp;amp;chksm=871b0912b06c8004ce420b78d657b9eee138c0e2990100ecfd759925804a0d248189b6014ba8&amp;amp;scene=21#wechat_redirect"&gt;人工智能、自动化与经济&lt;/a&gt;》的报告，谈到了智能技术和自动化技术对经济的影响和可能的应对策略。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除了美国政府之外，欧洲、中国、日本和新加坡等多个国家和地区的政府也开始将人工智能看作是未来实现国家竞争力的重要战略方向。中国国务院总理李克强就曾多次谈到过政府对人工智能和机器人产业的大力扶持。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而除了对人工智能产业的扶持，相关的管理规范和法律方面的工作也已经被许多政府和研究机构提上了议事日程：如何应对自动化所带来的就业危机、如何公平分配人工智能所创造的经济价值、如何对自动设备所带来的问题进行追责、以及如何防止人工智能技术被恶意利用而造成危害……这些都是重要的议题，而且我们都目前为止都还没有找到这些问题的完备答案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 7 月份美国经济顾问委员会提交给总统的一份报告中，该委员会估计大约 83% 时薪低于 20 美元的工作将会被自动化。针对这一问题，该委员会还提出了两个指导决策的基本原则：允许灵活性和实验，而不是强加限制；直接鼓励工作，而不是为其废止做规划。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但不管怎样，这一次以智能和自动化技术为基础的技术变革对所有人（包括所有政府）来说都是全新的。不过其带来的结果如何，政府都应该对目前所发生的一切保持敏锐和预见能力，这样才能以一种健康公正的社会状态迎接这个前所未有的技术变革。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;参考阅读：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719763&amp;amp;idx=1&amp;amp;sn=0aa9ed8a6e943705e74adc62828b5fe1&amp;amp;chksm=871b026db06c8b7b76724bd8ec49036de3543e39d6bd3a45a69efcb3dfa5d3422bb9caf9f918&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719763&amp;amp;idx=1&amp;amp;sn=0aa9ed8a6e943705e74adc62828b5fe1&amp;amp;chksm=871b026db06c8b7b76724bd8ec49036de3543e39d6bd3a45a69efcb3dfa5d3422bb9caf9f918&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;Nature 评论白宫发布的最新报告：人工智能研究中的一个盲点&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715708&amp;amp;idx=2&amp;amp;sn=21e67aa5f4ab68f38ae7d2e08e6624db&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715708&amp;amp;idx=2&amp;amp;sn=21e67aa5f4ab68f38ae7d2e08e6624db&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;白宫人工智能会议系列报道（一）：人工智能视野下的法律与政策&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715201&amp;amp;idx=3&amp;amp;sn=d329fc97a8158f3a861dd733043d024e&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715201&amp;amp;idx=3&amp;amp;sn=d329fc97a8158f3a861dd733043d024e&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;美国白宫为人工智能发声：通过公开对话讨论机遇与风险&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719745&amp;amp;idx=1&amp;amp;sn=4c8b294e5eb537bcd638612653e5c434&amp;amp;chksm=871b027fb06c8b699ce17d0bd2924eb9f233e6dbe9b582b81bba88ae26ee943ee28d638b1d80&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719745&amp;amp;idx=1&amp;amp;sn=4c8b294e5eb537bcd638612653e5c434&amp;amp;chksm=871b027fb06c8b699ce17d0bd2924eb9f233e6dbe9b582b81bba88ae26ee943ee28d638b1d80&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;奥巴马再谈人工智能：我们的经济模型需要适应新技术&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720875&amp;amp;idx=3&amp;amp;sn=0603f8906145835fd33c4127aad6b8fc&amp;amp;chksm=871b0e15b06c8703604c9e43d7bb4a64124cf391bc1e85479d0963350de4763eb7e40d66b680&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720875&amp;amp;idx=3&amp;amp;sn=0603f8906145835fd33c4127aad6b8fc&amp;amp;chksm=871b0e15b06c8703604c9e43d7bb4a64124cf391bc1e85479d0963350de4763eb7e40d66b680&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;人工智能黎明，美国参议院举行听证会邀请顶级学者探讨未来&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;No.5 继续超越人类，微软语音识别技术达到专业转录员水平&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;里程碑意义：★★★★☆&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;社会关注度：★★★★☆&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果人类是一个单一的好强的生命体，那么今天对它来说一定不好过，因为人工智能不仅在围棋上让它吃了亏，也更是在其它领域超越了人类。在微软的研究者十月份发表的一篇论文《Achieving Human Parity in Conversational Speech Recognition》中，人工智能与研究部门的一个研究者和工程师团队报告出他们的语音识别系统实现了和专业速录员相当甚至更低的词错率（WER），达到了 5.9%！而就在一个月前，微软才刚实现了历史性的 6.3%。这一成果和实现进展的速度甚至让一些人类转录员感受到了失业的风险。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而几乎就在同一时间，备受关注的锤子科技 CEO 罗永浩在该公司的新品发布会上演示了科大讯飞的语音输入法功能，结果没让任何人失望。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9ib7qeAzkJbnskHfbTEctNsXmQuqkWNmZKiaKbrPLpry2O0eT3ibXMsSfNxmpM8T275QpU0n1yqZo5A/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这一技术的日益成熟也为语音助理的普及奠定了发展基础。在 2016 年的 AWS re:invent 大会上，亚马逊就发布了多款可以帮助开发者更轻松地开发其语音助理 Alexa 相关应用的开发工具。据亚马逊 Alexa 部门副总裁 Rohit Prasad 介绍，Alexa 现在已经具备 5000 多种能力（skill）了；而装备了 Alexa 的 Amazon Echo 现在也已经能够帮助用户通过语音完成很多日常任务了，包括日程规划、音乐搜索等等。除了亚马逊之外，谷歌、微软、三星、苹果等公司都有专门的团队在帮助建设他们自家的语音助理平台。也许不久之后，你就再也不用担心没人听你说话了吧，因为机器会一直在身边听见和听懂你的话。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;参考阅读&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719135&amp;amp;idx=1&amp;amp;sn=012d179f83a6c3b38c6e58b4ac9ba82f&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719135&amp;amp;idx=1&amp;amp;sn=012d179f83a6c3b38c6e58b4ac9ba82f&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;重磅 | 语音识别新里程碑：微软新系统词错率低至 6.3%（附论文）&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719843&amp;amp;idx=1&amp;amp;sn=0c6387d422cf9765b9b10c178d160680&amp;amp;chksm=871b021db06c8b0b0b0447124c5c07818f53a17ba470305049af1d7d49806c87e07307a93811&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719843&amp;amp;idx=1&amp;amp;sn=0c6387d422cf9765b9b10c178d160680&amp;amp;chksm=871b021db06c8b0b0b0447124c5c07818f53a17ba470305049af1d7d49806c87e07307a93811&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;重磅 | 微软语音识别实现历史性突破：语音转录达到专业速录员水平（附论文）&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720189&amp;amp;idx=1&amp;amp;sn=10a3630e7f65d7b845c1fd032970d46e&amp;amp;chksm=871b03c3b06c8ad527a7dffd215be5b128a7aaf88ec09a131d68a249e9ff77c3edff6204d3d2&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720189&amp;amp;idx=1&amp;amp;sn=10a3630e7f65d7b845c1fd032970d46e&amp;amp;chksm=871b03c3b06c8ad527a7dffd215be5b128a7aaf88ec09a131d68a249e9ff77c3edff6204d3d2&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;专访 | 顶级语音专家、MSR 首席研究员俞栋：语音识别的四大前沿研究&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719843&amp;amp;idx=2&amp;amp;sn=4611f810734df8a72286567e90c65a92&amp;amp;chksm=871b021db06c8b0b283ac93f267d95365392be02b3cde5d2fe6df85b359aa96368f25318e2f5&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719843&amp;amp;idx=2&amp;amp;sn=4611f810734df8a72286567e90c65a92&amp;amp;chksm=871b021db06c8b0b283ac93f267d95365392be02b3cde5d2fe6df85b359aa96368f25318e2f5&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;独家 | 专访微软首席语音科学家黄学东： CNTK 是词错率仅 5.9% 背后的「秘密武器」&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720050&amp;amp;idx=1&amp;amp;sn=da2e46b031173adc25d16a68e2fcb54b&amp;amp;chksm=871b034cb06c8a5a1984b1158e83e94095ce12aff6fd0fe42126429e6e942aa786714c904589&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720050&amp;amp;idx=1&amp;amp;sn=da2e46b031173adc25d16a68e2fcb54b&amp;amp;chksm=871b034cb06c8a5a1984b1158e83e94095ce12aff6fd0fe42126429e6e942aa786714c904589&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;深度 | 在语音识别这件事上，汉语比英语早一年超越人类水平（附论文）&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;No.6 机器翻译整合神经网络，接二连三实现颠覆性突破&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;里程碑意义：★★★★☆&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;社会关注度：★★★★☆&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;据维基百科介绍，人类目前大概有 6000 多种语言。自人类在未建成的「巴别塔」下不欢而散以来，实现全人类之间的顺畅交流一直是我们的梦想。现在，基于神经网络的人工智能方法已经让我们看到了真正实现这一梦想的希望。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2016 年 9 月份，谷歌在 arXiv 上发布了一篇论文介绍了其神经机器翻译系统（GNMT），「该系统使用了当前最先进的训练技术，能够实现到目前为止机器翻译质量的最大提升。」谷歌的博客还宣布已经将其投入到了汉语-英语之间的机器翻译应用中。之后不到两个月，谷歌又再次发表论文宣布了进一步的突破：实现多种语言之间的神经机器翻译，并且还实现了突破性的 zero-shot 翻译！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9ib7qeAzkJbnskHfbTEctNskCwicAtao1wVm3SVMcQqicl9ujwXSj9MZg20I4PcbibSRbH13LcgCqjcg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;GNMT 的模型架构&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 11 月份的乌镇互联网大会上，搜狗 CEO 王小川在演讲过程中同步演示了自家的实时机器翻译应用。尽管这一事件后来引起了很多争议，但毫无疑问这反映了机器翻译技术正变得越来越成熟的趋势。也许几年之后，我们就能在自己的耳朵里面塞入一个人工智能「巴别鱼」，然后就能听懂每一个人所说的话了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除了语言对之间的文本序列到文本序列的翻译，另外值得一提的一项突破是唇语到语言（视频序列到文本序列）的「翻译」，而且其所实现的超越人类的进展基本上毫无争议的。11 月份，牛津大学、Google DeepMind 和加拿大高等研究院（CIFAR）联合发布了一篇重要论文，介绍了利用机器学习实现的句子层面的自动唇读技术 LipNet，该技术将自动唇读技术的前沿水平推进到了前所未有的高度——实现了 93.4% 的准确度，远远超过了经验丰富的人类唇读者。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;参考阅读&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719470&amp;amp;idx=1&amp;amp;sn=3368dea980517ea7d7942967da2740dc&amp;amp;chksm=871b0090b06c89863620be4e75c757940d03d8a43cd3c1d9a8309b6594c1bccd769cab193177&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719470&amp;amp;idx=1&amp;amp;sn=3368dea980517ea7d7942967da2740dc&amp;amp;chksm=871b0090b06c89863620be4e75c757940d03d8a43cd3c1d9a8309b6594c1bccd769cab193177&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;重磅 | 谷歌翻译整合神经网络：机器翻译实现颠覆性突破（附论文）&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719511&amp;amp;idx=1&amp;amp;sn=88bbb6bb3d28b3f0f62c5c5929968444&amp;amp;chksm=871b0169b06c887f302dc791c67f19ce4ba49c43744e11341b7bb225d9e22443ebf9e3b70339&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719511&amp;amp;idx=1&amp;amp;sn=88bbb6bb3d28b3f0f62c5c5929968444&amp;amp;chksm=871b0169b06c887f302dc791c67f19ce4ba49c43744e11341b7bb225d9e22443ebf9e3b70339&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;专访 | 谷歌神经网络翻译系统发布后，我们和 Google Brain 的工程师聊了聊&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720335&amp;amp;idx=1&amp;amp;sn=b030d7f82d10acde0378035c900264df&amp;amp;chksm=871b0c31b06c852746f35e16814808ceb13e91b091732afa48b2bb8c6d6f2f542df26e7f5575&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720335&amp;amp;idx=1&amp;amp;sn=b030d7f82d10acde0378035c900264df&amp;amp;chksm=871b0c31b06c852746f35e16814808ceb13e91b091732afa48b2bb8c6d6f2f542df26e7f5575&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;如何通过机器学习解读唇语？DeepMind 要通过 LipNet 帮助机器「看」懂别人说的话&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716730&amp;amp;idx=1&amp;amp;sn=52a29ba227a8a21e021fe71e4caad731&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716730&amp;amp;idx=1&amp;amp;sn=52a29ba227a8a21e021fe71e4caad731&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;深度｜让机器理解语言的魔法师——揭秘 Facebook 语言技术小组&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720536&amp;amp;idx=2&amp;amp;sn=1617ed96796bba31f4d6c6749b7579db&amp;amp;chksm=871b0d66b06c8470e86bf243fab1b7710dd8b222ecbfa99d5ac61dac07694542e6d4b6846db8&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720536&amp;amp;idx=2&amp;amp;sn=1617ed96796bba31f4d6c6749b7579db&amp;amp;chksm=871b0d66b06c8470e86bf243fab1b7710dd8b222ecbfa99d5ac61dac07694542e6d4b6846db8&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;重磅 | 谷歌神经机器翻译再突破：实现高质量多语言翻译和 zero-shot 翻译（附论文）&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;No.7 人工智能硬件大战打响，巨头 vs. 创业公司&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;里程碑意义：★★★☆☆&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;社会关注度：★★★★☆&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随着深度学习算法变得越来越复杂、所使用的数据集变得越来越大，对专用硬件的需求也正变得越来越大。2016 年，面向人工智能的平台成了计算硬件开发的一个主要的新方向。这一年，除了英特尔和英伟达这两家芯片巨头在人工智能方向连绵不断的高调动作，掌握核心科技的创业公司也在尽力改变着市场格局（尽管其中大部分有潜力的都被收购了），此外，就连谷歌这样的互联网也从中看到了发展的空间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;传统芯片厂商方面，英伟达借助 GPU 和深度学习算法的高度契合而顺势发展，股价飞涨，可以说是 2016 年人工智能计算硬件领域的最大赢家。体量更大的巨头英特尔自然也不会等着这个新市场被竞争对手占领，而收购似乎是个更快捷的追赶方法。2016 年，英特尔收购了多家人工智能创业公司，其中包括计算机视觉创业公司 Movidius 和深度学习芯片创业公司 Nervana 等。到 11 月份，有了 Nervana 和 2015 年收购的 FPGA 厂商 Altera 加持的英特尔公布了其人工智能路线图，介绍了该公司在人工智能芯片市场上的公司战略和产品生态系统。另外随便一提，在这一领域存在感差很多的 AMD 在 2016 年年底也终于发力，宣布推出了其首款基于 VEGA GPU 架构的机器学习芯片。另外，DSP 供应商 CEVA、FPGA 供应商 Xilinx 和处理器技术提供商 Imagination 等厂商也都已经在机器学习领域进行了布局。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9ib7qeAzkJbnskHfbTEctNsRVDPQBRaU5ibkxyDmbN0gPzB2D1PFajbibkCqVHibVO5RAt7sj8UNXEuQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;英伟达 CEO 黄仁勋在 GTC Europe 2016 上演讲&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;互联网巨头似乎也从计算硬件领域发现了新的机会。2016 年 5 月，谷歌发布了一款新的定制化设计的芯片张量处理单元（TPU/Tensor Processing Unit），这款芯片是专门为基于谷歌已经开源的 TensorFlow 机器学习框架而量身定制的。微软也通过 Project Catapult 表明了对 FPGA 的支持。另外，这一年 IBM 在神经形态计算上的进展也得到了很大的关注，甚至可能预示着一种人工智能发展的新方向。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;创业公司方面，除了被收购的 Nervana 等公司，还有 Wave Computing、Kneron 以及中国的寒武纪和深鉴科技等公司都在努力开发自家的深度学习专用芯片平台。而这些创业公司在 2016 年同样也取得了相当不俗的表现，比如源自中科院计算机研究所的寒武纪就在 2016 年推出的寒武纪 1A 处理器，据称这是世界首款商用深度学习专用处理器。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;参考阅读：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715580&amp;amp;idx=2&amp;amp;sn=564b17f5654b42e492c9e96b8eb8667e&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715580&amp;amp;idx=2&amp;amp;sn=564b17f5654b42e492c9e96b8eb8667e&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;谷歌发布 TPU 只是开始，是时候让英特尔害怕了&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719470&amp;amp;idx=1&amp;amp;sn=3368dea980517ea7d7942967da2740dc&amp;amp;chksm=871b0090b06c89863620be4e75c757940d03d8a43cd3c1d9a8309b6594c1bccd769cab193177&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719470&amp;amp;idx=1&amp;amp;sn=3368dea980517ea7d7942967da2740dc&amp;amp;chksm=871b0090b06c89863620be4e75c757940d03d8a43cd3c1d9a8309b6594c1bccd769cab193177&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;谷歌翻译整合神经网络：机器翻译实现颠覆性突破&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718133&amp;amp;idx=1&amp;amp;sn=ec37253865c8fbb20a3f2b4fdc2164dc&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718133&amp;amp;idx=1&amp;amp;sn=ec37253865c8fbb20a3f2b4fdc2164dc&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;深度学习芯片大战愈演愈烈，英特尔为何斥巨资收购创业公司 Nervana？&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718354&amp;amp;idx=2&amp;amp;sn=54bd32eb533f69b12ec40a270c2f0b5d&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718354&amp;amp;idx=2&amp;amp;sn=54bd32eb533f69b12ec40a270c2f0b5d&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;芯片之争：英伟达质疑英特尔深度学习芯片比较结果&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718543&amp;amp;idx=2&amp;amp;sn=6cad8ee35cfe4a32fef981b1a6c0ddc1&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718543&amp;amp;idx=2&amp;amp;sn=6cad8ee35cfe4a32fef981b1a6c0ddc1&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;芯片之争后续：英特尔对英伟达的质疑做出回应&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720561&amp;amp;idx=3&amp;amp;sn=76741dd8ae09d6493b3abebcbd387520&amp;amp;chksm=871b0d4fb06c8459752dff98c4ffd59a8fd6114f1c43b2e1e9c85294402f3adf7947f74e1bab&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720561&amp;amp;idx=3&amp;amp;sn=76741dd8ae09d6493b3abebcbd387520&amp;amp;chksm=871b0d4fb06c8459752dff98c4ffd59a8fd6114f1c43b2e1e9c85294402f3adf7947f74e1bab&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;深度学习硬件架构简述&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718975&amp;amp;idx=2&amp;amp;sn=8fd7b1b7ade4faa4867fd89003ff2e4f&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718975&amp;amp;idx=2&amp;amp;sn=8fd7b1b7ade4faa4867fd89003ff2e4f&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;布局移动端芯片，英特尔收购计算机视觉公司 Movidius&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717046&amp;amp;idx=2&amp;amp;sn=5f047515b4ba8e42c7b2765b462ab3a8&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717046&amp;amp;idx=2&amp;amp;sn=5f047515b4ba8e42c7b2765b462ab3a8&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;业界 | 探秘 Facebook 的人工智能大脑：Big Sur 硬件系统&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721406&amp;amp;idx=2&amp;amp;sn=3a52bfbd1b7720e48e086b0d7df5e09f&amp;amp;chksm=871b0800b06c8116136f3d0cf14ba5ad16ea47b1b5b6f07697c2a0c7bc395e1632428e78e7da&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721406&amp;amp;idx=2&amp;amp;sn=3a52bfbd1b7720e48e086b0d7df5e09f&amp;amp;chksm=871b0800b06c8116136f3d0cf14ba5ad16ea47b1b5b6f07697c2a0c7bc395e1632428e78e7da&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;AMD 推出首个基于 VEGA GPU 架构的机器学习芯片，打响与英伟达的硬件战争&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719294&amp;amp;idx=3&amp;amp;sn=d23a6d7c03732f7218f70447336801bd&amp;amp;chksm=871b0040b06c89564722f7292215997f474374d43d26761700f00b240e83a9c5dc2dd7595a26&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719294&amp;amp;idx=3&amp;amp;sn=d23a6d7c03732f7218f70447336801bd&amp;amp;chksm=871b0040b06c89564722f7292215997f474374d43d26761700f00b240e83a9c5dc2dd7595a26&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;专栏 | FPGA vs. ASIC，谁将引领移动端人工智能潮流？&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717770&amp;amp;idx=1&amp;amp;sn=9f33fc6a5a3cabd55f26bd31e871769d&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717770&amp;amp;idx=1&amp;amp;sn=9f33fc6a5a3cabd55f26bd31e871769d&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;重磅 | IBM 创造出世界上首个人工相变神经元，可实现高速无监督学习&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719442&amp;amp;idx=2&amp;amp;sn=1233c803d2dd3766b2ca43830438dc78&amp;amp;chksm=871b00acb06c89bacc82b4555c3efb657ec40baf3e57539a67f24b39641fcdf5cde1d7cfb77e&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719442&amp;amp;idx=2&amp;amp;sn=1233c803d2dd3766b2ca43830438dc78&amp;amp;chksm=871b00acb06c89bacc82b4555c3efb657ec40baf3e57539a67f24b39641fcdf5cde1d7cfb77e&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;深度 |《连线》长文揭秘微软 Project Catapult：人工智能时代押注 FPGA&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;No.8 斯坦福大学发布人工智能研究百年报告&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;里程碑意义：★★★★☆&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;社会关注度：★★★☆☆&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2014 年秋季，斯坦福大学启动了一个人工智能百年研究项目。两年之后——2016 年 9 月初——斯坦福大学所组织的包含了谷歌和微软等科技巨头、哈佛大学和 MIT 等著名大学以及艾伦人工智能研究所等专门的人工智能研究机构的众多专家学者的委员会终于发布了他们百年项目的第一份报告《2030 年的人工智能与生活（AI and Life in 2030）》，该报告囊括了人工智能最近的发展以及对就业、环境、运输、公共安全、医疗、社区参与和政府的潜在影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9ib7qeAzkJbnskHfbTEctNsGosO0Sd9TF1BGmhnw9K1g0TvQibRaGkCwQlXOd9rRQ1ibEibV7dJ7D5jw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;报告发布后得到了极大的关注，在某种程度上也为近未来的人工智能的发展起到了一定的指导性作用。该报告写道：「「百年研究」定期进行专家回顾的首要目标是：提供一个随着人工智能领域发展的关于人工智能及其影响的收集性的和连通的集合。这些研究希望能在人工智能领域的研究、发展以及系统设计方面、以及在帮助确保那些系统能广泛地有益于个人和社会的项目与政策上提供专业推断上的方向指南及综合评估。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除了斯坦福大学的这份报告，也还有其它许多调研机构和科技媒体也发布了自己的调查或预测报告。在这里当然要安利一下机器之心发布的月度《AI00：全球最值得关注的 100 家人工智能公司》系列报告，该报告按语音和自然语言、计算机视觉、芯片和硬件等十个主题梳理盘点了人工智能领域最值得关注的 100 家公司。该报告将继续保持每月更新的频率，最新版本的报告可点击这里查看。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;参考阅读：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718808&amp;amp;idx=1&amp;amp;sn=998d5748605dd82b624f69b8983cd287&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718808&amp;amp;idx=1&amp;amp;sn=998d5748605dd82b624f69b8983cd287&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;斯坦福「人工智能百年研究」首份报告：2030 年的人工智能与生活&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721378&amp;amp;idx=1&amp;amp;sn=16f8a955e1459926dd1e66f82e26028c&amp;amp;chksm=871b081cb06c810aedab8a7c1902daf18f3d00f20c1b04ec0645303ffe2023b5e4dd87c41ee8&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721378&amp;amp;idx=1&amp;amp;sn=16f8a955e1459926dd1e66f82e26028c&amp;amp;chksm=871b081cb06c810aedab8a7c1902daf18f3d00f20c1b04ec0645303ffe2023b5e4dd87c41ee8&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;高盛百页人工智能生态报告：美国仍是主导力量，中国正高速成长&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720257&amp;amp;idx=4&amp;amp;sn=c8129b25c80557edf0729177025bef8b&amp;amp;chksm=871b0c7fb06c85692342324e848b4dfc403a52540cf3646e7dc942702ce05b5ff020a8dae48a&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720257&amp;amp;idx=4&amp;amp;sn=c8129b25c80557edf0729177025bef8b&amp;amp;chksm=871b0c7fb06c85692342324e848b4dfc403a52540cf3646e7dc942702ce05b5ff020a8dae48a&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;业界 | 彭博发布 2016 机器智能图谱：竞争进入白热化&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721325&amp;amp;idx=2&amp;amp;sn=4a40f5ae33fa087a95f1b36dbfb4477d&amp;amp;chksm=871b0853b06c8145877471db75af61e6e22fe6154814266e54c3e5ff4e757c7672ca141ecda1&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721325&amp;amp;idx=2&amp;amp;sn=4a40f5ae33fa087a95f1b36dbfb4477d&amp;amp;chksm=871b0853b06c8145877471db75af61e6e22fe6154814266e54c3e5ff4e757c7672ca141ecda1&amp;amp;scene=21#wechat_redirect"&gt;深度 | 变革的开始，深度学习将如何改变医疗成像领域？&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720132&amp;amp;idx=1&amp;amp;sn=d630d47c4ab60d35752aba74a9d53361&amp;amp;chksm=871b03fab06c8aec767776a6a4a407c3897dcad26392b24a22536261565e9dc6b5ce52df0816&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720132&amp;amp;idx=1&amp;amp;sn=d630d47c4ab60d35752aba74a9d53361&amp;amp;chksm=871b03fab06c8aec767776a6a4a407c3897dcad26392b24a22536261565e9dc6b5ce52df0816&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;40 年认知架构研究概览：实现通用人工智能的道路上我们已走了多远？&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718543&amp;amp;idx=1&amp;amp;sn=597ee49e4dccabe2892366b8afb061f2&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718543&amp;amp;idx=1&amp;amp;sn=597ee49e4dccabe2892366b8afb061f2&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;卡内基国际和平研究院报告：印度如何开展人工智能革命？&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;No.9 人工智能/机器人开始渗透进人们的日常生活&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;里程碑意义：★★★☆☆&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;社会关注度：★★★☆☆&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管现在的人工智能和机器人离科幻作品里面的那些善解人意的、甚至有自我知觉的形象还有很大的差距，但它们已经在成群结队（有时候却悄无声息）地进入我们的日常生活了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;且不必谈那些背后使用了智能和学习算法的模式筛查、搜索引擎、推荐系统和翻译应用等等。在我们能够直观感受智能应用上，我们也能感受到非常直接的进步：过去的一年里，亚马逊 Alexa 变得更加聪明了——具备了近 5000 种技能，而谷歌也在 2016 年 3 月份宣布了对标了亚马逊 Echo 的音箱式语音助理产品 Google Home，此外，微软的小娜和小冰姐妹也在我们的生活场景中变得越来越常见。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;软件之下，在我们可以直接触摸的承载和表现智能的硬件（机器人）上，我们也能看到它们大步迈进的身影：自动驾驶汽车开始实验性地载客、快递无人机正在探索货运的新方式、人形机器人在日本的企业里面充当接待员、护理机器人进入了欧洲一些老人和自闭症儿童的生活、更不要说已经在很多家庭里面兢兢业业工作的扫地机器人了……甚至还有一些机器人加入了执法者的队伍——7 月份，美国达拉斯警方在与杀警狙击手对峙几小时后，出动机器人载着炸弹炸死了嫌犯，这被认为是美国警方首次以这样的自动装置来执法。（当然，军用无人机早已经在战场得到了应用。）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然，除了普通人的日常生活之外，科学家的日常生活里面更是出现了更多人工智能/机器人。2016 年 7 月，NASA 向好奇号火星车推送了一个更新，让其可以在遥远的火星上自己选择需要研究的石头。人工智能甚至还成了科学家寻找外行星甚至外星生命的助手。至于分析粒子数据、大气系统、基因组、经济活动、社会状况等数据的模式，那几乎已经可以算是人工智能的拿手好戏了。另外值得一提的是，12 月初 Science 旗下的机器人主题期刊 Science Robotics 的创刊号正式发布，为机器人领域的繁荣提供了直接的见证。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;艺术方面人工智能也没有落后，能够编写古典音乐的智能系统已经出现，Prisma 等艺术风格渲染应用更是风靡一时，人工智能还作为鉴赏家找出了莎士比亚作品的合作者并且甚至还学会了剪辑色情视频，当然也不要忘了人工智能甚至还当了编剧写出了一些剧本！下面这段视频就是基于人工智能 Jetson 生成的剧本拍摄的科幻短片：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;iframe class="video_iframe" data-vidtype="1" allowfullscreen="" frameborder="0" height="417" width="556" data-src="https://v.qq.com/iframe/preview.html?vid=d0361upxrgl&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0"&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;参考阅读：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715225&amp;amp;idx=1&amp;amp;sn=1e12c67237b31ced510f85d216eb0724&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715225&amp;amp;idx=1&amp;amp;sn=1e12c67237b31ced510f85d216eb0724&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;深度｜老龄化下的看护机器人革命：为什么我会愿意接受它的照料并与其终老&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720561&amp;amp;idx=2&amp;amp;sn=561479181c184d4bed67ea539424867c&amp;amp;chksm=871b0d4fb06c84593781e1e57ccf6336b2215c62e0ebffb106efa5ee4227dd7e92a1b3ec60b1&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720561&amp;amp;idx=2&amp;amp;sn=561479181c184d4bed67ea539424867c&amp;amp;chksm=871b0d4fb06c84593781e1e57ccf6336b2215c62e0ebffb106efa5ee4227dd7e92a1b3ec60b1&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;开源 | 让老司机告别快进，Miles Deep 使用 CNN 截取色情视频的关键部分&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717374&amp;amp;idx=4&amp;amp;sn=33a17644f9cdfd0035bddefa7c240106&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717374&amp;amp;idx=4&amp;amp;sn=33a17644f9cdfd0035bddefa7c240106&amp;amp;scene=21#wechat_redirect"&gt;业界 | 人工智能让好奇号更聪明：可以自己选择「激光枪」的攻击目标&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721325&amp;amp;idx=3&amp;amp;sn=dbcb2f24f32a835b16adb0bda72d37a3&amp;amp;chksm=871b0853b06c8145f9a57d9e93f10317246f57ede4303066baf739e3957ad8bf7413a23f64df&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721325&amp;amp;idx=3&amp;amp;sn=dbcb2f24f32a835b16adb0bda72d37a3&amp;amp;chksm=871b0853b06c8145f9a57d9e93f10317246f57ede4303066baf739e3957ad8bf7413a23f64df&amp;amp;scene=21#wechat_redirect"&gt;深度学习遇上物理学：上能分析星系团，下能解码基本粒子&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;No.10 打破产业与学界之间的壁垒，大学与企业共同推进技术进步&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;里程碑意义：★★☆☆☆&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;社会关注度：★★★☆☆&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;多年来积累的深度学习技术研究成果的应用价值正在开始显现，产业界也已经将人工智能作为了重点发展和关注的领域。而为了在未来占据这个万亿级市场的优势，人才和技术积累就成了当前需要投资的关键。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2016 年，我们看到很多学术界的研究者和科学家开始进入到了产业领域，其中包括 8 月份中国科学院计算机视觉资深研究专家山世光创立人脸识别技术公司「中科视拓」、 10 月份卡耐基梅隆大学机器学习教授 Ruslan Salakhutdinov 加入苹果、10 月份加拿大蒙特利尔大学教授 Yoshua Bengio 参与创立深度学习孵化器 Element AI、11 月份斯坦福大学教授李飞飞加入谷歌和卡耐基梅隆大学教授邢波创立机器学习平台公司 Petuum。而其中一些研究者也表示在进入产业界之后仍然会保留在大学内的研究或教学职务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9ib7qeAzkJbnskHfbTEctNsJice14VTyxNVASsNuDfdjfcUuD5MiaVFR067BgCRcjsiaYYIMjjwV346g/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;学术界的人才在向产业界流动的同时，产业界也在凭借自身强大的优势资源产出高质量的学术成果。谷歌、微软、Facebook、腾讯、百度等科技巨头都已经有了自己专门的人工智能研究机构，这些机构不仅在帮助这些公司提升自己的产品和应用，也同时在将自己的研究成果公开发表出来。这样一片欣欣向荣共同进步的发展景象让一贯遵循保密策略的苹果公司也坐不住了，在今年 12 月份，前面提到的该公司的人工智能研究主管 Russ Salakhutdinov 在 NIPS 2016 上宣布「苹果的人工智能研究团队将公开发表他们的研究成果并更多地参与到广阔的学术圈中去。」之后不久，苹果发布了其第一篇人工智能论文《Learning from Simulated and Unsupervised Images through Adversarial Training》。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;闭门造车的时代已经结束了，要想在人工智能时代继续保持领先，方法大概只有一个：参与进来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;参考阅读：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720553&amp;amp;idx=1&amp;amp;sn=c88e48aab2d789d744ac1629ffec9a8a&amp;amp;chksm=871b0d57b06c844121d6fdf6fda546996e87c1cc395bef55fde20cb910b2fe1bbcdf8d1ce6c9&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720553&amp;amp;idx=1&amp;amp;sn=c88e48aab2d789d744ac1629ffec9a8a&amp;amp;chksm=871b0d57b06c844121d6fdf6fda546996e87c1cc395bef55fde20cb910b2fe1bbcdf8d1ce6c9&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;谷歌新人李飞飞：击碎玻璃天花板的华裔女科学家&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720553&amp;amp;idx=3&amp;amp;sn=0565089045c8a6621b7b3aa2c079acc8&amp;amp;chksm=871b0d57b06c8441c4f15f3b8d0b0f9ddd77cf1b30bcf11febb20ac8de24f9463fbee0827701&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720553&amp;amp;idx=3&amp;amp;sn=0565089045c8a6621b7b3aa2c079acc8&amp;amp;chksm=871b0d57b06c8441c4f15f3b8d0b0f9ddd77cf1b30bcf11febb20ac8de24f9463fbee0827701&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;CMU 教授邢波创立公司 Petuum，获 1500 万美元 A 轮融资&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719828&amp;amp;idx=3&amp;amp;sn=5f72f8b9bbd0078d483ad233e578081a&amp;amp;chksm=871b022ab06c8b3ce2ef881c941e1ea532e3f465bbc1109c74e0aa0a72b283a8408dca7b353f&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719828&amp;amp;idx=3&amp;amp;sn=5f72f8b9bbd0078d483ad233e578081a&amp;amp;chksm=871b022ab06c8b3ce2ef881c941e1ea532e3f465bbc1109c74e0aa0a72b283a8408dca7b353f&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;知名机器学习专家 Russ Salakhutdinov 加入苹果，负责人工智能研究&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;总结&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除了上面的盘点中所提到的十大焦点，2016 年的人工智能领域还有更多值得我们关注的焦点事件和重要研究，其中至少包括：更为逼真的语音合成（WaveNet）、稳步推进的图像识别……此外在视频预测、阅读理解和生成对抗网络等领域也出现了一些非常之关注的研究进展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外，在一些相关的其它技术上，我们见证了很多重要的进步，其中至少包括量子计算、光计算、生物计算、脑机接口、机器人技术和新型加密技术等领域也都出现了一些重要的研究或应用进展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在，人工智能在我们的日常生活所发挥的作用正变得越来越大，一般人的生活在很大程度上已经离不开各种应用背后的人工智能技术了；所以，我们可以总结说：2016 年我们已经进入了人工智能时代。新的一年，人工智能又将会引来怎样的机遇和催生出怎样的应用和故事，就让我们拭目以待吧。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心原创，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 01 Jan 2017 11:12:39 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 面部识别系统侵犯隐私，Facebook再次遭遇法律诉讼</title>
      <link>http://www.iwgc.cn/link/4157511</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自IEEE Spectrum&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李泽南&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;有关生物识别的法律纠纷正在困扰着人们。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Nimesh Patel 是伊利诺伊州的居民，也是权利受到损害的 Facebook 用户，但他并不无知：他非常了解 Facebook 这家社交网络公司正在收集他的信息。当 Facebook 在收集数据的道路上走得更远，开始获取用户面部的细节，如眉毛之间有几毫米距离，嘴角深入脸颊的长度，以及其他数十种数据时，事情正在变得越来越严重。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Patel 是最近一个针对 Facebook 的集体诉讼的指定原告。起诉书中称，Facebook 目前正在使用的面部识别技术违反了伊利诺伊州在 2008 年通过的一项法律，「生物信息隐私法案（BIPA）」。该法案规定了公司在存储和使用用户生物识别信息中的限制条件，受限的信息包括指纹、声纹、虹膜或视网膜扫描，以及手掌和面部轮廓几何细节。该法案在去年&amp;nbsp;10 月份被法院接受审理，同时，伊利诺伊州也在审理针对谷歌和 Snapchat 的类似案件。在未来的一年里，该州法庭将主持一系列有关谁有权拥有我们的脸的辩论。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW99YY0dPcrTwsMPbJbYCSxQxhXyX0LCf17YOAR4ZMScT6OrRLpowqx0lsKPtEbCGibnmNuOqSCjW8Q/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;美国 FBI 的 FACES 面部识别数据库包含从驾驶执照和护照照片中获得的公民的图像，大部分是守法公民的信息&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;公民自由团体对于个人隐私权的诉求一直高涨，他们纷纷表示此类辩论早就应该进行。然而，伊利诺伊州的法律即使在美国也只是一个特例，因为近年来面部识别系统已经被纳入很多执法机构的监视系统和数据库中了。「此类技术在近年来迅速得到完善，」Electronic Frontier Foundation 的律师 Jennifer Lynch 说道。「与此相比，法律跟随的步伐显得过于缓慢，我们很快就可以通过商店里安装的监控摄像头来识别前来购物的每个人的身份。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;控告 Facebook 的缘由来自于这家社交网络公司在 2010 年推出的一项照片标记功能：当用户上传照片时，Facebook 的系统会识别照片中每个人的面孔，并尝试将这些面孔与其他照片中的人脸相匹配，再尝试为每个面孔与人名建立关联。根据本案诉讼书，这一「标记建议」系统证明了 Facebook 正在收集和存储所有美国用户的「面部特征」（Facebook 已于 2012 年在欧洲关闭了此项功能，原因是可能侵犯隐私）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;值得注意的是，伊利诺伊州的法律早于 Facebook 推出的图像标注功能，而该法案文字上并未提及社交网络。相反，BIPA 提及了未来在金融领域生物识别 ID 的潜在应用，并指出这些生物识别标记与密码和 PIN 码有很大不同——如果客户的生物识别特征被窃取，他/她并不能简单地通过换一个新的指纹或脸来脱离危险。但最近的一系列诉讼并没有针对银行，而是指向了科技公司。在 2016 年&amp;nbsp;4 月份，曾有一起案件指控 Shutterfly 违反了此项法律，赔偿金额未被公开。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 BIPA 法律的限制下，私人公司必须制定规则，限制用户生物识别信息在服务器上存储的时间，限定在某个时间点必须删除数据。「在某种程度上看，这是一个温和的法律，」EPIC 律师 Claire Gartland 表示，她专攻消费者隐私案件。「公司只需要在同意条款中加上一个免责声明。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「通过使用伊利诺伊州用户的面部识别数据，而未在同意条款中提及，」诉讼书中写到。「Facebook 触犯了本州法律。」Facebook 的发言人目前拒绝回答有关此次诉讼的问题，但指出用户可以在自己的账户设置中很轻松地关闭被提及的面部识别功能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有关隐私，用户和公司在法律上的交锋已经展开一段时间了。在 2015 年末，Facebook 针对 BIPA 法案提出了撤诉动议，该公司认为法案中对生物识别的解释，包括面部扫描和面部几何，但明显不包含照片中的信息，以及图片上面部特征的物理描述。Facebook 认为该法案限制的内容只包括面部扫描建立的生物识别记录——从生物实体上获得的。但法庭认为 Facebook 提出的观点「不具有说服力」，并指出 BIPA 法案旨在解决所有新生的生物识别技术引发的问题，同时让诉讼继续进行。如果 Facebook 在本案中败诉，它将为数百万伊利诺伊州的用户支付赔偿金，并被迫改变其在该州，以及全美国的运营策略。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;我们很快就可以通过商店里安装的监控摄像头来识别前来购物的每个人的身份。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在法庭上，Facebook 在面部识别上的技术优势也许会发挥作用。「法庭也许会询问公司有关面部识别的技术细节，询问 Facebook 是否采用了传统的面部匹配计算方法，」密歇根州立大学计算机科学教授 Anil Jain 说道。「此类系统通过测量面部的几千个数据点，构建和存储面部模板，系统会在用户面部的眉毛、鼻子、嘴唇轮廓、嘴的两端等等轮廓取样。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但 Jain 同时指出，Facebook 研究人员也掌握一种更加先进的面部识别方式，通过机器学习来识别人脸。在 2014 年，该公司发布了 DeepFace 系统（论文：DeepFace: Closing the Gap to Human-Level Performance in Face Verification）。在论文中，研究人员曾描述他们在 440 万已标记的面部图片数据集的基础之上训练系统，而这些照片都是在 Facebook 中收集到的。多层神经网络经过训练学会了识别面部特征的方式，在获得新图片后可以进行准确的识别和分类，但人们无法观察到训练后模型的内部机制。「这就像是一个黑箱。」Jain 说道。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Facebook 不会透露自己现在是否已经在标记服务中使用了 DeepFace，或者它的改进版本。如果这家公司已经使用了基于机器学习的技术，它可能不会违反 BIPA 法案。「问题的关键在于数据库中存储的是什么，」Jain 解释道。「DeepFace 在分析照片时，系统会通过训练后自己的逻辑进行识别，其中的机制可能与法案中『生物识别信息』定义的内容无关。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这样看来或许有点讽刺：如果 Facebook 的系统实际上不存储人脸，它可能就会在法庭上找回脸面。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 01 Jan 2017 11:12:39 +0800</pubDate>
    </item>
  </channel>
</rss>
