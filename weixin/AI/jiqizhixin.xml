<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>独家 | 机器之心对话NIPS 2016最佳论文作者：如何打造新型强化学习观？（附演讲和论文）</title>
      <link>http://www.iwgc.cn/link/3846238</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心报道&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;编辑：&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;杜夏德、吴攀、微胖&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;em style="color: rgb(136, 136, 136);"&gt;&lt;span&gt;当地时间 12 月 5 日，机器学习和计算神经科学的国际顶级会议第 30 届神经信息处理系统大会（NIPS 2016）在西班牙巴塞罗那开幕。本届最佳论文奖（Best Paper Award）获奖论文是 Value Iteration Networks。&lt;/span&gt;&lt;/em&gt;&lt;br/&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2016 NIPS 最佳论文《Value Iteration Networks》的作者，是加州大学伯克利分校 Aviv Tamar、吴翼（Yi Wu）等人。这篇论文介绍了一个能学习设计策略，而不是被动的完全遵循策略的神经网络。同时，这种新的强化学习观并不是基于模型的（model-free）。机器之心第一时间联系到最佳论文的作者之一吴翼（Yi Wu），为我们详细讲述 VIN 的特点、应用方式和他的研究心得。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;与最佳论文作者吴翼的对话&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibPS3Rm2nxF9Ee5ylPNia1mPuMau5U2lvlXbrTkXqacyXkyzLeQEiaAT5IFIg9B01rNpNODQia09wZCw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心：谈谈你的研究方向和最近工作&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我自己的研究兴趣比较广泛，主要考虑的问题是如何能够在 AI 模型中更好的表达人的先验知识，并利用这些人的已有知识，让模型利用更少的数据，做出更好的推断。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我做过的项目包括概率编程语言（probabilistic programming language）以及概率推理（probabilistic inference），层次强化学习（hierachical reinforcement learning）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除此之外，这个假期我在北京的今日头条实验室做了 3 个月实习，期间利用层次化模型处理了一些与自然语言处理（natural language processing）相关的问题。回到 Berkeley 之后我也和一些相关教授合作，继续利用层次化模型做一些和 NLP 有关的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;机器之心&lt;/strong&gt;&lt;/em&gt;：简单介绍一下《Value IterationNetwork》的主题及 VIN 网络应用的场景&amp;nbsp;&lt;/span&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;VIN 的目的主要是解决深度强化学习泛化能力较弱的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;传统的深度强化学习（比如 deep Q-learning）目标一般是采用神经网络学习一个从状态（state）到决策（action）的直接映射。神经网络往往会记忆一些训练集中出现的场景。所以，即使模型在训练时表现很好，一旦我们换了一个与之前训练时完全不同的场景，传统深度强化学习方法就会表现的比较差。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 VIN 中，我们提出，不光需要利用神经网络学习一个从状态到决策的直接映射，还要让网络学会如何在当前环境下做长远的规划（learn to plan），并利用长远的规划辅助神经网络做出更好的决策。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通俗点来说叫：授人以鱼不如授人以渔。不妨说大家生活在北京，那么要怎么才能让一个人学会认路呢？传统的方法就是通过日复一日的训练，让一个人每天都从天安门走到西直门，久而久之，你就知道了长安街周边区域大致应该怎么走，就不会迷路了。但是如果这个人被突然扔到了上海，并让他从静安寺走到外滩，这个人基本就蒙了。VIN 提出的 learning to plan 的意义就在于，让这个人在北京学认路的时候，同时学会看地图。虽然这个人到了上海之后不认识路，但是如果他会看地图，他可以在地图上规划出从静安寺到外滩的道路，然后只要他能知道自己现在处在地图上的什么位置以及周边道路的方向，那么利用地图提供的额外的规划信息，即使这个人是第一次到上海，他也能成功的从静安寺走到外滩。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在文章中，我们提出了一种特殊的网络结构（value iteration module），这种结构和经典的规划算法 value iteration 有着相同的数学表达形式。利用这种数学性质，VIN 将传统的规划算法（planning algorithm）嵌入了神经网络，使得网络具有长期规划的能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;VIN 中所使用的特殊结构，value iteration module，在很多问题上都可以直接加入现有的强化学习框架，并用来改进很多现有模型的泛化能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;机器之心&lt;/strong&gt;&lt;/em&gt;：跟从 Russell 教授学习带来了哪些启发？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;Berkeley 有着全世界最好的 AI 研究氛围和学者，我很幸运能够在 Berkeley 学习和研究。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我的导师 Stuart Russell 教授对我的影响是最大的。他改变了很多我对的科研观点和习惯，让我不要急功近利。在我比较艰难的时间段里他也不停的鼓励我，也对我在很多方面给予了很大的支持，信任和帮助。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此外我第一篇关于概率编程语言的论文也非常幸运得到了 Rastislav Bodik 教授的指导和帮助，不过很不凑巧，在我博士第一年结束之后他就被挖到了华盛顿大学（University of Washington）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在强化学习方面，我得到了 Pieter Abbeel 教授，Sergey Levine 教授，Aviv Tarmar 博士，还有他们组里的很多博士生的帮助。他们都是领域里最厉害的学者，让我学到了非常多的东西。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在自然语言处理方面，我在今日头条实验室实习的时候得到了李磊博士的很多指导，回到 Berkeley 后，我和 David Bamman 教授也有合作，他也是圈内顶尖的学者，也总能给我提出很有价值的建议和指导。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;机器之心&lt;/strong&gt;&lt;/em&gt;：获得 BestPaper 是意料之中的事情吗？有什么感想？&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;大家知道消息的时候还是挺意外的，也很高兴。毕竟 best paper 是个很高的荣誉，这一次 NIPS 也有很多非常非常优秀的工作，能够被选中，大家都非常开心。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;最佳论文：Value Iteration Networks&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibPS3Rm2nxF9Ee5ylPNia1mPibP9eQCben9icvqrCfrSSLx4BniaVtcibdyy78wpEwlHt7yG1npmMiadQnQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;摘要&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在本研究中，我们介绍了价值迭代网络（value iteration network, VIN）：一个完全可微分的神经网络，其中嵌入了「规划模块」。VIN 可以经过学习获得规划（planning）的能力，适用于预测涉及基于规划的推理结果，例如用于规划强化学习的策略。这种新方法的关键在于价值迭代算法的新型可微近似，它可以被表征为一个卷积神经网络，并以端到端的方式训练使用标准反向传播。我们在离散和连续的路径规划域和一个基于自然语言的搜索任务上评估了 VIN 产生的策略。实验证明，通过学习明确的规划计算，VIN 策略可以更好地泛化到未见过的新域。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;引言&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;过去十年中，深度卷积神经网络（CNN）已经在物体识别、动作识别和语义分割等任务上革新了监督学习的方式。最近，CNN 被用到了需要视觉观测的强化学习（RL）任务中，如 Atari 游戏、机器人操作、和模拟学习（IL）。在这些任务中，一个神经网络（NN）被训练去表征一个策略——从系统状态的一个观测到一个行为的映射，其目的是表征一个拥有良好的长期行为的控制策略，通常被量化为成本随时间变化的一个序列的最小化。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;强化学习（RL）中决策制定的连续性（quential nature）与一步决策（one-step decisionsin）监督学习有本质的不同，而且通常需要某种形式的规划。然而，大部分最近的深度强化学习研究中都用到了与监督学习任务中使用的标准网络十分相似的神经网络架构，通常由用于提取特征的 CNN 构成，CNN 的所有层都连在一起，能将特征映射到行动（action）的概率分布上。这样的网络具有内在的反应性，同时特别的一点是它缺乏明确的规划计算。序列问题中反应策略的成功要归功于该学习算法，它训练了一个反应策略去选择在其训练领域有良好长期结果的行动。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了理解为什么一个策略（policy）中的规划（planning）是一个重要的要素，可以参考一下图 1（左）中网格世界的导航任务，其中的 agent 能观测其域的地图，并且被要求在某些障碍之间导航到目标位置。有人希望训练一个策略后能解决带有不同的障碍配置的该问题的其他几个实例，该策略能泛化到解决一个不同的、看不见的域，如图 1（右）显示。然而，根据我们的实验显示，虽然标准的基于 CNN 的网络能被轻易训练去解决这类地图的一个集合，它们却无法很好的泛化到这个集合之外的新任务中，因为它们不理解该行为的基于目标的形式。这个观察结果显示被反应策略（reactive policy）学习的计算不同于规划（planning），它需要解决的是一个新任务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibPS3Rm2nxF9Ee5ylPNia1mPEreHk1wOz7iayPHnId7A6Uw0fRbfibGWJumIMvyvT8gboCHBMmImZ25Q/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 1：一个网格世界域的两个实例。任务在障碍之间移动到全局。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这个研究中，我们提出了一个基于神经网络的策略（policy），它能有效地去学习规划（plan），我们的模型，termeda 值迭代网络（VIN），有一个可微分的「规划程序」，被植入了该神经网络结构。我们方法的关键是观测到经典值迭代（VI）规划算法可能由一个 特定类型的 CNN 表征。通过将这样一个 VI 网络模块植入到一个标准的前馈分类网络中，我们就获得了一个能学习一个规划计算的神经网络模型。这个 VI 模块是可微分的，而且整个网络能被训练去使用一个标准的反向传播。这就让我们的策略简单到能训练使用标准的强化学习和模拟学习算法，并且直接与神经网络整合，用于感知和控制。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们的方法不同于基于模型的强化学习，后者需要系统识别以将观测映射到动力学模型中，然后产生解决策略。在强化学习的许多应用中，包括机器人操纵和移动场景中，进行准确的系统识别是极其困难的，同时建模错误会严重降低策略的表现。在这样的领域中，人们通常会选择无模型方法。由于 VIN 仅是神经网络策略，它可以进行无模型训练，不需要进行明确的系统识别。此外，通过训练网络端到端可以减轻 VIN 中的建模误差的影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们证明了 VIN 可以有效应用于标准的强化学习和模拟学习算法中的各种问题，其中包括需要视觉感知，连续控制，以及在 WebNav 挑战中的基于自然语言的决策问题。在训练之后，策略学习将观察映射到与任务相关的规划计算中，随后基于结果生成动作预测的计划。正如我们所展示的结果，这种方式可以更好地为新的，未经训练的任务形式的实例归纳出更好的策略。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;结论和展望&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;强大的和可扩展的强化学习方法为深度学习开启了一系列新的问题。然而，最近很少有新的研究探索如何建立在不确定环境下规划策略的架构，目前的强化学习理论和基准很少探究经过训练的策略的通用性质。本研究通过更好地概括策略表示的方法，朝着这个方向迈出了一步。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们提出的 VIN 方法学习与解决任务相关的大致策略并计算规划，同时，我们已经在实验中证明，这样的计算方式在不同种类任务中具有更好的适用性，从简单的适用性价值迭代的网格世界，到连续控制，甚至到维基百科链接的导航。在未来的研究中，我们计划向基于模拟或最优线性控制学习的方向开发不同的计算规划方式，并将它们与反应策略相结合，从而为任务和运动规划拓展新的强化学习解决方案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;长按二维码阅读论文&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibPS3Rm2nxF9Ee5ylPNia1mPLzaTyfRuKzeO8icWYmLfO0zSYnq6u3jwMD9cz5N5f877iarAUlnQ1Qibg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以下是最佳论文《Value Iteration Networks》相关的演讲幻灯片介绍，演讲者为该论文的第一作者、 Berkeley AI Research Lab (BAIR) 博士后 Aviv Tamar。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibPS3Rm2nxF9Ee5ylPNia1mPIRTMyLX7sjib4fnic9BeSL3weFoxq0f7ic0IeRG8W0M2lq9PVKDxVk3Wg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P1-6：介绍&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于自动化机器人的目标（比如命令机器人打开冰箱给你拿牛奶瓶），用强化学习可以吗？深度强化学习从高维的视觉输入中学习策略，学习执行动作，但它理解这些策略和动作吗？可以简单测试一下：泛化到一个网格世界中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibPS3Rm2nxF9Ee5ylPNia1mP8eNSv9X1aNZHUppagaFyWKicFpanerzyrM70ZHhicQEiciboET39PoyF3g/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P7-10：观察：反应性策略（reactive policies）的泛化效果并不好。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为什么反应性策略的泛化效果不好呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个序列任务需要一个规划计算（planning computation）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;强化学习绕过了它——而是学习一个映射（比如，状态→Q 值，状态→带有高返回（return）的动作，状态→带有高优势（advantage）的动作，状态→专家动作，[状态]→[基于规划的项]）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Q/返回/优势：在训练域（training domains）上的规划&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;新任务：需要重新规划（re-plan）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibPS3Rm2nxF9Ee5ylPNia1mPm5UXiaVv70uehDDkguSibpQoy15JCFLUyGIYr9wbvfghlp4DMszZFAUw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P11：在这项成果中，我们可以学习规划和能够泛化到未见过的任务的策略。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P12-14：背景&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibPS3Rm2nxF9Ee5ylPNia1mPwTrpPPaynClyicgAqgNQcXwxN1OeHO7W2CWiciaaSQK2EyAOfC7Hpl1hg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P16-21：一种基于规划的策略模型&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从一个反应性策略开始&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;加入一个明确的规划计算&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;将观察（observation）映射到规划 MDP&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;[Image: https://dx903567.quip.com/-/blob/ZGWAAAmgzbz/PJmsMbEdvlUK-WTHNGTf9g] 假设：观察可被映射到一个有用的（但未知的）规划计算&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;神经网络将观察映射成奖励和转变（transitions）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然后，学习这些&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;怎么去使用这种规划计算？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;事实 1 ：值函数 = 关于规划的足够信息&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;思路 1：作为特征向量加入反应性策略&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;事实 2：动作预测可以仅需要 V-*的子集&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;类似于注意模型，对学习非常有效&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;策略仍然是一个映射 g ϕ(s) → Prob(a)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;映射 R-、P-、注意的参数 θ&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们可以反向传播吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;反向传播怎么通过规划计算？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibPS3Rm2nxF9Ee5ylPNia1mPUWGlNlwnx2KDEmCPr4GjicJnxcicibV9mM6g4BK6bym29JYqN36xrH0BA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P22-23：价值迭代=卷积网络&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P24-27：价值迭代网络（VIN）&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibPS3Rm2nxF9Ee5ylPNia1mPm6nsrR49rpdSKoeCIMhzwBUBsw2pc45kE4rwxD6zSANcc9sKvYhA8w/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P28-29：实验&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;问题：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1.VIN 能学习规划计算吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2.VIN 能够比反应策略泛化得更好吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibPS3Rm2nxF9Ee5ylPNia1mPW6We8FWPYWvib6Gw2veKx89TVTsFt7XKxARssHAPZIGTIYSWiafibRODg/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P30-46：网格世界域&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibPS3Rm2nxF9Ee5ylPNia1mPWSLmzJiaj2WbRp4HyibBOa5z0eZXN5fFHq71OicD58PSH6VjI9Poz6BKQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P47-51：火星导航域&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibPS3Rm2nxF9Ee5ylPNia1mPicCdgCt9e6qclroAHasqq0K255tK6tY13F0n63un9cXLONXNFlicyVOQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P52-59：连续控制域&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibPS3Rm2nxF9Ee5ylPNia1mPGbGLiaUKPpGwiaG4Db9TLEUCjEbfwpibhSIsojDPl2HWgibm1p1jdzSA9w/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P60-72：网页导航域：基于语言的搜索&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibPS3Rm2nxF9Ee5ylPNia1mPVJFkZ8aRXXz6DibCQcoHibiaN6b0qKOJcIXlsIE8eUlckvw0UguAFdicGA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P73-76：总结和展望&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;总结&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;学习规划→泛化&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;用于基于规划的神经网络策略的框架&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由动态编程理论所激励&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;可微分规划器（VI = CNN）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;神经网络的组合性（compositionality）——感知 &amp;amp; 控制&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;利用灵活的先验知识&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;简单易用&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;展望和讨论&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不同的规划算法&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;MCT&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最优控制（Optimal control）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;逆向强化学习（Inverse RL）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如何获得近似规划问题&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Atari 中的游戏手册&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;强化学习中的泛化&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;理论？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;基准？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;算法？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;泛化 ≠ 终身强化学习，迁移学习&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;分层策略，但不是选择/技能等等&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;完整PTT请点击阅读原文下载&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心整理报道，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 09 Dec 2016 12:33:07 +0800</pubDate>
    </item>
    <item>
      <title>重磅 | 2016年机器学习领域百大影响力学者：吴恩达位列榜首</title>
      <link>http://www.iwgc.cn/link/3846239</link>
      <description>&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心编辑&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：杜夏德、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;em style="color: rgb(136, 136, 136);"&gt;&lt;span&gt;AMiner Most Influential Scholar Annual List 列举了全球理工科领域引用量最高的一批研究学者。该列表是为了表彰为研究界带来了持久贡献和影响的学者。2016 年的获胜者是指在 2016 年在各自领域被引用最多的学者。该名单是通过 AMiner 部署的计算机算法系统自动根据收集自顶级刊物上的引用数量而排序生成的。AMiner 的榜单涉及到多个学科领域，机器之心在此筛选了其中与人工智能和机器学习相关的几个&lt;/span&gt;&lt;/em&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;领域的前十&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;大学者（有的榜单有百大学者）进行呈现，欲了解完整榜单的读者可访问：&lt;span&gt;https://cn.aminer.org/mostinfluentialscholar&lt;/span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibPS3Rm2nxF9Ee5ylPNia1mPVy5TV5AIKUenTOTNlokLuPUrhAvicTQ36dLqU5KsWyclo6nc0YvaJ2Q/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;机器学习领域 Top 10（评选完毕）&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibPS3Rm2nxF9Ee5ylPNia1mPBica2H0YrV4qTpEcWIoHB80LDgoaogkRe6ZffRhteG0mhkWTxsGH11A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该列表是根据机器学习领域顶级会议 ICML 和 NIPS 上的引用数量排序的。 在机器学习列表中，AMiner Most Influential Scholar Annual List 还列出了前 100 名学者名单。 Yoshua Bengio、Yann LeCun、邢波等都榜上有名。查看完整列表可访问链接：https://aminer.org/mostinfluentialscholar/ml&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibPS3Rm2nxF9Ee5ylPNia1mPxico8vib4pYHsRc6rphHrpOp7VStDd2icuUg8JeF1gQs3m4BPUF2MQkNQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibPS3Rm2nxF9Ee5ylPNia1mPHhSEIzMok3akialSCvk0Vwib8NgG27y3xWeHC9wvNPApUuJXzkpgwKMg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibPS3Rm2nxF9Ee5ylPNia1mP9fG3FFRTwyLL0Hag6BckWBjEgofg4MWMLmf8ibpxQMgBJe2x08AIhKw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibPS3Rm2nxF9Ee5ylPNia1mPRmtHTeMeVtCTxjzxCbibkMFOh9456RQ89cLtQmDBgWicRzemCbDXRrSw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;人工智能 Top 9（候选）&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该列表是根据人工智能领域顶级会议IJCAI和 AAAI 上的引用数量排序的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibPS3Rm2nxF9Ee5ylPNia1mPGDYico8dfRTQAWjB4Hx5Nctia0QYTGNdJPiadFoibnyKiaye2icCBu5c6C9g/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibPS3Rm2nxF9Ee5ylPNia1mPfk8SCQdydkgrrJRdCCEl0NHGOhq7hSs5tcqI8M0VHhlwZUlnfxiaFWA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibPS3Rm2nxF9Ee5ylPNia1mPuDNu5vSNRPOtmzAN6VVLSiaJkxsvpW7MOjY5VnITNb9om4ibiaEBqmeGQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;计算机视觉 Top 10（候选）&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该列表是根据计算机视觉领域顶级会议CVPR 和 ICCV 上的引用数量排序的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibPS3Rm2nxF9Ee5ylPNia1mPgzyohWpPCibvthicq8M5xeexqBfJuh0cBicbMbFyxXktkOA8x37jm8kFg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibPS3Rm2nxF9Ee5ylPNia1mPfBycYn6UAlEJYibhpsOgGqE6qeQfYFKSmWsXpywTVJk1OV1L8vmHN7A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibPS3Rm2nxF9Ee5ylPNia1mPZ0AeTIxxSjMUFNK5368h3ticzK09JYQYcawLAScLHacEPaibAPwdqHRw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibPS3Rm2nxF9Ee5ylPNia1mPaojiblAYYfMBicyRicqKGbLIx6TtZtc3CBqp2Fw3pZ2iaChqvcHmgo7HsA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;自然语言处理 Top 10（候选）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;该列表是根据自然语言处理领域顶级会议 ACL 上的引用数量排序的。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibPS3Rm2nxF9Ee5ylPNia1mPWp4aqUnfKVC8kogC1tTFIicMZrG5kTC97ibqBrYrXEVL9NKiar5nnHU4w/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibPS3Rm2nxF9Ee5ylPNia1mPT3ibCuwcRyYItHNd8OzorARLoia6GbFrdwWAEUFbah2cjiaNKmeRF9AZA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibPS3Rm2nxF9Ee5ylPNia1mPPJiaRulf8tN0qEToKwQH02JFJNXt2icLYeOicpaDGp9bvicchZhumd891g/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibPS3Rm2nxF9Ee5ylPNia1mPQcrQ8Ygic8yjia148jONZZKA68a6Qb2lYPIFfIvPPlQpRmLbCL9mL88Q/0?wx_fmt=png"/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;数据挖掘 Top 10（评选完毕）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该列表是根据数据挖掘领域顶级会议 ACM SIGKDD 上的引用数量排序的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibPS3Rm2nxF9Ee5ylPNia1mPswzfKpWzibShDwzgG9zsAvA7OBN6OAaPwSBuCgzTkxMlmxWZWB5bAZw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibPS3Rm2nxF9Ee5ylPNia1mPSYqC8viccolL0wjF44Mibp4d7HZgPALoTzicMFtHPsUFKYWia6vWEqdI7A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibPS3Rm2nxF9Ee5ylPNia1mPCTSXEWfmaaOZ5GcXfrGMP6SObk4TuPtmYxSGskvSOaEJ4LXwTN2Gpw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibPS3Rm2nxF9Ee5ylPNia1mP6J8xzRJSK6GfK7icPCSzv2IEu0Fc0TzyCMKZ481glH5sUwuCJBPDiblA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;人机交互 Top 10（候选）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibPS3Rm2nxF9Ee5ylPNia1mPhk1dVOkCkicIkCed7a4hqGX1G2Dvz02Y3Tv0vTOoAXXu6ia4AKYEhv6Q/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibPS3Rm2nxF9Ee5ylPNia1mPfrpdODVyQVMuvJYPG9pSuxUkGhxUx3B61ZyKBjqaID8awSd2bHT71w/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibPS3Rm2nxF9Ee5ylPNia1mPox1pSeYt7cHjdDwwcAOSNTRCba9uzKlibC9E2GJEAibqxGYd5SibBoXLg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibPS3Rm2nxF9Ee5ylPNia1mPWyxJsqeQGI9xt8GsRhrznkSG0sIeVRX9dPylQIawedow5AvvGvo7WA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该列表是根据人机交互领域顶级会议CHI上的引用数量排序的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;信息检索 Top 9（候选）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该列表是根据信息检索领域顶级会议 SIGIR 上的引用数量排序的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibPS3Rm2nxF9Ee5ylPNia1mP7MAd8a5Cof0tHvIE6XH6KbQbjIlam1aPLphia3SFxQBhicgEL82bZgiaQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibPS3Rm2nxF9Ee5ylPNia1mPHwopiclCnyPOMaUwW6eZ7CzUGbUTrSeQzaLvMpM73UnkDmcZibyxxcKQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibPS3Rm2nxF9Ee5ylPNia1mPUgRQnzP2uhGPITWcnOU7ZtGZf5ev63UgIGWcHE24JK2eSNBibg8pdcw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文链接：https://cn.aminer.org/mostinfluentialscholar/cv&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编辑，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 09 Dec 2016 12:33:07 +0800</pubDate>
    </item>
    <item>
      <title>开源 | 雅虎开源轻量级多语言实体链接工具包</title>
      <link>http://www.iwgc.cn/link/3846240</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Yahoo&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李泽南、蒋思源&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;开源地址： &lt;span&gt;https://github.com/yahoo/FEL&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你每次打开客户端（如 Yahoo News 或者 Yahoo Sports），你想优先获得什么样的文本信息？虽然每个人的喜好不同，但你想知道的永远有关文本中的人物，组织和位置信息。自动搜寻此类信息的系统被称为「实体名称识别和链接系统（named entity recognition and linking systems）」。它是文本分析中最重要的系统，许多应用都会使用到它，例如搜索引擎、推荐系统、问答系统和情绪分析系统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;实体名称识别和链接系统使用统计模型，通过大量经过标记的文本进行训练。这种方法面临的主要挑战是在不同语言、长文本、缺乏标记的数据中准确探测实体，同时不需要耗费过多的系统资源（内存和处理器资源）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在雅虎长期研究和不断应用这些解决方案之后，我们很高兴为开源社区贡献我们的这一工具：Fast Entity Linker，我们的无监督、准确、可扩展多语言实体名称识别和链接系统，同时也包含英语、西班牙语和中文数据包。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了增加可用性，我们的系统将文本实体链接至维基百科。例如，当语句中出现「雅虎是一家总部位于加州 Sunnyvale 的公司，CEO 是 Marissa Mayer」时，这一系统会点出以下实体：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Yahoo – linked to https://en.wikipedia.org/wiki/Yahoo!&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Sunnyvale, CA – linked to https://en.wikipedia.org/wiki/Sunnyvale,_California&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Marissa Mayer – linked to https://en.wikipedia.org/wiki/Marissa_Mayer&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在算法上，我们使用了实体嵌入，click-log 数据和高效聚类等方法来实现高精度。该系统通过使用压缩数据结构和主动散列函数以实现低内存占用和快速执行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「实体嵌入（Entity embeddings）」是基于向量的表示，它捕获上下文中引用实体的方式。我们使用维基百科文章训练实体嵌入，并在文章中使用超链接格式来创建规范实体。使用下图中的神经网络架构来建模实体的上下文和表征，其中实体向量经过训练不仅会预测其周围实体，而且可以预测包含词序列的全局上下文。这种方式分为两层，一层实体上下文模型，另一层表征上下文模型。我们使用和用于训练段落向量的相同技术（Quoc 和 Mikolov，2014）来连接这两个层。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibPS3Rm2nxF9Ee5ylPNia1mPZfYgIgMuxHbkibNI8Lzqibq65Se9Zu0hD7ibgtSiaaRicDWWcibNn4ax8Jkw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;同时训练字嵌入和实体嵌入的架构。「Ent」表示实体，「W」表示它们的上下文单词&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;搜索 click-log 数据提供了非常有用的信号来消除局部歧义或实体歧义。例如，搜索「Fox」的人倾向于点击「Fox News」而不是「20th Century Fox」，我们可以使用这些数据来识别文档中的「Fox」。为了消除实体歧义，并确保文档具有一致的实体集合，我们的系统支持三个实体消歧算法：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Forward Backward Algorithm (Austin et al. 91)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Exemplar Clustering (Frey and Dueck 『07)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Label Propagation (Talukdar and Crammer 『09)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前，只有前向后向算法（Forward Backward Algorithm）在我们的开源版本中是可用的，其他两个算法将很快可用！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibPS3Rm2nxF9Ee5ylPNia1mPrVfOCSPjBJGIFic2xE9UjjBic7ibzDqMicGicchs7iaX4khs7DuzgNb53zAg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当常用候选项是实体歧义的错误选项时，这些算法非常有助于精确地链接实体。在下面的例子中，这些算法利用周围语境能准确地将 Manchester City、Swansea City、 Liverpool、Chelsea 和 Arsenal 等词组连接到它们各自的足球俱乐部。模糊提及能用红色突出指明多个实体，例如 Chelsea 可以指纽约或伦敦的 Chelsea 区，或一家著名的足球俱乐部。明确的实体命名以绿色突出显示，在上例中引用的模糊和无歧义示例的实体链接候选项进行检索过程中，正确的候选项就以绿色突出显示。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibPS3Rm2nxF9Ee5ylPNia1mPbvw6Shtn9t27wXkODk6QmHJIzSJ0N2Vzl67qpcmbLvicyK5SlEN0DOg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前，快速实体链接器（Fast Entity Linker）是仅有的三个可用于多语言实体命名识别和链接系统（其他是 DBpedia Spotlight 和 Babelfy）之一。除了独立的实体链接器，这一软件还包括了可用于创建和压缩来自维基百科的不同语言中的词/实体嵌入和数据包等工具。其中，包含了所有英语维基百科信息的数据包只有 2GB！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个系统的技术基础在下面两篇科学论文中被详细论述：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Roi Blanco, Giuseppe Ottaviano, and Edgar Meij:「Fast and space-efficient entity linking in queries.」In Proceedings WDSM 2015.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Aasish Pappu, Roi Blanco, Yashar Mehdad, Amanda Stent, and Kapil Thadani:「Lightweight multilingual entity extraction and linking.」In Proceedings WSDM 2017.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;开源工具包中有许多可用的应用程序，其中之一是将情绪归于文本中检测到的实体，而不是整个文本本身。例如考虑以下来自 MetaCritic 用户对电影《但丁密码》的实际评论：「虽然汤姆·汉克斯的表演很好，制片商也创造了一个神秘而生动的电影，但是剧情还是很难理解。虽然这部电影情节婉转有趣，但我对哥伦比亚影业的期待不止如此」。所以虽然最后的评论是中立的，但是它同样传递了对于汤姆·汉克斯积极情绪和对哥伦比亚电影公司的消极情绪。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;许多现有的情绪分析工具将与文本相关联的情感值整理作为一个整体处理，这使得系统很难跟踪用户对任何单独实体的情绪。使用我们的工具包，开发者们可以让系统自动提取给定文本中的「正面」和「负面」信息，从而更清楚地了解用户对各个单独实体的情绪。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文链接：https://yahooresearch.tumblr.com/post/154110423951/presenting-an-open-source-toolkit-for-lightweight&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 09 Dec 2016 12:33:07 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 波士顿动力最新机器人亮相NIPS 2016，但还未用到机器学习</title>
      <link>http://www.iwgc.cn/link/3846241</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心报道&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：曹瑞、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;波士顿动力公司（Boston Dynamics）发明的机器人不但可以导航家庭住址，利用操控和视觉方面取得的先进性进展甚至还发展出了送包裹 的技能。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在今年 6 月份的时候，机器之心曾报道&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716375&amp;amp;idx=3&amp;amp;sn=6c425d33f1eb1beeb76cdf5ebed94482&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716375&amp;amp;idx=3&amp;amp;sn=6c425d33f1eb1beeb76cdf5ebed94482&amp;amp;scene=21#wechat_redirect"&gt;波士顿动力发布最新机器人 Spot Mini&lt;/a&gt;。本周，在巴塞罗那的 NIPS 会议上，波士顿动力公司的 CEO——Marc Raibert 展示了他公司的研究者们所作出的一些新成绩，该公司一直以来都致力于动态平衡步行机器人的 研发。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibPS3Rm2nxF9Ee5ylPNia1mPiabsYDeQDtnyMLyantBGRaOsGDibyvufQVqFWfhNDTD7x6fpDZoeudjQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Raibert 在会上展示的四足机器人 Spot Mini，大小大约和一只大型犬相当。波士顿动力此前发布过 Spot Mini 在一个模拟的家庭环境中进行运作的视频，它可以爬楼梯、开门，甚至还可以用夹持器来洗碗。这个机器人有一个像脖子一样的附件，连接的夹持器能够让它做一些简单，但是有用的操纵任务。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;iframe class="video_iframe" data-vidtype="1" style="   z-index:1; " height="375" width="500" frameborder="0" data-src="https://v.qq.com/iframe/preview.html?width=500&amp;amp;height=375&amp;amp;auto=0&amp;amp;vid=y0353xppbbn" allowfullscreen=""&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个机器人是半自动的。在神经信息处理系统大会（NIPS）上，波士顿动力公司的一位工程师在 Raibert 演讲的过程中操控 Spot Mini，让它走上了台。但是机器人能够自己感知并对上台的路进行导航，在收到指令之后，就可以进行定位，从桌子上拿起一个罐子。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;步行机器人在混乱的人类环境中导航的能力比轮式机器人可能要更强，但是波士顿动力公司研发的这个机器人价格实在过于昂贵，有些甚至要花费超过 100 万美元。因此波士顿动力在探索潜在的应用，很明显的能够看到在保持平衡的同时控制物体是关键。Raibert 在演讲中说「移动性的操纵是我们的下一挑战。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Robert 展示了数个 Spot Mini 作任务视频，比如打开把手形状怪异的大门。他也展示了该机器人负重走到不同房屋的实验视频。Raibert 说，「每个人都在讨论无人机快递，那为什么不用腿式机器人送快递呢？」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;据 MIT TR 的报道，波士顿动力目前还没在其机器人中使用到机器学习，但 Raibert 说以后会改变，因为机器学习技术能够为动态平衡以及其他任务的编程提供自动化的方式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 09 Dec 2016 12:33:07 +0800</pubDate>
    </item>
    <item>
      <title>活动 | Bot大赛赛后分享：解读计算机视觉研究前沿和应用创新</title>
      <link>http://www.iwgc.cn/link/3846242</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;活动主题&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section&gt;&lt;/section&gt;&lt;/blockquote&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;一直以来，人们都在追求在计算机视觉技术不断创新和突破。随着技术的不断发展和成本的降低，计算机视觉正逐渐改变着我们的生活，人脸识别、安防、购物、汽车、医疗等应用不断创新。科技爆发唤起机器觉醒，技术进步引发应用创新，巨头涌入，机器视觉正迎来风口。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在此背景下，为了促进计算机视觉技术与创新应用交流与合作，追踪BOT大赛赛后实况，BOT大赛组委会联合机器之心、清数D-LAB，邀请大赛优胜团队导师及成员，围绕大赛解题思路和计算机视觉领域前沿技术及创新应用等与您共同分享交流。&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;活动时间&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/m5Ydqt3vdFy4SMYiagqGT8DZp6Yib8XRibblQHAfDdzNszx7pwQ4OgjenV8EEgXKtc46e7PMbTPKqYWet8vEJktaQ/640?wx_fmt=png"/&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;2016年12月10日（周六）13:30-16:00pm&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;活动地点&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/m5Ydqt3vdFy4SMYiagqGT8DZp6Yib8XRibblQHAfDdzNszx7pwQ4OgjenV8EEgXKtc46e7PMbTPKqYWet8vEJktaQ/640?wx_fmt=png"/&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;北京市朝阳区酒仙桥东路电子城科技园A2东门一层&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;活动议程&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/m5Ydqt3vdFy4SMYiagqGT8DZp6Yib8XRibblQHAfDdzNszx7pwQ4OgjenV8EEgXKtc46e7PMbTPKqYWet8vEJktaQ/640?wx_fmt=png"/&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;13:30-14:00pm 签到&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;14:00-14:05pm 主持人开场及主办方介绍&lt;/p&gt;&lt;p&gt;主持人：（待定）&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;14:05-14:20pm &amp;nbsp;深度学习技术与创新（拟定）&lt;/p&gt;&lt;p&gt;陶进，大唯团队队长，BOT大赛计算机视觉赛题二等奖&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;14:20-14:40pm &amp;nbsp;大数据时代的视觉智能&lt;/span&gt;&lt;/p&gt;&lt;p&gt;王金桥，BOT大赛计算机视觉赛题冠军ITDog导师，&lt;span&gt;中科院自动化研究所研究员&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;14:40-15:00pm 计算机视觉技术应用（拟定）&lt;br/&gt;&lt;/p&gt;&lt;p&gt;陈朝才，DeeeeeeeeeepNet团队队长，获BOT大赛计算机视觉赛题优胜奖&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;15:00-15:20pm 赛题解题思路分享&lt;/p&gt;&lt;p&gt;刘智威，ITDog团队队长，获 BOT大赛计算机视觉赛题冠军、最佳算法奖&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;15:20-15:40pm &amp;nbsp;计算机视觉赛题创新与设计（拟定）&lt;/p&gt;&lt;p&gt;&lt;span&gt;尹相志 BOT大赛组委会赛题组组长&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;15:40-16:00pm 讨论互动环节&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;嘉宾介绍&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/m5Ydqt3vdFy4SMYiagqGT8DZp6Yib8XRibblQHAfDdzNszx7pwQ4OgjenV8EEgXKtc46e7PMbTPKqYWet8vEJktaQ/640?wx_fmt=png"/&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;尹相志&lt;/span&gt;&lt;/strong&gt;&lt;span&gt; ，&lt;/span&gt;&lt;/span&gt;&lt;span&gt;BOT大赛组委会赛题组组长。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;华院数据技术（上海）有限公司数据科学家，拥有丰富的信用评等模型、交叉销售模型、其他数据挖掘模型、数据仓库、新巴塞尔资本协定等项目经历，出版过多部数据挖掘相关的著作与论文，并拥有因特网活动记录装置及方法、因特网信息搜集方法及装置两项专利其先后在特力集团、数博网、和信电讯、台湾亚洲资采等领导数据挖掘相关工作，并曾出任世新大学讲师，是台湾微软的特聘金牌讲师。&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;王金桥&lt;/strong&gt;，&lt;/span&gt;BOT大赛冠军团队ITDog导师，中科院自动化研究所研究员，研究领域图像与视频分析目标识别，发表论文SCI/EI论文120篇，主持和参与多个国家重大项目，2015-2016年所指导团队在近10场国际专业大赛中取得优秀成绩。&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;刘智威&lt;/span&gt;&lt;/strong&gt;，BOT大赛计算机视觉赛题冠军、最佳算法奖获得团队ITDog团队队长。来自中科院自动化所，丰富计算机视觉和模式识别的研究经验。致力于使用深度学习相关知识处理计算机视觉领域所存在的问题，重点关注于理论与实际的结合，在应用和产品中发挥算法的极致性能。&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;陶进&lt;/strong&gt;，&lt;/span&gt;大唯团队队长，ＢＯＴ大赛计算机视觉赛题二等奖获得团队；大唯科技创始人。&amp;nbsp;“学习的本质是把不习惯的变成习惯的一个痛苦的过程，深度学习是深度的痛苦，我喜欢这种痛苦。”&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;陈朝才&lt;/strong&gt;，&lt;/span&gt;DeeeeeeeeeepNet团队队长，ＢＯＴ大赛计算机视觉赛题优胜奖获得团队；&lt;span&gt;360数据挖掘工程师，喜欢静静的看着loss下降。&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;活动主办方&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/m5Ydqt3vdFy4SMYiagqGT8DZp6Yib8XRibblQHAfDdzNszx7pwQ4OgjenV8EEgXKtc46e7PMbTPKqYWet8vEJktaQ/640?wx_fmt=png"/&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心&lt;/strong&gt;，&lt;/span&gt;国内领先的前沿科技垂直媒体，关注人工智能、机器人、神经认知科学等前沿科技及深度思考，旨在通过高质量内容让用户更好地了解即将到来的下一次技术变革，同时启发大家对人与科技的哲学思考。&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW83GIFs6icx4ictPqX5sphoStIssdBAhbCK8SRBWVL48qC6uenbK4xWq6htS905Y8ibicNiaeFCm8zEOibQ/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;&lt;strong&gt;清华数据创新基地&lt;/strong&gt;，&lt;/span&gt;&lt;span&gt;即清数D-LAB，是在清华大学数据科学研究院、清华大数据产业联合会和启迪创业孵化器大力支持下成立的大数据创新创业平台。基地顺应“实施国家大数据战略”和“大众创新、万众创业”的号召，汇聚了国内大数据领域优秀的政产学研资源，肩负着引领数据创新，培育数据人才，促进数据开放，打造数据生态的使命。&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/bw1naTt4iay9Dy77gR1Bg8TFBpKBfhRUZp58DfiahapvtPCzoOHtiaXzPdv7FbibqHdXetP88xJzcibvA5iamOMqVycg/640?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;“&lt;strong&gt;&lt;span&gt;上海BOT大数据应用大赛&lt;/span&gt;&lt;/strong&gt;”&lt;/span&gt;&lt;span&gt;自2016年起，每年举办一届，力争成为国内一流、具有国际影响力的人工智能大赛。第一届大赛由上海大数据产业基地（市北高新）、上海大数据联盟、英特尔（中国）有限公司、和华院数据技术（上海）有限公司联合主办。本次大赛聚焦“人工智能聊天机器人创新产业应用”和“计算机视觉识别”两大赛题，吸引来自13个国家和地区的近800位选手参赛，将推动人工智能产业应用落地，打造人工智能新生态。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/bw1naTt4iay9Dy77gR1Bg8TFBpKBfhRUZHKhpG5QcnGuwZRuoYjaQWmBnwzW21feIAcpE0sRfe3NbGJ71FsYmVw/0?"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;点击阅读原文即刻报名参加&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;hr style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW83GIFs6icx4ictPqX5sphoStoEjwHr2StN6TxVmBTImoibIzIPjCy5by15WVC3Uaktx5E64JErFfBqA/640?wx_fmt=png"/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;THU数据派，清华大学数据科学研究院和清华大数据产业联合会的官方微信公众号。分享前沿数据产业动态，定期组织清华线下活动，持续传播数据科学思维，打造数据人才聚集平台。清华大数据，尽在数据派！&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 09 Dec 2016 12:33:07 +0800</pubDate>
    </item>
    <item>
      <title>重磅 | 谷歌开源Embedding Projector，可将高维数据可视化（附论文）</title>
      <link>http://www.iwgc.cn/link/3830974</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自GoogleResearchBlog&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀、微胖&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;近段时间以来，机器学习领域内的进展已经催生出了很多激动人心的结果，其应用已经延展到了图像识别、语言翻译、医学诊断等许多领域。对研究科学家来说，随着机器学习系统的广泛应用，理解模型解读数据的方式正变得越来越重要。但是，探索数据的一大主要难题是数据往往具有数百个乃至数千个维度，这需要我们使用特别的工具才能研究调查清楚数据空间。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了实现一种更为直观的探索过程，谷歌今日布开源了一款用于交互式可视化和高维数据分析的网页工具 Embedding Projector，其作为 TensorFlow 的一部分，能带来类似 A.I. Experiment 的效果（参阅：&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720553&amp;amp;idx=5&amp;amp;sn=15a0903d74e54403f1290197408904a3&amp;amp;chksm=871b0d57b06c8441a631b966defdf5569cc078850c3dd5428244d0c55efc73fc9c97b3c675d3&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720553&amp;amp;idx=5&amp;amp;sn=15a0903d74e54403f1290197408904a3&amp;amp;chksm=871b0d57b06c8441a631b966defdf5569cc078850c3dd5428244d0c55efc73fc9c97b3c675d3&amp;amp;scene=21#wechat_redirect"&gt;业界 | 谷歌推出 A.I. Experiments：让任何人都可以轻松实验人工智能&lt;/a&gt;）。同时，谷歌也在 projector.tensorflow.org 放出了一个可以单独使用的版本，让用户无需安装和运行 TensorFlow 即可进行高维数据的可视化&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Embedding Projector 地址：&lt;span&gt;https://www.tensorflow.org/versions/master/how_tos/embedding_viz/index.html&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;可单独使用的版本：&lt;span&gt;http://projector.tensorflow.org/&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;相关论文地址：&lt;span&gt;https://arxiv.org/pdf/1611.05469v1.pdf&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicXY1ia2icOE9cA9pp0mRC1qS8Q7twqCO8Lz1IL8L7L7WFN6lNj9aicqmAYxznCNpxXEcdwicrjVboaVg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;探索嵌入（embeddings）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;训练机器学习系统所需的数据一开始的形式是计算机无法直接理解的。为了将这些我们人类能够自然而然理解的东西（如：话语、声音或视频）翻译成算法能够处理的形式，我们会使用到嵌入（embeddings）——一种获取了数据的不同方面（即：维度 dimension）的数学向量表征。比如说，在一个语言嵌入中，相似的词会被映射到彼此相近的点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicXY1ia2icOE9cA9pp0mRC1qSKcIqL5eybNXlIJ5WJxYDOaThuViaYicBItGwf3dX6ACdw6YgSvMSgsgw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;降维的方法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Embedding Projector 提供了三种常用的数据降维（data dimensionality reduction）方法，这让我们可以更轻松地实现复杂数据的可视化，这三种方法分别是 PCA、t-SNE 和自定义线性投影（custom linear projections）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;PCA 通常可以有效地探索嵌入的内在结构，揭示出数据中最具影响力的维度。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;t-SNE 可用于探索局部近邻值（local neighborhoods）和寻找聚类（cluster），可以让开发者确保一个嵌入保留了数据中的所有含义（比如在 MNIST 数据集中，可以看到同样的数字聚类在一起）。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;自定义线性投影可以帮助发现数据集中有意义的「方向（direction）」，比如一个语言生成模型中一种正式的语调和随意的语调之间的区别——这让我们可以设计出更具适应性的机器学习系统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicXY1ia2icOE9cA9pp0mRC1qSQIIicRCrnVaCiaQxWnLMOBiacslriaLU4LWvgAx3Eec0eS1hJDIico4AYtQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;在一个拥有 3.5 万个电子邮件常用短语的语料库中，「see attachment」的 100 个最近的点到「yes」-「yeah」向量上（yes 在右，yeah 在左）的自定义线性投影&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌的博客写道：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Embedding Projector 网站包括一些可供试玩的数据组。我们也让用户更容易使用它并与其他人共享他们的嵌入（仅需点击左边的* publish *按钮）。我们希望 Embedding Projector 能有效帮助研究社区探索并调节他们的机器学习应用，也让所有人更好地理解机器学习算法如何解读数据。如果对 Embedding Projector 细节有兴趣，请阅读我们的论文。祝你在嵌入的世界里玩得开心！&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;以下是论文摘要：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicXY1ia2icOE9cA9pp0mRC1qSb3ibJUibYsd1CL9Hd0so5vsd1lcbeSKVhSB4kicbgmQluCibkYsUjh9GeA/0?wx_fmt=png"/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：嵌入在机器学习领域，比如推荐系统、NLP 以及许多其他应用领域中很常见。研究人员和开发者常常需要探索某个具体嵌入的属性，并找到分析嵌入的方法以将它们视觉化。我们为交互式可视化和嵌入的诠释工作推出了 Embedding Projector 这款工具。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文链接：https://research.googleblog.com/2016/12/open-sourcing-embedding-projector-tool.html&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 08 Dec 2016 11:31:50 +0800</pubDate>
    </item>
    <item>
      <title>前沿 | MIT研发语音关联的图像识别系统，一次破解所有语言</title>
      <link>http://www.iwgc.cn/link/3830975</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自MIT&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：Jane W、李泽南&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;将录音语音与图像相关联的系统可以达到完全自动语音识别。MIT 研究人员研发了一种新的训练语音识别系统的方法，它不依赖于转录抄本（transcription）。相反，这个系统的工作方式是分析图像间的关联和图像的语言描述，而这些语言描述是在大量的音频记录中捕获的。点击阅读原文查看论文。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;语音识别系统，如手机上将语音转换为文本的软件，通常是机器学习的产物。计算机通过研究数以百万的音频文件和它们的转录，学习得到音频的声学特征与词语类型的对应关系。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但目前转录是一项昂贵、费时的工作，因此语音识别的研究只限于少数经济发达国家的语言。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在本周的神经信息处理系统会议（Neural Information Processing Systems conference）上，MIT 计算机科学与人工智能实验室（CSAIL）的研究人员提出了一种新的方法来训练语音识别系统，使其不依赖于转录。相反，这个系统的工作方式是分析图像间的关联和图像的语言描述，而这些语言描述是在大量的音频记录中捕获的。该系统会学习录音中的声学特征与图像特性之间的对应关系。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「该研究的目标是让机器学习语言的方式更像人类，」CSAIL 的高级研究员 Jim Glass 说，他也是阐述此系统的论文的合著者。「当前用来训练语音识别的方法是完全的有监督学习。一段声音会被标记为对应的意思。这种被标记的数据量是非常大的。」&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们已经取得了巨大进步——我们有了 Siri 和 Google assistant——但是对语音标注是昂贵的，因此它们大多用于世界主要语言。世界上有 7000 种语言，我认为只有不到 2％ 具有自动语音识别（ASR）的能力，我们可能无暇解决其它语言的语音识别问题。因此，如果你在思考技术怎样造福整个社会，那么思考为了改变现状我们可以做什么也是很有趣的。我们多年来一直在探索的方法是怎样在减少监督的情况下实现机器学习。」Glass 说道。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;与 Glass 合作论文的有第一作者 David Harwath，MIT 电气工程和计算机科学（EECS）研究生，以及 EECS 教授 Antonio Torralba。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;视觉语义&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;论文中描述的系统类型不同于传统的将语音与标签文本对应的系统; 相反，它将语音与一组主题相关的图像关联起来。这种关联可以作为其它系统的基础。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;例如，如果一段语音与特定类别的图像相关联，并且图像具有与其相关联的文本标签，则可以找到这段语音可能的转录，而所有环节都不需要人工参与。类似，一组具有各种语言文本标签的图像可以为自动翻译提供解决方法。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相反，与类似内容的图像集（如「暴风雨」和「云」）所相关的标签文本词语可以被推断为具有相关含义。因为从某种意义上该系统在学习词的意义——与它们相关联的图像——而不仅仅是它们的声音，所以它比标准语音识别系统具有更广泛的潜在应用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了测试该系统，研究人员使用了数据大小为 1000 的图像集，每一张图像带有一段相关的语音描述。研究人员可以将其中的一段语音传入系统，并让系统返回 10 张最符合的图像。这一个 10 张图像的集合能以 31% 的概率含有一张正确的图像。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我一直在强调我们正在像婴儿一样学步，未来仍然有很长的路要走，」Glass 说。「但是这是一个振奋人心的开始。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;研究人员从海量数据库中取得图像来训练该系统，这个数据库是由 Torralba；CSAIL 的首席研究员 Aude Oliva；以及他们的学生建造的。他们在亚马逊 Mechanical Turk 众包网站上雇人使用语音描述图像，这些语音可以是任何脑海里蹦出的短语，大概持续 10 到 20 秒。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;作为研究方法的初步论证，这种裁剪的数据对于保证预测结果是很必要的。但是该研究的最终目的是使用数字视频来训练系统，最大程度的减少人工参与。「自然而然地，我认为它可以发展到完全使用视频，」Glass 说。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;融合形态&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了建立这种系统，研究人员使用了神经网络，一种模仿大脑结构的机器学习系统。神经网络由多个处理节点组成，每个节点像单个神经元一样，处理节点仅能够进行非常简单的计算，但是它们在密集网络中彼此连接。需要处理的数据被输送到网络的输入节点，节点进行一步处理并且将其传递到其它节点，再由下一个节点进一步处理，这一过程在神经网络中会不断继续。当神经网络被数据集训练时，它不断地修改由其节点执行的操作流程，以便改进其在特定任务上的性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;研究人员的神经网络被分为两个单独的网络：一个将图像作为输入；另一个采用频谱图，代表音频信号作为幅度随时间变化的分量频率。每个网络的顶层的输出是 1024 维向量——1024 个数字的序列。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;网络中的最终节点采用两个向量的点积。也就是说，它将向量中的对应项相乘在一起，并将它们全部相加以产生单个输出。在训练期间，当音频信号对应于图像时，网络必须尝试使点积最大化，并且当音频信号不对应时使网络输出最小化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;研究人员系统的每个谱图可以识别点积峰。在实验中，这些峰值可靠地挑选出了解释图像的词语标签——例如给棒球投手的照片标记「棒球」，或为草地图像标记「草地」和「场地」。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在目前的研究中，研究人员正在继续完善该系统，使它可以挑选出单个词的谱图并且仅识别与它们相对应的图像的那些区域。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「一个婴儿在学会形容周遭环境的过程中，大部分需要处理的信息可能都来自于视觉，」台湾大学电机工程和资讯工程系教授李琳山说道。「今天，机器已经开始模仿这样的学习过程了。这项研究是这一方向最早的探索，令人印象深刻。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「也许更令人兴奋的是，我们能以此探究深层神经网络可以学到多少，」芝加哥大学丰田技术学院助理教授 Karen Livescu 说道。「研究人员在这方面的工作越多，我们从大数据中挖掘出的潜力就越大。我们一直难以标记体量巨大的数据集，所以这项研究备受瞩目，Harwath 等人可以让系统从未标记的数据集中学习。我对此非常期待，想看看他们能走多远。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;下面是相关研究论文&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicXY1ia2icOE9cA9pp0mRC1qSDLJXAGNs2a6EcicvBTfsfOvdu295Asz9QzNHOy152MqkzOQoSrdJ2Vw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要 ：人类在学会读写之前就可以说话了，为什么计算机不能同样如此？ 在本研究中，我们提出了一个深层神经网络模型，能够使用未经转录的音频训练数据进行基本的口语语言学习，其唯一的监督来自于上下文相关的图像形式。我们描述了由12万多个语音音频标记的图像数据集，并评估了我们的模型在图像搜索和注释任务的表现。我们同时提供了一些可视化结果，以证明我们的模型是在学习从字幕谱图中识别有意义的单词。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文链接：http://news.mit.edu/2016/recorded-speech-images-automated-speech-recognition-1206&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 08 Dec 2016 11:31:50 +0800</pubDate>
    </item>
    <item>
      <title>盘点 | 2016深度学习重大进展：从无监督学习到生成对抗网络</title>
      <link>http://www.iwgc.cn/link/3830976</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自tryolabs&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;过去几年，深度学习成为了机器学习社区的核心话题，2016 年更是如此。在 Tryo Labs 的这篇盘点文章中，作者回顾了对该领域贡献最大（或有潜力的）的进展以及组织和社区如何保证这些技术能以一种使所有人都受益的方式被使用。&lt;/span&gt;&lt;/em&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicXY1ia2icOE9cA9pp0mRC1qSyddK0VCUbkJiakhEL7mOdCOuicWl3h65t9USYYmPKwLpLnLtdQxC8a1Q/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;无监督学习一直以来都是研究人员所面临的一个主要挑战。我们认为该领域在 2016 年真是发展得非常不错，这主要是得益于在生成模型（Generative Model）上大量研究。此外，与机器自然交流的能力也是梦想中的目标之一，谷歌、Facebook 这样的巨头也为此提出了多种实现方法。在这一背景中，我们可以看到许多在自然语言处理（NLP）上的创新，这些问题对我们实现与机器自然交流的目标来说是至关重要的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;无监督学习&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;无监督学习指在没有额外信息的情况下，从原始数据中提取模式和结构的任务，它与需要标签的监督学习相互对立。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使用神经网络解决该问题的经典方法是自动编码器。其基础的版本由多层感知机（Multilayer Perceptron）组成，其中输入层和输出层有同样的大小，并会训练一个较小的隐藏层来恢复输入。一旦训练完成，来自该隐藏层的输出相当于对聚类、降维、改进监督分类以及数据压缩都有用的数据表征。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;生成对抗网络（GAN）&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最近一种被称为生成对抗网络的生成模型被广泛的提及，这个模型是在原生成模型的基础上提出的。GAN 可以实现能解决无监督学习问题的模型。GAN 的网络结构是具有颠覆性的，Yann LeCun 在一次关于这个研究的演讲中如此评论：「GAN 是机器学习过去的 20 年里最重要的思想之一。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管在 2014 年 Ian Goodfellow 就提出了 GAN，研究者们直到现在（2016 年）才看到 GAN 的真正潜力。基于 GAN 的更好的训练模型的方法已经出现了，深度卷积式的 GAN（Deep Convolutional GAN）也在今年被提出，这个更加优化的 GAN 模型已经解决了一些之前限制深度学习发展的难题。不仅如此，一些新的应用（我们稍后提供名单）表明这个模型非常强大且灵活。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;一个直观的例子解说&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;试想如下情境，一个很有野心的画家从事名画赝品交易（称之为 G），同时另有一个人（称之为 D）以鉴别画的真伪为生。我们设想先让 D 观摩（即机器学习里的 learning）了一些毕加索的画作，当 D 对毕加索的作品有了一定的认知之后，G 尝试用他的毕加索画作赝品来愚弄 D，让 D 相信他的赝品是毕加索的真作。有时候 G 能够成功的骗过 D，但是随着 D 对毕加索的作品的了解的加深（即机器学习里学习的样本数据越来越多），G 发现越来越难以愚弄 D 了，所以 G 也在不断提升自己仿制赝品的能力。如此多次，不仅 D 已经很精通毕加索作品的鉴别，同时 G 对毕加索作品的伪造技术也大为提升。这就是 GAN 模型的初始想法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从机器学习的模型构建来说，GAN 模型包涵了两个持续相互博弈的神经网络（这也是被称为「对抗」模型的原因）：一个生成器（G）和一个鉴别器（D）。输入一组训练数据（如图像），并假设这些图像服从某种分布（x）。在 GAN 网络中，G 会输出一组分布结果而 D 则会判定这个分布是否来自于同一个训练集。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;刚开始训练的时候，G 会从一些噪声（z）开始生成得到生成的图像 G(z)。D 则会得到来自真实分布（x）的图像和来自 G 生成的图像（G(z)），然后需要将它们分类成 D(x) 和 D(G(z))。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicXY1ia2icOE9cA9pp0mRC1qSUxCq1ptcCRo47PBPubIhqdd6UJUAcsSPWsSQibQDdL9NLBdeHOm81AA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图：GAN 的工作方式&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;D 和 G 同时进行学习，一旦 G 被训练而对训练样本的分布有了足够的了解，它就可以生成有类似特性的新样本：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicXY1ia2icOE9cA9pp0mRC1qScMenMI1WPtibTxQwA8nP8ib8RpWQgicuOuDARuZD9ReGQj5GbrrxuxYMA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;GAN 生成的图像&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些图像由在 CIFAR-10 上训练的一个 GAN 生成。如果你注意细节，你会发现它们并非真正的物体。然而，它们捕捉到了让自己看起来真实的一些概念。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;InfoGAN&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;近期的进展对 GAN 的思想进行了延展，让其不仅可以用于近似数据的分布，还能学习数据的可解释的、有用的表征。这些我们希望得到的表征需要捕捉到丰富的信息（和自动编码器中的一样），也需要是可解释的，也就是说我们要能够区分导致了生成的输出中特定类型的变换的向量部分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;InfoGAN 模型由 OpenAI 研究员在 8 月份提出，其目标就是为了解决这个问题。简言之，InfoGAN 能够以无监督的方式生成包含数据集相关信息的表征。例如，当被应用于 MNIST 数据集的时候，它能够在不需要人工标记数据的情况下推断出数字的类型（1、2、3……）、生成的样本的转动（rotation）与宽度（width）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;条件 GAN（Conditional GAN）&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;GAN 的另一种延展是一类被称为 Conditional GAN 的模型。这些模型能够生成考虑了外部信息（类标签、文本、其它图像）的样本，并使用它来迫使 G 生成特定类型的输出。近期出现的一些应用如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;文本到图像&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;采用文本描述（由字符级的 CNN 或 LSTM 将其编码为向量）作为外部信息，然后基于它生成图像。查看论文：Generative Adversarial Text to Image Synthesis&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicXY1ia2icOE9cA9pp0mRC1qSibNZfKU8ogqe5jCz1ibaQRCHrQIwAgQR1Qtia5EL9FhpBt1GdfrYQicicVA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;图像到图像&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;将输入图像映射到输出图像。查看博客：https://phillipi.github.io/pix2pix/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicXY1ia2icOE9cA9pp0mRC1qSUIISwqecS7b3T0yO10GDibIr9mKWAAXpdr2ia2uC07FxubOEvFWPUyJA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;超分辨率&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;它采用下采样图像（更少细节），生成器试图将它们似然为更自然的图像。查看论文：Generative Adversarial Text to Image Synthesis&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicXY1ia2icOE9cA9pp0mRC1qSEupoDJ2qytIBzDSGJgUIjicsRKMlAjwKbvh4SJr94Hic64icFXpVFLTWg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;自然语言处理&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了能够和机器流畅地对话，我们首先要解决很多问题，包括：文本理解、问答系统和机器翻译。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;文本理解&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Salesforce MetaMind (http://metamind.io/) 建立了一个叫做 Joint Many-Tasks（JMT）的模型，目标是要创造出一个可以学习五个常见自然语言处理任务的模型：&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;词性标注（Part-of-speech tagging）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;指对句子中的每个词都指派一个合适的词性，比如说名词、动词、形容词等。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;词块分析（Chunking）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;也叫做浅层句法分析（shallow parsing），其中涉及到很多任务，像是寻找名词和动词词组等。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;依存关系分析（Dependency parsing）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;识别词语之间的语法关系（比如说形容词修饰名词）。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;语义相关度（Semantic relatedness）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;衡量两个句子之前的语义相关程度，其结果是用一个实值分数来表示的。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;文字蕴含（Textual entailment）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;确定前提的句子是否包含一个表示假设的句子。可能出现的句子关系包括：蕴含、矛盾 和中立。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个模型背后的魔力就在于它是端对端训练的。也就是说它能够让两个不同层面的处理兵种，这样浅层任务（不那么复杂的）可以得到改善，从深层（较复杂的任务）中得出结论。我们之前的想法是只用浅层来改进深层的任务，而不是用其他的方式，所以这个采用不同的方式与之前的思路比较来说是一个新的想法。除了词性标注之外，这个模型在其他方面都取得了很好的成绩。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;问答系统&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;MetaMind 同样提出了称之为 Dynamic Coattention Network (DCN) 的新模型来解决疑问解答问题，该模型建立在相当直观的思路之上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;想象下我给你了一篇长文并问你一些问题，你是想先看文章再听问题呢，还是更想先听问题再开始阅读文章？一般提前知道问题是怎么样的就会知道看文章要注意些什么，如果不知道问题，那么你就会将你的注意力平均分配并记下每一点可能会被提问的细节。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;DCN 也是在做这样一件事，首先它生成一个内部表征，这个内部表征是基于文本并且由系统将要回答的问题做为约束条件，然后就是按照可能的回答列表迭代，直到收敛到最后的回答。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器翻译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌在今年九月发布了用于翻译服务的新模型，即谷歌神经网络机器翻译系统（Google Neural Machine Translation (GNMT)），这个系统是由如英-汉那样独立的语言对训练的。不过新的 GNMT 系统在 11 月份也发布了，它进一步训练了能实现多语言对互译的单个模型。现在 GNMT 系统与以前唯一不同之处就是它采用了能指定目标语的新型输入方法。它同样能够进行 zero-shot translation，这就意味着它能够翻译一对没有训练过的语言。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;GNMT 系统的开发表明了基于多语言对的训练要比基于单语言对的训练效果好得多，这也证明了从一种语言对迁移「翻译知识」到另一种语言对是可行的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;社区&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一些公司和企业已经建立起非营利性伙伴关系进而讨论机器学习的未来，并确保这些惊人的技术得以正确使用，从而有利于社区。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;OpenAI 是一个非营利性组织，它旨在建立学界和工业界之间的合作关系，并将其研究结果免费公开。OpenAI 在 2015 年建立，并在 2016 年开始发表它的研究结果（通过 InfoGAN 出版物、Universe 平台、this one 会议）。OpenAI 的目标就是确保人工智能技术对尽可能多的人来说都是可行的，并且防止出现超人工智能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一方面，亚马逊、DeepMind、谷歌、Facebook、IBM 和微软还在人工智能之上达成了一项合作，其目标是提升公众对这一领域的理解、支持最佳的实践和为讨论和参与开发一个开放的平台。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该研究社区另外值得提及的一点是其开放性。你不仅可以在 arXiv（或 arXiv-Sanity）这样的网站上免费找到几乎任何论文，而且还能使用他们同样代码复现他们的实现。GitXiv 是其中一个很有用的工具，其将 arXiv 上的论文和它们对应的开源项目库链接到了一起。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;arXiv：&lt;span&gt;https://arxiv.org&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;arXiv-Sanity：&lt;span&gt;http://www.arxiv-sanity.com&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GitXiv：&lt;span&gt;http://www.gitxiv.com&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在，开源工具已经无处不在，并且已经得到了研究者和企业的广泛使用和开发。下面简单列出了 2016 年最受欢迎的深度学习工具：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;TensorFlow，来自谷歌，地址：https://github.com/tensorflow/tensorflow&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Keras，来自 François Chollet，地址：https://github.com/fchollet/keras&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;CNTK，来自微软，地址：https://github.com/Microsoft/CNTK&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;MXNET，来自 DMLC，被亚马逊采用，地址：https://github.com/dmlc/mxnet&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Theano，来自蒙特利尔大学，地址：https://github.com/Theano/Theano&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Torch，来自 Ronan Collobert, Koray Kavukcuoglu, Clement Farabet，被 Facebook 广泛使用，地址：https://github.com/torch/torch7&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;最后的思考&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如今正是参与到机器学习发展中的好时机。正如你所看到的，今年取得的成果尤其令人激动。该领域的研究正在迅猛发展，紧跟进步的步伐都成了一件难事。我们非常幸运生活在一个人工智能民主化的时代。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文链接：https://tryolabs.com/blog/2016/12/06/major-advancements-deep-learning-2016/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 08 Dec 2016 11:31:50 +0800</pubDate>
    </item>
    <item>
      <title>前沿 | 脑机接口新进展：通过直接脑刺激操作视频游戏</title>
      <link>http://www.iwgc.cn/link/3830977</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自33rdsquare&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：王宇欣、微胖&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;华盛顿大学的科学家们发表了一项研究，首次展示了仅用直接大脑刺激产生的输入信号——不依赖任何通常来自视觉、听觉或者触觉的感知提示——就可以玩简单的二维电脑游戏。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人类如何通过直接脑刺激实现虚拟互动，华盛顿大学迈出了第一步。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWicXY1ia2icOE9cA9pp0mRC1qSLzr8dNA4YgHNAzhH5RZiaznP7bu7Rj48jfet42wwNus4YAqlict5zJxg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在一篇已经发表在 Frontiers in Robotics and AI 的在线文章中，他们对其演示进行了说明：仅用直接大脑刺激产生的输入信号——不依赖任何通常来自视觉、听觉或者触觉的感知提示——就可以玩简单的二维电脑游戏。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在该游戏中，受试者必须在通过 21 个不同的迷宫，根据是否感到一种被称为光幻视的人造视觉效果，向前或者向下移动。为了示意往哪个方向移动，研究人员通过经颅磁刺激（TMS）制造出光幻视。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;论文第一作者，威斯康星计算科学与工程教授、感觉神经工程中心主任 Rajesh Rao 说，「如今我们通过显示器、头显设备和眼镜来实现虚拟现实，但是最终你的大脑才能创造出你所能看到的现实。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「对于我们想问的基本问题的回答是：大脑是否可以利用一些从未被传递到大脑用来展示虚拟世界的人工信息，或者在没有其他感官的输入下，以执行有用的任务？答案是肯定的。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当他们通过直接脑刺激接受输入时，5 个测试对象在 92% 的迷宫当中都做出了正确的动作，相比之下，当他们缺乏该指导时，则只有 15%。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;没有光幻视——直接脑刺激产生的人为视觉效果——会告诉受试者向前或向下移动。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;「如今我们通过显示器、头显设备和眼镜来实现虚拟现实，但是最终创造你所看到的现实的是大脑。」&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这一简单游戏证实了一种——将来自人工传感器或计算机生成的虚拟世界中的新奇信息成功编码并非侵入地传递给大脑以完成有用的任务——的方式。它采用了神经科学中经常用来研究大脑运作原理的技术——经颅磁刺激（TMS）技术——取代将可行动信息传达给大脑。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随着时间的推移，测试对象在导航任务方面的表现也越来越好，这表明他们可以更好地学习检测人工刺激。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;论文的主要作者，电脑与生物学的硕士，学习和脑科学研究所 (I-LABS) 的研究人员 Darby Losey 说，「我们必须尝试给人类第六感（a sixth sense）, 神经科学领域一直在致力于从大脑中解码信息。我们的研究方向则是如何将信息编码到大脑中」&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;研究人员总结，「这些结果表明，人类可以利用以非侵入式方式（non-invasively）传递给他们大脑的信息来解决一些不能用他们天生的感知来解决的任务。探索这个人类感觉增强（human sensory augmentation）的新兴领域及其技术，伦理以及社会的影响，仍然是一个活跃的研究领域，」&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;初始实验使用了二进制信息—无论是否存在光幻视（phosphene）—让游戏玩家知道在迷宫面前是否有障碍物。在现实世界中，即使是这种类型的简单的输入也可以帮助盲人或者视障人士导航。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;心理学助理教授和 I-LABS 的研究科学家、论文合著者 Andrea Stocco 说，「该技术还无法实现—我们用来刺激大脑的设备太过庞大，人们无法随身携带，但最后我们或许可以用经得起现实应用的东西替换这个硬件。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过直接大脑刺激接收输入，并在其指导下穿行试验迷宫（蓝色）的被试，92% 的行动步骤都是正确的，而没有接收刺激的玩家在穿行试验迷宫（红色）时，成功率仅为 15%。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;与来自 UW 以外的其他合作伙伴一起，研究团队的成员共同创办了 Neubay，这是一家初创公司，旨在将他们的想法商业化，并引入能够让虚拟现实、游戏以及其他应用更好、更吸引人的神经科学和人工智能。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该团队目前正在研究如何改变脑刺激的强度和位置来创建更复杂的视觉和其他的感知效果，这些效果目前难以在增强现实或虚拟现实中得以复制。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们认为，距离实现直接、非侵入式地（noninvasively）将丰富感觉输入大脑的伟大愿景，这不过迈出了很小一步，」Rao 说，「从长远来看，这一成果对帮助那些感官缺陷的人有着深刻影响，同时也为实现更真实地虚拟现实体验铺平了道路。」&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文链接：http://www.33rdsquare.com/2016/12/people-pay-video-game-using-only-direct.html&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 08 Dec 2016 11:31:50 +0800</pubDate>
    </item>
    <item>
      <title>资源 | Yoshua Bengio新书《Deep Learning》中文版开放预览（附PDF下载链接）</title>
      <link>http://www.iwgc.cn/link/3830978</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自GitHub&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;编辑：杜夏德、曹瑞&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Yoshua Bengio 新书《Deep Learning》中文版发布。该书由北京大学张志华老师团队负责翻译。本书&lt;span&gt;于学习研究目的，不得用于任何商业行为。&lt;/span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下载链接：&lt;/span&gt;&lt;span&gt;https://github.com/exacity/deeplearningbook-chinese/raw/master/dlbook_cn_initial.pdf&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicXY1ia2icOE9cA9pp0mRC1qSKFev1Eu4ttHia9Mul6ibkIYnMQrG8c46dDHjD8ic70ZHdgaEfnwyte6Ig/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;em style="color: rgb(136, 136, 136);"&gt;&lt;span&gt;这本书对各类读者都一定用处的，但是有两个主要目标受众。其一是学习机器学习的大学生（本科或研究生），包括那些开始了职业生涯的深度学习和人工智能的研究者。另一个目标群体是没有机器学习或统计背景但要迅速在他们的产品或平台开始使用深度学习的软件工程师。&lt;/span&gt;&lt;/em&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;——前言&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本书被组织为三个部分：&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;第一部分介绍了基本的数学工具和机器学习的概念。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;第二部分介绍了本质上已解决的技术、最成熟的深度学习算法。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;第三部分介绍了被广泛认为是深度学习未来研究重点的但更具猜测性的想法。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;译者声明：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Deep Learning 中文翻译&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;经过 3 个多月，我们终于完成了翻译草稿。当然这是草稿中的草稿，我们会不断改进，就像梯度下降一样，要迭代好几轮才能找的一个不错的解。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前的版本是直译版，尽可能地保留原书中的每一个字。如&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Inventors have long dreamed of creating machines that think. This desire dates back to at least the time of ancient Greece. 自古以来, 创造者就梦想着创造能思考的机器。这个愿望至少可以追溯到古希腊的时期。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;之后我们可能会翻译成：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;远在古希腊的时期, 创造者就梦想着创造能思考的机器。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;语句流畅度的提高必然伴随精度下降（我们水平有限）。因此我们需要 ensemble，需要大家的建议。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;面向的读者&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这一版读起来肯定费劲，我们建议英文好的或者研究者直接读原版。这一版面向的读者是英语不好，急于想入门深度学习的同学。或者希望帮忙校对的各路大哥也可以读读，只要不嫌弃。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;注意&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;各种问题或者建议可以提 issue，建议使用中文。由于版权问题，我们不能将图片和 bib 上传，请见谅。可用于学习研究目的，不得用于任何商业行为。谢谢！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;TODO&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;翻译图片描述&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;链接补全&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;语句通顺&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;第 20 章正在校对，这章比较难估计还需 2 周&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Updating.....&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://github.com/exacity/deeplearningbook-chinese&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;本书目录：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一章、前言&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二章、线性代数&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第三章、概率与信息&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第四章 、数值计算&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;第五章、机器学习基础&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第六章、深度前馈网络&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第七章、深度学习的正则化&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第八章、深度模型中的优化&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第九章、卷积神经网络&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第十章、序列建模：循环和递归网络&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第十一章、实用方法&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第十二章、应用&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第十三章、linear factor&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第十四章、自动编码&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第十五章、表征学习&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第十六章、结构概率模型&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第十七章、monte carlo 方法&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第十八章、面对区分函数&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第十九章、近似推断&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文来自：https://github.com/exacity/deeplearningbook-chinese&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 08 Dec 2016 11:31:50 +0800</pubDate>
    </item>
  </channel>
</rss>
