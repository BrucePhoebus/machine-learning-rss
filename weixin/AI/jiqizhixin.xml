<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>从PyTorch到Mxnet ，对比7大Python深度学习框架</title>
      <link>http://www.iwgc.cn/link/6907a047c4f72ec4895e3331c213ffb370a8fe4b</link>
      <description>
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自kdnuggets&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Madison May&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：王宇欣、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote style="color: rgb(62, 62, 62); font-size: 16px; white-space: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/blockquote&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;选择什么深度学习框架一直是开发者非常关心的一个话题，而且深度学习框架之间的「战争」也越来越激烈。过去一段时间，机器之心发过多篇机器学习框架的对比文章，但随着 Python 逐渐成为机器学习社区最受欢迎的语言，支持 Python 的深度学习框架的性能也值得关注。Indico Data Solutions 的 CTO Madison May 根据他们公司在产品和开发过程中的经验对 7 大 Python 深度学习框架进行了对比，希望这篇文章能对机器之心的读者有所帮助。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最近我无意间在「Best Python library for neural networks」话题下发现了一个我以前的数据科学栈交换（Data Science Stack Exchange）的答案，并且 Python 深度学习生态系统在过去两年半中的演变打击到了我。我在 2014 年 7 月推荐的库，pylearn2，已经不再被积极地开发或者维护，大量的深度学习库开始接替它的位置。这些库每一个都各有千秋。我们已经在 indico 的产品或者开发中使用了以下列表中的大部分的技术，但是对于剩下一些我们没有使用的，我将会借鉴他人的经验来帮助给出 2017 年 Python 深度学习生态系统的清晰的、详尽的理解。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;确切地说，我们将会关注：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Theano&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Lasagne&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Blocks&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;TensorFlow&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Keras&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;MXNet&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;PyTorch&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面是对这 7 大 Python 深度学习框架的描述以及优缺点的介绍，而且也为每个框架的使用推荐了一些资源，但因微信不支持外网链接，读者们请点击阅读原网址查看资源。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Theano&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://github.com/Theano/Theano&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;描述：&lt;/span&gt;&lt;span&gt;Theano 是一个 Python 库，允许你定义、优化并且有效地评估涉及到多维数组的数学表达式。它与 GPUs 一起工作并且在符号微分方面表现优秀。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;文档：&lt;/span&gt;&lt;span&gt;http://deeplearning.net/software/theano/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;概述：&lt;/span&gt;&lt;span&gt;Theano 是数值计算的主力，它支持了许多我们列表当中的其他的深度学习框架。Theano 由 Fr&amp;eacute;d&amp;eacute;ric Bastien 创建，这是蒙特利尔大学机器学习研究所（MILA）背后的一个非常优秀的研究团队。它的 API 水平较低，并且为了写出效率高的 Theano，你需要对隐藏在其他框架幕后的算法相当的熟悉。如果你有着丰富的学术机器学习知识，正在寻找你的模型的精细的控制方法，或者想要实现一个新奇的或者不同寻常的模型，Theano 是你的首选库。总而言之，为了灵活性，Theano 牺牲了易用性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;优点：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;灵活&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;正确使用时的高性能&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;缺点：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;较高的学习难度&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;低水平的 API&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;编译复杂的符号图可能很慢&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Lasagne&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://github.com/Lasagne/Lasagne&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;描述：&lt;/span&gt;&lt;span&gt;在 Theano 上建立和训练神经网络的轻量级库&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;文档：http://lasagne.readthedocs.org/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;概述：&lt;/span&gt;&lt;span&gt;因为 Theano 致力于成为符号数学中最先且最好的库，Lasagne 提供了在 Theano 顶部的抽象，这使得它更适合于深度学习。它主要由当前 DeepMind 研究科学家 Sander Dieleman 编写并维护。Lasagne 并非是根据符号变量之间的函数关系来指定网络模型，而是允许用户在层级思考，为用户提供了例如「Conv2DLayer」和「DropoutLayer」的构建块。Lasagne 在牺牲了很少的灵活性的同时，提供了丰富的公共组件来帮助图层定义、图层初始化、模型正则化、模型监控和模型训练。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;优点：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;仍旧非常灵活&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;比 Theano 更高级的抽象&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;文档和代码中包含了各种 Pasta Puns&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;缺点：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;社区小&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Blocks&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://github.com/mila-udem/blocks&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;描述：&lt;/span&gt;&lt;span&gt;用于构建和训练神经网络的 Theano 框架&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;文档：&lt;/span&gt;&lt;span&gt;http://blocks.readthedocs.io/en/latest/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;概述：&lt;/span&gt;&lt;span&gt;与 Lasagne 类似，Blocks 是在 Theano 顶部添加一个抽象层使深度学习模型比编写原始的 Theano 更清晰、更简单、定义更加标准化。它是由蒙特利尔大学机器学习研究所（MILA）编写，其中一些人为搭建 Theano 和第一个神经网络定义的高级接口（已经淘汰的 PyLearn2）贡献了自己的一份力量。比起 Lasagne，Blocks 灵活一点，代价是入门台阶较高，想要高效的使用它有不小的难度。除此之外，Blocks 对递归神经网络架构（recurrent neural network architectures）有很好的支持，所以如果你有兴趣探索这种类型的模型，它值得一看。除了 TensorFlow，对于许多我们已经部署在 indico 产品中的 API，&lt;/span&gt;&lt;span&gt;Blocks 是其首选库。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;优点：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;仍旧非常灵活&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;比 Theano 更高级的抽象&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;易于测试&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;缺点：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;较高的学习难度&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;更小的社区&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;TensorFlow&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://github.com/tensorflow/tensorflow&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;描述：&lt;/span&gt;&lt;span&gt;用于数值计算的使用数据流图的开源软件库&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;文档：https://www.tensorflow.org/api_docs/python/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;概述：&lt;/span&gt;&lt;span&gt;TensorFlow 是较低级别的符号库（比如 Theano）和较高级别的网络规范库（比如 Blocks 和 Lasagne）的混合。即使它是 Python 深度学习库集合的最新成员，在 Google Brain 团队支持下，它可能已经是最大的活跃社区了。它支持在多 GPUs 上运行深度学习模型，为高效的数据流水线提供使用程序，并具有用于模型的检查，可视化和序列化的内置模块。最近，TensorFlow 团队决定支持 Keras（我们列表中下一个深度学习库）。虽然 TensorFlow 有着自己的缺点，但是社区似乎同意这一决定，社区的庞大规模和项目背后巨大的动力意味着学习 TensorFlow 是一次安全的赌注。因此，TensorFlow 是我们今天在 indico 选择的深度学习库。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;优点：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;由软件巨头 Google 支持&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;非常大的社区&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;低级和高级接口网络训练&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;比基于 Theano 配置更快的模型编译&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;完全地多 GPU 支持&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;缺点：&lt;/span&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;虽然 Tensorflow 正在追赶，但是最初在许多基准上比基于 Theano 的慢。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;RNN 支持仍不如 Theano&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Keras&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://github.com/fchollet/keras&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;描述：&lt;/span&gt;&lt;span&gt;Python 的深度学习库。支持 Convnets、递归神经网络等。在 Theano 或者 TensorFlow 上运行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;文档：https://keras.io/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;概述：&lt;/span&gt;&lt;span&gt;Keras 也许是水平最高，对用户最友好的库了。由 Francis Chollet（Google Brain 团队中的另一个成员）编写和维护。它允许用户选择其所构建的模型是在 Theano 上或是在 TensorFlow 上的符号图上执行。Keras 的用户界面受启发于 Torch，所以如果你以前有过使用 Lua 语言的机器学习经验，Keras 绝对值得一看。由于部分非常优秀的文档和其相对易用性，Keras 的社区非常大并且非常活跃。最近，TensorFlow 团队宣布计划与 Keras 一起支持内置，所以很快 Keras 将是 TensorFlow 项目的一个分组。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;优点：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;可供选择的 Theano 或者 TensorFlow 后端&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;直观、高级别的端口&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;更易学习&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;缺点：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;不太灵活，比其他选择更规范&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;MXNet&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://github.com/dmlc/mxnet&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;描述：&lt;/span&gt;&lt;span&gt;MXNet 是一个旨在提高效率和灵活性的深度学习框架。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;文档：http://mxnet.io/api/python/index.html#python-api-reference&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;概述：&lt;/span&gt;&lt;span&gt;MXNet 是亚马逊（Amazon）选择的深度学习库，并且也许是最优秀的库。它拥有类似于 Theano 和 TensorFlow 的数据流图，为多 GPU 配置提供了良好的配置，有着类似于 Lasagne 和 Blocks 更高级别的模型构建块，并且可以在你可以想象的任何硬件上运行（包括手机）。对 Python 的支持只是其冰山一角&amp;mdash;MXNet 同样提供了对 R、Julia、C++、Scala、Matlab，和 Javascript 的接口。如果你正在寻找最佳的性能，选择 MXNet 吧，但是你必须愿意处理与之相对的一些 MXNet 的怪癖。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;优点：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;速度的标杆&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;非常灵活&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;缺点：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;最小的社区&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;比 Theano 更困难的学习难度&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;PyTorch&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://github.com/pytorch/pytorch&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;描述：&lt;/span&gt;&lt;span&gt;Python 中的张量（Tensors）和动态神经网络，有着强大的 GPU 加速。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;文档：http://pytorch.org/docs/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;概述：&lt;/span&gt;&lt;span&gt;刚刚放出一段时间，PyTorch 就已经是我们 Python 深度学习框架列表中的一个新的成员了。它是从 Lua 的 Torch 库到 Python 的松散端口，由于它由 Facebook 的 人工智能研究团队（Artificial Intelligence Research team (FAIR)）支持且因为它用于处理动态计算图（Theano，TensorFlow 或者其他衍生品没有的特性，编译者注：现在 TensorFlow 好像支持动态计算图），它变得非常的有名。PyTorch 在 Python 深度学习生态系统将扮演怎样的角色还不得而知，但所有的迹象都表明，PyTorch 是我们列表中其他框架的一个非常棒的选择。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;优点:&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;来自 Facebook 组织的支持&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;完全地对动态图的支持&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;高级和低级 API 的混合&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;缺点：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;比其他选择，PyTorch 还不太成熟（用他们自己的话说&amp;mdash;「我们正处于早期测试版本。期待一些冒险」）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;除了官方文档以外，只有有限的参考文献/资源&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;原文链接：http://www.kdnuggets.com/2017/02/python-deep-learning-frameworks-overview.html&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;span&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Sun, 05 Mar 2017 15:12:51 +0800</pubDate>
    </item>
    <item>
      <title>观点 | 投资人必看：2017年关于人工智能创业的五大预测</title>
      <link>http://www.iwgc.cn/link/40316aaace2911b79b5538fb68c3ea392258a0ac</link>
      <description>
&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;选自bradfordcross&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Bradford&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;参与：黄小天、李亚洲、微胖、蒋思源&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote style="color: rgb(62, 62, 62); font-size: 16px; white-space: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/blockquote&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;近日，机器学习与金融风险投资机构 DCVC 的合伙人 Bradford 写的一篇博客在国外引起了极大的关注，他认为 2017 年人工智能领域内的创业将会发生 5 大变化。这篇文章也许能为投资者提供一些洞见。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Bot 公司将破产&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;深度学习商品化&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;人工智能成为风险投资的「清洁科技」翻版&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;MLaaS 将陷入第二次停滞&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;全栈垂直人工智能创业公司有发展&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随着对 AI 的狂热追逐日趋放缓，2017 将是重新梳理的一年。纯炒作趋势将不攻自破。矛盾的是，小部分垂直型 AI 创业公司在满足了相关专业知识、独特数据和使用 AI 传递其核心价值观的产品的需求之后，将解决全栈产业问题，因此 2017 同时又是取得突破性胜利的一年。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Bot 将陷入破产&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;过去一年升起了一股对 bot 的狂热追逐。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在技术社区，当谈到机器人时，我们通常指的是软件代理，且通过 4 个关键概念进行定义，从而与任意程序（arbitrary programs）代理、环境反应（reaction to the environment）代理、自主（autonomy）代理、目标导向和持续性的代理进行区分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;业界盗用了原指任何形式的业务流程自动化的术语「bot」，并创造了新术语 RPA&amp;mdash;&amp;mdash;机器人流程自动化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然，业务流程自动化将会在未来的几十年内持续发挥作用，如今表现为「bot」（包含语音和聊天功能的对话式界面）的机器人狂热将在 2017 年开始冷却。原因如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;消费互联网领域内的社会化与个性化之争提供了一个很好的借鉴。最后胜出的是个性化平台 Facebook，同时也是一个社交平台。人们依然喜欢在大多数事情上与人交流，我猜测许多 chatbot 将采用与非社交媒体平台相同的方式，试图在没有社交策略的情况下押注个性化。围绕着 bot 的很多思考是肤浅的功利主义，缺少社交智能来辨识人们之间相互交流所满足的人类需求。由于这个原因，大多数 bot 很难留住用户，即使在一开始吸引了他们。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;全球通讯 App 的大爆发，比如 Slack 的崛起和中国的微博等特定社交平台的成功释放了很多误导性信号。很多人据此推断并押注诸如 AI 驱动的数字个人助手等平台。根据第一条，这些社交平台正在解决人们的功利与情感需求。但据此推断可以将其应用于纯功利的 AI chatbot 上，这尚不明了。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;相比于其他更可视化的解决方案，会话式界面在完成任务方面不总是那么有效。会话式界面很有趣，并在在 HCI 社区中已存在了几十年。在一些应用中会话式界面表现绝佳，但是在现实中，我认为有做事效率跟高的界面可用于绝大多数应用。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;注意，我并没有说过 AI 还不够好。像 siri 等大多数系统存在的更多问题是执行欠佳。我们用现代技术打造了很多有趣的机器人界面，随之我心中出现了一个更大的问题：机器人并不清楚我们想使用它们。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;深度学习商品化&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在深度学习非常盛行。对于那些不了解其他 AI 术语的人来讲，深度学习是机器学习的一部分，机器学习是人工智能的一部分。深度学习并不是一个新鲜事物，它只是一系列为很多重要问题提供了最好的答案的很酷工作，人们可以正确地从中受益。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深度学习初创公司已经取代了 5 年之前的 iOS 移动应用创业公司。许多公司都为深度学习的能力感到意外，尤其是产生优越成果并解决新问题的计算机视觉。结果，我们看到了谷歌、Facebook、推特、Uber、微软和 Salesforce 积极采取并购策略填补空缺。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此，如果深度学习如此重要并高受追捧，为什么我认为它今年会商品化？原因在于 2016 NIPS 会议及其他所有会议。很明显深度学习现在无处不在，在这方面有很多毕业生。4 年之前的情景却大不相同。如今，市场已经作出调整以创造更多的人才供给。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在，我要对上述所言做一个清晰的声明。我认为今年在机器学习人群中，深度学习会成为更大的社区，但是我并没有说机器学习本身会商品化。机器学习人才依然炙手可热。我们在过去几年中看到的深度学习初创公司被收购而带来的收益，将在第二层技术公司和外部技术公司（如底特律的公司）完成目前的收购浪潮后崩溃。我预计今年一群数量稳定的迟到者将会带着傻钱进入，但此后我们也许看到并购浪潮开始放缓。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;人工智能成为风险投资的「清洁科技」翻版&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;让我们回想一下最近「清洁科技」公司破产的主要原因，这同样适用于人工智能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;清洁技术不是一个市场。它是一个交叉问题。气候变化和可持续发展是非常严肃的问题，绝对值得人们作为事业和盈利性业务认真对待。交叉问题并不是一个生意，生意是提供产品或服务，消费者想要买。特斯拉和 Solar City 无疑是清洁科技领域的成功案例，但需要注意的是它们是全栈生意&amp;mdash;&amp;mdash;分别是一个汽车公司和一个太阳能公司。所以当一个包含有清洁技术元素的全栈公司向真实市场出售真实产品时，这是可行的，但纯粹为了自身目的的清洁技术并不奏效。因为它无法满足消费者需求。伟大的商业皆以满足消费者需求为起点。伟大的使命性商业从由消费者需求定义的愿景开始，并包含有充分满足需求的任务。&lt;/span&gt;&lt;span&gt;一个具有社会使命却没有满足消费者需求愿景的组织最多是一个还算有效的慈善组织。伟大的商业把消费者需求放在第一位，而不是交叉的科技趋势，即使它是有使命感的。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;绿色能源不是一个市场，但能源是。太阳能由于经济化运作，成为了市场第一，并且快速增长。当巴菲特和马斯克就这一市场竞争时，很可能表明这是一桩好生意。双方都将可持续发展看作一项使命，但同时又理解只有将其看作一项生意并把消费者放在优先位置，这样才有意义。只有在满足消费者和被雇佣者需求的服务中，使命才能被完成。没有没一个带有可持续发展使命结果却没有持续的商业更讽刺的了。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;自我重视并拯救世界的心态。在清洁技术之中充斥着典型的自大自傲的技术狂热特点。在过去人工智能发展的两年中，我们开始看到自我扩张的人工智能伦理委员会，以及讨论机器取代所有工作我们怎么办等诸如此类的人们。正因为我们在致力于一项至关重要的事，在人工智能圈工作的人有责任去引领人类发展进程才是该有的态度。骄傲自大使人们看不到这个事实：他们深陷这样一个回声室，其中大家关心的是技术趋势而不是消费者需求和商业经济。正是这个有害的现实扭曲场力把很多聪明但自我感觉重要的人带进了即将发生的网络末日之中。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;清洁技术和人工智能都是深刻的技术问题。经常被消费互联网和琐碎的 SaaS 服务灌输思想的创业与风投社区逐渐难以评估深度技术领域内的投资机遇。在前文概述的自傲状态的驱使下，读了篇博文、听了几句只言片语之后就一头扎了进去。Linked 上的档案随机更新，一个临时专家的时代来临。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那么，这是如何发生的呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我有一个理论，经济的信息时代从根本上改变了我们在人类历史上经历的狂热-恐怖的循环周期。作为一个前对冲基金从业人员，我阅读了有关金融历史和市场心理学的所有名著。&lt;/span&gt;&lt;span&gt;探索事情是如何自 90 年代中期朝着不同方向进展很有趣。我认为社交活动和线上信息扩展的急剧增长创造了一种 self-heisenberging 效应，在商业周期还没开始之前就将其推到其面前。消费者互联网是一个巨大的例证，就在实体经济刚开始的时候，90 年代的预狂热导致了 2000 年的大崩盘。两年后的 2002 年，谷歌，一家注册于 1998 年的公司，在经济谷底期雇佣了所有的人才，并且定义了消费者互联网真实的商业周期。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在连线杂志宣布清洁科技死亡的 4 年里，太阳能一直是最环保最廉价的能源资源。马斯克和巴菲特都很热衷它。特斯拉和 Solar City 成为了一个全栈清洁技术帝国。因此我认为我们正处在对人工智能创业公司狂热的前夕。我看到的绝大多数正以人工智能创业公司 10 年来一直失败的同样方式走向失败。这是一个由有人工智能创业公司 10 余年经验的人组成的一个小社区。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这群处在狂热期前夕最顶端的人正在重蹈清洁技术之覆辙。他们眼里只有人工智能，而没有消费者需求。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在的人工智能创业公司绝大多数是钉钉子的锤子。在接下来的 1-2 年内这会变的越发明显。大公司精疲力竭，并减少了对人工智能人才的需求，就像他们对移动应用开发商所做的那样。我猜想我们开始看到创始人和风投者意识到一些东西在落幕。在这一点上，我将在 linkedin 上更少听到在过去的 1 年中决定加入人工智能创业公司的声音。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;MLaaS将陷入第二次停滞&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;将机器学习打造成一个服务是我们近十年来就一直在考虑的一个想法，然而这个想法却一直遭到挫折。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个想法之所以不管用，是因为知道机器学习在干什么的人只是在使用开源代码，而不知道的人怎么都做不到，即使使用 API。许多聪明的朋友都陷入了这种困境。一些人被大公司所获得来增强机器学习团队（IBM 的 Alchemy API、英特尔的 Saffron 、Salesforce 的 Metamind 等）。然而，建立 API 功能背后的机器学习模型所带来的热钱仍然吸引着大批开发者。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;亚马逊、谷歌和微软都试图通过出售 MLaaS 层作为他们云战略的一个组成部分。我还没有看到创业公司或大公司使用这些 API，但我看到了很多的人工智能应用，所以不太可能是因为我观察到的样本量太小的缘故。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;来自大型云服务提供商的服务，其结局会和创业公司的情况一样，因为今年他们的情况摇摆不定。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;云服务提供商会留下这些服务项目，但是不会再在这上面挣大钱，MLaaS 创业公司会在今年开始迎接末日，因为增长情况的摇摆不懂，也没有胃口再翻番了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里有一个 Lvery 实践问题； MLaaS 解决方案没有客户细分&amp;mdash;&amp;mdash;他们既为有能力（机器学习能力）的客户细分服务，也为没有机器学习能力的客户细分服务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;就匹配的细分来说：你需要机器学习人员帮忙打造真的产品机器学习模型，因为很好地训练和调试这些东西很难，而且，这也需要综合地了解理论和实践。这些机器学习人员趋于使用由 MLaaS 服务商提供的相同的开源工具。因此，这就淘汰了有机器学习能力的客户细分了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;没机器学习能力的客户细分：没有机器学习能力的细分客户不会通过使用 API 让机器学习运行。他们购买应用，解决更高层面的问题。机器学习不过是如何解决问题的一部分。在公司内部做机器学习的技术能力很难提上来，而且找到「数据产品」人才帮你找到问题并做出机器学习解决方案更难。没机器学习能力的客户细分包括科技公司之外，需要建立强大的机器学习与数据产品团队的任何公司。是的，这意味着全球所有的产业，是相当大的一个细分。如果你认同「software is eating the world」理论，那也就意味着全球所有的公司或多或少都会是科技公司。同样，也是数据公司。在顶级的科技公司与顶级的非科技公司之间已经有了很大的差距。在数据竞争力时代，这个差距会更大。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;全栈式垂直人工智能创业公司有发展&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在人工智能上，我已经干了 20 多年，其中有近 10 年是在硅谷创建人工智能初创公司。我是 DCVC（注重风险投资的人工智能与数据公司）的联合创始人，我的经历使我对全栈式垂直人工智能应用既激动又冷静的看待。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我激动是因为我认为每个产业都会被人工智能转变，冷静是因为低层的基于任务的人工智能能更快的商品化。我认为如果你并未解决足够高级的全栈式问题，你就会陷入低级人工智能服务的商品世界，最终由于缺乏动力而被收购或慢性死亡。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;垂直人工智能创业解决全栈式产业问题需要与主题相关的专业知识、独特的数据和使用人工智能传递其核心价值的产品。虽然大部分机器学习人才为消费型互联网巨头以及相关的科技公司工作，但大多数的问题都潜伏在科技产业外的主要产业中。如果你认同「software is eating the world」的假设，那每个产业中的每家公司都要变成科技公司了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;专注于垂直领域，你可以发现与人工智能非常吻合的高层级的消费需求，或者没有人工智能无法得到的新需求。这些都是极好的商业机遇，但需要极大的商业悟性和专业知识。一般而言，大部分人工智能创业者要么没有，要么意识不到，要么不够谦逊，把商业与专业知识的需求带入全栈之中（mov up the stack 或 go full stack)。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;新的全栈垂直人工智能创业公司突然出现在了金融服务、生命科学、医疗、能源&lt;/span&gt;&lt;span&gt;、交通、重工、农业、材料等领域。在拥有的数据、机器学习模型的支持下，这些创业公司将会解决高级别的领域内问题。2017 年至 2018 间，其中一些公司的会计收益率将达到 1 千万美元。这些全栈式人工智能创业公司可能会成为「清洁科技」领域的特斯拉和 Solar City。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;原文链接：http://www.bradfordcross.com/blog/2017/3/3/five-ai-startup-predictions-for-2017&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;span&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Sun, 05 Mar 2017 15:12:51 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 不要再提「人工智能」，因为今天的计算机系统一点儿都不特别</title>
      <link>http://www.iwgc.cn/link/95dd8f6aeea1116a6c7fbd88a49b68930a5a96cd</link>
      <description>
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自大西洋月刊&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：IAN BOGOST&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：微胖、晏奇&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote style="color: rgb(62, 62, 62); font-size: 16px; white-space: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/blockquote&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;「算法」这个词已经成为了一种文化崇拜，一种世俗的上帝祈求般的技术等价物。不加区别的使用这个术语将会错误的让那些既普通又有缺陷的软件服务变得让人崇拜。由此，所谓人工智能就变得和其它东西毫无差别。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在科幻作品中，人工智能可将来会威胁人类，这一想法与人类和有意识机器关系，密不可分。无论是《终结者》、《塞隆人》或者类似《星际迷航》中的机器人仆人还是《星球大战》中的机器人，当他们变得有情感&amp;mdash;&amp;mdash;或至少有了自我意识，能够根据专业知识行动时（更别提有了意志力和会吃惊）时，你就可以叫这台机器人工智能了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有些情况下，人工智能的设计或许是能对得起这一称呼，即使有一些愿望的成分在里面。比如自动驾驶汽车就不需按照 R2D2（或者 Hal）的标准来衡量，但是，他们确实使用了传感器、数据以及计算来执行复杂的驾驶任务。但是，绝大多数情况下，系统宣称人工智能并无情感，自我意识，也不会有意志力，或者吃惊。他们不过是软件。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能这一表述已经贬值了，例子随处可见。谷歌资助了一个在线识别「有毒」评论（toxic comments），这一款机器学习算法叫 Perspective。但是，结果呢，简单的输入错误都可以愚弄到这个系统。人们也将人工智能视为增强美国国立的屏障，但是，所谓的「屏障」不过是些传感器网络、潜在可疑嵌入性能分析的自动查询机。同样，所谓的「网球俱乐部人工智能（Tennis Club AI）」不过就是好一点的线传感器，使用了现有计算机视觉技术。Facebook 宣布使用人工智能防止自杀，但是，近距离观察一下，你会发现所谓的「人工智能识别（AI detection）」就比一个模式匹配过滤器多那么一丁点儿东西，可以为社区管理人员标记博文。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在技术领域之外，人们也庆祝着人工智能的奇迹。据报道，可口可乐也想使用「人工智能机器人程序」取代人类，进行「创意广告」。这意味这什么，我们还无从了解。类似的还有用人工智能来谱曲或者写故事，乍一看似乎有前途，但是接着，维基百科的机器人程序（修改输入错误和链接）最终在无限反馈回路中不断出错。根据人&amp;mdash;机器人程序交互咨询公司 Botanalytics 的分析，40% 的对话者仅一次互动后就都放弃的了对话机器人程序。或许是因为这些程序几乎都是那些漂亮的电话树（一款机器人程序的对话界面设计，在一个主题下，展开的故事，如下图&amp;mdash;&amp;mdash;译者）或者聪明的自动 Mad Libs（一款自动发推特的机器人程序&amp;mdash;&amp;mdash;译者。）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/ff5fba0ca205aad838c31ab63050d735f39ed6c3"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能也成为公司战略中的一种时尚。彭博情报经济学家 Michael McDonough 追踪了媒体文字记录中提及「人工智能」的情况，&lt;/span&gt;&lt;span&gt;请注意最近两年，曲线有一个大幅上升。公司吹嘘着还未敲定的人工智能方面的收购情况。2017 年德勤全球人力资源趋势报告中（超级链接，机器之心前几天报告了）中宣称人工智能已经「变革」人类工作和生活的方式，但是从未引用具体的资料。然而，报告总结说，人工智能正在迫使公司领导人「重新思考公司的某些核心架构。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/90c3e7a16cd0729c2e6d06d87bb4a6412ba6509c"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;媒体和流行话语有时会将一些简单的特点也夸大成人工智能的奇迹。上个月，比如，推特宣布提升服务，保护用户免受低质量和辱骂推文的困扰。这一变化不过做了点简单修改，隐藏来自被封、禁言、新的账号以及其他未描述内容过滤器的内容。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是，有些媒体将这些变化&amp;mdash;&amp;mdash;不过是在数据库查询中再加些条款而已&amp;mdash;&amp;mdash;总结为「推特一直在努力让它的人工智能更加智能。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我请我在佐治亚理工的同事&amp;mdash;&amp;mdash;人工智能研究专家 Charles Isbell 谈谈他是怎么看待「人工智能」的意思的。他的第一个回答是：「把计算机打造得像电影里表现的那样。」这听起来很炫，但是，它强调的是人工智能与认知理论以及科学间的本质联系。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;指挥官数据（Commander Data）提出了这样一个问题，具备从什么样的品质和能力才算有意识和道德&amp;mdash;&amp;mdash;当我们处理自动驾驶汽车的道德两难时。一个内容过滤器，尽管可以隐藏来自没有头像账户的博文，这可算不上智能。不过就是个软件。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Isbell 给出了一个系统可以被称为人工智能的两个必要特征。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先，系统必须不断学习以回应其所处环境中的变化。那些虚构的机器人和人机结合体都以神奇的方式在无形中具备了这种功能。但是，即便就像 Netflix 的动态优化器（Netflix's dynamic optimizer ）这样简单的机器学习系统（该系统试图改进压缩视频的质量）首先也要从人类收集的数据中学习，通过在这些数据上进行训练，算法才可能对视频传输做出识别和选择。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;什么才是真的人工智能？Isbell 的第二条建议是：人工智能应该掌握那些足够有趣的、但人类学习却要花费功夫的事情。这一点区分开了单纯的自动计算系统和人工智能。一个可以代替人类工人组装汽车的机器人并不配称为人工智能，同样，那些被编程执行重复操作的机器也都是如此。对 Isbell 来说，「真正」的人工智能需要计算机程序或者机器展现出自我管理、让人吃惊和新奇的东西。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;真正的人工智能提醒了其创造者和用户一条根本真理：今天的计算机系统一点都不特别。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;抱怨人工智能这一表述的贬值，或许看起来并不重要。如果传感器驱动、数据支持的机器学习系统蓄势待发，那么，人类或许能很好地跟踪这些技术的演化轨迹。但是，先前的经验已经表明，计算优势需要监管。我早就强调说「算法」这个词已经成为了一种文化崇拜，一种世俗的上帝祈求般的技术等价物。不加区别的使用这个术语将会错误的让那些既普通又有缺陷的软件服务变得让人崇拜。由此，所谓人工智能就变得和其它东西毫无差别。就像机器人作家 Allison Parrish 说的那样：「不管什么时候提到人工智能，人们其实都是在讨论『一台人写好程序的计算机』。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;斯坦福大学计算机科学家 Jerry Kaplan 在麻省理工科技评论（MIT Technology Review）也表达过类似的主张：人工智能只是一个虚构（fable），它是「从一个混合完全不相关工具和技术的袋子中粗制滥造出来的。」人工智能研究社区似乎也赞同这一观点，他们将自己的研究领域形容为「碎片化且很大程度上不协调。」考虑到人工智能实践中的不连贯性，Kaplan 建议将「类人计算（anthropic computing）」作为一种替代方案&amp;mdash;&amp;mdash;程序意味着运行起来像人类或者可与人类互动。对 Kaplan 来说，人工智能的神秘神话本质（包括小说、电影和电视中的一系列集合）让这个术语成为了一个应该抛弃的可怕妖怪，而不是一个欲求的未来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大约 70 年前，当数学家阿兰&amp;middot;图灵偶然间发明了机器智能思想时，他提出了测试机器是否具有智能的标准，即当机器可以成功让人类误以为它们是人而非机器（这个测试被称为「图灵测试」）。当时还是 1950 年代，这个想法看起来还不太可能实现；虽然图灵的思想实验并没有受到计算机的限制，但是，就为了执行一些简单计算，计算机器还是大到占用了整个房间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是今天，计算机已经可以到处欺骗人类了。这不是说它们可以成功模仿人类的行为，而是计算机已足以让人相信：它们是人类劳动工具的很好替代者。Twitter 和 Facebook 还有 Google 并不是「更好」的市政大厅、邻里中心、图书馆或者是新闻报刊&amp;mdash;&amp;mdash;它们和上述各种都不一样，它们由计算机驱动，可以更好亦可更糟。这些应用和其它的服务必须被理解为一种公司中特殊的软件应用，而不应被当作那种超现实的人工智能图腾来崇拜。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这方面，Kaplan 可能是对的：放弃这个术语也许是消除其在当代文化中恶魔般形象的最好办法。不过，Isbell 的更为传统的想法也有好处，他认为，人工智能是一种机器，可以学习并依照所学内容行动起来。通过保护好人工智能在科幻传统中的高贵形象，人工智能还能提醒其创造者以及用户一个根本真理：今天的计算机系统一点也不特别。他们不过人造的部件，运行着人类编好的程序，充满了人类和机器的技能与缺陷。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;原文链接：https://www.theatlantic.com/technology/archive/2017/03/what-is-artificial-intelligence/518547/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;span&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;
</description>
      <pubDate>Sun, 05 Mar 2017 15:12:51 +0800</pubDate>
    </item>
    <item>
      <title>演讲 | Youichiro Miyake：数字游戏世界中角色的觉醒与意识</title>
      <link>http://www.iwgc.cn/link/9340b894db5ba99ee6be0bf09214ac691b79b7ca</link>
      <description>
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Joni&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;编译参与：马亚雄、黄小天&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote style="color: rgb(62, 62, 62); font-size: 16px; white-space: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;2 月 16 日，星期四，我参加了在东京举办的第五届意识俱乐部 (consciousness club)。这是一个由 Araya 脑成像公司 (Araya Brain Imaging) 的 CEO Ryota Kanai 博士组织的每周活动，这次的演讲嘉宾是 Youichiro Miyake。他是一个因为在游戏人工智能（Game AI）方面的工作而闻名的设计师，曾提出在游戏人工智能和其他先进系统中创造人工意识的初始概念。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以下是 Youichiro Miyake 的演讲摘要：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;视频游戏中的角色处在具有许多物体、复杂环境以及其他角色的 3D 环境中。自从家庭计算机 (FC) 和超级家庭计算机 (NES 1983、SNES 1990、以及任天堂) 时代以来，游戏角色是受游戏设计师所写的脚本程序控制的，这使得游戏角色成为游戏中的演员。这被称为「脚本化人工智能 (scripted AI)」。然而，随着游戏关卡设计变得越来越复杂，脚本化人工智能的方法已经不能适应这么复杂的情况了。3D 游戏的一个转折点是索尼互动娱乐 (SIE) 公司在 1994 年推出的 PlayStation。在拥有 3D 环境的游戏中，需要采用人工智能技术来建立深层次的游戏角色的人工智能。在 3D 的层面，游戏角色将是具有自主性角色，使其能够感知游戏世界的许多不同方面，做出决策，并且依靠自身采取实时的行动。游戏角色解决了它周围的本地问题，发挥了作用。游戏角色不仅感知周围的环境，还要感受它的身体和心灵。因而，游戏角色的意识模型在游戏行业中已经被研究了多年。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这一研究的历史从 2000 年麻省理工媒体实验室性格合成组 (MIT,Media Lab, Synthetic Group) 的心理模型 (Mind Model) 开始。这个模型已经在许多不同主题的游戏角色中经历了多次演化。游戏角色的 AI 基础就是机器人的代理结构。它包括三个部分：认知模块、决策模块以及行动模块。随着信息流入一个角色的心灵，它们被分析转化成 AI 结构中的新知识。通过使用这些知识，决策模块做出决策，行动模块形成角色的动作以执行这个决策。结合环境和人工智能代理 (agent)，这个循环就形成了角色的心灵活动。通过这些模块的流动和改变之后，信息就被存储在了记忆中，因此角色的人工智能就被描述成了类似于信息的化学反应一样的东西。数字游戏是测试意识模型的合适领域。许多关于意识的模型已经被提出和在试验当中。在本次研讨会中，介绍了一些很多游戏角色意识模型及其结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;演讲人简介&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Youichiro Miyake 在参与视频游戏主题开发的同时，还作为主要研究人员在 Square Enix（一家游戏开发公司）进行游戏人工智能技术的研究。他为很多游戏项目设计并开发了人工智能。他在大学和游戏开发者会议上做过很多次讲座。此外，他是人工智能特殊利益集团 (SIGAI) 在国际游戏开发商协会 (IGDA) 日本分会的主席。他也是日本数字游戏研究协会和科学艺术协会的董事。他在 2016 年出版了 3 本日语专著：「人工智能的哲学故事 (Stories on Philosophy for Artificial Intelligence)」，「人工智能图画书 (Artificial Intelligence pictures book)」以及「制作游戏人工智能的方法 (Making a game AI method)」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;游戏及其他人工智能系统的设计哲学&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关于人工智能的演讲话题是基于最终幻想 15（FFXV）的设计示例展开的，但是读者可以参考其他游戏系统。首先，Miyake 在游戏系统中介绍了人工智能的一般设计理念。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;第一个问题：人工智能在游戏中意味着什么？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他定义了游戏中的人工智能就是通过角色的身体区感知来自环境的反馈，并通过游戏环境互动控制运动。通过这种方式，环境和角色的身体形成了一个反馈回路 (如下图所示)。从这一点讲，它和体现智能的具身性观点是类似的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/ec7e0a749f620adcca45dd39427cb1b804b1ed5f"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这就是为什么说随着 3D 游戏的发展，其中的人工智能系统较之于 2D 游戏而言，也发生了很大的变化的原因。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最终幻想 15(FF XV) 中的人工智能系统有三个子部分。我们将逐个作介绍：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 元人工智能&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 角色人工智能&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 导航人工智能&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/3dc0ea8bb6373447e1308590db0bbb4363731de9"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;元人工智能&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在之前没有元人工智能的游戏系统中，从根本上来说，代理 (agent) 上实现的单个的人工智能与通用游戏策略之间最大的问题，就是每一个角色的行动是由人工智能图形编辑器 (AI Graph Editor) 在意识到每个情形和周围环境，并考虑了下一步应该做什么之后自动决定的。然而，基于设计通用策略时的情况，角色有时候因为一个特定的事件需要集合在一起，或者需要以协作的方式执行一个特殊的行动。在这种情况下，需要一个通用的指挥者。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此，最终幻想 15(FF XV) 中开发了统治游戏环境和进展的元人工智能 (Meta AI)。它就像整个人工智能系统的指挥者一样控制着为敌人和非玩家角色 (NPCs) 设计的通用策略。元人工智能 (Mata AI) 的一个重要任务就是以一个集中的方式去协调代理 (agent) 的策略。因此它限制了团队成员与玩家之间的许多互助。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;分配给元人工智能 (Meta-AI) 的任务是很多很广的，所以它的策略由分离的互联元素组成的不同状态 (level) 控制，这些分离的互联元素包括实现任务管理的分层结构，过渡并合并一些功能以创建智能系统，以及具体区域的不同元素之间的交流。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在最终幻想 15 中，这些状态包括：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;地图和角色的位置&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;事件定位，管理&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;游戏均衡设置&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/5520ec702d4a87735aa323daac9068b17328ece9"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如图所示，根据计算求出理想情况下敌人的数量，玩家的强度以及实际出现的敌人数量，这些是关键参数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;具体分为四个状态：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;积累 (build up):让敌人一直出现，直到超过玩家紧张度的目标值；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;维持峰值 (sustain peak):为了让玩家的紧张度维持 3 到 5 秒，维持敌人的数量；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;峰值衰减 (peak fade):把敌人的数目朝着最小限度减少；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;放松 (relax):维持最小数量的敌人数目 30 到 45 秒，以让玩家放松。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;一个游戏人工智能的例子&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;状态机表示元人工智能是如何控制敌人数量和刷新频率的。元人工智能对敌人数量的控制分为四个状态：积累 (build up)，维持峰值 (sustain peak)，峰值衰减 (peak fade)，以及放松 (relax)。状态变化的输入参数可能包括玩家杀死的敌人数量、玩家的位置和时间间隔等。所以，从玩家的角度来看，貌似敌人每隔一段时间就会出现，并且敌人的强度与玩家的作战能力、游戏难度也有关系。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;角色人工智能&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;角色人工智能 (character AI) 控制着访客和非玩家角色 (NPCs) 的个体策略。对于角色人工智能 (Character AI) 而言，一个主要的任务就是在响应不同情况的时候在人工智能和角色之间进行协调。从主要团体成员到各地的非玩家角色，最终幻想 15(FF XV) 中的不同组别的非玩家角色都有不同水平和风格的人工智能。角色人工智能所做的基本上可解决每一个代理的决策问题。有不同的模型可以解决这个问题，但对于角色人工智能，在游戏设计界有如下 7 个简单的算法：基于规则的人工智能，基于状态的人工智能，基于行为的人工智能，基于目标的人工智能，基于任务的人工智能，基于效率的人工智能，以及基于模拟的人工智能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/434d7907f6f21e8b6921750bfb502c9bc3289727"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在最终幻想 15(FF XV ) 中，我们利用了两种开发角色人工智能的方式：开发人员利用两种针对人工智能的标准「经典」设计作为参考：围绕适应和决策的行为模型，和基于环境决策的状态模型。这个最终幻想 15(FF XV) 的人工智能系统由自开发的「人工智能图」系统实现，它表示一个人工智能的多层结构。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;角色人工智能是一种结合行为树和状态机的混合方法。其中状态机负责协调一般状态的转换，行为树指定特定情况下的每种行为。所以，最终幻想 15(FF XV) 中的角色人工智能是以层状托盘的方式形成的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;包含一个行为树和状态机的混合模型&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;一组结点以托盘的形式被管理&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;分层的结构&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/01b305bc0ead33f5221683cdb18d81d7a16cff13"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在混合模型中，状态机的状态是由关卡设计者考虑的动作，以使玩家运用通用术语来命令人工智能。它还由在运动单位中设置的行为树模式组成。例如，如果角色选择战斗，它会有几种行为可供选择：&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;移动：移动到指定位置&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;引导：指导玩家&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;袭击：袭击敌人&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;空闲：让角色处于空闲状态&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在游戏中，关卡设计师只需考虑一些命令，切换到所需的模式，其余的可交由人工智能轻松处理。此外，在这些角色人工智能系统中，被期望的元素不仅是关卡设计者对人工智能动作改变的容易性和灵活性，而且还要允许人工智能规划者有效地对每个人工智能角色进行编辑以及做出动作。在大规模的最终幻想 15(FF XV) 世界中移动的所有角色都在人工智能上运行。他们希望的是一个真正让他们有效地制作这些不同种类人工智能的系统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;导航人工智能&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，导航人工智能决定诸如角色和敌人这类移动元素的最佳路线和模式。最终幻想 15 中导航人工智能系统的两大主要元素是点查询系统 (PQS) 和转向系统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;点查询系统 (PQS) 建立路径的方法是这样的：它在一些重要点周围构建点阵，并且围绕一些特定情况滤除一些点，以使得代理能够被引向最佳点的路径。PQS 主要涉及对人工对手的控制以便遵循跑道上的最佳路径，并且可以并入更高级别的计划以便成功地导航这一过程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如下图所示是点查询系统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/3cf0e8a2cd2449eb1cbef657a2b7b9696a6ff3e3"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;转向系统根据感知引导运动。例如，合适的非玩家角色 (NPC) 经常需要避开障碍物的能力。导航期间的一个转向行为允许代理 (agent) 向前看，跟随目标并避开障碍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;结论&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，为了与意识俱乐部的主要目标保持一致，Miyake 也表示他愿意在游戏人工智能系统中开发人工意识。并且，他还支持这样的观点，随着游戏环境和角色的发展，将来可能需要更复杂的人工智能系统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;一些想法：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;作为一个早期的游戏迷和现在的人工智能研究员，我确实从这个演讲中感到一点惊讶，一个包含着简单但是优雅的规则的精密人工智能系统如何发展成一个复杂的游戏中。你可以从前面的几张图片推断，实际上最终幻想 15(FF XV) 的游戏人工智能并没有涉及复杂的机器学习。例如，也许敌人的强弱是由你杀死的人来决定的，但实际上这是预先定义好的。我认为这与一个事实有关：当下游戏平台是如此的受限，以至于根本就没有必要去学习复杂的场景和对象。在我看来，以下的方向可能学术界和产业界都比较感兴趣：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 设计不同水平的游戏人工智能会让开发人员付出很多努力。那么，能否像现在的游戏引擎一样，设计一个通用游戏人工智能系统能达到重用的效果？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 有没有必要在游戏人工智能系统中实现当前的一些机器学习技术？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&amp;copy;本文为机器之心原创，&lt;strong&gt;&lt;span&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Sun, 05 Mar 2017 15:12:51 +0800</pubDate>
    </item>
    <item>
      <title>学界 | 最小二乘GAN：比常规GAN更稳定，比WGAN收敛更迅速</title>
      <link>http://www.iwgc.cn/link/f04b79b36571c4b025c3f346bb00a2ef6ac1621c</link>
      <description>
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自Github&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：蒋思源&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote style="color: rgb(62, 62, 62); font-size: 16px; white-space: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/blockquote&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;近来 GAN 证明是十分强大的。因为当真实数据的概率分布不可算时，传统生成模型无法直接应用，而 GAN 能以对抗的性质逼近概率分布。但其也有很大的限制，因为函数饱和过快，当判别器越好时，生成器的消失也就越严重。所以不论是 WGAN 还是本文中的 LSGAN 都是试图使用不同的距离度量，从而构建一个不仅稳定，同时还收敛迅速的生成对抗网络。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;项目地址：http://wiseodd.github.io/techblog/2017/03/02/least-squares-gan/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由于生成对抗网络训练的一般框架 F-GAN 已经构建了起来，最近我们可以看到一些并不像常规 GAN 的修订版生成对抗网络，它们会学习使用其它度量方法，而不只是 Jensen-Shannon 散度 (Jensen-Shannon divergence/JSD)。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中一个修订版就是 Wasserstein 生成对抗网络（WGAN），该生成网络使用 Wasserstein 距离度量而不是 JSD。Wasserstein GAN 运行十分流畅，甚至其作者都声称该系统已经克服了模型崩溃难题并给生成对抗提供了十分强大的损失函数。尽管 Wasserstein GAN 的实现是很直接的，但在 WGAN 背后的理论是十分困难并需要一些如权重剪枝（weight clipping）等「hack」知识。另外 WGAN 的训练过程和收敛都要比常规 GAN 要慢一点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在，问题是：我们能设计一个比 WGAN 运行得更稳定、收敛更快速、流程更简单更直接的生成对抗网络吗？我们的答案是肯定的！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;最小二乘生成对抗网络&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;LSGAN 的主要思想就是在辨别器 D 中使用更加平滑和非饱和（non-saturating）梯度的损失函数。我们想要辨别器（discriminator）D 将生成器（generator）G 所生成的数据「拖」到真实数据流形（data manifold）Pdata(X)，从而使得生成器 G 生成类似 Pdata(X) 的数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们知道在常规 GAN 中，辨别器使用的是对数损失（log loss.）。而对数损失的决策边界就如下图所示：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/be15e1b540f0dcd3869ffb9fc3a949b76fdd73ee"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因为辨别器 D 使用的是 sigmoid 函数，并且由于 sigmoid 函数饱和得十分迅速，所以即使是十分小的数据点 x，该函数也会迅速忽略 x 到决策边界 w 的距离。这也就意味着 sigmoid 函数本质上不会惩罚远离 w 的 x。这也就说明我们满足于将 x 标注正确，因此随着 x 变得越来越大，辨别器 D 的梯度就会很快地下降到 0。因此对数损失并不关心距离，它仅仅关注于是否正确分类。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了学习 Pdata(X) 的流形（manifold），对数损失（log loss）就不再有效了。由于生成器 G 是使用辨别器 D 的梯度进行训练的，那么如果辨别器的梯度很快就饱和到 0，生成器 G 就不能获取足够学习 Pdata(X) 所需要的信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;输入 L2 损失（L2 loss）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/446384472b13cc6949d5294dc8dae8abadf85e5f"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 L2 损失（L2 loss）中，与 w（即上例图中 Pdata(X) 的回归线）相当远的数据将会获得与距离成比例的惩罚。因此梯度就只有在 w 完全拟合所有数据 x 的情况下才为 0。如果生成器 G 没有没有捕获数据流形（data manifold），那么这将能确保辨别器 D 服从多信息梯度（informative gradients）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在优化过程中，辨别器 D 的 L2 损失想要减小的唯一方法就是使得生成器 G 生成的 x 尽可能地接近 w。只有这样，生成器 G 才能学会匹配 Pdata(X)。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最小二乘生成对抗网络（LSGAN）的整体训练目标可以用以下方程式表达：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/1ba7d180853cc09e2c32bd64923651df3bf6e2bf"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在上面方程式中，我们选择 b=1 表明它为真实的数据，a=0 表明其为伪造数据。最后 c=1 表明我们想欺骗辨别器 D。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是这些值并不是唯一有效的值。LSGAN 作者提供了一些优化上述损失的理论，即如果 b-c=1 并且 b-a=2，那么优化上述损失就等同于最小化 Pearson &amp;chi;^2 散度（Pearson &amp;chi;^2 divergence）。因此，选择 a=-1、b=1 和 c=0 也是同样有效的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们最终的训练目标就是以下方程式所表达的：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/13de29cacf719030bf966c00acf7226b4c1c6dbb"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;在 Pytorch 中 LSGAN 的实现&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;先将我们对常规生成对抗网络的修订给写出来：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 从辨别器 D 中移除对数损失&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 使用 L2 损失代替对数损失&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以现在先让我们从第一个检查表（checklist）开始&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;G = torch.nn.Sequential(&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;torch.nn.Linear(z_dim, h_dim),&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;torch.nn.ReLU(),&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;torch.nn.Linear(h_dim, X_dim),&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;torch.nn.Sigmoid()&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;)&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;D = torch.nn.Sequential(&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;torch.nn.Linear(X_dim, h_dim),&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;torch.nn.ReLU(),&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;# No sigmoid&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;torch.nn.Linear(h_dim, 1),&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;)&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;G_solver = optim.Adam(G.parameters(), lr=lr)&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;D_solver = optim.Adam(D.parameters(), lr=lr)&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;剩下的就十分简单直接了，跟着上面的损失函数做就行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;for it in range(1000000):&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;# Sample data&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;z = Variable(torch.randn(mb_size, z_dim))&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;X, _ = mnist.train.next_batch(mb_size)&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;X = Variable(torch.from_numpy(X))&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;# Dicriminator&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;G_sample = G(z)&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;D_real = D(X)&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;D_fake = D(G_sample)&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;# Discriminator loss&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;D_loss = 0.5 * (torch.mean((D_real - 1)**2) + torch.mean(D_fake**2))&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;D_loss.backward()&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;D_solver.step()&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;reset_grad()&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;# Generator&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;G_sample = G(z)&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;D_fake = D(G_sample)&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;# Generator loss&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;G_loss = 0.5 * torch.mean((D_fake - 1)**2)&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;G_loss.backward()&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;G_solver.step()&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;reset_grad()&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;完整的代码可以在此获得：https://github.com/wiseodd/generative-models&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;结语&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;br&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这篇文章中，我们了解到通过使用 L2 损失（L2 loss）而不是对数损失（log loss）修订常规生成对抗网络而构造成新型生成对抗网络 LSGAN。我们不仅直观地了解到为什么 L2 损失将能帮助 GAN 学习数据流形（data manifold），同时还直观地理解了为什么 GAN 使用对数损失是不能进行有效地学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，我们还在 Pytorch 上对 LSGAN 做了一个实现。我们发现 LSGAN 的实现非常简单，基本上只有两段代码需要改变。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;论文：Least Squares Generative Adversarial Networks&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;论文地址：https://arxiv.org/abs/1611.04076&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：最近应用生成对抗网络（generative adversarial networks/GAN）的无监督学习被证明是十分成功且有效的。常规生成对抗网络假定作为分类器的辨别器是使用 sigmoid 交叉熵损失函数（sigmoid cross entropy loss function）。然而这种损失函数可能在学习过程中导致导致梯度消失（vanishing gradient）问题。为了克服这一困难，我们提出了最小二乘生成对抗网络（Least Squares Generative Adversarial Networks/LSGANs），该生成对抗网络的辨别器（discriminator）采用最小平方损失函数（least squares loss function）。我们也表明 LSGAN 的最小化目标函数（bjective function）服从最小化 Pearson X^2 divergence。LSGAN 比常规生成对抗网络有两个好处。首先 LSGAN 能够比常规生成对抗网络生成更加高质量的图片。其次 LSGAN 在学习过程中更加地稳定。我们在五个事件数据集（scene datasets）和实验结果上进行评估，结果证明由 LSGAN 生成的图像看起来比由常规 GAN 生成的图像更加真实一些。我们还对 LSGAN 和常规 GAN 进行了两个比较实验，其证明了 LSGAN 的稳定性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;参考文献：&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;1. Nowozin, Sebastian, Botond Cseke, and Ryota Tomioka.「f-GAN: Training generative neural samplers using variational divergence minimization.」Advances in Neural Information Processing Systems. 2016. arxiv (https://arxiv.org/abs/1606.00709)&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;2. Mao, Xudong, et al.「Multi-class Generative Adversarial Networks with the L2 Loss Function.」arXiv preprint arXiv:1611.04076 (2016).&amp;nbsp;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;span&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Sun, 05 Mar 2017 15:12:51 +0800</pubDate>
    </item>
    <item>
      <title>阿里iDST视觉计算负责人华先胜：算法的红利正在消失</title>
      <link>http://www.iwgc.cn/link/f8b4fef44ba9488a6eff8d7edccfd1505d83f2cb</link>
      <description>
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：刘燕&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote style="color: rgb(62, 62, 62); font-size: 16px; white-space: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;「我越来越明确自己的兴趣点&amp;mdash;&amp;mdash;把技术研究与现实世界里的问题结合起来，去解决真正的问题、创造价值。」阿里云视觉计算团队负责人华先胜说。华先胜是视觉识别和搜索领域的国际级权威学者，曾被评为 IEEE Fellow、ACM2015 年度杰出科学家、MIT TR 全球 35 位 35 岁以下的杰出青年创新人物，曾担任 ACM Multimedia 等大会程序委员会主席。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;2015 年，华先胜离开职业的起点微软研究院，选择加入阿里巴巴。这在很多人眼里是一个不容易理解的选择，但在华先胜看来，理论研究有价值，但把这些技术放在一个切实的应用场景中让更多人使用同样有意义。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;在阿里巴巴的第一年，华先胜负责电商图片搜索技术的优化，推动了手机淘宝、天猫中的「拍立淘」的技术开发，让用户通过手机拍摄物品照片搜索相同或者相似的商品，这正在成为一种更为高效的商品搜索方式。有数据显示，2015 年双 11 当天，千万消费者使用「拍立淘」功能，达成了超过数千万元的销售额。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;随着云上的视觉计算需求量越来越大，2016 年初，华先胜转入阿里云并创立视觉计算团队，目前该团队隶属于人工智能研究机构 iDST 团队。2 月 27 日，机器之心对华先胜进行了独家访谈，他介绍了视觉计算团队所推动的研究进展与突破，以及他对AI行业发展的看法。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;视觉计算团队实现了哪些突破&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;机器之心：能否和我们分享一下，您带领的阿里云视觉计算团队的工作有哪些突破性进展？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;华先胜&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：视觉计算团队成立以后就针对几个大的场景，包括监控、交通、安防、人脸、个人图片、医疗等，其中最重要的一部分实际上是城市大脑里面的视频分析，这里面的突破，我觉得可以分为几个方面：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一是大规模视频分析，我们处理的城市数据量非常大，甚至远远超过电商的数据，这里面涉及到我们要去实时处理分析大规模的视频，所以要依靠阿里云高效力计算平台，构建一套大规模视频数据分析平台；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二是把电商的图像搜索技术，延伸到城市场景里面来，叫做城市图搜或者叫城市搜索，专业一点的语言甚至可以叫索引整个城市，城市视频数据图像数据那么多，当然会有查找的问题，比如一辆车、一个人、一个物等，这跟电商有相似之处也有不同，从视觉角度来做的，这其实也是非常困难的事；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第三是我们可以对城市里面发生的，交通事故、违章停车、横穿马路等特殊交通事件进行检测和识别。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;机器之心：视觉计算团队在研究方向上会有明确的侧重点吗？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;华先胜&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：一方面，要确保在云计算上进行大规模的视频分析必须充分可行，必须不断进行算法的优化。另一点就是继续深入行业，在各行各业去挖掘金矿，让算法在里面能够得到优化，把一个个行业吃透，为客户带来真正的价值。当然还有像深度学习本身算法的研究还是有很大的空间，这也是我们接下来要做的事情。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;机器之心：城市大脑是您所在团队的一个重要项目，除了城市道路的管理、路况预测、交通调度的优化，它还有其他方面的应用方向吗？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;华先胜&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：目前城市大脑以交通方面的应用为主，包括路况检测识别和交通优化等。城市大脑既然是「大脑」，当然应该有更多的功用，包括安防，城市规划，环保，旅游等等。安全防护方面，如上所述，对人、机动车、非机动车等的实时索引，可以提升城市的安全防控能力；还有对一些异常事件，例如塌方、水淹、漏水、交通事故等等，能够快速警报，这个时候，能争取 1 分钟提前警报都会有很大的价值，例如，可能因此而挽救一个人的生命。&lt;/span&gt;&lt;span&gt;当然，很多技术还在研究迭代当中。另一方面，除了城市摄像头的数据，还有卫星数据、无人机数据等等，对城市的规划、环保等等也能起到检测作用。总体来说，就像是整个城市的一个眼睛，其实不是一个眼睛，像是复眼一样，而且不仅仅是看，还要理解识别，要看全、看清、看透，并作出相应决策。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;机器之心：高效准确地对路况进行仿真预测是破解交通问题的难点，可否具体介绍一下这里应用了怎样的算法去进行实时交通预测？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;华先胜：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我们首先要对整个城市及其交通状况有一个全面、清晰、透彻的了解。要看全，因为城市的摄像头非常多，看全就涉及到刚才讲的大规模视频处理，也包括以前在交通领域里还无法获取的信息，比如行人的信息，过去的交通模型里面其实是没有办法使用的，因为没有办法获取信息，车辆的信息还可以通过其他手段得到一部分，比如说通过地面上的感应线圈也可以得到，当然这个是比较粗一点，车的类型是没办法知道的。第二是通过 GPS 采样信息，但是也不够完整，视频的信息是可以看得非常完整，看到整个车流和人流。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;看得清晰，在技术上来讲，是要看到到底有多少车经过，车的类型是什么，车牌是什么，走到哪里去，左转右转还是直行，速度是多少等，也包括到底多少行人在占用人行横道等，这些对交通的优化都是非常重要的信息，也是过去无法获取的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从看得透彻的角度来讲，实际上是挖掘大量数据之间的关系，从而发现这个规律，或者说发现他们之间的相互制约性，从而得出决策。举个例子，比如说在交通的优化当中，我要优化红绿灯，我不能只看这一个路口的信息，要看很多的路口，因为你如果把这一个路口解决了，有可能反而造成别的路口更加拥堵。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有了这样三个层次的了解之后，才是交通模型。作为我们云计算公司来说，是要在更大规模、更准确的数据状况下，尤其是视觉数据，再加上交通专家的研究成果、交管部门实际经验，我们一起来解决交通的建模和优化问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;机器之心：在遇到交通事故或是拥堵问题时，利用什么评价指标体系来推演获取最佳的解决策略？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;华先胜：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;通常来说，我们看到车流情况以后，其实就可以对红绿灯进行优化了。做离线的优化，是根据每天的规律，或者每周长时间的规律，对红绿灯做一次性离线的优化，以及配时方案，星期一早上几点到几点是什么样子，中午、晚上是什么样子，星期二是什么样子，每天不一样的方案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对交通事故的应对需要实时调控，这里也分两类，一种是已经堵起来，还没有堵死的时候已经看到这个趋势，可以对红绿灯进行管控，一个方向时间延长，另外一个方向减少时间等，这是对红绿灯的调控。更聪明的一点做法，我们如果观察到一些事故发生，就对它的规模、可能带来的交通问题做一个大概的估计，提前做出疏导预案，这是可以做到的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;机器之心：能否为我们详细介绍一下，城市大脑项目中的实时和离线这两个视觉计算平台中的关键技术点和数据规模？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;华先胜&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：这是很好的问题。阿里云的计算平台，叫做飞天系统，你可以把它看作是一个超级的计算机。飞天的离线计算和实时计算，这一套系统有 100 万个 CPU 的核，这个是相当大的数量了。有 60 万块硬盘，有一个 EB 的能力，这个 EB 是 1024 个 PB，一个 PB 是 1024 个 TB，一个 TB 是 1024 个 GB，这个量是非常得大的。视频分析背后依靠的就是这样一个大规模的这样一个计算的能力，必须有这样的能力在里面，才能够完得成这些复杂的大量的计算。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于视频而言，当然我们在这里面也会有一点特殊的地方，因为视频处理有它的特点，比如说数据量大、吞吐量大、计算消耗也非常大。我们在这个基础上，跟计算平台一起，让计算平台能够处理这些视频数据。用比喻来说，就是它能吃得进去，消化得了，并把这个营养吸收得了，最终产生结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但这里面的视频处理有特殊性：视频处理有时间上的相关性。比如说我们对某一当前时刻图像进行处理的时候，是依赖于前面的若干时刻图像的，所以在视频里面要很方便地处理这种逻辑。再比如说像交通的场景下，甚至是我当前的视频需要跟别的好几路视频合在一起才能形成一个决策，比如说像红绿灯的管控，我光看一个路口的一路肯定是不行的，甚至光看一个路口的四路也不行的，我要看好几个路口一起来决策，这就是在物理的空间上也是有相关性，我经常把这叫做「时空的相关性」。在这种情况下能够顺利完成计算，从而实时得出决策，这都是通过平台才能达到的。对于算法专家来说，更多的精力是放在算法的研发上，提升算法准确性和本身的计算效率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;机器之心：在离线和实时处理过程中，如果要达到理想的识别精度，比如道路车辆信息、路况信息等，需要多大规模的训练样本库？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;华先胜&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：这个是 case by case 的，对于简单一些的问题，要识别的目标特异性明显，和其他目标和背景的差异性大，就不需要太多的样本。当然，实际应用环境中的情况往往比较复杂，识别模型往往需要到实际应用中迭代优化。离线和实时处理是模型训练好之后的生产环境，不是训练环境。当然，模型的在线更新是和离线、实时处理系统在一起的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;机器之心：深度学习落地产业应用是近年来的发展趋势，计算速度也是衡量算法能否落地的一个重要性能。我们注意到，这个项目中计算速度的提升效果是非常惊人，单核 CPU 对单帧图片处理速度可以从 998ms 提升至 135ms，可否为我们介绍一下基于 Intel 的 MKL 加速以及在优化深度学习模型方面做了哪些努力吗？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;华先胜：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;其实我们最初的模型在 CPU 上的处理需花费 2600 毫秒，这个其实是相当慢的。后来我们跟英特尔合作，利用英特尔的 CPU 上的优化，在单核上压缩到 900 多毫秒。后来我们再通过算法本身的优化，包括模型的结构优化，参数的优化等等，就降低到 130 多毫秒，这又提升了很多倍，整个提升了十几倍。这十几倍的提升，听起来可能没什么感觉，但对于大量的计算资源来讲是非常重要的。如果你只要一台、两台机器做事情，还不是太大的问题，假如你要 1 万台、2 万台机器同时运行，那就是一个很大的事情了。这个量的相差是非常非常多的。所以大规模计算的效率也是非常重要的方向。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;机器之心：深度学习计算加速技术的实际应用中，您认为哪一种是更符合工业界需求：GPU (M4) 加速，CPU (Intel MKL) 加速 或者 FPGA 加速？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;华先胜&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：各有千秋吧，当然仅结合 CPU 的特性来优化还是很有挑战的。技术上，FPGA 当然要复杂一些，但成本上应该更优一些。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;机器之心：人脸技术作为计算机视觉中较为重要的课题，阿里云的人脸识别技术在服务端和手机端分别达到了 99.53%、98.93% 的准确率，能否分享一下这背后的人脸识别技术及算法革新？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;华先胜&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：识别技术上和其他公司并没有关键的区别，但有一些其他方面的创新应用可以讲（例如 3D 试戴、试衣、试妆等），准确率可以说和主流公司提供 comparable，方法上除了流行的方法外，借鉴了拍立淘中电商图像特征学习的经验。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;机器之心：人脸识别和图像识别技术的应用范围广泛，比如安全金融、智能审核以及图像编辑等，除了支撑阿里巴巴集团内部产品，是否也在推进与其他平台厂商的合作？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;华先胜&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：阿里云的视觉计算技术以对 B 端应用为主，当然也有to C 的。我们更多立足于用视觉智能解决各行各业的问题，过去不能解决或者必须人眼去看才能解决的问题，耗时耗力，变成简单高效。我们还着力打造生态，让第三方算法能够跑在阿里云的视觉计算平台上，为更多的客户、用户带来实在的价值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;机器之心：现在的人脸识别系统仍然主要依赖有标签数据的训练，但在特定的任务中特定群体（如刑侦或治安监控任务的小孩或青少年）的训练数据量不足导致了应用效果较差，以及图像质量不稳定或者目标有意的伪装都会影响识别。在未来的人脸识别中解决这些问题的方向是什么？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;华先胜&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：在金融场景，可以考虑用眼纹的方法，例如蚂蚁金服收购的 EyeVerify 公司的眼纹技术，进一步增强准确率。但确实很多监控场景中人脸的分辨率都不太高，或者成像质量不好。这种情况可以考虑用一下 context，例如人体特征、步态等。这种场景下，与金融场景中的人脸比对不同，对人或人脸的识别的要求是不一样的，并不要求（也做不到）很高的准确率，而是要很高的召回率，然后通过人工来进一步确认。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;机器之心：无论是在工业诊断方面还是在医疗图像领域，高精确度都是计算机视觉解决问题的前提条件，目前提升精确度的挑战是什么？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;华先胜&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：这种场景和典型的识别场景是不一样的，因为这类场景的目标通常是个小概率事件，正例的目标很少，而且有时正例之间的差异性还很大，甚至无法穷举。在这种情况下，高召回率是主要的目标，准确率是要被牺牲的目标。例如，10000 个样本，如果目标正样本很少，只有 10 个，如果算法测出来有 100 个，只要那是个证样本在这 100 个之内，召回率就是 100%；而这时的准确率只有 10%。然而，这已经是非常不错的结果了，因为我们只需要人工确认这 100 个样本就好了，而不需要看那 10000 个样本，人工省了 99%。所以这种应用，关键是召回，然后一步一步降低虚警，也就是提高准确率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;机器之心：针对仿真视频图像的生成，阿里云采用了什么样的方法？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;华先胜&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：这里有两种生成。一种是三维场景中的物体植入，这种场景是要做三维重建，寻找嵌入位置，然后将三维目标植入场景，随场景一起运动；另一种是平面图形的生成，只要用于生成以假乱真的某个特定类型的图像，方法是自主研发的基于 GAN（生成对抗网络）的方法，目前用于训练数据的大量自动合成。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;机器之心：简单谈谈阿里云的图像搜索技术有什么特点？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;华先胜&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：阿里的图像搜索技术有深厚的技术和实践积累，在电商中经过多年的精细打磨。目前我们正在将其应用到城市图搜的场景当中。一般而言，图像的索引（indexing）过程是图像搜索的关键，其中又包括了识别、目标检测、特征提取和索引建立，索引建得好不好直接关乎搜索结果排序 (ranking) 的质量（相关性）和搜索效率。识别、目标检测和特征又是索引质量的关键，基本上每一步都是通过深度学习来达成的，一步有问题都不能得到满意的结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;机器之心：计算机视觉是深度学习中第一个取得突破的领域，前面在静态图片上已经获得很大成功，在您看来，下一步的突破会在哪些方面？还要解决哪些关键性挑战？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;华先胜：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;确实，深度学习是在视觉、语音，包括自动翻译这方面有很好的应用，为什么在文本搜索上可能进展并没有那么明显？当然也有人觉得还没有做到足够深入，也有人讲是因为图像和语音，尤其是图像和语义之间的差距还很大，所以深度学习在里面能够起到很关键的作用。从视觉的角度来讲，我觉得还有很多问题去解决，深度学习本身算法的研究还是有很大的空间，这并不是所有的问题都做得很好了。模型这些年也不断的在演化，训练的策略都在不断的进步。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;还有一个就是人工智能的平台，我觉得也是值得思考的一个方向。就像过去电脑是单机的操作系统，像 Windows，那么在 Windows 这个平台，产生了大量的程序。对于手机也一样，在安卓、在苹果的 iOS 上也产生大量的应用，那么云计算也一样，它也是在云计算的平台上逐渐在形成大量的应用。所以 AI 是不是也会这样？是不是要有一个这样的平台，使得大家去做 AI 应用的开发和研究变得更加容易，就像过去写一个程序一样那么好做，我觉得这可能也是很关键的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从应用的角度来讲，我觉得计算的效率可能也非常重要，尤其是大规模的视觉计算，如果需要大量的数据，计算量非常大，必须是在资源消耗可控的情况下才能完成。如果发现完成这件事情都要破产的话，就没有办法继续做下去了，这里面涉及到系统架构的效率包括算法本身的效率等等之类的各种优化，这个也是很重要的系统问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;算法的红利会逐渐消失&lt;/strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;机器之心：您从业近二十年，经历了人工智能行业的技术变迁，在您看来，哪些因素造就了这一波行业热度？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;华先胜：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我个人认为，技术是其中最重要的原因，应该说是一个根本的推动力。这些年，技术发生了很大变化，首先机器学习的技术，尤其是深度学习的技术，在识别、搜索、生成的方面都比传统方法表现更加优秀。第二是计算能力，特别是云计算使得计算的能力远远的超过以前，而且我们获得大量计算的能力，也变得非常便利，当然，移动设备的发展也是一个重要因素。我记得在上个世纪图像搜索这个事情刚刚开始研究的时候，那时候也很火热，那个时候叫 CBIR，也成就了很多的博士论文。但是当时经常有人提问，你第一张图片到底哪里来呢？到今天今天这根本不再是个问题，因为我们获取数据变得非常容易。还有网络带宽的发展，使得我们在设备端，在互联网上大量的数据得以传播，尤其是视觉的图像识别数据得以传播，这些因素都是促成人工智能火热火爆的场面。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;机器之心：在您看来，一个成功的商业应用应该具备哪些条件？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;华先胜：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我认为应该具备五个条件：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一个是算法。你要有好的算法，你的算法要有先进性，你的算法不行一切都没有了基础。（当然你也可以把算法这一个条件看做是科学家，因为人才和算法是紧密相连的）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二个是要有数据。数据本身就是一个很大的话题，里面有数据的采集、搜集、清洗、有效的标注，甚至包括算法里面数据怎么使用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第三个是用户。你做的这个东西应该有用户的，因为有很多问题是需要用户参与才可以做得越来越好。当然你从商业的角度来讲，没有用户的话也不能够长久。用户本身是数据的消费者，也是数据的提供者，这过去在搜索引擎里面有非常重要的体现，可以说搜索引擎的技术能够做那么好，每个人都有 contribution 的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第四个就是平台。这个就是涉及到你要有强大的计算能力和一套体系架构，能够方便地去研发、部署和生产，这一套是必须要有的。当然现在因为有云计算，所以这部分的瓶颈，对于很多企业来讲已经没有过去那么困难了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第五个就是有好的商业模式。如果没有好的商业模式，就不可能长久。你做一个事情，低频的事情没有多少人用，或者不能给少量用户带来大的价值，最后产生的总体价值不够的话，其实是很难长久的。这几点，我个人觉得其实是都应该具备的。当然了，可能不同的商业应用，应该来说可能有不同的侧重，但是我觉得都应该具备。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;机器之心：很多大公司押注人工智能，越来越多创业公司也在涌入，公司之间的差距会体现在哪些方面，算法是公司竞争的核心要素吗？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;华先胜&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：这是一个很好的问题，也有很多的争论，我说说我自己的观点，我们有很多公司确实是以算法起家的，但是我觉得算法之间的差异，可能会逐渐越来越小。尤其是现在基于深度学习的方法，以及包括很多开源的出现，对于内行人而言，或者叫高手之间，他们之间算法性能的差异其实不会太大。比如说人脸识别，在 AFW 上面，大家测试的差距都在小数点后面一位两位的，没有太大的差距。像 ImageNet 也一样，差不多都是 99.6%、99.7% 这样子，都是不难达到的。那这些对于内行人而言没有太大的差距，但是在真实场景下应用的时候还会有差距，随着时间的推移，大家都在实战当中磨炼的话，都不会差距太大。甚至包括数据的优势，也会减少，很多的公司，不管是大公司还是创业公司，做得稍微早一点，积累了大量的数据，不管是标注的信息还是算法在练习当中搜集的反馈，随着时间的推移算法、数据的红利也都会逐渐减少。&lt;/span&gt;&lt;span&gt;当然，这里是对一个具体的图像识别或搜索或生成算法而言的。在很多行业，数据的获取有barrier, 这时数据本身就是价值。如果不具备或者没有足够量的相关数据，基于数据上的智能和应用就无法完成，这时数据本身就成为了核心竞争力。如果相关数据是容易获取的，就不能成为核心竞争力了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;还有什么是具有竞争力的东西呢？我觉得可能还是要看平台和商业应用。从商业模式上来使得自己的竞争力具有长久性，尤其是在细分的这个行业，你做到非常精深。&lt;/span&gt;&lt;span&gt;因为这部分并不是那么显而易见的，并不是说随便搞搞，我们就都是 90% 几之类的，这个需要你精耕细作的，需要你深入这个行业，结合真实场景数据的一些特点，才能够逐渐把这个行业吃透、打穿，才能够有一席之地、成为高手。那么这个的话，其实是可以有差异化的。因为这个行业非常的多，其实大家不见得一定要挤在一个独木桥上，一定要去刷通用的图像识别这些东西，或者是非常火热的一些领域，其实有很多路可以走的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;机器之心：现在有不少人工智能威胁论，但反过来看，人们对人工智能整体的发展和展现出来的技术能力，是不是也过于乐观了？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;华先胜&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：我们确实也要冷静看待一些问题，有几个角度来看到。比如说现在的识别就已经做到真的那么好了呢？大家可能有一些体会，这个准确率的数字好像很高，但是在真实场景下，有时候也不那么好。我举个例子，像大家比较公认的 ImageNet 比赛，有数百万张图片，进行 1000 类的分类，我们通常说现在最高的准确率已经做到超过 96% ，错误在3% 左右。那这个其实这里面有很多可以去探讨的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一点，超过 96% ，是指前五的正确率。也就是说一个图像识别出来 5 个结果，其中有一个对的就算对。如果规定第一个必须对才算达到正确，那可能正确率只有 80% 左右。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二点，是我们这个世界是很复杂的，远远超过这 1000 类，有很多现实世界当中太多太多不一样的东西都需要去识别。这实际上是一个覆盖率的问题，刚才讲到在标准的测试级上可以到很高，这是一个准确率的问题，准确率当然也是非常关键的，也是推动这个领域发展重要的一个指标，然而真正在现实当中的覆盖也是非常重要的。覆盖直接关系到人的体验，尤其是在识别和搜索这里面。比如说我那一年在做拍立淘的时候也是花很大的心思去解决覆盖的问题，覆盖的意思是就是说你搜什么都能给点相关结果出来。那准确率是说，我搜出来的东西要跟我想象的东西是相关的。这两个都是非常重要的。现在的识别的技术在覆盖上其实是有欠缺的，当然了覆盖的话，也不是说不能解决的。我记得我在前些年也做过一套系统，当时是利用了互联网的数据，使得覆盖能够得到更大的提升，用了互联网的数据自动取挖掘训练数据，使得它可以识别任意的东西，当然这个任意的东西还是有条件的，互联网上可以找得到数据，可以找到足够足量的数据然后可以自动清洗自动建立模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第三点，有没有好的商业应用，有没有真正深入行业产生价值，也是非常关键的。这一部分做不到，就不能长久。我觉得还是应该认真地考虑一下，创业也好，创新也好，基础是不是稳固的？比如说刚才我讲到的我的观点的五个要素是不是都具备了，缺什么，需不需要补，或者我们的优势在哪里？如果我们的优势只在算法上，那么可能还有一点危险，如果我们还有成功的商业模式，有源源不断的商业应用商业价值的产生，那可能就会比较安全一点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;机器之心： AI 模型的通用性怎么样？然后为了可用性高，是否最终都需要定制方案，那么开放平台上的 API 还有多大意义？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;华先胜&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：这个问题问得比较有深度，前面其实我们也讲过了这也是为什么我讲要深入行业，但是深入行业的话，可能有人会讲了，那你有多少人，你做得过来吗？那这里面的第二个问题就是刚才讲的生态，这个不是一家人能够做得出来的，需要很多人去做，就像操作系统上那么多应用程序，包括手机操作系统上那么多好玩的 APP，各种功能的 APP 那不是苹果一家能做得出来的，所以我们要做成这样的一个生态。就像你搭了一个舞台一样，不是光自己在那里演，有很多人都可以上来演，有很多有创意的人都可以上来演，这个就解决了深入各行各业解决实际应用的，在这里面能够做得更好，在一个行业里面在一个应用领域里面怎么做得更好，这样才能够真正发展起来。现实世界就是这么残酷的，很少有一个模型可以打天下的情况，几乎都是不可能存在的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&amp;copy;本文为机器之心原创，&lt;strong&gt;&lt;span&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Sat, 04 Mar 2017 11:57:36 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 谷歌使用深度学习帮助病理学家检测癌症，算法得分高达89%</title>
      <link>http://www.iwgc.cn/link/12f5c9a989baf4d569427cd83caac9b06da8d280</link>
      <description>
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;选自Google Research&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Martin Stumpe、Lily Peng&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;参与：微胖、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote style="color: rgb(62, 62, 62); font-size: 16px; white-space: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;在检查完病人的生物组织样本之后，病理学家的报告通常会成为许多疾病诊断中的黄金标准。特别是在癌症诊断中，病理学家的诊断对病人的治疗有着极大的影响。检查病理切片是一件非常复杂的任务，需要多年的培训从而掌握专业知识、获取经验。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;即使经过了如此密集的培训，不同的病理学家对同一病人可能给出相当不同的诊断，从而导致误诊。例如，诊断同样形式的乳腺癌上的一致率（agreement）只有 48%，几乎和前列腺癌一样低。为了做出准确诊断而需要检查如此大量的信息，缺乏一致率也无可厚非。病理学家要负责检查切片上的所有可见的生物组织。然而，每个病人都会有许多切片，在进行 40 倍放大时每个切片都有 100 多亿的像素（10+gigapixels)。想象一下要浏览 1000 多个百万像素的图片，还要为每个像素负责。不用说，这要覆盖大量的数据，而给的时间往往是有限的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了解决时间有限和诊断不一致的问题，我们研究了如何将深度学习应用到数字化病理学中，通过创造自动检测算法来自然地补充病理学家工作流。我们使用由 Radboud 大学医疗中心提供的图像训练算法，这些训练数据也曾被用于 2016 年 ISBI Camelyon 挑战赛，而该算法经过优化可来确定是扩散到淋巴结的乳腺癌还是扩展到临近乳房的乳腺癌。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;结果如何？标准的像是 Inception（又叫做 GoogLeNet ) 这样的现成深度学习方法对以上两个任务都有效，尽管产生的肿瘤概率预测热点图有点噪音。经过额外定制化之后，包括训练神经网络在不同放大倍数的图像上进行试验（很像病理学家所做的），我们表示是有可能训练一个相当于或超越病理学家（他们试验切片的时间没有限制）表现的模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/e841cfe22c620a3c0ef9d0ea9f60d9e145685dc7"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;左：两个淋巴结活组织检查的图像；中：较早之前我们的深度学习肿瘤检测的结果；右：目前的结果，可看到两者之间噪声（潜在的假正例）的减少&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;事实上，算法产生的预测热点图已经有了很大的改进，算法的 FROC 得分达到了 89%，大大超过了病理学家无时间限制进行诊断的得分（73%）。我们并不是唯一一家看到它的潜力的团队，其他团队在同一数据集上也得到了高达 81% 的结果。更激动人心的是，我们的模型泛化非常好，即使是在不同医院使用不同扫描仪得到的图片上。想要了解更多，可参考我们的论文《Detecting Cancer Metastases on Gigapixel Pathology Images》。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/958f8586df47f0fcae90fa4ca2f5617c44d10e12"/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/4ccb50926f36844162e1062175cf9875c3e9dedf"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;淋巴结活组织检查特写图。该组织包含乳腺癌转移和巨噬细胞，看起来像是肿瘤但却是良性的正确组织。我们的算法成功的识别了肿瘤区域（亮绿），并未被巨噬细胞所迷惑。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然这些结果惊人，但还是要考虑以下重要的提醒：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;像大部分标准一样，FROC 定位得分（FROC localization score）并不完美。在这里，每个切片有一些预定义的平均假正例的情况下，FROC 得分被定义为敏感性（sensitivity)。病理学家做出假正例的情况相当罕见（把正常细胞误诊为肿瘤）。例如，上面提到的 73% 的得分对应 73% 的敏感性，以及 0 个假正例。与之对比，我们算法的敏感性在更多假正例的情况下会上升。每个切片有 8 个假正例的情况下，我们算法的敏感性达到 92%。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;这些算法在之前训练过的任务中，表现良好，不过，尚缺乏人类病理学家的知识广度和经验&amp;mdash;&amp;mdash;比如，识别其他不正常情况的能力，而之前没有详细训练过该模型对这些情况进行分类（比如，发炎过程，自身免疫疾病以及其他类型的癌症。）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;为了确保最佳临床效果，还需要将这些算法吸收到病理学家的工作流程中去，完善这一流程。我们的愿景是，诸如这些算法能提高病理学家的工作效率和诊断的一致性。比如，通过检查排在前面的预测肿瘤区域（包括每个切片有 8 个假正例的区域），病理学家可以降低假率的未检出率（也就是没有被监测到的肿瘤）。另一个例子这些算法能够让病理学家简单而准确地测量肿瘤大小，这一因素与预后 (prognosis) 有关。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;训练模型知识将有趣的研究成果转化为真实产品的第一步。从临床有效到官方批准，还有长的路要走&amp;mdash;&amp;mdash;不过，我们起了一个好头，也希望通过成果共享，加速这一领域的发展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;原文链接：https://research.googleblog.com/2017/03/assisting-pathologists-in-detecting.html&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;span&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Sat, 04 Mar 2017 11:57:36 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 人工智能芯片群雄势力图景：面向应用场景的设计成为趋势</title>
      <link>http://www.iwgc.cn/link/3d180478fece2d05eef8e5956d363269828d9657</link>
      <description>
&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自Forbes&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;作者：Karl Freund&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李泽南、微胖&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;毫无疑问，2016 年科技界的关键词是人工智能与机器学习。但直到今天，除了自动驾驶汽车和手机里的智能助手，没有人能列举出几种应用了机器学习的设备。人工智能在哪里？我们不禁产生了怀疑。当我们要求 Siri 播放音乐，或提供明天的天气预报时，那个「她」是在你手机中的意识体，还是苹果服务器的一部分？亚马逊 Alexa 呢？答案是：它们都在云端。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当你正在考虑这些技术上的问题时，投资者和开发者们则更进一步，开始研究 AMD、英特尔、英伟达、高通和 Xilinx 提供的芯片各有哪些优点，哪一家公司的芯片更符合人工智能时代的需要了。本文为你展示了目前芯片行业的图景，针对不同的应用需求（云端、单机和混合场景），对目前市面上的芯片类型进行了分类讨论。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;以行业和部署位置分类&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;根据 Angel List 的数据，目前应用机器学习构建业务的初创公司数量惊人，已达 1700 家，投资机构则超过了 2300 个。下表列出了这些公司触及各领域的大致分类，以计算能力为标准，共分为单机、混合以及云端解决方案三种。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/68559149d7478dc4685dde9619328750b6171532"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;机器学习应用图景 (Source: Moor Insights &amp;amp; Strategy)&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;CPU、GPU、ASIC 还是 FPGA？&lt;/strong&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前机器学习的应用主要是通过大量编制好的数据训练神经网络模型，然后再让训练后的神经网络处理接收需要处理的数据。其中训练神经网络如何「思考」的过程需要耗费大量计算资源，这类任务通常是由数据中心的 GPU 来完成的，而 GPU 的提供商以英伟达为主，在 AMD 等其他公司的竞品性能有限的情况下，目前英伟达的市场地位稳固。但在混合以及单机计算解决方案领域，目前市场上还存在一定的竞争，下图展示了更大方向上机器学习硬件的主要产品。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/4735b98f53bd49ccc76117be3304c6fa496a49d7"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;机器学习图景中的硬件情况&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在机器学习时代刚刚到来的今天，全球市场并未出现「一家独大」的局面。所有硬件公司都声称自家的计算架构（CPU，GPU，ASIC 和 FPGA）最适用于人工智能和机器学习的计算，并给出了自己的数据。实际上，每一种架构仅会在特定场景、数据、应用或部署方式条件下优于其他架构。数据的复杂性和任务的速度要求决定了计算能力的需求，而应用场景则对延迟和功耗产生不同限制。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;CPU，如数据中心常见的英特尔 Xeon 和 Xeon Phi，还有移动设备中采用的高通骁龙，善于处理相对简单的数据，比如文本和 jpeg 图片，一旦要训练神经网络，在处理源自诸如 4K 摄像头或雷达的高速率像素数据时，就会捉襟见肘了。为了解决这一问题，英特尔准备推出新版本的多核 Xeon Phi，代号 Knights Mill，有望今年年底上市。不过，在很多情况下，完成任务需要一个 GPU，一个专用集成电路（ASIC）类似英特尔期望中的 Nervana 引擎或编程 FPGA 以满足低能耗、低延迟的性能水平，这是智能无人机、车辆或导弹方面应用的基本需求。尽管英伟达 GPU 在未来仍会是很多性能测评的胜出者，因为它是最快的解决方案，但是，当加速算法不断演进时，FPGA（通常来自英特尔或 Xilinx）却有能力对机器学习算法进行专门优化，延迟也低。在云端，我们也能发现类似情况，在这个领域里 GPU、FPGA 以及类似谷歌 TPU 的 ASIC 共存，每类都代表一些独特的功能，针对特定数据类型和吞吐要求，各自有其利弊。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一些应用，比如视觉导航自动驾驶系统就需要一种混合硬件的解决方案，以满足应用环境对延迟和数据处理的要求。尽管之前提到的加速善于运行人工智能推理引擎、传感器融合、数据预处理，后评分策略执行也需要很多特定的 I/O，快速传统逻辑最适合 CPU。为了应对这一挑战，英伟达提出了混合硬件平台，英伟达 Jetson TX1 和 DrivePX2 是 ARM 处理器与 GPU 的混和体，甚至还附有存储单元，而英特尔和 Xilinx 的 SoC 中，ARM 处理器和 FPGA 被整合成为一个单独、优雅的低能耗解决方案。所有这些设备都可以在无人机、工厂机器人/合作机器人以及自动车辆等应用场景中找到自己的位置，这些领域要求开发者们必须合理地权衡速度、灵活性以及功耗需要。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/6dd3ae22d956e16325dd13e882b6892b5a8eacec"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;英伟达 Jetson TX1，适用于为嵌入式系统中的机器学习和计算机视觉任务提供计算能力&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而在移动计算领域，高通一直在不断增强自己的骁龙处理器，以囊括各种加速器技术来支持移动端以及其他单机设备的机器学习技术，这些设备是智能物联网的重要组成部分。最新的骁龙 835（8 核处理器，预计由三星 Galaxy S8 在 3 月 29 日首发）已经发展到了 10nm 制程，整合了 4 个主频 2.45GHz 的 Kryo 280，4 个主频 1.9GHz 的 Cortex-A53，Adreno 540 GPU，ISP（图像信号处理器）、DSP（数字信号处理器）等模块，以满足各种编程以及硬件模型加速机器学习算法的需求。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一种强大的架构并不能解决所有问题，不能满足兴起的机器学习应用中所有环境的计算需求。因此，我们必然会看到越来越多的选项，针对不同工程/设计团队，针对具体智能系统、产品服务，量体裁衣。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;原文链接：https://www.forbes.com/sites/moorinsights/2017/03/03/a-machine-learning-landscape-where-amd-intel-nvidia-qualcomm-and-xilinx-ai-engines-live/#742f84ef742f&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;span&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Sat, 04 Mar 2017 11:57:36 +0800</pubDate>
    </item>
    <item>
      <title>学界 | DeepMind 连发两文：从可微分界树构建深度最近邻表征到合成梯度与解耦神经接口的深入研究</title>
      <link>http://www.iwgc.cn/link/6ce7ac554efe08134ff06c7391a3717735c7cd6c</link>
      <description>
&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;选自arXiv.org&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：蒋思源&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;近日 DeepMind 连发两篇论文，其都注重于开发一种更加高效、可解释的模型或算法。其中机器之心重点关注了 DeepMind 使用深度学习构造高效、可解释的最近邻分类树，初步了解了边界树及其变换构造深度最近邻表征。其次 DeepMind 发表了合成梯度 (SG) 与解耦神经接口 (DNI) 深入研究，并表明了 SG 的并入并不会影响神经网络学习系统的表征强度。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：Learning Deep Nearest Neighbor Representations Using Differentiable Boundary Trees&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文地址：https://arxiv.org/abs/1702.08833&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/122ca19315b6b14302db2d0cb78e8af97390f7e1"/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;摘要&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随着计算机硬件水平的进步和算法效率的提升，K 近邻（K-Nearest neighbor/kNN）法近年来已经越来越受到欢迎。如今机器学习模型有很多算法可以选择，每一种都有其自身的长处与短处。其中所有基于 K 近邻（kNN）的方法都要求在样本间有一个优良的表征（representation）和距离度量（distance measure）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们引进了可微分界树（differentiable boundary tree）这一新方法，该方法能学习深度 K 近邻的表征（Deep kNN representations）。我们的方法建立在最近提出来的边界树（boundary tree）算法之上，该算法能进行高效的最近邻分类、回归和检索。通过将树中的遍历建模作为随机事件（stochastic events），我们能构建与树预测（tree's predictions）相关联的可微分成本函数。通过使用深度神经网络转换（transform）数据还有沿树进行反向传播，模型就能学习 K 近邻法的优良表征。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们证明了该方法能学习合适的表征，并通过清晰的可解释架构提供一个非常高效的树。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/bbdad25427d52cd6edfdf0adf02ef920f202073e"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;图 1：边界树以在线的方式（online manner），一个接一个样本构建。从左到右：给定当前树（左图中描绘）从根节点开始。对于每一个查询（query），我们采用递归的方式遍历整棵树，每一步选择离询问节点（query node）局部最近的节点。一旦遍历停止，我们就会使用最后节点的类做预测（中间那幅图）。如果预测是错误的（如这个案例），我们就会将查询节点作为子节点（child）添加到最终节点中，从而构建一颗新树（最右边那幅），同时丢弃查询结点。因为树的边界根据定义和样本将倾向于靠近分类边界，所以也就有了「边界树（Boundary Tree）」这一名字。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/0e2079e1bd2149330c882e1fd74eb4342de3be06"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;图 2：方程式 6 中的成本函数在构建中涉及到不同近邻和变换（transitions）的可视化。树在这里是以任意二维空间展示的（为了可视化）。给定询问节点并通过 f_theta 转换所有样本后，我们可以遍历树中节点以下的所有路径（图中标红）。每一个变换（transitions）的概率都进行了计算，直到最后节点的近邻才停止。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这里我们聚集了节点的类标签，并通过它们各自的变换概率（transition probability）加权，从而构建出类的预测作为输出。可以参见图 3，用于计算成本函数的关联神经网络（associated neural net）可视化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/b1c4e985a7979faadfbf2b52339f7e78b5c5ecf8"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;图 3：需要为每个查询节点（query point）动态地构建神经网络。对于每一个变换（transition），通过树模块输出的转换样本（transformed samples）是共享的。每一个模块都会提取转换样本（transformed samples），并计算它们和转换询问点之间的距离，然后转为对数概率（log probabilities）。数据变换（Transitions）是基于转换样本的。这些转换样本与最终的节点预测相结合以生成类预测，同时损失也通过构建的网络进行传播。可以参见图 2，相似树结构和路径（corresponding tree structure and path）的可视化。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/1f26887dc8132201ae39ee5d06e916c5ca044e7b"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;图 4：使用 MNIST 手写数字数据库中 1000 个已训练的表征样本所构建的树。样本在这里是以原始像素空间（original pixel space）表达的，但是学到的表征（learned representation）是用来构建树的。注意其简单且可解释结构&amp;mdash;节点是原型样本（prototypical examples）或边界情况（boundary cases）。值得注意的是，这棵树仍然在测试集上获得了 2% 的错误降低率。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：Understanding Synthetic Gradients and Decoupled Neural Interfaces&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文地址：https://arxiv.org/abs/1703.00522&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/070c1b4ec4ba6c20e69a5ad0abff0ff51c2ce03c"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;摘要&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当使用合成梯度（Synthetic Gradients /SG）训练神经网络时，可以在不使用更新锁定（update locking）的情况下训练层级或模块，这样就不需要等待误差真值梯度（true error gradient）沿反向传播，也就导致一种退耦合神经接口（Decoupled Neural Interfaces/DNIs）。这种更新解锁的能力（unlocked ability）可以使用异步的方式更新部分神经网络，并且 Jaderberg 等人（2016）也证明了只有局部信息（local information）能以经验为主地工作（work empirically）。然而，很少有证据表明是什么改变了从函数（functional）、表征（representational）和视角学习动力点（learning dynamics point）实施的 DNI 和 SG。在本论文中，我们通过使用前馈网络上的合成梯度（Synthetic Gradients）来研究 DNI，并期望能更好地理解它们的行为和阐明其对优化算法的影响。我们的研究表明 SG 的并入并不会影响神经网络学习系统的表征强度（representational strength），并证明了线性和深线性（deep linear）模型的学习系统收敛性。在实际操作问题上，我们调查了使用合成梯度估计量逼近损失真值（true loss）的机制，并很惊讶地发现其是如何导致完全不同的层级表征。最后，我们还揭示了合成梯度和其他误差逼近技术（error approximation techniques）的关系，并发现可以使用同一的语言进行讨论和比较。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;span&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Sat, 04 Mar 2017 11:57:36 +0800</pubDate>
    </item>
    <item>
      <title>一周论文 | VAE在自然语言处理中的应用</title>
      <link>http://www.iwgc.cn/link/8aefa28f529b505c51a58c9f7118b5b962e4c24c</link>
      <description>
&lt;p&gt;&lt;span&gt;提及 Generative Models，Variational Autoencoder (VAE) 和 GAN 可以说是两座大山头。二十四期的「&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650723149&amp;amp;idx=5&amp;amp;sn=5f8ef659299397737b29c62489f1fabf&amp;amp;chksm=871b1733b06c9e2520bdf64724707e47e139495da9f7a1e268dce0119cd3ab566cd6a6623341&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650723149&amp;amp;idx=5&amp;amp;sn=5f8ef659299397737b29c62489f1fabf&amp;amp;chksm=871b1733b06c9e2520bdf64724707e47e139495da9f7a1e268dce0119cd3ab566cd6a6623341&amp;amp;scene=21#wechat_redirect" target="_blank"&gt;GAN for NLP&lt;/a&gt;」一文中对 GAN 在 NLP 中的进展做了详细的介绍，推荐错过的朋友不要再错过。虽然 GAN 在图像生成上效果显著（当然 VAE 也很强），但在 NLP 方面暂时还是 VAE 较为 work。今天的分享作为姊妹篇（捂脸），对 VAE 在 NLP 的应用里最具有代表性的几篇 paper 进行介绍。我会尽量梳理论文之间的联系，希望对大家有所帮助。本期涉及的论文有：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="max-width: 100%; color: rgb(62, 62, 62); font-size: 16px; font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;《Generating Sentences From a Continuous Spaces》. ICLR 2016&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;《Neural Variational Inference for Text Processing》. ICML 2016&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;《Language as a Latent Variable: Discrete Generative Models for Sentence Compression》. EMNLP 2016&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;《A Hierarchical Latent Variable Encoder-Decoder Model for Generating Dialogues》. AAAI 2017&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;其他&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;a rel="gallery0" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title=""&gt;&lt;img src="http://img03.iwgc.cn/mpimg/b3a3551f7b0a775729cdac4dd6dde0e5ef747fde"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在展开之前，我先带大家简单回顾一下 VAE 的核心。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1) 如上图所示，VAE 可以看做是 Standard autoencoder 的 regularized version（在 autoencoder 的架构上引入随机 latent variable）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;2) VAE 从 data 学到的是在 latent space 的 region，而不是单个点。换句话说是 encode 学到了一个概率分布 q(z|x)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;3) 引入 KL divergence 让后验 q(z|x)接近先验 p(z)。这里的 motivation 在于如果仅用 reconstruction loss，q(z|x)的 variances 还是会很小（又和原有的单个点差不多了）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;VAE 详细推导这里就不展开，各种 tutorial 也非常多。只要掌握变分推断和理解 reparametrization trick 就基本 ok 了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面进入正题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&amp;mdash; 01 &amp;mdash;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Generating Sentences From a Continuous Spaces&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a rel="external" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" target="_blank"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;论文链接:&amp;nbsp;&lt;/span&gt;&lt;a rel="external" style="color: rgb(136, 136, 136); text-decoration: underline; max-width: 100%; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important;" target="_blank"&gt;&lt;span&gt;https://aclweb.org/anthology/K/K16/K16-1002.pdf&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a rel="external" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" target="_blank"&gt;&lt;br&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这篇文章对后面很多 paper 影响很大而且我也很喜欢，所以重点介绍一下。paper 最早发表在 ICLR 2016 上，motivation 在于作者为了弥补传统的 RNNLM 结构缺少的一些 global feature（其实可以理解为想要 sentence representation）。其实抛开 generative model，之前也有一些比较成功的 non-generative 的方法，比如 sequence autoencoders[1]，skip-thought[2]和 paragraph vector[3]。但随着 VAE 的加入，generative model 也开始在文本上有更多的可能性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;a rel="gallery0" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title=""&gt;&lt;img src="http://img03.iwgc.cn/mpimg/b243c62dab7ce00af2fed3e934b39db25aa38765"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Loss 的组成还是和 VAE 一样。具体模型上，encoder 和 decoder 都采用单层的 LSTM，decoder 可以看做是特殊的 RNNLM，其 initial state 是这个 hidden code z（latent variable），z 采样自 Gaussian 分布 G，G 的参数由 encoder 后面加的一层 linear layer 得到。这里的 z 就是作者想要的 global latent sentence representation，被赋予了先验 diagonal Gaussians，同时 G 就是学到的后验。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;模型很简单，但实际训练时有一个很严重的问题：KL 会迅速降到 0，后验失效了。原因在于，由于 RNN-based 的 decoder 有着非常强的 modeling power，直接导致即使依赖很少的 history 信息也可以让&amp;nbsp;reconstruction errors 降得很低，换句话说，decoder 不依赖 encoder 提供的这个 z 了，模型等同于退化成 RNNLM（摊手）。顺便一提，本文最后有一篇 paper 也是为了解决这个问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;先看这篇 paper 提出的解决方法：KL cost annealing 和 Word dropout。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1) KL cost annealing&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;a rel="gallery0" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title=""&gt;&lt;img src="http://img04.iwgc.cn/mpimg/c974c31e6417374042ac3b577eb5923dc445775b"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a rel="gallery0" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title=""&gt;&lt;br&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;作者引入一个权重 w 来控制这个 KL 项，并让 w 从 0 开始随着训练逐渐慢慢增大。作者的意思是一开始让模型学会 encode 更多信息到 z 里，然后随着 w 增大再 smooth encodings。其实从工程/代码的角度看，因为 KL 这项更容易降低，模型会优先去优化 KL，于是 KL 很快就降成 0。但如果我们乘以一开始很小的 w，模型就会选择忽视 KL（这项整体很小不用降低了），选择优先去降低 reconstruction errors。当 w 慢慢增大，模型也慢慢开始关注降低 KL 这项了。这个技巧在调参中其实也非常实用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2) Word dropout&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;a rel="gallery0" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title=""&gt;&lt;img src="http://img05.iwgc.cn/mpimg/bb338f76efb43fef7c71d95238b0d7b5f253ff4e"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;既然问题是 RNN-based 的 decoder 能力太强，那我们就来弱化它好了。具体方法是把 input 的词替换成 UNK（我可能是个假的 decoder），模型被迫只能去多多依赖z。当然保留多少 input 也需要尝试，我们把全都不保留的叫做 inputless decoder，实验表明，inputless VAE 比起 inputless RNN language model 不知道好到哪里去了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;受到 GAN 的启发，作者还提出了一个 Adversarial evaluation，用一半真一半假的数据作为样本训练出一个分类器，再对比不同模型生成的句子有多少能骗过这个分类器，这个 evaluation 被用在 Imputing missing words 这个任务上，VAE 的表现同样比 RNNLM 出色。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，作者展示模型的确学到了平滑的 sentence representation。选取两个 sentence 的 code z1 和 z2，z1 和 z2 可以看做向量空间的两个点，这两个点连线之间的点对应的句子也都符合语法且 high-level 的信息也保持局部一致。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;a rel="gallery0" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title=""&gt;&lt;img src="http://img05.iwgc.cn/mpimg/7f6e2c9534ee901eab1d4980abda91ed0b5e62f7"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&amp;mdash; 02 &amp;mdash;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;Neural Variational Inference for Text Processing&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;论文链接:&amp;nbsp;&lt;/span&gt;&lt;a rel="external" style="color: rgb(136, 136, 136); text-decoration: underline; max-width: 100%; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important;" target="_blank"&gt;&lt;span&gt;https://arxiv.org/pdf/1511.06038.pdf&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其实这篇 paper 和第一篇是一起投的 ICLR，后来转投了 ICML 2016，所以时间上其实和第一篇是一样的（两篇文章也有互相引用）。不同于第一篇，作者的出发点是构建一个 generative neural variational framework。为了证明 framework 的优越性，分别在 unsupervised 和 supervised 的任务上提出了两个模型，结果也很令人满意。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;a rel="gallery0" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title=""&gt;&lt;img src="http://img04.iwgc.cn/mpimg/a65f9620e71e75ef3637c2b5920ca9bd351af0ba"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一个任务是 unsupervised document modeling，模型叫 Neural Variational Document Model（NVDM）。h 和第一篇的 z 一样，在这里代表&amp;nbsp;latent document semantics，但 document 是以 bag-of-words 的形式（个人以为这里作者主要还是受到 LDA 的影响）。encoder 采用MLP，decoder 是一层 softmax。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二个任务是 supervised answer selection，模型叫 Neural Answer Selection Model（NASM）。文本的建模方式采用 LSTM（在第二个任务用 LSTM，第一个任务用词袋，可能为了证明普适性）。h 代表 latent question semantics。如上图所示，Zq 和 Za 用来表示 question 和 answer，y 代表 answer 是不是正确答案，用 Zq 和 Za 预测 y。那么 Zq 和 Za 是怎么得到的呢？Zq 延用 LSTM 的 last state，而 Za 则较为复杂，所谓脱离问题谈答案都是耍流氓，所以对 Za 建模时要显式的放入 question 的信息。可这里该怎么表示 question 呢？如果还用 Zq，模型很容易 overfitting。这里我们的 latent h 终于可以出场了，引入 h 不仅起到了 muti-modal&amp;nbsp;的效果，还让模型更 robust，再把基于 attention 的 c(a,h)和 answer&amp;nbsp;的 LSTM last state 组合得到 Za。这种做法对我们在寻找 representation 时有很好的借鉴作用。最后通过推导 variational lower bound 确定 h 的先验是 p(h|q)（第一个任务中先验是 p(h)）, 这里就不赘述了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&amp;mdash; 03 &amp;mdash;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;Language as a Latent Variable: Discrete Generative Models for Sentence Compression&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;论文链接:&amp;nbsp;&lt;/span&gt;&lt;a rel="external" style="color: rgb(136, 136, 136); text-decoration: underline; max-width: 100%; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important;" target="_blank"&gt;&lt;span&gt;https://arxiv.org/pdf/1609.07317v1.pdf&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这篇 paper 发表在 EMNLP 2016，同样出自第二篇 paper 的作者。传统的 VAE 是把数据 encode 成 continuous latent variable，这篇 paper 的贡献在于提出了一个 generative model 用来学到 language 的 discrete representation&amp;mdash;一个带有 sequential discrete latent variable 的 VAE。所谓的 discrete latent variable 就是指一个单词，加上 sequential 其实就是一个句子，由于 VAE 本身是压缩数据的，换句话说是用短一点的句子来表示原来的句子，也就是句子压缩。我觉得作者的 intuition 在于每个句子可以有多个缩写，且都可以表示原句，有一点点 distribution 的意思，所以用 latent variable 很合适。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;a rel="gallery0" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title=""&gt;&lt;img src="http://img03.iwgc.cn/mpimg/e94fa43918a5116faef673a2a576e3b53a939ef1"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;原句和压缩句分别是 s 和 c ，模型整体是 encoder -&amp;gt; compressor -&amp;gt; decoder。我们分解开看，encoder -&amp;gt; compressor 采用 pointer network[4]只从 s 里选取合适的词而不是整个词典，从而大大减少了 search space。compressor -&amp;gt; decoder 是一个带 soft attention 的 seq2seq。这个模型的好处是不需要 label 数据，但是如果我们有足够的 label 数据（真实数据里 c 里的词可不仅仅来自 s），需要额外加个 softmax 从整个词典里选词，同时再定义一个 latent factor 判断是从 s（pointer network）还是从词典里选，更加符合任务需求。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;a rel="gallery0" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title=""&gt;&lt;img src="http://img04.iwgc.cn/mpimg/38c02097261b7f938c535f9be497824a58a3494c"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;值得一提的是 Variational lower bound 里的 p(c)是 pre-train 好的 language model。因为 Language model 的一个特点是比较喜欢短句子，很适合句子压缩的场景。由于 reparameterisation trick 并不适用 discrete latent variable，作者还采用了 REINFORCE[5]的方法（凡是 discrete 的问题，GAN/VAE 都可以采用 REINFORCE）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&amp;mdash; 04 &amp;mdash;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;A Hierarchical Latent Variable Encoder-Decoder Model for Generating Dialogues&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;论文链接:&amp;nbsp;&lt;/span&gt;&lt;a rel="external" style="color: rgb(136, 136, 136); text-decoration: underline; max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important; font-size: 14px;" target="_blank"&gt;&lt;span&gt;https://arxiv.org/pdf/1605.06069.pdf&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是第一篇把 VAE 的思想引入到 dialogue 的 paper。和普通的 VAE 区别在于 dialogue 的 reconstruction 是生成的下一句 utterance，而不是 input 自身。这篇 paper 的前身是 HRED[6]，HRED 的核心思想是，把&amp;nbsp;dialogue 看做是 two-level：dialogue 是 utterance 的组合，utterance 是 words 的组合。HRED 由 3 个 RNN 组成：encode RNN 把每个&amp;nbsp;utterance 变成 real-valued 的向量 u，context RNN 把每个 turn 里的 u 作为输入变成向量 c，最后把 c 交给 deocde RNN 生成下一个 utterance。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;a rel="gallery0" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title=""&gt;&lt;img src="http://img04.iwgc.cn/mpimg/bba75480479552821cf74cfcad12220a4ca3a5ab"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;VHRED 在 HRED 的基础上每个 turn 里引入一个 latent variable z，z 由 context RNN 的 c 生成。z 的意义比较笼统，sentiment/topic 怎么解释都行。模型的训练技巧如 KL annealing 等大量借鉴了第一篇 paper 的思想，特别要注意训练时的 z 从后验采样（保证 decode 的正确性），测试时再从先验采样（ KL 已经把分布拉近）。实验表明，latent variable 有助于生成更加 diverse 的回复。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&amp;mdash; 05 &amp;mdash;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;其他&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;论文链接:&amp;nbsp;&lt;/span&gt;&lt;a rel="external" style="color: rgb(136, 136, 136); text-decoration: underline; max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important; font-size: 14px;" target="_blank"&gt;&lt;span&gt;https://arxiv.org/pdf/1605.06069.pdf&lt;/span&gt;&lt;/a&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="max-width: 100%; color: rgb(62, 62, 62); font-size: 16px; font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;第一次将 VAE 引入机器翻译：&lt;br&gt;《Variational neural machine translation》EMNLP 2016&lt;/span&gt;&lt;br&gt;&lt;span&gt;论文链接:&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;a rel="external" style="color: rgb(136, 136, 136); text-decoration: underline; max-width: 100%; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important;" target="_blank"&gt;&lt;span&gt;https://arxiv.org/pdf/1605.07869.pdf&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;为了改进 KL 迅速降到 0，提出 convolutional 和 recurrent 结合的 VAE：&lt;br&gt;《A Hybrid Convolutional Variational Autoencoder for Text Generation》&lt;/span&gt;&lt;br&gt;&lt;span&gt;论文链接:&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;a rel="external" style="color: rgb(136, 136, 136); text-decoration: underline; max-width: 100%; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important;" target="_blank"&gt;&lt;span&gt;https://arxiv.org/pdf/1702.02390.pdf&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参考文献&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;[1] Semi-supervised sequence learning&lt;br&gt;[2] Skip-thought vectors&lt;br&gt;[3] Distributed representations of sentences and documents&lt;br&gt;[4] Pointer Networks&lt;br&gt;[5] Recurrent models of visual attention&lt;br&gt;[6] Building End-To-End Dialogue Systems Using Generative Hierarchical Neural Network Models&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;作者&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;br&gt;&lt;/section&gt;&lt;br&gt;&lt;/section&gt;&lt;/section&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;苏辉，中科院软件所在读硕士，研究方向为 dialogue system 和文本生成。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;邮箱: suhui15@mails.ucas.ac.cn&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微信: suhui759596&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Please feel free to contact me if you have similar interests.&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;footer style="max-width: 100%; color: rgb(62, 62, 62); font-size: 16px; font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/footer&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/f9c45c7b507963e896553eef965b4845a22013d5"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;
</description>
      <pubDate>Sat, 04 Mar 2017 11:57:36 +0800</pubDate>
    </item>
  </channel>
</rss>
