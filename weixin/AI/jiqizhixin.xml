<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>重磅 | Edge 2017年度人工智能话题预测：从算法、迁移学习到自产生程序</title>
      <link>http://www.iwgc.cn/link/4482149</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Edge&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Edge.org 为著名知识分子俱乐部 The Reality Club 的线上社区，自 1996 年上线，如今已有 20 年历史。在其创刊 20 周年之际，Edge.org 也推出了 2017 年度问题——2017 年，最值得关注的科学术语或概念是什么？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以下是我们从206个回答中精选的一部分：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Terrence J. Sejnowski，计算神经科学家；萨克生物研究学院（Salk Institute）弗朗西斯·克里克学院（Francis Crick Institute）教授；《The Computational Brain》联合作者&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;科学术语：算法（Algorithms）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 20 世纪，我们使用方程和连续变量的数学方法作为主要洞见来源，因此对物理世界有了一个深刻的认识。一个连续变量在空间和时间上的变化是平滑的。与火箭仅仅遵循牛顿运动定律不同，还没有一种简单的方法来描述。在 21 世纪，我们在算法的数学基础上——通常含有离散变量而非连续变量——在理解计算机科学和生物学中的复杂性质方面取得了进展。算法是一个按步骤进行以实现某个目标的方法，就像在烤一个蛋糕。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自相似分形（Self-similar fractals）产生自简单的递归算法，该算法能创建类似于灌木和树的模式。一个真正的树结构也是一个算法，由一系列决定着细胞分裂时基因的打开和关闭的决策所驱动。大脑的结构也许是宇宙中最苛刻的构造项目，它也受到嵌入 DNA 中的算法所支配，该算法能够调节大脑中数百个不同的部分的成千上万种不同类型的神经元之间的连接的发育。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大脑中的学习与记忆是由算法控制的，该算法根据神经元活动的历史来改变神经元之间突触的强度。学习算法最近也被用于训练深度神经网络模型来识别语音、翻译语言、为照片添加说明以及进行锦标赛水平的围棋对弈。获得这些惊人能力的方法就是将同一个简单的学习算法应用到不同类型的数据上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;生成复杂性的算法有多常见？「游戏人生（The Game of Life）」是一个元胞自动机，其生成对象似乎有自己的生命。Stephen Wolfram 想知道能够导致复杂行为的最简单的元胞自动机规则，因而对所有的规则开始了搜索。前 29 个规则产生的模式总是返回到无聊的行为：所有节点都以相同的值结束，陷入一个无限重复的序列或无尽的混乱变化中。但规则 30 却能产生不断演化的复杂模式。甚至可以证明，规则 30 能够进行一般计算——可以计算任何可计算函数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这一发现的启示之一是，我们在自然界中所发现的显著复杂性，可能来自对分子间最简单的化学作用空间的取样。复杂的分子应该是从进化中演化来而不应该被视为一种奇迹。然而，元胞自动机可能不是一个早期生命的良好模型，而对于何种简单化学系统能够创造出复杂分子的探讨还仍然是一个悬而未决的问题。也许只有特殊的生化系统才有这种特性，该特性或许有助于缩小生命起源中相互作用的可能范围。Francis Crick 和 Leslie Orgel 认为，RNA 可能会有这些特性，它们在 DNA 的概念于进化早期出现之前打开了一个 RNA 的世界。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有多少算法？想象所有可能的算法空间，空间中的每一点都是一个处理问题的算法。其中有些算法有用而多产得令人吃惊。在过去，这些有用的算法是由数学家和计算机科学家像工匠那样手工制作的。与此相反，Wolfram 发现元胞自动机通过自动搜索能产生高度复杂的模式。Wolfram 定理规定，你不必在算法空间中走得太远去寻找一个解决一类有趣问题的算法。这就像是让机器人在网上玩 StarCraft 之类的游戏，尝试所有可能的策略。根据 Wolfram 定理，在能够赢得游戏的算法宇宙中的某个地方，应该有一个办法可以找到该算法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Wolfram 专注于研究元胞自动机空间——所有可能算法空间中一个小的子空间——中最简单的算法。我们现在已确认了神经网络空间——人类所设计过的最复杂的一部分算法空间——中的 Wolfram 定理。每个深度学习网络是所有可能算法空间中的一个点，而且它们是通过自动搜索被发现的。对于一个大网络和一个大数据集，从不同起点进行的学习可以产生无限的网络，它们解决问题的能力大致相等。每个数据集产生自己的算法星系，而数据集还在激增。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谁知道宇宙算法对我们来说会是什么样子？可能整个有用的算法星系还未被人类发现，但可以通过自动搜索实现。21 世纪才刚刚开始。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Peter Lee，微软全球资深副总裁&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;科学术语：迁移学习（Transfer Learning）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「你永远不能理解一种语言——除非你至少理解两种语言」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;任何一个学过第二语言的人，对英国作家杰弗里·威廉斯的这句话应该都会「感同身受」。但为什么这样说呢？其原因在于学习使用外语的过程会不可避免地加深一个人对其母语的理解。事实上，歌德也发现这一理念的强大威力，以至于他不由自主地做出了一个与之类似但更为极端的断言：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「一个不会外语的人对其母语也一无所知」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种说法极为有趣，但令人惊讶的是恐怕更在于其实质——对某一项技能或心理机能的学习和精进能够对其他技能或心理机能产生积极影响——这种效应即为迁移学习。它不仅存在于人类智能，对机器智能同样如此。如今，迁移学习已成为机器学习的基础研究领域之一，且具有广泛的实际应用潜力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今天的机器学习领域主要围绕着能力可随数据及经验的积累而提高的算法，且已取得惊人进步，并由此催生出可比肩甚至超越人类智能的计算系统，例如具有理解、处理及翻译语言能力的系统。近年来，机器学习研究多聚焦在深度神经网络（DNN）——一种通过从大量数据中推断异常复杂模式而进行学习的算法概念。例如，向一台基于 DNN 的机器输入数千个英文录音片段及其对应文本，机器便可从录音与文字的关联中推断出相关模式。伴随着关联模式的逐渐精确，系统最终将能「理解」英语语音。事实上，今天的 DNN 已经相当成熟，一台功能强大的计算机在学习过足够的训练样本后，完全可以对真人对话进行文字速记，并达到比专业速记员更高的准确率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一些人也许会很惊讶，计算机化的学习机器（computerized learning machines）展现出迁移学习的能力。我们可以通过一项涉及两套机器学习系统的实验来思考这个问题，为了简单起见，我们将它们称为机器 A 和机器 B。机器 A 使用全新的 DNN，机器 B 则使用已经接受训练并能理解英语的 DNN。现在，假设我们用一组完全相同的普通话录音及对应文本来对机器 A 和 B 进行训练，大家觉得结果会怎样？令人称奇的是，机器 B（曾接受英语训练的机器）展现出比机器 A 更好的普通话技能，因为它之前接受的英语训练将相关能力迁移到了普通话理解任务中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不仅如此，这项实验还有另一个令人更为惊叹的结果：机器 B 不仅普通话能力更高，它的英语理解能力也会提高！看来威廉斯和歌德确实说对了一点——学习第二语言确实能够加深对两种语言的理解，即使机器也不例外。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;迁移学习的理念至今仍是基础研究的课题之一，因此，许多根本性的问题仍然悬而未决。例如，并非所有的「迁移」都是有用的。要让「迁移」发挥作用，学习任务之间至少需要相互关联，而这种关联方式仍然缺乏精确定义或科学分析，且与其他领域相关概念之间的联系仍有待阐明，如认知科学和学习理论。诚然，对于任何一个计算机科学家而言，从事计算机系统的「拟人化（anthropomorphizing）」在理智层面都是危险的，但我们却不得不承认，迁移学习让人类学习和机器学习之间产生了强烈而诱人的相似性；当然，如果通用人工智能真能有朝一日成为现实，迁移学习恐怕将是这一过程中的决定性因素之一。对于善于哲学思考的人来说，迁移学习的正规模型可能会为知识和知识迁移带来新发现和分类方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;迁移学习同样具有极高的应用潜力。过去，机器学习在搜索和信息检索等领域中的实用价值较为单一，大多聚焦于通过万维网上大量数据集和人物信息进行学习的系统。但我们是否想过，经过网络训练的系统可以了解关于较小社区、组织甚至个人的信息么？未来智能机器可以学习与特定个人或小型组织相关的、高度专业化的任务么？迁移学习让我们可以想象这样一种可能性，让所有网络信息都成为机器学习系统的基础，而系统则可通过迁移学习获得更个性化的信息。实现这个愿景，我们将向人工智能普及化迈出又一大步。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Susan Blackmore，心理学家，《Consciousness: An Introduction》一书作者&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;科学术语：Replicator Power（复制体能力）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;宇宙中的一切设计都从何而来？无论在何处，我都能看见一系列事物——它们有的被设计过，而有的则没有——岩石、星星、水洼里的雨水，桌子、书本、草地、兔子乃至我的双手。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人们并非通过这样的方式来区分被设计的与未被设计的（事物）。通常人们将地上的书与岩石区分开来——因为书籍是为特定目的而设计的，但岩石则不是。书籍会有作者、出版商、印刷者、封面设计者等等，这代表着一种自上而下（译者注：由整体概念到具体细节）的设计模式，是「真正的」设计。但对于青草、兔子乃至双手，它们的确能够服务于特定的功能，但它们是通过一种无意识的、自下而上的过程演化的。因而，它们不是「真正的」设计。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于真正的设计与演化的「设计」之间的区别，偶尔被明确地说清。但在未被说清时，进化生物学家们往往对于将「设计」一词用在无意识的过程上会有某些畏惧的陈述。但它们真的「好像」是被设计的。它们并非是依据某种计划或意识的由上至下的模式，而是一种完全根据无意识过程的由下自上的模式。换句话说，我们大脑与「真正的」设计是不同的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果关于复制力（Replicator Power）的概念被更好的了解，那么这种错误的区分方法也许就会消除。因为我们会发现，所有的设计都基于一种相同底层过程。一个复制体（Replicator）是能够影响环境并能复制自身的信息（information）。基于变化与选择进行复制的进化算法，是一种能够无限制增加已有信息的过程。而复制体的能力，就从它在这种进化算法中扮演的信息载体的角色而来。基因就是最为明显的例子，它们带来了各种各样的生物作为它们（达到目的的）媒介或产物。而自然选择的作用则决定了复制体的成败。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「复制体」这个术语的价值在于它的普适性。这也是道金斯（英国演化生物学家）在撰写关于普适达尔文主义（Universal Darwinism，即将达尔文主义中最基本的想法应用到到所有的自复制信息中）时所强调的。当复制体存在并且环境适宜的情况下，「设计」将会随之发生。所以道金斯创造术语「文化基因（meme）」来说明世界上不止有一个复制体在进化。遵循关于进化的方式的思考，他也做出了这样的断言：复制体的有差别幸存（differential survival）导致了各个地方生命的进化。我则会补充认为：复制体的有差别幸存导致了各个地方智能的进化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这也就表明，人类设计从本质上与生物设计并无二致。两者都基于复制体被复制（的过程）——要不然是以 DNA 碱基对的分子顺序进行复制，要不然是以书本上字词的顺序进行复制。在分子复制的情况下，新的序列由复制过程的错误、突变或重组而产生。在撰写书籍的过程中，新的序列通过作者重组熟悉的词汇到新词组、句子乃至段落产生。在两个例子中，许多不同的序列被创造但很少的被保留被继续复制，而创造性设计的产品因复制力而出现。要理解人类以这种方式进行设计，就要放弃对于自上而下设计、智慧与规划对创造力必不可少这样的假设，要将那些能力及它们带来的设计视为进化的原因而非结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;接受这样的观点也许会带来不适，因为它意味着认同我们一切认为我们设计的东西实际上是一种从下到上、毫无头绪的过程利用我们作为一种复制机器（copy machinery）。这种不适也许就如同伯明翰主教之妻所说：这样知识贬低了人类自身，并且会消除我们的人性乃至能力。但我们已经能（或多或少在世界上的某些地方）学会拥抱而非畏惧这样的知识，我们的身体通过一种无意识的自下而上的过程进化。在相同方向上还有另一过程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;认识到复制力的意义在于认识到现在还有其他的复制体、以后还会有更多。这种无意识的过程将我们人类从猿猴转变为能讲话、能够复制文化基因（meme）的动物，让我们能生产桌子、书本、汽车、飞机以及复制机器——这是最重要的一步。这（复制机）包括了导致印刷过程的写作、产出家具的陶论、木头加工工具，以及导致现在信息爆炸的计算机技术。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能，无论是被造成桌上箱子的样子，还是分布在网络世界中的机器人，都被以复制能力的方式而创造，就如同我们的智慧被复制能力创造一般。它们以远超过我们的速度进化，并且会带来更深刻乃至更快的复制体。这种能力不停止，因为我们即希望如此。并且它的产物并不会臣服于我们的陈述，不会受我们的控制也不会按照（我们希望的）它兴盛的方式设计。这种智能会不断地成长，并且我们越快接受复制能力的概念，我们将会对有人工机器的未来生活的态度越现实。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Ursula Martin，牛津大学计算机科学教授&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;科学术语：抽象（Abstraction）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;翻开 Ada Lovelace 在 1843 年关于 Charles Babbage 未建成的分析引擎 (Analytical Engine) 的论文，如果你足够「极客」的话，你依然能够应付 19 世纪的长难句——令人惊讶的是，它们到如今仍然具有可读性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个分析引擎是完全机械的。设置一个具有十个齿的重金属盘来存储数字，五十个这样的盘堆叠后可以存储五十位数字，并且存储器将包含 100 个这样的堆叠。添加两个数字的基本指令将它们从存储器移动到 CPU 中，在那里它们将被添加在一起，而后移回到存储器中的新位置等待进一步使用，这些过程全都是机械的。它用冲孔卡来编程，代表了变量和操作，并进一步用精心设计的机制来移动冲孔卡，在需要循环时以组为单位重新使用。Babbage 估测认为这个巨大的机器将两个 20 位的数字相乘需要三分钟的时间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这篇论文可读性非常高，因为 Lovelace 所描述的机器使用抽象——存储、mill、变量、操作等，而非精心制作的铁器。这些抽象及它们之间的关系在识别主要组件和组件间传递的数据的过程中捕获了机器的本质。他们用当时的语言捕获当时和现在计算中的一个核心问题——使用不同的机器可计算和不可计算的内容。本文确定了「若所有智力执行的操作本身能够被精确定义，则重现这些操作以获得确定结果」所需的元素，并且算术、条件分支等恰恰是百余年后阿兰·图灵证明其关于计算力量的结果所需要的元素。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;仅在代表它们的机械行为中，你不能在 Babbage 的机器中指向一个变量或一个附加指令。在 20 世纪 60 年代，曾经 Lovelace 只能用来应对官方解释的抽象已被改进得更加精良。牛津大学的 Dana Scott 和 Christopher Strachey 等计算机科学家使用单一抽象来对机器和运行的程序建模，使得精确的数学推理能够预测其行为。这些概念已经进一步完善，如计算机科学家 Samson Abramsky 使用先进的逻辑和数学来捕获更微妙的抽象，不仅可以用于经典计算机，也可用于量子计算。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为实际问题确立一个优质的抽象不仅是一门科学，也是一门艺术。确立过程需要捕捉问题的构建块和连接它们的元素，这些元素应具有恰到好处的细节量；确立过程提取的是远离块内部复杂区域的部分，所以设计者只需关注与其他组件交互所需的元素即可。Jeannette Wing 将这些技能描述为计算思维，而这个概念可以在编程之外的许多情况下被指出。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Lovelace 发现了更广泛的抽象力，希望通过发展「利用法则建立大脑分子的相互作用」来理解神经系统，实现自己的理想。并且如今的计算机科学家确实在为此扩展技术开发并建立合适的抽象。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Samuel Arbesman，复杂性（Complexity）科学家；拉克斯资本公司（Lux Capital）住宅研究方面科学家；《Overcomplicated》一书作者&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;科学主题：自产生程式/奎因（Quines）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在计算机程序的无限空间中有一个特殊的代码子集：当执行程序时输出该程序本身。换句话说，这是一些自复制程序；当你运行它们时，它们会输出自身。这些短小的程序通常被称为「自产生程式/奎因（quines）」，来源于哲学家韦拉德·范·奥曼·奎因（Willard Van Orman Quine）的名字，基于侯世达（Douglas R. Hofstadter）所著的《哥德尔、埃舍尔、巴赫：一条永恒的金带（Gödel, Escher, Bach: an Eternal Golden Braid）》一书中的术语。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Quines 一词给人的第一印象往往显得不可思议。你要是曾经写过代码就更会有这种感觉，因为如果你不了解创建 quines 的技巧，便可能会觉得难以构建。它们往往是优雅的小东西，而现在有大量的计算机语言写出了各种各样的 quines 案例，从简短可爱型到不可思议之长。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不过它们为什么如此重要呢？quines 是计算机科学、语言学及其他学科思想的精华。简单点说，quines 可以被认为是定点，即数学中的 fixed point：一个输出自身而保持函数值不变的数学函数的值（想想 1 的平方根为什么仍然为是 1）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不过我们可以进一步地讨论一下。Quines 表明计算机所产生的语言既可以是操作符也可以是操作数——一个 quine 文本运行并通过一个向自身反馈的过程输出原始代码。文本可以是有意义的单词，也可以是「有意义的单词」，思考这个句子「This sentence has five words.」，我们很高兴地看到，此句中的单词不仅是在描述（充当一个操作符）也是在被描述（充当一个操作数）。不过这个文字游戏也很有用。文本和功能之间的这种关系是 Kurt Gödel 在不完备性数学研究中用到的一个基本组成部分，而这又与阿兰·图灵在解决停机问题时所用的方法有关。这些基本思想显示出数学和计算机科学中的某种局限性：我们不能证明某些陈述在一个给定系统中的对与错，并且也没有任何算法可以确定任何给定的计算机程序是否将会永远地终止运行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;更广泛地说，quines 还表明了复制（reproduction）行为不是生物领域所独有的。就像一个细胞利用物理及化学规律来生存和繁衍一样，一个 quines 会添加一门编程语言的规则来执行代码。虽然它并不完全复制自身，但其工作原理是相似的。你甚至可以进一步在某个「辐射硬化（radiation hardened）」quine 中发现这种生物性质的迹象：在这种 quine 中，任何字符都可以被删除，而它仍然可以进行复制！对我们中的许多人来说，辐射硬化 quine 听起来无疑就像基因的 DNA 序列那样令人费解。冗长与坚固——生物学的标志——在有机体与计算机中输出的是相似的结构。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;冯·诺依曼（John von Neumann）是计算机界的先驱之一，他在机器的自我复制方面做过大量的思考，把从计算早期开始研究的技术与生物学结合起来。我们仍然会在小段的 quine、小段的计算机代码中看到，它们通过其微小的努力将各个领域一个接一个地缝合起来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Sean Carroll，加州理工学院理论物理学家；《The Big Picture》一书作者&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;科学术语：贝叶斯定理（Bayes's Theorem）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你担心朋友生你的气。你设了一个晚宴而没有邀请他们；这就是那种会令他们不开心的事情。但你并不确定。所以你给他们发了一条短信：「今晚想出去吗？」二十分钟后你收到一个回复：「不能，忙。」我们怎么解释这条新信息？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然部分答案可以归结为人类心理学。但其中一部分是统计推理的一个基本原理，称为贝叶斯定理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当我们不确定某些命题的真假时就会寻求于贝叶斯定理，而新信息会影响该命题为真的概率。这个命题可以是朋友们的感受、世界杯结果、总统选举结果，或有关早期宇宙活动的特定理论。换句话说：我们真的一直在使用贝叶斯定理。可能是以某些正确或不正确的方式，但它无处不在。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该理论本身理解起来不是很难：给定一些新数据，一个命题为真的概率正比于其在数据出现之前就为真的概率乘以该命题为真时出现该新数据的可能性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此它有两个影响因素。第一个是先验概率（prior probability），即我们在收集任何新信息前就确定某一想法的概率。第二个是在该想法为真时所收集的一些特定数据的可能性。贝叶斯定理认为：不同命题在新数据收集过程之后的相对概率就是二者的乘积。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;科学家们总是以精确、定量的方法使用贝叶斯定理。但这个定理——或实际上是构成其基础的「贝叶斯推理」这个思想——无处不在。在你给朋友发短信之前，你已经知道他们有多大可能会生你的气。换句话说，你对「生气」与「不生气」的命题有一个先验预期。当你收到他们的回复时，你含蓄地对这些概率做了一个贝叶斯更新（Bayesian updating）。如果他们生气，那么他们有多大可能会发送这样的回复？要是他们不生气呢？乘以适当的先验概率，有了新信息后，现在你就可以明白他们生气的可能性有多大。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这一条纯统计学逻辑背后潜伏有两个伟大而深刻、足以塑造世界观的思想。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个是先验概率的概念。不管你承认与否，不管拥有什么样的数据，你都隐约会对所能想到的每一个命题持有一个先验概率。如果你说，「我不知道它是真是假，」那么其实你是在说「我的先验概率是 50%。」并且其设置过程不涉及客观的、事先准备好的步骤。人与人之间想法差别巨大。对某个人来说，一张看起来像是鬼魂的照片无疑是人死后生命的凭证；对另一个人来说，它更可能是伪造的。无论我们以何种先验概率开始思考，给定无限量的证据和完美的理性，我们都应该会趋于相似的信仰——但没有无限的证据，理性也并不完美。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一个伟大的思想是，你对一种思想的信仰程度将永远不可能是 0 或 1。对某些数据的收集永远不是绝对不可能的，无论真相是什么——即使最严格的科学实验也容易出错，而大多数日常数据的收集根本算不上严格。这就是为什么科学从来没有「证明」什么；我们只是增加了对某些思想的凭证，直到它们几乎（但不完全）达到 100%。贝叶斯定理提醒我们在面对新信息时应当保持思想的开放性，而且它会告诉我们到底需要什么样的新信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Ian Bogost，Ivan Allen 学院媒体研究名誉主席，乔治亚理工学院交互式计算教授；Persuasive Games LLC 创始合伙人；《The Atlantic》特约编辑&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;科学术语：概率空间（possibility space）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有些问题很容易，但大多数问题都很难。它们超越了人类掌握和推理可能答案的能力。不仅仅是复杂的科学与政治问题，例如制定复杂的经济决策或建立模型以应对气候变化，日常生活也是如此。「今晚去吃晚饭吧。」「好啊，但是去哪呢？」这样的问题很快就陷入了无结构形式的存在主义危机（existential crisis）。甚至是，「我是谁？」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数学家思考复杂问题的一种方法是利用可能解的概率空间（possible solutions，有时也称为解空间/solution space 或 probability space）在数学中，概率空间被用作一个寄存器或所有可能解的分类帐目。例如，掷一枚硬币的概率空间是头或尾。对于两枚硬币：正面-正面、正面-反面、反面-正面、反面-反面。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是一个相对简单的例子，因为任何概率空间的给定子集都可以被测量和记录下来。但在其他情况下，概率空间可能非常大，甚至无限大。例如宇宙中可能存在的生命形式，或可能的未来进化分支。或是可能的围棋游戏。甚至是你能够用一晚上的时间所能做到的所有事情。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这些情况下，要完整地描绘概率空间不仅很难或根本不可能做到，而且往往连尝试甚至都毫无意义。一个经济学家可能会依据某些行为的相关效益成本而从其净边际效益（net marginal benefit）中建立一个可能外出吃晚饭的模型，比如看一部电影、骑一次自行车或吃一份惠灵顿牛排，但这种做法假定了日常生活中所不存在的理性主义。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在游戏设计中，创作者经常将自己的工作看作是为玩家创造概率空间。在源自古代中国的围棋游戏中，棋子、棋子摆放规则以及一块棋盘为整个对弈提供了一个非常大的概率空间。但每个人的行动都会越来越受限——依赖于每位棋手的先前决策集。否则棋手就不能移动一步。任何人都不能在所有围棋比赛的全部数学概率空间之内下棋，却可以在——于给定的时间点、给定的棋盘上所进行的可能且合乎规则的移动步骤中——更窄的概率空间内下棋。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一些设计师尊崇围棋和象棋类游戏的数学帮助，希望用最少的元素创造出最大的概率空间。但更多时候，令一款游戏在美学上显得独特的东西不是数学上的大或深，而是其组成元素及其可能配置有多么有趣而独特。俄罗斯方块只有七个不同的元素，所有元素以相同方式运作。俄罗斯方块的乐趣来自于学习在各种情况下识别和操作这些元素。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;积极且慎重地去限制一个概率空间的练习效用远远超出了科学、数学和游戏设计。每种情况都可以通过确认或强加限制以产生一个可行的、可操作的可能行动领域而被更加慎重且卓有成效地解决。这并不意味着你每次启动洗碗机或与朋友进行通宵辩论时都必须制定效用图表。而是说，任何问题的第一步都得承认，现有的大量限制已经存在，正等待被确认和激活。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在面对巨大或无限大的概率空间时，科学家们试图强加一些限制以创造可测量且可记录的工作。例如，一个生物学家可以通过限制对一定规模和组成成分的恒星或行星的请求来建立一个可能存在外星生命的概率空间。当你为一顿晚饭的选址进行争论时也会这样做——即使你在正常情况下不这样想：你喜欢什么样的食物？你想花多少钱？你愿意跑多远？要决定其中的一两个问题往往会产生一些进步。而它在避免进入一个存在主义螺旋中时也是这样做的，向内心深处寻问你到底是谁，或人类选择的终极来源：你真正想要的是什么。在日常生活中，就像在科学中一样，答案已然存在于世，比它们在你头脑中被发明的都要多。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Scott Aaronson，德克萨斯大学奥斯汀分校计算机科学 David J. Bruton 的荣誉教授；《Quantum Computing Since Democritus》一书作者&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;科学术语：态（State）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在物理学、数学和计算机科学中，系统的状态是封装所有你所需要的预测它将做什么，或至少预测它做这件事而非另一件事的概率的信息，来响应任何可能的刺激。从某种意义上说，态是一个决定系统在表面外观下的行为的「隐藏现实」。但在另一种意义上，没有什么隐藏的态——对于从不重视观察的态的任何部分，都能够用奥卡姆剃刀原理（Occam』s Razor）将其切割，来产生更简单、优质的描述。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这样看来，「态」这个概念似乎很明显。那么，为何爱因斯坦，图灵和其他人还会在这个概念上，在走向人类最难得的知识胜利的道路上奋斗那么多年？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;一起来看几个迷题：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果要添加两个数字，计算机显然需要一个包含着添加说明的添加单元。但是，它还需要一些说明解释这些说明，而后它便需要说明来解释这些说明的说明……所以我们得出结论，添加数字对于任何范围有限的机器来说是不可能的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;根据量子重力的现代理念，空间（space）可能并不是根本，而是对普朗克量级自由度的量子位（qubit）网络的描述。我曾有过疑问：倘若宇宙是一个量子位的网络，那么这些量子位在哪里？它们是不是没有意义（例如，假设两个量子位是「邻居」，却没有预先存在的空间来使量子位成为邻居）？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;根据狭义相对论，可知光速最快。但假设我翻转一枚硬币，将结果写在两个相同的信封中，然后将一个信封放在地球上，另一个放到冥王星。接着，我打开地球上信封的瞬间，改变了冥王星上信封的状态，从「正面和反面可能性相同」变成「绝对是正面」或「绝对是反面」（我们可以看到，这种类型的量子纠缠甚至成为了经典谜题）！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关于计算机的谜题是我与非科学家知识分子进行无数次辩论的一个话题。我认为，分辨率可以指定计算机的状态，涉及到要添加（编码，如二进制）的数字，和横跨数字的添加和携带、由布尔逻辑操控并最终通过物理定律实现的有限控制单元。你可能会问：物理定律本身是什么？无论对于这个问题有什么答案，它的基础在哪里？这些都是我们的问题；同时，计算机工作所需要的一切都包含在它的态中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;这个关于量子位的问题是许多其他问题的附加问题：例如，如果宇宙正在扩张，那么它正扩张到哪里？这些问题未必不好。但从科学的角度来讲，一个人完全有理由回应：「你在建议我们在世界的态上创建新事物，比如扩张或寻找我们的第二个生存空间。那么这第二个空间对观察有什么影响？如果永远不会有影响，为什么不把它切割出去呢？」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关于信封问题，可以通过认为你在地球上决定是否打开信封不会影响观察者在冥王星上感知信封内容的概率分布来解决。如此便可以证明一个定理——即使地球和冥王星之间存在量子纠缠，类似的事实在量子情况下同样成立：在这里你选择做的任何事情都不会改变局部量子状态（即密度矩阵）。这就是与爱因斯坦的担忧相反，量子力学与狭义相对论相一致的原因。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;这种情况下，相对论、量子力学、计量理论、密码学、人工智能以及其他 500 个可能的领域都可以总结为「没有差异的区别不能算作区别」。这个总结可能会使一些读者想到 20 世纪早期的逻辑实证主义教义，或者想到波普尔所坚持的理论：从不冒险伪造预测的理论都是伪科学。然而我们没有必要冒险做出关于实证主义者或波普尔究竟是否正确的复杂辩论（或者实证主义本身是实证主义的还是可伪造的）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们只要记住一个简单的道理就足够了，那便是——世界真实存在于我们的感觉之外，但我们不能坐在扶手椅中便说出它的态由什么组成。我们的工作是围绕最优的科学理论创建本体，而不能本末倒置。也就是说，我们应实时修改对于「实际存在」的概念，将我们所发现的可以通过观察来区分的新事物包含进来，并排除不能区分的事物。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有些人发现把自己的本体限制在态的程度似乎远远不够，只达到解释观察的程度。但考虑到替代时，Charlatans 这个种族主义者的每个有说服力的忠告都在不断地激励我们超越系统的态，到达它隐藏的本质，并在没有要求的地方做出区分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;甚至在自由意志中的许多困惑也存在对「态」概念的不清晰。许多人认为，根据物理学，你未来的选择由宇宙的当前状态所「决定」。但这忽视了一个事实，即无论何种物理学都需要与该主体契合，宇宙的当前状态总会被认为秘密地决定未来的选择，而这确实是隐藏变量所解释的量子力学，如 Bohmian 力学。对我来说，这使得「决定（determination）」这一概念在这些讨论中几近空洞，而实际的可预测性更为重要。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;态是应当广为人知的科学概念，因为在我看来，这其中蕴含着全部的科学世界观。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Joshua Bongard，佛蒙特大学威诺德计算机科学教授，《How the Body Shapes the Way We Think》一书作者&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;科学术语：符号接地问题（The Symbol Grounding Problem）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;阿兰·图灵二战期间的合作者 I.J. Good 曾经写道，比人类更聪明的机器将是我们所做的「最后发明」。许多人认为社会将走到这一步，因为智能机器正愈加侵入我们的日常生活和想象力，而这种入侵正沿着两条战线前进。这些机器愈发被扣上诱发经济变革的帽子，导致一些人质疑工作的必要性。但更深层的是，我们不知道这样的超级智能机器是否会「和我们一样」：他们可能会思考，但他们有感觉吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;为了帮助锚定后面的问题，Stevan Harnad 提出了符号接地问题（symbol grounding problem）。对机器而言，通过将所听到的单词直接转换为口语来学习构成人类语言的符号的意思是有问题的。这就像试图使用词典学习埃及象形文字，其中每个象形文字是使用其他象形文字定义的。下面来看我刚刚与网络上功率最大的聊天机器的交流内容：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我：你好。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;它：你好，最近过得怎么样？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我：不错啊，你呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;它：我过得很好，谢谢。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我：我最近一直在思考。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;它：思考什么？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我：符号接地问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;它：你可以给我讲一个令人开心的故事吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;符号接地问题的解决方案是使符号在物理经验丰富的土壤中接地。例如，机器人可以知道符号「跳跃（jump）」与其脚底压力的突然消失有关。这个机器人可以通过让一个人跳跃，观察她的双脚离开地面，并推断这个人类的感觉与它在跳跃时的感觉相同来与人类共情。最后，这样的机器可以递归地将已接地的符号中越来越抽象的符号接地，直到最终它可以在第一次听到成语「don』t jump to conclusions」时理解为「三思而后行」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;公众理当关注这个看似神秘的认知科学角落，因为不以这种方式将符号接地的机器会很危险。来看我与这个聊天机器的交流：它不仅不知道它最后的回复是「错误的」，也没能预测我对于它的回复会感到沮丧还是开心。同样，另一台机器也可能无法预测我对于它的行为的恐惧反应。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如今机器可以在接收到一百万张包含人类的照片和另一百万张不含人类的照片之后，不必经历接地符号便可分辨新照片是否包含人类。但换成由两百万段对话组成的数据集：第一百万中，演讲者正在讨论如何最好地帮助 Bob; 在第二百万中，他们在密谋伤害他。就算目前最先进的机器也不能分辨一个新的对话中的发言者是想帮助还是伤害 Bob。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大多数人可以通过听一段谈话来预测被讨论的人是否处于危险之中。因为我们在现实生活、书籍和电影中听过足够的讨论，从而能够延伸至当前的谈话，而不像在之前未见到的照片中识别人类的计算机，所以我们也许可以对电脑也这样做。然而，我们也可以通过连接词，图像和亲身体验来感同身受：我们可以处于谈论 Bob 的人的立场中或 Bob 自己的立场中。如果一个人说「善有善报」，并伴以一个讽刺的嘲笑，我们可以提取这些语言符号（「一个」，「好」，...）且结合视觉提示，并做一些心理模拟。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先，我们可以回溯并假装自己是 Bob，并想象他/我们的行为减缓了讲话者的饥饿或消融了另一个身体或情感的痛苦。然后我们做回自己，想象她会说的话。我们不会像她那样做出讽刺的嘲笑，我们的预测失败了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以我们再次想象自己是 Bob，但这次精神上模拟在某种程度上想要伤害讲话者。在此行为期间，我们再转变为讲话者并遭受她的痛苦。回到现在，我们想象自己说同样的话，并且预期中报复的感觉出现了，于是我们做出冷笑来匹配讲话者的嘲笑。故而我们预测，讲话者想要伤害 Bob。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;神经科学越来越多的证据表明，听到的词点亮了大部分的大脑，而不仅仅是某些本地化的语言模块。这会不会表明一个人扭曲的话、行动、自己之前的感受经历和精神抢到了感官/行动/经历的编织电缆？这些电缆可以作为从他人的行为和感觉转到我们自己的行为和感觉，而后再返回去的桥梁吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些机器可能是有用的，甚至能够共情。但它们会有意识吗？意识是目前科学无法达到的，但我们可以思考。倘若我「感觉」你的痛苦，主体和客体是清晰的：我是主体，你是客体。但倘若我感到自己脚趾的疼痛，主体和客体的区分便不那么明显了。或者他们是一致的？如果两个人能够通过彼此的共情相连，当我伤害自己时，我的大脑的两个部分不能共情吗？也许感觉是动词而不是名词：它们可能是细胞群之间的特异性交换。那么，意识可以不仅仅是一个更小的上接接地符号的感觉/运动/经验的分支的分形安排吗？如果神话告诉我们地球是平的，并且放在一只巨龟的背面，我们可能会问什么拿着乌龟。答案当然是：一直都是乌龟。所以也许意识也一直只是细胞群之间的同感。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Roger Highfield，Science Museum Group 外事部门负责人、 Supercooperators 作者之一、复杂度前沿者&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;科学术语：可以采取行动的预测（Actionable Predictions）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;对显而易见的事根本不值一提的想法一般不会被怪罪，更不用说它即将成为一种文化越来越流行。毕竟，「pre」意味着「以前」，因此毫无疑问你应该在得到预测后采取行动来改变你的未来——举个例子，就像大雨要来了买伞一样。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;天气预报确实是一个促使你采取行动的预测的例子，是从卫星和各处传感器汇总过来的数据与模型的完美结合。但是当你的视线从物理科学转移到医学，这些预测却很难辨别。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;在医生能够针对每个患者做出规范的、可信并能够采取行动的预测上，我们仍有很长的路要走——哪种治疗会对患者的帮助最大，哪种药会对患者的副作用最小等等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;很遗憾，对于很多简单的问题，答案依然不易捉摸。我应该因为嗓子疼而吃抗生素吗？免疫疗法对我管用吗？那个长长的药品副作用清单中的哪部分应该引起我的注意？对我来说最好的食谱安排是什么？如果我们能像气象学家预测明天的天气那样预测出每个患者需要的答案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;今天很多人讲大数据可以提供所有答案。在生物学上，举个例子，曾经，人类基因工程所得到的数据曾经为我们带来了很大的希望和愿景——如果我们获得一段病人的 DNA 序列，我们可以预测它们最后的衰亡。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;抛开基因组的扩散、表观基因组、蛋白质组和转录物组不谈，情况已经比预想的糟糕了，最初有关个性化定制的基因药物的梦想已经降格成了精确药物，在这里我们假定一个特定的人会与之前研究过的基因相似的人群相同的药物反应。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;生物学领域里盲目地搜集大数据依然盛行，不过重点突出变换技术，比如机器学习—人工神经网络—来发现所有数据中有意义的特征。但不管它们多「深」多复杂，神经网络仅仅是尽可能适配了可用数据的变化曲线。它们也许能做插值，但对于超过训练范围的外扩，效果依然让人忧心忡忡。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;数据的量并不是能成为解决问题的全部。我们是收集了很多数据，但是我们收集到保质保量的数据了吗？我们能从一系列错误的关联关系中分辨出有用信号吗？假定身体是动态且不断变化的，数据的即时记录样本真的能记录下生命的全部复杂性吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;为了得到医学上有效的预测，我们同样要在生物学的数学建模中进行一个改变，这改变很好理解：细胞是非常复杂的，更不用说器官和身体了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;我们应该增加对复杂系统的研究兴趣，以使得我们能预测单个病人的后续发展。而不是从早期传播研究中推断应该存什么，谁开的新处方，谁没有，谁有严重的副作用。我们需要更深入的探究，至少不能到死后尸检的程度，这可以防止成千上万的人免于人为医疗事故的伤害。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;最终我们需要在医学理解的基础上更好的开展建模，只有这样，终有一天，你的医生可以在你的数字分身上做实验，而后才是你。现代医学需要更多的可操作的预测。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Daniel Rockmore，达特茅斯学院 Neukom 计算科学学院主任、数学教授、计算科学 William H. Neukom 1964 终身杰出教授&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;科学术语：电车问题（The Trolley Problem）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;科学的历史是由各种各样的「思想实验」堆成的。「思想实验」这个词是爱因斯坦想出来的，它的意思是针对一个虚构的场景，在这个场景中能够精精准的表达一些难于思考的问题症结，以这种方式能够激发一些就此问题的深度思考最终得到解决方法或者相关发现。这些「思想实验」中最著名的是爱因斯坦的「追光传说」，最终促使他发现了狭义相对论。还有薛定谔的猫，它被困在一个刻意严格设计的量子机械盒里，永远半生半死，这更加明晰地揭示了波动理论机理与测量间的复杂交互关系。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「电车问题」是另一个思想实验，它源自于道德哲学。它有许多的流传版本，这就是其中一个：一个有轨电车沿着铁轨行驶，遇到了一个铁轨分叉点，其左方向上，有一个人被困在铁轨上，右方向上则是五个人。你可以改变分叉点以使电车从朝向五个人的方向变为一个人的方向。你会怎么做？这个电车无法刹车。如果铁轨上的人中有我们的熟人我们会怎么办呢？也许如果其中一个是儿童而另外五个是成年人呢？又或者是其中一个有孩子而其他五个是单身呢？所有这些不同的场景如何来决定事情的发展变化呢？什么是至关重要的？你更珍视什么以及为什么？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是一个有趣的思想实验，但在很多时候远不是这样仅仅有趣而已。鉴于我们正逐渐将我们的决定赋予管理这些事情的机器和软件，开发人员和工程师将要做越来越多这样需要解析那些重要并很有可能潜在关乎生死的决策机制的事情，并把这些事情直接编码给机器。决策机制来源于一种价值评估系统，一种「效用方程」，在这种系统中我们决定做这件或那件事原因在于这样做比其他选择能获得更大的价值。有时这种价值评估看上去很平常且显而易见——推荐给你这个食物搅拌器而不是那个是因为你有更大的概率买这个，这是基于各种各样历史上的购买数据得出的结论。这双鞋比其他的更好卖（或者不算更好卖但起码因为它某些方面利润更高所以值得一试——这使得我们愿意计算概率和期望的回报）。这首歌对比那首歌等等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;但有时在紧要关头它会更重要：是这条新闻还是那条？更广泛意义上来说，是这件事的这条信息还是那条信息？嵌入价值评估体系的程序可以开始评估你的价值了，并以此类推以至于整个社会的价值。有一些是价值相当大的决策赌注了。电车问题告诉我们价值评估体系渗透在编程的方方面面，甚至有时关乎生命：很快我们会有无人驾驶的电车、汽车、卡车。当糟糕的事情发生了，决定就需要做：事故车道上的骑车少年还是停在前面车里的世界 500 强公司的 CEO 和他的助理？你的算法会怎么做以及为什么这么做？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们终将制造出无人驾驶汽车而它们也一定会具备道德指南。我们的机器人伴侣也是一样的情况。它们会有价值评估体系且必然是受道德约束的机器，而它的道德和伦理是由我们设计的。「电车问题」是我们时代的思想实验，它是我们新人机时代工程高度复杂的光辉体现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Bruno Giussani，TED 欧洲办事处主任及全球活动策划人&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;科学术语：指数（Exponential）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（有关指数的这一小故事）已经不清楚当时用来计数的是米粒还是麦粒了，由于故事有很多版本，我们对故事的起源也不太确定。但故事的内容大致是这样：国际象棋的发明者向国王展示了有趣的象棋游戏，国王甚是开心，便要求象棋发明者自己点名要奖赏。象棋发明者谦虚地要了些米粒（或者是麦粒），具体数量通过最简单的公式计算得出，即第一个格子 1 粒，第二个格子 2 粒，第三个格子 4 粒，依次往下格子中谷粒的数量翻倍，直至第 64 个也就是最后一个。国王欣然同意，直到发现自己已经受骗。到棋盘一半时，国王的城堡就几乎不够存放谷物了，但剩下棋盘中的第一个格子就会将谷粒数量再翻一倍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从 13 世纪的穆斯林学者到物理学家/作家卡尔·萨根（Carl Sagan），再到社会传媒界的电视录像制作人无不引用该故事来阐释指数序列的威力，事务起于微小，非常微小，但之后一旦开始增长，就增长地越来越快—按欧内斯特·海明威（Ernest Hemingway）的说法：成长缓慢，然后突然暴涨（they grow slowly, then suddenly）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;每个人都应该更深刻地知道并理解指数及其衍生（棋盘寓言是一个非常实用的比喻），因为我们生活在一个指数世界。实际上，这种情形已经存在一段时间了。但是，目前为止我们处在棋盘的上半部分，也就意味着由于我们即将进入棋盘的下半部分，事物将急剧加速发展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1999 年雷·库兹韦尔（Ray Kurzweil）在他的著作《灵魂机器的时代》（The Age of Spiritual Machine）中提出了「后半个棋盘」的概念。他指出，尽管指数在前半个棋盘时重要，但正是在进入后半个后其影响变得巨大，事情变得疯狂，其加速度开始远超人类的想象和控制。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;15 年后，Andrew McAfee 和 Erik Brynjolfsson 在《第二次机器时代》中通过对比摩尔定律来讨论库兹韦尔的观点。戈登·摩尔（Gordon Moore）是仙童公司（Fairchild）和英特尔公司（Intel）的联合创始人，这两个公司是硅谷很有开拓性的公司。回顾硅晶体管刚发展的前几年，在 1965 年摩尔做出了一个预测，在给定的成本下，大约每 18 至 24 个月，计算能力会翻一番。换句话说，也就是呈指数级增长。摩尔的预测已经维持了数十年，对科技与商业带来了巨大的影响，尽管近些年节奏有一点点放缓——需要指出的是摩尔定律是一个产业规律的洞察定律，而非物理定律，而且，我们很可能从晶体管时代迈进量子计算的时代，而后者依赖粒子来进行计算。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;McAfee 和 Brynjolfsson 认为，如果我们把摩尔定律的起始点定为 1958 年，即第一个硅晶体管商业化的时间，那么依指数曲线，从数字技术的角度看，我们进入棋盘第二部分的时间是 2006 年（这种观点是考虑到，人类基因组第一次绘制完成是在 2003 年，当前智能手机操作系统启动是在 2007 年，同一年 IBM 的 Deep Blue 在象棋比赛中打败了 Garry Kasparov，同时耶鲁大学的科学家开发出第一个固态量子处理器是在 2009 年。）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此，我们会发现我们自己正处于棋盘第二部分的第一个，可也能是第二个格子中。这有利于帮助我们理解我们所见的在科技领域发生的引人注目的高速进步，这些进步表现在从智能手机、语言翻译、区块链到大分析、自动驾驶和人工智能的领域，从机器人学到传感器，从太阳能电池到生物技术，再到基因组学和神经学及更多其他领域中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当这些领域中的每一个其自身都呈指数级增长时，它们的组合效应——每个对其他领域的加速性影响是巨大的。另外还要加上人工智能系统自我改进能力的空间以及我们正在聊的近乎不可思议的改变速度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;还是以最初的棋盘寓言作为比喻，进入棋盘的第二半部分意味着:到目前，谷粒是以越来越快的速度累积着，但还在国王城堡能容纳的限度内。但之后格子的谷粒就会淹没这座城市，然后淹没这片土地，这个世界。之后仍然有 32 个格子还要走，所以这将不是一个短暂的转变期，而将是一个长期、深度、史无前例的剧变。这种发展将带领我们进入一个物质丰富，并以技术为驱动的新兴时代，我们的权利和/或希望与坠入无法控制的黑洞等其他忧虑一样多。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然，我们仍然生活在一个对其大部分都不甚了解的世界，这部分也不适用于指数规律。基本上社会运行的每一结构和方法——政府机关、民主、教育和医疗系统、法律和规范性框架、出版业、公司、安全防范设施，甚至科学管理本身都被设计为在一个可预测的线性世界发挥作用，在此，猛然上升或下降被看作为危机。因此，我们几乎每天都在见证的各种指数级变化所带来的从政治到社会再到心理学方面的忧虑及压力也就不足为奇了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在没有深入思考，深思熟虑和细致入微关注的情况下，我们该如何以指数式思维思考问题？在棋盘第二半的现实条件下，社会该如何运行？在指数型社会中，政府治理与民主的意味着什么？我们又该如何重新审视从教育到法律框架再到伦理与道德理念的诸多事宜？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些事情都开始于对指数和「后半个棋盘」的比喻更好的理解，以及将这种「后半程思考」的思维方式施加到几乎所有事情上所带来的结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 25 Jan 2017 12:24:58 +0800</pubDate>
    </item>
    <item>
      <title>前沿 | D-Wave再度升级：研发出2000量子比特量子计算机</title>
      <link>http://www.iwgc.cn/link/4482150</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Nature&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;参与：微胖、朱思颖&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;要发掘出量子计算的真正潜力，我们可能还需要再等几十年，而 D-Wave 正在向着这个目标大步迈进，2016 年，这家公司承诺将在明年推出其已经得到了大幅改进的量子处理器。（&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719333&amp;amp;idx=1&amp;amp;sn=468fef3ccbeab4a270095b5dd635ea25&amp;amp;chksm=871b001bb06c890d14a1f254c517d1d6916e3cf69be9c79b8b4a9eb127b2eeda447edb063203&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719333&amp;amp;idx=1&amp;amp;sn=468fef3ccbeab4a270095b5dd635ea25&amp;amp;chksm=871b001bb06c890d14a1f254c517d1d6916e3cf69be9c79b8b4a9eb127b2eeda447edb063203&amp;amp;scene=21#wechat_redirect"&gt;量子计算大跃进？D-Wave 将于明年推出 2000 量子比特芯片&lt;/a&gt;）。目前，公司发布的最新机器模型已达 2,000 量子比特。虽然有关 D-Wave 最终潜力的质疑不绝于耳，但是，研究人员已在寻找这一机器的用武之地。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicfJFax3rHUWXK8QUmf7aiaiaQLdXuOj0kCp67ltO5DIlPRwyU7BicfX0Byz3hciaLde9AXHI4FbGVQVQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;D - Wave 最新处理器可以处理 2,000 量子比特，远超之前的模型能力。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这家打造世界上唯一商用量子计算机的公司已经发布了到目前为止，公司最大的机器，而且研究人员也正在密切关注着。加拿大 D- Wave 公司用处理器的量子比特数命名的这台 2000Q，其能力远超之前模型。不同于其他尚出初期的量子计算机，长远来看，D-Wave 这类机器潜力如何，不少研究人员仍持怀疑态度。不过，也有其他研究人员已经认为用 D-Wave 解决机器学习、网络安全等难题已指日可待。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而且这次升级到 2000Q，亦即公司的第四代机器，已经大量吸取了研究人员反馈。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;NASA 阿姆斯研究中心的物理学家 Davide Venturelli 说，「我们正以科学家团体的身份对他们进行指导」。Davide Venturelli 正负责管理一个由非盈利组织——位于华盛顿的大学太空研究联合会（Universities Space Research Association，USRA）运营的计划，旨在让外部研究人员接触到一台 NASA 和谷歌共同拥有的 D-Wave 计算机。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;据悉，D-Wave 也正在研发第五代模型，有望解决诸如更大功能、更多连接性等问题，希望能更加满足科学家研究需求。这一模型的研发工作可能在两年内启动，并再度翻倍既有量子比特数，达至 4，000 量子比特。关键是，新模型还能提供更加复杂的量子比特连接，让机器具有解决更加复杂问题的能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;位于布拉格的 Charles University 物理学家 Mark Novotny 说，「改变底层连接会改变游戏规则，」他正在研究如何将 D- Wave 应用到网络安全上，「基本上，我很渴望实现这一点。这太激动人心了。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;六年前，当 D- Wave 上市后，这台机器不仅让众人惊喜，也招致了不少怀疑。到目前为止，研究人员已经证实，对于某个契合这台机器能力的问题来说，量子计算机会大大提升处理该问题的速度，力压传统算法（V. S. Denchev et al）。但是，这类机器并没有在每种传统算法上击败传统对手，人们还没有发现在解决哪个问题上，这类机器比所有传统对手表现更好。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;较之于在更加传统的量子计算中建造量子比特，D-wave 要容易多了，但是，其量子状态也更加脆弱，控制精确性也更弱些。因此，尽管科学家现在认为 D-Wave 确实在计算过程中利用了量子现象，但是，一些人仍然怀疑这个办法在解决真实世界难题上，其速度会快过传统计算机——无论许多量子如何协作，也不管其布局如何。不过，不确定性无法阻止用户数量增长：去年九月，大约 100 名科学家参加了 D-Wave 首批用户会议，大会在新墨西哥州的圣达菲举行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现有的 D-Wave 计算机都在美国，不过，全球研究人员都能远程接触到它们，包括参加诸如 USRA 这样的项目。计算机也正在吸引着新的研究人员，Venturelli 说，他正在尝试用 D-Wave 找到探测器自动安排运行时间、管理时间的最佳方法，他说，「现在，那些不涉及量子物理研究的大学也在尝试它们的算法。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;和其他量子计算机不同，D-Wave 仅用来解决某个问题，诸如优化问题。为了找到最优解决方案，研究人员首先将由超导回路（superconducting loops）打造的量子比特置入其最低能量状态，在这一状态下，每个都处于一个「开」、「关」叠加状态。然后，表征问题的磁场会轻轻将这一状态推进到一个新的状态下——亦即所谓的量子退货法。状态不断演进的同时也持维持着低能量状态，这样，当最终发生「坍塌」时，量子比特就能处在用来解决问题的最佳配置状态。因为系统会立刻筛选每个可能的答案，理论上，它就能以更快的方式解决难题，如果使用传统计算机解决这个难题，每增加一个变量，解决问题的难度会呈指数增长。但是，能以机器可以处理的方式提出研究问题意味着使用几个量子比特来表征某个单独变量，限制机器可以处理的问题的规模大小。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicfJFax3rHUWXK8QUmf7aiaia724sMwURZm46a9sM2cgu8cXEgTfYV2CF8lKzqA5lfvm68gfH5tAibRQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;一台 D-Wave 机器正在研究星球探测车如何能自动进行任务、时间管理。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Novotny 说，「量子计算是一个新工具，所以，我们目前工作的一部分就是试图找到新工具的使用方式。」他正在研究机器学习算法（波兹曼机），用它来研究在线浏览量模式，识别出网络攻击。到目前为止，他的团队已经可以证明，对于小型样本，在识别诸如可能的网络攻击等方面，D-Wave 要比传统对手更高效，也更快速。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;D-Wave 最新迭代包括一个 Novotny 呼吁过的升级。当不同量子比特组经历退火过程时，这一升级后的特征能增加过程的可控性。D-Wave 已经表明，至少在一个例子中，它将某次计算速度翻 1，000 番。对于 Novotny 来说，这一功能很关键，这样，他的团队就能在过程中「取样」量子比特，也为利用 D-Wave 探索不同类型的机器学习算法（识别更多复杂的网络攻击模式）打开了一扇门。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是，研究人员期待更大连接性。Scott Pakin 是位于新墨西哥洲的**洛斯阿拉莫斯国家实验室的计算科学家，也是 D-Wave 科学技术负责人，去年八月，他拥有了一台 D-Wave 计算机。他说，**目前，处理器只能实现每六个量子比特之间的对话，「连接越丰富，用 D-Wave 解决问题就更容易，也更快。所以，这也是我最期待的一点。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;D-wave 正在重新设计其第五代处理器来大幅提升联结度，D-wave 负责技术的高级副总 Jeremy Hilton 说道。同时因为这次的提升涉及到硬件的彻底检修，新一代处理器将具备一个额外的好处：允许公司超越当前处理器设计设置的 10，000 量子比特的限制，他补充说。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;距离 D-wave 倡导者所希望看到的——量子计算机运行速度是普通计算机运行速度的指数倍这一愿景，还有很长一段路要走。但是，一篇于 1 月 17 日发表的尚未进行同行评议的论文中，D-wave 的一个团队宣称其 2000Q 处理器解决问题的速度，是当前任一知名传统算法速度的 2600 倍（J. King et al. 2017）。现在轮到怀疑派们去找更快的传统算法了。德州大学奥斯汀分校的计算机科学家 Scott Aaronson 说，「据我所知，就这种情况，过去也遇到到两三次，结果，确实有一个不同的传统解决方法消除了所宣称的差距。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Hilton 认为，今年 D-wave 将证明完成即使是最强劲的传统超级计算机都不可能实现的计算，他们的这个目标被竞争对手称为「量子霸权」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们已经取得一些结果了，」他说，「我们正在与外部合作者一起审核这些结果，看看能否经得起检验。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相关链接：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720969&amp;amp;idx=1&amp;amp;sn=d5723c205f594616932624684d3a1327&amp;amp;chksm=871b0eb7b06c87a1d4d9809b35c361a4d8a4bf75315eaa9502a051058b184fb233e5b2d2695c&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720969&amp;amp;idx=1&amp;amp;sn=d5723c205f594616932624684d3a1327&amp;amp;chksm=871b0eb7b06c87a1d4d9809b35c361a4d8a4bf75315eaa9502a051058b184fb233e5b2d2695c&amp;amp;scene=21#wechat_redirect"&gt;Science：实用量子计算机已近在咫尺&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721997&amp;amp;idx=2&amp;amp;sn=a7ae3e6f57d41c4c10464422f60fc7de&amp;amp;chksm=871b0ab3b06c83a58926ff6f313d63d94fa9f3afc9433f23047174cb78f99617b17699ac3322&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721997&amp;amp;idx=2&amp;amp;sn=a7ae3e6f57d41c4c10464422f60fc7de&amp;amp;chksm=871b0ab3b06c83a58926ff6f313d63d94fa9f3afc9433f23047174cb78f99617b17699ac3322&amp;amp;scene=21#wechat_redirect"&gt;Nature：量子计算机或将在 2017 年走向实用化&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 25 Jan 2017 12:24:58 +0800</pubDate>
    </item>
    <item>
      <title>业界 | Quora 第一个开放数据集：相似问题对构建语义理解</title>
      <link>http://www.iwgc.cn/link/4482151</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Quora&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：蒋思源、朱思颖&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Quora开放了第一个数据集，希望通过这40万行的问题对整合相同提问成同一页面，促进自然语言的语义理解，自动识别与整合，加强知识共享平台的建设。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今天我们很高兴地宣布过去计划发布的一系列公开数据集中的第一个成功开放。我们开放的数据集将面向与 Quora 相关的各种问题，并且旨在帮助在机器学习、自然语言处理、神经网络科学等领域的研究人员能够自行构建可扩展性的在线知识分享平台。我们第一个数据集与识别重复性问题相关。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Quora 一个重要的产品原则，即每一个逻辑独立的问题应该只需要一个单独的问题页面。简单地说，如询问「美国哪一个州人口最多？」和「在美国人最多的州是哪个？」，这两个问题不应该在 Quora 单独地存在，因为两个问题所要表达的意图是完全相同的。如果每一个页面都是一个逻辑独立的问题，那么就能在很多方面上让知识分享更加地高效。如知识查询者可以在一个位置查看问题的所有答案，并且如果读者群体因为不同的页面而分割，那么回答问题的作者可以获得更高的阅读量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了大规模减少低效的重复问题页面，我们需要一种自动化的方式来检测问题文本实际上是不是在语义上和其他问题相等。这在机器学习和自然语言处理上是很具挑战性的问题，并且也是我们一直在寻找更好解决方案的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们今天发布的数据集将让任何人可以根据实际的 Quora 数据来训练和测试语义等价模型。我们希望看到是解决这个问题的多样性方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们数据集所包含的潜在重复问题对（duplicate pairs）超过 40 万行。每一行包含问题对的问题 ID 编号、完整文本以及一个表明这一行是否真正含有重复问题对的二进制值。以下这张图是我们数据集中一些行的示例：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicfJFax3rHUWXK8QUmf7aiaiabcVQEX58LECeZ2uw6sbAJQJPBiaEx4icQiblWzUPibs91X4wXYn9PK3AYg/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关于这个数据集的必知要点说明：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;我们初始采样方法得到的是一个不均衡的数据集，即数据集中重复问题对（二进制值为真）的数量远远多于非重复问题对的数量。因此，我们补充了数据集中非重复问题对（二进制值为假）的数量。非重复问题对的一个来源是构建相关问题对，相关问题对中的问题尽管是属于相似的主题，但在语义上并不是完全等价的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;数据集中问题的分布情况并不能代表 Quora 里所问问题的分布情况。部分是因为抽样过程的系统性操作和运用了一些数据清洗方式（sanitization measures）来完成最终数据集的构建（例如：去除了包含细节描述的极长问题）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;真值标签（ground-truth labels）含有一定量的数据噪点：并不能保证所有的标注都完美无错。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们的数据集在 S3 上托管，只允许非商业使用且使用条件取决于我们的服务条款规定。你可以通过这个链接下载数据集：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;http://qim.ec.quoracdn.net/quora_duplicate_questions.tsv&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 25 Jan 2017 12:24:58 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 为推进科学研究，谷歌呼吁建立标准的数据生态系统</title>
      <link>http://www.iwgc.cn/link/4482152</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Google Research Blog&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李泽南、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote style="max-width: 100%; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;谷歌希望在人们的努力之下，我们最终能够像搜索论文一样轻松找到自己想要的数据集，新的标准是努力的第一步。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前网络上有数百个数据库，它们提供了数以百万计的数据集。这些数据的提供者包括国家和地方政府、科学和出版机构、数据供应商等等，数据的涵盖面从社会科学、生命科学到高能物理、气候科学，几乎无所不包。这些数据对于促进研究结果的重现至关重要，能够让科学家在前人的基础上继续探索，让数据挖掘者可以更轻松地接触信息，探究它背后的意义。出于这些原因，很多出版者和资金提供者现在要求科学家们尽量公开他们的数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而，由于网络上数据存储的数量庞大，人们会发现难以寻找自己需要的数据集，同时无法核实信息的来源和真实性。搜索数据集本应该像搜索食谱、工作甚至电影一样简单——那些类型的搜索通常是开放式的，能够偶然的发现搜索空间中的某些结构。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了让书籍、电影、活动、食谱、评测和一系列其他类型的搜索在谷歌引擎上有更佳表现，我们依赖于各网站上嵌入 schema.org 词汇的结构数据。为了促进数据集实现类似的功能，我们最近发布了一个新的指导帮助数据提供商以标准的形式形容他们的数据集，让谷歌和其他的搜索引擎可以连接到这些结构化元数据描述的地理位置、出版商甚至知识图谱，以便被使用者发现。我们希望这些元数据可以帮助网上公开的信息能够更有效地被人们使用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Schema.org 上形容数据集的方式基于最近在 W3C（Data Catalog Vocabulary）上的标准化成果，我们认为它是在未来不断完善描述和改进数据集索引的第一步。虽然各领域还在不断讨论，但我们认为这一标准已经为构建数据生态系统打下了坚实基础。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;技术挑战&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然我们已经发布了元数据的索引指南，但在轻松搜索数据集之前我们还面临着很多技术挑战。这些挑战包括：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;数据集定义的一致性：例如，单一表格和大量表格的集合都算是一个数据集吗？如果都是，蛋白质序列呢？图片集合呢？用于链接数据的 API 呢？我们希望获得更多关于数据提供者的定义、解释以及使用方式。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;数据集的识别：在理想状况下，数据集应该拥有一些被所有人认可的永久标识，让数据集具有唯一性，但在一些情况下这还不现实。原数据界面的 URL 或许是作为标识符的不错选择，我们需要提供多种标识符吗？如果有多重标识的话，需要选择一个主要标识吗？&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;彼此间关联数据集：什么时候两种记录能够统一的描述一个数据集？（例如，万一 repository 从其他人那里复制来元数据呢）如果数据整合方（aggregator) 在一个数据集上加入了更多的元数据，或者以有益的方式清洁了数据呢？我们正在研究如何明晰、定义这些关系。但是，元数据的消费者不得不假定这些数据提供者不准确描述的数据，并忍受这种情况。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在相关数据集间传播元数据：在相关数据集之间我们能够传播多少元数据？例如，我们可能从合成数据集到它包含的子数据集来传播出处信息。但经过这样的传播，元数据有了多少的退化？我们预期根据不同的应用退化程度不同：搜索应用的元数据可能要比数据融合的精确度更低。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;描述数据集的内容：数据集要包含多少的描述内容，从而使得能够进行类似于 Explore for Docs, Sheets and Slides 中使用的查询，或者进行数据集的其他探索与重复使用（当然是在许可之下）？我们如何高效的使用供应商使用 W3C 标准已经描述的内容？&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除了我们已经列出来的技术和社会挑战，剩下的许多研究挑战涉及到长期的开放式研究：许多数据集是用无结构的方式描述的，包括科学论文形式的说明、图解、表格，以及其他文档。我们能建立提取元数据的其他有前途的方式。虽然我们有合理的排序网页搜索内容的方式，而排序数据集是个挑战：我们不知道排序网页的 signals 是否同样适用于数据集。在数据集内容是公开且可用的情况下，我们可能能够提取数据集中额外的语义，例如，学习不同领域的值类型。但是，我们是否能够足够了解内容，从而能够进行相关资源的数据融合于挖掘？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;呼吁行动&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对任何生态系统而言，一个数据系统只有在大量人员共同贡献的情况下才会繁荣，因此我们呼吁：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;个人和数据仓库提供者：使用 schema.org、DCAT、CSVW 等社区标准公布结构元数据，这能使得其他人发现、使用这些元数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据消费者（科学家到数据新闻更作者等）：更准确的引用数据，如同我们引用科学论文一样。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;开发者：为 schema.org (http://schema.org/) 元数据的数据集的拓展做出贡献，提供专业领域的词汇，以及研究使用这一丰富元数据的工具与应用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们最终的目标是帮助建立一个公布、使用、挖掘数据集的生态系统。如此以来，该生态系统将会包括数据发布者、整合者（大型数据仓储方提供数据清洗、调和元数据等价值）、挖掘数据的搜索引擎、以及更重要的数据消费者。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 25 Jan 2017 12:24:58 +0800</pubDate>
    </item>
    <item>
      <title>教程 | 没有博士学位，照样玩转TensorFlow深度学习</title>
      <link>http://www.iwgc.cn/link/4468818</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Codelabs&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：侯韵楚、王宇欣、赵华龙、邵明、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;本文内容由机器之心编译自谷歌开发者博客的 Codelabs 项目。据介绍，Google Developers Codelabs 提供了有引导的、教程式的和上手式的编程体验。大多数 Codelabs 项目都能帮助你了解开发一个小应用或为一个已有的应用加入新功能的过程。这些应用涉及到很多主题，包括 Android Wear、Google Compute Engine、Project Tango、和 iOS 上的 Google API。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;本项目的原文可参阅：https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/#13&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1、概述&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdO9nh6G6U3pVLCbOeUqDhb7FmXngMrVGicdQjKCicL42g3lfvr6eYvpjdQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 codelab 项目中，你将学习如何构建并训练出能够识别手写数字的神经网络。在这过程中，当这个神经网络的准确度提升至 99％时，你还会发现深度学习专业人士用来有效训练模型的贸易工具。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个 codelab 项目使用的是 MNIST 数据集，这个包含 60,000 个有标记数字的集合是几届博士努力近二十年的成果。你将会用不到 100 行的 Python/TensorFlow 代码来解决上述问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你将学到：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;①神经网络的定义及如何训练神经网络&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;②如何使用 TensorFlow 构建基本的 1 层神经网络&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;③如何添加多层神经网络&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;④训练提示和技巧：过拟合、dropout、学习速率衰减等...&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;⑤如何解决深度神经网络的问题&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;⑥如何构建卷积网络&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对此，你将需要：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;①Python 2 或 3（建议使用 Python 3）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;②TensorFlow&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;③Matplotlib（Python 的可视化库）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;安装说明会在下一步中给出。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2. 准备：安装 TensorFlow，获取示例代码&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在你的计算机上安装必要软件：Python、TensorFlow 和 Matplotlib。完整的安装说明如下：INSTALL.txt&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;克隆 GitHub 存储库：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;p&gt;$ git clone https://github.com/martin-gorner/tensorflow-mnist-tutorial&lt;/p&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;这个库包含了多个文件，而你将只在mnist_1.0_softmax.py中操作。其它文件是用于加载数据和可视化结果的解决方案或支持代码。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当你启动初始python脚本时，应当能够看到训练过程的实时可视化：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;p&gt;$ python3 mnist_1.0_softmax.py&lt;/p&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOdnYBxdmmHG4vX3OQgQvn6NGt0uhzibIk0paGTXTcEibibMsolGOn4lhcA/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;疑难解答：如果无法运行实时可视化，或者如果你只想要使用文本输出，则可以通过注释掉一行并取消另一行的注释来禁用可视化。请参阅文件底部的说明。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为 TensorFlow 构建的可视化工具是 TensorBoard，其主要目标比我们在这里所需的更宏大。它能使你能够跟踪你在远程服务器上的分布式 TensorFlow 工作。而对于我们的这个实验，matplotlib 将作为替代，并且我们还有额外收获——实时动画。但是如果你使用 TensorFlow 进行严谨的工作，你一定要试试 TensorBoard。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3、理论：训练一个神经网络&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们首先来观察一个正在训练的神经网络。其代码会在下一节解释，所以现在不必查看。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们的神经网络可以输入手写数字并对它们进行分类，即将它们识别为 0、1、2……9。它基于内部变量（「权重（weights）」和「偏差（bias）」，会在后面进行解释），需要有一个正确的值来分类才能正常工作。这个「正确的值」通过训练过程进行学习，这也将在后面详细解释。你现在需要知道的是，训练回路看起来像这样：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Training digits =&amp;gt; updates to weights and biases =&amp;gt; better recognition (loop)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;让我们逐个通过可视化的六个面板，了解训练神经网络需要什么。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdODmcm4QKaZDng3wwLkeibiamawibQcicyhaNAHz5GLGmIibN1W5UnnMibQ8lA/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你可以看到训练数字每次 100 个被送入训练回路；也可以看到当前训练状态下的神经网络是已将数字正确识别（白色背景）还是误分类（红色背景，左侧印有正确的标示，每个数字右侧印有计算错误的标示）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此数据集中有 50,000 个训练数字。我们在每次迭代（iteration）中将 100 个数字送入训练循环中，因此系统将在 500 次迭代之后看到所有训练数字一次。我们称之为一个「epoch」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOVEQLNmqgibCGDVcSE09IZ2oxCmz4icXcNZFWc7DIsEuGsemBCia7F2BibQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了测试在现实条件下的识别质量，我们必须使用系统在训练期间从未看过的数字。否则，它可能记住了所有的训练数字，却仍无法识别我刚才写的「8」。MNIST 数据集包含了 10,000 个测试数字。此处你能看到每个数字对应的大约 1000 种书写形式，其中所有错误识别的数字列在顶部（有红色背景）。左边的刻度会给你一个粗略的分辨率精确度（正确识别的百分比）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOzPxBLL5PPnnv2e57GHJVN9PEBK3afcHsCnlIiaBmI0gSLndIrSm2H0A/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了驱动训练，我们来定义损失函数，即一个展示出系统数字识别能力有多糟的值，并且系统会尽力将其最小化。损失函数（loss function，此处为「交叉熵」）的选择稍后会做出解释。你会看到，随着训练的进行，训练和测试数据的损失会减少，而这个现象是好的，意味着神经网络正在学习。X 轴表示了学习过程中的迭代。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOQPiaHohibpPRNuEhnibDEV4KZmen8ibE82RcXk6vLr5TksJv2t1e0BPTWg/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个准确度只是正确识别的数字的百分比，是在训练和测试集上计算出的。如果训练顺利，它便会上升。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdO5sAVy5w2AziaPMgf5tqgpjIblWuLnXWXneDbFgtwjWRn53YP0RdW2Dg/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOVgpWsytn7tSJicLGnibvibMPFvyTOTq5Y9WnqFBrmrdzVM7UriaI2wzaZQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后的两幅图表说明了内部变量所取的所有值的扩展，即随训练进行而变化的权重和偏置。比如偏置从 0 开始，且最终得到的值大致均匀地分布在-1.5 和 1.5 之间。如果系统不能很好地收敛，那么这些图可能有用。倘若你发现权重和偏差扩展到上百或上千，那么就可能有问题了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图中的条带为百分数。此处有 7 条带，所以每条带是所有值的 100/7，也就是 14%。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;用于可视化 GUI 的键盘快捷键&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1 ......... display 1st graph only 仅显示第 1 张图&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2 ......... display 2nd graph only 仅显示第 2 张图&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3 ......... display 3rd graph only 仅显示第 3 张图&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4 ......... display 4th graph only 仅显示第 4 张图&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;5 ......... display 5th graph only 仅显示第 5 张图&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;6 ......... display 6th graph only 仅显示第 6 张图&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;7 ......... display graphs 1 and 2 显示 1 和 2 图&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;8 ......... display graphs 4 and 5 显示 4 和 5 图&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;9 ......... display graphs 3 and 6 显示 3 和 6 图&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;ESC or 0 .. back to displaying all graphs 返回，显示所有图&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;空格 ..... pause/resume 暂停/继续&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;O ......... box zoom mode (then use mouse) 框缩放模式（然后使用鼠标）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;H ......... reset all zooms 重置所有缩放&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Ctrl-S .... save current image 保存当前图像&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;什么是“权重”和“偏置”？“交叉熵”又是如何被计算的？训练算法究竟是如何工作的？请到下一部分一探究竟。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;4、理论 : 单层神经网络&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOZkicgjjyjxtjQIfmXckY18Ca5BNCe24kiaDZxfIHsMSWWibclAibqYG4QA/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;MNIST 数据集中，手写数字是 28x28 像素的灰度图像。将它们进行分类的最简单的方法就是使用 28x28=784 个像素作为单层神经网络的输入。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOBam4JXCrGU4sCnBnEyLTRAMibRJfomUdt3icX24JoKh9yGPfFOrwqpjQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;神经网络中的每个「神经元」对其所有的输入进行加权求和，并添加一个被称为「偏置（bias）」的常数，然后通过一些非线性激活函数来反馈结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了将数字分为 10 类（0 到 9），我们设计了一个具有 10 个输出神经元的单层神经网络。对于分类问题，softmax 是一个不错的激活函数。通过取每个元素的指数，然后归一化向量（使用任意的范数（norm），比如向量的普通欧几里得距离）从而将 softmax 应用于向量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOwjPHhA5qHOn4vV1qIO86TqTwcS7BWKTn30HKUiazMaNkha65ib1icUibcQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那么为什么「softmax」会被称为 softmax 呢？指数是一种骤增的函数。这将加大向量中每个元素的差异。它也会迅速地产生一个巨大的值。然后，当进行向量的标准化时，支配范数（norm）的最大的元素将会被标准化为一个接近 1 的数字，其他的元素将会被一个较大的值分割并被标准化为一个接近 0 的数字。所得到的向量清楚地显示出了哪个是其最大的值，即「max」，但是却又保留了其值的原始的相对排列顺序，因此即为「soft」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOsc1iaUWm9iaowsZT8apdVvSIticX9yA0lG7tAaszNxaUR0t5KSic1eALYw/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们现在将使用矩阵乘法将这个单层的神经元的行为总结进一个简单的公式当中。让我们直接这样做：100 个图像的「mini-batch」作为输入，产生 100 个预测（10 元素向量）作为输出。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使用加权矩阵 W 的第一列权重，我们计算第一个图像所有像素的加权和。该和对应于第一神经元。使用第二列权重，我们对第二个神经元进行同样的操作，直到第 10 个神经元。然后，我们可以对剩余的 99 个图像重复操作。如果我们把一个包含 100 个图像的矩阵称为 X，那么我们的 10 个神经元在这 100 张图像上的加权和就是简单的 X.W（矩阵乘法）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;每一个神经元都必须添加其偏置（一个常数）。因为我们有 10 个神经元，我们同样拥有 10 个偏置常数。我们将这个 10 个值的向量称为 b。它必须被添加到先前计算的矩阵中的每一行当中。使用一个称为 "broadcasting" 的魔法，我们将会用一个简单的加号写出它。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「Broadcasting」是 Python 和 numpy（Python 的科学计算库）的一个标准技巧。它扩展了对不兼容维度的矩阵进行正常操作的方式。「Broadcasting add」意味着「如果你因为两个矩阵维度不同的原因而不能将其相加，那么你可以根据需要尝试复制一个小的矩阵使其工作。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们最终应用 softmax 激活函数并且得到一个描述单层神经网络的公式，并将其应用于 100 张图像：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOGZkKwmpUrRscOIzbso4YjUhEwicnicGMXu3wSYGassaosNUv4oRDlgww/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;顺便说一下，什么是「tensor（张量）」？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「张量（tensor）」像一个矩阵，但是却有着任意数量的维度。一个 1 维的张量是一个向量。一个二维的张量是一个矩阵。然后你可以有 3, 4, 5 或者更多维的张量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;5、理论：梯度下降&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在我们的神经网络从输入图像中产生预测，我们需要知道它们可以做到什么样的程度，即在我们知道的事实和网络的预测之间到底有多大的距离。请记住，我们对于这个数据集中的所有图像都有一个真实的标签。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;任何一种定义的距离都可以进行这样的操作，普通欧几里得距离是可以的，但是对于分类问题，被称为「交叉熵（cross-entropy）」的距离更加有效。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOUNDMfnZ1HG2frK0f9UFjPUiaH2DwAD0ehdJy8wOiaNDyerSyWY8YfcQw/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「one-hot」编码意味着你使用一个 10 个值的向量，其中除了第 6 个值为 1 以外的所有值都是 0。这非常方便，因为这样的格式和我们神经网络预测输出的格式非常相似，同时它也作为一个 10 值的向量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「训练」一个神经网络实际上意味着使用训练图像和标签来调整权重和偏置，以便最小化交叉熵损失函数。它是这样工作的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;交叉熵是一个关于权重、偏置、训练图像的像素和其已知标签的函数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果我们相对于所有的权重和所有的偏置计算交叉熵的偏导数，我们就得到一个对于给定图像、标签和当前权重和偏置的「梯度」。请记住，我们有 7850 个权重和偏置，所以计算梯度需要大量的工作。幸运的是，TensorFlow 可以来帮我们做这项工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;梯度的数学意义在于它指向「上（up）」。因为我们想要到达一个交叉熵低的地方，那么我们就去向相反的方向。我们用一小部分的梯度更新权重和偏置并且使用下一批训练图像再次做同样的事情。我们希望的是，这可以使我们到达交叉熵最小的凹点的低部。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOPic4LeNISGUVD9NSvUNbsAIEWt0hkJSic3b9RLZmh0Idv5kxsk1MYLbQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这副图片当中，交叉熵被表示为一个具有两个权重的函数。事实上，还有更多。梯度下降算法遵循着一个最陡的坡度下降到局部最小值的路径。训练图像在每一次迭代中同样会被改变，这使得我们向着一个适用于所有图像的局部最小值收敛。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「学习率（learning rate）」： 在整个梯度的长度上，你不能在每一次迭代的时候都对权重和偏置进行更新。这就会像是你穿着七里靴却试图到达一个山谷的底部。你会直接从山谷的一边到达另一边。为了到达底部，你需要一些更小的步伐，即只使用梯度的一部分，通常在 1/1000 区域中。我们称这个部分为「学习率（Learning rate）」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;总结一下，以下是训练过程的步骤：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Training digits and labels =&amp;gt; loss function =&amp;gt; gradient (partial derivatives) =&amp;gt; steepest descent =&amp;gt; update weights and biases =&amp;gt; repeat with next mini-batch of training images and labels&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;训练数字和标签 =&amp;gt; 损失函数 =&amp;gt; 梯度（部分偏导数）=&amp;gt; 最陡的梯度 =&amp;gt; 更新权重和偏置 =&amp;gt; 使用下一个 mini-batch 的图像和标签重复这一过程&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为什么使用 100 个图像和标签的 mini-batch？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你当然也可以只在一个示例图像中计算你的梯度并且立即更新权重和偏置（这在科学文献中被称为「随机梯度下降（stochastic gradient descent）」）。在 100 个样本上都这样做可以得到一个更好地表示由不同样本图像施加约束的梯度并且可能更快地朝着解决方案收敛。mini-batch 的大小是可调整的参数。还有一个更加技术化的原因：使用批处理也意味着使用较大的矩阵，而这些通常更容易在 GPU 上优化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;常见问题&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为什么交叉熵是在分类问题中合适的定义距离？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;解答链接：https://jamesmccaffrey.wordpress.com/2013/11/05/why-you-should-use-cross-entropy-error-instead-of-classification-error-or-mean-squared-error-for-neural-network-classifier-training/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;6、实验：让我们来看看代码&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;单层神经网络的代码已经写好了。请打开 mnist_1.0_softmax.py 文件并按说明进行操作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你在本节的任务是理解开始代码，以便稍后对其改进。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你应该看到，在文档中的说明和启动代码只有微小的差别。它们对应于可视化的函数，并且在注释中被标记。此处可忽略。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;mnist_1.0_softmax.py：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://github.com/martin-gorner/tensorflow-mnist-tutorial/blob/master/mnist_1.0_softmax.py&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOtia4weAo34TUtWxxY9wEopFEAPobvdKO4LTCnvdYfyjZFBSOzXF8zVw/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们首先定义 TensorFlow 的变量和占位符。变量是你希望训练算法为你确定的所有的参数。在我们的例子中参数是权重和偏差。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;占位符是在训练期间填充实际数据的参数，通常是训练图像。持有训练图像的张量的形式是 [None, 28, 28, 1]，其中的参数代表：&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;28, 28, 1: 图像是 28x28 每像素 x 1（灰度）。最后一个数字对于彩色图像是 3 但在这里并非是必须的。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;None: 这是代表图像在小批量（mini-batch）中的数量。在训练时可以得到。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;mnist_1.0_softmax.py：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://github.com/martin-gorner/tensorflow-mnist-tutorial/blob/master/mnist_1.0_softmax.py&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOfMVLI9BQdgEia1kjzmicN4CnmhDRphQkd6XNPiaNics2nKsic9Un0b3PmRw/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一行是我们单层神经网络的模型。公式是我们在前面的理论部分建立的。tf.reshape 命令将我们的 28×28 的图像转化成 784 个像素的单向量。在 reshape 中的「-1」意味着「计算机，计算出来，这只有一种可能」。在实际当中，这会是图像在小批次（mini-batch）中的数量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然后，我们需要一个额外的占位符用于训练标签，这些标签与训练图像一起被提供。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在我们有模型预测和正确的标签，所以我们计算交叉熵。tf.reduce_sum 是对向量的所有元素求和。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后两行计算了正确识别数字的百分比。这是留给读者的理解练习，使用 TensorFlow API 参考。你也可以跳过它们。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;mnist_1.0_softmax.py：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://github.com/martin-gorner/tensorflow-mnist-tutorial/blob/master/mnist_1.0_softmax.py)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;optimizer = tf.train.GradientDescentOptimizer(0.003)&lt;/p&gt;&lt;p&gt;train_step = optimizer.minimize(cross_entropy)&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;才是 TensorFlow 发挥它力量的地方。你选择一个适应器（optimiser，有许多可供选择）并且用它最小化交叉熵损失。在这一步中，TensorFlow 计算相对于所有权重和所有偏置（梯度）的损失函数的偏导数。这是一个形式衍生（ formal derivation），并非是一个耗时的数值型衍生。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;梯度然后被用来更新权重和偏置。学习率为 0.003。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，是时候来运行训练循环了。到目前为止，所有的 TensorFlow 指令都在内存中准备了一个计算图，但是还未进行计算。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;TensorFlow 的 “延迟执行（deferred execution）” 模型：TensorFlow 是为分布式计算构建的。它必须知道你要计算的是什么、你的执行图（execution graph），然后才开始发送计算任务到各种计算机。这就是为什么它有一个延迟执行模型，你首先使用 TensorFlow 函数在内存中创造一个计算图，然后启动一个执行 Session 并且使用 Session.run 执行实际计算任务。在此时，图形无法被更改。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由于这个模型，TensorFlow 接管了分布式运算的大量运筹。例如，假如你指示它在计算机 1 上运行计算的一部分 ，而在计算机 2 上运行另一部分，它可以自动进行必要的数据传输。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;计算需要将实际数据反馈进你在 TensorFlow 代码中定义的占位符。这是以 Python 的 dictionary 的形式给出的，其中的键是占位符的名称。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;mnist_1.0_softmax.py：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://github.com/martin-gorner/tensorflow-mnist-tutorial/blob/master/mnist_1.0_softmax.py&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOD46e8viatjtbtvYPibFy9aVC11EDpIjib3qia7D2up4RrMDdwDrwzP7Ofw/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这里执行的 train_step 是当我们要求 TensorFlow 最小化交叉熵时获得的。这是计算梯度和更新权重和偏置的步骤。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最终，我们还需要一些值来显示，以便我们可以追踪我们模型的性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在训练回路中使用该代码来计算准确度和交叉熵（例如每 10 次迭代）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;p&gt;# success ?&lt;br/&gt;a,c = sess.run([accuracy, cross_entropy], feed_dict=train_data)&lt;/p&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过在馈送 dictionary 中提供测试而不是训练数据，可以对测试数据进行同样的计算（例如每 100 次迭代计算一次。有 10,000 个测试数字，所以会耗费 CPU 一些时间）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;p&gt;# success on test data ?&lt;br/&gt;test_data={X: mnist.test.images, Y_: mnist.test.labels}&lt;br/&gt;a,c = sess.run([accuracy, cross_entropy], feed=test_data)&lt;/p&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;TensorFlow 和 Numpy 是朋友：在准备计算图时，你只需要操纵 TensorFlow 张量和命令，比如 tf.matmul, tf.reshape 等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而，只要执行 Session.run 命令，它的返回值就是 Numpy 张量，即 Numpy 可以使用的 numpy.ndarray 对象以及基于它的所有科学计算库。这就是使用 matplotlib（基于 Numpy 的标准 Python 绘图库）为本实验构建实时可视化的方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个简单的模型已经能识别 92% 的数字了。这不错，但是你现在要显著地改善它。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOibE6mhmHev14JgswcB4wMnd5qXxqlfRjgicUYwluOFG7tGoUglMrLqQw/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;7、实验:增加层&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOCqnO54VTEZxPX6IzSXuiciaiaCWZib92gyUic9UmETCiblUt10bncHT8NpuA/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了提高识别的准确度，我们将为神经网络增加更多的层。第二层神经元将计算前一层神经元输出的加权和，而非计算像素的加权和。这里有一个 5 层全相连的神经网络的例子：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOuGfYSFT74kbFNvs4eWZMt9DL8hrzoH5MrDfELW5sFWusmLbC6bCMibQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们继续用 softmax 来作为最后一层的激活函数，这也是为什么在分类这个问题上它性能优异的原因。但在中间层，我们要使用最经典的激活函数：sigmoid：在这一节中你的任务是为你的模型增加一到两个中间层以提高它的性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOB4k0BWGoiaW2UF4dic0QsNpH0Rgap3ed508yIQthD8t9juRwOVqXI0uA/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;答案可以在 mnist_2.0_five_layers_sigmoid.py 中找到。只有当你实在想不出来的时候再使用它！为了增加一个层，你需要为中间层增加一个额外的权重矩阵和一个额外的偏置向量：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;p&gt;W1 = tf.Variable(tf.truncated_normal([28*28, 200] ,stddev=0.1))&lt;br/&gt;B1 = tf.Variable(tf.zeros([200]))&lt;br/&gt;&lt;br/&gt;W2 = tf.Variable(tf.truncated_normal([200, 10], stddev=0.1))&lt;br/&gt;B2 = tf.Variable(tf.zeros([10]))&lt;/p&gt;&lt;/pre&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对，就这么做。通过 2 个中间层以及例子中 200 个和 100 个神经元，你现在应该能够把你的神经网络的准确度推高到 97% 了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOBQPDQRdByiaeZjCeBJvnPgT7uamialK5OQ3w3nccMwMKuXuF6J4ocfCg/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;8、实验：深度网络需要特别注意的地方&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOAz0DeOvpRIo3FmjXthdgCkx0zcQ0zp6r1cdKThYBILcsNA9eWTFjIw/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随着层数的增加，神经网络越来越难以收敛。但现在我们知道如何控制它们的行为了。这里是一些只用 1 行就可以实现的改进，当你看到准确度曲线出现如下情况的时候，这些小技巧会帮到你：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdO0ibWQnsgUnI8KAHfqOshQE1dLV1XVnIfUmhStP5nwtft6yv3bjtkAtQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;修正线性单元（ReLU）激活函数&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在深度网络里，sigmoid 激活函数确实能带来很多问题。它把所有的值都挤到了 0 到 1 之间，而且当你重复做的时候，神经元的输出和它们的梯度都归零了。值得一提的是，出于历史原因，一些现代神经网络使用了 ReLU（修正线性单元），它大致是如下这个样子：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOdvfO7WTTNy8iaqgJuWTQAbE2FAFVXoYxOGcEWvnb3Xvvib2X36xAzicpw/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;升级 1/4：用 RELU 替换你所有的 sigmoid，然后你会得到一个更快的初始收敛并且当我们继续增加层的时候也避免了一些后续问题的产生。仅仅在代码中简单地用 tf.nn.relu 来替换 tf.nn.sigmoid 就可以了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个更好的优化器&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在一个特别多维的空间里，就像当前这个情况——我们有 10K 量级的权值和偏置值——「鞍点 (saddle points）」会频繁出现。这些点不是局部最小值点，但它的梯度却是零，那么梯度降的优化会卡在这里。TensorFlow 有一系列可以用的优化器，包括一些带有一定的惯性，能够安全越过鞍点的优化器。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;升级 2/4：现在将你的 tf.train.GradientDescentOptimiser 替换为 tf.train.AdamOptimizer。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随机初始化&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;准确性一直卡在 0.1？你把你的权值初始化成随机值了没？对于偏置值，如果用 ReLU 的话，最好的办法就是把它们都初始化成小的正值，这样神经元一开始就会工作在 ReLU 的非零区域内。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;p&gt;W = tf.Variable(tf.truncated_normal([K, L] ,stddev=0.1))&lt;br/&gt;B = tf.Variable(tf.ones([L])/10)&lt;/p&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;升级 3/4：现在检查是否你所有的权值和偏置值都被初始化好了。上图所示的 0.1 会作为偏置值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不定值（NaN）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOOnxOofUfcz3ephxl0UhxeqOB6s1OapSoZrlNUHRzTIu9c359vyqotA/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你看到你的精确曲线陡然下滑并且调试口输出的交叉熵是 NaN，不用感到头疼，你其实是正在尝试计算 log(0)，而这肯定是个不定值（NaN）。还记得吗，交叉熵的计算涉及到对 softmax 层的输出取对数。鉴于 softmax 基本上是一个指数，它肯定不是 0，我们如果用 32 位精度的浮点运算就还好，exp(-100) 基本上可以算作是 0 了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;很幸运，TensorFlow 有一个非常方便的函数可以在单步内计算 softmax 和交叉熵，它是以一种数值上较为稳定的方式实现的。如果要使用它，你需要在应用 softmax 之前将原始的权重和加上你最后一层的偏置隔离开来（在神经网络的术语里叫「logits」）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你模型的最后一行是这样的：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;p&gt;Y = tf.nn.softmax(tf.matmul(Y4, W5) + B5)&lt;/p&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你需要把它替换成：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;p&gt;Ylogits = tf.matmul(Y4, W5) + B5
Y = tf.nn.softmax(Ylogits)&lt;/p&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;并且你现在能以一种安全的方式计算交叉熵了：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;p&gt;cross_entropy = tf.nn.softmax_cross_entropy_with_logits(Ylogits, Y_)&lt;/p&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;同样加上下面这行代码使得测试和训练的交叉熵能够同框显示：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;p&gt;cross_entropy = tf.reduce_mean(cross_entropy)*100&lt;/p&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;升级 4/4：请把 tf.nn.softmax_cross_entropy_with_logits 加到你的代码里。你也可以跳过这一步，等你真在你的输出里看到 NaN 以后再来做这步。现在，你已经准备好实现「深度」了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;9、实验：学习速率衰退&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOBXiae4PSfty9lGiahnT8icSXVLZqCzulJicVNX2DAfuDqicwmp27o6LUicrA/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过两个、三个或者四个中间层，你现在可以将准确度提升至接近 98%，当然，你的迭代次数要达到 5000 次以上。不过你会发现你并不总是会得到这样的结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOfz5Jt3iaGqYJ1MUS2IFg9JfKJBYiaTZv8HBwcj6xE2Dsbzh4zpjo14Og/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些曲线很嘈杂，看看测试精确度吧：它在全百分比范围内跳上跳下。这意味着即使 0.003 的学习率我们还是太快了。但我们不能仅仅将学习率除以十或者永远不停地做训练。一个好的解决方案是开始很快随后将学习速率指数级衰减至比如说 0.0001。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个小改变的影响是惊人的。你会看到大部分的噪声消失了并且测试精确度持续稳定在 98% 以上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOibZOXe6pMQUaoxekhItByZ6XpxLgOdkzD3vBic8MT3bHqdFn6nqo0tjw/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;再看看训练精确度曲线。在好多个 epoch 里都达到了 100%（一个 epoch=500 次迭代=全部训练图片训练一次）。第一次我们能很好地识别训练图片了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;请把学习率衰退加到你的代码里。为了把一个不同的学习率在每次迭代时传给 AdamOptimizer，你需要定义一个新的占位符（placeholder）并在每次迭代时通过 feed_dict 赋给它一个新的参数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里是一个指数级衰减的方程：lr = lrmin+(lrmax-lrmin)*exp(-i/2000) 答案可以在这个文件里找到：mnist_2.1_five_layers_relu_lrdecay.py。如果你被卡住了可以用它。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdO6ibEW0PFjTz2o5vAKGS182t8KX4pYydL5CiaA89MQmG8R7gdtEWNkPvw/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;10、实验：dropout、过拟合&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOW3aDx7CC1MavglFrxicfoY8IKibMRlwoEqVJxicu1qcdw0KgOkXrwRUibQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你可能已经注意到在数千次迭代之后，测试和训练数据的交叉熵曲线开始不相连。学习算法只是在训练数据上做工作并相应地优化训练的交叉熵。它再也看不到测试数据了，所以这一点也不奇怪：过了一会儿它的工作不再对测试交叉熵产生任何影响，交叉熵停止了下降，有时甚至反弹回来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOFK4z7czD5rGCWNufmbCAiap36XmnMNWFpcIKT7dzPgYaX160DdJVI3Q/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;它不会立刻影响你模型对于真实世界的识别能力，但是它会使你运行的众多迭代毫无用处，而且这基本上是一个信号——告诉我们训练已经不能再为模型提供进一步改进了。这种无法连接通常会被标明「过拟合（overfitting）」，而且当你看到这个的时候，你可以尝试采用一种规范化（regularization）技术，称之为「dropout」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOgqW2ZHGOGEvhibC0bPuGx4LksibJwGQdJuzrdm4RRLeTLrGXdlvrDY8Q/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 dropout 里，在每一次训练迭代的时候，你可以从网络中随机地放弃一些神经元。你可以选择一个使神经元继续保留的概率 pkeep，通常是 50% 到 75% 之间，然后在每一次训练的迭代时，随机地把一些神经元连同它们的权重和偏置一起去掉。在一次迭代里，不同的神经元可以被一起去掉（而且你也同样需要等比例地促进剩余神经元的输出，以确保下一层的激活不会移动）。当测试你神经网络性能的时候，你再把所有的神经元都装回来 (pkeep=1)。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;TensorFlow 提供一个 dropout 函数可以用在一层神经网络的输出上。它随机地清零一些输出并且把剩下的提升 1/pkeep。这里是如何把它用在一个两层神经网络上的例子。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;p&gt;# feed in 1 when testing, 0.75 when training&lt;br/&gt;pkeep = tf.placeholder(tf.float32)&lt;br/&gt;&lt;br/&gt;Y1 = tf.nn.relu(tf.matmul(X, W1) + B1)&lt;br/&gt;Y1d = tf.nn.dropout(Y1, pkeep)&lt;br/&gt;&lt;br/&gt;Y = tf.nn.softmax(tf.matmul(Y1d, W2) + B2)&lt;/p&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你现在可以在网络中每个中间层以后插入 dropout。如果你没时间深入阅读的话，这是本项目里的可选步骤。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该解决方案可以在 mnist_2.2_five_layers_relu_lrdecay_dropout.py：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;(https://github.com/martin-gorner/tensorflow-mnist-tutorial/blob/master/mnist_2.2_five_layers_relu_lrdecay_dropout.py)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;里找到。如果你被难住了，可以用它。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOyxN9yZ3yrdbVytBxsXycQhPfIz42BFIIqBInJ76J7aEGQKiav7U76Fw/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你会看到测试损失已经被搞回来了，已经在可控范围内了，不过至少在这个例子中噪声重新出现了（如果你知道 dropout 的工作原理的话，这一点也不奇怪）。测试的准确度依然没变，这倒是有点小失望。这个「过拟合」一定还有其它原因。在我们继续进行下一步之前，我们先扼要重述一下我们到目前为止用过的所有工具：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdO2QJiaBHKYTv46tchksDiauciarcnNmDWVZKfL6NvoByQicemibQwGAiaPRrw/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;无论我们做什么，我们看上去都不可能很显著地解决 98% 的障碍，而且我们的损失曲线依然显示「过拟合」无法连接。什么是真正的「过拟合」？过拟合发生在该神经网络学得「不好」的时候，在这种情况下该神经网络对于训练样本做得很好，对真实场景却并不是很好。有一些像 dropout 一样的规范化技术能够迫使它学习得更好，不过过拟合还有更深层的原因。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOPDUSb8c5dUQGsCo7mPsibNibfNCia51RDvd5LZ0rnUZmcpWIORcUEtZgw/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;基本的过拟合发生在一个神经网络针对手头的问题有太多的自由度的时候。想象一下我们有如此多的神经元以至于所组成的网络可以存储我们所有的训练图像并依靠特征匹配来识别它们。它会在真实世界的数据里迷失。一个神经网络必须有某种程度上的约束以使它能够归纳推理它在学习中所学到的东西。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你只有很少的训练数据，甚至一个很小的网络都能够用心学习它。一般来说，你总是需要很多数据来训练神经网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，如果你已经做完了所有的步骤，包括实验了不同大小的网络以确保它的自由度已经约束好了、采用了 dropout、并且训练了大量的数据，你可能会发现你还是被卡在了当前的性能层次上再也上不去了。这说明你的神经网络在它当前的形态下已经无法从你提供的数据中抽取到更多的信息了，就像我们这个例子这样。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;还记得我们如何使用我们的图像吗？是所有的像素都展平到一个向量里么？这是一个很糟糕的想法。手写的数字是由一个个形状组成的，当我们把像素展平后我们会丢掉这些形状信息。不过，有一种神经网络可以利用这些形状信息：卷积网络（convolutional network）。让我们来试试。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;11、理论：卷积网络&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOsics1Sdpp40BwcnX6wuY2SEfSQjEy51ib7a3HVyytJ7qH3OyZ9AUjVDA/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在卷积网络层中，一个「神经元」仅对该图像上的一个小部分的像素求加权和。然后，它通常会添加一个偏置单元，并且将得到的加权和传递给激活函数。与全连接网络相比，其最大的区别在于卷积网络的每个神经元重复使用相同的权重，而不是每个神经元都有自己的权重。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在上面的动画中，你可以看到通过连续修改图片上两个方向的权重（卷积），能够获得与图片上的像素点数量相同的输出值（尽管在边缘处需要填充（padding））。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;要产生一个输出值平面，我们使用了一张 4x4 大小的彩色图片作为出输入。在这个动画当中，我们需要 4x4x3=48 个权重，这还不够，为了增加更多自由度，我们还需要选取不同组的权重值重复实验。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdODjLZnxbJw0tUXQ8L0PuemMOpibdnDSRqAhgq3bvqrU8WnqxyCib4wYrg/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过向权重张量添加一个维度，能够将两组或更多组的权重重写为一组权重，这样就给出了一个卷积层的权重张量的通用实现。由于输入、输出通道的数量都是参数，我们可以开始堆叠式（stacking）和链式（chaining）的卷积层。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOPULsoCEKvD5glEjlx6nfrNnO0zicyeXKHiaFNS22jOboB4nE5EJgJnjA/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，我们需要提取信息。在最后一层中，我们仅仅想使用 10 个神经元来分类 0-9 十个不同的数字。传统上，这是通过「最大池化（max-pooling）」层来完成的。即使今天有许多更简单的方法能够实现这分类任务，但是，「最大池化」能够帮助我们直觉地理解卷积神经网络是怎么工作的。如果你认为在训练的过程中，我们的小块权重会发展成能够过滤基本形状（水平线、垂直线或曲线等）的过滤器（filter），那么，提取有用信息的方式就是识别输出层中哪种形状具有最大的强度。实际上，在最大池化层中，神经元的输出是在 2x2 的分组中被处理，最后仅仅保留输出最大强度的神经元。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里有一种更简单的方法：如果你是以一步两个像素移动图片上的滑块而不是以每步一个像素地移动图片上的滑块。这种方法就是有效的，今天的卷积网络仅仅使用了卷积层。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOGkibWblVcuxBusHNJicMS0YfjUB9W0WictqKoTnQ2B8FhQwmIqsszzW5g/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;让我们建立一个用于手写数字识别的卷积网络。在顶部，我们将使用 3 个卷积层；在底部，我们使用传统的 softmax 读出层，并将它们用完全连接层连接。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOw2YCBMDXTOmZVAa6xqVNTKibeYFEqUrCANiaWRhByCgsrw8fC4Uv9SdA/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;注意，第二与第三卷积层神经元数量以 2x2 为倍数减少，这就解释了为什么它们的输出值从 28x28 减少为 14x14，然后再到 7x7。卷积层的大小变化使神经元的数量在每层下降约为：28x28x14≈3000-&amp;gt;14x14x8≈1500 → 7x7x12≈500 → 200。下一节中，我们将给出该网络的具体实现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;12、实现：一个卷积网络&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOw2YCBMDXTOmZVAa6xqVNTKibeYFEqUrCANiaWRhByCgsrw8fC4Uv9SdA/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了将我们的代码转化为卷积模型，我们需要为卷积层定义适当的权重张量，然后将该卷积层添加到模型中。我们已经理解到卷积层需要以下形式的权重张量。下面代码是用 TensorFlow 语法来对其初始化：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOf8ytOJXpaOxhDdKvJCOYCdNYZN9UAuoCNwlicDvghIs8Tr6V3IuSVyg/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;p&gt;W = tf.Variable(tf.truncated_normal([4, 4, 3, 2], stddev=0.1))&lt;br/&gt;B = tf.Variable(tf.ones([2])/10) # 2 is the number of output channels&lt;/p&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 TensorFlow 中，使用 tf.nn.conv2d 函数实现卷积层，该函数使用提供的权重在两个方向上扫描输入图片。这仅仅是神经元的加权和部分，你需要添加偏置单元并将加权和提供给激活函数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;p&gt;stride = 1 &amp;nbsp;# output is still 28x28&lt;br/&gt;Ycnv = tf.nn.conv2d(X, W, strides=[1, stride, stride, 1], padding='SAME')&lt;br/&gt;Y = tf.nn.relu(Ycnv + B)&lt;/p&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不要过分在意 stride 的复杂语法，查阅文档就能获取完整的详细信息。这里的填充（padding）策略是为了复制图片的边缘的像素。所有的数字都在一个统一的背景下，所以这仅仅是扩展了背景，并且不应该添加不需要的任何样式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在该你了。修改你的模型并将其转化为卷积模型。你可以使用上图中的值来修改它，你可以减小你的学习速率但是务必先移除 dropout。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你的模型的准确率应该会超过 98%，并且最终达到约 99%。眼看目标就要实现，我们不能停止！看看测试的交叉熵曲线。在你的头脑中，此时，是否解决方案正在形成？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOMbUHpFafiarW1jfE9cyjSBSZw9nWic0FGRicKzrRQhTVZtAYjSM2qRbYg/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;13、99% 准确率的挑战&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;调整你的神经网络的一个好方法：先去实现一个限制较多的神经网络，然后给它更多的自由度并且增加 dropout，使神经网络避免过拟合。最终你将得到一个相当不错的神经网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;例如，我们在第一层卷积层中仅仅使用了 4 个 patch，如果这些权重的 patch 在训练的过程中发展成不同的识别器，你可以直观地看到这对于解决我们的问题是不够的。手写数字模式远多于 4 种基本样式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此，让我们稍微增加 patch 的数量，将我们卷积层中 patch 的数量从 4，8，12 增加到 6，12，24，并且在全连接层上添加 dropout。它们的神经元重复使用相同的权重，在一次训练迭代中，通过冻结（限制）一些不会对它们起作用的权重，dropout 能够有效地工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOSUDKaRejmOTlOBxOofAHtEXQ1RNQMv08iaX43293TuLQicQXu8a902uA/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;加油吧，去打破 99％的限制。增加 patch 数量和通道的数量，如上图所示，在卷积层中添加 dropout。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdO5gK1hCdfdOlmhc1Jwet6DQsecEYoaGeoicgABFJOk8MEXGia58LBRulQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;解决方案可以在文件 mnist_3.1_convolutional_bigger_dropout.py 中找到。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使用上图所示的模型，在 10000 个测试的数字中，结果仅仅错误了 72 个。你可以在 MNIST 网站上发现，数字识别准确率的世界纪录大约为 99.7%，这仅比我们用 100 行 Python/TensorFlow 代码构建的模型的准确率高 0.4%。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，不同的 dropout 使我们能够训练更大的卷积网络。增加神经网络的额外自由度，使模型的最终准确率从 98.9% 达到 99.1%。向卷积层中增加 dropout 不仅减少了测试误差，而且使我们模型的准确率突破 99%，甚至达到了 99.3%。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOFJnyJdibkIkWrnFic0OqfB7miab9ADhErO6feoRHvqVrafwibc7MNFQslQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;14、恭喜！&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你已经建立了你的第一个神经网络，并且训练精度达到了 99%。在这个学习过程中，你所学到的技术，并不局限于 MNIST 数据集。实际上，这些技术在训练神经网络的过程中被广泛使用。作为礼物，下面提供的内容可以用来帮助你回忆已经所学的内容。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOWGSBND1vSh4DaMfFJQwQiazcapvHmbKAA2BMgo3kQHoOoueZoDkbcBg/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在完成了完全神经网络和卷积网络后，你应该学习循环神经网络：https://www.tensorflow.org/tutorials/recurrent/。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在本教程中，你已经学习了如何在矩阵层次构建 TensorFlow 模型。Tensorflow 还有更高级的 API，称为 tf.learn：https://www.tensorflow.org/tutorials/tflearn/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;要在云上的分布式框架上训练，我们提供 Cloud ML 服务：https://cloud.google.com/ml&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;最后，我们希望收到你的反馈。如果你在发现了本实验中的些许错误，或者你认为有什么需要改进的地方，请告诉我们。我们通过 GitHub 处理反馈。反馈链接：https://github.com/googlecodelabs/feedback/issues/new?title=[cloud-tensorflow-mnist]:&amp;amp;labels[]=content-platform&amp;amp;labels[]=cloud&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 24 Jan 2017 12:32:21 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 蚂蚁金服与UC Berkeley RISE实验室启动合作，加速数据人才培养</title>
      <link>http://www.iwgc.cn/link/4468819</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心报道&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：老红&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;近日，蚂蚁金服与美国加州伯克利大学近期新成立的 RISE 实验室达成合作意向。据悉，本次蚂蚁金服和 RISE 实验室的合作，是对海内外数据技术人才引进的布局。蚂蚁金服董事长彭蕾曾在内部讲话中表明蚂蚁金服对大数据技术的人才引进将&lt;span&gt;「&lt;/span&gt;不拘一格，不遗余力&lt;span&gt;」&lt;/span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;RISE 实验室的前身是著名伯克利 AMP 实验室，主导研发了当今大数据计算领域最前沿的开源系统：Apache Spark 和 Apache Mesos。以 Apache Spark 为例，作为大数据分析处理的计算引擎，它具备 DAG 执行引擎以及基于内存的多轮迭代计算等优势，使得其在数据分析等工作负载上表现优秀，成为大数据领域最活跃的开源项目之一。从 AMP 实验室在大数据领域取得成果可以看到，其升级版 RISE 实验室在大数据方面的技术基础以及人才培养与储备都是领域内领先的。此次蚂蚁金服和 RISE 实验室合作，除了对基础技术深度研究之外，更是对人才长期的持续投资。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdO5aWNPsPia4o3ncJ0SOIhbBZMCJzX8UziaGwNr7EoFl1BgOAkxmFkj9XQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此前，蚂蚁金服和清华大学、同济大学等高校就基础科研进行了合作。本次和 UC Berkeley 的合作向国际高校基础科研合作迈出了第一步，旨在结合双方资源优势，进一步拓展与升级合作的领域及范围，深化高科技人才的培养与合作交流，共同探索数据技术人才培养的新模式与新机制。该项合作的背后是对高科技人才尤其数据技术人才的极度渴望。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;RISE 实验室的成立，标志着世界顶级计算机科学系在大数据计算领域种下一个五年重大研究计划。这个新实验室专注于下一代大数据计算系统「Real-Time Intelligence &amp;nbsp;with Secure &amp;nbsp;Execution &amp;nbsp;(RISE)&lt;span&gt;」&lt;/span&gt;的研发，世界十一家顶级科技公司成为该实验室的创始成员：蚂蚁金服、谷歌、微软、亚马逊、CAPITAL ONE、英特尔、华为、爱立信、 IBM、VMWare 和通用电气。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;RISE 实验室主任 Ion Stoica 教授描绘了实验室的使命愿景：解决大规模数据计算中长期未能很好解决的世界难题，机器如何在实时数据环境中快速地做出智能决策。这项技术适用于许多未来场景，从地震监控，无人车／无人机指挥与导航、到网络安全等等，需要在复杂环境交互中做出实时计算决策。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Ion Stoica 教授评价本次与蚂蚁金服的合作：「基于最新的强安全数据的智能决策技术将开启一个与数十亿用户息息相关的新应用时代，提高用户的隐私性的同时提供更精准实时的建议。我们非常高兴能与蚂蚁金服合作开发新系统和算法来赋能更多应用和服务，这将从根本上改变人们消费行为并从一系列持续变化的金融、健康、消费、娱乐等数据流中获得价值。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;蚂蚁金服首席技术架构师胡喜说：「蚂蚁金服的核心愿景让全球数十亿普通人享受普惠而便利的金融服务。低成本的实时安全智能决策能力对我们提升客户体验和业务效率都具有极大的价值。我们将与 RISE 实验室合作共同应对某些基础研究的挑战，提供更创新和智能的金融服务。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;ISE 实验室的主要教授包括 Ion Stoica , Michael Jordan 等在内的涵盖了大数据系统及人工智能等领域的世界顶级专家。本次合作中实验室的初创成员都是各领域极具代表性的领先企业，RISE 实验室五年计划的启动将是来自世界各地代表不同产业的人才精英汇聚在一起共同合作创新的尝试。与蚂蚁金服的合作，建立在双方共同的使命和远景基础上，致力于用科技给人们带来智能、安全、低成本的数字普惠金融服务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心报道，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 24 Jan 2017 12:32:21 +0800</pubDate>
    </item>
    <item>
      <title>学界 | DeepMind牵手UCL启动机器学习顶级培训计划</title>
      <link>http://www.iwgc.cn/link/4468820</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;作者Demis Hassabis&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李泽南&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;作为谷歌旗下的人工智能公司，DeepMind 一直以学术性氛围著称，从不断发表论文，参加所有大型学术会议，到开源技术平台，这家公司的所有动作都着眼于长远利益。昨天，该公司创始人 Demis Hassabis 撰文宣布，DeepMind 又启动了与伦敦大学学院（UCL）合作的一项顶级培训计划，致力于培养机器学习领域的顶尖人才，让我们看看他是怎么说的。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 90 年代中期，当我还是一名大学生的时候，很少会有人会去推动学界与业界公司的互动——而后者是几乎所有大学生毕业后的去向。这对于学生而言也许意味着失去机会。同时，虽然私人机构时常受益于大学的研究成果，但这些技术突破带来的好处却很少被两者共享。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相比之下，DeepMind 的研究环境是一种介于学界与业界的混合体，我们在进行计划时会以学术的思维进行长远考虑，同时像最好的初创公司那样，保持专注与速度。学术背景对于我们所有人而言非常重要，机器学习领域的所有突破性理念都是由学术先驱开创的，包括 Geoff Hinton，包括 Rich Sutton。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这就是为什么我们总是公开自己的研究成果，包括超过一百篇同行评议论文，以及总是出现在大型会议（如 NIPS）上的原因。在上个月巴塞罗那举行的 NIPS2016 上，DeepMind 提交了 20 篇论文，参加了 42 次海报论文讨论，21 次研讨会，随后开源了我们的旗舰研究平台：DeepMind Lab，我们所做的还不止于此。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在，我们希望为学术界做出更多的贡献，为教育训练下一代机器学习人才提供自己的帮助。所以从本月开始，我们将和伦敦大学学院（UCL）计算机系一道启动顶级培训计划「Advanced Topics in Machine Learning」。这项计划由 DeepMind 的 Thore Graepel 牵头，其他应邀参与授课的学者包括机器学习领域各方向的领先人物，涵盖深度学习、强化学习、自然语言识别等方面。他们包括 Hado van Hasselt、Joseph Modayil、Koray Kavukcuoglu、Raia Hadsell、James Martens、Oriol Vinyals、Simon Osindero、Ed Grefenstette、Karen Simonyan、Volodymyr Mnih、David Silver 和 Alex Graves。他们中的一些人曾是 DeepMind 在 Nature 上发表的三篇论文的主要作者。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdO7ZHEpp06fPJUFQPmtnVNG5hV9LpictKKoCe7HpOTvfQ21TpS7bvbBDQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;DeepMind 研究科学家 Hado van Hasselt 在 UCL 上的授课，在 Advanced Topics in Machine Learning 训练营上&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今年一月，牛津大学计算机系也开展了自然语言处理中的先进深度学习课程。这项应用课程重点介绍使用循环神经网络分析和生成语音及文本方向上的最新进展，它由 Phil Blunsom 主讲，DeepMind 语言研究小组协助，向大四、研究生和博一学生开放。除此以外，我们还开办了暑期国际训练营，其中 DeepMind 成员会轮流授课，这样的活动已在德国、中国、南非和其他地区举行过。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们一直确保来到 DeepMind 的研究者不会失去他/她在学术上的影响力。我们的很多成员目前同时隶属于各家大学，包括 UCL、牛津、剑桥、MIT 和弗莱堡大学、里尔大学等等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们认为更多的独立学术机构对于人工智能领域的发展大有益处。因此，我们向众多实验室和其中的博士学生提供资助，帮助他们开展自己的研究。我们资助的大学包括阿尔伯塔大学、蒙特利尔大学、阿姆斯特丹大学、UCL 的 Gatsby Unit、纽约大学、牛津大学等等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们认为公司研究部门和学界的紧密联系对于未来人工智能意义重大。通过分享各自拥有的天分、专业知识和研究突破——不仅仅是以技术为导向，而是把合作扩展到伦理、安全和社会影响这样的广泛话题上去，这样才能为人工智能和它的未来创造更好的条件，让新技术拥有正能量，造福整个社会。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 24 Jan 2017 12:32:21 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 扎克伯格夫妇基金会收购Meta：将免费开放人工智能论文搜索引擎</title>
      <link>http://www.iwgc.cn/link/4468821</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心报道&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：蒋思源、朱思颖、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Mark Zuckerberg 和 Priscilla Chan 的 450 亿美元慈善机构正在进行第一笔收购，这笔收购的目的是为了让科学家们更容易实现对 2600 多万科研论文的搜索、阅读和文章之间联系的构建。他们的慈善机构（Chan Zuckerberg Initiative/CZI）正在收购 Meta——一家人工智能驱动的研究搜索引擎初创公司。在完成现有产品的优化之后，Meta 将会在近几个月免费开放自己的工具给所有人。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOoemW02JAF3ORDttfprjq5rJyXSlfqrg5EDrNeAIuooWzNq05bqLjag/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Meta 可以帮助科学家找到与自己项目相关的最新论文，另一方面也能协助投资机构与研究员之间的合作并且确立值得投资和作用的高潜力方向。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Meta 的特别之处在于通过人工智能识别不同论文的作者和引用，从而挖掘出最重要的研究而不只是找到有最佳 SEO 的论文。此外，还免费提供对 1 万 8 千个期刊和文献资料的全文入口。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Meta 的联合创始人、CEO Sam Molyneux 写道：「向前发展，我们的目的不是从 Meta 的数据和数据体量中获利；而是确保把这些资源能跨越不同的地区以最快的速度提供给最需要的人，从而让全世界获益。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对收购的这家多伦多的初创公司的技术和团队，CZI 还没有透露任何风声。Meta 于 2010 年创立，包括 Rho Canada Ventures 和 HIGHLINEvc 在内等投资机构对其注入 750 万美金。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这家初创公司之前对提供订阅服务或个性化解决方案的用户收费，但是现在 Meta 的所有产品将会免费给所有人。但是这次收购还需要一定的时间才能完成。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Cori Bargmann，Science 和 Brain Pinkerton 的董事长，CZI 的技术主管，介绍 Meta 将如何被使用时写道：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这类平台的潜力几乎是无限制的：一个研究员可以用 Meta 来发现可以用来理解冠心病的新兴技术；一个研究生可以看到两种不同的疾病激活相同的免疫防御途径的资料；临床医生能够更快找到研究最有前景的 Zika 诊治方案的科学家。从长远来看，Meta 还可以扩展到其他知识领域：例如，可以帮助教育者时刻关注人类学的研究进展，从而更好的理解小孩子是如何学习的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这一个收购案例中，因为 Meta 已经将自己打造成聚合研究（aggregation of research）的领导者，那么收购这家公司并将它的工具公开而不是建立一些新的就很有意义了。Zuckerberg 和他夫人的组织机构已经投资了一个初创作为 CZI 的教育提升，其包括了 Andela（非洲科技工作工程师预备学习）和 Byju（印度的视频学习平台）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过将 Meta 从商业领域转出来而聚焦并最大化其价值，CZI 能在更大范围社区内解决科研最大的障碍，也就是任何科学家或者是研究团队都无法查看极其巨量的研究论文这一问题。单单在生物制药上，每天就有 2 千到 4 千的新论文发表出来，因此研究人员很难从如此多的论文中找出哪些是最好的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Meta 原来称之为 Sciencescape，是通过文献检索系统（PubMed）和网页爬取建立整个论文库的索引，并且在作者分析引用了谁或链接了什么的时候进行识别并建立配置文件。这有效地将 Google PageRank 用于科学，从而很容易挖掘相关论文并对查看论文的优先度进行排序。它甚至能从以前的搜索中提供其新发表论文的一个更新反馈。下面是它如何在不同地方帮助研究界：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;科学家可以找到他们研究领域的最新数据和分析，确定已经完成的实验从而他们不需要再重复进行，他们还可以寻求调查研究的新机遇。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如同大学或基金会那样的资助机构可以与作者联系以支持他们未来的研究，也可以通过它发现科技突破点，从而确保他们的投资是正确的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;学生可以根据精确的词语匹配和搜索引擎优化（SEO）来排序结果，而不是寻找与他们研究最相关的论文或仅仅只是通过已有引用来查论文。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;学校可以确保他们的课程是最新的，并以最具潜力的方式训练学生在科学领域的进步。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这起收购之前，机器之心曾向 Meta 公司的 CSO Ofer Shai 了解过该公司的目标和状况，Shai 说：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;我们仍然在继续提升我们的算法和扩展我们的内容源，目前我们关注的重点是生物医学，但我们也正在从专利开始延伸到计算机科学、物理、化学等领域；所以我们关注的重点还是很多的。另一件激动人心的事情是我们启动了一个新项目来帮助发现和提取概念（concept）之间的『深度语义连接（deep semantic connections）』，这能帮助我们更好地理解科学。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;要指出一篇论文是关于神经网络的很简单，但要总结这篇论文并且给出总结的方式则会困难得多——而这正是我们正在解决的问题。所以我们目前正在大幅地采纳人工智能策略，并且也有而且还在聘请专业的资源来帮助我们变革。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当 CZI 刚宣布建立时，其灵活的 LLC 状态受到了人们的批评，因为这与慈善机构传统的结构不同。但是，能够收购 Meta 这样的营利性公司使其重复使用其获取的利润，这也正是 Zuckerburg 选择这种形式的原因。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「帮助科学家将能带来良性的循环，因为他们又能为更快的进展开发出新的工具，」Molyneux 写道，「Chan Zuckerberg Initiative 对这种『超（meta）』效应的认识是 Meta 成为了其中的关键环节的原因。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Chan Zuckerberg Initiative 知道即使有这个家庭有如此巨大的财富，他们也无法为科学的每个领域都提供赞助。但如果他们可以为每一位科学家提供可扩展的工具，从而让这些科学家不用再自己费心追求利益而实现更高的效率，那么 CZI 就能成为为人类服务的慈善。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心报道，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 24 Jan 2017 12:32:21 +0800</pubDate>
    </item>
    <item>
      <title>前沿 | 李飞飞团队新论文：通过迭代式信息传递的场景图生成</title>
      <link>http://www.iwgc.cn/link/4468822</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自arXiv&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicKlJibSVAicqxlFTC2znL3MfJWzJGay6vmrp2icxicBia2vLxyfdVEiav0C2nYhmle6LC2lOXc8wczdWrA/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;理解一个视觉场景（visual scene）不只是要理解单独的一个个物体。物体之间的关系也能提供丰富的有关这个场景的语义信息（semantic information）。在我们这项工作中，我们使用场景图（scene graphs）明确地对物体及其关系进行了建模。我们提出了一种全新的端到端模型，其可以从输入图像中生成这种结构化的场景表征（scene representation）。该模型可以使用标准 RNN 解决场景图推理问题（scene graph inference problem）以及通过消息传递（message passing）学习迭代式地提升其预测能力。我们的联合推理模型可以利用语境线索（contextual cues）来更好地预测物体及其关系。我们的实验表明我们的模型在使用 Visual Genome 数据集生成场景图和使用 NYU Depth v2 数据集推理支持关系（support relations）上的表现显著超越了之前的方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicKlJibSVAicqxlFTC2znL3MfQcIMp0fOMCIiaibibkKt7zloOjuibTP9NseS7VHd8IiaBFlHMY3SoMVhG0Q/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;图 1：目标检测器通过关注单个的物体来感知一个场景。这使得即使是一个完美的检测器也会在两个语义上有明显区别的图像上得到相似的输出（第一行）。我们提出了一种场景图生成模型，其以图像作为输入，然后可以生成基于视觉的（visually-grounded）场景图（第二行右图），该场景图捕获到了图像中的物体（蓝色节点）以及它们之间配对的关系（红色节点）。&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicKlJibSVAicqxlFTC2znL3Mf5uNnK7xKICG7tTiaSYXvpicGbo3LXbK5QGPX2xHPV5bpUH840B0z9Ukg/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 2：我们的模型的架构概览。给定一张图像作为输入，该模型首先使用一个 Region Proposal Network (RPN) [32] 产出一个目标提议（object proposals）集合，然后将从目标区域提取出来的特征传递给我们全新的图推理模块（graph inference module）。该模型的输出是一个场景图 [18]，其包含一个本地化的目标集合、每个目标的类别以及每个目标对之间的关系类型。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicKlJibSVAicqxlFTC2znL3MfDd9ypOwHXbzqmronrSgib4QloRTfib0upibI7OnoTgBNV7tD3tG7GeWJw/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 3：我们模型的架构图示。该模型首先会从目标提议集合中提取出节点和边（edge）的视觉特征，然后边 GRU 和节点 GRU 将这些视觉特征作为初始输入并得出一个隐藏状态的集合 (a)。然后一个节点消息池化函数（node message pooling function）在下一次迭代中计算从隐藏状态传递到节点 GRU 的消息。类似地，一个边消息池化函数（edge message pooling function）也会计算传递到边 GRU 的消息和推送 (b)。⊕ 符号表示学习到的加权和。该模型可以迭代式地更新 GRU 的隐藏状态 (c)。在最后一个迭代步骤，该 GRU 的隐藏状态可以被用于预测目标类别、bounding box offsets 和关系类别 (d)。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicKlJibSVAicqxlFTC2znL3Mf1dFjvAP9zr2z0RRemZnx1p8gJfF5KOPHdCcgBVBvQXWRXwJTTsWywg/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 6：我们的模型在 NYU Depth v2 数据集 [28] 上的支撑关系预测（support relation predictions）样本。尖头箭头表示从下面支撑，圆头箭头表示从旁边支撑。红色的箭头表示不正确的预测。我们还给不同的代码结构类涂上了不同的颜色：地面是蓝色的、结构是绿色的、家具是黄色的、工具是红色。紫色表示缺失的结构类别。注意分割掩码（segmentation masks）在这里仅用作可视化的目的。我们的模型使用了目标边界框作为输入，而不是这些掩码。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 24 Jan 2017 12:32:21 +0800</pubDate>
    </item>
    <item>
      <title>2016中国人工智能大事件：从百度深度学习平台到中国脑计划</title>
      <link>http://www.iwgc.cn/link/4456043</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：李亚洲、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote style="color: rgb(62, 62, 62); font-size: 16px; white-space: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;2017 年元旦，机器之心以 3 分钟视频的方式回顾了全球人工智能在过去一年中取得的发展。开源、无人驾驶、创业、深度学习等词汇似乎成为了人工智能领域的表征，一次又一次的拨动我们的神经。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721913&amp;amp;idx=1&amp;amp;sn=61fa411795fac54aacfa771959f0cba5&amp;amp;chksm=871b0a07b06c83118bf01830b545b89571d1550efab887e4369eef22ce5893fc0d9da3197df2&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721913&amp;amp;idx=1&amp;amp;sn=61fa411795fac54aacfa771959f0cba5&amp;amp;chksm=871b0a07b06c83118bf01830b545b89571d1550efab887e4369eef22ce5893fc0d9da3197df2&amp;amp;scene=21#wechat_redirect"&gt;元旦的视频总结&lt;/a&gt;中，我们能够明显的看到中国在整个人工智能领域的参与度。MXNet、百度无人车、科大讯飞都让我们看到了中国对人工智能发展的推动。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在为春发蓄势的年末，机器之心回顾了国内在 2016 年发生的人工智能大事件。百度无人车体验、开源深度学习平台 PaddlePaddle，多种算法、应用竞赛的举办，商汤、旷视、图普等创业公司新一轮融资的成功，这些种种让我们相信中国会成为人工智能的前沿阵地，如同高盛报告中提到的「人工智能前沿的重要参与者可能会继续来自美国和中国」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;百度开源深度学习平台 PaddlePaddle&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 2016 年 9 月 1 日百度世界大会上，百度首席科学家 Andrew Ng（吴恩达）宣布正式对外开放百度内部 3 年内不断丰富、优化的深度学习平台 Paddle，并更名为 PaddlePaddle：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9iaSgfTFRChrskKuUMbnjjpYicPfqxFR5BWtJichEEsuzCRaGTnzam4qPmZ9olBa9CNXFRrK9micibTUQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;深度模型：广泛支持各种深度学习模型，包括 DNN，CNN，RNN，复杂记忆（Memory）模型，NTM 等，支持多种优化算法&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;模型训练：支持多机多显卡训练，充分利用机器性能，支持稀疏更新&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;模型预测和评估：支持线下多语言（Python/C++）预测接口&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;据介绍，PaddlePaddle 有着极大的易用性、灵活性、高效性与扩展性。随着亚马逊年底宣布使用 MXNet，深度学习框架之间的竞争是愈演愈烈。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;第三届世界互联网大会，百度无人车体验&lt;/span&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;iframe class="video_iframe" data-vidtype="1" allowfullscreen="" frameborder="0" height="417" width="556" data-src="https://v.qq.com/iframe/preview.html?vid=h0346g9f437&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0"&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2015 年底，百度宣布正式成立自动驾驶事业部，且表示「计划三年实现自动驾驶汽车的商用化，五年实现量产。」一年将近，在第三届世界互联网大会在乌镇召开之际，百度无人车邀请了多位嘉宾切身体验百度已经从「测试」走向「试乘」的无人车。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这成为百度继 2013 年启动无人车项目、2015 年底完成多种路段测试、今年 9 月和 10 月分别获得美国加州自动驾驶汽车道路测试许可证和完成加州首次公共道路测试，无人车项目的有一个重大进展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这也是国内首次第四级别的自动驾驶汽车全程无干预的在全开放城市道路上行驶，投入乌镇运营无人车 15 辆，3 天内超过 200 位乘客规模化试乘，应付了多时段的复杂气象条件。更加重要的是，这是支持 5 款车型的跨平台无人驾驶技术。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;参考文章：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720582&amp;amp;idx=3&amp;amp;sn=998e786926ccae181bd2cfb915a6fa69&amp;amp;chksm=871b0d38b06c842eab4405aa07ade9ea08dbfd0de6a2a8eea2b60ea5f1d93428d6c8614d83d2&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720582&amp;amp;idx=3&amp;amp;sn=998e786926ccae181bd2cfb915a6fa69&amp;amp;chksm=871b0d38b06c842eab4405aa07ade9ea08dbfd0de6a2a8eea2b60ea5f1d93428d6c8614d83d2&amp;amp;scene=21#wechat_redirect"&gt;业界 | 体验百度无人车，系统性人工智能技术让自动驾驶越来越近&amp;nbsp;&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;腾讯 AI Lab 研究院成立&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今年，腾讯成立了人工智能研究院腾讯 AI Lab，专注机器学习、计算机视觉、语音识别、自然语言处理等人工智能领域的研究。但腾讯一直没有对外做过多宣传，机器之心是报道腾讯 AI Lab 研究的第一家媒体。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;后来，腾讯副总裁、AI Lab 院长姚星在 2016 年腾讯研究院年会上正式向外公布了腾讯 AI Lab 所关注 AI 四个基础研究领域和 4 个专属研究方向，并且强调说，「AI 对腾讯来说是非常重要的，对整个中国互联网都很重要。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;参考文章：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722553&amp;amp;idx=3&amp;amp;sn=5a9b6e4dfe30957744b9331c65dbfdca&amp;amp;chksm=871b1487b06c9d91e37b9cc02f910ac7460a23fa9dc4cd5929835b497b811128f87ee9083e20&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722553&amp;amp;idx=3&amp;amp;sn=5a9b6e4dfe30957744b9331c65dbfdca&amp;amp;chksm=871b1487b06c9d91e37b9cc02f910ac7460a23fa9dc4cd5929835b497b811128f87ee9083e20&amp;amp;scene=21#wechat_redirect"&gt;演讲 | 腾讯副总裁姚星：人工智能真实的希望与喧哗的隐忧&lt;/a&gt;；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720536&amp;amp;idx=1&amp;amp;sn=76e38d366841b567d38c4334df175eeb&amp;amp;chksm=871b0d66b06c8470d96d6faf9c636e0e0eed6d0e89e74abd3ecfe52c68f384a906c95efd1329&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720536&amp;amp;idx=1&amp;amp;sn=76e38d366841b567d38c4334df175eeb&amp;amp;chksm=871b0d66b06c8470d96d6faf9c636e0e0eed6d0e89e74abd3ecfe52c68f384a906c95efd1329&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;独家专访 | 腾讯 AI Lab 公布首项研究：提出独特神经网络实现实时视频风格变换&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;腾讯大数据开源高性能计算平台 Angel&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 12 月 18 日于深圳举办的腾讯大数据技术峰会暨 KDD China 技术峰会上，腾讯大数据宣布推出了面向机器学习的「第三代高性能计算平台」——Angel，并表示将于 2017 年一季度开放其源代码。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;据腾讯数据平台部总经理、首席数据专家蒋杰介绍，Angel 是腾讯大数据部门发布的第三代计算平台，使用 Java 和 Scala 语言开发的面向机器学习的高性能分布式计算框架，由腾讯大数据与香港科技大学、北京大学联合研发。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9iaSgfTFRChrskKuUMbnjjpNQwV6YI4AibLP62GprMXOiaW86w1MB3WhfZibyWC5oq1z2ic1fjPHrdzKw/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;采用参数服务器架构，解决了上一代框架的扩展性问题，支持数据并行及模型并行的计算模式，能支持十亿级别维度的模型训练。不仅如此，Angel 还采用了多种业界最新技术和腾讯自主研发技术，性能更高、系统更具易用性。自今年年初在腾讯内部上线以来，Angel 已应用于腾讯视频、腾讯社交广告及用户画像挖掘等精准推荐业务。Angel 更是腾讯大数据下一代的核心计算平台。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;参考文章：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721559&amp;amp;idx=1&amp;amp;sn=0ca5ad4d7ce70c260cb596c8eae76d97&amp;amp;chksm=871b0969b06c807feba50561c516c9987e0a0b354f0ab554d14de2b8e7035134f879f1419b77&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721559&amp;amp;idx=1&amp;amp;sn=0ca5ad4d7ce70c260cb596c8eae76d97&amp;amp;chksm=871b0969b06c807feba50561c516c9987e0a0b354f0ab554d14de2b8e7035134f879f1419b77&amp;amp;scene=21#wechat_redirect"&gt;腾讯大数据将开源高性能计算平台 Angel，机器之心专访开发团队&amp;nbsp;&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;人工智能华人力量&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;就像前面所说的「人工智能前沿的重要参与者可能会继续来自美国和中国」，2016 年，我们看到了华人对人工智能发展所做出的贡献，华人力量也逐渐被国际所认可。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;华人力量的彰显可从两个维度得见：1. 中国力量在国际学术组织和会议上的存在感和影响力愈发强大，可以看成是中国人工智能快速发展的一个标志；2. 一批优秀的华人学者为产业界所看重，其中最具代表性的美籍华人李飞飞。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 百度副总裁王海峰当选 ACL 会士&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;11 月 28 日晚，国际计算语言学会（The Association for Computational Linguistics：ACL）公布了 2016 年 ACL 会士名单。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;截至目前，ACL 历史上在全球范围内累计评出过 40 位会士。而王海峰则成为了首位获此荣誉的中国大陆科学家，同时也是 ACL 目前最年轻的会士。ACL 会士评选委员会在对王海峰的评语中写道：王海峰在机器翻译、自然语言处理和搜索引擎技术领域，在学术界和工业界都取得了杰出成就，对于 ACL 在亚洲的发展也做出了卓越贡献。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;参考文章：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720823&amp;amp;idx=3&amp;amp;sn=e0670a173ef0af638625f4eda6a78355&amp;amp;chksm=871b0e49b06c875f13241f75027892adc1b7e01daf521d7dcc26e04d681c08041b13709ab979&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720823&amp;amp;idx=3&amp;amp;sn=e0670a173ef0af638625f4eda6a78355&amp;amp;chksm=871b0e49b06c875f13241f75027892adc1b7e01daf521d7dcc26e04d681c08041b13709ab979&amp;amp;scene=21#wechat_redirect"&gt;资讯 | 百度副总裁王海峰当选 ACL 会士，成为中国大陆首位获此殊荣的科学家&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 黄学东、周志华当选 2016ACM Fellow&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2016 年 12 月 8 日，世界领先的计算机学会、全球最大的计算机领域专业性学术组织 Association for Computing Machinery（ACM）正式公布了 2016 年当选的 ACM Fellow 名单。今年共有 53 名成员入选。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;新当选的 ACM Fellow 中，仅有两位华人：一位是美国微软首席语音科学家黄学东博士，贡献是「对口语语言的处理」；另一位是中国大陆学者、南京大学的周志华教授，当选理由是「对机器学习和数据挖掘的贡献」（for contributions to machine learning and datamining）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 李飞飞加入谷歌&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2016 年 11 月 16 日，谷歌宣布其雇佣了两位人工智能领域的顶级研究者：斯坦福大学人工智能实验室主任李飞飞、前 Snapchat 研究主管李佳，这两位华裔女科学家都是计算机视觉行业的专家。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在人工智能风起的今天，科技巨头从学术界拉拢人才已经成为了一种常态，而李飞飞加入谷歌的消息无疑也掀起了轩然大波。从另一个角度来讲，李飞飞作为第一代中国移民，最后成为谷歌人工智能团队新任领导者，也让我们看到了华人力量的崛起。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;参考文章：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720553&amp;amp;idx=1&amp;amp;sn=c88e48aab2d789d744ac1629ffec9a8a&amp;amp;chksm=871b0d57b06c844121d6fdf6fda546996e87c1cc395bef55fde20cb910b2fe1bbcdf8d1ce6c9&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720553&amp;amp;idx=1&amp;amp;sn=c88e48aab2d789d744ac1629ffec9a8a&amp;amp;chksm=871b0d57b06c844121d6fdf6fda546996e87c1cc395bef55fde20cb910b2fe1bbcdf8d1ce6c9&amp;amp;scene=21#wechat_redirect"&gt;深度 | 谷歌新人李飞飞：击碎玻璃天花板的华裔女科学家&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;中国脑计划一体两翼战略，推动人工智能发展&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2016 年 11 月份时，中国科学院神经科学研究所、中国科学院脑科学与智能技术卓越创新中心、香港科技大学生命科学部和分子神经科学国家重点实验室、中国科学院自动化研究所在《Neuron》上联合发表了一篇概述论文《China Brain Project: Basic Neuroscience, Brain Diseases, and Brain-Inspired Computing》，介绍了「中国脑计划」在基础神经科学、脑疾病和脑启发计算上的研究进展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在论文中，作者们写到，「神经科学的一个普遍目标——理解人类认知的神经基础——应该成为「中国脑计划（China Brain Project）」的核心。此外，中国也应该投入资源和研究能力，以满足迫切的社会需求。由主要脑疾病造成的社会压力逐渐上升，所以现在迫切需要一种预防、诊断和治疗脑疾病的新方法。在大数据的新时代，受大脑启发而得的计算方法和系统对于实现更强的人工智能和更好地利用越来越多的信息至关重要。正是由于对这些问题的考虑，中国脑计划项目提出了「一体两翼」战略（图 1）。其中对基本神经回路机制的认知的基础研究提供了输入并且接受来自脑疾病的诊断/干预和脑启发智能技术（两翼）的反馈。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9iaSgfTFRChrskKuUMbnjjpicvEXkvvHm2CdoibU9I9do7dWUhPCgG1jdzGZysGfo6fRB2OS0HdRBXw/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此篇论文的作者包括：蒲慕明（Mu-ming Poo）、杜久林（Jiu-lin Du）、熊志奇（Zhi-Qi Xiong）、叶玉如（Nancy Y. Ip）、徐波（Bo Xu）、谭铁牛（Tieniu Tan）。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;参考文章：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720765&amp;amp;idx=1&amp;amp;sn=d023cbc68ce9cec7e00ebc44d940a7d9&amp;amp;chksm=871b0d83b06c84952a94754e60f22126dd64a9c198deaeccc7ae3c6dc04eb0f190c9877de4f3&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720765&amp;amp;idx=1&amp;amp;sn=d023cbc68ce9cec7e00ebc44d940a7d9&amp;amp;chksm=871b0d83b06c84952a94754e60f22126dd64a9c198deaeccc7ae3c6dc04eb0f190c9877de4f3&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-align: justify;"&gt;深度 | 全面解读中国脑计划：从基础神经科学到脑启发计算&lt;/a&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;神经机器翻译，不止谷歌一家&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2016 年 9 月底，谷歌宣布将其神经机器翻译技术（GNMT）整合到了其谷歌翻译应用中，引起了很大关注。但实际上，利用人工智能做机器翻译的企业并不只有谷歌一家，中国的百度、讯飞、搜狗等公司都在 2016 年拿出了一些值得关注的机器翻译上的新应用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在机器之心 2016 年对百度 NLP 团队和百度首席科学家吴恩达的采访中，他们就曾谈到百度其实也非常早的就进入到了神经网络机器翻译领域。已当选 ACL Fellow 的百度副总裁王海峰博士就曾告诉机器之心：「我们从 2014 年开始便尝试做基于神经网络的翻译系统，2015 年发布在线翻译系统的时，BLEU（Bilingual Evaluation Understudy）指标已经比传统的 SMT（统计机器翻译）系统高六、七个点。我们同时还开发了离线版本，可以在手机上使用，当时学术界对于深度学习的翻译方法到底是否实用还有一番争论，我们很早就发现基于 Attention 机制的 Seq2Seq 深度学习模型是有用的，经过多次实验验证，在很多集合上超过了传统方法。同时，针对 NMT 本身存在的一些问题，进行了技术攻关，短短 3 个月的时间便完成了开发和上线。当大家还在讨论 Attention 机制时，我们已经结合了原有的统计方法上线。可以说，百度翻译是全球首个互联网神经网络翻译系统。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除了百度外，讯飞和搜狗也在持续投入机器翻译技术。2015 年，科大讯飞曾在美国国家标准技术研究院（NIST）组织的机器翻译大赛（Open Machine Translation Evaluation，NIST 2015）中取得了全球第一的好成绩。而在 2016 科大讯飞年度发布会上，该公司正式发布了「晓译翻译机」。据介绍：这款机器基于科大讯飞机器翻译的国际领先技术，达到了英语大学六级的水平，能够实现语音输入后中英、汉维的实时翻译，具有易用性、稳定性、安全性等特点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;搜狗也在 2016 年 5 月份上线了英文搜索（后在 12 月份升级为搜狗海外搜索频道并新增了搜狗翻译频道）。搜狗英文搜索可提供跨语言检索功能，可自动将中文翻译成英文进行查询，再生成英文查询结果。在 11 月的乌镇世界互联网大会上，搜狗展示了机器同传技术，可将演讲者的中文同步翻译成英文并实时上屏。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;参考文章：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719470&amp;amp;idx=1&amp;amp;sn=3368dea980517ea7d7942967da2740dc&amp;amp;chksm=871b0090b06c89863620be4e75c757940d03d8a43cd3c1d9a8309b6594c1bccd769cab193177&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719470&amp;amp;idx=1&amp;amp;sn=3368dea980517ea7d7942967da2740dc&amp;amp;chksm=871b0090b06c89863620be4e75c757940d03d8a43cd3c1d9a8309b6594c1bccd769cab193177&amp;amp;scene=21#wechat_redirect"&gt;重磅 | 谷歌翻译整合神经网络：机器翻译实现颠覆性突破&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721480&amp;amp;idx=1&amp;amp;sn=191cb46a8ebbb71519d5d668705aa81b&amp;amp;chksm=871b08b6b06c81a0265fc5de459f78cd5e1e887f3569f57a2e7ccb4ff7835d73c66699cc483a&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721480&amp;amp;idx=1&amp;amp;sn=191cb46a8ebbb71519d5d668705aa81b&amp;amp;chksm=871b08b6b06c81a0265fc5de459f78cd5e1e887f3569f57a2e7ccb4ff7835d73c66699cc483a&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;机器之心独家对话吴恩达：很多技术其实是中国最先开始应用的&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717168&amp;amp;idx=2&amp;amp;sn=462ac989178d34f15ab56947416b8b5f&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717168&amp;amp;idx=2&amp;amp;sn=462ac989178d34f15ab56947416b8b5f&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;机器之心专访 | 讯飞研究院王士进：如何让机器拥有阅读推理能力？&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716160&amp;amp;idx=1&amp;amp;sn=871d9d398de5cf665265e5eeab3dc040&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716160&amp;amp;idx=1&amp;amp;sn=871d9d398de5cf665265e5eeab3dc040&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;专访 | 搜狗的人工智能研发与应用：让技术在产品中创造更多用户价值&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722227&amp;amp;idx=2&amp;amp;sn=4dd4514c3e957422697a8854a2dae8d6&amp;amp;chksm=871b0bcdb06c82dbf69d2f2157b287318471692720449c5f12001188b26830f7fcf0e4d9ce17&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722227&amp;amp;idx=2&amp;amp;sn=4dd4514c3e957422697a8854a2dae8d6&amp;amp;chksm=871b0bcdb06c82dbf69d2f2157b287318471692720449c5f12001188b26830f7fcf0e4d9ce17&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;业界 | 搜狗知音引擎再进一步，实现语音实时翻译&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;算法与应用大赛&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据竞赛是今年中国人工智能领域的又一亮点，学术界、产业界纷纷举办数据竞赛来争取人才，挖掘新技术的产业应用。当然，以下三场竞赛并不代表 2016 年内举办过的全部竞赛，但管中窥豹，希望大家能从中洞见数据竞赛在人工智能发展中带来的益处。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今日头条 2016 Byte Cup 世界机器学习比赛：2016 年，中国人工智能学会主办，今日头条、电气电子工程师学会（IEEE）中国代表处协办了 2016ByteCup 国际机器学习竞赛。这场数据分析竞赛的主题是：如何在社交问答系统中精准地匹配专家和问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;据了解，此次数据竞赛共有 1000 多支队伍参赛，冠亚季军队伍分别是 brickmover、天穹战队和西电战队。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;参考文章：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721644&amp;amp;idx=2&amp;amp;sn=f2145ab0797a722b6887cc8a9ebb219d&amp;amp;chksm=871b0912b06c8004ffb4338f6c790c7b9b50f69b6bf638414ec9e28fab1c5ec5beddbd139ab9&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721644&amp;amp;idx=2&amp;amp;sn=f2145ab0797a722b6887cc8a9ebb219d&amp;amp;chksm=871b0912b06c8004ffb4338f6c790c7b9b50f69b6bf638414ec9e28fab1c5ec5beddbd139ab9&amp;amp;scene=21#wechat_redirect"&gt;专访 | 今日头条 2016 Byte Cup 大赛实战经验分享：要充分挖掘模型本身的信息&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;上海 BOT 大数据应用大赛：今年上海大数据产业基地（市北高新）、上海大数据联盟、英特尔（中国）有限公司和华院数据技术（上海）有限公司联合主办，机器之心协办了国内首个专业化人工智能大赛「2016 上海 BOT 大数据应用大赛」。在计算机视觉与人工智能聊天机器人商业应用这两大热门赛题上，全球近 400 支专业团队进行了角逐。本次大赛从 2016 年 9 月 1 日初赛开始到 11 月 11 日总决赛结束，经历了三个多月。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;参考文章：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720516&amp;amp;idx=3&amp;amp;sn=80ed2bde64e872e29dbeb2bab36e8c0b&amp;amp;chksm=871b0d7ab06c846c28886012b6c117597f5ee3b8617b0095253139a1170aef63f91d09022098&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720516&amp;amp;idx=3&amp;amp;sn=80ed2bde64e872e29dbeb2bab36e8c0b&amp;amp;chksm=871b0d7ab06c846c28886012b6c117597f5ee3b8617b0095253139a1170aef63f91d09022098&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;业界 | 2016 上海 BOT 大数据应用大赛闭幕：决赛 11 个聊天机器人项目盘点&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;滴滴 Di-Tech 算法大赛：今年上半年，滴滴研究院举办首届 Di-Tech 算法大赛，这是一场面向全球大数据人才的算法竞赛。滴滴通过开放国内真实的出行数据，用最炙手可热的研究课题征集更聪明的解决方案。而且此次比赛中获得的解决方案有机会直接应用于「滴滴出行」产品端。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;参考文章：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717305&amp;amp;idx=3&amp;amp;sn=abc06a528c76ed2cb2c16c1991508e07&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717305&amp;amp;idx=3&amp;amp;sn=abc06a528c76ed2cb2c16c1991508e07&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;业界 | 滴滴算法大赛背后，是对人工智能人才与技术的呼唤&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;融资：图像识别公司屡获巨额融资&lt;/span&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;创业、融资是体现人工智能热度的另一个维度。2016 年，我们看到人工智能成为了最受资本市场追捧的领域之一，机器之心很早就关注的一批创业公司接连获得高额融资。下面这三家融资的成功引起了业内极大的关注。当然，这并非完全性统计。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 旷视科技：旷视科技（Face++）是一家专注于机器视觉和人工智能的技术公司，是国内人脸识别领域知名的创业公司。据机器之心获得的消息称，旷视科技获 2000 万美元新一轮融资。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9iaSgfTFRChrskKuUMbnjjpaaXibhfkFkk6z9l8mvoOUQ6jkIduoShibS8EEfJRfpFKiaqouEPWMLvicQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;旷视科技成立于 2011 年，创业之初获得了联想之星的一笔天使融资；2013 年获得创新工场百万美元 A 轮投资。2014 年 11 月，获得 2200 万美元 B 轮融资，2015 年完成 B 轮 4700 万美元融资。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;延展文章：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722208&amp;amp;idx=3&amp;amp;sn=a1f217aa810783e9dfb137072f11d969&amp;amp;chksm=871b0bdeb06c82c853d4d6d4177523e33cd35d10e3c59f6f98b2e1924381cffbc06ace4520b3&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722208&amp;amp;idx=3&amp;amp;sn=a1f217aa810783e9dfb137072f11d969&amp;amp;chksm=871b0bdeb06c82c853d4d6d4177523e33cd35d10e3c59f6f98b2e1924381cffbc06ace4520b3&amp;amp;scene=21#wechat_redirect"&gt;专栏 | 旷视 (Face++) 孙剑：创业公司里的研究之美&amp;nbsp;&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 图普科技：据机器之心一手消息称，图普科技已经于今年 9 月完成了新一轮融资，金额为千万美元，由晨兴资本领投，北极光创投跟投。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图普科技由微信创始团队成员之一的李明强创办，主要做基于图像识别技术的第三方内容审核服务，在识别色情、暴恐、时政敏感信息、小广告等违规图片和视频方面市场占有率领先。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;延展文章：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717202&amp;amp;idx=2&amp;amp;sn=31b6924db5eb4500fa4a57d9669878fc&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717202&amp;amp;idx=2&amp;amp;sn=31b6924db5eb4500fa4a57d9669878fc&amp;amp;scene=21#wechat_redirect"&gt;专访 | 图普科技李明强：用产品思维打造图像识别的场景化应用&amp;nbsp;&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 商汤科技：2016 年 12 月 14 日，商汤科技宣布完成 1.2 亿美元新一轮融资，本轮由鼎晖投资，万达集团、IDG 资本、StarVC 等投资方共同参与。此前商汤科技，曾于 2014 年 11 月获得 IDG 资本的千万美元投资；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;商汤集团是一家科技创新公司，致力于引领人工智能核心「深度学习」技术突破，构建人工智能、大数据分析行业解决方案。目前，商汤汇聚了一支庞大的深度学习算法研究团队，拥有上百名深度学习研究人员。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;延展文章：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716578&amp;amp;idx=2&amp;amp;sn=471e5e957b51feedc88062532a5a041c&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716578&amp;amp;idx=2&amp;amp;sn=471e5e957b51feedc88062532a5a041c&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;CVPR2016 | 商汤科技论文解析：服饰识别搜索技术&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716578&amp;amp;idx=2&amp;amp;sn=471e5e957b51feedc88062532a5a041c&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716578&amp;amp;idx=2&amp;amp;sn=471e5e957b51feedc88062532a5a041c&amp;amp;scene=21#wechat_redirect"&gt;CVPR 2016｜商汤科技论文解析：人脸检测中级联卷积神经网络的联合训练&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716180&amp;amp;idx=2&amp;amp;sn=e217c6b32ee5ef5eb8a6a7470c872e8a&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716180&amp;amp;idx=2&amp;amp;sn=e217c6b32ee5ef5eb8a6a7470c872e8a&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;CVPR 2016｜商汤科技论文解析：行为识别与定位&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716355&amp;amp;idx=2&amp;amp;sn=da3bae2c4352773db3660ca113977245&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716355&amp;amp;idx=2&amp;amp;sn=da3bae2c4352773db3660ca113977245&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;CVPR 2016 | 商汤科技论文解析：物体分割&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 23 Jan 2017 12:33:02 +0800</pubDate>
    </item>
  </channel>
</rss>
