<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>重磅 | 谷歌大脑养成记：从识别猫到突破性机器翻译</title>
      <link>http://www.iwgc.cn/link/3928460</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自NYT&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;em style="color: rgb(136, 136, 136); font-size: 12px;"&gt;谷歌如何使用人工智能来改进谷歌翻译等许多谷歌服务？《纽约时报》杂志今日发布了一篇重磅长篇《The Great A.I. Awakening》全面解读谷歌利用机器学习重塑自身的战略。机器之心编译时进行了适当的删减。&lt;/em&gt;&lt;br/&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;序言：你即你所读&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;十一月一个周五的晚上，东京大学著名人机交互教授 Jun Rekimoto（暦本純一）正在准备演讲，他开始留意到社交媒体上出现了一些奇特的博文。谷歌公司颇受欢迎的机器翻译服务已经突然有了大幅提升。Jun Rekimoto 开始亲自测试这一服务。结果让他惊讶不已。他在一篇博文中写下了一些发现。他比较了两个版本的《伟大的盖茨比》（一个 1957 年 Takashi Nozaki 的版本，一个是 Haruki Murakami 近期的修订版本）中的几个句子，选择了谷歌翻译能够翻译的句子。他后来对我解释道，Haruki Murakami 的翻译非常优美，但显然是 Murakami 风格的。谷歌翻译后的日文尽管有点小小的不自然，但是，读起来感觉更加易懂（transparent）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;接着，博文的第二部分从另一个方向（日文到英文）检查了谷歌翻译。他把自己翻译的海明威《乞力马扎罗的雪》的开头输入进去，让谷歌翻译成英文。结果发现翻译的准确度难以置信。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Rekimoto 将自己的发现放在了 Twitter 上，几个小时后，数以千计的人也贴出了自己的实验结果。一些翻译结果很赞，另一些的翻译结果颇有喜剧效果。每个人都好奇：谷歌翻译是怎么变得如此惊艳的？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌公司的人工智能研究机构谷歌大脑（Google Brain）成立于五年前。成立原则是：通过试错熟悉周围世界的人工「神经网络」或许会发展出类似人类的灵活能力。这个概念不是新东西。不过，其大部分历史，在绝大多数计算机科学家看来，有些狼藉甚至神秘。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管如此，2011 年以来，谷歌大脑已经证实深度学习方法可以解决传统手段无法解决的难题。语音识别之前并不理想，直到谷歌大脑更新了这一技术；机器学习的应用在谷歌移动平台安卓上的表现堪比人类。同样，图像识别也是硕果累累。不到一年前，谷歌大脑首次开始充满热情地更新整个产品线。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;翻译工具声名鹊起的那一年是 2006 年，打那时起，它就成为谷歌最可靠也最受欢迎的资产；月用户量达 5 亿多人，每天需要进行 1400 亿词的翻译。它不仅自成一体，也是谷歌邮件、浏览器以及其他产品的一部分，是该公司数字业务中浑然天成的一部分。Pichai 解释说，不仅仅是难民危机，公司也估计翻译的地理政治重要性：他身后的屏幕上出现了一幅图表，一个陡峭的曲线表明最近阿拉伯语和德语之间的翻译需求翻了五番。谷歌翻译团队一直在稳定地为产品添加新的语言和功能，不过，过去四年的质量提升已经明显放缓。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;直到今天，翻译工具引进了人工智能技术。首轮尝鲜的语言包括英语、西班牙语、法语、葡萄牙语、德语、中文、日语、韩语和土耳其语。接下来还有上百种语言——大概每个月处理八种，直至明年年底。翻译工具的焕然一新仅花了九个月的时间。人工智能系统一夜之间取得的成果相当于旧的技术一辈子成果的总和。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌决定以人工智能为中心的策略也反映出整个业界范围内的机器学习热。过去四年中，特别是谷歌、Facebook、苹果、亚马逊、微软和百度这六家公司已经启动了人工智能人才争夺战，特别是争夺大学里的人才。公司许诺的资源和自由已经让顶尖学术机构的人才越来越少。硅谷谁人不知 Mark Zuckerberg 用电话、视频聊天等糖衣炮弹亲自督导公司最想要的研究生。诱人的七位数年薪并非罕见。参加这一领域最重要的学术会议的人员已经翻了四倍。利害攸关的不仅是渐进创新，还要控制住能够代表未来全新计算平台的东西：无处不在的人工智能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;Part 1:学习的机器&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1. 大脑的诞生&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然 Jeff Dean 的职称是高级研究员（senior fellow），但却是谷歌大脑实际上的负责人。作为医疗人类学家与公共健康流行病学专家的儿子，Dean 在世界多个地方长大——明尼苏达州、夏威夷、波士顿、阿肯色州、日内瓦、乌干达、索马里、亚特兰大。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在高中和大学的时候，他写的软件被世界卫生组组所使用。从 1999 年开始，他就加入了谷歌，从此他几乎插手了谷歌的每一个重大业务中的核心软件系统。谷歌公司文化的一个可爱伪影就是 Jeff Dean Facts，模仿「罗礼士的真相」写下：Jeff Dean 的 PIN 是 pi 的后四位；在贝尔发明电话之后，他看到有一通 Jeff Dean 的未接电话；在系统最大等级是 10 的时候，Jeff Dean 提升到了 11 级（这一个确实是真的）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2011 年的一天，Dean 走进谷歌的休息区碰见了吴恩达。当时吴恩达还是斯坦福大学计算机科学教授，也是谷歌的顾问。吴恩达告诉了 Dean 关于 Project Marvin 的事，这个项目是吴恩达最近帮助建立的实验「神经网络」的一次内部尝试。Dean 自己也在 1990 年在明尼苏达大学上学时做过简单版本的神经网络。如今，研究神经网络的学术人员 5 年来又开始发展，从屈指可数的几个增长到了几十位。吴恩达告诉 Dean 由谷歌神秘部门 X 实验室正在做的 Project Marvin 已经取得了一些惊人成果。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Dean 对此非常感兴趣，愿意在此项目上付出「20%」的工作时间，也就是期望每个谷歌员工在自己核心工作之外的项目上付出的工作时间。不久之后，他建议吴恩达让另一个有神经科学背景的 Greg Corrado 加入进来。在春末，吴恩达最好的毕业生之一 Quoc Le 也加入了进来，成为了第一个实习生。然后，一些谷歌工程师喜欢称 Project Marvin 为谷歌大脑。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因为人工智能一词是 1956 年才被首次提出，一批研究员一直以来在思考创造人工智能的最佳途径，写出很大的、综合的程序，能同时展示逻辑推理与世界上足够知识的规则。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;例如，如果你想要从英语翻译到日语，你要把英语的所有语法规则编程到计算机，然后是牛津英语词典中的所有定义。接下来你还要把日语的语法规则与单词编程，只有所有的语句用源语言输入之后才能让它把语句翻译成目标语言。这种观念通常被称为符号人工智能，因为它对认知的定义是基于符号逻辑的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但这种老旧的方法主要有两个问题。第一个就是这样做非常耗费人工时间。第二个就是这种方法只能处理规则和定义都非常清晰的问题，比如数学问题和国际象棋。对于翻译来说，这种方法完全失效，因为词语不仅只有词典上定义，而且语言的使用中常常有很多特殊用法，尽管有很多语法规则。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;iframe class="video_iframe" data-vidtype="1" style="   z-index:1; " height="375" width="500" frameborder="0" data-src="https://v.qq.com/iframe/preview.html?width=500&amp;amp;height=375&amp;amp;auto=0&amp;amp;vid=e0355310x9a" allowfullscreen=""&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;一份 1961 年的文摘强调人工智能研究的前提：如果你可以编程让计算机模拟高级的认知任务如数学和象棋，那么你终将找到让计算机实现模拟意识的途径。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个系统所能做到的事情是有限的。20 世纪 80 年代，卡内基梅隆大学的一位机器人方面的研究员指出，让计算机去做那些成人能够做到的事情很容易，但是让它们去做那些 1 岁孩童做的事情几乎是不可能的，像是拿着一颗球，或者是辨别车辆等。在 20 世纪 90 年代前，计算机象棋方面取得了一些进展，但我们离强人工智能还很远。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌大脑是首个投资人工智能所能呈现的可能的重大商业机构。Dean、Corrado 和吴恩达用兼职时间工作，协作实验，但他们很快就取得了进展。他们从近期的理论基础以及上世纪 80 年代、90 年代的思路中获取设计灵感，并利用公司无与伦比的数据资源和大量计算基础设施，在大量的银行标记数据（例如，准确录音的语音文档）上构建网络，结果计算机的回应和真实情况实现了很好的匹配。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Dean 相当保留地说，「进化中动物发育出眼睛是一大进步。」当时，我们像往常一样坐在一间带有白板的会议室，他在白板上密密麻麻写上谷歌大脑的时间轴，以及与近期神经网络的历史拐点的关系。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「现在计算机有了眼睛，我们可以围绕现有的能力建造眼睛从而理解不同的难题。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他们建造的这些能力看起来很简单，但影响很大。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicr33MwRF3MYPqDITzNX5zhT1DuUhcFWc3IzJz4JZYsH5qY2ojdHOMmcR4JRouY5wMDZUCliaRZMiaA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图：Geoffrey Hinton&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2. 想像不到的实习生&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Dean 说，在谷歌大脑诞生的一两年左右，该部门在开发一岁儿童智能水平的机器上取得非常好的结果。其语音识别团队将他们的旧系统和神经网络结合了起来，实现了近 20 年来最好的提升。他们的系统的物体识别能力也提升了一个数量级。这并不是因为谷歌在这一年突然想出了什么突破性的方法，而是谷歌开始向其中投入更为显著的资源和人才。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;作为当时一些概念的提出者和优化者，Geoffrey Hinton 在谷歌大脑成立的第二年加入谷歌大脑，和吴恩达共事（吴恩达现在在百度领导着 1300 人的人工智能团队）。当时，Hinton 只想离开其在多伦多大学的岗位 3 个月，所以因为一些合同上的原因他的身份是实习生。在「实习」培训期间，Hinton 还问了「什么是 LDAP（一种用户登录方法）？」这样的问题。那里有很多 25 岁左右的聪明学生一起培训，他们只是对深度学习有所耳闻而已，他们会问：「这个老头子是谁？为什么他在这里实习？」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Hinton 说：「在午餐时间，有人大叫：『Hinton 教授，我上过你的课！你在这里做什么？』自那以后，一切都变好了。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;几个月后，Hinton 带着两个学生在 ImageNet 图像识别竞赛上展现出了真正激动人心的成果。谷歌很快就接触了 Hinton，要给他和他的学生工作邀请。他们接受了。Hinton 说：「我认为他们对我们的知识产权感兴趣，结果发现他们感兴趣的是我们。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Hinton 来自一个老式的英国家庭，希望在天文学或流体动力学领域做出一些小的贡献。他有一位伟大的曾曾外祖父乔治·布尔——计算机基础的布尔逻辑的提出者，还有一位曾曾祖父是著名外科医生，他的父亲是一位有冒险精神的昆虫学家，他的叔叔是洛斯阿拉莫斯国家实验室研究员……他在剑桥和爱丁堡上学，然后在卡内基梅隆任教，最后落脚多伦多大学，并在那里度过了他的半生时间（他的研究工作得到了加拿大政府的大力支持）。我在当地的谷歌办公室拜访了他，他会说一些奇怪的话，比如说：「计算机会比美国人先理解讽刺。」&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自 60 年代末 Hinton 在剑桥的本科阶段以来，他就一直在研究神经网络，被视为这个领域的先驱。但在那个时候，当他谈论机器学习时，人们看他就好像在谈论托勒密球或水蛭。那时候神经网络被当作是未经证实的愚蠢想法。造成这种看法的主要原因是当时一个被炒作过度的项目：Perceptron（感知器）——康奈尔大学心理学家 Frank Rosenblatt 在 50 年代末开发的一个人工神经网络。该研究的资助者美国海军预期其「能走路、说话、看见、书写、复制自己和意识到自己的存在」。结果没让任何人满意。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;美国的人工智能元老 Marvin Minsky 也在他 1954 年普林斯顿的论文里研究过神经网络，但自那以后，他渐渐地就对 Rosenblatt 对神经范式的夸张说法感到厌倦了（他们当时也在竞争美国国防部的资金）。后来，Minsky 和他的 MIT 同事出版了一本书，证明有一些非常基本的问题是感知器无法解决的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Minsky 对感知器的批评只扩展到了一层（layer）的网络，而后来，他却又阐释了和当代的深度学习非常相似的思想。但那个时候 Hinton 已经明白使用很多层的网络可以执行复杂的任务。对于神经网络的最简单的描述是：基于发现数据中模式的能力来进行分类和预测。如果只有一层，你只能发现一个简单模式；有更多的层时，你甚至能发现模式的模式。比如图像识别，现在这项任务依赖于一种被称为「卷积神经网络」的技术（该技术是由 Yann LeCun 在其 1998 年的开创性论文中提出的，他是 Hinton 的博士后）。该网络的第一层学习非常简单的「边（edge）」，意味着一个 off-pixel 之后跟着一个 on-pixel，或相反。后续的每一层都会在前一层中寻找模式。边的某一个模式可能是圆或三角形，而圆或三角形的模式又可能是一张脸……这种技术有点类似于人类视觉系统处理到达眼睛的信息的方式。在每一个感知步骤，不重要的细节会被丢弃。如果边、圆、三角形之类的模式能够组合成一张脸，那么我们的目的就达到了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;iframe class="video_iframe" data-vidtype="1" style="   z-index:1; " height="375" width="500" frameborder="0" data-src="https://v.qq.com/iframe/preview.html?width=500&amp;amp;height=375&amp;amp;auto=0&amp;amp;vid=k0355veznol" allowfullscreen=""&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;多层的深度神经网络的问题在于试错（trial-and-error）的部分会随着深度的增加而越来越复杂。这就像让孩子学习把玩具放进身边的箱子 A，一下子就学会了。如果让他学习带着玩具走过一段很多分支的路然后放进 A 箱，那就可能会在中间走错路。怎么让机器学会这样复杂的指令呢？为了解决这个问题，Hinton 及其同事在 70 年代末和 80 年代的停滞期发明（或者说重新发明）了一个解决方案，然后计算机科学家对神经网络的兴趣有了短暂的恢复。Hinton 说：「人们对此感到兴奋，但我们炒作过度了。」不久之后，计算机科学家又继续将 Hinton 看作是怪人和神秘主义者了。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但这些思想却受到了哲学家和心理学家的欢迎，他们将其称为「联结主义（connectionism）」或「并行分布式处理（parallel distributed processing）」。Hinton 说：「少数几个人的想法就让这个思想继续燃烧，这是一个不错的神话。在人工智能领域这确实是事实，但是在哲学领域，很多人相信这是正确的，他们只是不能实践。」尽管 Hinton 得到了加拿大政府的资助，但他自己也不能做到。「那时候的计算机算力和数据都不够。我们这边的人常常说：『呃，如果我有一台真正大的机器，它就有效果。』这可不是什么很有说服力的论据。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3. 深度学习的深度解释&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人脑中神经元的平均数量的数量级大概是 1000 亿。其中每一个神经元都与其它 10000 个神经元相连，这意味着突触的数量是在 100 万亿到 1000 万亿之间。我们目前仍然远远不能构建那么大规模的网络，但谷歌大脑的投资已经帮助实现了大约小鼠大脑的人工神经网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了理解为什么规模会如此重要，你首先要理解这项技术的细节。有些人认为人工智能可以直接从图书馆或网络上读取理解知识，但事实并非如此。它们的工作是在数据中寻找模式——先是基本模式，然后寻找更复杂的模式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果这个简短的解释不够说明问题，没有技术背景的读者可以阅读下一节关于猫的故事（当然这一节也有猫）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;假设你要在老式的符号式人工智能模型上编程一个猫识别器。那么你需要花大量的时间来帮机器定义什么是「猫」——四条腿软软的毛、尖尖耳朵喵喵叫……所有这些信息组合起来构成了一只猫。然后你向其展示一张图片用于识别。首先，该机器需要分解图片中不同的元素，然后再将这些元素和它记忆中的信息进行比对。如果有四条腿、尖耳朵、有胡须、有尾巴、表情傲慢，那么这就是一只猫。但是这个模型却不能识别苏格兰折耳猫——这种有基因缺陷的猫的耳朵耷拉在头上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在让我们来尝试用神经网络识别猫。我们并不会人工编写猫的定义，它们的定义存在于大量互连的「开关」之中，就像一条带有大量分岔路的道路。在这团开关的一边是输入的图片，在另一边则是对应的输出标签。然后你让网络自己通过调整其中的每一个开关来将一个输入映射到对应的输出。这个训练过程就像是走隧道迷宫一样，目的就是要将输入和合适的输出连接到一起。训练数据越多，隧道的数量和复杂性就越大。一旦训练完成，这团开关之中就有了大量的隧道，可以在其从未见过的数据上做出可靠的预测，这就是所谓的「监督学习」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为什么这样的网络需要如此之多的神经元和数据呢？因为从某种程度上讲，该网络的工作方式就像是一种「机器民主」。可以假想你想要计算机进行 5 种分类，你的网络由数亿个神经元「投票人」组成，他们可以进行 5 个选项的投票：猫、狗、蜘蛛猴、勺子和除颤器。然后你拿出一张图片问：这是猫、狗、蜘蛛猴、勺子和除颤器中的哪一个？投票者开始投票，然后网络统计员根据大多数的意见认为这是狗。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然后你告诉他：「不对，这是猫。再投一次。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然后，统计员回头检查哪些投了猫，哪些选了其它的。选了猫的投票者获得了加权——「一票可当两票用」（至少在选择猫的时候，选择其他分类时权重可能不同）；这样不断调整知道得到正确的答案。所以重要的不是单个神经元的票，而是整个投票的模式。你的投票者越多，你就能获得越多的模式。如果你有数百万个投票者，你就能获得数十亿种模式。每一种模式都可以对应一种结果，这些不同的模式归类成不同的类别。训练的数据越多，网络就越了解一种模式属于哪一个类别，就能在未来遇到没有标注的图片时做出更准确的分类。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;计算机科学领域对这些思想有如此大的抵触的部分原因是其输出只是基于模式的模式（patterns of patterns) 的预测，这不会是完美的，而且这样的机器也不能为你定义到底什么是一只猫。只有当它看到一只猫时，它才能知道那是猫。但这个方法的最主要缺点还是数据量。要让神经网络理解一只猫是在懒洋洋晒太阳还是躲在阴影里注视世界，我们需要给神经网络送入大量大量的数据，需要大量大量的投票者。而这是很难满足的需求。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;值得一提的是，神经网络的概率性本质使其无法胜任某些任务。但有些情况我们又需要它完美，比如自动驾驶汽车的应用。但这不是唯一的缺陷。监督学习是一种基于有标签数据的试错过程。也就是说，机器的学习使用了人类最先设计的分类，这个过程有很大程度上的人类参与。如果你的训练数据存在对女性或少数族裔的偏差，那么最后得到的模型也会是有偏见的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4. 猫识别论文&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在最初的一两年，谷歌大脑设计出了具有 1 岁孩童智力的机器，这些努力让其最终从 X 实验室毕业，进入了公司更宽阔的研究中。（谷歌 X 负责人曾提到谷歌大脑曾支付过 X 的所有花费）。而那时的谷歌大脑团队依然不足 10 人，也不清楚最后会得到什么。但即使如此，他们仍在思考接下来会发生什么。人的思想不需要多少时间就能学会识别球和其它东西，时间或长或短。然后，开始进军语言。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌大脑在这个方向迈出的第一步是一篇关于猫的论文，也让谷歌大脑出名了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这篇论文证明的是带有十亿「突触」连接的神经网络（要比当时公开的任何神经网络都要大数百倍，当然也要比我们大脑小无数数量级）能观察原始的未标记数据，从而为自己挑选出高级的人类概念。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌大脑研究员像网络展示了 YouTube 视频的数百万张静止图片，无论是翻滚的猫，还是面部清楚的猫，神经网络会先剥离出一个稳定的模型，能毫不迟疑地识别出这是猫。机器之前从未被编程过有关猫的先验知识，它直接接触世界、为自己抓取想法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当时大部分的机器学习还受限于标记数据的质量。猫识别论文证明机器也能过处理原始为标记数据，即使这些数据人类之前从未建立先验知识。这不仅是猫识别研究上的重大进展，也是整个人工智能的重大进展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这篇猫论文的第一作者是 Quoc Le。他在越南顺化城边长大，父母都是农民，家中甚至没有电。但艰苦的环境没有埋没 Quoc Le 的数学天赋，他很小就被送到科学院学习。在上世纪 90 年代后期，他还在学校中的时候，他尝试开发了一个聊天机器人。他想看看这到底有多难。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「但事实上，」他对我悄悄说道，「这实在是难。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Quoc Le 从越南的农村一路走来，进入了堪培拉的澳大利亚国立大学。在那里，他进行了人工智能的一些研究。时间主导的方法，例如给机器传递边缘这样的概念，让他感觉有点像是作弊。Quoc Le 当时并不知道，这一领域当时在全世界有几十位学者正在做着同样的研究，很多人都不约而同想到了机器可以从头开始学习。在 2006 年，Quoc Le 在德国大学城 Tübingen 的马克斯·普朗克生物控制论研究所任职。在一个读书小组中，他接触了 Geoffrey Hinton 的两篇论文。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「当时出现了一次很大的争论，」他对我说道。「一次非常大的争论。」我们坐在一个小型会议室里，一个狭窄的有着很高天花板的空间，配备了一个小桌子和两个白板。他看着他在他背后白板上画的曲线，轻声说道，「我从没有见过这样激烈的辩论。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他记得他在读书小组中站起来发言，「这就是未来。」他表示，发表这种言论在当时那种情形下可不是一个很好的选择。他在澳洲国立大学的前导师，在小组里坐在他的旁边，事后发来电子邮件质问：「你为什么要这样做？」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我当时没有办法回答这个问题，」Le 说，「我只是好奇。那是一个成功的范式，但实话说我只是对这个新范式感到好奇。」2006 年时，此类讨论活动还屈指可数。」很快他进入了吴恩达的门下，在斯坦福大学开始了追随 Hinton 理念的旅程。「到 2010 年底，我已经非常确定马上将有变革会发生了。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随后发生了什么？不久以后，Le 成为了 Google Brain 的实习生，在那里，他继续着自己的研究——最终成就了这篇猫的论文。在一个简单的层面上，Le 希望看到计算机是否可以训练自己识别给定图像中最重要的信息。他的神经网络训练了从 YouTube 中获取的大量数据。之后，他命令神经网络丢掉图像中包含的一些信息，但他没有指定抛弃哪些信息。机器开始服从命令，抛弃一些信息，一开始，被抛弃的内容是随机的。随后他说：「好了，现在根据保留的信息尝试重新构建原始图像。」这就像他在让机器「总结」一张图片的内容，然后再从总结描述中还原这张图片。如果图片描述中包含的是不相关的信息——如天空的颜色而不是胡须——机器就不能有效地重建原始图像。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这就像一个原始人，需要在剑齿虎附近隐蔽自己的行踪，这个过程不能发出一点声音。Le 的神经网络不需要原始人那样小心，它可以无限次地试错。每一次它都会在数学上「选择」一个新的最优解试图让信息的处理更加准确。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;神经网络在某种程度上来说是一个黑箱。它识别模式，但识别模式的过程对于人类观察者而言并不总有直观意义。同样的网络既能识别猫，也能识别出某些形式的家具和动物的组合，比如一条长椅和一只山羊重叠在一起。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Le 并不认为自己是一个语言学者，但他认为这项研究和他早期的聊天机器人有一些相同之处。在猫论文之后，他意识到如果你要求神经网络总结一张照片，你应该要求它生成一句完整的话来形容照片的内容。这个问题是 Le 和他在谷歌中的同事 Tomas Mikolov 在之后两年里的主要研究内容。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在那个阶段，谷歌大脑发展迅速。有一段时间，他们在大楼的同一层办公，可以随时和高管们分享自己的想法。他们后来收到了一封电子邮件，信中要求他们禁止团队成员在 Larry Page 和 Sergey Brin 的套房前面的沙发上睡觉，因为这会让来访的客人们感到尴尬。随后，他们被分配在街对面的一个大楼中，在那里，他们在厨房中交流，不会被繁文缛节所拖累。在那段时间，谷歌的竞争对手们纷纷加快了追赶步伐。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Le 一直向我强调他与 Tomas Mikolov 的密切合作，他以一种奇怪的方式重复 Mikolov 的名字，听起来有点可怕，他在说这个词的时候表现出了前所未有的庄严，我终于无法抑制住自己的好奇心，问道：「他是...？」Le 点了点头。「他现在在 Facebook 了。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicr33MwRF3MYPqDITzNX5zh9rRBf1iaRz3lia97aEJ080ozrEme9TIxjy566Nhul0btTFruyTAHnh8g/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Google Brain 团队的图片小组在 2012 年发布著名的「猫论文」，展示了神经网络对于未标记数据的分析能力&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他们花费了很长一段时间构建这个神经网络架构，使其不仅可以进行简单的照片分类，也可以识别各种静态的，但同样复杂的结构，如语言和音乐。其中用到的许多方法在 20 世纪 90 年代已被提出，Le 和他的同事们回到那些长期被忽视的研究成果中去寻找。他们明白，一旦建立起了具有基本语言预测能力的系统，你就可以用它从事其他各种智能的任务——例如自动回复电子邮件或预测一个谈话流程。你会发现它看起来很神奇；在外行眼里，看起来它就像是在思考。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;Part II：语言机器&amp;nbsp;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;5. 语言学的转向&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前谷歌大脑团队不像是一个巨大的企业层次分明的科技公司的一个部门，而更像是一个社团或者一个学术集体，或者说是一个「星际酒店」。这些年来谷歌大脑团队的成员一直是整个谷歌内部比较自由且广受赞誉的员工。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当我 6 月份开始进驻谷歌大脑团队的时候，办公室里还有成排的空工位，但已被贴上便利贴，上面大多写着类似「Jesse，6/27」（新职工及将要入职时间）这样的标注。现在这些空工位都已满。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌大脑团队的发展使得团队的负责人 Dean 开始有点担忧公司对需求的掌控。他想一改谷歌以往「成功毁灭者」的形象，而外界对谷歌的这个印象是由于谷歌在产品开发落地上的能力远不及其在理论研究上的能力。他曾做过简单的估算，并用一个只有 2 页的 PPT 向执行董事汇报了他的估算。「假设未来使用安卓手机的用户每人每天和手机语音对话的时间为三分钟，那么这就是我们所需服务器的总量。」也就是谷歌需要将他们的全球计算能力扩增 1 到 2 倍。「这个数量听起来有些吓人，但是我们必须去做——去建造新的数据处理中心。」他不愿去设想如果不这样做的后果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是还有另外一种解决方案：只需设计芯片，成批量的设计出让所有计算过程更快的芯片并在全球各地的数据中心使用。这些芯片将被称为「张量处理单元（TPU）」，这些芯片区别于普通芯片在执行计算过程时是非精确计算，这也是体现芯片价值之处。如在计算 12.246 乘 54.392 的时候，芯片会给一个 12 乘 54 的近似计算值。在数学层面上，一个神经网络只是一组成百上千或者成千上万的矩阵的有序计算。对这些矩阵的计算过程而言，计算速度比精确计算更重要。「一般情况下，为某一特别任务而设计硬件是一个不明智的做法。因为这样设计出来的硬件只能加速该项任务的计算过程。但是由于神经网络的普适性，你可以在很多其他的任务执行时运用专为神经网络而设计的硬件。」Dean 说。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当芯片的设计过程即将完成的时候，Le 和两个同事终于证明出神经网络可以用来构造语言模型。他的结论是基于「词向量」而得出的。当你看到图像的时候，大脑会从边缘到图形依次概括图像主要内容。语言概括的过程也与此类似，你本质上也是在构建不同维度的距离图。在构建的时候，依据惯用使用规则，构建一个词和其他单独的每一个词的距离。计算机并不是以人认知语言的方式进行语言分析的，而是在构建的距离图里转移、偏转或者倾斜词向量。二维的向量图是没有价值的。比如在地图中你希望 "cat "在 "dog "附近，同时 "cat "也在 "tail""supercilious""meme"附近，因为你需要构建这些词相互之间的关系而且一个词（这里是"cat"）对于其他所有词的关系有强弱之分。如果一个词与其他所有词之间的关系各自成为一个独立的向量维度，那么一个词与其他词之间的关系就能一步构建出来。但是创建一个维度为 16 万的向量不是一件容易的事，所幸的是某种语言的词向量图完全可以用一个只有一千维度的向量图来很好的构建出来。换句话说来说，在这个词向量图的空间里，每个词是由一组 1000 个数值来定位的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是在这样构建的空间里，并不能很好地显示出不同种人的称呼之间的区别。如果把定位「king」的那组数对应的减去定位「queen」的那组数中相同位置的数那么得到的新向量将会同定位「man」的那组数对应减去定位「man」那组数的向量相同。如果让机器学习整个英语词汇所构建的向量空间图以及整个法语词汇所构建的向量空间图，在理论上你是可以训练出这样的一个神经网络，从英语中选取一条语句对应的生成法语中向量值相同的语句。在训练时，你只需要先将大量的英文语句作为网络的数据输入，然后将对应的法语语句作为网络的输出，进行一个监督学习的过程，在机器完成这个监督学习之后神经网络将会习得词语之间的关系，这就跟图像分类器能识别不同像素点之间的关系一样。词语和像素之间的主要区别在于一副图像中的像素点在时间上是没有先后之分的，而词语的使用是有时间先后的。你需要时刻让神经网络"记住"它是以时间先后的顺序来处理语句，即从语句的第一个词至最后一个词的顺序进行。在 2014 年 9 月的某周里，这种处理方法的所有理论工具在三篇论文中被提出来。一篇来自 Le，另外两篇来自加拿大和德国的研究者。他们的研究催发了一些开发式的项目如谷歌大脑的 Magenta 项目，这个项目是对机器如何创作艺术作品和音乐作品的研究。同时也为工具性的研究（如机器翻译）扫清障碍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;6. 伏击&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Le 的论文表明神经翻译是靠谱的，但是他只使用了一个相对较小的公共数据集。（对于谷歌来说很小，要知道谷歌拥有世界上最大的公共数据集。过去十年旧的翻译系统已经积累了比其使用的数据集大上成百上千倍的生产数据。）更重要的是，Le 的模型对于超过 7 个单词的句子就不怎么管用了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Mike Schuster 那时是 Brain 团队的一名研究科学家，接管了这项研究。他明白如果谷歌找不到一种能将理论见解拓展到产品层面的方式，其他人也会找到的。这个项目花了他两年的时间。Schuster 说，「你想要翻译一些东西，你就要有数据、做实验，并且你做了，效果未必如你所愿。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Schuster 是个时刻保持紧张专注，大脑永远灵活的家伙，皮肤黝黑，肩膀不宽，穿着窄口过膝迷彩短裤，脚踩一双闪着荧光的 Nike Flyknits。Schuster 在前西德 blast-furnace 区的杜伊斯堡长大，研究的是电子工程，后来去京都研究早期的神经网络。上世纪 90 年代，他做了一个会议室大小的神经网络机器实验；花费数百万美元，训练了好几周才能做一些你现在一个小时内就能在台式电脑上训练出来的东西。1997 年，他发表了这篇研究的论文，之后的十五年都几乎没有人引用过；今年，这篇文章被引用了 150 次左右。他不乏幽默，但穿着上总是流露出一种严肃的感觉，他的签名带着一种日本人和德国人特有克制感。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个非解决不可的问题很棘手。一方面，Le 的代码是自定义编写的，与谷歌之后新开发的开源机器学习平台 TensorFlow 不兼容。2015 年秋天，Dean 给 Schuster 介绍了另外两名工程师，Yonghui Wu 和 Zhifeng Chen。然后他们花了两个月将 Le 的结果复制到这个新系统上。Le 就在旁边，但是他从头到尾都没有给过他们一点指导。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;就像 Schuster 说的那样，「很多工作都不是在完全清楚的情况下完成的。他们不知道自己为什么要做。」今年二月，谷歌的研究组织——谷歌的一个松散部门，大约有 1000 名员工，做的都是前瞻性和一些未知的研究——将总部外的各个带头人召集到联合广场上的 Westin St. Francis 酒店，奢华程度略低于谷歌自己在东部一英里之外三藩市里的那家店。上午是几轮的「闪电会谈」，快速汇报最新的研究进展，下午是悠闲的跨部门「促进讨论。」这次召集是为了提供一个场合能促进不可预测的、不明朗的、贝尔实验室风格的交流，期望这种交流能给公司带来更多的生产力量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;午餐时间，Corrado 和 Dean 两人在找谷歌翻译的负责人 Macduff Hughes。Hughes 一个人用餐，两名谷歌大脑的成员坐在离他有点距离的两边位置上。就像 Corrado 说的那样，「我们伏击了他。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「O.K.」Corrado 想放松 Hughes 的警惕，让他的呼吸恢复平稳。「我们要和你谈点事。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他们告诉 Hughes 2016 年是个不错的时机，可以用神经网络重整一下谷歌翻译——数百名工程师超过十年编出来的代码。这个旧系统采用的是 30 年来所有机器翻译系统采用的方法：它能将连续的句子片段隔开，在一个大型统计衍生词汇表中检索句子中的单词，然后使用一组后处理规则附上适当的结果，再重新排列起来组合成句子。这个方法叫「基于短语的统计机器翻译」，因为直到该系统获取下一个短语，它才知道这个短语是什么。这就是为什么谷歌翻译的输出有时像一对抖动后的冰箱贴。如果谷歌大脑团队的神经网络能用到翻译中来，就能实现阅读并在一个草稿上呈现完整的句子。它会扑捉整个语境，这和句子表达的意思紧密相关。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;赌注似乎很低：谷歌翻译带来的收入最小，而且这种情况可能会一直持续下去。对于大多数以英语为母语的用户来说，即使是激进地升级一个服务，也不会给他们带来任何用户体验上提升。有个案例可以说明这个问题，人类水平的机器翻译不仅是短期内的必需品，长期来看其发展也很可能会带来颠覆性的变化。在这中间，公司打什么样的战略至关重要。谷歌估计，英语中有 50% 的使用来自 20% 的世界人口。如果谷歌打算进军中国——这里大多数搜索引擎流量的市场份额属于它的竞争对手百度——或印度，得体的机器翻译将是基础系统不可或缺的一部分。2015 年 7 月，百度也发表了一篇关于神经机器翻译的开创性论文。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在更远的将来，机会更多，机器翻译可能是迈向一个使用人类语言的通用计算设备的第一步。这将在真正的人工智能的发展道路上代表一个主要的转折点，或许它本身就是主要的转折点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;硅谷的大多数人都意识到机器学习是一条捷径，所以 Hughes 预料到 Corrado 和 Dean 会来找他谈这个事情。他仍然保持怀疑。这个温和强壮刚刚步入中年的男人，蓬乱的褐色头发，两鬓却已斑白。Hughes 是一个典型直线条的工程师，就是那种上世纪 70 年代出现在波音飞机草稿桌上工匠。他知道，多年来在谷歌其他岗位上或者谷歌之外其他地方的很多人一直试图做神经翻译的研究，不仅是实验室里的还有能投入量产的，但是收效甚微。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Hughes 听了他们的案例，最后小心翼翼地说，这听上去就好像他三年内就能做出来一样。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Dean 却不这么想。「如果我们真的想做，今年内就能做出来。」人们喜欢并崇拜 Dean 的一个原因就是他总能成功地实现自己的想法。另一个原因是，他能轻松地说一件很严肃的事情，「我们能不能把我们的想法加进去。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Hughes 那时肯定神经翻译不会那么快实现，他个人不关心是一个原因。「我们来为 2016 年做准备，」他回去告诉他的团队。「我们不会说 Jeff Dean 没那么快。」一个月后，他们终于可以运行一个并排（side-by-side）实验，将 Schuster 的新系统与 Hughes 的旧系统相比较。Schuster 想用它来试一试英语-法语翻译，但是 Hughes 建议他换个语种试试。「英语-法语太简单了，提升不会太明显。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Schuster 不会坚持这个挑战。评估机器翻译的基准度量是 BLEU 得分，它将机器翻译的结果与许多可靠的人类翻译的平均水平相比较。当时，英语-法语最好的得分是 20s。有一个点的改进就是非常好；两个点的改进就算是十分出色了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;英语 - 法语语对上的神经系统改进比旧系统多达 7 分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Hughes 告诉 Schuster 的团队，在过去四年里，他们自己的系统中从来没有出现过这么大的改进。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了确保这不是侥幸得出的，他们也利用人力对此进行了平行比较。在用户体验得分中，其中例句得分从 0 到 6，平均改善了 0.4——大致相当于旧系统在其整个生命周期的总增益。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicr33MwRF3MYPqDITzNX5zhxhZSG03us3Nk8PI3xZfibtEeJNIxs6kibuFJJtnYJgwy5H6KOdrPpPdw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;谷歌的 Quoc Le（图右），他的工作证明了神经翻译的合理性，Mike Schuster 帮助将这项工作应用于谷歌翻译。图片来源：Brian Finke for The New York Times&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;三月中旬，Hughes 给他的团队成员发了一封邮件，暂停了所有旧系统有关项目。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;7. 将理论变为产品&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在那之前，神经翻译团队只有三个人（Schuster、Wu 和 Chen），但是在 Hughes 的支持下，更多的团队开始了联合。后来他们在谷歌大脑写字楼开会，会议一般有十几人参加。当 Hughes 或 Corrado 在的时候，他们是仅有的以英语为母语的人，工程师们用混杂的语言和数学进行表达，不过他们讲中文、德语和日语等其他语言。在 Google，谁举行会议并不总是完全清楚的，但这次会议是没有疑义的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不过即便如此，他们所需要采取的步骤还是不完全确定的，整个过程都是不明确的。Schuster 将手伸出到胸前 8 英寸说：「这就像在大海里游泳，你只能看到这么远的距离，目标就在某处，或许它就在我们这里」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大多数谷歌的会议室都配有视频聊天显示器，它会在闲置时显示极高分辨率的过饱和公开 Google+照片，包括梦幻森林、北极光或德国国会大厦。Schuster 指向正在显示华盛顿纪念碑水晶般静立的夜景屏幕，「外人会认为我们每个人都有双筒望远镜，可以看到遥远的前方。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;到达现在的理论工作已经让他们精疲力竭了，那么将它转化为可行的产品呢，做学术的科学家可能就会将其归于纯粹的工程学，并认为要实现起来是不难的。首先，他们需要确保有良好的数据进行训练。谷歌数十亿词的「阅读」训练主要是由中等复杂性的完整句子组成，就像海明威的那样。其中一些是公共领域内的：统计机器翻译 Rosetta Stone 就是数百万页的加拿大议会的完整的双语记录建立的。然而它的大部分都从 10 年收集的数据中剔除，包括从热心的受访者得到的众包翻译数据。他们团队的语料库里有大约 9700 万个独特的英语「单词」。但是一旦他们删除了表情符号、拼写错误和冗余，他们的有效词汇量就只剩下了大约 16 万。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然后你不得不重新关注用户实际想要翻译的内容，这通常与是否使用合理的语言无关。谷歌发现许多人不去看复杂句子翻译地是否完整，而是考察那些奇怪的小碎片语言。如果你希望网络能够处理用户查询流，那么就必须确保将其定向到处理小碎片语言。该网络对其训练的数据非常敏感，正如 Hughes 向我提出的一点：「神经翻译系统就像一个小孩，它正在学习一切」他笑着说：「你们都应该谨慎点」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不管怎样，他们需要确保整个翻译过程是快速和可靠的，这样用户才能接受这个产品。在今年 2 月，神经翻译翻译一条 10 个单词长的句子需要 10 秒钟，他们是不可能去推荐一个如此慢的翻译系统。所以翻译小组开始对一小部分用户进行延迟实验，以伪造延迟的形式识别容错。他们发现，如果翻译需要 2 倍到 5 倍的时间不会被注意到，但是到达八倍的减速就会了。他们不需要确保所有语言都是这样，在高流量的语言（如法语或中文）的情况下，他们几乎不会放慢速度。而对于一些更模糊更抽象的事物，他们知道如果用户能获得更好的质量，那么基本不会害怕轻微的延迟。他们只是想防止用户转换到某些竞争对手的服务上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于 Schuster 而言，他承认不是太清楚他们团队能否让这个系统运行地足够快。Schuster 还记得和 Chen 在小厨房里的对话，他当时说：「一定有一些我们不知道的，但能使我们的系统运行地足够快的东西，虽然我不知道是什么」。不过他们都知道他们需要更多的计算机，确切地说是需要更多的图形处理器训练神经网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Hughes 去问 Schuster 他是怎么想的：「我们是不是应该使用一千块图形处理器？」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Schuster 回答：「为什么不用 2 千块？」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;十天后，他们增加了 2000 块图形处理器。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;到 4 月份，原来的三人阵容已经超过 30 人，其中一些人，如 Le，来自谷歌大脑团队，许多人还是来自谷歌翻译。5 月，Hughes 为每种语对配备了一位临时主管，每个人都需要将结果录入到一个大型的共享绩效评估电子表格中。在任何时候都至少有 20 个人正在进行为期一周的独立实验，并处理出现的各种意想不到的问题。有一次有一个模型毫无缘由地把开始所有句子中的数字删除。这个问题花了几个月的时间才得以解决。Schuster 说：「所有人都在着急地大喊大叫。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;到春末，各部分的工作都聚在一起。团队引入了一些诸如 word-piece model、coverage penalty、length normalization 的概念。Schuster 说，「每个部分的结果都能改进几个百分点，总体就会有显著的效果。」一旦模型标准化，它将只是一个单一的多语言模型，而不是目前使用的翻译的 150 种不同模型，这一模型将会随着时间的推移而不断改进。但是，当一个工具通过学习机器来实现普遍化时，实现自动化的过程会需要异于常人的才智和努力。但是很多做出的决定都依赖的是直觉。每层需要使用多少个神经元？1024 还是 512？有多少层？一次运行多少句？需要训练多久？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;Schuster 对我说，「我们做了成百上千次实验，直到我们确定在一周后我们可以停止训练。你总是在问我们什么时候才可以结束？我怎么知道我做了些什么？你永远不知道你做了些什么。机器学习的机制永远都达不到完美的状态。你需要训练，在某一个时间，你需要停下来。这就是整个系统的本质。对于某些人来说，这确实很困难。这就是创造艺术一样，你得拿着你的刷子慢慢让它变得完美。所以我们要去做，有些人会做得越来越好，有些人会越来越糟糕。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;5 月份，谷歌大脑团队了解到，他们唯一能够使系统作为产品快速实现的方法是能够在 TPU 上运行。正如 Chen 所说：「我们甚至不知道代码是否能工作。但是我们知道没有 TPU 肯定是不行的。」他还记得曾经一个接一个地去请求 Dean，让他帮忙保留一些 TPU。Dean 保留了，但是 T.P.U.s 却不能正常工作。Wu 花了两个月的时间坐在硬件团队的人旁边，试图找出原因。他们不只是在调试模型，他们也在调试芯片。神经翻译项目成为整个基础设施投资概念的验证。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;六月一个星期三的晚上，在 Quartz Lake 举办的一个会议以对近来出现在行业权威网上论坛上百度的一篇论文的讨论开始。Schuster 说，「确实百度出了一篇论文，就好像有人在监视着我们一样——相似的架构、相似的结果。」它们的 BLEU 分数是谷歌在二三月份内部测试时达到的分数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌团队知道它们应该早一点发布自己的结果，这样或许就能够打败它们的竞争对手。但 Schuster 说道：「推出要比发布更重要」。最终他们确实首先推出了更好的服务。但是 Hughes 说，「我们不想说这是一个新系统，我们只想确保它能够正确运行。理想的情况是看到大批人在 Twitter 上面说：『你们有看到谷歌翻译现在有多厉害吗？』」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;8. 一次庆祝&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;9 月下旬一个星期一的下午，团队的论文最终发布，论文共有 31 位作者。第二天谷歌大脑和谷歌翻译的成员聚集在为厨房中举行了一个小小的庆祝活动。一定程度上，它们是在庆祝谷歌大脑和谷歌翻译的联合工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌的神经翻译终于开始运作了起来。在聚会举办的时候，公司的中英翻译已经处理了 1800 万条查询指令。几周之后，谷歌正式将神经翻译拓展到了中英互译领域，这是谷歌取得最好业绩的语言对。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Hughes 说道：「上一分钟存在问题，上上一分钟也存在问题，对论文的测量误差或者是一个奇怪的标点符号都可能导致系统缺陷，但所有的问题我们都解决了，或者至少当前是有效解决了。神经翻译目前取得了一些进步，但是这种进步是间断的、垂直的，而不是一条光滑的曲线。相关的翻译并不仅是关于两个团队，而是关于将理论转变为现实，目的是为了交流、合作。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Dean 说：「它们展示了可以同时处理两大主要任务的能力：做研究，并且将结果摆在 5 亿人（我猜测）的面前。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所有人听到都发出了笑声，并不是因为这句话夸大其词，反倒是因为它丝毫没有夸张。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;后记：没有灵魂的机器&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;或许对于人工智能最著名的历史性批判或者是在其立场上做出的断言，便设计到了翻译的问题。伯克利的哲学家 John Searle 中 1980 年提出中文屋（Chinese room）的实验。在这个思想实验当中，他将一个只会说英语的人关在一间只有一个开口的封闭房间中。房外的人不断向房间内递进用中文写成的问题。房间里面的人只有几张桌子和一本用英文写成的手册，指示他该如何处理收到的汉语讯息及如何以汉语相应地回复。房内的人便按照手册的说明，很快他们的回答似乎就变得与与讲中文的人没有什么差别了。那么我们可以说房间里面的人「懂」中文吗？Searle 的答案是否定的。他在之后用计算机来作比喻，他说「给适当编程的电子计算机赋予正确的输入和输出，就会造成一种计算机和人脑一样也具有思维的感觉。」&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于谷歌大脑团队，以及在硅谷从事机器学习工作的几乎每个人来说，这种观点都有些文不对题。这并不是说它们在无视哲学问题，而是说他们对智能的思维有着完全不一样的看法。和 Searle 不一样，他们没有从特殊的心理方面来分析「意识」，Gilbert Ryle 将其称之为「意识的灵魂」。他们只是相信我们称之为「意识」的复杂技能分类，在很多简单机制的协调活动中是随机出现的。因此，逻辑推理就成为了一种补足的方式，就像是我们扔球和接球的能力一样。人工智能并不是要去建立一种思维，它是对于解决问题工具的改进。Corrado 在我第一天进入谷歌的时候就对我说，「人工智能并不是关于机器『知道什么』和『理解什么』，而是关于它可以『做什么』，还有至关重要的一点是——它目前还不能做什么」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而「知道」和「做」这两个概念当中确实存在一些文化和社会含意。Schuster 曾经因为媒体将「谷歌表示人工智能翻译的能力已经与人类无异」（GOOGLE SAYS A.I. TRANSLATION IS INDISTINGUISHABLE FROM HUMANS）放上头条一度在论文中强调这一点，他经常重复论文中的观点——「现在的发展状况比以前要好很多，但还是不及人类。」他希望人们能够清楚地意识到他们所做的工作是在帮助人类，而不是要取代人类。然而机器学习的崛起又为我们提出了难题。如果你相信，根据 Searle 的观点，人类「洞察力」当中存在着一些特殊之处，那你就可以在人类和机器之间划出一条明显的界限。如果你持相反的看法，那么就当然不能。所以为什么那么多人都支持前者似乎就容易理解了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 2015 年 MIT 关于人工智能根源的一次大会上，有人问 Noam Chomsky 他对机器学习的看法是怎么样的。他轻蔑的回答说，整个市场都仅仅是在做数据预测，其实就像是天气预报一样。即使神经翻译能够完美演绎，对于语言的本质也并不能产生什么深远的影响。这种预测能够成为我们完成任务的一种很好的工具，但是不能帮助我们理解事情为什么会这样发生。在医学扫描上，机器已经能够比人类放射专家更准确地检测出肿瘤，但是机器不能告诉你是怎么得病的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那么问题是放射专家能够告诉你吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;医学诊断是受到机器学习威胁最直接最不可预测的一个领域。放射科医生一般都经过广泛培训，并且报酬优渥，我们认为他们的技能是一种专业洞察力——最高级的思想领域。在过去的一年里，研究人员不仅发现神经网络可以比医疗图像更早找到肿瘤，而且机器甚至可以根据病理报告的文本做出诊断。放射科医生做的事情其实更像是一种预测模式而不是逻辑分析。他们并没有告诉你是什么导致了癌症，他们只是告诉你它在那里。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你出于某种目的建立了一个模式匹配装置，它可以在为别人服务时进行调整。一个翻译工程师既可以利用一个网络评价艺术品，也可以用它来驱动一个自主无线电控制的汽车。用于识别猫的网络可以用于训练 CT 扫描。一个用于翻译的神经网络可以很快处理数百万页的法律的文件，所需要的时间和收费最昂贵的资格律师相比也仅仅是一小部分。那些机器可以做的工作也不再仅仅是我们之前所做的一些重复性的工作。我们不只是在谈论 350 万名可能很快面临失业的卡车司机。我们谈论的还有库存管理者、经济学家、财务顾问、房地产代理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在硅谷发生的最重要的事情现在不是分裂。相反，它对体制的建设和权力的巩固，在规模和速度上都达到了人类历史上可能是前所未有的程度。谷歌大脑有实习生，有常驻职员，有培训其他部门的「忍者」。每个地方都有免费自行车头盔和免费的雨伞、水果沙拉、午休的地方、共享的跑步机书桌、按摩椅、高级糕点、婴儿衣服捐赠场所、配备教练的两层攀岩墙、阅读小组和政策会谈以及各种支持网络。这些大规模投资的受益者可以控制分布在四大洲 13 个数据中心的复杂协调服务器，所拥有的数据中心吸引的电力足以照亮大城市。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但即使像谷歌这样庞大的机构也将面临自动化的浪潮，一旦机器可以从人类的语音当中进行学习，即使程序员的舒适工作也受到威胁。Hughes 在回忆过去 10 年翻译代码库历史时候曾说，「不要担心，新的代码库将会继续发展，一切都会变得越来越好。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;原文链接：http://www.nytimes.com/2016/12/14/magazine/the-great-ai-awakening.html?_r=0&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 15 Dec 2016 16:14:18 +0800</pubDate>
    </item>
    <item>
      <title>专访 | 云从科技创始人周曦：刷分的人脸识别没有任何意义</title>
      <link>http://www.iwgc.cn/link/3928461</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：虞喵喵&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一家成立不到两年的图像识别公司，如何在短时间内拿下众多银行客户？&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自 2015 年 4 月成立以来，海通证券、西安银行、中国建行等多家金融机构先后应用了云从的人脸识别系统。今年 9 月，中国农业银行更是率先将云从的技术应用到 37 家分行，成为全国第一家应用人脸识别技术的四大行。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;作为云从科技的创始人，周曦博士师从「计算机视觉之父」Thomas Huang（黄煦涛）教授，并在 2007-2011 年期间 6 次获得智能识别类世界大赛冠军。2011 年受邀回国后，周曦博士进入「中国科学院百人计划」，联合 UIUC（伊利诺伊大学厄巴纳-香槟分校）及新加坡国立大学成立中国科学院重庆研究院智能多媒体技术研究中心。期间带领团队研发出智能图像侦查仪、公安千万级人像检索机、人脸识别智能人员管理系统、大规模动态人群特征检测系统等产品，并作为中国科学院人脸识别唯一代表参与战略先导 A 类专项「新疆安防布控」。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;多年的学科钻研和技术、实践经验积累，使得云从自诞生之初就有着不俗的竞争力。可移动式大规模数据采集阵列、双层异构深度神经网络等复杂名词的背后，是云从「希望帮助更多人」的初心。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9DFP58EX6ymYTnLpicibkXOrxh1XKAbE69802iaAH3kGCpibHVsMuESWSsnzDb7N4o3EXr9ehHPfhoibw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;云从科技创始人周曦&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器之心专访周曦博士，从个人经历、云从科技的技术特色、金融业的技术应用特点、图像识别的发展等多个角度，还原这家图像识别公司的不同面貌。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;从语音转行图像，希望技术真正「有用」&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心&lt;/span&gt;&lt;span&gt;：您为什么选择了图像这个方向？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;周曦&lt;/span&gt;&lt;span&gt;：最早我在中科大做语音。后来去北京，在微软亚洲研究院语音识别组也呆了很长时间。但这期间「做了错误的判断，做了正确的决定」——我觉得语音没前途。按照摩尔定理，语音识别每 18 个月错误率能够减半，但我感觉离实用还是很难。而图像识别的视频和图像是个大得多的领域，可以解决的问题要多得多。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从信息分析来看，语音是一维信号，图像是二维信号，视频是三维信号，从信息上看图像比语音丰富。从任务来看，Audio（声音）本身是有很多任务的，但 Speech（语音）和 Audio 是两回事儿。Speech 是人的声音，背景音等很多声音对我们意义不大。我们想要研究的就是 Speech，这造成了所有做语音这一行，能做的任务就是能把说话的内容识别准。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图像和视频是完全不同的，人脸识别大概对应着语音识别。把图像中的人找到，再识别他是谁、他的情绪、年龄、性别。这只是浩瀚的图像识别和视频识别中的一小部分，对于我们来说有用的不止这一点。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;医学上应用图像处理，可以识别早期癌症等疾病。为什么体检后很多疾病没有检查出来？不是没拍到，是需要非常专业、非常资深的医生才能看出来。如果疾病尤其是癌症早期就看出来，基本能够治愈。通过图像识别和大数据，更好的把有嫌疑的部分都找到后再请专业的人确认，这样不就可以挽救很多人的生命吗？&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;再比如做工业视觉，生产线上的东西是不是有瑕疵，有没有裂缝？表面平不平？也可以通过图像视频看出来。又比如现在很「火」的自动驾驶，可以通过图像识别出所有路面的情况，是不是有标志等等。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于图像来说，识别宇宙万物都很有意义，不止是识别人的脸才有意义。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图像做一点点事都可能帮助到别人。当时我看到一条新闻，国外有人在泳池下装了一个摄像头，能自动识别出游泳者是不是溺水。做图像视频可以有很多的方法帮助别人，就觉得这个还蛮有意思的。所以「做了一个错误的判断，一个正确的决定。」来到美国，开始做图像视频。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;span&gt;机器之心&lt;/span&gt;：在美国您跟从 Thomas Huang（黄煦涛）教授学习，他是怎样一位老师？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;周曦&lt;/span&gt;：他是那种给我们营造环境的大师，给我们很大的平台和 high-level 的指导，比较轻松自由的环境，可以去做自己想做的方向。Thomas Huang 给我们很大的视野和平台。他本身是顶级教授，他指大的方向，给我们看大的视野是什么，我们自己三五成群研究自己感兴趣的东西。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9DFP58EX6ymYTnLpicibkXOricIsy0hTia3vZBECaXQ8J7G3h1VmicQuuKKEmxRWFLryroOl0HkSGBXQg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Thomas S. Huang（黄煦涛）教授在图像处理、模式识别、计算机视觉领域有奠基性贡献&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;span&gt;机器之心&lt;/span&gt;：那您后来为什么创业做了云从？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;周曦&lt;/span&gt;：很多时候都是幸运。我本来做语音、后来做图像，都属于人工智能甚至机器学习这一个分支里，有一定的学科交叉，很多东西都是复用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当时的语音识别走在图像识别前面，已经到了系统化的阶段。我到美国时，图像还没到这个阶段。从语音转到图像，让我们在方法论和做系统这件事上远远领先了所有人。当时图像领域都是「单兵作战」，在一个电脑上跑或者在一个服务器上跑任务。语音领域的人都认为必然需要 cluster 服务器阵列，分布式的提交任务。我到 UIUC 时发现还没有，马上就搞了一个。有 cluster 服务器就相当于正规军，别人是散兵游勇。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;语音有很多做得很好的算法和思想，我也在图像上实践。果不其然效果很好，2006-2010 年之间拿了很多世界冠军。拿了这么多冠军我就想，总要做什么有意义的事儿吧。这个东西要「实用」，不管是检查零件还是挽救溺水的生命，在各种场合下要能帮到大家。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这时就发现，虽然能识别宇宙万物，但图像识别一定要具体到一件事上才能帮助到别人。想来想去，人脸是图像中很重要的东西，把人脸做好可以做很多事。于是我们就先选了人脸识别。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;后来发现，如果没有商务推广能力也是不行。2013 年底、2014 年初，我发现芬兰有一家小公司做刷脸支付，觉得很好玩，就率先在国内做了刷脸支付。2014 年是做出来了，在手机上可以使用了，但其实是没有用的，因为没有人真的用。我只是告诉别人，可以这么玩儿，谁会真的去用呢？哪个金融机构会拿这个真的去做事呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果我们永远只在学术里，还是帮助不了人，做不了什么事儿。一定要自己有个公司、自己有能力去做商务推广，把这个东西往前推动，就有了云从。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;短时间搞定多家客户背后，是多年的实践积累&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;span&gt;机器之心&lt;/span&gt;：云从成立一年半时间，为什么能拿到银行、公安这么多客户？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;周曦：技术积累就不说了，很多年我一直在尝试怎么让技术实用。从学术到好用的系统，有很长的距离。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们在美国拿很多世界冠军，回国就是想让技术能实用。从 2011 年回国做了好多年，我们在中科院做的很多系统已经在新疆等地使用了。产品是成熟的，只是还没在商业推广起来。虽然公司去年成立，但准备工作特别完善。如果不全力以赴、以公司这样严肃的方式运作，是没有办法得到大家的认可的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9DFP58EX6ymYTnLpicibkXOrklJB4tTHiaiaF3g9ibkOVOHXnCJeJv7g5nLdhiagrGiaDjoPBRx8WLl2jicg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;云从科技部分应用案例，可于其官网查看具体内容&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;还有一点是我们做东西很集中，&lt;span&gt;我觉得专注是很重要的。一个是研究的东西很集中，虽然什么都能做，但现在还是做好人脸；第二是行业上要集中，各行各业都能做，我们只做金融和安防。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;span&gt;机器之心&lt;/span&gt;：银行这个行业应用分支有什么具体特点？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;周曦&lt;/span&gt;：银行的要求是，一定是一个严肃、认真的公司。不仅要求稳定，同时希望有非常快的响应速度。银行有严格的「2 小时、4 小时、8 小时原则」，系统宕机 2 小时，行长就要去当地人民银行喝茶；4 小时没解决，就要写报告；8 小时没解决，这就是严重事故，银行的评级一定会下降、甚至是关门，就是这么严重。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对我们这种 IT 供应商来说，能保证程序出现问题两小时之内修复吗？这是非常难的。如果人脸是其中的标准环节，恰好人脸识别的服务器宕机，银行只能关门，民众会怎么想？大家可能觉得银行是要垮了，会出现很大的金融事件，然后出现挤兑。这个就是银行的特点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们的系统还必须从总行部署，压力很大，需要我们非常专业。云从虽然成立时间不长，但很认真，在全国十个城市有销售服务中心，全国每一个省有自己的销售服务人员，要保证各个地方一线有云从的人。真的出现问题，我们要第一时间过得去。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;银行是很看重销售服务体系的，大部分互联网模式的公司可能不太重视这个事情。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;&lt;span&gt;机器之心&lt;/span&gt;：云从的「超大规模移动式数据采集阵列」是怎样的装置？作用是什么？&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;周曦&lt;/span&gt;：这实际上是受我在了解医学过程中的影响。我们这一行，其实没有做医学那么认真。医学上做 CT 切片时，因为光线是流明，从正极白到负极白每一度都要拍摄下来。这些图片形成一个严格的表格，可以反向查表解决问题。不能做错手术、不能误判、医学是很严格的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但我们这行经常说「情况很复杂，只能搞个大概」，光线、角度、遮挡、表情，影响因素很多。医学是值得学习的，所以当时从美国回来就做了结构化数据。采数据容易，结构化数据不容易。就算从互联网上下载 1000 万张人脸，或者在大街上安装摄像头收集行行色色的人脸，这些数据都是非结构化的。一张人脸的照片拿出来，它是什么角度？是什么光线？光源从哪儿来？有没有遮盖？是什么表情？有没有模糊？很难一张一张标回来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以我们花了很大力气，做了这个移动式采集阵列。&lt;span&gt;横向上从负 30 度到正 30 度，纵向上从 0 度到 30 度，每隔 5 度安装一个摄像头。7 层 13 列，一共 91 个摄像头形成了一个阵列，使用的摄像头是当时我们从加拿大进口的高速摄像机元件。&lt;/span&gt;这个阵列结构是可拆卸的。我们自己做了同步单元，保证毫秒级触发同步采集。因为视频量非常大，我们还要保证存储跟得上，整套东西做好是个宏大的工程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9DFP58EX6ymYTnLpicibkXOrmWjbFC6W8psibAsic54Bp0o0U7DhdStrxl6Lib7JWvln3qpvgQXDzXNjw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;采集的空间是有标尺的，人的脸部都是固定的，加上我们自己做了光源阵列，可以获得光线和角度属性。我们还自己设计了剧本规定了表情，遮挡方面有假发、帽子、眼睛等等。获得的每一张照片，属性都是自动获得的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但只是这样，就不需要「移动」了。实验室环境是不够的，从实验室到实用都要去做，所以这个阵列要可拆卸、可移动。银行业务很多在大堂办理，所以我们还要采集大堂情况下的数据；公安有时监控的是通道，我们就在通道采集数据看具体是什么情况。依靠这个结构化数据采集阵列，我们得到了广泛的数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为什么在大数据背景下，我们还要费力气做结构化数据？就像我们常说社会是最好的学校，为什么还要设立小学、中学、大学？在学校学习的是结构化知识体系，让小孩有三观和基础知识，再去接受广泛的数据洗礼，进行大量的学习。如果从最开始就随便学，最后学习的结果就不可控了。所以&lt;span&gt;需要先有结构化数据，再有海量的非结构化数据，才能做出最好的模型&lt;/span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;span&gt;机器之心&lt;/span&gt;：那么云从的另一项技术「双层异构深度神经网络」，是如何做到将看起来不相似、但实际是同一个人的人脸对应起来的？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;周曦&lt;/span&gt;：双层异构是双层、异构两件事。很多时候注册的照片是证件照，比较端正；现场照往往过了好几年，现场的光线、表情、角度等等各种因素都比不过证件照，需要用复杂的网络解开。描述每个东西都是一个分布，同一个人要满足同一个分布，但因为种种因素同一个人的照片之间已经隔得很远。我们不用强行把两张照片圈在一起，而是让他们在两个层上组成分布，用线将它们连接起来。接受注册和测试时的不同，将中间的原因找出来，这个就是双层。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;异构和双层是相辅相成的。大数据有一个特点，只要数据足够多就可以让它自己学习，但实际上影响因素是什么，人是知道的。人们知道原因是光线、遮挡、表情造成了差异，可以完全让它自己去学习，也可以提前告诉它可以省很多力。异构就是结构化不一样，数据是一种结构，知识是另外一种结构。要把知识簇给出，映射到一个一个簇中，让它用更少的代价解决这件事。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;用「三个苹果」举例。教一个孩子认识苹果，大概三个就够了。告诉他「圆圆的」、「上面有果蒂」、摸起来是什么感觉，这就是苹果。下一次再看见苹果，问他「这是什么」，他可能知道也可能不知道。如果不知道，可以告诉他「这就是上次说的苹果」。他会问「颜色为什么不一样」，可以回答「上次是青苹果，这次是红苹果」，孩子就会知道「苹果有不同颜色」。几次之后，他就认识苹果了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深度学习要想「搞定苹果」，需要多少个苹果？通常要 1000 或者 10000 个苹果的训练数据，训练结果达到识别率 90%。也就是说假如有 10000 个苹果，有 1000 个会识别错。我们问电脑，「这 1000 个为什么识别错了？」它不会回答「颜色不一样」，而是说「求了偏导、积分等，结果是 0.4，预置值 0.5 以上才是苹果，所以它不是苹果」。如何纠正电脑？没有办法，只能说是训练数据不够多，再找 10 万张苹果的照片训练。终于，识别率到达了 98%，效果还不错。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在我看来这并不是人工智能，&lt;span&gt;和小孩子沟通的过程才叫人工智能，因为他理解我抽象出来的概念。通过颜色、形状、材质等几个抽象出来的概念，定义了一个新的事物，当他有不同的理解时，也会用同样的概念提出问题，再来纠正他的认知。我们在一个很高的层次做交互，能够举一反三。&lt;/span&gt;一个点一个点的求偏导、求积分，是没办法交流的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除了基本的、初级的像素信息外，要加入上层的 concept（概念信息）和 attribute（属性信息），才能做到在更高的层面交互，快速的举一反三，迭代出问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;&lt;span&gt;机器之心&lt;/span&gt;：图像识别会涉及到大量运算，我们如何提升反应速度？&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;周曦&lt;/span&gt;：这又涉及到工程上的问题。为什么（图像识别）门槛很高？因为它不是搞一个模型就行的问题。人脸识别本身就有几十个模块，从检测、跟踪、分割、关键点、旋正，到质量分析、光线补偿、角度补偿、遮挡补全等等等等，对于任何一个模块又要针对每种场景做不同的适配。比如关键点提取如果应用在手机前端，供应商会要求模型大小在 1M 以下，而整个人脸识别模型在服务器端是有超过 1 亿个参数的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;同时，我们还要求很快，比如视频中有很多人，要求在 1ms 之内识别出多有的关键点。为什么是 1ms？因为还有很多的模块要运行，要满足所有的运行时间加在一起达到「实时」（30ms 之内）。有时候又要求很准，比如美妆应用对关键点的识别偏一个像素，就会让人感到不适。又要小、又要快、又要准，就要有不同的算法和模型应对不同的场景。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;几十个模块、每个模块要有不同的场景、还要应对所有的硬件（不同的手机型号、服务器、嵌入式设备），这就是我们常常说的「无数的精力都放到适配上了」。研究出一种新算法，Android、iOS、Linux 等等所有的模型都要重新更新一遍，这是很累的。所以为什么像我们这样的公司都要有庞大的研发队伍，很多人不理解为什么做一个人脸识别研发团队要超过 200 人，原因就在这里。这还只是核心技术的一小块，还不算在不同的行业做闸机、迎宾等等不同的设备。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;&lt;span&gt;机器之心&lt;/span&gt;：您曾在一次演讲中提到云从能够解决「人从哪里来」的问题，现在我们已经能做到对单人实现历史轨迹提取了吗？&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;周曦&lt;/span&gt;：这个不能光靠我们，首先要将所有的监控视频结构化，先将其中的人脸数据提取保存起来。将来如果想快速得到某一个人的信息，可以从系统快速的发布请求到所有的服务器端，将得到的信息组合起来。轨迹图、甚至这个人做过什么事、和谁说过话，信息链就会整合出来。现在在技术上是可行的，但数据联动等还不能保证。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;刷分的人脸识别，没有任何意义&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：图像识别发展到现在，您认为有哪些标志性事件？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;周曦&lt;/span&gt;：图像识别曾经很火过。到了 20 世纪末、本世纪初，这行变得很惨淡，大家都觉得未来遥遥无期、没有希望。直到 2001 年的 ICCV，Paul Viola 和 Michael Jones 发表了《Robust Real-Time face detection》，在现场引起了轰动。他们用摄像头对准大家，现场所有人的脸都被圈出来了。图像识别第一次有实用的东西出现，这是图像识别命运的扭转。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一件挽救了图像识别命运的事件，是 911。911 后美国政府率先要求全部应用摄像头，海量视频出现后需要加强智能监控，客观上也让经费大幅提升。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深度学习也是一个巨大的标志性事件，深度学习在 2006 年提出，2009 年左右开始在图像中应用。一直到现在，仍是大爆发的阶段。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;硬件先行、大数据也有了，云计算云存储又得到了非常好的发展，需要有算法将他们的能力表达出来。深度学习，就是炊米的「巧妇」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：中国在图像识别研究上，大概是什么样的位置？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;周曦&lt;/span&gt;：就图像识别而言，我们在国际上是领先的，至少没有落后美国。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在中国，尤其是人脸识别，需求是比美国旺盛的。需求推动造成企业敢于投入资金，大家的投入也很大，再加上算法基础相当，中国的数据更多，所以中国是不会落后于美国的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;span&gt;机器之心&lt;/span&gt;：有一种声音认为，现在的图像识别每天都在参赛刷分，离解决人类视觉认知等初衷太远，您怎么看这种观点？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;周曦&lt;/span&gt;：刷分是没意义的。我们的初心是让图像识别真的有帮助，真的能用起来。一定要有人沉得下来做基础研究，也要有人做实用的东西。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们是偏向做有用的东西，把好的技术在银行、公安、机场等各个地方用起来，让民众觉得很好用、很舒服。为了解决这件事就会面临很多科研问题，比如晚上光线不好，就无法进自己的家门了吗？应该 24 小时每天稳定的让每个人使用，这就是实用中出现的科研问题，同样要去解决。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;做原创性研究比如怎样从理论上解决大数据的问题，也很了不起。但刷分是没有意义的，因为解决的是制造出来的、不存在的问题，只是炫技。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心原创文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 15 Dec 2016 16:14:18 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 用游戏测试人工智能，Nature盘点三大开源3D测试环境</title>
      <link>http://www.iwgc.cn/link/3928462</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自 Nature&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;参与：李泽南&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;《我的世界》对于 José Hernández-Orallo 而言并不陌生，他是一名计算机科学家，正在使用这款游戏进行自己的研究。他在瓦伦西亚理工大学的研究团队设计了一种测试机器智能性能的基准，这种方法的设计灵感来源于他看到自己的孩子在 3D 虚拟世界中游戏的情形。在《我的世界》中，玩家通常需要通过互动解决问题，而不是射杀怪物。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicr33MwRF3MYPqDITzNX5zhuJatPeEWJ2E0454NCxChZicrbgjejlKIGMqpia41amCsfdiaDH21RUyVA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;《我的世界》是一款风靡全球的游戏，现在科研人员们正在使用它来测试人工智能&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2014 年，微软购买了《我的世界》的所有权，这家科技巨头的研究机构——微软研究院随后在此之上设计了一个用于科研的新版本，让计算机程序和科学家们可以探索和自定义游戏中的 3D 环境。随后，微软邀请了包括 Hernández-Orallo 在内的一些外部研究人员下载了这个机器友好版本的《我的世界》。从 2015 年 7 月起，微软将其完全开放，现在任何人都可以免费使用它，微软希望以此加快人工智能领域的研究速度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能在各种游戏中的研究最近变得非常火爆，很多公司正像微软一样在游戏中投入研究力量。12 月 3 日，DeepMind 开放了自己的 3D 虚拟世界程序 DeepMind Lab，供所有开发人员下载和自定义使用。这家谷歌下属公司设计的虚拟环境一开始被用于训练自己的人工智能程序。仅仅两天以后，OpenAI 发布了一个「元平台」允许人工智能程序在其中与最初为人类玩家设计的十几款 3D 游戏互动，另外，这个环境还包含了一些网络浏览器与手机 app。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这三个工具让研究人员与软件开发者们可以轻松地开展自己的实验，测试程序在遇到前所未见的问题时如何进行解决，同时可以帮助程序在类似真实场景的环境中进行自我训练。「这样的虚拟环境将会为人工智能的发展奠定基础，」西雅图华盛顿大学的机器学习研究者 Pedro Domingos 说道。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;iframe class="video_iframe" data-vidtype="1" style="   z-index:1; " height="375" width="500" frameborder="0" data-src="https://v.qq.com/iframe/preview.html?width=500&amp;amp;height=375&amp;amp;auto=0&amp;amp;vid=i0355gr1txb" allowfullscreen=""&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;DeepMind Lab，一开始被用于训练谷歌自己的人工智能程序，现在已经向所有开发者开放&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Atari 算法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能是各种视频游戏的老玩家，但在早期，每个用于通关的算法都是特殊定制的。近年来，人们的研究重点开始转向于使用机器学习让程序自我积累经验。在 2015 年上半年，DeepMind 推出的算法在 Atari 游戏中拥有了超越人类玩家的水平，算法通过不断试错来获得游戏高分，设计者并没有告诉程序每个游戏的目标是什么。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Atari 游戏仅仅是 2D 世界而已。像《我的世界》这样的「第一人称」3D 视频游戏可以让玩家置身于一个充满立体感的环境中，相比前者更接近于真实世界，因此吸引了更多研究者的目光。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在《我的世界》中，玩家可以和虚拟世界中的砖块互动，使用它们盖房子，同时也可以探索路线，和游戏世界中的其他内容展开交互。面向开发者的版本被称为 Malmo，允许机器算法像人类玩家一样在游戏中进行探索。Hernández-Orallo 正在使用 Malmo 来探究虚拟环境是否可用于创建机器智能的基准。不同算法可以相互竞争，看看哪一个可以将砖块搭建成某个物体的形状，或者比较它们在同一个迷宫中寻路所需的时间，这种测试的涵盖面相比图灵测试——机器智能最有名的测试方式——要广泛的多。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;让《我的世界》吸引人工智能学者们的另一个原因是，在游戏中玩家们可以打字互相交流。「这可以帮助专家们研究人工智能在现实世界中与人类互动的情况，」微软研究院的科学家 Katja Hofmann 说道，她在英国剑桥领导着开发 Malmo 的团队。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;iframe class="video_iframe" data-vidtype="1" style="   z-index:1; " height="375" width="500" frameborder="0" data-src="https://v.qq.com/iframe/preview.html?width=500&amp;amp;height=375&amp;amp;auto=0&amp;amp;vid=r03550afrzg" allowfullscreen=""&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;目前约有 100 个研究机构正在使用 Malmo 3D 世界，它由微软研究院开发，用于人工智能研究&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;训练机器人&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「虚拟世界的人工智能训练对于机器人的发展大有益处，」Hofmann 说道。「因为虚拟环境的定制成本很低，定制速度和安全性也有保障。虚拟环境也可以让机器人研究者们专注于解决机器人的智能问题——机械的问题有时的确令人分心。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除了 Hernández-Orallo 以外，微软研究院还与不少其他研究机构合作开展了一系列 Malmo 项目。Hofmann 认为真实的用户数量不止于此，也许有 100 家。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Malmo 平台包括 Java 版本的模块，以及帮助智能体在 Minecraft 环境中感知和操作的代码。这两个组件可以在 Windows，Linux 或 Mac OS 上运行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;DeepMind Lab 和 Malmo 类似，也允许研究者创建迷宫，让不同算法学习如何寻路，获得奖励。DeepMind 正在尝试将「更自然的元素」（如起伏的地形和植物）整加入到这个虚拟世界中。目前这个 3D 环境已经开源，DeepMind 希望在其他研究者的帮助下，这个平台能够更加复杂，从而训练更聪明的训练算法。「通过开源，我们可以让所有人参与进来，不断改进这个项目，」DeepMind 的一位发言人说道。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;OpenAI 的元平台，Universe，相比前两个 3D 世界则更进一步。通过为同一个人工智能程序提供多种不同类型的环境，这一平台或许可以解决领域内最棘手的问题：如何创建一个可以解决任何新问题的算法。目前的深度神经网络——通过模仿脑细胞和视觉皮质层的结构创建的计算机系统——可以快速学会在 3D 迷宫中寻路，但同样一个系统却无法将自己学会的方法用于在其他迷宫中导航。「你仅仅改变一下迷宫的颜色，系统就会迷失其中了，」Hernández-Orallo 说道。「这就是目前最先进的技术，令人哭笑不得。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;看来，人工智能的发展还有很长的路要走。目前微软现在正努力让 Malmo 可以在 Universe 中使用。「拥有一个社区平台将使所有人从中受益，」OpenAI 的共同创始人，首席技术官 Greg Brockman 说道。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相关链接：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Microsoft Project Malmo：&lt;span&gt;https://www.microsoft.com/en-us/research/project/project-malmo/&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;DeepMind Lab：&lt;span&gt;https://deepmind.com/blog/open-sourcing-deepmind-lab/&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;OpenAI Universe：&lt;span&gt;https://universe.openai.com/&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文链接：http://www.nature.com/news/tech-giants-open-virtual-worlds-to-bevy-of-ai-programs-1.21151&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 15 Dec 2016 16:14:18 +0800</pubDate>
    </item>
    <item>
      <title>前沿 | 机器学习新进展，从脑波中探知你的兴趣爱好</title>
      <link>http://www.iwgc.cn/link/3928463</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自TechCrunch&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：杜夏德、蒋思源&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;芬兰的研究人员利用机器学习开发出一种技术，可以在你阅读时读取你的脑信号来捕捉你的兴趣点。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;未来涌现的数据越来越多，人们又将如何智能地筛分导航信息呢？所以面对堆积如山的 MBs（数据流量），我们需要更好的方式去过滤分流数字内容。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;芬兰的研究人员一直关注这个问题，并且已经使用脑电图（electroencephalogram，EGG）感知器监控人们阅读 Wiki 文章时的脑信号，并将它与经过训练的机器学习模型结合起来去解析 EEG 数据，同时识别出阅读者感兴趣的概念。这个研究团队使用该技术生成了一列关键词，这些关键词是阅读者读到包含信息的地方时心理上标记下来（mentally flag）的。这些关键词之后可用于预测与这个阅读者相关的其他 Wiki 文章。或者线下帮助过滤一条社交媒体回复，或者为增强现实用户实时标记出一条符合其兴趣的内容。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们已经探索了搜索过程中人类大脑中产生的信号，」研究者 Tuukka Ruotsalo 说。「现在我们想要采集极端（extreme）的信号，我们能尝试直接读取使用者大脑中的兴趣和注意吗？」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该团队来自赫尔辛基信息技术研究所（HIIT），认为这是研究人员首次展示了基于直接从脑信号中提取关联推荐新信息。「现在有很多脑机接口研究，但通常... 主要研究的都是向计算机作出明确的命令，」Ruotsalo 说。「所以那就意味着，你想控制房间里的光线和你在做一个明确的模式时，你正在尝试明确地做一些事情，然后计算机就要试着从大脑中读取这些你要做的事情。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「在我们的研究中，这些是自然进行的。你只要阅读就好，我们不会让你在读到一个兴奋的单词时去拉左右胳膊。你就是在阅读，同时因为文本中有些地方与你相关，我们能让机器学习与文本唤起的事件匹配的大脑信号，并使用这些信号，」他补充道。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你只需要读你的书就好，计算机会挑出你阅读中的兴趣点或者有关联的地方。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「所以在某种意义上，它是纯粹的被动互动。你只要阅读，计算机会挑出你阅读中的兴趣点或者有关联的地方。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然这是一个研究，只有 15 名测试者和一个脑电帽（EEG cap），没人愿意在实验室之外的地方戴上那个帽子，但是它可以让我们窥探到未来的可能性。一旦有了高质量的 EGG 感知器（人人都能戴的可穿戴智能帽子？），让整个过程不再那么麻烦，并且可切实结合机器学习软件，经过训练后能掌握一点读心术时，它就能走出实验室了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「如果你只研究纯粹的信号无视其他事情，那就难了，」Ruotsalo 解释道，他指出该团队没有通过跟踪任何物理上的身体移动比如眼球运动来解释兴趣。他们对关联的理解仅仅是基于他们的机器学习模型解析 EEG 脑波。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「这是一个真正具有挑战性的机器学习任务。你需要训练这个系统来探测它。有很多像移动或眼球运动这样更加容易的东西... 能在信号中真实地看到。这次你真正要做的是把它从噪音中找出来。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Ruotsalo 说他们在数据量适度的数据集上训练模型，只使用了平均 120 词的 6 个文件，每个文件都用来为其对应的测试对象建立模型。实验还包括使用少量的初始化监督学习，使用的是每个维基百科文章的前六个句子。据 Ruotsalo 表明，在未来的研究中他们想看看是否可以在没有任何监督学习下达到同等实验结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然「兴趣」的概念是相当广泛的，它可能是由读者因各种不同原因在心理上标记的一个关键词，他强调人们已经经过有效地训练来以这种方式导航信息，因为他们已经习惯使用通过这种兴趣信号的语言来实现的数字服务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Ruotsalo 接着说：「这就是现在我们在数字世界中所做的。我们点赞或者点击链接和搜索引擎，只要我们点击了，它们就认为这是里面一定有什么。这就使得在没有任何明确的行动下也能获取我们的兴趣，所以你其实是从大脑中读取维基百科的。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;iframe class="video_iframe" data-vidtype="1" style="   z-index:1; " height="375" width="500" frameborder="0" data-src="https://v.qq.com/iframe/preview.html?width=500&amp;amp;height=375&amp;amp;auto=0&amp;amp;vid=j0355z42tsd" allowfullscreen=""&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那么这就意味着当人们在阅读相当大小的文本时从他们的思维中提取出兴趣信号是可能的。如果你考虑如何在一个人沉浸于某个内容时使用定制营销信息来抓取他的兴趣，那么这就有点恐怖了（dystopic）。所以换句话来说，将目标广告真正读取的是你的意图，而不只是你的点击。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Ruotsalo 希望未来将技术应用于其他更好的商业用途。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「例如在有大量的信息需要处理，很多事情需要控制、记忆的工作任务中，这可以作为一种支持 agent 类型的软件，并且标记上『这对用户很重要』，然后能以后提醒用户：『记得查阅这些你发现有趣的事情』，」他建议道。「这样的用户建模能在一个真正的信息密集型任务中自动提取特征是很重要的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「即使是搜索类型的场景，你正在与你的环境进行交互，在投影机上查看数字内容，我们同样可以看到你对它的兴趣，然后它可以自动检测并为你注释或推送个性化内容」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们已经在数字世界中留下了各种痕迹。我们正在研究过去看过的文档，并可能会粘贴一些我们以后想要再查看的数字内容，但是所有这些都可以自动记录。然后，我们表达的各种偏好，不论是评级还是其他什么，都能用于不同的服务建模。他补充说：「看来，现在所有这一切都可以通过从大脑中读取」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这并不是他们团队第一次参与解决搜索和信息超载问题。Ruotsalo 也是构建 SciNet 视觉检测搜索接口的研究人员，后来由这项技术成立了一家商业公司 Etsimo。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「信息检索或推荐是一种过滤问题，所以我们试图过滤信息，来找到到底什么是有趣的或相关的。他补充说：「我认为这是现在最大的问题之一，所有这些新的系统只是推送我们不一定想要的事情。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文链接：https://techcrunch.com/2016/12/14/researchers-use-machine-learning-to-pull-interest-signals-from-readers-brain-waves/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 15 Dec 2016 16:14:18 +0800</pubDate>
    </item>
    <item>
      <title>盘点 | 2016年不可错过的21个深度学习视频、教程和课程</title>
      <link>http://www.iwgc.cn/link/3911931</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自 Analyticsvidhya&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;几年之前，深度学习还是机器学习里面一个不太受人关注的领域。随着神经网络和大数据的出现，很多复杂任务的实现已经成为可能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2009 年时，深度学习还是一个新兴领域，只有少数人认为这是一个值得研究的领域。但很快，这个领域就得到了很大的发展，目前已经被应用到很多的领域当中，例如：语音识别、图像识别、在一个数据集当中寻找模式、照片中的事物分类、字符文本生成、自动驾驶汽车等等。因此，了解深度学习及其概念是非常重要的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了能够让你用一种更简单的方式学习深度学习，Analytics Vidhya 网站发表了一篇文章梳理了一些 2016 年关于深度学习的视频、教材和课程。其中包括深度学习暑期班、峰会和会议等的一些讲座和教材。希望你能够从中受益。（注：这篇文章中的视频都在 YouTube 上，你也许需要专门的工具才能查看。）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;目标读者&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不管是深度学些方面初学者、中等水平的学者还是专家，你都可以找到适合您观看的视频。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这篇文章也会根据读者的学习程度对学习材料进行分别罗列。如果你是一名初学者或者是中等水平的学者，建议你可以从第一部分开始。如果你想掌握完全掌握深度学习，那这篇文章就是你首先要阅读的不二之选。在开始对深度学习的探索之前，你首先要制作一个日程表。我相信在几周后，至少你可以建立你在深度学习中的第一个模型。对于深度学习方面的专家来说，深度学习的高级教程部分有很多精彩的视频可以帮助你加强现有的知识。你也可以看看 5 分钟的初学者视频来巩固基础知识。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于所有深度学习/数据科学方面的爱好者，你们一定会喜欢深度学习的应用和其他部分对例子的介绍。其中包括谷歌 DeepMind 的一些视频，你可以从中学习如何使用深度学习绘画，并且深度学习是如何让自动驾驶汽车成为现实的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外还有一小部分是关于强化学习的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1.深度学习初学者教程&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;深度学习简化版&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;2016 斯坦福湾区深度学习学校 Day 1&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;2016 斯坦福湾区深度学习学校 Day 2&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;深度学习教程&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;使用神经网络的深度学习及 TensorFlow 介绍&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;机器学习神经网络&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;TensorFlow 入门&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;神经网络&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;改变所有事物的神经网络&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;TensorFlow 广度&amp;amp;深度学习——机器学习&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;深度学习简介&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;深度学习揭秘&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2.深度学习高级&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;2016 年蒙特利尔深度学习暑期班&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;深度学习教程——高级&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;深度学习实践-语音识别与其他&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3.深度学习的应用&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;详解谷歌 DeepMind&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;自动驾驶汽车和深度学习 GPU-英伟达&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;九个有趣的深度学习应用&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;深度学习程序绘画&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4.强化学习&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;简介强化学习函数逼近-教程&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;深度强化地形学习&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;深度学习初学者教程&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1.深度学习简化版&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;时长：系列包含27个视频&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;链接：https://www.youtube.com/watch?list=PLjJh1vlSEYgvGod9wWiydumYl8hOXixNu&amp;amp;v=b99UVkWzYTQ&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果复杂的专业术语让你在学习深度学习时感到困难重重，那么这个教程就是给你的福利。这是深度学习及其基本概念的一个简化版教程。在这个教程里你将会了解到神经网络、深度网络、深度信念网络（DBN）和卷积神经网络。H2O.ai 和这个教程将会让你对深度学习有基本的理解。同时你也会了解到不同的模型，以及在不同情况下该选择何种模型和选择这种模型的理由。之后你将会学到深度学习在不同使用情形下的实际操作经验，包括支持构建你自己深度网络的平台、深度学习可以调用的库。这个简化教程里没有任何数学计算或者编程相关的内容，是为初学者了解深度学习基本思想而制作的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2.2016 斯坦福湾区深度学习学校 Day 1&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;时长：10 小时 33 分&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;链接：https://www.youtube.com/watch?v=eyovmAtoUx0&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;正如吴恩达（Andrew Ng）无比精确的描述，深度学习正在改变业界的发展布局，同时大量有意思的深度学习应用正涌现出来。这个视频是 2016 湾区深度学习学校第一天的内容展示。视频覆盖到的内容有： 1）Hugo Larochelle 讲授前馈神经网络介绍（Introduction on Feedforward Neural Network）；2）Andrej Karpathy 讲授用于计算机视觉的深度学习（Deep Learning for Computer Vision）；3）Richard Socher 讲授用于自然语言处理（NLP）的深度学习（Deep Learning for NLP）；4）Sherry Moore 讲授 TensorFlow 教程（TensorFlow Tutorial）；5）Ruslan Salakhutdinov 讲授深度无监督学习基础（Foundations of Deep Unsupervised Learning）；6）吴恩达讲授深度学习应用基本要点（Nuts and Bolts of Applying Deep Learning）。这些深度学习方面的专家都会以一个易于理解的方式讲解深度学习潜在的概念原理，让你对深度学习有基础理解。同时他们也会分享各自讲授主题相关的应用实例。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3.2016 斯坦福湾区深度学习学校 Day 2&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;时长：10 小时 33 分&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;链接：https://www.youtube.com/watch?v=9dXiAecyJrY&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是湾区深度学习学校的第二天讲授内容视频。视频覆盖到的内容有：1）John Schulman 讲授深度强化学习基础（Foundation of Deep Reinforcement Learning）；2）Pascal Lamblin 讲授 Theano 介绍：一个供模型构建和训练使用的极速 Python 库（Introduction to Theano: A Fast Python library for Modelling &amp;amp; Training）；3）Adam Coates 和 Vinay Rao 讲授语音识别和深度学习（Speech Recognition and Deep Learning）；4）Alex Wiltschko 讲授 Torch 和 Autograd 下的机器学习（Machine Learning with Torch &amp;amp; Autograd）；5）Quoc Le 讲授深度学习实现 Seq2Seq（Sequence to Sequence by Deep Learning）；5）Yoshua Bengio 讲授深度学习的基础和挑战（Foundation and Challenges of Deep Learning）。这些深度学习的应用者都是经常被检索到的深度学习应用专家，他们同时也为大型公司服务，如：谷歌大脑、Twitter 等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4. 教程：深度学习&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;时长：2 小时 29 分&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;链接：https://www.youtube.com/watch?v=CLSy5WlaWKc&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这个深度学习的视频教程里，Yoshua Bengio 和 Yann LeCun 讲解了近年来深度学习所取得的重大突破。在这个领域深耕 30 年之后，Yoshua 和 Yann 带来深度学习如何掀起机器学习和人工智能领域变革浪潮的深度解读。在本视频教程里，你将会学到深度学习是如何实现多层计算模型对数据表征的学习。这些方法大幅提升了语音识别、视觉对象识别、目标检测以及基因学等领域的相关研究。这个教程将会覆盖到深度学习基础，并讨论深度学习的不同应用和目前遇到的挑战。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;5. 使用神经网络的深度学习及 TensorFlow 介绍&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;时长：无&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;链接：https://www.youtube.com/watch?v=oYbVFhK_olY&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你一直在想知道神经网络是如何工作的，为什么最近它有这么多的关注。本教程将介绍神经网络，你将了解神经网络如何能够创建具有巨大数据集的强大模型。并理解神经网络的结构以及每个输入层如何组合在一起以生成输出。这只是完整教程中的第一个视频，第二部分是 TensorFlow 基础。如果需要了解怎样建立神经网络模型，请继续学习第三部分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;6. 机器学习神经网络&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;时长：无&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;链接：https://www.youtube.com/watch?v=cbeTc-Urqak&amp;amp;list=PLoRl3Ht4JOcdU872GhiYWf6jwrk_SNhz9&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;研究人工神经网络的主要思想是理解神经元的并行计算方式及其自适应连接。本课程将由多伦多大学教授 Geoffrey Hinton 讲授，你将学习到神经网络和机器学习将如何带来技术革命。本课程包括感知器、反向传播、卷积神经网络、循环神经网络、梯度下降和超参数贝叶斯优化等主题。这是深度学习最好的课程之一，如果你是深度学习爱好者，那就一定不能错过它。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;7.TensorFlow 入门&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;时长：系列，共 7 个视频&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;链接：https://www.youtube.com/watch?v=QfNvhPx5Px8&amp;amp;index=5&amp;amp;list=PL2-dafEMk2A7EEME489DsI468AB0wQsMV&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现如今最流行的机器学习框架之一就是 TensorFlow，虽然它主要用于进行机器学习和深度神经网络研究，但由于其多功能性，TensorFlow 也可用于各种应用。在这个有趣的 TensorFlow 教程中，您将学习在 Python 中用不到 40 行代码进行构建手写数字图像的分类器。您还将学习如何在 TensorFlow 中生成音乐，什么是 Tensorboard，怎样构建一个神经网络还有使用 TensorFlow 相比其他深度学习库的利弊。这个关于 TensorFlow 的简短教程是深度学习新手必须要了解的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;8. 神经网络&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;时长：系列，共 6 个视频&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;链接 https://www.youtube.com/watch?list=PL2-dafEMk2A5BoX3KyKu6ti5_Pytp91sk&amp;amp;v=h3l4qz76JhQ&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工神经网络能够学习，而且它们需要训练。基本上需要 3 步来构建机器学习模型，即构建、训练、测试。一旦模型构建起来，它就可以在模式识别上训练得越来越好。在这些短短 5 分钟视频里，你将学习建立神经网络、自动编码器和循环神经网络，每段视频的代码也可在 YouTube 上的描述中找到。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;9. 改变所有事物的神经网络&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;时长：14 分 16 秒&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;链接：https://www.youtube.com/watch?v=py5byOOHZM8&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;卷积神经网络是深度神经网络和核卷积（kernel convolution）的结合。这个视频解释了卷积神经网络是如何为精确图像分类带来巨大改变的。如果你是深度学习爱好者，但对神经网络了解甚少，不妨看看这个视频。它向你展示了深度学习是如何用来估计房价的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;10.TensorFlow 广度&amp;amp;深度学习——机器学习&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;时长：3 分 24 秒&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;链接：https://www.youtube.com/watch?v=Xmw9SWJ0L50&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;广度和深度学习（wide and deep learning）结合了用于训练广度线性模型和深度神经网络的记忆（memorization）和归纳（generalization）。在这个视频中，你可以了解到在 TensorFlow 当中对这种简单易用的 API 的应用。它们在大规模的回归分析和分类中所涉及到的稀疏输入问题当中非常实用，例如推荐系统、搜索和排名问题。通过这个 视频来探索广度和深度学习的可能性吧。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;11. 深度学习简介&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;时长：11 分钟&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;链接：https://www.youtube.com/watch?v=l42lr8AlrHk&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个视频对深度学习进行了数学解释。它将带你了解机器是如何找到不同变量的分组并做出具体决策的。如果你是一个数学爱好者，你将会学到如何调整模型参数。视频简单地解释了神经网络对不同输入内容的反应。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;12. 深度学习揭秘&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;时长：22 分钟&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;链接：https://www.youtube.com/watch?v=Q9Z20HCPnww&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是一个深度学习的初级教程。其中，你将了解深度学习是如何帮助机器识别特征的。同时，视频用简单的语言解释了神经网络。首先，视频介绍了神经元的工作方式，随后进一步解释神经元之间的交流方式。随后是深度学习在现实世界中的应用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;深度学习-高级&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1.2016 年蒙特利尔深度学习暑期班&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;时长：无&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;链接：https://www.youtube.com/watch?list=PL5bqIc6XopCbb-FvnHmD1neVlQKwGzQyR&amp;amp;v=xK-bzjIQkmM&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;蒙特利尔深度学习暑期班出现了很多来自不同年龄段的专家与从业人员。该教程是要教人们对深度学习与神经网络有基础的理解。里面有 Yoshua Bengio 教授循环神经网络，Surya Ganguli 教授理论神经科学与深度学习理论，Sumit Chopra 教授 reasoning summit 和 attention，Jeff Dean 讲解 TensorFlow 大规模机器学习，Ruslan Salakhutdinov 讲解学习深度生成式模型，Ryan Olson 讲解深度学习的 GPU 编程，还有其他很多的讲演。想要了解更多内容可参考机器之心之前发表的文章：&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718578&amp;amp;idx=1&amp;amp;sn=ff7d748b149e7952c9fa3b53cefd5afc&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718578&amp;amp;idx=1&amp;amp;sn=ff7d748b149e7952c9fa3b53cefd5afc&amp;amp;scene=21#wechat_redirect"&gt;重磅 | Yoshua Bengio 深度学习暑期班学习总结，35 个授课视频全部开放（附观看地址）&lt;/a&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2. 深度学习教程——高级&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;时长：1 小时 36 分钟&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;链接：https://www.youtube.com/watch?v=DlNR1MrK4qE&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在过去几年中，图像分类、分割、物体检测的技术因深度学习有了极大的进展。该教程会带你了解深度学习的进展，主要集中于使用 Theano 和 Lasagne 的计算机视觉与图像处理。此外，演讲者也讨论了一些重要的技巧，比如用更少的训练数据进行审核等。为了理解视频中的概念，需要一定的代数、微积分与机器学习基础。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3. 深度学习实践-语音识别与其他&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;时长：34 分 46 秒&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;链接：https://www.youtube.com/watch?v=LFDU2GX4AqM&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;吴恩达的地位无需再多做介绍了，大家都知道他对深度学习的贡献。他是世界上首先认识到深度学习潜力的几个人之一。在这个与吴恩达的一对一对话中，他分享了在深度学习上研究的经验、深度学习所到来的科技进展。他提到大数据的进展正在颠覆如今的产业。观看此视频可以了解更多关于深度学习与数据科学的未来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;深度学习的应用&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1. 详解谷歌 DeepMind&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;时长：13 分 44 秒&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;链接：https://www.youtube.com/watch?v=TnUYcTuZJpM&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;AlphaGo 击败围棋前世界冠军李世乭是一个历史时刻。每当机器超越人类的时候，就会引发一轮新的社会进步。谷歌 DeepMind 宣称自己将下一代人工智能和目标带到研发这样的系统活动中：聪明到可以自主采取行动。这个视频解释了 DeepMind 的起源，以及它能为人工智能领域带来的什么样的变革。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2. 自动驾驶汽车和深度学习 GPU-英伟达&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;时长：1 小时 7 分&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;链接：https://www.youtube.com/watch?v=KkpxA5rXjmA&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;英伟达 CEO 黄仁勋分享了深度学习与研究如何改变自动驾驶汽车的面貌，如何让其成真的故事。他开局引介了世界上第一个由英伟达设计的、用于自动驾驶汽车的人工智能超级计算机。还解释了深度神经网络和大数据如何被用于解决 GPU 的问题。深度学习和人工智能如何变不可能为可能？这个视频会让你脑洞大开。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3. 九个超酷的深度学习应用&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;时长：4 分 43 秒&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;链接：https://www.youtube.com/watch?v=Bui3DWs02h4&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;想知道深度学习和机器学习在现实生活中有哪些有趣应用？这个视频会给你答案。你会看到一些让你脑洞大开的应用，比如，不同化学结构的毒性检测，大型图像有丝分裂检测，序列生成，计算机程序自己怎么玩游戏等等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4. 深度学习程序学绘画&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;时长：4 分钟&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;链接：https://www.youtube.com/watch?v=UGAzi1QBVEg&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能神经网络受到了人类大脑的启发，旨在研究神经元之间的连接。在这个视频中，我们会看到几个深度学习应用。但是，神经网络的艺术创作是深度学习最神奇的应用形式。在这个视频里，你将学到如何使用深度学习绘画，或使用人工神经网络对世界名画进行再创作。用户要做的就是输入一张照片，再提供一张目标图片供系统学习（其艺术风格）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;强化学习&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1. 简介强化学习函数逼近-教程&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;时长：2 小时 18 分钟&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;链接：https://www.youtube.com/watch?v=ggqnxyjaKe4&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;强化学习是由机器学习研究社区开发出的用来做最佳序列决策的技术。该教程提供了对底层形式问题（马尔科夫决策过程）及其核心解决方法的透彻理解，后者包括动态编程、蒙特卡洛方法和时序差分学习。该视频注重这些方法如何与参数逼近（parametric approximation）结合从而找到因过大而难以解决问题的好的逼近解决方案。演讲者也会带你了解函数逼近、eligibility traces 和 off-policy 学习的最新进展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2. 深度强化地形学习&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;时长：3 分钟&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;链接：https://www.youtube.com/watch?v=wBrwN4dS-DA&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本视频描述了深度学习与强化学习的结合，这种结合被认为有助于解决许多极端困难的任务。谷歌 DeepMind 使用深度学习建立了一个能够玩 Atari 游戏的系统，其表现超过了人类。视频展示了一个有趣的应用就是使用深度强化学习教会处在某些地带中的动物绘制周围环境，避免障碍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;结语&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这就是 2016 年的人工智能视频盘点，我们收集了一系列关于深度学习与强化学习的视频。根据年份、浏览量与关联度挑选出最后名单。目前在网络上有着丰富的内容资源，而我们提供的是其中最引人关注的一部分。相信这个列表中肯定会有适合你的内容。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文链接：https://www.analyticsvidhya.com/blog/2016/12/21-deep-learning-videos-tutorials-courses-on-youtube-from-2016/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 14 Dec 2016 14:01:13 +0800</pubDate>
    </item>
    <item>
      <title>资源 | 斯坦福大学NLP组开放神经机器翻译代码库（附论文）</title>
      <link>http://www.iwgc.cn/link/3911932</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自斯坦福&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀、杜夏德&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;近日，斯坦福大学自然语言处理组（Stanford NLP）发布了一篇文章，总结了该研究组在神经机器翻译（NMT）上的研究信息。在这篇文章中，他们还放出了在多种翻译任务上（比如英德翻译和英语-捷克语翻译）实现了当前最佳结果的代码库（codebase）。除此之外，「为了鼓励再现和增加透明」，他们还放出了他们用于训练模型的处理过的数据以及可以通过他们的代码库使用的预训练好的模型。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;发布地址：http://nlp.stanford.edu/projects/nmt/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9DFP58EX6ymYTnLpicibkXOrOBVuMwuHto1wKEUWPRfLbPzw2YA0iaqnZeC4GmD5qyQ2Y8zu24U416w/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;参与成员：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Christopher D. Manning（斯坦福大学计算机科学和语言学教授）&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Minh-Thang Luong（斯坦福博士，Google Brain 研究科学家）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Abigail See（斯坦福大学计算机科学在读博士）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Hieu Pham&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;代码库&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;对于混合 NMT（hybrid NMT），请使用这个代码库并且引用：&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;代码库：https://github.com/lmthang/nmt.hybrid&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;论文：使用混合词-字符模型实现开放词汇神经机器翻译（Achieving Open Vocabulary Neural Machine Translation with Hybrid Word-Character Models）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：几乎之前所有的神经机器翻译（NMT）使用的词汇都受限，随后可能用一个方法来修补未知的单词。本论文展示了一个全新的能实现开放词汇神经机器翻译（open vocabulary NMT）的词-字符解决方法。我们建立了一个混合的系统，能够实现大部分的词级（word level）翻译，并可查阅罕见词的字母组成。我们字符级的循环神经网络能计算源词的表征，并能在需要时恢复未知的目标词。这种混合的方法还有一个双重优点是，与基于字符的网络相比，它更快且更容易训练；同时，它不像基于词的模型那样会产生未知的词。在 WMT' 15 英语-捷克语的翻译任务上，这种混合方法还实现了一个额外的+ 2.1 BLEU 分的提升——超过已经能处理未知单词的模型 11.4 BLEU 分。我们的最佳系统在这个任务上达到了新的最佳表现：20.7 BLEU 分。我们证明了我们的字符模型不仅能成功地学习生成形式很好的捷克语词（这是一种词汇复杂高度屈折的语言），还能为英语源词建立了正确的表征。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;对于通用的基于注意的 NMT（general attention-based NMT），请引用以下论文：&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;代码库：https://github.com/lmthang/nmt.hybrid&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;论文：实现基于注意的神经机器翻译的有效方法（Effective Approaches to Attention-based Neural Machine Translation）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：最近一种在翻译过程中通过选择性地集中关注部分源句子的注意机制被用于提升神经机器翻译（NMT）结果。然而，探索用于基于注意的神经机器翻译（NMT）的有用架构的研究还不多。本论文探讨了两种简单有效的注意机制类别：一种能顾及到所有源词的全局方法，以及一种只能一次查看源词的一个子集的局部方法。我们证明了在英语-德语/德语-英语 WMT 翻译任务上，这两种方法都是有效的。使用局部注意方法，相比于已经结合了 dropout 等技术的非注意系统，我们的系统增长了 5.0 BLEU 点。我们的组合模型使用了不同的注意架构，在 WNT'15 英语-德语的翻译任务中，实现了目前最好的结果：25.9 BLEU 点；比现有的基于 NMT 和 一个 n-gram reranker 的最佳系统提升了 1.0 BLEU 点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;对于剪枝 NMT（pruning NMT），请引用以下论文（如果你对代码有兴趣，请联系我们）：&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;论文：通过剪枝的神经机器翻译的压缩（Compression of Neural Machine Translation Models via Pruning）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：和其它许多深度学习领域一样，神经机器翻译（NMT）常会遭遇过度参数化（over-parameterization）的问题，这会导致需要大量的存储空间。这篇论文检查了三种简单的基于幅度的（magnitude-based）用来压缩 NMT 模型的剪枝方案，即 class-blind、class-uniform 和 class-distribution；它们的不同之处在于剪枝的阈值为 NMT 架构中不同的权重类所计算的方式。我们表明权重剪枝（weight pruning）可作为一种用于当前最佳 NMT 压缩技术。我们表明一个带有超过 2 亿个参数的 NMT 模型可以在仅有非常少量的性能损失的情况下被剪去 40%——这个结果是在 WMT'14 英语-德语翻译任务上得到的。这揭示了 NMT 架构中的冗余的分布。我们的主要结果是：通过再训练（retraining），我们可以使用 80% 剪枝的模型来恢复甚至超越原有的表现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;预处理的数据&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;WMT'15 英语-捷克语数据（大）&lt;/span&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;训练集（包含 1580 万个句子对）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;英语训练集（train.en）：http://nlp.stanford.edu/projects/nmt/data/wmt15.en-cs/train.en&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;捷克语训练集（train.cs）：http://nlp.stanford.edu/projects/nmt/data/wmt15.en-cs/train.cs&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;测试集：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;newstest2013.en：http://nlp.stanford.edu/projects/nmt/data/wmt15.en-cs/newstest2013.en&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;newstest2013.cs：http://nlp.stanford.edu/projects/nmt/data/wmt15.en-cs/newstest2013.cs&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;newstest2014.en：http://nlp.stanford.edu/projects/nmt/data/wmt15.en-cs/newstest2014.en&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;newstest2014.cs：http://nlp.stanford.edu/projects/nmt/data/wmt15.en-cs/newstest2014.cs&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;newstest2015.en：http://nlp.stanford.edu/projects/nmt/data/wmt15.en-cs/newstest2015.en&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;newstest2015.cs：http://nlp.stanford.edu/projects/nmt/data/wmt15.en-cs/newstest2015.cs&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;词汇库（最常见的词）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;vocab.1K.en：http://nlp.stanford.edu/projects/nmt/data/wmt15.en-cs/vocab.1K.en&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;vocab.1K.cs：http://nlp.stanford.edu/projects/nmt/data/wmt15.en-cs/vocab.1K.cs&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;vocab.10K.en：http://nlp.stanford.edu/projects/nmt/data/wmt15.en-cs/vocab.10K.en&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;vocab.10K.cs：http://nlp.stanford.edu/projects/nmt/data/wmt15.en-cs/vocab.10K.cs&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;vocab.20K.en：http://nlp.stanford.edu/projects/nmt/data/wmt15.en-cs/vocab.20K.en&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;vocab.20K.cs：http://nlp.stanford.edu/projects/nmt/data/wmt15.en-cs/vocab.20K.cs&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;vocab.50K.en：http://nlp.stanford.edu/projects/nmt/data/wmt15.en-cs/vocab.50K.en&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;vocab.50K.cs：http://nlp.stanford.edu/projects/nmt/data/wmt15.en-cs/vocab.50K.cs&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;词典（从对齐的数据中提取出来的，dict.en-cs）：http://nlp.stanford.edu/projects/nmt/data/wmt15.en-cs/dict.en-cs&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;字符库：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;vocab.char.200.en (http://nlp.stanford.edu/projects/nmt/data/wmt15.en-cs/vocab.char.200.en)&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;vocab.char.200.cs (http://nlp.stanford.edu/projects/nmt/data/wmt15.en-cs/vocab.char.200.cs)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;注：我们的论文《Achieving Open Vocabulary Neural Machine Translation with Hybrid Word-Character Models》中使用了这个数据集。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;WMT'14 英语-德语数据（中）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;训练集（包含 450 万个句子对）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;英语训练集（train.en）：http://nlp.stanford.edu/projects/nmt/data/wmt14.en-de/train.en&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;德语训练集：（train.de）：http://nlp.stanford.edu/projects/nmt/data/wmt14.en-de/train.de&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;测试集：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;newstest2012.en：http://nlp.stanford.edu/projects/nmt/data/wmt14.en-de/newstest2012.en&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;newstest2012.de：http://nlp.stanford.edu/projects/nmt/data/wmt14.en-de/newstest2012.de&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;newstest2013.en：http://nlp.stanford.edu/projects/nmt/data/wmt14.en-de/newstest2013.en&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;newstest2013.de：http://nlp.stanford.edu/projects/nmt/data/wmt14.en-de/newstest2013.de&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;newstest2014.en：http://nlp.stanford.edu/projects/nmt/data/wmt14.en-de/newstest2014.en&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;newstest2014.de：http://nlp.stanford.edu/projects/nmt/data/wmt14.en-de/newstest2014.de&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;newstest2015.en：http://nlp.stanford.edu/projects/nmt/data/wmt14.en-de/newstest2015.en&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;newstest2015.de：http://nlp.stanford.edu/projects/nmt/data/wmt14.en-de/newstest2015.de&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;词汇库（最常见的 5 万个词）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;vocab.50K.en (http://nlp.stanford.edu/projects/nmt/data/wmt14.en-de/vocab.50K.en)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;vocab.50K.de (http://nlp.stanford.edu/projects/nmt/data/wmt14.en-de/vocab.50K.de)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;词典（从对齐的数据中提取出来的，dict.en-de）：http://nlp.stanford.edu/projects/nmt/data/wmt14.en-de/dict.en-de&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;注：我们的论文《Effective Approaches to Attention-based Neural Machine Translation》中使用了这个数据集。另外，因为历史上的原因，我们对合成词（compound words）做了拆分。比如，rich-text format --&amp;gt; rich ##AT##-##AT## text format.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;IWSLT'15 英语-越南语数据（小）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;训练集（包含 13.3 万个句子对）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;英语训练集（train.en）：http://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/train.en&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;越南语训练集（train.vi）：http://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/train.vi&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;测试集：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;tst2012.en：http://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/tst2012.en&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;tst2012.vi：http://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/tst2012.vi&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;tst2013.en：http://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/tst2013.en &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;tst2013.vi：http://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/tst2013.vi&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;词汇库（最常见的 5 万个词）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;vocab.en：http://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/vocab.en&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;vocab.vi：http://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/vocab.vi&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;词典（从对齐的数据中提取出来的，dict.en-vi）：http://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/dict.en-vi&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;注：我们的论文《Stanford Neural Machine Translation Systems for Spoken Language Domains》中使用了这个数据集&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;预训练的模型&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们放出了预训练好的模型，可以直接通过我们的 Matlab 代码使用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;注：要使用这些模型，必须要一个 GPU。如果想要这些模型在 CPU 上可用，请考虑使用这个脚本：https://github.com/stanfordnlp/nmt/blob/master/code/misc/model2cpu.m&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;WMT'15 英语-捷克语混合模型（hybrid models）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;我们训练了 4 个具有同样架构的模型（全局注意、双线性形式、dropout、两层字符级模型）:&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;1. Model 1：http://nlp.stanford.edu/projects/nmt/models/wmt15.en-cs/model1.mat&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;2. Model 2 ：http://nlp.stanford.edu/projects/nmt/models/wmt15.en-cs/model2.mat&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;3. Model 3：http://nlp.stanford.edu/projects/nmt/models/wmt15.en-cs/model3.mat&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;4. Model 4：http://nlp.stanford.edu/projects/nmt/models/wmt15.en-cs/model4.mat&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;WMT'14 英语到德语基于注意的模型（attention-based models）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;1. 全局注意、点积：http://nlp.stanford.edu/projects/nmt/models/wmt14.en-de/globalAttn-dotProduct.mat&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;2. 全局注意、点积、dropout：http://nlp.stanford.edu/projects/nmt/models/wmt14.en-de/globalAttn-dotProduct-dropout.mat&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;3. 全局注意、双线性形式、dropout：http://nlp.stanford.edu/projects/nmt/models/wmt14.en-de/globalAttn-bilinear-dropout.mat&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;4. 局部注意（单调）、双线性形式：http://nlp.stanford.edu/projects/nmt/models/wmt14.en-de/localAttnMono-bilinear.mat&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;5. 局部注意（单调）、双线性形式、dropout：http://nlp.stanford.edu/projects/nmt/models/wmt14.en-de/localAttnMono-bilinear-dropout.mat&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;6. 局部注意（预测）、点积、dropout：http://nlp.stanford.edu/projects/nmt/models/wmt14.en-de/localAttnPred-dotProduct-dropout.mat&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;7. 局部注意（预测）、双线性形式：http://nlp.stanford.edu/projects/nmt/models/wmt14.en-de/localAttnPred-bilinear.mat&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;8. 局部注意（预测）、双线性形式、dropout：http://nlp.stanford.edu/projects/nmt/models/wmt14.en-de/localAttnPred-bilinear-dropout.mat&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;IWSLT'15 英语-越南语基于注意的模型（attention-based models）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;1. 全局注意、双线性形式、dropout：http://nlp.stanford.edu/projects/nmt/models/iwslt15.en-vi/globalAttn-bilinear-dropout.mat&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;2. 全局注意、concatenate ：http://nlp.stanford.edu/projects/nmt/models/iwslt15.en-vi/globalAttn-concat.mat&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;3. 局部注意（预测）、点积、dropout：http://nlp.stanford.edu/projects/nmt/models/iwslt15.en-vi/localAttnMono-dotProduct-dropout.mat&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;4. 局部注意（单调）、双线性形式、dropout：http://nlp.stanford.edu/projects/nmt/models/iwslt15.en-vi/localAttnMono-bilinear-dropout.mat&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;5. 局部注意（单调）、双线性形式：http://nlp.stanford.edu/projects/nmt/models/iwslt15.en-vi/localAttnMono-bilinear.mat&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;6. 局部注意（单调）、concatenate、dropout ：http://nlp.stanford.edu/projects/nmt/models/iwslt15.en-vi/localAttnMono-concat-dropout.mat&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;7. 局部注意（预测）、点积、dropout：http://nlp.stanford.edu/projects/nmt/models/iwslt15.en-vi/localAttnPred-dotProduct-dropout.mat&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;8. 局部注意（预测）、双线性形式：http://nlp.stanford.edu/projects/nmt/models/iwslt15.en-vi/localAttnPred-bilinear.mat&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;9. 局部注意（预测）、concatenate、dropout：http://nlp.stanford.edu/projects/nmt/models/iwslt15.en-vi/localAttnPred-concat-dropout.mat&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;联系信息&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有任何评论或疑问，可联系第一作者：lmthang@stanford.edu&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 14 Dec 2016 14:01:13 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 谷歌无人车项目成为独立公司Waymo，新车或2017年商用</title>
      <link>http://www.iwgc.cn/link/3911933</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自TechCrunch&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李泽南、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;谷歌母公司 Alphabet 本周二宣布，旗下的无人驾驶汽车项目正式从 X 中独立出来，成为一家新公司 Waymo，这个名字源于它的使命：「出行新方式（a new way forward in mobility）」。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们现在是 Alphabet 旗下的独立公司了，」Waymo 首任 CEO John Krafcik 在旧金山举行的新闻发布会上说道。他在发布会上同时透露，Waymo 团队去年已经在奥斯汀的公共道路上实现了第一次全无人驾驶，谷歌的无人驾驶汽车不同于其他公司的传统设计，它没有方向盘，没有控制踏板，已经可以在「真实交通情况」的城市街道上正常运行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;iframe class="video_iframe" data-vidtype="1" style="   z-index:1; " height="375" width="500" frameborder="0" data-src="https://v.qq.com/iframe/preview.html?width=500&amp;amp;height=375&amp;amp;auto=0&amp;amp;vid=d03555jcdn4" allowfullscreen=""&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2015 年 10 月 20 日是有史以来第一次，全无人驾驶汽车开上了公共道路，Waymo 首席工程师 Nathaniel Fairfield 的一位盲人朋友 Steve Mahan 成了无人驾驶汽车首次独立出行的乘客。Mahan 曾经乘坐谷歌原型车参与过多次实验，但在此之前每一次出行都有警察开道。这一次，无人驾驶汽车完全不受保护，并且在行驶过程中进行了四向停车，通过人行道并穿越了奥斯丁的一些狭窄的街道。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在新闻发布会上，Mahan 把乘坐无人驾驶汽车比作宇航员飞行，自己是「1 号驾驶员」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最近，谷歌无人驾驶汽车战略发生了变化，前现代北美负责人 Krafcik 被邀请成为新成立的 Waymo CEO。这一步暗示谷歌的无人驾驶汽车已经从实验室走向了实用阶段，公司正在为其商业化，积极布局。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9DFP58EX6ymYTnLpicibkXOricTwykvY2aMSVLibIP735KicjsZyiaUJ6j8lEblWrWEkibWiazdB0f2gpOMg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们一直在强调，谷歌无人车已经在公共道路上行驶了 200 万英里，」Krafcik 在发布会上说道。「现在我们的实验车正在进行最后一百万英里的测试，而且我还没有提到我们在模拟器上的里程数。我们的车辆已经载着谷歌员工和一些客人在山景城、奥斯丁和菲尼克斯进行了超过一万次旅行。」&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌在过去一年不断扩大自己的无人驾驶汽车项目，雇用了更多的工程师，同时将其设在美国的测试中心从两个增加至四个。自 2009 年以来，谷歌的自动驾驶原型车在道路上累积行驶了相当于 300 年的驾驶时间，而在过去一年时间里，谷歌自动驾驶汽车的模拟行驶里程也已超过 10 亿英里。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Google X 的自动驾驶汽车项目组（现在的 Waymo），已经在驾驶和测试上花费了大量时间，也取得了很多成绩。尽管如此，Waymo 的自动驾驶技术主管 Dmitri Dolgov 仍然表示，目前还有很多工作需要完成，包括构建更详细的地图，让汽车行驶更加平稳，让自动导航系统能够适应极端恶劣天气，如大雨和雪天等等。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;至于 Waymo 的未来发展，Krafcik 表示，目前公司看到了很多潜在机会。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9DFP58EX6ymYTnLpicibkXOrBMjDia5ibeUP5Fic3leSImt1FhDI09AB5yf7BVoALHeUSpB3P2go8Ko8A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;新公司 Waymo 的 logo&lt;/span&gt;&lt;/em&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们可以想象，未来，在拼车、交通运输、货运、物流甚至个人用车、公共交通和解决最后一英里问题方面，自动驾驶技术都将占据重要地位，」Krafcik 说道。「在所有这些领域，自动驾驶汽车都具有很大潜力。」Krafcik 同时强调，新公司将专注于技术，不一定会自己制造汽车。这种策略符合分析师们之前的报告——谷歌会倾向于和汽车厂商合作制造新产品，而不是自己建厂。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们是一家自动驾驶汽车科技公司，」Krafcik 强调。「我们非常清楚自己不是汽车厂商，尽管这说起来有点拗口，但这就是我们的理念：我们要做的不是更好的汽车，而是更好地驾驶方式。」&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9DFP58EX6ymYTnLpicibkXOrqHafNAEWUCs2hD4z7UIl0I7WsONiaq0Medjc3ulzmVqjrhVcPicicwAkQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Krafcik 表示，Waymo 目前正处在「构建阶段」，正在将下一代自动驾驶系统装进克莱斯勒 Pacifica 中。在今年早些时候，谷歌曾经宣布与菲亚特-克莱斯勒合作，在 100 辆车上试验自动驾驶装置，这是谷歌第一次宣布与汽车厂商进行合作。目前，这一计划中的车辆正在进行道路测试。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌在自动驾驶上的潜在竞争对手 Uber 也正在进行自己的计划，后者正在积极寻求与汽车制造厂商合作，目前 Uber 的自动驾驶系统已经在福特与沃尔沃等品牌的汽车上进行了测试。而一些汽车厂商，如大众和通用，也正在发展自己的自动驾驶技术。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;据彭博社昨日的报道，Alphabet 的最新自动驾驶公司将与克莱斯勒合作部署拼车服务，或许在 2017 年底，我们就将看到半自动驾驶的克莱斯勒 Pacifica 上路载客。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;就像之前提到的，谷歌先前曾宣布基于菲亚特-克莱斯勒 Pacifica 平台制造 100 台原型自动驾驶汽车，但这次新计划的规模将更广，对汽车要求更高。菲亚特也计划在即将到来的拉斯维加斯 CES 展上公布一款全电驱动的 Pacifica 汽车，这会成为与谷歌合作的要素，因为电动汽车更符合未来自动驾驶按需服务的实际需求。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;作为 Alphabet 旗下的又一个独立公司，Waymo 肯定不能再忽视商业上的进展与表现了，这家公司下一步的动向将非常值得关注。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文链接：https://techcrunch.com/2016/12/13/googles-self-driving-car-unit-spins-out-as-waymo/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 14 Dec 2016 14:01:13 +0800</pubDate>
    </item>
    <item>
      <title>前沿 | 纽约大学发现新的言语工作记忆结构，可用于人工智能研究</title>
      <link>http://www.iwgc.cn/link/3911934</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自NYU&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：杜夏德、李泽南、曹瑞&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;纽约大学的一项新研究发现，在言语工作记忆中，我们用来存储和处理信息的神经结构比我们之前所理解的要复杂的多，这种结构的发现会影响到人工智能系统的建立。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人类用于言语工作记忆（vWM）中储存和处理信息的神经结构要比以前我们所理解的更加复杂，纽约大学的研究者们刚刚在Nature Neuroscience上发表了他们的新研究，这一发现对人工智能系统例如语音翻译工具的构建有着重要的意义。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这项研究认为，在言语记忆工作中的信息处理过程包含了大脑中两个不同的网络，而不是以往认为的一个，这个发现可能会对打造语音翻译工具这样的人工智能系统产生影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;「&lt;/span&gt;我们的研究结果显示，当人类在思维中处理使用语音和语言信息时，至少有两个大脑网络是活跃的，&lt;span&gt;」&lt;/span&gt;纽约大学神经科学副教授Bijan Pesaran说，他是这篇论文的作者之一。&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;过去的研究强调了单一的「中央执行机构」 如何监督存储在记忆工作的操作（manipulation）信息。据Pesaran的观察，这是一个非常重要的假设，因为目前的复制人类语音的人工智能系统通常都假设言语工作记忆中的计算都由一个单独的中心网络负责。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;「&lt;/span&gt;人工智能需要尽量模仿人类， &lt;span&gt;」&lt;/span&gt;Pesaran说。&lt;span&gt;「&lt;/span&gt;通过更好的理解人脑的运行机制，我们可以提出更多提升人工智能系统的方法。我们的研究暗示了我们需要构建带有多个工作记忆网络的人工智能系统。&lt;span&gt;」&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本文的第一作者是Greg Cogan，他曾经是纽约大学的一名博士后，现在来到了杜克大学；其他共同作者包括纽约大学Langone医学中心综合性癫痫中心主任Orrin Devinsky教授，纽约大学Langone神经外科系副教授Dan Friedman，和纽约大学神经系统助理教授Lucia Melloni。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该研究旨在对这种思考、规划和创造性推理至关重要的工作记忆形式进行研究，并涉及了记忆中的语言形式转换，以及形成语言所需的信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;研究人员分析了耐药性颠病人类患者的治疗过程，对病人们的大脑活动进行了监测。具体来说，他们探究了这些病人在倾听和说话时大脑中的深层神经活动，尝试解答为什么病人的反应会出现一定时间的延迟。科学家们在实验中要求研究对象使用研究人员提供的规则，将他们听到的语音用自己的话复述出来。例如，有时患者会被告知要原文复述他们听到的内容，而在其他时间，研究人员指示患者听到声音后用不同的方式复述内容。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;研究人员将每一位患者大脑当中的神经活动进行了解码，患者采用了研究人员提供的规则，将他们听到的东西转化为所需要说的话。结果表明抑制工作记忆当中的操纵信息涉及到了两个大脑网络的运作。一个网络解码了指导患者表达的原则，也就是规则网络（the rule network）。令人惊讶的是，规则网络没有解码出怎样将听到的内容转化为表达内容的细节。使用这个规则将声音转化为言语的过程仅需要一秒钟，这就是转化网络（transformation network）。这个网络当中的活动能够跟踪输入（听到的内容）是如何渐渐转化为输出（所说的话）的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;研究者同时表示，将你听到的一种语言进行翻译，再用另外一种语言表达出来，其中涉及到了一些类似的抽象原则。具有言语工作记忆（vWM）障碍的人学习一门新语言很困难。现代的智能机器在学习语言当中也存在着一些问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Pesaran说：「创造更加智能系统的唯一途径就是对人类大脑和思维的运作进行更加全面的了解。」「人类工作记忆障碍的诊断和治疗涉及到心理学鉴定。以此类推，机器心理学可能也会在将来的某一天对机器智能障碍的诊断和治疗有帮助。这项研究对这种独特的人类智能、言语工作记忆形式进行了研究，提出了让人工智能进一步发展的新方向。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;论文：Manipulating stored phonological input during verbal working memory&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：&lt;/span&gt;&lt;span&gt;言语工作记忆（vWM）包含了音系感知输入中的存储和操纵信息。对 vWM 目前最具影响力的理论认为，全部处理任务由一个中央执行机构执行，信息存储则由两个互相联系的系统执行：语音输出是由可获取基于声音信息的音位输入缓冲器和和发音排练系统来控制的。然而，目前仍没有理论解释语言在大脑中的神经活动是如何被编码处理的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在本研究中，我们在受试者处理语音时的脑神经活动中成功读取了 vWM 内容。正如我们所猜测的，我们找到了包含语音感觉和发音运动表示的存储系统。然而，意料之外的是，我们发现这一处理过程不是由单一的中央处理机构进行，而是由两个任务不同的系统协作完成的。因此，我们认为，中央执行机构是由多个用于处理语音输入和形成语音输出的 vWM 子系统组成的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 14 Dec 2016 14:01:13 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 微软开放小娜：推出两款开发工具提供软硬件支持</title>
      <link>http://www.iwgc.cn/link/3911935</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自微软&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：曹瑞、蒋思源&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;目前正处于人工智能科技革命的开端。所有人工智能的力量都通过个人数字助手的界面成为我们每个人的延伸。要实现这样的前景，需要有一整个社区来对其进行投资，并且能够分享其所带来的益处。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今天，微软让我们看到了 Cortana 的下一步新发展。这家科技巨头今天宣布推出全新的 Cortana Skills Kit 和 Cortana Devices SDK。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9DFP58EX6ymYTnLpicibkXOrCfvY192D3qibqDFmjendLN9F6LfeuQsOpz4eJg25IjaJ5PsX0LicEETw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Cortana Skills Kit 是为了让开发者能够接触到 1.45 亿 Cortana 用户，帮助用户跨平台地发现、参与和完成事务，这些平台包括：Windows、Android、iOS、Xbox 和 Cortana 驱动的新型设备。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Cortana Devices SDK 能够让原始设备制造商（OEM）和原始设计制造商（ODM）创造出新一代的智能个人设备：不管是没有屏幕还是在大屏幕上、不管家里还是在外面使用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前开发者和制造商已经可以注册了：https://developer.microsoft.com/zh-cn/windows/projects/campaigns/cortana-skills-kit，微软表示结束 private preview 之后就会推送更新。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Cortana Skills Kit 预览&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Cortana Skills Kit 能够让开发者利用微软 bot 开发框架（Microsoft Bot Framework）帮助开发 bot 并将其发布出来作为 Cortana 的一项新技能，还能让开发者整合网页服务作为新技能以及将他们已有的 Alexa 技能的代码用于创建 Coratna 技能。它可以在用户询问时将用户与所需的技能连接起来，并能在适当的背景下主动向用户提供服务。另外，Cortana Skills Kit 还能够帮助开发者通过 Cortana 了解用户偏好，并基于用户给予的权限为他们带来个性化的用户体验。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在今天旧金山的发布会上，微软向大家展示了一些早期的开发伙伴是如何利用 Cortana Skills Kit 的。微软表示该工具包将在 2017 年 2 月向更多人开放。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Knowmail 将人工智能应用于电子邮件过载问题，其使用 Bot Framework 构建了一个 bot，并已发布到了 Cortana。他们的智能解决方案可用于 Outlook 和 Office 365，它会学习你使用电子邮件的习惯，以便在你有空的时候提供需要优先处理的电子邮件。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一家登录 Cortana 平台的金融服务公司是 Capital One，微软展示了它是如何通过 Cortana 的免手持自然语言交谈，使用在声音技术上的已有投入来使客户有效地管理他们的资金。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;全球最大的在线旅游公司 Expedia 利用 Microsoft Bot Framework 研发了一款 Skype 平台的 bot，这个 bot 作为一种新的 Cortana 技能，能够帮助用户预订酒店。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;家政服务平台 TalkLocal 公司的 Cortana 技能可以让人们使用自然语言找到当地的服务提供商。比如说，你对 Cortana 说:「小娜，我家的天花板漏水了，情况紧急。」这时候 TalkLocal 公司就会帮助你找一位合适的水暖工。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;设备制造商的 Cortana 设备 SDK&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们相信个人助手需要在你日常生活中提供帮助，不论你是在家、在工作还是其它任何地方都能有效地给予帮助。我们称之为 Cortana 是和你「无约束（unbound）」地绑定的，而不是与任何一个平台或设备绑定的。这就是 Cortana 支持 Windows 10、Android、iOS、Xbox 和多种移动平台的原因。我们上周发布的 Windows 10 Creators Update 的 IoT Core 版将嵌入 Cortana，这将为物联网设备提供有力的支持。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;实现这个目标的下一步正是 Cortana Devices SDK，这将 Cortana 提供给了所有 OEM 和 ODM，让他们可以在所有平台上构建更智能的设备。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该 SDK 也将带领 Cortana 继续完成在任何地方任何时间提高个人生产力的承诺，它将提供与 Skype、电子邮件、日历和列表集成的实时的、双向的语音通信功能，这一切都将使得生活无处不简单。当然 Cortana 也会加载一些专业化技能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们正在与一系列行业和硬件开发商进行合作，包括一些激动人心的互联汽车项目。该 SDK 是为多样化而设计的，支持通过开源协议和软件库跨 Windows IoT、Linux 和 Android 等许多平台。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Cortana Devices SDK 目前正在进行 private preview，它将在 2017 年向更多人开放。如果你是 OEM 或 ODM 并有兴趣在你的设备中嵌入 Cortana，可以填写这个表格获得 Cortana Devices SDK 的最新消息和（可能的）早期预览版使用权限：http://cortanadevicesdksignup.azurewebsites.net&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文链接：https://blogs.windows.com/buildingapps/2016/12/13/cortana-skills-kit-cortana-devices-sdk-announcement/#GIHy5kf5QIzIxc9q.97&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 14 Dec 2016 14:01:13 +0800</pubDate>
    </item>
    <item>
      <title>深度｜NIPS 2016最全盘点：主题详解、前沿论文及下载资源（附会场趣闻）</title>
      <link>http://www.iwgc.cn/link/3896801</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心编辑&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;参与：微胖、杜夏德、吴攀、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;当地时间 12 月 5 日到 10 日，机器学习和计算神经科学的国际顶级会议第 30 届神经信息处理系统大会（NIPS 2016）在西班牙巴塞罗那举行。在这次会议上，人工智能和机器学习领域的研究者为我们呈现了这一领域的研究前沿，其中包括：学习去学习（learning-to -learn）、生成对抗网络（GAN）、用于三维导航的强化学习、RNN 等等；与此同时，一些资深研究者也带来了一些极具看点和启发价值的演讲和教程，其中包括：《&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721081&amp;amp;idx=1&amp;amp;sn=d557968703d4af879b5cf6461069dacd&amp;amp;chksm=871b0f47b06c865185865fcd5ef92af7726e84ae9e689b7ced9986a08c9fe3113df296a8469a&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721081&amp;amp;idx=1&amp;amp;sn=d557968703d4af879b5cf6461069dacd&amp;amp;chksm=871b0f47b06c865185865fcd5ef92af7726e84ae9e689b7ced9986a08c9fe3113df296a8469a&amp;amp;scene=21#wechat_redirect"&gt;吴恩达 NIPS 2016 演讲现场直击:如何使用深度学习开发人工智能应用?&lt;/a&gt;》、《&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721284&amp;amp;idx=1&amp;amp;sn=427e7f45c8253ab22a3960978409f5d1&amp;amp;chksm=871b087ab06c816c424ad03810be3e1b3aa9d6e99a5f325047796f110d178a07736f667d1a10&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721284&amp;amp;idx=1&amp;amp;sn=427e7f45c8253ab22a3960978409f5d1&amp;amp;chksm=871b087ab06c816c424ad03810be3e1b3aa9d6e99a5f325047796f110d178a07736f667d1a10&amp;amp;scene=21#wechat_redirect"&gt;GAN 之父 NIPS 2016 演讲现场直击：全方位解读生成对抗网络的原理及未来&lt;/a&gt;》和《&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721325&amp;amp;idx=4&amp;amp;sn=d570f04d737d09c1b1cebd962755af3f&amp;amp;chksm=871b0853b06c8145985f8c2c5ac7445118f18ce35532c0389b0e5ec24a7a1c4b841fe81280de&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721325&amp;amp;idx=4&amp;amp;sn=d570f04d737d09c1b1cebd962755af3f&amp;amp;chksm=871b0853b06c8145985f8c2c5ac7445118f18ce35532c0389b0e5ec24a7a1c4b841fe81280de&amp;amp;scene=21#wechat_redirect"&gt;Bengio 和 LeCun 在 NIPS 2016 上的演讲&lt;/a&gt;》等等。现在，NIPS 2016 已经顺利闭幕，与会的各路研究者开始在网上分享他们的参会经历和体验，以及总结相关的研究进展。机器之心在此对网络上多篇 NIPS 相关的总结文章进行了综合梳理。&lt;/span&gt;&lt;/em&gt;&lt;br/&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;NIPS 2016 主题概览&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;首先，开放性&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。两年前，亚马逊开始公开他们的研究，现在他们是这场大会的主要参与者。今年，根据 NIPS 与会者的一系列推文，苹果人工智能研究主管、卡内基梅隆大学教授 Russ Salakhutdinov 在会议上表示，「苹果的人工智能研究团队将公开发表他们的研究成果并更多地参与到广阔的学术圈中去。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;其次，模拟&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。Yann LeCun 在开幕 Keynote 演讲中提到，「模拟是减轻强化学习的高样本复杂性的好策略。」同时，从科学方法论上看，对于反事实的场景，模拟的环境是数据集的模拟，因此它们可以使用共同的指标，允许重复性实验和创新民主化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;模拟器不是什么新东西，过去人们对它也曾有过热情和悲观的浪潮，也有很多陷阱，基本上可以归结为过度训练模拟器（包括微观上得到一个不好的模型和宏观上将科学注意力集中在不相关的问题上。）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有两点需要注意。第一个是 Jason Williams 建议的，相对的性能结论可以接受，但是，绝对的性能结论值得怀疑。第二点是 Antoine Bordes 主张使用一个可实现的模拟问题的集合（也就是对于多种问题，哪一种完美的性能是可能实现的，哪一种能表现出明显不同的能力，目前还不知道什么方法可以解决所有问题。）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;毫无疑问，模拟器正在激增。比如 GVGAI，CommAI-env，Project Malmo 以及会议期间公布的 OpenAI Universe 以及 DeepMind Lab。除了理模拟器外，以下几个主题今年也讨论的也比较多。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;生成对抗网络。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;今年，来自其他会议（比如 ICLR）的 GAN 研究热席卷了本次大会。这与模拟有关，尽管更多的是面向减轻样本复杂性而非科学方法论主题。人们正在弄清楚 GAN 能实现如此好的优化能力的奇怪原因，这些原因应该能在近期内帮助深度学习获得一些有趣的改进（不止于许多漂亮照片）。对于 NLU 任务来说，这有点不幸，因为目前从 GAN 生成文本的成熟性并不如声音、图像的生成.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;可解释模型&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。在产业领域，有关能够自己进行解释的模型的想法很流行，不过，我还是第一次看到可解释性得到 NIPS 的很大关注。即将到来的欧盟管制显然加剧了人们对这个主题的兴趣。不过还有其他原因：比如，如果表征更加可以解释的话，那么，表征学习近期取得的进展就能让科学查询更加容易。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;NIPS 2016 研究主题详解&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这部分的要点总结来自 Insight Data Science 程序开发主任兼研究科学家 Ross Fadely 的系列文章。机器之心进行了适当的删减和整理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;第一天亮点：生成对抗网络&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大会第一天主要是参会研究者们带来的一系列研究主题上的最近进展 tutorial。其中这三个是比较引人关注的：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先是来自哥伦比亚大学的统计与计算机科学教授 David Blei 深入介绍了变分推理（Variational Inference）研究的最近的多项进展。最有影响的还是重新参数化（reparameterization）的技巧，该技巧可以通过随机变量实现反向传播，同时也推动了变自编码器上最新进展。吴恩达带来的则是偏向应用的指导，他介绍了自己在业界打造学习系统的最佳实践经历。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一个演讲是法国国家信息与自动化研究所的 Francis Bach 带来的（非）凸优化上的最新进展，其中如 SAGA（https://arxiv.org/abs/1407.0202）这样的算法轻松打败了 BFGS（Broyden–Fletcher–Goldfarb–Shanno algorithm）。一旦有了通用的库，这种算法可以在数据科学和应用机器学习领域发挥巨大的作用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;明星级的 Tutorial 当属 Ian Goodfellow 的 GAN（生成对抗网络）。Yann LeCun 大会开幕主题演讲上将 GAN 评价为「近 20 年来（该领域）最令人兴奋的思想。」Goodfellow 清晰地描绘了 GAN 的概念及其目前的进展，还有一些小技巧和提示以及当前的研究前沿。他提到的更多的是使用 GAN 训练的最新进展。最后，Goodfellow 以 Plug &amp;amp; Play Generative Networks（即插即用生成网络）的最新进展惊艳全场，该技术首次产生了逼真的计算机生成图像（如下图）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8qAJibEDtyiaJvlXTAh04GAcynBPehCpTaibw1JsrISo4SKfjK9NpDsgRnZe9G4Yf4HY6zwHLUCYqjA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;从 Plug &amp;amp; Play Generative Networks（Nguyen et al. 2016）上面的图像分别是赤足鹬鸟、蚂蚁和修道院，看上去比最近的其他几张生成图都要真实&amp;nbsp;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一天还有一个大亮点：共 170 多个展位的海报展示。Yoshua Bengio、 Diederik Kingma 和 David Blei 也站在人群中给大家讲解他们的展示。这些展示的质量也非常高，以下是其中的亮点：&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Exponential Family Embeddings：一种多类型数据的全新强大的嵌入（embedding）技术，带来了用户使用嵌入技术评估数据的可能性。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Unsupervised Learning for Physical Interaction through Video Prediction：利用机器人的推动动作的数据来规划可能的未来。传统的代理（agent）学习算法严重依赖于监督，而这种类型的方法或许是机器人和类似领域未来的新方法。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Improving Variational Inference with Inverse Autoregressive Flow ：结合了变分推断的最新进展和自动回归网络（autoregressive network）的一些想法，得出更好的编码模型。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;第二天亮点：平台之战和强化学习&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721081&amp;amp;idx=2&amp;amp;sn=fb1b2ba31d256c08e3c93e813deabc73&amp;amp;chksm=871b0f47b06c86510e447bd4c366d1d5c78bbffe3b92903eff2e8f5a6b2df67f5c440dc822e9&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721081&amp;amp;idx=2&amp;amp;sn=fb1b2ba31d256c08e3c93e813deabc73&amp;amp;chksm=871b0f47b06c86510e447bd4c366d1d5c78bbffe3b92903eff2e8f5a6b2df67f5c440dc822e9&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;DeepMind 宣布开源其强化学习平台 DeepMind Lab&lt;/span&gt;&lt;/a&gt;&lt;span&gt;，旨在提供一种打造丰富模拟环境的手段方法，用于人工智能研究。最受欢迎的通用平台，恐怕要数 OpenAI 的 Gym。几个礼拜前 OpenAI 也公布了 Universe 平台, 旨在提供比 Gym 更灵活、具有扩展性的平台。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8qAJibEDtyiaJvlXTAh04GAcAR5UIyqebz8CNruqV5OWer9qXBnFjUN52ugjHKJicxatoPCJ0tQHalg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在会议的第二天，我们仍然可以看到强化学习和深度学习正在继续进步，这些机器学习技术也已经在更加广泛的应用中得到了使用，这里给出几篇比较亮眼的论文：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;最佳论文&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721198&amp;amp;idx=1&amp;amp;sn=accdd701751ab9678285f3cdf073304f&amp;amp;chksm=871b0fd0b06c86c6fa49bbae856898920e26c4456bc02be42a947d23fe2b593110e911bf54da&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721198&amp;amp;idx=1&amp;amp;sn=accdd701751ab9678285f3cdf073304f&amp;amp;chksm=871b0fd0b06c86c6fa49bbae856898920e26c4456bc02be42a947d23fe2b593110e911bf54da&amp;amp;scene=21#wechat_redirect"&gt; Value Iteration Network&lt;/a&gt; 令人印象深刻：该论文的主要创新在于其模型包含了一个可微分的「规划模块（planning module），这让网络可以做出规划并更好地泛化到其它从未见过的领域。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;两篇推进 RNN 的研究： Sequential Neural Models with Stochastic Layers 以及 Phased LSTMs。前者将 状态空间模型（State Space Model）的想法和 RNN 结合起来，充分利用了两个领域的最好的东西。后者将「time gate」添加到了 LSTM 中，这显著改善了针对长序列数据的优化和表现。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;一个来自亚马逊的团队的论文讨论了针对大型库存的贝叶斯间断需求预测（论文：Bayesian Intermittent Demand Forecasting for Large Inventories）。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;K-means 是许多数据科学应用的核心算法。不过，找到好的聚类中心（cluster centers）常常要依赖良好的初始化。Olivier Bachem 在论文《Fast and Provably Good Seedings for k-Means》中表明，他们可以获得良好的 centroid seeds，速度比当前最佳的算法（k-Means++）快几个数量级。更妙的是，他们还有代码，「pip install kmc2」= g2g。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外，第二天的 poster session 展示了 170 多篇论文，这里选出了 3 篇比较有意思的：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Attend, Infer, Repeat: Fast Scene Understanding with Generative Models 提出了一种极具启发性的理解图像中场景的方法。使用贝叶斯和变分推理（Bayesian and Variational Inference），该论文的作者构建了一个可以无需任何监督就能理解图像中的数字、地址和物体类型的模型。这引起了较大的关注，因为他们的模型可以在训练样本之外的分布上进行推理/推导。当然，该模型确实需要一些特别的需求，但它们也提供了新的有趣的研究探索路径。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;DeepMath—Deep Sequence Models for Premise Selection 提出的深度学习方法可以持续不断突破新的领域。一个来自 Google Research 的研究团队（包括 François Chollet and Geoffrey Irving）展示了世界上第一个使用深度学习进行自动理论证明（automated theorem proving）的案例。这项成果有助于加速系统的正确性证明，并可替代对该领域的专家所设计的特征的需求（其与自然语言有类似但也不同的结构）。它们可以自动选择与推理过程中的当前状态相关的操作运算，这个过程可以被扩展到其它领域，是一个非常激动人心的研究方向。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;我们喜欢稳步前进。词嵌入帮助改变了许多自然语言处理任务，去年《Word Movers Distance》提供一种使用它们的嵌入在不同文档进行摘要的方法。对监督任务（比如，文本分类）而言，这可以更进一步。《Supervised Word Mover’s Distance》提出了可以执行仿射变换（affine transformation）和重新调整权重（re-weightings）的方法来提供分类，实现了有效的当前最佳的表现。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;第三天亮点：机器人、汽车&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第三天出现的一个主题是将深度学习融入应用中，特别是机器人和汽车。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个出色的研究来自 Pulkit Agrawal 和他的团队论文 Learning to Poke by Poking: Experiential Learning of Intuitive Physics。他们使用了几百个小时数据（让机器人通过戳的动作来移动物体获得的）搭建了一个系统，机器人可以四处移动物体即使它从未见过这些物体。系统使用了 CNNs 来观察世界，有两个理解相关物理世界的模型。前向模型（forward model），用来预测一个动作/戳的结果，以及一个能够获取当前状况并将之映射到行动中的逆模型（inverse model）。通过一系列令人信服的视频，很明显，机器人已经学会如何相当普遍地四处移动物体。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8qAJibEDtyiaJvlXTAh04GAcJZ2RcSv2icEHtzcJqzSGZsaWBUzs6nhvGx4rDGF2rXicXfm3nrTFLUfg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外，来自奔驰的机器学习工程师 Michael Beaumier 的同事展示了他们最新的目标识别系统。他们一直在研发一种可以识路面小型物体的系统，而这份成功就是该研究的关键创新之处。将场景分割（在 ImageNet 上训练 CNN）和一些来自立体图像的几何信息结合起来，他们搭建了一个贝叶斯模型来识别 100 米之处大小为 5 厘米的物体。这项有助于让自动驾驶汽车更加可能和安全。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;第四天到第六天亮点：似然推理、Dessert 类比（Dessert analogies）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;过去两年，NIPS 有关注将机器学习和概率推论用于粒子物理学的研讨会，今年继续了这一主题。Kyle Cranmer 做了主旨演讲，讨论了许多机器学习进步改善粒子实验分析的领域，包括前馈神经网络、卷积网络以及生成对抗神经网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8qAJibEDtyiaJvlXTAh04GAcVwYMR5KZMBtKo6fT5A0iaU9QGiaJum4giaHnne5JbnpcVWXDHeAUA92Yw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;CERN 实验中描述的 ATLAS 实验的图解模型。每一个阶段都包括显著知识、分析和/或推理来让实验获得成功。Kyle Cranmer 在这份主旨演讲中讨论了如何处理模型的各种不同部分。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;演讲重点关注这样一个问题：当你想要推理模型参数时，但是不能评估似然函数时，你该做什么。当你有了针对数据的生成模型时，你可以用似然推理方法（比如《Approximate Bayesian Computation》），你可以评估一个模型的似然性，而无需一个明确的似然函数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些技巧和想法是许多无监督和生成模型的技术，目前也是一个极为活跃的研究领域。在其主旨演讲和接下来的讨论中，Cranmer 显然正在萌生这样一种想法：这些似然技巧不再是近似的。我们很兴奋，因为这些想法已经对自编码和对抗模型产生了巨大影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;与前三天一样，最后三天的日程安排大致相同，但依然是满满的干货。下面是大会第 4-6 天的演讲和研讨会精彩总结：&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;来自康奈尔大学计算机系的副教授 Killan Weinberger 探讨了深度极深的卷积网络。其团队论文 Deep Networks with Stochastic Depth 展示了训练过程中的所以抽样深度，是比微软团队 ResNet 大赛获奖研究的更好版本。在讨论中，他展示了他们能在 CIFAR-10 上训练一个 1202 层深的网络，并且获得了比 ResNet 更好的模型。最后他提到了 Densely Connected Convolutional Networks，该网络可实现一层与其下面所有层直接连接，达到了 目前的最佳表现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有一个趋势是张量方法及其应用中的最新进展。周六的张量学习 workshop 上，讨论了卷积网络的深度效率：网络设计中和分析中分层张量分解的使用。这个讨论证明了一个卷积网络和分级张量分解之间的一个等价，让我们对网络配置的空间、深度网络的表现力以及增加层数带来的益处有了更多的理论上的理解。此外还有一个成果是将当前很多技术形式化，并明确了未来的研究方向&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一个趋势，大会上出现了一些对话更加直接，探讨实际建议的 workshop。比如 Soumith Chintala 讨论了《How to train a GAN》和 John Schulman 的《The Nuts and Bolts of Deep Reinforcement Learning Research》展示了分享研究细节对于加速研究过程的重要性。这些东西无法呈现在最终的论文中，所以这样的分享非常好。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们仍然还有一些疑问：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;2016 年，记忆网络取得了巨大进步，却为什么没有变得更加流行？&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;会议上女性研究者的数量从原来的 13% 增长到了 15%，NIPS 和其它会议的多样性该怎样才能达到合理的水平？&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;几乎所有的强化学习研究都围着游戏转。什么时候能走出玩游戏？&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;人工智能技术的日益商业化会如何影响研究？开放的趋势会持续下去吗？&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;其它值得关注的论文&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里所总结的一些值得关注的论文是来自微软云与信息服务实验室首席研究软件开发工程师 Paul Mineiro的个人意见，在介绍这些论文之前，他也建议多看一些其他人所总结的推荐论文。他写道：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;看单个人的总结就够了吗？我可不这么想。对于这次会议上都有那些好论文，我觉得我们需要众包让大家一起推荐。我只是一个人，只有两只脚和两只眼睛；加上所有的论文都会首先出现在 arXiv 上，就算我读过我可能也没注意到那是投递给这个会议的。这让这个推荐列表有些怪异，但聊胜于无。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你觉得有什么论文也值得推荐却没有出现在这个列表中，请及时与我们分享！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;通过对抗训练生成文本（Generating Text via Adversarial Training）、用于带有 Gumbel-softmax 分布的离散元素的序列的 GAN（GANS for Sequences of Discrete Elements with the Gumbel-softmax Distribution）、对话模型的对抗式评估（Adversarial Evaluation of Dialogue Models）。短评：我对模拟和评估对话系统的技术很感兴趣。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;构建像人一样学习和思考的机器（Building Machines That Learn and Think Like People）。短评：这个主题演讲非常好，所以我想要深入了解一下论文。这个演讲探索了人类利用大量先验知识的方式，以及我们可以如何将其整合进我们的系统中；其中一些特定的观察结果为我们带来了一些可以执行的研究方向。（这似乎和对话有关，因为这个研究可能能够解释类似「the blorf flazzed the peezul」这样的无意义陈述的伪可理解性（pseudo-intelligibility）。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;跨许多个数量级学习价值（Learning values across many orders of magnitude）。短评：粗略看这可能是关于优化（optimization）的，但在反事实的背景（counterfactual setups）中，这个问题是很普遍的。我可是很喜欢把规模不变性用作一个有用的先验知识（scale invariance as a useful prior）。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;用于神经结构预测的回报增强最大似然（Reward Augmented Maximum Likelihood for Neural Structured Prediction）短评：这可以被看作是另一种使用世界的模型来转移强化学习的样本复杂性的方法。（比如：如果编辑距离（edit distance）只是该回报的初始模型呢？&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;安全高效的离策略强化学习（Safe and Efficient Off-Policy Reinforcement Learning）。短评：这是一个重要的设置。这种特别的调整让人联想到了之前这一领域提出的估计器（estimator，参阅论文《Learning from Logged Implicit Exploration Data》）；但尽管如此，这还是很有意思。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面这篇论文不是来自 NIPS 2016，但 Mineiro 表示：「我在一次喝咖啡的休息时间发现了它，真的非常赞！」：理解深度学习需要重新思考泛化（Understanding deep learning requires rethinking generalization）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;短评：当像素被重新排列或甚至完全随机时，卷积神经网络也可以理解标准的图像训练集。当然，在这种情况下泛化能力很差，但是这表明：和「局部像素统计组合（local pixel statistics composition）」架构相比，它们并没有人们认为的那样灵活。所以为什么它们的效果那么好呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;NIPS 2016 趣闻&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;LeCun 的蛋糕&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Yann LeCun 以题为《预测学习（Predictive Learning）》的演讲开启了主会议。这是一个高水平的演讲，他认为我们都应该真正多思考一下无监督学习。为了明确他的意思，他又拿出了自己蛋糕的比喻。他展示了一张蛋糕图片，把监督学习和强化学习分别比作是蛋糕的糖霜和樱桃，而无监督学习则就是蛋糕本身。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8qAJibEDtyiaJvlXTAh04GAcWO68JRjibEybbPN42JOblHtAmlH5Su8xIxChoAuO60ic15IXCVITxLIg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这个演讲之后，LeCun 的蛋糕火了！并且开始出现在这一周的其它 NIPS 幻灯片中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;LeCun 的主要观点是：许多我们通常关心的问题都回避了人工智能最需要的重要部分（即蛋糕本身）——（LeCun 认为）无监督学习。在支持这一观点的论据中，最常见的是「大多数数据都没有标签」（所以为了使用这些数据，我们需要无监督学习）和「人类基本上就是靠无监督学习的」。所以如果我们想要实现人工智能的进一步发展，我们真的需要长期努力地思考所谓的「无监督」的意义。LeCun 提出了一个看待无监督学习的新角度，他称之为「预测学习（predictive learning）」。对此他的描述是：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;从任何可用的信息中预测过去、现在和未来的规律的任何部分。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这听起来似乎有点定义不明。不过他还给出了几个预测学习的案例，比如说根据图像的一半预测另一半、以及 GAN 上面的所有工作。不过无监督学习要比监督学习难得多，LeCun 的蛋糕能够火出成效吸引更多人加入吗？让我们拭目以待。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Jürgen Schmidhuber 起波澜&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;LSTM 发明人、深度学习元老 Jürgen Schmidhuber 一直是一个颇有争议的人（参阅《&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720788&amp;amp;idx=2&amp;amp;sn=f71291991911e6949e0302da05ea00c4&amp;amp;chksm=871b0e6ab06c877c7abeb6763763ef870d4419c53fb23830fa611be7432e2a3539943b7aad5f&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720788&amp;amp;idx=2&amp;amp;sn=f71291991911e6949e0302da05ea00c4&amp;amp;chksm=871b0e6ab06c877c7abeb6763763ef870d4419c53fb23830fa611be7432e2a3539943b7aad5f&amp;amp;scene=21#wechat_redirect"&gt;深度 | LSTM 之父 Jürgen Schmidhuber 为何名声不显？&lt;/a&gt;》），在这次会议上，他又做出了一些有争议的事。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 Ian Goodfellow 的演讲《Generative Adversarial Networks》进行的过程中，Schmidhuber 走向麦克风打断了他。很显然，有些人对这样的行为感到不爽，MetaMind 资深研究科学家 Stephen Merity 就发了一条推文批评这样的行为：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8qAJibEDtyiaJvlXTAh04GAcMDMSZDmjkVk279fc0A41cdDHboRhByL5038tlFIxD71pMqUssj4JEg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;内容：Schmidhuber 打断了 GAN tutorial，这是在盗窃听众和学习者的时间。我不管你是谁，都不能做这种事。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;NIPS 2016 资源&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在主会议网站上，我们可以看到大量的视频资源，这里就不再一一列出了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：https://nips.cc/Conferences/2016/Schedule&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面列出的一些是在网站上没有列出的或无法获取的幻灯片，主要是在 Twitter 上发现的：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;Peter Abbeel, “Tutorial: Deep Reinforcement Learning through Policy Optimization” - http://people.eecs.berkeley.edu/~pabbeel/nips-tutorial-policy-optimization-Schulman-Abbeel.pdf&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Yoshua Bengio, “Towards a Biologically Plausible Model of Deep Learning” - http://www.iro.umontreal.ca/~bengioy/talks/Brains+Bits-NIPS2016Workshop.pptx.pdf&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Mathieu Blondel, “Higher-order Factorization Machines” - http://www.mblondel.org/talks/mblondel-stair-2016-09.pdf&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Kyle Cramer (keynote), “Machine Learning &amp;amp; Likelihood Free Inference in Particle Physics” - https://figshare.com/articles/NIPS_2016_Keynote_Machine_Learning_Likelihood_Free_Inference_in_Particle_Physics/4291565&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Xavier Giro, “Hierarchical Object Detection with Deep Reinforcement Learning” - http://www.slideshare.net/xavigiro/hierarchical-object-detection-with-deep-reinforcement-learning&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Ian Goodfellow, “Adversarial Approaches to Bayesian Learning and Bayesian Approaches to Adversarial Robustness” - http://www.iangoodfellow.com/slides/2016-12-10-bayes.pdf&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Ian Goodfellow, “Tutorial: Introduction to Generative Adversarial Networks” - http://www.iangoodfellow.com/slides/2016-12-9-gans.pdf&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Neil Lawrence, “Personalized Health: Challenges in Data Science” - http://inverseprobability.com/talks/lawrence-ml4hc16b/personalized-health-challenges-in-data-science.html&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Yann LeCun, “Energy-Based GANs &amp;amp; other Adversarial things” - https://drive.google.com/file/d/0BxKBnD5y2M8NbzBUbXRwUDBZOVU/view&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Yann LeCun (keynote), “Predictive Learning” - https://drive.google.com/file/d/0BxKBnD5y2M8NREZod0tVdW5FLTQ/view&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Valerio Maggio, “Deep Learning for Rain and Lightning Nowcasting” - https://speakerdeck.com/valeriomaggio/deep-learning-for-rain-and-lightning-nowcasting-at-nips2016&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Sara Magliacane, “Joint causal inference on observational and experimental data” - http://www.slideshare.net/SaraMagliacane/talk-joint-causal-inference-on-observational-and-experimental-data-nips-2016-what-if-workshop-poster&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Andrew Ng, “Nuts and Bolts of Building Applications using Deep Learning” - https://www.dropbox.com/s/dyjdq1prjbs8pmc/NIPS2016%20-%20Pages%202-6%20(1).pdf&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;John Schulman, “The Nuts and Bolts of Deep RL Research” - http://rll.berkeley.edu/deeprlcourse/docs/nuts-and-bolts.pdf&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Dustin Tran, “Tutorial: Variational Inference: Foundations and Modern Methods” - http://www.cs.columbia.edu/~blei/talks/2016_NIPS_VI_tutorial.pdf&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Jenn Wortman Vaughan, “Crowdsourcing: Beyond Label Generation” - http://www.jennwv.com/projects/crowdtutorial/crowdslides.pdf&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Reza Zedah, “FusionNet: 3D Object Classification Using Multiple Data Representations” - http://matroid.com/papers/fusionnet_slides.pdf&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，下面整理了机器之心发过的 NIPS 2016 相关文章：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721081&amp;amp;idx=1&amp;amp;sn=d557968703d4af879b5cf6461069dacd&amp;amp;chksm=871b0f47b06c865185865fcd5ef92af7726e84ae9e689b7ced9986a08c9fe3113df296a8469a&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721081&amp;amp;idx=1&amp;amp;sn=d557968703d4af879b5cf6461069dacd&amp;amp;chksm=871b0f47b06c865185865fcd5ef92af7726e84ae9e689b7ced9986a08c9fe3113df296a8469a&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;独家 | 吴恩达 NIPS 2016 演讲现场直击：如何使用深度学习开发人工智能应用？&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721198&amp;amp;idx=1&amp;amp;sn=accdd701751ab9678285f3cdf073304f&amp;amp;chksm=871b0fd0b06c86c6fa49bbae856898920e26c4456bc02be42a947d23fe2b593110e911bf54da&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721198&amp;amp;idx=1&amp;amp;sn=accdd701751ab9678285f3cdf073304f&amp;amp;chksm=871b0fd0b06c86c6fa49bbae856898920e26c4456bc02be42a947d23fe2b593110e911bf54da&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;独家 | 机器之心对话 NIPS 2016 最佳论文作者：如何打造新型强化学习观？&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721284&amp;amp;idx=1&amp;amp;sn=427e7f45c8253ab22a3960978409f5d1&amp;amp;chksm=871b087ab06c816c424ad03810be3e1b3aa9d6e99a5f325047796f110d178a07736f667d1a10&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721284&amp;amp;idx=1&amp;amp;sn=427e7f45c8253ab22a3960978409f5d1&amp;amp;chksm=871b087ab06c816c424ad03810be3e1b3aa9d6e99a5f325047796f110d178a07736f667d1a10&amp;amp;scene=21#wechat_redirect"&gt;独家 | GAN 之父 NIPS 2016 演讲现场直击：全方位解读生成对抗网络的原理及未来&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721325&amp;amp;idx=4&amp;amp;sn=d570f04d737d09c1b1cebd962755af3f&amp;amp;chksm=871b0853b06c8145985f8c2c5ac7445118f18ce35532c0389b0e5ec24a7a1c4b841fe81280de&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721325&amp;amp;idx=4&amp;amp;sn=d570f04d737d09c1b1cebd962755af3f&amp;amp;chksm=871b0853b06c8145985f8c2c5ac7445118f18ce35532c0389b0e5ec24a7a1c4b841fe81280de&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;资源 | Bengio 和 LeCun 在 NIPS 2016 上的演讲&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718527&amp;amp;idx=2&amp;amp;sn=8d054db2eca7a0b25190a6cc050fc1d7&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718527&amp;amp;idx=2&amp;amp;sn=8d054db2eca7a0b25190a6cc050fc1d7&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;学界 | NIPS 2016 公布 571 篇接收论文&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721033&amp;amp;idx=2&amp;amp;sn=d0d143e72cf4a637a617be356008b323&amp;amp;chksm=871b0f77b06c86615ed6a59ede1bee6cbff68b6ec08fb9b300e347d9c34b931aabdc3d0fee4e&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721033&amp;amp;idx=2&amp;amp;sn=d0d143e72cf4a637a617be356008b323&amp;amp;chksm=871b0f77b06c86615ed6a59ede1bee6cbff68b6ec08fb9b300e347d9c34b931aabdc3d0fee4e&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;学界 | NIPS 2016 论文 SpotlightVideo 精选，三分钟了解一项最新研究进展&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721081&amp;amp;idx=3&amp;amp;sn=111d844d50c98582695d04fa2b252c89&amp;amp;chksm=871b0f47b06c86514ac934c44fe4df92f5d4209f209b94b4c89d1f138492dbaf7e47479803a3&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721081&amp;amp;idx=3&amp;amp;sn=111d844d50c98582695d04fa2b252c89&amp;amp;chksm=871b0f47b06c86514ac934c44fe4df92f5d4209f209b94b4c89d1f138492dbaf7e47479803a3&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;学界 | NIPS 2016 现场：谷歌发布 28 篇机器学习论文&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720969&amp;amp;idx=2&amp;amp;sn=d1fae404486906125e01b5def7e26d94&amp;amp;chksm=871b0eb7b06c87a1d3e7d0b29e8c8f9e4c86f4949d04b0485df1b45823555a6c88a25ccf4dc4&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720969&amp;amp;idx=2&amp;amp;sn=d1fae404486906125e01b5def7e26d94&amp;amp;chksm=871b0eb7b06c87a1d3e7d0b29e8c8f9e4c86f4949d04b0485df1b45823555a6c88a25ccf4dc4&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;学界 | DeepMind NIPS 2016 论文盘点（Part1）：强化学习正大步向前&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721102&amp;amp;idx=2&amp;amp;sn=cbc44a149457d31ed9a8bbe825f09378&amp;amp;chksm=871b0f30b06c8626bb94cbd7a08fd4a5c8bec747082f49280fbd27e9c87c965de983a279796c&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721102&amp;amp;idx=2&amp;amp;sn=cbc44a149457d31ed9a8bbe825f09378&amp;amp;chksm=871b0f30b06c8626bb94cbd7a08fd4a5c8bec747082f49280fbd27e9c87c965de983a279796c&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;学界 | DeepMind NIPS 2016 论文盘点（Part2）：无监督学习的新进展&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721081&amp;amp;idx=4&amp;amp;sn=af93b221818ff9f564b372de5fc1958f&amp;amp;chksm=871b0f47b06c8651744e4b2819322f4026b248f4474f619c7248f604dafe8490405d70d3d1f3&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721081&amp;amp;idx=4&amp;amp;sn=af93b221818ff9f564b372de5fc1958f&amp;amp;chksm=871b0f47b06c8651744e4b2819322f4026b248f4474f619c7248f604dafe8490405d70d3d1f3&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;业界 | NIPS 2016 现场：LeCun 联同英伟达，推深度学习教学工具包&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721198&amp;amp;idx=4&amp;amp;sn=b2f6412538b2458116cd40f53bcdc23b&amp;amp;chksm=871b0fd0b06c86c6866c3e682aa9a15187154a67ae4b7df3d319cc2233fb5761c53da45abed1&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721198&amp;amp;idx=4&amp;amp;sn=b2f6412538b2458116cd40f53bcdc23b&amp;amp;chksm=871b0fd0b06c86c6866c3e682aa9a15187154a67ae4b7df3d319cc2233fb5761c53da45abed1&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;业界 | 波士顿动力最新机器人亮相 NIPS 2016，但还未用到机器学习&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;参考资料&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;http://beamandrew.github.io/deeplearning/2016/12/12/nips-2016.html&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;http://www.machinedlearnings.com/2016/12/nips-2016-reflections.html&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;https://medium.com/search?q=nips%202016&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心整理文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 13 Dec 2016 15:48:27 +0800</pubDate>
    </item>
  </channel>
</rss>
