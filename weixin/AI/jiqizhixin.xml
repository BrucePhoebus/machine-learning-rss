<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>资源 | 如何自学数据科学？这21个课程能帮你入门数据科学过程</title>
      <link>http://www.iwgc.cn/link/4524079</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;作者David Venturi&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀、侯韵楚&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Class Central 的数据顾问（Data Consultant）David Venturi 近日分享了其对于自学数据科学的课程推荐，本文主要推荐了数据科学过程（data science process）的入门课程。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一年前，我从加拿大顶级的计算机科学课程之一退出，并利用在线资源开始创建属于自己的数据科学硕士课程。我意识到，通过 edX 、Coursera 以及 Udacity，我只需用成本的一小部分便可以更迅速、有效地学到我所需要的一切。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这门课程差不多要完成了。我修读过许多数据科学相关的课程，并了解更多的课程。我知道其中有什么选择，也清楚成为数据分析师或数据科学家所需要的技能。我在几个月之前开始着手创建一个能够为数据科学的每个主题推荐最佳课程的评审驱动指南。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关于系列的第一个指南，我为初学级的数据科学家推荐了编码类指南，然后是概率与统计类的指南：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;编码类：https://medium.freecodecamp.com/if-you-want-to-learn-data-science-start-with-one-of-these-programming-classes-fb694ffe780c#.42hhzxopw&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;概率与统计类：https://medium.freecodecamp.com/if-you-want-to-learn-data-science-take-a-few-of-these-statistics-classes-9bbabab098b9#.p7pac546r&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;现在来介绍数据科学&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于数据科学课程所介绍的一些内容若有不确定的地方也不用担心，稍后会做出解释。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了这本指南，我花了 10 多个小时搜集截至 2017 年 1 月提供的数据科学课程的每一个在线介绍，从它们的教学大纲和评论中提取关键信息并编辑评分。为了完成这个任务，我使用了开源的 Class Central 社区和它的具有数千课程评分与评论的数据库作为辅助。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Class Central 的主页：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;www.class-central.com&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自 2011 年以来，Class Central 的创始人 Dhawal Shah 一直比世界上任何人都密切关注在线课程，他亲自帮我列出了这份资源清单。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;我们如何选择课程&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;每门课程必须符合三个标准：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;它所教授的必须是数据科学过程（data science process），稍后会对其做出解释。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;它必须按需或每几个月来提供课程。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;它必须是一个交互式的在线课程，所以这里没有书或只读教程。虽然存在多种可行的学习方法，但本指南只专注于课程。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们认为这个指南涵盖了所有符合上述标准的重要课程。由于 Udemy 中存在数百个课程，所以仅选择了评论最多且评分最高的课程。但我们总会有可能错过一些优秀的课程，所以如果发现我们有所遗漏，请在评论区告知。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;我们如何评估课程&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了计算每个课程的加权平均评分，我们汇集了 Class Central 和其他评论网站的平均评分和评论数。同时我们阅读文本评论，以该反馈作为数字评分的补充。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们基于两个因素做出主观的大纲判断内容：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 数据科学过程的覆盖。课程是否略过了某些科目？它是否覆盖了某些科目过多的细节？请参阅下一部分来了解此过程的具体内容。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 通用数据科学工具的使用。课程是使用普遍的编程语言（如 Python 和/或 R）教授的吗？这些都不是必要的，但在大多数情况下有帮助，所以对这些课程稍作优先考虑。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibkgzQLGMwFy1N0wOZ7kQ0DsAtugX00C5SWLA23ezTmCWKctL2GF9quickpKh0ludiajdiak79hxhxpw/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Python 和 R 是数据科学中使用最普遍的两种编程语言&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;什么是数据科学过程（data science process）？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;什么是数据科学？数据科学家做什么工作？这些是数据科学课程介绍所应回答的基本问题类型。哈佛大学教授 Joe Blitzstein 和 Hanspeter Pfister 的以下信息对典型的数据科学过程进行了概述，这会帮助我们回答这些问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibkgzQLGMwFy1N0wOZ7kQ0DIwD1jCxBvlbXZh1bE1faIPVUpa2fNrmib3YCXIymN1tsSkaZNqE8Ffg/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;来自 Opera Solution 的可视化&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们对于数据科学课程介绍的目标是熟悉数据科学过程，并不想太深入地涵盖过程的具体方面，因此便停留在该标题的「介绍/入门（intro to）」部分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于每一方面，理想课程应该解释过程框架内的关键概念、介绍常用工具并提供一些示例（动手实践更佳）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们只是在寻找课程介绍，因此本指南不包括约翰·霍普金斯大学的 Coursera 数据科学专业（Data Science Specialization）或 Udacity 的数据分析师纳米学位（Data Analyst Nanodegree）等专业。这些课程的汇编并未包含这个系列的目的：为每个科目找到包括数据科学教育在内的最佳个人课程。本系列文章的最后三个指南将详细介绍数据科学过程的每个方面。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;基本编码、统计以及概率所需的经验&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面列出的课程需要基本的编程、统计和概率经验。这个要求可以理解，因为有些前沿科目通常包含几门专项课程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种经验可以从我们所推荐的数据科学职业指南的前两篇文章（编程、统计）中获得。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;我们选择的数据科学最佳入门课程是：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据科学 A-Z™：包含实际数据科学练习（Data Science A-Z™: Real-Life Data Science Exercises Included）（Kirill Eremenko/Udemy）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://www.udemy.com/datascience&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在我们量化评估的 20 个数据科学课程中，Kirill Eremenko 在 Udemy 上的 Data Science A-Z™ 在数据科学过程的广度和深度上都是确定无疑的赢家。在其 3071 个评价中，其获得了 4.5 的加权平均评分，这个课程是目前评分最高且评论数最多的课程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该课程概述了完整的数据科学过程并提供了实际的案例。而且该课程的长度为 21 小时，是一个非常合适的长度。评价者普遍很喜欢该导师的讲解以及课程的内容组织。该课程的价格会随 Udemy 的折扣政策而发生改变，你甚至有可能只需 10 美元就能学习该课程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管它并不检查我们的「常用数据科学工具使用」工具箱，但非 Python/R 工具选择（gretl、Tableau、Excel）在这一背景中得到了有效的应用。Eremenko 解释了选择 gretl 的原因（注：gretl 是一个统计软件包），尽管这个解释也适用于其使用的所有工具：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;使用 gretl，我们可以实现与使用 R 和 Python 一样的建模，但我们却不需要编写代码。这是很重要的。你们一些人可能已经对 R 非常了解了，但另一些人却可能对 R 一无所知。我的目标是让你了解如何构建一个稳健的模型以及给你一个你可以应用你所选择的任何工具的框架。gretl 将能帮助我们避免陷入写代码的麻烦中。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一位著名的评论者指出：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Kirill 是我在网上找到的最好的老师。他使用实际案例并会解释常见的问题，让你能对该课程有更深入的理解。他也提供了很多关于作为一位数据科学家意味着什么的见解，从如何利用不足分的数据一直到如何将你的成果展示给高管。我强烈推荐初学者学生到中等的数据分析师都学习这门课程。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;一个非常棒的以 Python 为中心的入门介绍&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据分析入门（Intro to Data Analysis（Udacity））：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://www.class-central.com/mooc/4937/udacity-intro-to-data-analysis&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Udacity 的 Intro to Data Analysis 是一个相对较新的课程，该课程也是 Udacity 受欢迎的数据分析师纳米学位（Nanodegree）课程中的一部分。它包含了清晰的使用 Python 的数据科学过程，尽管其在建模方面还有所欠缺。该课程估计需要 36 个小时的时间（每周 6 小时，一共 6 周）。尽管在我的经历中它要短一些。这个课程有一个 5 星的评价。它是免费的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该课程的视频制作精良，其导师 Caroline Buckey 的授课清晰明了。课程中大量的编程测验能够帮助强化在视频中学到的概念。学生肯定能够获得新的或提升过得 NumPy 和 Pandas 技能（NumPy 和 Pandas 都是流行的 Python 库）。其最后的项目（其会在纳米学位中得到评估和评价，但并不在这个免费的单独课程中）可以作为一个很好的额外补充。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;一个很不错但没有评价数据的课程&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据科学基础（Data Science Fundamentals (Big Data University)）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://bigdatauniversity.com/learn/data-science/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Data Science Fundamentals 是由 IBM 的 Big Data University 所提供了一个 4 个课程的系列课程。这四门课程分别是：Data Science 101、Data Science Methodology、Data Science Hands-on with Open Source Tools 和 R 101。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;数据科学 101（Data Science 101）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://bigdatauniversity.com/courses/data-science-101/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据科学方法（Data Science Methodology）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://bigdatauniversity.com/courses/data-science-methodology-2/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使用开源工具上手数据科学（Data Science Hands-on with Open Source Tools）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://bigdatauniversity.com/courses/data-science-hands-open-source-tools/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;R 101：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://bigdatauniversity.com/courses/r-101/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个系列课程包含了使用 Python 和 R 的完整数据过程，此外，这里还有上手的实验环境。这些课程有极大的生产价值。根据你是否选修最后的 R 101 课程（这个课程对于本指南的目的而言并不是必需的），这个系列课程的时间长度为 13-18 小时。不幸的是，在主要的网站上没有关于该课程的评价数据可供我们分析，所以我们不能基于评价做出推荐，不过这个课程是免费的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;比赛&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们的第一名选择的是有 3068 个评论给出了加权平均分 4.5 的课程。下面让我们看看其它选择，按降序排序。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你打算通过 R 语言入门数据科学，你还能在下面找到一些以 R 为重点的课程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据科学入门（Introduction to Data Science (Data Hawk Tech/Udemy）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://www.udemy.com/learn-data-science&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该课程覆盖了数据科学的全过程，尽管深度有限。该课程相当简短（仅有三小时内容）。其简要地覆盖了 R 和 Python。它有 62 个评分，获得了 4.4 的加权平均分。价格依 Udemy 的折扣而波动。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;应用数据科学：入门（Applied Data Science: An Introduction（Syracuse University/Open Education by Blackboard））&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://www.class-central.com/mooc/1806/open-education-by-blackboard-applied-data-science-an-introduction&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该课程覆盖了数据科学的全过程，但并不均匀。其重点关注了基础统计学和 R 语言。对于本指南的目的而言，应用太多，对数据科学过程的关注不够。网络课程体验有所脱节。它获得了 6 个评论，得到了 4.33 的加权平均分。免费。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据科学入门（Introduction To Data Science (Nina Zumel &amp;amp; John Mount/Udemy)）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://www.udemy.com/introduction-to-data-science&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本课程仅覆盖了部分过程，但在数据准备和建模方面有很好的深度。6 小时内容的长度也还不错。使用 R 语言。它获得了 101 个评论，得到了 4.3 的加权平均分。价格依 Udemy 的折扣而波动。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使用 Python 的应用数据科学（Applied Data Science with Python (V2 Maestros/Udemy)）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://www.udemy.com/applied-data-science-with-python&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该课程覆盖了数据科学的全过程，并在该过程的每个方面都有很好的深度覆盖。长度不错（8.5 小时内容长度）。使用 Python。它获得了 92 个评论，得到了 4.3 的加权平均分。价格依 Udemy 的折扣而波动。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibkgzQLGMwFy1N0wOZ7kQ0DUfiakNRuJEjF6wOicViaZ7DwQWic9dByVVicw0P735EPkGBN640rbvrb26Q/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;V2 Maestros 有两个 Applied Data Science 课程版本，一个针对 Python，一个针对 R&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Python 版：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://www.udemy.com/applied-data-science-with-python&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;R 版：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://www.udemy.com/applied-data-science-with-r&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;想成为数据科学家（Want to be a Data Scientist?）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://www.udemy.com/want-to-be-a-data-scientist&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该课程覆盖了数据科学的全过程，尽管覆盖深度有限。内容相当短，仅有 3 小时。有限的工具覆盖。它获得了 790 个评论，得到了 4.3 的加权平均分。价格依 Udemy 的折扣而波动。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据到见解：数据分析入门（Data to Insight: an Introduction to Data Analysis (University of Auckland/FutureLearn)）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://www.class-central.com/mooc/2129/futurelearn-data-to-insight-an-introduction-to-data-analysis&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;覆盖的广度不清楚。声称重点是数据探索、发现和可视化。并不按需提供。内容长度为 24 小时——分成 8 周，每周 3 小时。它获得了 2 个评论，得到了 4 的加权平均分。课程免费，也提供付费的认证。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据科学方向（Data Science Orientation (Microsoft/edX)）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://www.class-central.com/mooc/6405/edx-data-science-orientation&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该课程使用 Excel。不过鉴于该课程是由微软提供的，所以也能理解。课程长度为 12-24 小时（6 周，每周 2-4 小时）。它获得了 40 个评论，得到了 3.95 的加权平均分。课程免费，也提供 25 美元的付费认证。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据科学基础（Data Science Essentials (Microsoft/edX)）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://www.class-central.com/mooc/3954/edx-dat203x-data-science-and-machine-learning-essentials&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该课程覆盖了数据科学的全过程，而且在每个方面都有不错的深度。覆盖了 R、Python 和 Azure ML（这是一个微软的机器学习平台）。有很多 1 星评价是因为该课程选择了 Azure ML 且导师教得不怎么好。该课程长度为 18-24 小时（为期 6 周，每周 3-4 小时）。它获得了 67 个评论，得到了 3.81 的加权平均分。课程免费，也提供 49 美元的付费认证。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibkgzQLGMwFy1N0wOZ7kQ0DfmdkBuyzKKcAAsf79eTfhmSC2Z19SubA0pBupsgEUqg0S8fwjEXaIw/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以上两个课程来自微软在 edX 上的数据科学专业课程证书（Professional Program Certificate in Data Science）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://www.edx.org/microsoft-professional-program-certficate-data-science&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使用 R 的应用数据科学（Applied Data Science with R (V2 Maestros/Udemy)）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://www.udemy.com/applied-data-science-with-r&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;前面也提到了该课程的 Python 版本。该课程覆盖了数据科学的全过程，并在该过程的每个方面都有很好的深度覆盖。长度不错（11 小时内容长度）。使用 R。它获得了 212 个评论，得到了 3.8 的加权平均分。价格依 Udemy 的折扣而波动。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据科学入门（Intro to Data Science (Udacity)）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://www.class-central.com/mooc/1480/udacity-intro-to-data-science&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;部分过程覆盖，但在其选择的主题上都有很好的深度。缺少探索方面，尽管 Udacity 在探索数据分析（EDA）方面有一个很好的全覆盖的课程：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://www.class-central.com/mooc/1478/udacity-data-analysis-with-r&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;声称有 48 小时长度（为期 8 周，每周 6 小时），但我感觉要短一些。一些评论认为其缺乏高级内容。感觉组织不太好，使用 Python。它获得了 18 个评论，得到了 3.61 的加权平均分。免费。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibkgzQLGMwFy1N0wOZ7kQ0DW4iat37VB7f4m1evrl9MeO24UDuwNQByRGzm7zE7yiaZRLePQnOHmlibA/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使用 Python 的数据科学入门（Introduction to Data Science in Python (University of Michigan/Coursera)）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://www.coursera.org/learn/python-data-analysis&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;部分过程覆盖。没有建模和可视化，尽管密歇根大学在 Coursera 上教授的 Applied Data Science with Python Specialization：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://www.coursera.org/specializations/data-science-python&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;课程的 #2 和 #3 覆盖了这些方面。但那对于本指南的目标的深度就太深了。使用 Python。时长 4 周。它获得了 15 个评论，得到了 3.6 的加权平均分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据驱动的决策（Data-driven Decision Making (PwC/Coursera)）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://www.coursera.org/learn/decision-making&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;部分覆盖（缺乏建模），重点关注商业应用。介绍了许多工具，包括 R、Python、Excel、SAS 和 Tableau。长度 4 周。它获得了 2 个评论，得到了 3.5 的加权平均分。有免费和付费的选择。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据科学速成课程（A Crash Course in Data Science (Johns Hopkins University/Coursera)）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://www.coursera.org/learn/data-science-course&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个对于全过程的极简概览。对于本指南来说实在太简单了。时长 2 小时，它获得了 19 个评论，得到了 3.4 的加权平均分。有免费和付费的选择。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据科学家工具箱（The Data Scientist』s Toolbox (Johns Hopkins University/Coursera)）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://www.coursera.org/learn/data-scientists-tools&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个对于全过程的极简概览。可看作是约翰·霍普金斯大学 Data Science Specialization 课程：https://www.coursera.org/specializations/jhu-data-science&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;的基础课程。声称有 4-16 小时内容（4 周，每周 1 到 4 小时），但有一位评论者说这个课程可以在 2 小时内学完。它获得了 182 个评论，得到了 3.22 的加权平均分。有免费和付费的选择。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据管理和可视化（Data Management and Visualization (Wesleyan University/Coursera)）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://www.coursera.org/learn/data-visualization&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;部分覆盖（缺乏建模），长度 4 周。有很好的生产价值。使用 Python 和 SAS。它获得了 6 个评论，得到了 2.67 的加权平均分。有免费和付费的选择。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面的课程截至 2017 年 1 月还没有评价。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibkgzQLGMwFy1N0wOZ7kQ0Dv2qgRe9N7nE5XDyc0zbLicdeDia2VWyTeb5KIdxTjARsXynic7Mu07acQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;CS 109 数据科学（CS109 Data Science (Harvard University)）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;http://cs109.github.io/2015/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;全过程覆盖，深度也很棒（对本系列来说也许太过深度了）。一个 12 周全时长的研究生课程。课程方向很难，因为其并不是为在线使用而设计的。这是哈佛大学课程的实际录像。上面的数据科学过程信息图就来自这个课程。使用 Python。免费。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;用于商业的数据分析入门（Introduction to Data Analytics for Business (University of Colorado Boulder/Coursera)）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://www.coursera.org/learn/data-analytics-business&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;部分过程覆盖（缺乏建模和可视化方面），重点关注商业。在这个课程中，数据科学过程被称为「信息-行动价值链（Information-Action Value chain）」。时长 4 周。描述了多种工具，尽管仅深度覆盖了 SQL。有免费和付费的选择。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据科学入门（Introduction to Data Science (Lynda)）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://www.lynda.com/Big-Data-tutorials/Introduction-Data-Science/420305-2.html&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;完全过程覆盖，尽管覆盖深度有限。相当短，仅有 3 小时内容。介绍了 R 和 Python。费用由 Lynda 订阅确定。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文链接：https://medium.freecodecamp.com/i-ranked-all-the-best-data-science-intro-courses-based-on-thousands-of-data-points-db5dc7e3eb8e#.4xypnelbl&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 30 Jan 2017 13:38:10 +0800</pubDate>
    </item>
    <item>
      <title>观点 | 人工智能的开源模式已经过时，我们需要新的开源模式</title>
      <link>http://www.iwgc.cn/link/4524080</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Techcrunch&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：朱思颖、Jane W&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibkgzQLGMwFy1N0wOZ7kQ0DW2icpAtPygV56ibRibwI2kqVCuKOvlL3mYjzib05d1Bibqftu5E2mkG729g/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能是一个大的领域，并且领域范围还在继续扩大。有机器学习相关经验的企业期望在人工智能的技术上占领先机。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;还没有构建出自己机器学习业务专长的企业正急于理解和策划自己的机器学习和人工智能战略。在当下人工智能的浪潮中，困惑、妄想、落后的风险以及谷歌、Facebook、百度和微软这些公司做了大量的开源（如 TensorFlow、BigSur、Torch、SciKit、Caffe、CNTK、DMTK、Deeplearning4j、H2O、Mahout、MLLib、NuPIC、OpenNN 等项目）提供进军人工智能和机器学习的一个显而易见的方式，尤其是对人工智能技术行业之外的企业而言。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;找到开源项目、下载、安装... 这个过程应该是很容易。但并不是如大家所想的那般容易。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前的开源模式（Open Source model）是过时的且不能满足由人工智能驱动或影响的系统所主导的环境下软件之间的共享。在人工智能驱动的系统所主导的环境中，理论上用户可以在一天之内与成千上万的人工智能引擎交互。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;仅靠人工智能和机器学习的先驱们分享他们的代码是远远不够的。工业界和整个世界需要一个新的开源模式，这个新开源模式能够实现人工智能和机器学习所训练的引擎自身同数据、特征以及真实环境下的表现细节一同开源。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;目前的开源模式能力不足并且已过时&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由人工智能和机器学习驱动（作用）的系统与运用开源组件构建的其它软件是不同的。运用开源组件构建的软件仍然具备「确定性」特质，例如软件的设计和编写都是为了保证每次按照相同的方式运行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能或者机器学习系统（尤其是人工智能系统）并不一定具备这样的「确定性」表现。在应用于和学习新情境（新环境或者新用户）时，这些系统能够改变自己的行为表现。本质上说，当人工智能系统应用于真实世界时，人工智能系统的构建者就失去对所构建系统的控制。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然，创建者可以在学习框架中构建制衡的机制，然而，即使是在人工智能系统所设定的限制下，仍然还会有大量不同的解释。与此同时，面对一个由人工智能所包围的世界的更大挑战来自已证实的冲突——这些限制中人的作用因素。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最近的一个对梅塞德斯主席 von Hugo 报道中引用了其所说「梅塞德斯的无人驾驶汽车将会优先保护车上乘客而不是行人」，尽管事后公司表明报告中对 von Hugo 的引用有误，但仍然揭露出一个根本性问题——资本主义将如何作用设置于人工智能中的限制。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibkgzQLGMwFy1N0wOZ7kQ0DqJuOwMT2y5hN8XpPsl8njG4tMK1q92N0Rr6FYvXZsEibRcQj266tL0g/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;资本主义和人工智能的道德伦理&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果一个企业的目的是实现盈利，在产品和服务开始进入市场前所需要的时间是否表明基于人工智能的经验可以作为一个附加值、差异化体验来要求顾客为这项技术额外付费？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这种情况下，原意并且具备差异化体验付费能力的用户将会获得比普通用户更多的好处。因为企业将会尝试和收回在人工智能上的投入成本，这项技术将只限于给能负担这项技术的用户群体使用。这将会导致人工智能系统的限制设置有利于（保护或者提供优先权）那些能够负担得起的用户。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外一个担忧是法律和政策方面的问题——谁将对人工智能或者机器学习驱动的产品故障（次优）行为负责。由用户、服务提供商、数据科学家或者人工智能引擎负责？这个责任（过失）怎么确立？要回答这些问题需要对创建和使用人工智能以及机器学习的一系列过程有清晰的描述和跟踪。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;人工智能到人工智能的交互&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibkgzQLGMwFy1N0wOZ7kQ0DnibLDjXbKrxMBAC7yh5XpxHKjkeibJ23tNxzB8zQK0dnWqwibLH053jCA/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;一张三维渲染图：一个机器人尝试解决木块拼图问题&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能-人工智能冲突&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;考虑到人工智能驱动的产品的不确定特质，那么在之前未查看的交互过程中人工智能驱动的产品将会和能够如何表现，人工智能驱动的产品在 2 个或多个不同用户的交互使用场景下，这个问题更加凸显出来。例如，如果两辆无人驾驶汽车是由两个独立的人工智能引擎（由不同的公司通过不同的训练数据和特征、相互独立的偏差和情景设置所构建）驱动和控制，当驶向一个停车标志或者一个撞车现场时将会发生什么。这些系统如何到达和应对相似场景上的轻微差别和变异，将会产生意想不到的且有潜在危害的副作用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;偏差泄露（Bias Leakage）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能引擎交互的另一个潜在的副作用是其扩大了训练偏差的风险。例如，一辆无人驾驶汽车可以观察到另一辆无人驾驶汽车以牺牲行人为代价来保护车上的乘客，并且观察到这样的选择机制保障另一辆车自身免出事故，那么这辆车将学会在相似情景下采取相似的做法。这样将会导致偏差泄露，即各自独立训练得到的人工智能引擎能够被其他的人工智能引擎所影响（正面或负面影响）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;学习的敏捷性（Learning Agility）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;即使给相似的人工智能引擎提供相同的训练数据，但训练环境和用以训练架构的不同仍会导致训练和学习过程以不同的速率进行，并得出不同的结论来作为输出结果。这些细微偏差经过多次迭代，将导致人工智能引擎的行为表现产生巨大变化，随之而来的是始料不及的后果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「陈腐」的人工智能引擎和「废料堆积场」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在一个由人工智能驱动的产品组成的世界里，如果这些产品被遗弃或者逐渐消亡将会发生什么。植入的人工智能或许会逐渐被冻结，久而久之变成人工智能的废料堆积场。这些被遗弃的人工智能驱动的产品，是处于对其环境和使用情境学习的巅峰时刻直到消亡时刻到来，如果在另一个时间因为任何原因复活，环境和使用情境还会再次导致不可预测或不理想的作用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibkgzQLGMwFy1N0wOZ7kQ0DddhFQEexhqcZOiaIBpJwJjBoSmsPxgeU8ia8hlSO7FQQxgNhicmhBHdBQ/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;新的人工智能开源模式&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们需要一个开源的人工智能新模式，它可以提供一个框架来解决上面列出的一些问题。考虑到人工智能的特质，仅仅将之前的用于构建人工智能和机器学习引擎的技术开源并嵌入到产品中是远远不够的。此外，与科学研究相似，业界也需要将用于大规模生产的人工智能和机器学习引擎反馈回学界，从而为新的改进的系统、引擎和产品提供基础支撑。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;基准、参照和标准&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于所有的基础场景，例如自动驾驶汽车、图像识别、语音文本转换等，尤其是在面对多个服务提供商的情况下，行业需要定义基准和标准，以应对所有其它新的或现有的人工智能引擎和堆栈的评估排名（例如，就像人工智能相当于自动驾驶汽车的美国国家公路交通安全管理局的 5 星级安全评级）。为基础情景定义业界可接受的基准，可以确保服务提供商和消费者能够在选择使用人工智能和机器学习的产品和服务方面做出明智的决策。此外，可以根据现有的基准和标准不断地评估现有的人工智能引擎，以确保这些系统的质量不断提高。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;构建人工智能和机器学习模式的公司应考虑将整个人工智能和机器学习模式开源（不仅仅是贡献构建模式的技术和框架）。例如，即使是已经有 5 年开发历史的谷歌图像识别或微软语音文本转换模式，也可以在其它板块行业或垂直行业中更快地激发人工智能和机器学习的创新和同化，从而引发自我创新的持续循环。构建人工智能和机器学习模式的公司应考虑将整个人工智能和机器学习模式开源（不仅仅是贡献构建模式的技术和框架）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;寻找偏差&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们需要能够寻找偏差的能力，以便人工智能和机器学习引擎中的偏差能够尽快被发现和解决。离开这样的能力，业界将非常难以运用通用人工智能引擎，从而无法令这些引擎在不同场景中一致和确定地运行。寻找偏差和解决问题需要以下人工智能开放源模式的支持：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据的假设和偏差&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能使得产品设计者需要确保他们了解人工智能和机器学习引擎中包含的假设和偏差。与人工智能产品交互的其它产品需要确保他们理解并准备好处理人工智能引擎行为带来的后果。为了确保人工智能和机器学习模式的消费者或集成商做好足够的准备，应该为每个人工智能和机器学习模式共享以下标准：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;收集标准&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据是怎样收集的？数据生成器是什么？数据生成的频率、地点、时间、方式和原因分别是什么？如何收集、存储和传输？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;选择标准&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据是如何被选择而进行训练的？未被选择的数据有什么标准？数据的子集是如何选择和未选择的？定义高质量数据的标准是什么？定义可接受但质量不高的数据的标准又是什么？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;处理标准&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;用于训练的数据需要怎样的处理？数据是如何转换、增强和归纳的？处理的频率如何？什么原因导致需要计划的处理推迟或中止。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;特征假设和偏差&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能和机器学习模式被建模的系统的特征或特点而训练的。这些特征被提取出来用于人工智能和机器学习引擎以预测该系统的行为或将新信号分类为所需的类别以从系统中推荐特定的行为。人工智能模式的消费者和集成商不仅要很好地理解应该选择什么特征来开发人工智能模式，而且还要理解为什么有的考虑了的特征没有被选择。此外，过程的可见性以及被用于确定训练特征的见解也将需要归档和共享。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;去除盲点&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由于模式内置的偏差和假设，人工智能和机器学习引擎可能会在某些情况、环境中受到限制。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;盲点报告和反馈循环&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;用于人工智能和机器学习的开源模式应该具有的又一特征是不仅能够探知特定模式是否具有盲点，同时具有提供用于消除盲点的反馈信息的能力（真实世界的例子）。这与用户的垃圾邮件报告非常相似——用户标记垃圾邮件的例子，过滤器从中学习规则。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;协作去除盲点&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在理想情况下，开源协议需要允许用户共享数据，更有效地消除盲点。就像谷歌自动驾驶汽车和特斯拉一样。谷歌 Waymo 已经积累了 200 万英里的自动驾驶数据，而特斯拉收集了 5000 万英里的高速公路驾驶数据。这些数据包含大量的避免崩溃/驾驶者/乘客/行人安全的信息，如果这两家公司展开合作分享数据的话，它们就可以利用他人的数据改善自身产品的安全。或许，这些数据应该被开源，为行业和用户提供更多安全保障。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;结论&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能和机器学习正在切实地改变我们的生活方式，为人类提供更好、更简单、更安全和愉快的体验。人工智能和机器学习在很多行业以不同形式不断被应用。但是，如果想加速这些应用，仅仅开源用于构建人工智能和机器学习引擎的框架是不够的。我们需要新的开源模式，让各家公司不仅能够贡献和改进人工智能/机器学习框架，而且可以将这些框架应用于新的环境中去，在标准模式的基础上构建新的模式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此外，人工智能模式中的假设和偏差信息（在数据和特征层面）可以让用户不断提出反馈，为改进产品提供依据。如果没有开源这样的模式，科技领域之外的公司将难以真正得到人工智能带来的好处。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 30 Jan 2017 13:38:10 +0800</pubDate>
    </item>
    <item>
      <title>教程 | 从头开始：用Python实现随机森林算法</title>
      <link>http://www.iwgc.cn/link/4524081</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自machine learning mastery&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：Linjing、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;拥有高方差使得决策树（secision tress）在处理特定训练数据集时其结果显得相对脆弱。bagging（bootstrap aggregating 的缩写）算法从训练数据的样本中建立复合模型，可以有效降低决策树的方差，但树与树之间有高度关联（并不是理想的树的状态）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随机森林算法（Random forest algorithm）是对 bagging 算法的扩展。除了仍然根据从训练数据样本建立复合模型之外，随机森林对用做构建树（tree）的数据特征做了一定限制，使得生成的决策树之间没有关联，从而提升算法效果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本教程旨在探讨如何用 Python 实现随机森林算法。通过本文，我们可以了解到：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;bagged decision trees 与随机森林算法的差异；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如何构建含更多方差的装袋决策树；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如何将随机森林算法运用于预测模型相关的问题。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;算法描述&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个章节将对随机森林算法本身以及本教程的算法试验所用的声纳数据集（Sonar dataset）做一个简要介绍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随机森林算法&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;决策树运行的每一步都涉及到对数据集中的最优分裂点（best split point）进行贪婪选择（greedy selection）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个机制使得决策树在没有被剪枝的情况下易产生较高的方差。整合通过提取训练数据库中不同样本（某一问题的不同表现形式）构建的复合树及其生成的预测值能够稳定并降低这样的高方差。这种方法被称作引导聚集算法（bootstrap aggregating），其简称 bagging 正好是装进口袋，袋子的意思，所以被称为「装袋算法」。该算法的局限在于，由于生成每一棵树的贪婪算法是相同的，那么有可能造成每棵树选取的分裂点（split point）相同或者极其相似，最终导致不同树之间的趋同（树与树相关联）。相应地，反过来说，这也使得其会产生相似的预测值，降低原本要求的方差。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们可以采用限制特征的方法来创建不一样的决策树，使贪婪算法能够在建树的同时评估每一个分裂点。这就是随机森林算法（Random Forest algorithm）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;与装袋算法一样，随机森林算法从训练集里撷取复合样本并训练。其不同之处在于，数据在每个分裂点处完全分裂并添加到相应的那棵决策树当中，且可以只考虑用于存储属性的某一固定子集。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于分类问题，也就是本教程中我们将要探讨的问题，其被考虑用于分裂的属性数量被限定为小于输入特征的数量之平方根。代码如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;num_features_for_split = sqrt(total_input_features)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个小更改会让生成的决策树各不相同（没有关联），从而使得到的预测值更加多样化。而多样的预测值组合往往会比一棵单一的决策树或者单一的装袋算法有更优的表现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;声纳数据集（Sonar dataset）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们将在本教程里使用声纳数据集作为输入数据。这是一个描述声纳反射到不同物体表面后返回的不同数值的数据集。60 个输入变量表示声纳从不同角度返回的强度。这是一个二元分类问题（binary classification problem），要求模型能够区分出岩石和金属柱体的不同材质和形状，总共有 208 个观测样本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该数据集非常易于理解——每个变量都互有连续性且都在 0 到 1 的标准范围之间，便于数据处理。作为输出变量，字符串'M'表示金属矿物质，'R'表示岩石。二者需分别转换成整数 1 和 0。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过预测数据集（M 或者金属矿物质）中拥有最多观测值的类，零规则算法（Zero Rule Algorithm）可实现 53% 的精确度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;更多有关该数据集的内容可参见 UCI Machine Learning repository：https://archive.ics.uci.edu/ml/datasets/Connectionist+Bench+(Sonar,+Mines+vs.+Rocks)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;免费下载该数据集，将其命名为 sonar.all-data.csv，并存储到需要被操作的工作目录当中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;教程&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此次教程分为两个步骤。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 分裂次数的计算。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 声纳数据集案例研究&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些步骤能让你了解为你自己的预测建模问题实现和应用随机森林算法的基础&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 分裂次数的计算&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在决策树中，我们通过找到一些特定属性和属性的值来确定分裂点，这类特定属性需表现为其所需的成本是最低的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;分类问题的成本函数（cost function）通常是基尼指数（Gini index），即计算由分裂点产生的数据组的纯度（purity）。对于这样二元分类的分类问题来说，指数为 0 表示绝对纯度，说明类值被完美地分为两组。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从一棵决策树中找到最佳分裂点需要在训练数据集中对每个输入变量的值做成本评估。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在装袋算法和随机森林中，这个过程是在训练集的样本上执行并替换（放回）的。因为随机森林对输入的数据要进行行和列的采样。对于行采样，采用有放回的方式，也就是说同一行也许会在样本中被选取和放入不止一次。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们可以考虑创建一个可以自行输入属性的样本，而不是枚举所有输入属性的值以期找到获取成本最低的分裂点，从而对这个过程进行优化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该输入属性样本可随机选取且没有替换过程，这就意味着在寻找最低成本分裂点的时候每个输入属性只需被选取一次。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如下的代码所示，函数 get_split() 实现了上述过程。它将一定数量的来自待评估数据的输入特征和一个数据集作为参数，该数据集可以是实际训练集里的样本。辅助函数 test_split() 用于通过候选的分裂点来分割数据集，函数 gini_index() 用于评估通过创建的行组（groups of rows）来确定的某一分裂点的成本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以上我们可以看出，特征列表是通过随机选择特征索引生成的。通过枚举该特征列表，我们可将训练集中的特定值评估为符合条件的分裂点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;# Select the best split point for a dataset&lt;br/&gt;def get_split(dataset, n_features):&lt;br/&gt;    class_values = list(set(row[-1] for row in dataset))&lt;br/&gt;    b_index, b_value, b_score, b_groups = 999, 999, 999, None&lt;br/&gt;    features = list()&lt;br/&gt;    while len(features) &amp;lt; n_features:&lt;br/&gt;        index = randrange(len(dataset[0])-1)&lt;br/&gt;        if index not in features:&lt;br/&gt;            features.append(index)&lt;br/&gt;    for index in features:&lt;br/&gt;        for row in dataset:&lt;br/&gt;            groups = test_split(index, row[index], dataset)&lt;br/&gt;            gini = gini_index(groups, class_values)&lt;br/&gt;            if gini &amp;lt; b_score:&lt;br/&gt;                b_index, b_value, b_score, b_groups = index, row[index], gini, groups&lt;br/&gt;    return {'index':b_index, 'value':b_value, 'groups':b_groups}&lt;/pre&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;至此，我们知道该如何改造一棵用于随机森林算法的决策树。我们可将之与装袋算法结合运用到真实的数据集当中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 关于声纳数据集的案例研究&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这个部分，我们将把随机森林算法用于声纳数据集。本示例假定声纳数据集的 csv 格式副本已存在于当前工作目录中，文件名为 sonar.all-data.csv。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先加载该数据集，将字符串转换成数字，并将输出列从字符串转换成数值 0 和 1. 这个过程是通过辅助函数 load_csv()、str_column_to_float() 和 str_column_to_int() 来分别实现的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们将通过 K 折交叉验证（k-fold cross validatio）来预估得到的学习模型在未知数据上的表现。这就意味着我们将创建并评估 K 个模型并预估这 K 个模型的平均误差。评估每一个模型是由分类准确度来体现的。辅助函数 cross_validation_split()、accuracy_metric() 和 evaluate_algorithm() 分别实现了上述功能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;装袋算法将通过分类和回归树算法来满足。辅助函数 test_split() 将数据集分割成不同的组；gini_index() 评估每个分裂点；前文提及的改进过的 get_split() 函数用来获取分裂点；函数 to_terminal()、split() 和 build_tree() 用以创建单个决策树；predict() 用于预测；subsample() 为训练集建立子样本集； bagging_predict() 对决策树列表进行预测。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;新命名的函数 random_forest() 首先从训练集的子样本中创建决策树列表，然后对其进行预测。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;正如我们开篇所说，随机森林与决策树关键的区别在于前者在建树的方法上的小小的改变，这一点在运行函数 get_split() 得到了体现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;完整的代码如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;# Random Forest Algorithm on Sonar Dataset&lt;br/&gt;from random import seed&lt;br/&gt;from random import randrange&lt;br/&gt;from csv import reader&lt;br/&gt;from math import sqrt&lt;br/&gt; &lt;br/&gt;# Load a CSV file&lt;br/&gt;def load_csv(filename):&lt;br/&gt; &amp;nbsp; &amp;nbsp;dataset = list()&lt;br/&gt; &amp;nbsp; &amp;nbsp;with open(filename, 'r') as file:&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;csv_reader = reader(file)&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;for row in csv_reader:&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;if not row:&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;continue&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;dataset.append(row)&lt;br/&gt; &amp;nbsp; &amp;nbsp;return dataset&lt;br/&gt; &lt;br/&gt;# Convert string column to float&lt;br/&gt;def str_column_to_float(dataset, column):&lt;br/&gt; &amp;nbsp; &amp;nbsp;for row in dataset:&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;row[column] = float(row[column].strip())&lt;br/&gt; &lt;br/&gt;# Convert string column to integer&lt;br/&gt;def str_column_to_int(dataset, column):&lt;br/&gt; &amp;nbsp; &amp;nbsp;class_values = [row[column] for row in dataset]&lt;br/&gt; &amp;nbsp; &amp;nbsp;unique = set(class_values)&lt;br/&gt; &amp;nbsp; &amp;nbsp;lookup = dict()&lt;br/&gt; &amp;nbsp; &amp;nbsp;for i, value in enumerate(unique):&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;lookup[value] = i&lt;br/&gt; &amp;nbsp; &amp;nbsp;for row in dataset:&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;row[column] = lookup[row[column]]&lt;br/&gt; &amp;nbsp; &amp;nbsp;return lookup&lt;br/&gt; &lt;br/&gt;# Split a dataset into k folds&lt;br/&gt;def cross_validation_split(dataset, n_folds):&lt;br/&gt; &amp;nbsp; &amp;nbsp;dataset_split = list()&lt;br/&gt; &amp;nbsp; &amp;nbsp;dataset_copy = list(dataset)&lt;br/&gt; &amp;nbsp; &amp;nbsp;fold_size = len(dataset) / n_folds&lt;br/&gt; &amp;nbsp; &amp;nbsp;for i in range(n_folds):&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;fold = list()&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;while len(fold) &amp;lt; fold_size:&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;index = randrange(len(dataset_copy))&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;fold.append(dataset_copy.pop(index))&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;dataset_split.append(fold)&lt;br/&gt; &amp;nbsp; &amp;nbsp;return dataset_split&lt;br/&gt; &lt;br/&gt;# Calculate accuracy percentage&lt;br/&gt;def accuracy_metric(actual, predicted):&lt;br/&gt; &amp;nbsp; &amp;nbsp;correct = 0&lt;br/&gt; &amp;nbsp; &amp;nbsp;for i in range(len(actual)):&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;if actual[i] == predicted[i]:&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;correct += 1&lt;br/&gt; &amp;nbsp; &amp;nbsp;return correct / float(len(actual)) * 100.0&lt;br/&gt; &lt;br/&gt;# Evaluate an algorithm using a cross validation split&lt;br/&gt;def evaluate_algorithm(dataset, algorithm, n_folds, *args):&lt;br/&gt; &amp;nbsp; &amp;nbsp;folds = cross_validation_split(dataset, n_folds)&lt;br/&gt; &amp;nbsp; &amp;nbsp;scores = list()&lt;br/&gt; &amp;nbsp; &amp;nbsp;for fold in folds:&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;train_set = list(folds)&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;train_set.remove(fold)&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;train_set = sum(train_set, [])&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;test_set = list()&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;for row in fold:&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;row_copy = list(row)&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;test_set.append(row_copy)&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;row_copy[-1] = None&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;predicted = algorithm(train_set, test_set, *args)&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;actual = [row[-1] for row in fold]&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;accuracy = accuracy_metric(actual, predicted)&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;scores.append(accuracy)&lt;br/&gt; &amp;nbsp; &amp;nbsp;return scores&lt;br/&gt; &lt;br/&gt;# Split a dataset based on an attribute and an attribute value&lt;br/&gt;def test_split(index, value, dataset):&lt;br/&gt; &amp;nbsp; &amp;nbsp;left, right = list(), list()&lt;br/&gt; &amp;nbsp; &amp;nbsp;for row in dataset:&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;if row[index] &amp;lt; value:&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;left.append(row)&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;else:&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;right.append(row)&lt;br/&gt; &amp;nbsp; &amp;nbsp;return left, right&lt;br/&gt; &lt;br/&gt;# Calculate the Gini index for a split dataset&lt;br/&gt;def gini_index(groups, class_values):&lt;br/&gt; &amp;nbsp; &amp;nbsp;gini = 0.0&lt;br/&gt; &amp;nbsp; &amp;nbsp;for class_value in class_values:&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;for group in groups:&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;size = len(group)&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;if size == 0:&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;continue&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;proportion = [row[-1] for row in group].count(class_value) / float(size)&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;gini += (proportion * (1.0 - proportion))&lt;br/&gt; &amp;nbsp; &amp;nbsp;return gini&lt;br/&gt; &lt;br/&gt;# Select the best split point for a dataset&lt;br/&gt;def get_split(dataset, n_features):&lt;br/&gt; &amp;nbsp; &amp;nbsp;class_values = list(set(row[-1] for row in dataset))&lt;br/&gt; &amp;nbsp; &amp;nbsp;b_index, b_value, b_score, b_groups = 999, 999, 999, None&lt;br/&gt; &amp;nbsp; &amp;nbsp;features = list()&lt;br/&gt; &amp;nbsp; &amp;nbsp;while len(features) &amp;lt; n_features:&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;index = randrange(len(dataset[0])-1)&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;if index not in features:&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;features.append(index)&lt;br/&gt; &amp;nbsp; &amp;nbsp;for index in features:&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;for row in dataset:&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;groups = test_split(index, row[index], dataset)&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;gini = gini_index(groups, class_values)&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;if gini &amp;lt; b_score:&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;b_index, b_value, b_score, b_groups = index, row[index], gini, groups&lt;br/&gt; &amp;nbsp; &amp;nbsp;return {'index':b_index, 'value':b_value, 'groups':b_groups}&lt;br/&gt; &lt;br/&gt;# Create a terminal node value&lt;br/&gt;def to_terminal(group):&lt;br/&gt; &amp;nbsp; &amp;nbsp;outcomes = [row[-1] for row in group]&lt;br/&gt; &amp;nbsp; &amp;nbsp;return max(set(outcomes), key=outcomes.count)&lt;br/&gt; &lt;br/&gt;# Create child splits for a node or make terminal&lt;br/&gt;def split(node, max_depth, min_size, n_features, depth):&lt;br/&gt; &amp;nbsp; &amp;nbsp;left, right = node['groups']&lt;br/&gt; &amp;nbsp; &amp;nbsp;del(node['groups'])&lt;br/&gt; &amp;nbsp; &amp;nbsp;# check for a no split&lt;br/&gt; &amp;nbsp; &amp;nbsp;if not left or not right:&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;node['left'] = node['right'] = to_terminal(left + right)&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;return&lt;br/&gt; &amp;nbsp; &amp;nbsp;# check for max depth&lt;br/&gt; &amp;nbsp; &amp;nbsp;if depth &amp;gt;= max_depth:&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;node['left'], node['right'] = to_terminal(left), to_terminal(right)&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;return&lt;br/&gt; &amp;nbsp; &amp;nbsp;# process left child&lt;br/&gt; &amp;nbsp; &amp;nbsp;if len(left) &amp;lt;= min_size:&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;node['left'] = to_terminal(left)&lt;br/&gt; &amp;nbsp; &amp;nbsp;else:&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;node['left'] = get_split(left, n_features)&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;split(node['left'], max_depth, min_size, n_features, depth+1)&lt;br/&gt; &amp;nbsp; &amp;nbsp;# process right child&lt;br/&gt; &amp;nbsp; &amp;nbsp;if len(right) &amp;lt;= min_size:&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;node['right'] = to_terminal(right)&lt;br/&gt; &amp;nbsp; &amp;nbsp;else:&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;node['right'] = get_split(right, n_features)&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;split(node['right'], max_depth, min_size, n_features, depth+1)&lt;br/&gt; &lt;br/&gt;# Build a decision tree&lt;br/&gt;def build_tree(train, max_depth, min_size, n_features):&lt;br/&gt; &amp;nbsp; &amp;nbsp;root = get_split(dataset, n_features)&lt;br/&gt; &amp;nbsp; &amp;nbsp;split(root, max_depth, min_size, n_features, 1)&lt;br/&gt; &amp;nbsp; &amp;nbsp;return root&lt;br/&gt; &lt;br/&gt;# Make a prediction with a decision tree&lt;br/&gt;def predict(node, row):&lt;br/&gt; &amp;nbsp; &amp;nbsp;if row[node['index']] &amp;lt; node['value']:&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;if isinstance(node['left'], dict):&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;return predict(node['left'], row)&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;else:&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;return node['left']&lt;br/&gt; &amp;nbsp; &amp;nbsp;else:&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;if isinstance(node['right'], dict):&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;return predict(node['right'], row)&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;else:&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;return node['right']&lt;br/&gt; &lt;br/&gt;# Create a random subsample from the dataset with replacement&lt;br/&gt;def subsample(dataset, ratio):&lt;br/&gt; &amp;nbsp; &amp;nbsp;sample = list()&lt;br/&gt; &amp;nbsp; &amp;nbsp;n_sample = round(len(dataset) * ratio)&lt;br/&gt; &amp;nbsp; &amp;nbsp;while len(sample) &amp;lt; n_sample:&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;index = randrange(len(dataset))&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;sample.append(dataset[index])&lt;br/&gt; &amp;nbsp; &amp;nbsp;return sample&lt;br/&gt; &lt;br/&gt;# Make a prediction with a list of bagged trees&lt;br/&gt;def bagging_predict(trees, row):&lt;br/&gt; &amp;nbsp; &amp;nbsp;predictions = [predict(tree, row) for tree in trees]&lt;br/&gt; &amp;nbsp; &amp;nbsp;return max(set(predictions), key=predictions.count)&lt;br/&gt; &lt;br/&gt;# Random Forest Algorithm&lt;br/&gt;def random_forest(train, test, max_depth, min_size, sample_size, n_trees, n_features):&lt;br/&gt; &amp;nbsp; &amp;nbsp;trees = list()&lt;br/&gt; &amp;nbsp; &amp;nbsp;for i in range(n_trees):&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;sample = subsample(train, sample_size)&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;tree = build_tree(sample, max_depth, min_size, n_features)&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;trees.append(tree)&lt;br/&gt; &amp;nbsp; &amp;nbsp;predictions = [bagging_predict(trees, row) for row in test]&lt;br/&gt; &amp;nbsp; &amp;nbsp;return(predictions)&lt;br/&gt; &lt;br/&gt;# Test the random forest algorithm&lt;br/&gt;seed(1)&lt;br/&gt;# load and prepare data&lt;br/&gt;filename = 'sonar.all-data.csv'&lt;br/&gt;dataset = load_csv(filename)&lt;br/&gt;# convert string attributes to integers&lt;br/&gt;for i in range(0, len(dataset[0])-1):&lt;br/&gt; &amp;nbsp; &amp;nbsp;str_column_to_float(dataset, i)&lt;br/&gt;# convert class column to integers&lt;br/&gt;str_column_to_int(dataset, len(dataset[0])-1)&lt;br/&gt;# evaluate algorithm&lt;br/&gt;n_folds = 5&lt;br/&gt;max_depth = 10&lt;br/&gt;min_size = 1&lt;br/&gt;sample_size = 1.0&lt;br/&gt;n_features = int(sqrt(len(dataset[0])-1))&lt;br/&gt;for n_trees in [1, 5, 10]:&lt;br/&gt; &amp;nbsp; &amp;nbsp;scores = evaluate_algorithm(dataset, random_forest, n_folds, max_depth, min_size, sample_size, n_trees, n_features)&lt;br/&gt; &amp;nbsp; &amp;nbsp;print('Trees: %d' % n_trees)&lt;br/&gt; &amp;nbsp; &amp;nbsp;print('Scores: %s' % scores)&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里对第 197 行之后对各项参数的赋值做一个说明。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;将 K 赋值为 5 用于交叉验证，得到每个子样本为 208/5 = 41.6，即超过 40 条声纳返回记录会用于每次迭代时的评估。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;每棵树的最大深度设置为 10，每个节点的最小训练行数为 1. 创建训练集样本的大小与原始数据集相同，这也是随机森林算法的默认预期值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们把在每个分裂点需要考虑的特征数设置为总的特征数目的平方根，即 sqrt(60)=7.74，取整为 7。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;将含有三组不同数量的树同时进行评估，以表明添加更多的树可以使该算法实现的功能更多。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，运行这个示例代码将会 print 出每组树的相应分值以及每种结构的平均分值。如下所示：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Trees: 1&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Scores: [68.29268292682927, 75.60975609756098, 70.73170731707317, 63.41463414634146, 65.85365853658537]&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Mean Accuracy: 68.780%&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Trees: 5&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Scores: [68.29268292682927, 68.29268292682927, 78.04878048780488, 65.85365853658537, 68.29268292682927]&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Mean Accuracy: 69.756%&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Trees: 10&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Scores: [68.29268292682927, 78.04878048780488, 75.60975609756098, 70.73170731707317, 70.73170731707317]&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Mean Accuracy: 72.683%&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;扩展&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本节会列出一些与本次教程相关的扩展内容。大家或许有兴趣一探究竟。&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;算法调校（Algorithm Tuning）。本文所用的配置参数或有未被修正的错误以及有待商榷之处。用更大规模的树，不同的特征数量甚至不同的树的结构都可以改进试验结果。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;更多问题。该方法同样适用于其他的分类问题，甚至是用新的成本计算函数以及新的组合树的预期值的方法使其适用于回归算法。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;回顾总结&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过本次教程的探讨，你知道了随机森林算法是如何实现的，特别是：&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;随机森林与装袋决策树的区别。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如何用决策树生成随机森林算法。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如何将随机森林算法应用于解决实际操作中的预测模型问题。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 30 Jan 2017 13:38:10 +0800</pubDate>
    </item>
    <item>
      <title>深度 | Richard Sutton：人工智能的未来属于搜索和学习</title>
      <link>http://www.iwgc.cn/link/4524082</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;作者：Yuting&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;strong&gt;参与：&lt;strong&gt;吴沁桐、赵华龙&lt;/strong&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Richard Sutton 在多伦多大学数学科学研究中心的机器学习应用进展系列研讨会上探讨了人工智能的未来方向。他认为人工智能的未来属于可扩展的方法、搜索与学习。而在人工智能未来的发展中，可扩展性是及其重要的方向。监督学习和计算能力的可扩展性并不大，真正重要的是在普通的经验知识世界中学习的能力，这个能力需要扩展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;iframe class="video_iframe" data-vidtype="1" allowfullscreen="" frameborder="0" height="418" width="557" data-src="https://v.qq.com/iframe/preview.html?vid=h0369guf74a&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0"&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;摘要&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当人类最终开始理解智能的原理并将这些原理赋予机器的时候，这会是我们这个时代，或者可以说是任何时代，最重要的发现。最近几年，随着深度学习及其相关领域的进步，这一巨大的进步几乎触手可及。它给人类所带来的后果、利益和危险已成为新闻界、各种公共政策会议以及科学会议上的热门话题，这是一种夸张和恐惧，还是隐藏在激动人心之下的真正科学进步？在这次讨论中，我将基于我 38 年的人工智能研究经验，给大家讲一些有用的但毫无疑问又带有偏颇的观点。我所讲的内容包括两个方面：1）将目前的发展视为人工智能最长久趋势的一部分——更廉价的计算，以及由此而来的将会扮演更重要角色的搜索、学习以及所有可扩展的事情，2）基于预测以及强化学习，勾勒出一条可能的人工智能之路。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;介绍&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在不远的将来，人工智能的可扩展性将会是极其重要的。鉴于摩尔定律奠定了我们目前计算能力发展的基础，根据该定律我们的计算资源每两年将翻一番。优秀的算法必须能够随着硬件的发展而扩展。尽管现在研究人员还不需要花费太多的时间关注人工智能的可扩展性，但在不远的将来，这一部分开销将呈现指数级的增长。人工智能的未来应当属于可扩展的搜索与学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;要点总结&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;现在&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最火最有名的人工智能应用有：AlphaGo、自动驾驶汽车、扑克、语音识别与计算机视觉。为什么它会在现在出现？是因为人工智能算法的巨大进步还是因为摩尔定律？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摩尔定律肯定在其中扮演了重要角色。摩尔定律告诉我们，能够放置在一块相同大小的集成电路上的晶体管的数量大约每两年会翻一番。在计算机硬件领域的长时间指数级增长至少为人工智能的发展贡献了一半的力量。硬件是算法发展的一个巨大激励因素。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 是解决还是不解决，所涉及的是人工智能的问题，但根源来源于人类自身。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;a. 人工智能是不安全的且会威胁到人类本身，人工智能将会比人更聪明。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;b. 人工智能的研究人员有时对这些担忧过于轻视。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Richard &lt;span&gt;Sutton&lt;/span&gt;认为&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;a. 2040(40%), never(10%) 一个人类级别的人工智能将会是一项意义深远的科学成就，它可能会在 2030 年实现（25%），也可能在 2040 年实现（40%），也可能永远不会实现（10%）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;b. 人工智能会带来很多改变，我们应为此做好准备。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;c. 对人工智能的恐惧被过于夸大了，且这种恐惧是无建设性的。有些恐惧人工智能的人甚至都不知道他们恐惧具体是什么。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp; i. 如果人工智能比我们聪明，它们将会脱离我们的控制。很有可能人工智能会是我们的继任者而不是奴隶。而坏的继任者源自于它们父辈的错误。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp; ii. 以摩尔定律的速度来看，人工智能的发展速度是缓慢的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp; iii. 最大的风险来源于那些不当使用人工智能之人。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;过去：从长期来看可扩展的方法总是赢家。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 三波神经网络的热潮&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;a.50-60 年代的感知机、Adaline：仅有一层可学习层。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;b.80-90 年代的连接主义（Connectionism）、神经网络：通过反向传递的多层学习（SGD）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;c.2010 年起的深度学习：神经网络类的方法胜利了，因为它们的性能可以随着摩尔定律的发展大幅提高，而计算类（computational）的方法却做不到这一点。最优秀的算法本质上和 80 年代的算法是一样的，不同的是更快的计算机和更大的数据集。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 最好的解决方案来自于最好的算法和强有力的计算机。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;a. 赢得象棋比赛：关键是巨大、高效、启发式的搜索。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;b. 赢得围棋比赛：关键是巨大且基于样本的搜索。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;c. 理解自然语言：关键是一些统计式的机器学习方法和大数据集。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;d. 视觉识别物体：关键是大数据集、更多的参数和更长的训练时间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 搜索和学习是可扩展的方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;a. 一个可随着摩尔定律扩展的方法在某种程度上它的性能大致和给予它的计算量成比例。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;b. 一个不能扩展的方法意味着它所带来的改进不太受可用计算能力的影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;c. 可扩展的能力是关键，但是它往往也与其他一些问题有关。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;符号的 VS. 统计的、纯手工的 VS 可自我学习的、专用领域的 VS 通用的。尽管前者更依靠人类自己的理解，但是从人工智能的发展历史来看，那些统计化的、可自我学习的、通用的方法已经逐渐变得越来越重要。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;未来&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 监督学习的可扩展性有多大？并不太大&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;a. 通过神经网络，学习的进程已经被大幅扩展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;b. 可扩展性是有限度的，因为它需要人们提供训练数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 强化学习的可扩展性有多大？并不太大&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;a. 一个经典的与不受模型限制的强化学习可以通过失败与错误学习出一条规则，不需要数据标注。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;b. 计算是廉价的，没有什么扩展性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 相比较仅仅一个权值方程和策略，相比较仅仅老师告诉你的什么是应该做的事，还有太多的东西要学。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4. 世界经验知识的大挑战（知识表达与推理）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;a. 知识的定义：知识是关于世界的状态和变化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp; i. 状态是事物过去的总结，它可以用来预测它将来的状态。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp; ii. 有了状态的知识就是有了一个好的总结，它能够使预测更精确。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp; iii. 预测本身就是动态的知识。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp; iv. 需要预测的最重要的东西是状态和奖惩，当然，这取决于 agent 是做什么的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;b. 举个例子，知识可以是知道象棋里的每一小步如何走，知道什么导致了什么，预测下面会发生什么。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;c. 知识必须具有可表达性（可以表示所有重要的事物）、可学习性（监督的或者非监督的）、适合推理和论证。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;d. 感觉运动观点（与感觉运动阶段有关的感觉运动）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp; i. 你的数据流其实就是你所知的世界中的每一件事。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp; ii. 知识在数据中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;5. 一个古已有之的宏伟目标是用感觉运动数据来理解世界。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;a. 能够在各个抽象层次做预测。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;b. 这个目标非常适合进行扩展，它利用大量的数据来学习预测行为以及搜寻最好的抽象。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;6. 在未来 12 个月中机器学习领域最重要的进展将会是：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;a. 从寻常知识中进行大规模学习的能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp; i. 从与世界的互动中进行大规模学习的能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp; ii. 这种学习不再需要已标注数据的训练集。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp; iii. 以一种更自然的方式学习，就像儿童或者动物那样。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp; iv. 学习世界如何，以及理解因果性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;b. 能够使机器学习扩展到更高的水平。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;c. 使用深度强化学习来进行远期预测（可能）和/或 无监督的学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;7. 新工具&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;a. 通用的价值函数为高效可学习可预测的知识提供了一种统一语言。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;b. 可选项以及备选模型（时域抽象）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;c. 可预测的状态表达。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;d. 新的离策略（off-policy）学习算法（梯度-TD，强度-TD）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;e. 时域差分网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;f. 深度学习，表达搜索。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;结论（最终看法）&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 摩尔定律极大地影响了人工智能的发展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 人工智能的未来属于可扩展的方法、搜索与学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 能够从平常经验中学习知识是一种巨大的进步。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4. 我们的计划应该具有雄心，并且可扩展，还要有耐心。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;5. 在 AI 领域的研究者中，对于着眼于未来的可扩展性并不是十分有吸引力。因为对于想要出成绩的研究者而言，他们更希望自己对相关领域的贡献可以在短期内有显著的影响力，更希望自己的知识与新奇的想法应用的现有的研究当中。然而，随着硬件计算能力的提升，即使是一个算法具有优秀扩展性的算法没法在短期内满足研究应用的需求，从长远来看这样的算法将会很有竞争力。这就像「一步到位方法」vs.」长期演进方法」。研究者们应在他们自己的研究中找到平衡点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;相关阅读&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过强化学习教机器下象棋&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://www.technologyreview.com/s/541276/deep-learning-machine-teaches-itself-chess-in-72-hours-plays-at-international-master/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关于假肢的实时预测&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://webdocs.cs.ualberta.ca/~sutton/papers/PDDCCHS-13.pdf&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Rich NIPS 2015 RL tutorial&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://www.microsoft.com/en-us/research/video/tutorial-introduction-to-reinforcement-learning-with-function-approximation/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心原创，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 30 Jan 2017 13:38:10 +0800</pubDate>
    </item>
    <item>
      <title>人工智能从入门到进阶，机器之心高分技术文章全集</title>
      <link>http://www.iwgc.cn/link/4516627</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：吴攀&lt;span&gt;、&lt;span&gt;蒋思源&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;新的一年到来了，过去的 2016 年可以说是有史以来机器学习领域进展最显著的一年。在大数据和高性能计算设备的助力下，具备学习能力的机器在围棋、语音识别、翻译、图像渲染和识别等许多领域都实现了惊人的成就。但那远远还不是这一领域的终点，大部分媒体和投资者仍然还看好以机器学习为主的人工智能技术的未来发展，市场也无法掩饰地表现出了对这方面的人才的需求。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这篇文章尽可能地全面地梳理了机器之心在 2016 年发过的基础知识和技术指导方面的文章，希望能为读者通往人工智能领域的专业人才乃至学界大牛之路提供一点助力。本文按照从基础到前沿划分对文章进行了分类（学习资源、基础介绍文章、技术起点、继续进阶、前沿研究），读者可方便地根据自己的学习进度选择合适的文章阅读。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;一、学习资源&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWic17FA5ZBlbiaEavsI2wmR5XHRc2ibiaJJr5Ho8fkLeb2pXZMrHqbzLImYFBhjg4kwVZnA9oOR9cjR4g/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721853&amp;amp;idx=3&amp;amp;sn=f9f0048cccefbf9c00dc94f2a71c7d00&amp;amp;chksm=871b0a43b06c8355376d1bc897b4f3585b4a129d77a9e5b025f4c344f2ef264c05133cff7682&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721853&amp;amp;idx=3&amp;amp;sn=f9f0048cccefbf9c00dc94f2a71c7d00&amp;amp;chksm=871b0a43b06c8355376d1bc897b4f3585b4a129d77a9e5b025f4c344f2ef264c05133cff7682&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;深度学习资料大全：从基础到各种网络&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719733&amp;amp;idx=1&amp;amp;sn=2fce6d18e8fcae9b805d4652a7c702e9&amp;amp;chksm=871b018bb06c889d339f34b192579f2e7f97e2f7b64cbe3ccd85ec7b3ed9022178ed5a150359&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719733&amp;amp;idx=1&amp;amp;sn=2fce6d18e8fcae9b805d4652a7c702e9&amp;amp;chksm=871b018bb06c889d339f34b192579f2e7f97e2f7b64cbe3ccd85ec7b3ed9022178ed5a150359&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;30个深度学习库：按Python和C++等10种语言分类&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721418&amp;amp;idx=1&amp;amp;sn=71b28bce48b70f9fa30929db29e685e1&amp;amp;chksm=871b08f4b06c81e24d16ef66265e142de1fd8a18fd872da99a2e70c4e10062ac41575ec0e382&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721418&amp;amp;idx=1&amp;amp;sn=71b28bce48b70f9fa30929db29e685e1&amp;amp;chksm=871b08f4b06c81e24d16ef66265e142de1fd8a18fd872da99a2e70c4e10062ac41575ec0e382&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;2016年不可错过的21个深度学习视频、教程和课程&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721817&amp;amp;idx=4&amp;amp;sn=a2e9f4c19f92fd95040f4b13935c6681&amp;amp;chksm=871b0a67b06c837108989bc0cd0b2dc06ce2c0009190f1ab6cfd38bca5f6d08d6b56e776d811&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721817&amp;amp;idx=4&amp;amp;sn=a2e9f4c19f92fd95040f4b13935c6681&amp;amp;chksm=871b0a67b06c837108989bc0cd0b2dc06ce2c0009190f1ab6cfd38bca5f6d08d6b56e776d811&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;程序员实用深度学习免费课程:从入门到实践&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721817&amp;amp;idx=3&amp;amp;sn=f03d9c31c8db61c7d980b0137c9e2da3&amp;amp;chksm=871b0a67b06c8371ddaa7a49f56ee7b5b9725f52e0a3a930b9d424e7d6fae0ca24bca7e319af&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721817&amp;amp;idx=3&amp;amp;sn=f03d9c31c8db61c7d980b0137c9e2da3&amp;amp;chksm=871b0a67b06c8371ddaa7a49f56ee7b5b9725f52e0a3a930b9d424e7d6fae0ca24bca7e319af&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;9本不容错过的深度学习和神经网络书籍&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719393&amp;amp;idx=1&amp;amp;sn=41ed306d26dd209acfd61ee70efc8cf6&amp;amp;chksm=871b00dfb06c89c9dc8d5da87a0be1b3666c439909b41559097e952b7ccec29bae09823521bf&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719393&amp;amp;idx=1&amp;amp;sn=41ed306d26dd209acfd61ee70efc8cf6&amp;amp;chksm=871b00dfb06c89c9dc8d5da87a0be1b3666c439909b41559097e952b7ccec29bae09823521bf&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;深度学习专业名词表：从激活函数到word2vec&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721717&amp;amp;idx=2&amp;amp;sn=6a58289f9f65448339a845f88f168088&amp;amp;chksm=871b09cbb06c80dd7b790d34e3627eaf3f330b8670350ee5ad3718bc36e3d5f3f30581fe8453&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721717&amp;amp;idx=2&amp;amp;sn=6a58289f9f65448339a845f88f168088&amp;amp;chksm=871b09cbb06c80dd7b790d34e3627eaf3f330b8670350ee5ad3718bc36e3d5f3f30581fe8453&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;2016年年度十大Python库盘点&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716071&amp;amp;idx=1&amp;amp;sn=7aa209732425c6a52536fbb9012a09fd&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716071&amp;amp;idx=1&amp;amp;sn=7aa209732425c6a52536fbb9012a09fd&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;2010-2016年被引用次数最多的深度学习论文&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722147&amp;amp;idx=1&amp;amp;sn=0584e654c66f694502ff2918dcbc3ca1&amp;amp;chksm=871b0b1db06c820bc8396e6b4ab1ced5f0bada892385eabed7fb581c5b911162bfe326bc36a0&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722147&amp;amp;idx=1&amp;amp;sn=0584e654c66f694502ff2918dcbc3ca1&amp;amp;chksm=871b0b1db06c820bc8396e6b4ab1ced5f0bada892385eabed7fb581c5b911162bfe326bc36a0&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;自学数据科学&amp;amp;机器学习，19个数学和统计学公开课推荐&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721121&amp;amp;idx=5&amp;amp;sn=5af0fb9465ce9345c017adfb1d0c9796&amp;amp;chksm=871b0f1fb06c8609b8b9d792b222b16f7b6fa4479a6d426663ab03cf1ebebd5209080bebe48b&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721121&amp;amp;idx=5&amp;amp;sn=5af0fb9465ce9345c017adfb1d0c9796&amp;amp;chksm=871b0f1fb06c8609b8b9d792b222b16f7b6fa4479a6d426663ab03cf1ebebd5209080bebe48b&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;Yoshua Bengio新书《Deep Learning》中文版开放预览（附PDF下载链接）&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715120&amp;amp;idx=2&amp;amp;sn=108bc0f1bac2deb0b423a2587ebe306a&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715120&amp;amp;idx=2&amp;amp;sn=108bc0f1bac2deb0b423a2587ebe306a&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;数据科学家应该掌握的12种机器学习算法（附信息图）&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720472&amp;amp;idx=1&amp;amp;sn=a0d8f835a300fb5d0c4a3a224cc17924&amp;amp;chksm=871b0ca6b06c85b0461163c3043bf45ab6d58dd57263ce381646ba71842608785d97e00014f6&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720472&amp;amp;idx=1&amp;amp;sn=a0d8f835a300fb5d0c4a3a224cc17924&amp;amp;chksm=871b0ca6b06c85b0461163c3043bf45ab6d58dd57263ce381646ba71842608785d97e00014f6&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;从入门到研究，人工智能领域最值得一读的20份资料&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715104&amp;amp;idx=3&amp;amp;sn=2f3c9a625519f6265a3ba755697cad56&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715104&amp;amp;idx=3&amp;amp;sn=2f3c9a625519f6265a3ba755697cad56&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;关于数据科学的十本好书&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719875&amp;amp;idx=1&amp;amp;sn=f1030f9dbd1d8080585b4d3bba3a9b73&amp;amp;chksm=871b02fdb06c8beb2dc94e3f69a76fa56aafb3c310d03e53f3aca2167a27a9e115fbb6b0bfe2&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719875&amp;amp;idx=1&amp;amp;sn=f1030f9dbd1d8080585b4d3bba3a9b73&amp;amp;chksm=871b02fdb06c8beb2dc94e3f69a76fa56aafb3c310d03e53f3aca2167a27a9e115fbb6b0bfe2&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;哈佛大学九大自然语言处理开源项目&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718688&amp;amp;idx=1&amp;amp;sn=c473fd7fe002fe6b8b5b917c432daf27&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718688&amp;amp;idx=1&amp;amp;sn=c473fd7fe002fe6b8b5b917c432daf27&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;ICML 2016演讲视频：数百个演讲带你读懂机器学习&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721717&amp;amp;idx=1&amp;amp;sn=470fef6589c81afa913b2e0572996f92&amp;amp;chksm=871b09cbb06c80ddc4c21fc55511b30c6e1a0461c9f1c0588ce9dd484d6216d819e949a1a259&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721717&amp;amp;idx=1&amp;amp;sn=470fef6589c81afa913b2e0572996f92&amp;amp;chksm=871b09cbb06c80ddc4c21fc55511b30c6e1a0461c9f1c0588ce9dd484d6216d819e949a1a259&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;Yoshua Bengio研究生科研指导演讲：解读人工智能全貌和下一个前沿&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720663&amp;amp;idx=2&amp;amp;sn=d06c7a2e8cdde84901ffd8335a775737&amp;amp;chksm=871b0de9b06c84ff467a63042b17ad1622224fc1ab84597ab80b64ab0049c4f4b09cabc3d7dc&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720663&amp;amp;idx=2&amp;amp;sn=d06c7a2e8cdde84901ffd8335a775737&amp;amp;chksm=871b0de9b06c84ff467a63042b17ad1622224fc1ab84597ab80b64ab0049c4f4b09cabc3d7dc&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;&lt;span&gt;Yann LeCun演讲&lt;span&gt;：人工&lt;/span&gt;&lt;/span&gt;智能的下一个前沿——无监督学习&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720780&amp;amp;idx=1&amp;amp;sn=39ac663849c90ab31d3dd04013f7e646&amp;amp;chksm=871b0e72b06c8764becc21ecb10ece2b7d285f72a85cec79920967abe53bdbf7a16522623caf&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720780&amp;amp;idx=1&amp;amp;sn=39ac663849c90ab31d3dd04013f7e646&amp;amp;chksm=871b0e72b06c8764becc21ecb10ece2b7d285f72a85cec79920967abe53bdbf7a16522623caf&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;今年GitHub排名前20的Python机器学习开源项目&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715438&amp;amp;idx=3&amp;amp;sn=2c2a6e4dfda2307d818dcab385ef6727&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715438&amp;amp;idx=3&amp;amp;sn=2c2a6e4dfda2307d818dcab385ef6727&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;机器学习工程师和数据科学家最应该读的16本书&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722365&amp;amp;idx=4&amp;amp;sn=af6b4a85b4e447d0d54e71399f6d8e93&amp;amp;chksm=871b1443b06c9d55f1678dbe89573c1fcb31758b12b6b992cb63be11b7b1dc6b9f1874cee0bc&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722365&amp;amp;idx=4&amp;amp;sn=af6b4a85b4e447d0d54e71399f6d8e93&amp;amp;chksm=871b1443b06c9d55f1678dbe89573c1fcb31758b12b6b992cb63be11b7b1dc6b9f1874cee0bc&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;任何阶段的学习者都适用的参考：机器学习领域书目全集&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718578&amp;amp;idx=1&amp;amp;sn=ff7d748b149e7952c9fa3b53cefd5afc&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718578&amp;amp;idx=1&amp;amp;sn=ff7d748b149e7952c9fa3b53cefd5afc&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;Yoshua Bengio深度学习暑期班学习总结，35个授课视频全部开放&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722318&amp;amp;idx=2&amp;amp;sn=f03f56fb91bfd5fe393268f74435349f&amp;amp;chksm=871b1470b06c9d661a72d727c76e7f75a8cf57c17c97542cc1c8b330b8969b1fd2748722fb95&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722318&amp;amp;idx=2&amp;amp;sn=f03f56fb91bfd5fe393268f74435349f&amp;amp;chksm=871b1470b06c9d661a72d727c76e7f75a8cf57c17c97542cc1c8b330b8969b1fd2748722fb95&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;Andrej Karpathy CS294课程总结：可视化和理解深度神经网络&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719828&amp;amp;idx=2&amp;amp;sn=c6a73c885c3a8db5f2b0484f7c20498a&amp;amp;chksm=871b022ab06c8b3c8e93ff797be2d68d96945f01b617584e79593e16dcd4a76b19a4642b441d&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719828&amp;amp;idx=2&amp;amp;sn=c6a73c885c3a8db5f2b0484f7c20498a&amp;amp;chksm=871b022ab06c8b3c8e93ff797be2d68d96945f01b617584e79593e16dcd4a76b19a4642b441d&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;Geoffrey Hinton最新演讲梳理：从人工神经网络到RNN应用&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a target="_blank" data_ue_src="http://"&gt;&lt;span&gt;吴恩达NIPS 2016演讲现场直击：如何使用深度学习开发人工智能应用&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721406&amp;amp;idx=1&amp;amp;sn=8251dfebd3c360d180339c34c4710fa7&amp;amp;chksm=871b0800b06c81160244fcda78d7816da8ec31d5fbec546ba6e36241e6d32c0ca943ce9ce73d&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721406&amp;amp;idx=1&amp;amp;sn=8251dfebd3c360d180339c34c4710fa7&amp;amp;chksm=871b0800b06c81160244fcda78d7816da8ec31d5fbec546ba6e36241e6d32c0ca943ce9ce73d&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;NIPS 2016最全盘点：主题详解、前沿论文及下载资源&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719377&amp;amp;idx=1&amp;amp;sn=114e536fc2ca22edcb6ad6ceb332228e&amp;amp;chksm=871b00efb06c89f953e6d7320a7f5fed54e062687425c1dee8166b16704fef23f4eb53b1a473&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719377&amp;amp;idx=1&amp;amp;sn=114e536fc2ca22edcb6ad6ceb332228e&amp;amp;chksm=871b00efb06c89f953e6d7320a7f5fed54e062687425c1dee8166b16704fef23f4eb53b1a473&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;斯坦福大学周末学习盛宴：12位大牛解读深度学习&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719367&amp;amp;idx=1&amp;amp;sn=1cd2e133a56eb3e841e98ab837086df8&amp;amp;chksm=871b00f9b06c89eff783040ad6b30152440e628908fc478b9b8cbce991f914f94237e1333fb1&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719367&amp;amp;idx=1&amp;amp;sn=1cd2e133a56eb3e841e98ab837086df8&amp;amp;chksm=871b00f9b06c89eff783040ad6b30152440e628908fc478b9b8cbce991f914f94237e1333fb1&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;提升深度学习模型的表现，你需要这20个技巧&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720407&amp;amp;idx=1&amp;amp;sn=768d7248e0ab5fa469dbae86d11152e1&amp;amp;chksm=871b0ce9b06c85ffefa2e0c8f6fb7ae4cc1c0500cda7bad008fe68ed6b87d7c8765d138e1fd1&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720407&amp;amp;idx=1&amp;amp;sn=768d7248e0ab5fa469dbae86d11152e1&amp;amp;chksm=871b0ce9b06c85ffefa2e0c8f6fb7ae4cc1c0500cda7bad008fe68ed6b87d7c8765d138e1fd1&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;TensorFlow开源一周年：这可能是一份最完整的盘点&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718160&amp;amp;idx=3&amp;amp;sn=a2114e3324f28740d2603da26fbbdfb4&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718160&amp;amp;idx=3&amp;amp;sn=a2114e3324f28740d2603da26fbbdfb4&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;五大主流深度学习框架比较分析：MXNET是最好选择&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;二、基础介绍文章&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWic17FA5ZBlbiaEavsI2wmR5XlcKzbS0htgFjBuzZZqdvgnBw0XiavstyaNKmgde7F4QyKZRdrR0IYKg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719723&amp;amp;idx=3&amp;amp;sn=0338d470c8668aa912aeebc18c1ced0e&amp;amp;chksm=871b0195b06c8883bab39807043824dcec576180f006226672da649459e7c2de0ecd3fd98c6e&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719723&amp;amp;idx=3&amp;amp;sn=0338d470c8668aa912aeebc18c1ced0e&amp;amp;chksm=871b0195b06c8883bab39807043824dcec576180f006226672da649459e7c2de0ecd3fd98c6e&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;2016伦敦深度学习峰会观感：人工智能面临的三大难题&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722085&amp;amp;idx=1&amp;amp;sn=14a9cc3610e0de25587a707f554939f0&amp;amp;chksm=871b0b5bb06c824da313d70525cca67c9c7417951174455f1e27d9431af132e914c5ab4f6be5&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722085&amp;amp;idx=1&amp;amp;sn=14a9cc3610e0de25587a707f554939f0&amp;amp;chksm=871b0b5bb06c824da313d70525cca67c9c7417951174455f1e27d9431af132e914c5ab4f6be5&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;2016机器学习与自然语言处理学术全景图：卡耐基梅隆大学排名第一&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720407&amp;amp;idx=3&amp;amp;sn=f8484e3aa14bfe9b925d75bb9acc52e2&amp;amp;chksm=871b0ce9b06c85ff78b2ec6a708e0a9128027a8e862a08a2fca38a17d1aa117f48b27402f133&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720407&amp;amp;idx=3&amp;amp;sn=f8484e3aa14bfe9b925d75bb9acc52e2&amp;amp;chksm=871b0ce9b06c85ff78b2ec6a708e0a9128027a8e862a08a2fca38a17d1aa117f48b27402f133&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;2016年美国机器人路线图出炉，最新机器人产业盘点&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720758&amp;amp;idx=3&amp;amp;sn=0d7e70cfd3624296fc8aac4944a359dc&amp;amp;chksm=871b0d88b06c849e71808681107f2b695233bdd37d7a79249cad5b2721f4285ed50577bee89d&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720758&amp;amp;idx=3&amp;amp;sn=0d7e70cfd3624296fc8aac4944a359dc&amp;amp;chksm=871b0d88b06c849e71808681107f2b695233bdd37d7a79249cad5b2721f4285ed50577bee89d&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;一张图看懂全球Bot布局&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715580&amp;amp;idx=1&amp;amp;sn=cc67a90fe35702732f1a67e3e59d80f6&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715580&amp;amp;idx=1&amp;amp;sn=cc67a90fe35702732f1a67e3e59d80f6&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;Yoshua Bengio：深度学习崛起带来人工智能的春天&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718943&amp;amp;idx=1&amp;amp;sn=258117d392ca1bfc37d6496992da5eae&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718943&amp;amp;idx=1&amp;amp;sn=258117d392ca1bfc37d6496992da5eae&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;神经网络架构演进史：全面回顾从LeNet5到ENet十余种架构&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719010&amp;amp;idx=1&amp;amp;sn=aaa7cc47f27129bbced25e6d090e2c1d&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719010&amp;amp;idx=1&amp;amp;sn=aaa7cc47f27129bbced25e6d090e2c1d&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;Andrej Karpathy：计算机科学博士的生存指南&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721559&amp;amp;idx=3&amp;amp;sn=98a74c48397f8a8d9166a3bf0b74fb4f&amp;amp;chksm=871b0969b06c807f90e72c890c4b23308501f46c7315823c3fee1c423817ed81626d3da9d711&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721559&amp;amp;idx=3&amp;amp;sn=98a74c48397f8a8d9166a3bf0b74fb4f&amp;amp;chksm=871b0969b06c807f90e72c890c4b23308501f46c7315823c3fee1c423817ed81626d3da9d711&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;贝叶斯神经网络简史&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720407&amp;amp;idx=2&amp;amp;sn=86603b0276580e9e969e78cac606fe3c&amp;amp;chksm=871b0ce9b06c85ff79c95b4b42ad8bfa8fa14438266e689e7ffe3a882ee024bfd3e0ac90655e&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720407&amp;amp;idx=2&amp;amp;sn=86603b0276580e9e969e78cac606fe3c&amp;amp;chksm=871b0ce9b06c85ff79c95b4b42ad8bfa8fa14438266e689e7ffe3a882ee024bfd3e0ac90655e&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;百度首席科学家吴恩达刊文：人工智能的能力和不足&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721378&amp;amp;idx=1&amp;amp;sn=16f8a955e1459926dd1e66f82e26028c&amp;amp;chksm=871b081cb06c810aedab8a7c1902daf18f3d00f20c1b04ec0645303ffe2023b5e4dd87c41ee8&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721378&amp;amp;idx=1&amp;amp;sn=16f8a955e1459926dd1e66f82e26028c&amp;amp;chksm=871b081cb06c810aedab8a7c1902daf18f3d00f20c1b04ec0645303ffe2023b5e4dd87c41ee8&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;高盛百页人工智能生态报告：美国仍是主导力量，中国正高速成长&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720663&amp;amp;idx=1&amp;amp;sn=ffadef6ce7d0e2d60e09c0c8bdc366c5&amp;amp;chksm=871b0de9b06c84ffad7621ec0b3e7578d085d9557f029067d978a286e22ff5e67e0b98ed209b&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720663&amp;amp;idx=1&amp;amp;sn=ffadef6ce7d0e2d60e09c0c8bdc366c5&amp;amp;chksm=871b0de9b06c84ffad7621ec0b3e7578d085d9557f029067d978a286e22ff5e67e0b98ed209b&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;伯克利教授Stuart Russell：人工智能基础概念与34个误区&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720174&amp;amp;idx=2&amp;amp;sn=cb195f4dfda478510479eba5dc53fc99&amp;amp;chksm=871b03d0b06c8ac674234d2bcea8515c2720bb502bcb281024b71ebaf4864e1e6fad863d3ebd&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720174&amp;amp;idx=2&amp;amp;sn=cb195f4dfda478510479eba5dc53fc99&amp;amp;chksm=871b03d0b06c8ac674234d2bcea8515c2720bb502bcb281024b71ebaf4864e1e6fad863d3ebd&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;初学者必读：解读14个深度学习关键词&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720335&amp;amp;idx=3&amp;amp;sn=7552135b320b24ce9b273423187b5a78&amp;amp;chksm=871b0c31b06c852753124d9962aff43c049f2283dcfa78cc8ca51289aa0dd2db53d88b2c2e96&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720335&amp;amp;idx=3&amp;amp;sn=7552135b320b24ce9b273423187b5a78&amp;amp;chksm=871b0c31b06c852753124d9962aff43c049f2283dcfa78cc8ca51289aa0dd2db53d88b2c2e96&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;智能时代每个人都应该了解：什么是深度学习？&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720553&amp;amp;idx=2&amp;amp;sn=8f77792079e14219da4006247d738652&amp;amp;chksm=871b0d57b06c84414a164a210ac350e6fc22af6ba06c2604c749776431fef53731c7f40439c7&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720553&amp;amp;idx=2&amp;amp;sn=8f77792079e14219da4006247d738652&amp;amp;chksm=871b0d57b06c84414a164a210ac350e6fc22af6ba06c2604c749776431fef53731c7f40439c7&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;CMU机器学习系负责人：人工智能与人类的未来是共生自主&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715759&amp;amp;idx=2&amp;amp;sn=d005ca89ba3b0bd2eae4b7677cbb8be2&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715759&amp;amp;idx=2&amp;amp;sn=d005ca89ba3b0bd2eae4b7677cbb8be2&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;CMU教授邢波：人工智能的路径、方向与未来&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716455&amp;amp;idx=2&amp;amp;sn=48da4b101ef293de0f627aeb3ba3231b&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716455&amp;amp;idx=2&amp;amp;sn=48da4b101ef293de0f627aeb3ba3231b&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;从供应链优化到差异化定价：机器学习十种方式变革制造业&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721938&amp;amp;idx=1&amp;amp;sn=a7568453296f8b34f1bbb6287cb994d0&amp;amp;chksm=871b0aecb06c83fad3b111c2f48206b26c85762e2b9834a07dddd7a282b60a5df2f78c104de5&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721938&amp;amp;idx=1&amp;amp;sn=a7568453296f8b34f1bbb6287cb994d0&amp;amp;chksm=871b0aecb06c83fad3b111c2f48206b26c85762e2b9834a07dddd7a282b60a5df2f78c104de5&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;对比深度学习十大框架：TensorFlow最流行但并不是最好&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721480&amp;amp;idx=3&amp;amp;sn=0ee6a881f01d8d1bee16d2042ac93e5f&amp;amp;chksm=871b08b6b06c81a027a5b5490f1c9decf3d70002e1f1e1869c25c7a12657f9cfa518b855cf9b&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721480&amp;amp;idx=3&amp;amp;sn=0ee6a881f01d8d1bee16d2042ac93e5f&amp;amp;chksm=871b08b6b06c81a027a5b5490f1c9decf3d70002e1f1e1869c25c7a12657f9cfa518b855cf9b&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;当AI遇上AR ——从微软HPU说起&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720922&amp;amp;idx=5&amp;amp;sn=110bf38376c42b55d95521dd04944828&amp;amp;chksm=871b0ee4b06c87f2315db196b47620853d3587c69f9486cf5ae9a19c5aa2d4fa101f4541888b&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720922&amp;amp;idx=5&amp;amp;sn=110bf38376c42b55d95521dd04944828&amp;amp;chksm=871b0ee4b06c87f2315db196b47620853d3587c69f9486cf5ae9a19c5aa2d4fa101f4541888b&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;洞悉AlphaGo超越围棋大师的力量：机器之心邀你一起强化学习&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719022&amp;amp;idx=2&amp;amp;sn=6efb98d3650bd963122744b14b09e1d9&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719022&amp;amp;idx=2&amp;amp;sn=6efb98d3650bd963122744b14b09e1d9&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;东南大学漆桂林教授：知识图谱不仅是一项技术，更是一项工程&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717374&amp;amp;idx=1&amp;amp;sn=14c7af07c4d6859a7cb8d7a8650d5825&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717374&amp;amp;idx=1&amp;amp;sn=14c7af07c4d6859a7cb8d7a8650d5825&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;人工智能全局概览：通用智能的当前困境和未来可能&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722118&amp;amp;idx=1&amp;amp;sn=1934dfd96eedb777b506a7f9fca1c44a&amp;amp;chksm=871b0b38b06c822e4419d7263ece28aa7ad683c4478eb908397c2fae2aa7505529f9708c72d4&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722118&amp;amp;idx=1&amp;amp;sn=1934dfd96eedb777b506a7f9fca1c44a&amp;amp;chksm=871b0b38b06c822e4419d7263ece28aa7ad683c4478eb908397c2fae2aa7505529f9708c72d4&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;访谈百度IDL林元庆：百度大脑如何在人脸识别上战胜人类「最强大脑」&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720302&amp;amp;idx=4&amp;amp;sn=5a54ac9d2097f0db11d1da8a65cf2e4c&amp;amp;chksm=871b0c50b06c85466eb0bb5e455e306deca82662d83895f9d6ad2311539a9adf7056dac306ac&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720302&amp;amp;idx=4&amp;amp;sn=5a54ac9d2097f0db11d1da8a65cf2e4c&amp;amp;chksm=871b0c50b06c85466eb0bb5e455e306deca82662d83895f9d6ad2311539a9adf7056dac306ac&amp;amp;scene=21#wechat_redirect"&gt;TensorFlow 生态系统：与多种开源框架的融合&amp;nbsp;&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719511&amp;amp;idx=2&amp;amp;sn=ef5f5c1d8d70cc81cdcd2c6fde36f695&amp;amp;chksm=871b0169b06c887f46d4b87987bd58881875f352c3bdb5d8c2e39d9898b6bcac8b7c0c31783d&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719511&amp;amp;idx=2&amp;amp;sn=ef5f5c1d8d70cc81cdcd2c6fde36f695&amp;amp;chksm=871b0169b06c887f46d4b87987bd58881875f352c3bdb5d8c2e39d9898b6bcac8b7c0c31783d&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;Kaggle创始人问答：深度学习会淘汰其他的机器学习方法吗？&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721755&amp;amp;idx=1&amp;amp;sn=61837dc0127c1c829522e1772959a0dd&amp;amp;chksm=871b09a5b06c80b3d89848a140f13519bf2c3e264724a8604603751079f43252365e5f40dadd&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721755&amp;amp;idx=1&amp;amp;sn=61837dc0127c1c829522e1772959a0dd&amp;amp;chksm=871b09a5b06c80b3d89848a140f13519bf2c3e264724a8604603751079f43252365e5f40dadd&amp;amp;scene=21#wechat_redirect"&gt;机器之心年度盘点 | 从技术角度，回顾2016年语音识别的发展&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719333&amp;amp;idx=2&amp;amp;sn=ba2491a4c22da7512d9add55c1ac50ee&amp;amp;chksm=871b001bb06c890d71a688cd127557913694240b6a81ea1681552677d63cec27fcd45570dc4d&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719333&amp;amp;idx=2&amp;amp;sn=ba2491a4c22da7512d9add55c1ac50ee&amp;amp;chksm=871b001bb06c890d71a688cd127557913694240b6a81ea1681552677d63cec27fcd45570dc4d&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;机器学习的基本局限性：从一个数学脑筋急转弯说起&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721777&amp;amp;idx=3&amp;amp;sn=20cf64536919147639b2f5cbad38df0f&amp;amp;chksm=871b098fb06c80995100a9afee640203b14f5429f72ee9259b01b6c87d72396beeecdea99144&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721777&amp;amp;idx=3&amp;amp;sn=20cf64536919147639b2f5cbad38df0f&amp;amp;chksm=871b098fb06c80995100a9afee640203b14f5429f72ee9259b01b6c87d72396beeecdea99144&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;人们都在说人工智能，其实现在我们真正做的是智能增强&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717606&amp;amp;idx=4&amp;amp;sn=b94b58d4fe75c1a1e42274720a269a99&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717606&amp;amp;idx=4&amp;amp;sn=b94b58d4fe75c1a1e42274720a269a99&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;人工智能、机器学习、深度学习，三者之间的同心圆关系&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722126&amp;amp;idx=1&amp;amp;sn=00b5c6ed7e4c576c8be3eae1dc348cfe&amp;amp;chksm=871b0b30b06c8226b163198b78ad40b52715509d3b36f0774670d6e0e284378cc3bdeca42d4a&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722126&amp;amp;idx=1&amp;amp;sn=00b5c6ed7e4c576c8be3eae1dc348cfe&amp;amp;chksm=871b0b30b06c8226b163198b78ad40b52715509d3b36f0774670d6e0e284378cc3bdeca42d4a&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;R vs Python：R是现在最好的数据科学语言吗？&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722239&amp;amp;idx=3&amp;amp;sn=aa556d22c8dc71195175930fda1655d0&amp;amp;chksm=871b0bc1b06c82d70e62081d87c1e75291ea15f631aff5c0a5d03de41ffbbcc4be650e63b014&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722239&amp;amp;idx=3&amp;amp;sn=aa556d22c8dc71195175930fda1655d0&amp;amp;chksm=871b0bc1b06c82d70e62081d87c1e75291ea15f631aff5c0a5d03de41ffbbcc4be650e63b014&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;斯坦福NLP团队介绍交互式语言学习：从语言游戏到日程规划&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720597&amp;amp;idx=2&amp;amp;sn=815b3426c4855e446e4aa118abdee0d6&amp;amp;chksm=871b0d2bb06c843da11f16f85510da8cb398542c82a80a8822ac9f78beb24aaf58f066eaaed2&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720597&amp;amp;idx=2&amp;amp;sn=815b3426c4855e446e4aa118abdee0d6&amp;amp;chksm=871b0d2bb06c843da11f16f85510da8cb398542c82a80a8822ac9f78beb24aaf58f066eaaed2&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;斯坦福大学副教授Reza Zadeh：神经网络越深就越难优化&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=402228099&amp;amp;idx=1&amp;amp;sn=a8e664d332f7d28250fbbf357c773f62&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=402228099&amp;amp;idx=1&amp;amp;sn=a8e664d332f7d28250fbbf357c773f62&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;神经网络和深度学习简史（三）：强化学习与递归神经网络&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=402552632&amp;amp;idx=1&amp;amp;sn=694a4a327a79c4efeeb4db15b3ff4a28&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=402552632&amp;amp;idx=1&amp;amp;sn=694a4a327a79c4efeeb4db15b3ff4a28&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;神经网络和深度学习简史（四）：深度学习终迎伟大复兴&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717977&amp;amp;idx=2&amp;amp;sn=705d47688adadcdce6e09a81e3381e2d&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717977&amp;amp;idx=2&amp;amp;sn=705d47688adadcdce6e09a81e3381e2d&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;深度学习技术在股票交易上的应用研究调查&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721378&amp;amp;idx=4&amp;amp;sn=cb49818959281909d8878bea5b34e837&amp;amp;chksm=871b081cb06c810a0075a475beeecbbe41a915679f05d629aa2e4d3a38da45e0899a764a98be&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721378&amp;amp;idx=4&amp;amp;sn=cb49818959281909d8878bea5b34e837&amp;amp;chksm=871b081cb06c810a0075a475beeecbbe41a915679f05d629aa2e4d3a38da45e0899a764a98be&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;深度学习十大飙升趋势&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=401846516&amp;amp;idx=1&amp;amp;sn=ed76da1e8f99c604957c8889692de884&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=401846516&amp;amp;idx=1&amp;amp;sn=ed76da1e8f99c604957c8889692de884&amp;amp;scene=21#wechat_redirect"&gt;深度学习入门，以及它在物联网和智慧城市中的角色&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720765&amp;amp;idx=3&amp;amp;sn=a9ec5e451cc7e46ab254b663ec78c3b6&amp;amp;chksm=871b0d83b06c8495b977ba6f82c3aa5974a6d2066e3fec63f9fc33e7e0766a2008804795895e&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720765&amp;amp;idx=3&amp;amp;sn=a9ec5e451cc7e46ab254b663ec78c3b6&amp;amp;chksm=871b0d83b06c8495b977ba6f82c3aa5974a6d2066e3fec63f9fc33e7e0766a2008804795895e&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;服务器端人工智能，FPGA和GPU到底谁更强？&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721102&amp;amp;idx=1&amp;amp;sn=347d3a3b5fd136df7bc51fb67948fd30&amp;amp;chksm=871b0f30b06c86263fd2d51665aaa5e81d1e3cbc0044ed71ab0f74238a461ba0e75490a04af7&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721102&amp;amp;idx=1&amp;amp;sn=347d3a3b5fd136df7bc51fb67948fd30&amp;amp;chksm=871b0f30b06c86263fd2d51665aaa5e81d1e3cbc0044ed71ab0f74238a461ba0e75490a04af7&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;Science「机器人子刊」创刊号，五大研究解读机器人领域最新进展&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718975&amp;amp;idx=1&amp;amp;sn=2b0ccf0c746e6f10707e5357168d51d6&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718975&amp;amp;idx=1&amp;amp;sn=2b0ccf0c746e6f10707e5357168d51d6&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;西红柿还是猕猴桃？一个案例帮你入门机器学习&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715201&amp;amp;idx=1&amp;amp;sn=d7ad8c79bf060875b6247d634c52449b&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715201&amp;amp;idx=1&amp;amp;sn=d7ad8c79bf060875b6247d634c52449b&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;详细解读神经网络十大误解，再也不会弄错它的工作原理&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719646&amp;amp;idx=2&amp;amp;sn=3f84e8af0ca03476eb843f57b497465e&amp;amp;chksm=871b01e0b06c88f6c77601db4a1d224a5007ba306eac7d0522c0b973ca9c3d57c4fabf57a5c4&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719646&amp;amp;idx=2&amp;amp;sn=3f84e8af0ca03476eb843f57b497465e&amp;amp;chksm=871b01e0b06c88f6c77601db4a1d224a5007ba306eac7d0522c0b973ca9c3d57c4fabf57a5c4&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;基于图的机器学习技术：谷歌众多产品和服务背后的智能&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;三、技术起点&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWic17FA5ZBlbiaEavsI2wmR5XUUmTqyW1ichwTzcwbmWWCEickQ9R8YSQibE6icRr4oicQsJeDPxKUOSAXHA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719723&amp;amp;idx=4&amp;amp;sn=f86e2f30bcee67a424d4617b72560b8d&amp;amp;chksm=871b0195b06c88832108944311c2494a30483590c8c301b0076e2190734a3271e2929db312ed&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719723&amp;amp;idx=4&amp;amp;sn=f86e2f30bcee67a424d4617b72560b8d&amp;amp;chksm=871b0195b06c88832108944311c2494a30483590c8c301b0076e2190734a3271e2929db312ed&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;10种深度学习算法的TensorFlow实现&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719794&amp;amp;idx=2&amp;amp;sn=8e320caa1d32f7a444a17bfa93b318ad&amp;amp;chksm=871b024cb06c8b5a421efa2eedff5b7149d17028d99e95a38857785db06c1eb2b7796d6e7e4f&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719794&amp;amp;idx=2&amp;amp;sn=8e320caa1d32f7a444a17bfa93b318ad&amp;amp;chksm=871b024cb06c8b5a421efa2eedff5b7149d17028d99e95a38857785db06c1eb2b7796d6e7e4f&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;数十种TensorFlow实现案例汇集：代码+笔记&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720367&amp;amp;idx=2&amp;amp;sn=d71e1e6550faece1cb5fb58bd7c919d9&amp;amp;chksm=871b0c11b06c8507d765a781b3ff49c1755deba7f12f36763b468aa23dfafccd768f59538004&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720367&amp;amp;idx=2&amp;amp;sn=d71e1e6550faece1cb5fb58bd7c919d9&amp;amp;chksm=871b0c11b06c8507d765a781b3ff49c1755deba7f12f36763b468aa23dfafccd768f59538004&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;机器学习入门必备：如何用Python从头实现感知器算法&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718527&amp;amp;idx=1&amp;amp;sn=04db4fc59cc23c079a17573657d2b1c7&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718527&amp;amp;idx=1&amp;amp;sn=04db4fc59cc23c079a17573657d2b1c7&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;ACM 最新月刊文章：强化学习的复兴&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720174&amp;amp;idx=4&amp;amp;sn=da197d35bf9b5ac59b9ffb8e442264f0&amp;amp;chksm=871b03d0b06c8ac622e5ff2b83c786b7fb34d49b6186f1d9f1964b28e31c1e0d7b2ac3863afc&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720174&amp;amp;idx=4&amp;amp;sn=da197d35bf9b5ac59b9ffb8e442264f0&amp;amp;chksm=871b03d0b06c8ac622e5ff2b83c786b7fb34d49b6186f1d9f1964b28e31c1e0d7b2ac3863afc&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;人工智能开发者的入门指南&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717691&amp;amp;idx=2&amp;amp;sn=3f0b66aa9706aae1a30b01309aa0214c&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717691&amp;amp;idx=2&amp;amp;sn=3f0b66aa9706aae1a30b01309aa0214c&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;从入门到精通：卷积神经网络初学者指南&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718466&amp;amp;idx=1&amp;amp;sn=016f111001e8354d49dd4ce279d283cd&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718466&amp;amp;idx=1&amp;amp;sn=016f111001e8354d49dd4ce279d283cd&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;机器学习敲门砖：任何人都能看懂的TensorFlow介绍&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720463&amp;amp;idx=2&amp;amp;sn=50d88169778ec31a1e1e2d801325005d&amp;amp;chksm=871b0cb1b06c85a7e0299fc733b67d3107970f1176186a2ac8ca2dd5a23d896b5041e592ab4d&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720463&amp;amp;idx=2&amp;amp;sn=50d88169778ec31a1e1e2d801325005d&amp;amp;chksm=871b0cb1b06c85a7e0299fc733b67d3107970f1176186a2ac8ca2dd5a23d896b5041e592ab4d&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;DeepMind提出的可微神经计算机架构的TensorFlow实现&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718229&amp;amp;idx=4&amp;amp;sn=f47990a661e1522a5794d6334a334830&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718229&amp;amp;idx=4&amp;amp;sn=f47990a661e1522a5794d6334a334830&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;RNN 怎么用？给初学者的小教程&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=401970614&amp;amp;idx=2&amp;amp;sn=479370f70613e431d35c752139c0b602&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=401970614&amp;amp;idx=2&amp;amp;sn=479370f70613e431d35c752139c0b602&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;深度学习教程：从感知器到深层网络&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721559&amp;amp;idx=4&amp;amp;sn=950d87934d39712fab6164d3d2a37be5&amp;amp;chksm=871b0969b06c807f47b6fac20daae25d6d2f57495f6624554550fad7177f56657d208f40690d&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721559&amp;amp;idx=4&amp;amp;sn=950d87934d39712fab6164d3d2a37be5&amp;amp;chksm=871b0969b06c807f47b6fac20daae25d6d2f57495f6624554550fad7177f56657d208f40690d&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;OpenAI 的 PixelCNN++实现：基于 Python的实现&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719828&amp;amp;idx=2&amp;amp;sn=c6a73c885c3a8db5f2b0484f7c20498a&amp;amp;chksm=871b022ab06c8b3c8e93ff797be2d68d96945f01b617584e79593e16dcd4a76b19a4642b441d&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719828&amp;amp;idx=2&amp;amp;sn=c6a73c885c3a8db5f2b0484f7c20498a&amp;amp;chksm=871b022ab06c8b3c8e93ff797be2d68d96945f01b617584e79593e16dcd4a76b19a4642b441d&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;Geoffrey Hinton最新演讲梳理：从人工神经网络到RNN应用&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717557&amp;amp;idx=1&amp;amp;sn=6c8239ec01c2a3f0def744063d070eec&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717557&amp;amp;idx=1&amp;amp;sn=6c8239ec01c2a3f0def744063d070eec&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;官方指南：如何通过玩TensorFlow来理解神经网络&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720174&amp;amp;idx=1&amp;amp;sn=d770ab6ccbf25c6569d002472daf1b3b&amp;amp;chksm=871b03d0b06c8ac6c16a6e37e1dcc2a5f490e4ab5a21b82b76a2a41d3a1d35d76a6a3d21fdc3&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720174&amp;amp;idx=1&amp;amp;sn=d770ab6ccbf25c6569d002472daf1b3b&amp;amp;chksm=871b03d0b06c8ac6c16a6e37e1dcc2a5f490e4ab5a21b82b76a2a41d3a1d35d76a6a3d21fdc3&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;一篇文章带你进入无监督学习:从基本概念到四种实现模型&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721979&amp;amp;idx=2&amp;amp;sn=146a34534414fb4842398cac62cd201a&amp;amp;chksm=871b0ac5b06c83d3eeb71d5b39d74f9d5648d7e334039cf6d6a3d42b18856abc47ba229b8890&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721979&amp;amp;idx=2&amp;amp;sn=146a34534414fb4842398cac62cd201a&amp;amp;chksm=871b0ac5b06c83d3eeb71d5b39d74f9d5648d7e334039cf6d6a3d42b18856abc47ba229b8890&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;NIPS 2016上22篇论文的实现汇集&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721979&amp;amp;idx=1&amp;amp;sn=82ccf18462e569d43d72736aef57177a&amp;amp;chksm=871b0ac5b06c83d30e65fcd1344bf4b9773281af6cd58f4d3e6709f24d66f6c2bbbfaddb8ccf&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721979&amp;amp;idx=1&amp;amp;sn=82ccf18462e569d43d72736aef57177a&amp;amp;chksm=871b0ac5b06c83d30e65fcd1344bf4b9773281af6cd58f4d3e6709f24d66f6c2bbbfaddb8ccf&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;机器学习初学者入门实践：怎样轻松创造高精度分类网络&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718717&amp;amp;idx=1&amp;amp;sn=85038d7c906c135120a8e1a2f7e565ad&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718717&amp;amp;idx=1&amp;amp;sn=85038d7c906c135120a8e1a2f7e565ad&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;解决真实世界问题：如何在不平衡类上使用机器学习？&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717628&amp;amp;idx=1&amp;amp;sn=a6f1b35f8168f1bc842ca36bb3a69368&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717628&amp;amp;idx=1&amp;amp;sn=a6f1b35f8168f1bc842ca36bb3a69368&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;卷积神经网络架构详解：它与神经网络有何不同？&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717709&amp;amp;idx=2&amp;amp;sn=2bff1e56bc75d65e178476ea9a93b2c5&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717709&amp;amp;idx=2&amp;amp;sn=2bff1e56bc75d65e178476ea9a93b2c5&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;LSTM和递归网络基础教程&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718717&amp;amp;idx=2&amp;amp;sn=9cf62b1b684f5dea3c735d1413a50689&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718717&amp;amp;idx=2&amp;amp;sn=9cf62b1b684f5dea3c735d1413a50689&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;门外汉如何使用谷歌的Prediction API做机器学习&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718597&amp;amp;idx=2&amp;amp;sn=98c141c6d73eb62a0f3f8aa2a8231b66&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718597&amp;amp;idx=2&amp;amp;sn=98c141c6d73eb62a0f3f8aa2a8231b66&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;NVIDIA趣味解读：深度学习训练和推理有何不同？&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722126&amp;amp;idx=4&amp;amp;sn=96b2fa1fe3fc858d415ddddf2ac3f8e5&amp;amp;chksm=871b0b30b06c82262fec886bc76b0427542dcf8b1fb4bae62d851d032e4fc22d247e981f263f&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722126&amp;amp;idx=4&amp;amp;sn=96b2fa1fe3fc858d415ddddf2ac3f8e5&amp;amp;chksm=871b0b30b06c82262fec886bc76b0427542dcf8b1fb4bae62d851d032e4fc22d247e981f263f&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;如何利用 Python 打造一款简易版 AlphaGo&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715104&amp;amp;idx=2&amp;amp;sn=f6ba338c02f8e08c7821b4ecd5a527e9&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715104&amp;amp;idx=2&amp;amp;sn=f6ba338c02f8e08c7821b4ecd5a527e9&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;如何用图像识别技术来变革商业？这里有份操作指南&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719093&amp;amp;idx=4&amp;amp;sn=d852318f6b3adb5ef7730def66fb0a93&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719093&amp;amp;idx=4&amp;amp;sn=d852318f6b3adb5ef7730def66fb0a93&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;MIT生成视频模型，预测静态图片的未来场景&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720257&amp;amp;idx=1&amp;amp;sn=92ac1424c5880a406c1a00558359792b&amp;amp;chksm=871b0c7fb06c8569e23927623aa3c98af8a3377069ba6cd11a0acecb54cd8ce7896e29238b97&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720257&amp;amp;idx=1&amp;amp;sn=92ac1424c5880a406c1a00558359792b&amp;amp;chksm=871b0c7fb06c8569e23927623aa3c98af8a3377069ba6cd11a0acecb54cd8ce7896e29238b97&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;EMNLP 2016干货：从原理到代码全面剖析可用于NLP的神经网络&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718504&amp;amp;idx=1&amp;amp;sn=ba884ec5bd9dd93b77c85f91d8371056&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718504&amp;amp;idx=1&amp;amp;sn=ba884ec5bd9dd93b77c85f91d8371056&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;使用机器学习翻译语言：神经网络和seq2seq为何效果非凡？&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720758&amp;amp;idx=1&amp;amp;sn=3004c425e0d427f4900a182d74bed31d&amp;amp;chksm=871b0d88b06c849e951469ae1ed54e5f66074d6322eb6681c85727bb8199154709c04c48c034&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720758&amp;amp;idx=1&amp;amp;sn=3004c425e0d427f4900a182d74bed31d&amp;amp;chksm=871b0d88b06c849e951469ae1ed54e5f66074d6322eb6681c85727bb8199154709c04c48c034&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;神经网络快速入门：什么是多层感知器和反向传播？&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718853&amp;amp;idx=4&amp;amp;sn=4f33d503f1602e608b34c6cda4e55dad&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718853&amp;amp;idx=4&amp;amp;sn=4f33d503f1602e608b34c6cda4e55dad&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;神经网络中激活函数的作用&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720582&amp;amp;idx=2&amp;amp;sn=06076c800c912622d8fa42665d7de1fc&amp;amp;chksm=871b0d38b06c842e3f6edaa5d36046b6702d26a0bcfb710c2010e5f0815389bf4f60077441ef&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720582&amp;amp;idx=2&amp;amp;sn=06076c800c912622d8fa42665d7de1fc&amp;amp;chksm=871b0d38b06c842e3f6edaa5d36046b6702d26a0bcfb710c2010e5f0815389bf4f60077441ef&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;逐层剖析，谷歌机器翻译突破背后的神经网络架构是怎样的？&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719294&amp;amp;idx=1&amp;amp;sn=f1a01cd6710e6ea9629619cd3324d102&amp;amp;chksm=871b0040b06c895642ff961a6fe81f05c5e9776aff5da4845f2d3d874f88213863afd2059833&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719294&amp;amp;idx=1&amp;amp;sn=f1a01cd6710e6ea9629619cd3324d102&amp;amp;chksm=871b0040b06c895642ff961a6fe81f05c5e9776aff5da4845f2d3d874f88213863afd2059833&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;深度学习漫游指南：强化学习概览&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717969&amp;amp;idx=1&amp;amp;sn=712e4880e63db42bcb4db5ba06c9856d&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717969&amp;amp;idx=1&amp;amp;sn=712e4880e63db42bcb4db5ba06c9856d&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;深度学习与神经网络全局概览：核心技术的发展历程&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=402261356&amp;amp;idx=1&amp;amp;sn=f66ee62b002b8a9879d3c428f846e440&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=402261356&amp;amp;idx=1&amp;amp;sn=f66ee62b002b8a9879d3c428f846e440&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;最全的深度学习硬件指南&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719118&amp;amp;idx=2&amp;amp;sn=fad8b7cad70cc6a227f88ae07a89db66&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719118&amp;amp;idx=2&amp;amp;sn=fad8b7cad70cc6a227f88ae07a89db66&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;主流深度学习框架对比：看你最适合哪一款？&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;四、继续进阶&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWic17FA5ZBlbiaEavsI2wmR5XyMML92qa5OichfA9LIr2ZV4hAIqkcSaVZr3RiajjE1rR2Vic6SDlQebXA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720132&amp;amp;idx=1&amp;amp;sn=d630d47c4ab60d35752aba74a9d53361&amp;amp;chksm=871b03fab06c8aec767776a6a4a407c3897dcad26392b24a22536261565e9dc6b5ce52df0816&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720132&amp;amp;idx=1&amp;amp;sn=d630d47c4ab60d35752aba74a9d53361&amp;amp;chksm=871b03fab06c8aec767776a6a4a407c3897dcad26392b24a22536261565e9dc6b5ce52df0816&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;40年认知架构研究概览：实现通用人工智能的道路上我们已走了多远？&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721682&amp;amp;idx=1&amp;amp;sn=6bdbf5739bb312449cb60cb6679f98d2&amp;amp;chksm=871b09ecb06c80fa59dba741fb79e44021d5ae16f67488c38b3fb477235a203931da86c829bc&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721682&amp;amp;idx=1&amp;amp;sn=6bdbf5739bb312449cb60cb6679f98d2&amp;amp;chksm=871b09ecb06c80fa59dba741fb79e44021d5ae16f67488c38b3fb477235a203931da86c829bc&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;第四范式联合创始人陈雨强：机器学习在工业应用中的新思考&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719971&amp;amp;idx=2&amp;amp;sn=c7e0d1f6dd4e9ddce291e9bc2c85c65f&amp;amp;chksm=871b029db06c8b8b7557095989dd3fdb57b86a1d7923c388ca1e74255d07f08992bb0461d958&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719971&amp;amp;idx=2&amp;amp;sn=c7e0d1f6dd4e9ddce291e9bc2c85c65f&amp;amp;chksm=871b029db06c8b8b7557095989dd3fdb57b86a1d7923c388ca1e74255d07f08992bb0461d958&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;词嵌入系列博客Part1：基于语言建模的词嵌入模型&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720050&amp;amp;idx=2&amp;amp;sn=9fedc937d3128462c478ef7911e77687&amp;amp;chksm=871b034cb06c8a5a8db8a10f708c81025fc62084d871ac5d184bab5098cb64e939c1c23a7369&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720050&amp;amp;idx=2&amp;amp;sn=9fedc937d3128462c478ef7911e77687&amp;amp;chksm=871b034cb06c8a5a8db8a10f708c81025fc62084d871ac5d184bab5098cb64e939c1c23a7369&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;词嵌入系列博客Part2：比较语言建模中近似 softmax 的几种方法&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720074&amp;amp;idx=2&amp;amp;sn=183fc6285835a48ae7c6bbcce228b063&amp;amp;chksm=871b0334b06c8a22b072f61d4f914210468db7df36a1c6586bd9b6bf3fc6d9f821101d5254c0&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720074&amp;amp;idx=2&amp;amp;sn=183fc6285835a48ae7c6bbcce228b063&amp;amp;chksm=871b0334b06c8a22b072f61d4f914210468db7df36a1c6586bd9b6bf3fc6d9f821101d5254c0&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;词嵌入系列博客Part3：word2vec 的秘密配方&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718853&amp;amp;idx=1&amp;amp;sn=17462cfef179876db1f9d29dbd95ba2c&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718853&amp;amp;idx=1&amp;amp;sn=17462cfef179876db1f9d29dbd95ba2c&amp;amp;scene=21#wechat_redirect"&gt;从分割到识别，全面解析Facebook开源的3款机器视觉工具&amp;nbsp;&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718786&amp;amp;idx=1&amp;amp;sn=58e6cdf2ffb0f47eb831e0cd623ce0e1&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718786&amp;amp;idx=1&amp;amp;sn=58e6cdf2ffb0f47eb831e0cd623ce0e1&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;从硬件到软件：OpenAI 解读自家的深度学习基础架构&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719694&amp;amp;idx=1&amp;amp;sn=93c5aa0b6dd9cdb35c8b8186ce70afff&amp;amp;chksm=871b01b0b06c88a6ee9c3264e67b3e3256f007c4046fefb1d003f91ada71d00547f91b48ca21&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719694&amp;amp;idx=1&amp;amp;sn=93c5aa0b6dd9cdb35c8b8186ce70afff&amp;amp;chksm=871b01b0b06c88a6ee9c3264e67b3e3256f007c4046fefb1d003f91ada71d00547f91b48ca21&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;分布式深度学习：神经网络的分布式训练&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720463&amp;amp;idx=4&amp;amp;sn=ddffc71e49002f731ada533cf05cc84d&amp;amp;chksm=871b0cb1b06c85a73aeb3562836c2ff15357417ce7106ceed06f8987b1cdb70a990895592e9d&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720463&amp;amp;idx=4&amp;amp;sn=ddffc71e49002f731ada533cf05cc84d&amp;amp;chksm=871b0cb1b06c85a73aeb3562836c2ff15357417ce7106ceed06f8987b1cdb70a990895592e9d&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;Embedding 新框架模型：Exponential Family Embeddings&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719294&amp;amp;idx=3&amp;amp;sn=d23a6d7c03732f7218f70447336801bd&amp;amp;chksm=871b0040b06c89564722f7292215997f474374d43d26761700f00b240e83a9c5dc2dd7595a26&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719294&amp;amp;idx=3&amp;amp;sn=d23a6d7c03732f7218f70447336801bd&amp;amp;chksm=871b0040b06c89564722f7292215997f474374d43d26761700f00b240e83a9c5dc2dd7595a26&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;FPGA vs. ASIC，谁将引领移动端人工智能潮流？&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717977&amp;amp;idx=3&amp;amp;sn=e07366137aab6694c3d3d4a311ed6c54&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717977&amp;amp;idx=3&amp;amp;sn=e07366137aab6694c3d3d4a311ed6c54&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;概述性论文：卷积神经网络的近期研究进展&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715279&amp;amp;idx=2&amp;amp;sn=fd25ed0539b7bf8e79f5e99eea47b889&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715279&amp;amp;idx=2&amp;amp;sn=fd25ed0539b7bf8e79f5e99eea47b889&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;《Nature》 封面文章：人工智能引发材料科学变革&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721922&amp;amp;idx=3&amp;amp;sn=b7af3daa477955e0466c521fd45a23e6&amp;amp;chksm=871b0afcb06c83ead80f3cc7e2e650ba441d4068ecd10532272fc4c0b88aadf8b9b24fa8cc19&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721922&amp;amp;idx=3&amp;amp;sn=b7af3daa477955e0466c521fd45a23e6&amp;amp;chksm=871b0afcb06c83ead80f3cc7e2e650ba441d4068ecd10532272fc4c0b88aadf8b9b24fa8cc19&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;概述论文：迁移学习研究全貌&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721602&amp;amp;idx=2&amp;amp;sn=f18e2d3a23dec485350611651e571031&amp;amp;chksm=871b093cb06c802aecc953e10c6bf5a14784ce3bad2c82170262ed6d6d7daedfcea9cceb804d&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721602&amp;amp;idx=2&amp;amp;sn=f18e2d3a23dec485350611651e571031&amp;amp;chksm=871b093cb06c802aecc953e10c6bf5a14784ce3bad2c82170262ed6d6d7daedfcea9cceb804d&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;Andrej Karpathy：你为什么应该理解反向传播&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721284&amp;amp;idx=1&amp;amp;sn=427e7f45c8253ab22a3960978409f5d1&amp;amp;chksm=871b087ab06c816c424ad03810be3e1b3aa9d6e99a5f325047796f110d178a07736f667d1a10&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721284&amp;amp;idx=1&amp;amp;sn=427e7f45c8253ab22a3960978409f5d1&amp;amp;chksm=871b087ab06c816c424ad03810be3e1b3aa9d6e99a5f325047796f110d178a07736f667d1a10&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;GAN之父NIPS 2016演讲现场直击：全方位解读生成对抗网络的原理及未来&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719228&amp;amp;idx=2&amp;amp;sn=b3ccd8c77c2ef81369c02b85de013038&amp;amp;chksm=871b0782b06c8e94e88ce927f8357a6637b051c9f2ace9dbadea84c77b1b8ca0fec7efdb7448&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719228&amp;amp;idx=2&amp;amp;sn=b3ccd8c77c2ef81369c02b85de013038&amp;amp;chksm=871b0782b06c8e94e88ce927f8357a6637b051c9f2ace9dbadea84c77b1b8ca0fec7efdb7448&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;Google Brain 讲解注意力模型和增强RNN&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719723&amp;amp;idx=2&amp;amp;sn=03925a0eb5a8b78cc2642781b924032c&amp;amp;chksm=871b0195b06c888336f97ac330524580589bf29b073aa76585319a6ad43744a5697d6a424b0f&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719723&amp;amp;idx=2&amp;amp;sn=03925a0eb5a8b78cc2642781b924032c&amp;amp;chksm=871b0195b06c888336f97ac330524580589bf29b073aa76585319a6ad43744a5697d6a424b0f&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;谷歌Magenta项目是如何教神经网络编写音乐的？&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721644&amp;amp;idx=4&amp;amp;sn=51ff444c29797ea83f55f47c694b2e84&amp;amp;chksm=871b0912b06c8004a9d5cf461a496b693f5c5010896a0b32f1ae5ede9ab32ce2de4b2a8f37b0&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721644&amp;amp;idx=4&amp;amp;sn=51ff444c29797ea83f55f47c694b2e84&amp;amp;chksm=871b0912b06c8004a9d5cf461a496b693f5c5010896a0b32f1ae5ede9ab32ce2de4b2a8f37b0&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;基于MXNet 的神经机器翻译实现&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721121&amp;amp;idx=3&amp;amp;sn=e21d84cb34b75b744a31fb27c3af8528&amp;amp;chksm=871b0f1fb06c8609de11c76854c1ad9582aece4b79eed6d94b588498109d78a2c62ffe69e02c&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721121&amp;amp;idx=3&amp;amp;sn=e21d84cb34b75b744a31fb27c3af8528&amp;amp;chksm=871b0f1fb06c8609de11c76854c1ad9582aece4b79eed6d94b588498109d78a2c62ffe69e02c&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;2016深度学习重大进展：从无监督学习到生成对抗网络&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715145&amp;amp;idx=1&amp;amp;sn=84ddd1cbb981e260e49100ec39d01663&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715145&amp;amp;idx=1&amp;amp;sn=84ddd1cbb981e260e49100ec39d01663&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;深度学习遇上基因组，诊断疾病和揭示深层生物原理或迎来突破&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719794&amp;amp;idx=3&amp;amp;sn=a64c739eab79f95c85685db7b06d3649&amp;amp;chksm=871b024cb06c8b5aa3e8b3ddd59de64dcf32f05b068bda1fa6c9400a491de6f63b1ca4a81d14&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719794&amp;amp;idx=3&amp;amp;sn=a64c739eab79f95c85685db7b06d3649&amp;amp;chksm=871b024cb06c8b5aa3e8b3ddd59de64dcf32f05b068bda1fa6c9400a491de6f63b1ca4a81d14&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;King+Woman-Man=Queen:用基于Spark的机器学习来捕捉词意&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721817&amp;amp;idx=2&amp;amp;sn=110962b592985cb01216feafe0d8510e&amp;amp;chksm=871b0a67b06c8371b96cff1675cc762f4677dc02a94d985c21c28ba8af1c1afccca64080e41f&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721817&amp;amp;idx=2&amp;amp;sn=110962b592985cb01216feafe0d8510e&amp;amp;chksm=871b0a67b06c8371b96cff1675cc762f4677dc02a94d985c21c28ba8af1c1afccca64080e41f&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;初学者必读:从迭代的五个层面理解机器学习&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722553&amp;amp;idx=5&amp;amp;sn=81228e1becc1895699fd5a87e120be05&amp;amp;chksm=871b1487b06c9d915136b64c14800f60af13ac956060716b654b1a8944beffe0947b036cce47&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722553&amp;amp;idx=5&amp;amp;sn=81228e1becc1895699fd5a87e120be05&amp;amp;chksm=871b1487b06c9d915136b64c14800f60af13ac956060716b654b1a8944beffe0947b036cce47&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;轻量级Matlab深度学习框架LightNet的实现&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650714956&amp;amp;idx=3&amp;amp;sn=de8326724feb96cd5891e6198226a365&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650714956&amp;amp;idx=3&amp;amp;sn=de8326724feb96cd5891e6198226a365&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;如何基于机器学习设计一套智能交易系统？&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718229&amp;amp;idx=1&amp;amp;sn=adaf68f2c193028f1c4de5b8d3217cca&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718229&amp;amp;idx=1&amp;amp;sn=adaf68f2c193028f1c4de5b8d3217cca&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;如何在TensorFlow中用深度学习修复图像？&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720420&amp;amp;idx=2&amp;amp;sn=179fa42fafe685265fef3b88f186fd62&amp;amp;chksm=871b0cdab06c85cc1500ab14605fe2848188bb55cebd0cfdb1af6c6b1e0c1d2f2b3cf886394a&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720420&amp;amp;idx=2&amp;amp;sn=179fa42fafe685265fef3b88f186fd62&amp;amp;chksm=871b0cdab06c85cc1500ab14605fe2848188bb55cebd0cfdb1af6c6b1e0c1d2f2b3cf886394a&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;机器学习中的并行计算：GPU、CUDA和实际应用&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720922&amp;amp;idx=5&amp;amp;sn=110bf38376c42b55d95521dd04944828&amp;amp;chksm=871b0ee4b06c87f2315db196b47620853d3587c69f9486cf5ae9a19c5aa2d4fa101f4541888b&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720922&amp;amp;idx=5&amp;amp;sn=110bf38376c42b55d95521dd04944828&amp;amp;chksm=871b0ee4b06c87f2315db196b47620853d3587c69f9486cf5ae9a19c5aa2d4fa101f4541888b&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;深度解读AlphaGo胜利背后的力量：强化学习&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718429&amp;amp;idx=1&amp;amp;sn=46214968459af95e85efe12b8a26b11b&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718429&amp;amp;idx=1&amp;amp;sn=46214968459af95e85efe12b8a26b11b&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;英伟达自动驾驶技术解读：用于自动驾驶汽车的端到端深度学习&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720663&amp;amp;idx=3&amp;amp;sn=d9f671f77be23a148d1830448154a545&amp;amp;chksm=871b0de9b06c84ffaf260b9ba2a010108cca62d5ce3dcbd8c98c72c9f786f9cd460b27b496ca&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720663&amp;amp;idx=3&amp;amp;sn=d9f671f77be23a148d1830448154a545&amp;amp;chksm=871b0de9b06c84ffaf260b9ba2a010108cca62d5ce3dcbd8c98c72c9f786f9cd460b27b496ca&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;深度解读最流行的优化算法：梯度下降&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718391&amp;amp;idx=1&amp;amp;sn=99fd9d942768706e93f7f1aa744ea4b7&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718391&amp;amp;idx=1&amp;amp;sn=99fd9d942768706e93f7f1aa744ea4b7&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;Science：斯坦福大学用迁移学习预测非洲贫困状况&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720823&amp;amp;idx=4&amp;amp;sn=2ed3964e94e3076e060e48a4708faa2a&amp;amp;chksm=871b0e49b06c875fd2ead27692e8c2b35ac38724adc0215183a434283f4f869fde11e7036c5e&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720823&amp;amp;idx=4&amp;amp;sn=2ed3964e94e3076e060e48a4708faa2a&amp;amp;chksm=871b0e49b06c875fd2ead27692e8c2b35ac38724adc0215183a434283f4f869fde11e7036c5e&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;用 Word2vec 轻松处理新金融风控场景中的文本类数据&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720969&amp;amp;idx=1&amp;amp;sn=d5723c205f594616932624684d3a1327&amp;amp;chksm=871b0eb7b06c87a1d4d9809b35c361a4d8a4bf75315eaa9502a051058b184fb233e5b2d2695c&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720969&amp;amp;idx=1&amp;amp;sn=d5723c205f594616932624684d3a1327&amp;amp;chksm=871b0eb7b06c87a1d4d9809b35c361a4d8a4bf75315eaa9502a051058b184fb233e5b2d2695c&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;Science：实用量子计算机已近在咫尺&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720561&amp;amp;idx=3&amp;amp;sn=76741dd8ae09d6493b3abebcbd387520&amp;amp;chksm=871b0d4fb06c8459752dff98c4ffd59a8fd6114f1c43b2e1e9c85294402f3adf7947f74e1bab&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720561&amp;amp;idx=3&amp;amp;sn=76741dd8ae09d6493b3abebcbd387520&amp;amp;chksm=871b0d4fb06c8459752dff98c4ffd59a8fd6114f1c43b2e1e9c85294402f3adf7947f74e1bab&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;深度学习硬件架构简述&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718634&amp;amp;idx=1&amp;amp;sn=1220e691541c34281c64655a01793cb0&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718634&amp;amp;idx=1&amp;amp;sn=1220e691541c34281c64655a01793cb0&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;深度学习系列Part2：迁移学习和微调深度卷积神经网络&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719170&amp;amp;idx=1&amp;amp;sn=68b6b7f87677f5287b6e5a306409653b&amp;amp;chksm=871b07bcb06c8eaa0a649d7d3fd7963423dd4ea51b6e7711bc63653a528fbf196566345ae064&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719170&amp;amp;idx=1&amp;amp;sn=68b6b7f87677f5287b6e5a306409653b&amp;amp;chksm=871b07bcb06c8eaa0a649d7d3fd7963423dd4ea51b6e7711bc63653a528fbf196566345ae064&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;图文并茂的神经网络架构大盘点：从基本原理到衍生关系&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717143&amp;amp;idx=1&amp;amp;sn=4eb48040935380a7c87d18efea403d58&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717143&amp;amp;idx=1&amp;amp;sn=4eb48040935380a7c87d18efea403d58&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;为你的深度学习任务挑选性价比最高GPU&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719511&amp;amp;idx=3&amp;amp;sn=0674ef2a2e995d180ca081ed3a6ae1b9&amp;amp;chksm=871b0169b06c887feefc5604f1f53081e919eadec5c3d02c25d8da786de0bfa23141bd3f184e&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719511&amp;amp;idx=3&amp;amp;sn=0674ef2a2e995d180ca081ed3a6ae1b9&amp;amp;chksm=871b0169b06c887feefc5604f1f53081e919eadec5c3d02c25d8da786de0bfa23141bd3f184e&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;详解谷歌神经网络图像压缩技术：高质量地将图像压缩得更小&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718229&amp;amp;idx=3&amp;amp;sn=bb2fd16046e6e08bea612a5f7fd0f2dd&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718229&amp;amp;idx=3&amp;amp;sn=bb2fd16046e6e08bea612a5f7fd0f2dd&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;用于视觉任务的CNN为何能在听觉任务上取得成功？&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722208&amp;amp;idx=1&amp;amp;sn=52397806416c7d7f570d5c8fc9ecb96e&amp;amp;chksm=871b0bdeb06c82c85c03e7a07a3c71d9258969470ed8b70eeff850db98a0b7b98cda6fe787ee&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722208&amp;amp;idx=1&amp;amp;sn=52397806416c7d7f570d5c8fc9ecb96e&amp;amp;chksm=871b0bdeb06c82c85c03e7a07a3c71d9258969470ed8b70eeff850db98a0b7b98cda6fe787ee&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;自然语言处理领域深度学习研究总结：从基本概念到前沿成果&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720780&amp;amp;idx=3&amp;amp;sn=bac6cbe4972c236ee0bcdbf76139fa98&amp;amp;chksm=871b0e72b06c8764837fdf6f6cc8b01361b883c0a86bb253163cde5f380beb2e413d855d84b9&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720780&amp;amp;idx=3&amp;amp;sn=bac6cbe4972c236ee0bcdbf76139fa98&amp;amp;chksm=871b0e72b06c8764837fdf6f6cc8b01361b883c0a86bb253163cde5f380beb2e413d855d84b9&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;专访谷歌Jeff Dean：强化学习适合的任务与产品化应用&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720302&amp;amp;idx=1&amp;amp;sn=c88634da158f36db23b9dc7d0dc550ad&amp;amp;chksm=871b0c50b06c854694984e193f289deb51a5efe71f53223dc37feb70509fd957c8af5bb61ab3&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720302&amp;amp;idx=1&amp;amp;sn=c88634da158f36db23b9dc7d0dc550ad&amp;amp;chksm=871b0c50b06c854694984e193f289deb51a5efe71f53223dc37feb70509fd957c8af5bb61ab3&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;重磅论文：解析深度卷积神经网络的14种设计模式&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;五、前沿研究&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWic17FA5ZBlbiaEavsI2wmR5XZribybxutUNvxSC3xw8gcIg3fUbQuD240T0iceS1hsA3ob3XGzH8UH0g/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721777&amp;amp;idx=4&amp;amp;sn=a55d6807a8e65059c426876c623f655b&amp;amp;chksm=871b098fb06c80990a07affb5ecae55b496ca5e3a8b42e686d287b3bd308235c04a2d29c9a28&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721777&amp;amp;idx=4&amp;amp;sn=a55d6807a8e65059c426876c623f655b&amp;amp;chksm=871b098fb06c80990a07affb5ecae55b496ca5e3a8b42e686d287b3bd308235c04a2d29c9a28&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;并行运算，Facebook提出门控卷积神经网络的语言建模&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718798&amp;amp;idx=3&amp;amp;sn=6ec32a0f0f09b8f193c578ee0af9d7ae&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718798&amp;amp;idx=3&amp;amp;sn=6ec32a0f0f09b8f193c578ee0af9d7ae&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;FAIR与微软研究院合著论文：通过虚拟问答衡量机器智能&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717728&amp;amp;idx=2&amp;amp;sn=228e5905d7cd6fd175fc596e2d511eed&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717728&amp;amp;idx=2&amp;amp;sn=228e5905d7cd6fd175fc596e2d511eed&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;FusionNet融合三个卷积网络：识别对象从二维升级到三维&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720234&amp;amp;idx=3&amp;amp;sn=1fe8cce38750ad900e31109e4358ee0a&amp;amp;chksm=871b0394b06c8a826c9af5302dc38ccc8279db3288b573227d0547d27a720aec5dba2592e0e6&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720234&amp;amp;idx=3&amp;amp;sn=1fe8cce38750ad900e31109e4358ee0a&amp;amp;chksm=871b0394b06c8a826c9af5302dc38ccc8279db3288b573227d0547d27a720aec5dba2592e0e6&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;谷歌新论文提出神经符号机：使用弱监督在Freebase上学习语义解析器&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720399&amp;amp;idx=4&amp;amp;sn=3dcdb45229af883cd646985fe0964537&amp;amp;chksm=871b0cf1b06c85e7eeebdb857bcc95b456e5f5ccdb597c9739d6b2fda96069bc1fc53cb32b6b&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720399&amp;amp;idx=4&amp;amp;sn=3dcdb45229af883cd646985fe0964537&amp;amp;chksm=871b0cf1b06c85e7eeebdb857bcc95b456e5f5ccdb597c9739d6b2fda96069bc1fc53cb32b6b&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;Google Brain与OpenAI合作论文：规模化的对抗机器学习&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721644&amp;amp;idx=5&amp;amp;sn=55b63682dc248b842e9229f6db251c6e&amp;amp;chksm=871b0912b06c800437eedb3fab4ca179a8e83aac4c2879b218974a26e26f79cf6829aa6f4dfd&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721644&amp;amp;idx=5&amp;amp;sn=55b63682dc248b842e9229f6db251c6e&amp;amp;chksm=871b0912b06c800437eedb3fab4ca179a8e83aac4c2879b218974a26e26f79cf6829aa6f4dfd&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;谷歌新论文：使用生成对抗网络的无监督像素级域适应&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720367&amp;amp;idx=3&amp;amp;sn=15551131dbd1d1fad15d2752dd78fe83&amp;amp;chksm=871b0c11b06c8507b17d846e7d09b8fc4f0f12267d2f7dd019afa3d0ca3345a8774041ef5c84&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720367&amp;amp;idx=3&amp;amp;sn=15551131dbd1d1fad15d2752dd78fe83&amp;amp;chksm=871b0c11b06c8507b17d846e7d09b8fc4f0f12267d2f7dd019afa3d0ca3345a8774041ef5c84&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;谷歌ICLR 2017论文提出超大规模的神经网络：稀疏门控专家混合层&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718466&amp;amp;idx=3&amp;amp;sn=ffeb503724abb0934c5c60e1202b12c0&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718466&amp;amp;idx=3&amp;amp;sn=ffeb503724abb0934c5c60e1202b12c0&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;谷歌论文：使用循环神经网络的全分辨率图像压缩&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722239&amp;amp;idx=4&amp;amp;sn=3544eee8b2bf5eeab1ae852ba9fde64c&amp;amp;chksm=871b0bc1b06c82d74fa57cbcb0d9f6178a78d474c6bfe93db174dd0c8f580272e398006b0f14&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722239&amp;amp;idx=4&amp;amp;sn=3544eee8b2bf5eeab1ae852ba9fde64c&amp;amp;chksm=871b0bc1b06c82d74fa57cbcb0d9f6178a78d474c6bfe93db174dd0c8f580272e398006b0f14&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;谷歌新论文提出适应性生成对抗网络AdaGAN：增强生成模型&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718943&amp;amp;idx=4&amp;amp;sn=f93b540a0b28100a6912e916d2ad1ac0&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718943&amp;amp;idx=4&amp;amp;sn=f93b540a0b28100a6912e916d2ad1ac0&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;谷歌技术论文：用于YouTube推荐的深度神经网络&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719170&amp;amp;idx=3&amp;amp;sn=5c9dd730e1454335efdae14b24cd2053&amp;amp;chksm=871b07bcb06c8eaa7e4e210727f03214ddf633513522828ac2d3c5a339ee50486d5f32833566&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719170&amp;amp;idx=3&amp;amp;sn=5c9dd730e1454335efdae14b24cd2053&amp;amp;chksm=871b07bcb06c8eaa7e4e210727f03214ddf633513522828ac2d3c5a339ee50486d5f32833566&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;谷歌与微软合著论文：由知识引导的结构化注意网络&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719594&amp;amp;idx=2&amp;amp;sn=b8398c3059b23babb02487baf2cc738f&amp;amp;chksm=871b0114b06c8802ed86e1bc0a17fb33d79500962206eb480bdf023b25c753a7535bb877df2b&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719594&amp;amp;idx=2&amp;amp;sn=b8398c3059b23babb02487baf2cc738f&amp;amp;chksm=871b0114b06c8802ed86e1bc0a17fb33d79500962206eb480bdf023b25c753a7535bb877df2b&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;谷歌深度解读：机器人可以如何通过共享经历学习新技能&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719099&amp;amp;idx=2&amp;amp;sn=52807674a2235e7ed8065a165427e1d6&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719099&amp;amp;idx=2&amp;amp;sn=52807674a2235e7ed8065a165427e1d6&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;谷歌NIPS 2016提交的8篇论文：从无监督学习到生成模型&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718429&amp;amp;idx=2&amp;amp;sn=2dad7f9aab23cf05323bb9d01c49d11b&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718429&amp;amp;idx=2&amp;amp;sn=2dad7f9aab23cf05323bb9d01c49d11b&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;谷歌DeepMind论文：使用合成梯度的解耦神经接口&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722118&amp;amp;idx=2&amp;amp;sn=42199ff21f3b06912e487de2c83eca1b&amp;amp;chksm=871b0b38b06c822ef121554a1f9bf23ef49e15cbbe6d84ac11c8e68eb377746a24809aa8e34c&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722118&amp;amp;idx=2&amp;amp;sn=42199ff21f3b06912e487de2c83eca1b&amp;amp;chksm=871b0b38b06c822ef121554a1f9bf23ef49e15cbbe6d84ac11c8e68eb377746a24809aa8e34c&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;谷歌提交ICLR 2017论文：学习记忆罕见事件&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722472&amp;amp;idx=4&amp;amp;sn=892464db8e5e2d1e060bfeeacef63882&amp;amp;chksm=871b14d6b06c9dc0e5f870684b95dee11d47f75d155d601f86e9700ddc0c1b65191d9c46e19b&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722472&amp;amp;idx=4&amp;amp;sn=892464db8e5e2d1e060bfeeacef63882&amp;amp;chksm=871b14d6b06c9dc0e5f870684b95dee11d47f75d155d601f86e9700ddc0c1b65191d9c46e19b&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;谷歌提出深度概率编程语言Edward：融合了贝叶斯、深度学习和概率编程&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721938&amp;amp;idx=4&amp;amp;sn=64634dd519ee70c35fdf1e771da7d9e5&amp;amp;chksm=871b0aecb06c83face511e46c836911a7a15c69980a76198ae928aa935b51d162ebe20946a35&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721938&amp;amp;idx=4&amp;amp;sn=64634dd519ee70c35fdf1e771da7d9e5&amp;amp;chksm=871b0aecb06c83face511e46c836911a7a15c69980a76198ae928aa935b51d162ebe20946a35&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;谷歌新论文提出预测器架构：端到端的学习与规划&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720220&amp;amp;idx=4&amp;amp;sn=85923b1102993f0c88c0394ae0ecb4fc&amp;amp;chksm=871b03a2b06c8ab4ca055cc73ee73c50275f70990ccdab71107626640548b916d383c549ea18&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720220&amp;amp;idx=4&amp;amp;sn=85923b1102993f0c88c0394ae0ecb4fc&amp;amp;chksm=871b03a2b06c8ab4ca055cc73ee73c50275f70990ccdab71107626640548b916d383c549ea18&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;DeepMind最新论文：线性时间的神经机器翻译&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718504&amp;amp;idx=3&amp;amp;sn=0469d037c1d004270da3006216a97cef&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718504&amp;amp;idx=3&amp;amp;sn=0469d037c1d004270da3006216a97cef&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;DeepMind David Silver论文：学习跨多个数量级的值&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719494&amp;amp;idx=3&amp;amp;sn=67ed3e91731a47abe1a29df4c949119b&amp;amp;chksm=871b0178b06c886e6da4c83c0c26476c2f679f5e72d542531c5fbb8c798b6d768f9a9c596485&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719494&amp;amp;idx=3&amp;amp;sn=67ed3e91731a47abe1a29df4c949119b&amp;amp;chksm=871b0178b06c886e6da4c83c0c26476c2f679f5e72d542531c5fbb8c798b6d768f9a9c596485&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;DeepMind论文：在线Segment to Segment神经传导&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719745&amp;amp;idx=2&amp;amp;sn=242eda88fa9a5572e60b43e451a1549b&amp;amp;chksm=871b027fb06c8b693cff17f43553625f008fcb7965582119b651dbbd17e116e35dc801ebeec3&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719745&amp;amp;idx=2&amp;amp;sn=242eda88fa9a5572e60b43e451a1549b&amp;amp;chksm=871b027fb06c8b693cff17f43553625f008fcb7965582119b651dbbd17e116e35dc801ebeec3&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;DeepMind深度解读Nature论文：可微神经计算机&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719843&amp;amp;idx=4&amp;amp;sn=d54e7e415990bcfe69727e0b9f4c5f98&amp;amp;chksm=871b021db06c8b0b008c7004e130d596ae14f4b4de017098ecc4409e54fad8a4a77d3bcb93f4&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719843&amp;amp;idx=4&amp;amp;sn=d54e7e415990bcfe69727e0b9f4c5f98&amp;amp;chksm=871b021db06c8b0b008c7004e130d596ae14f4b4de017098ecc4409e54fad8a4a77d3bcb93f4&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;DeepMind论文：调控运动控制器的学习和迁移&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720969&amp;amp;idx=2&amp;amp;sn=d1fae404486906125e01b5def7e26d94&amp;amp;chksm=871b0eb7b06c87a1d3e7d0b29e8c8f9e4c86f4949d04b0485df1b45823555a6c88a25ccf4dc4&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720969&amp;amp;idx=2&amp;amp;sn=d1fae404486906125e01b5def7e26d94&amp;amp;chksm=871b0eb7b06c87a1d3e7d0b29e8c8f9e4c86f4949d04b0485df1b45823555a6c88a25ccf4dc4&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;DeepMind NIPS 2016论文盘点（Part1）：强化学习正大步向前&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721102&amp;amp;idx=2&amp;amp;sn=cbc44a149457d31ed9a8bbe825f09378&amp;amp;chksm=871b0f30b06c8626bb94cbd7a08fd4a5c8bec747082f49280fbd27e9c87c965de983a279796c&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721102&amp;amp;idx=2&amp;amp;sn=cbc44a149457d31ed9a8bbe825f09378&amp;amp;chksm=871b0f30b06c8626bb94cbd7a08fd4a5c8bec747082f49280fbd27e9c87c965de983a279796c&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;DeepMind NIPS 2016论文盘点（Part2）：无监督学习的新进展&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719772&amp;amp;idx=2&amp;amp;sn=9540989a7862ef93d1e5146a7b5641c9&amp;amp;chksm=871b0262b06c8b74bcd961a7bfe45076a92c1d9456af235f8e84a4bce6e15d120f295cab5576&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719772&amp;amp;idx=2&amp;amp;sn=9540989a7862ef93d1e5146a7b5641c9&amp;amp;chksm=871b0262b06c8b74bcd961a7bfe45076a92c1d9456af235f8e84a4bce6e15d120f295cab5576&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;ECCV 2016 最佳论文新鲜出炉&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719971&amp;amp;idx=3&amp;amp;sn=c23aa4b6172bd4ccea042d139ffa5daf&amp;amp;chksm=871b029db06c8b8b939ba2e0eb256db1d5fdd5ce2b229139cb31e7e54e5bdd2772761ce01c19&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719971&amp;amp;idx=3&amp;amp;sn=c23aa4b6172bd4ccea042d139ffa5daf&amp;amp;chksm=871b029db06c8b8b939ba2e0eb256db1d5fdd5ce2b229139cb31e7e54e5bdd2772761ce01c19&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;Geoffrey Hinton论文：使用快速权重处理最近的过去&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717143&amp;amp;idx=2&amp;amp;sn=dbb912c06671f0ba4bb7faf8b1677831&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717143&amp;amp;idx=2&amp;amp;sn=dbb912c06671f0ba4bb7faf8b1677831&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;哈工大讯飞联合实验室最新论文刷新机器阅读理解纪录&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715759&amp;amp;idx=3&amp;amp;sn=20d16db66afb2d742422f0a3abfa7f1e&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715759&amp;amp;idx=3&amp;amp;sn=20d16db66afb2d742422f0a3abfa7f1e&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;华盛顿大学论文：使用机器学习分析科学文献中的视觉信息&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718786&amp;amp;idx=5&amp;amp;sn=1c91d80ce0422c7049bfdbaa8188d56f&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718786&amp;amp;idx=5&amp;amp;sn=1c91d80ce0422c7049bfdbaa8188d56f&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;Ian Goodfellow 论文：通过视频预测的用于物理交互的无监督学习&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719909&amp;amp;idx=4&amp;amp;sn=90e189c8989817e3b52d2a40c355da10&amp;amp;chksm=871b02dbb06c8bcdc29a69b7a9ba2711f3ba1e2a08192e184f298093b404fa57272cdfdf81b9&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719909&amp;amp;idx=4&amp;amp;sn=90e189c8989817e3b52d2a40c355da10&amp;amp;chksm=871b02dbb06c8bcdc29a69b7a9ba2711f3ba1e2a08192e184f298093b404fa57272cdfdf81b9&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;Ian Goodfellow 论文：用于隐私训练数据的深度学习的半监督知识迁移&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715900&amp;amp;idx=4&amp;amp;sn=948406fcbd53cdca4ce96bd33a28874d&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715900&amp;amp;idx=4&amp;amp;sn=948406fcbd53cdca4ce96bd33a28874d&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;IBM论文：多尺度循环神经网络在对话生成中的应用&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715145&amp;amp;idx=3&amp;amp;sn=21d98866046180034d68da334501ce24&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715145&amp;amp;idx=3&amp;amp;sn=21d98866046180034d68da334501ce24&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;ICLR2016会议，不可错过Facebook提交的七篇论文&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718262&amp;amp;idx=1&amp;amp;sn=0391500e43530e7f4a8b8053176e5d7f&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718262&amp;amp;idx=1&amp;amp;sn=0391500e43530e7f4a8b8053176e5d7f&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;计算机科学领导者：卡内基梅隆大学ACL2016论文汇总&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715794&amp;amp;idx=3&amp;amp;sn=3c328f66f24dee02b6a29a7821c7f6a1&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715794&amp;amp;idx=3&amp;amp;sn=3c328f66f24dee02b6a29a7821c7f6a1&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;论文：TensorFlow，一个大规模机器学习系统&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717969&amp;amp;idx=4&amp;amp;sn=7fa67419573685604dde9811d434f6b8&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717969&amp;amp;idx=4&amp;amp;sn=7fa67419573685604dde9811d434f6b8&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;论文：通过连续奖励策略梯度学习在线比对&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718688&amp;amp;idx=4&amp;amp;sn=17b45f18ccb1e29e80fdca1645a71e5c&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718688&amp;amp;idx=4&amp;amp;sn=17b45f18ccb1e29e80fdca1645a71e5c&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;论文：基准评测当前最先进的深度学习软件工具&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720189&amp;amp;idx=3&amp;amp;sn=8e0d8f7d3b9c037935736e09f85a4884&amp;amp;chksm=871b03c3b06c8ad57d13417933b779f6b0a5931c3448ef9bf2129fb64b0c3f4c84293358aebf&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720189&amp;amp;idx=3&amp;amp;sn=8e0d8f7d3b9c037935736e09f85a4884&amp;amp;chksm=871b03c3b06c8ad57d13417933b779f6b0a5931c3448ef9bf2129fb64b0c3f4c84293358aebf&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;论文：一种用于训练循环网络的新算法Professor Forcing&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718988&amp;amp;idx=4&amp;amp;sn=79c38974f2908e909e0f3bdd140cfa88&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718988&amp;amp;idx=4&amp;amp;sn=79c38974f2908e909e0f3bdd140cfa88&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;论文：高斯混合模型的似然方法中的局部极大值：结构结果和算法结果&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721081&amp;amp;idx=3&amp;amp;sn=111d844d50c98582695d04fa2b252c89&amp;amp;chksm=871b0f47b06c86514ac934c44fe4df92f5d4209f209b94b4c89d1f138492dbaf7e47479803a3&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721081&amp;amp;idx=3&amp;amp;sn=111d844d50c98582695d04fa2b252c89&amp;amp;chksm=871b0f47b06c86514ac934c44fe4df92f5d4209f209b94b4c89d1f138492dbaf7e47479803a3&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;NIPS 2016现场：谷歌发布 28 篇机器学习论文&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715615&amp;amp;idx=1&amp;amp;sn=f114c4683656991bd331dc9971499a02&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715615&amp;amp;idx=1&amp;amp;sn=f114c4683656991bd331dc9971499a02&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;Nature论文：无监督表征学习，用电子健康病历增强临床决策&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716475&amp;amp;idx=1&amp;amp;sn=2b03deead0c1e63be80fdc239293e805&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716475&amp;amp;idx=1&amp;amp;sn=2b03deead0c1e63be80fdc239293e805&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;Nature论文：从不确定性表征到自动建模&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718527&amp;amp;idx=2&amp;amp;sn=8d054db2eca7a0b25190a6cc050fc1d7&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718527&amp;amp;idx=2&amp;amp;sn=8d054db2eca7a0b25190a6cc050fc1d7&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;NIPS 2016 公布571篇接收论文&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719581&amp;amp;idx=3&amp;amp;sn=e75b2fcd08d4ef5d8feeb79ebc223d18&amp;amp;chksm=871b0123b06c883511d8dbf853bb60f8e0903e335ed384421d1ab8db96ebf45d9b4cf3e96356&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719581&amp;amp;idx=3&amp;amp;sn=e75b2fcd08d4ef5d8feeb79ebc223d18&amp;amp;chksm=871b0123b06c883511d8dbf853bb60f8e0903e335ed384421d1ab8db96ebf45d9b4cf3e96356&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;OpenAI与NASA论文：用于张拉整体机器人运动的深度强化学习&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720257&amp;amp;idx=3&amp;amp;sn=4dfc480bfc70691f5baa44a75a0c1b82&amp;amp;chksm=871b0c7fb06c85696574d7f15d160afd3f45aa669bad4d1589f908c2fe0f56a3f34946bb6e73&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720257&amp;amp;idx=3&amp;amp;sn=4dfc480bfc70691f5baa44a75a0c1b82&amp;amp;chksm=871b0c7fb06c85696574d7f15d160afd3f45aa669bad4d1589f908c2fe0f56a3f34946bb6e73&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;OpenAI论文：神经GPU的扩展和限制&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721777&amp;amp;idx=1&amp;amp;sn=a51774b58c1b39ae9cb23c41361780af&amp;amp;chksm=871b098fb06c80992893818772a5c9410adb8826f60ae44d9468685413708c9c1c4583f967df&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721777&amp;amp;idx=1&amp;amp;sn=a51774b58c1b39ae9cb23c41361780af&amp;amp;chksm=871b098fb06c80992893818772a5c9410adb8826f60ae44d9468685413708c9c1c4583f967df&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;苹果发布第一篇人工智能研究论文：模拟+无监督方法改善合成图像&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716071&amp;amp;idx=2&amp;amp;sn=fb8944218199ac4c29af926d8847cc58&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716071&amp;amp;idx=2&amp;amp;sn=fb8944218199ac4c29af926d8847cc58&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;商汤科技论文解析：人脸检测中级联卷积神经网络的联合训练&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717606&amp;amp;idx=3&amp;amp;sn=9d20357d6ce5877e7df31058c1ba0b4c&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717606&amp;amp;idx=3&amp;amp;sn=9d20357d6ce5877e7df31058c1ba0b4c&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;斯坦福大学李飞飞最新论文：弱监督动作标记的连接时序模型&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720285&amp;amp;idx=5&amp;amp;sn=583751084a6855b35f684f582afd7976&amp;amp;chksm=871b0c63b06c857523341e94380cd6b87e84502854886f7aa8fa40ff665166db4ffda8a5ea1b&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720285&amp;amp;idx=5&amp;amp;sn=583751084a6855b35f684f582afd7976&amp;amp;chksm=871b0c63b06c857523341e94380cd6b87e84502854886f7aa8fa40ff665166db4ffda8a5ea1b&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;Vicarious在ICLR2017提交无监督学习论文：层级组合特征学习&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719118&amp;amp;idx=3&amp;amp;sn=4565fb14db41208571b808956a39e310&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719118&amp;amp;idx=3&amp;amp;sn=4565fb14db41208571b808956a39e310&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;Yann LeCun论文：基于能量的生成对抗网络&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717728&amp;amp;idx=3&amp;amp;sn=2de2d33afc32c04f2bcb1cfe1a788c0f&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717728&amp;amp;idx=3&amp;amp;sn=2de2d33afc32c04f2bcb1cfe1a788c0f&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;Yoshua Bengio 论文：一种神经知识语言模型&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720390&amp;amp;idx=1&amp;amp;sn=8ad603e853b88706ca4916495f59b228&amp;amp;chksm=871b0cf8b06c85ee216eb2d46361de137679cd9fd7d09a2a72cdf06d79d6c01dfe1683eb003c&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720390&amp;amp;idx=1&amp;amp;sn=8ad603e853b88706ca4916495f59b228&amp;amp;chksm=871b0cf8b06c85ee216eb2d46361de137679cd9fd7d09a2a72cdf06d79d6c01dfe1683eb003c&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;Yann LeCun提交ICLR 2017论文汇总：从GAN到循环实体网络等&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717572&amp;amp;idx=2&amp;amp;sn=da7a53cde74285f229fcf6827bbb17d6&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717572&amp;amp;idx=2&amp;amp;sn=da7a53cde74285f229fcf6827bbb17d6&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;Bengio论文：用于序列预测的actor-critic算法&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718133&amp;amp;idx=4&amp;amp;sn=97ce57340e916cb049ec96c96fa55fe3&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718133&amp;amp;idx=4&amp;amp;sn=97ce57340e916cb049ec96c96fa55fe3&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;Yoshua Bengio论文：迈向生物学上可信的深度学习&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719794&amp;amp;idx=4&amp;amp;sn=8a1d4e46663439c509f8d580e2b871e8&amp;amp;chksm=871b024cb06c8b5a1cbc79b9b2d9ff0d312842f04ad375ef7838c30f1b639cb3d1e1724f2902&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719794&amp;amp;idx=4&amp;amp;sn=8a1d4e46663439c509f8d580e2b871e8&amp;amp;chksm=871b024cb06c8b5a1cbc79b9b2d9ff0d312842f04ad375ef7838c30f1b639cb3d1e1724f2902&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;Yoshua Bengio论文：使用线性分类器探头理解中间层&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718391&amp;amp;idx=3&amp;amp;sn=75cac85169b49af157755a3cbc68670e&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718391&amp;amp;idx=3&amp;amp;sn=75cac85169b49af157755a3cbc68670e&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;Yoshua Bengio论文：Mollifying Networks&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720220&amp;amp;idx=2&amp;amp;sn=0f2f5061e470ffbf76fee6ac77b3cf52&amp;amp;chksm=871b03a2b06c8ab4a0cb275b1044fb23a646997af91d5753439488ee976512c84979eadd2293&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720220&amp;amp;idx=2&amp;amp;sn=0f2f5061e470ffbf76fee6ac77b3cf52&amp;amp;chksm=871b03a2b06c8ab4a0cb275b1044fb23a646997af91d5753439488ee976512c84979eadd2293&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;微软重磅论文提出LightRNN：高效利用内存和计算的循环神经网络&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718106&amp;amp;idx=2&amp;amp;sn=93aceb9b6e4a0772bbaf9257a4def3d2&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718106&amp;amp;idx=2&amp;amp;sn=93aceb9b6e4a0772bbaf9257a4def3d2&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;微软ACL 2016论文汇集，自然语言技术逼近人类对话水平&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718072&amp;amp;idx=2&amp;amp;sn=dc0f5e9ac4ca943afe91ea8d4e08f78c&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718072&amp;amp;idx=2&amp;amp;sn=dc0f5e9ac4ca943afe91ea8d4e08f78c&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;自然语言顶级会议ACL 2016谷歌论文汇集&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心原创，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 29 Jan 2017 13:31:25 +0800</pubDate>
    </item>
    <item>
      <title>盘点 | Github上的18个顶级深度学习项目</title>
      <link>http://www.iwgc.cn/link/4516628</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Github&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;hunkim 盘点了 Github 上 18 个深度学习项目，根据收藏数自动排名。最新的一次 update 在几小时前完成。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;项目地址：https://github.com/hunkim/DeepLearningStars&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面是在 Github 上和深度学习相关的项目：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1.TensorFlow&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://github.com/tensorflow/tensorflow&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Stars：44,201&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;介绍：为可扩展机器学习提供使用数据流图的计算。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2.Caffe&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://github.com/BVLC/caffe&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Stars：15,615&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;介绍：Caffe: 一个为深度学习提供的快速开放式框架&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3.neural-style&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://github.com/jcjohnson/neural-style&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Stars：12,496&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;介绍：神经风格算法的 Torch 实现&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4.keras&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://github.com/fchollet/keras&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Stars：11,632&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;介绍：Python 上的深度学习库。提供循环神经网络和卷积神经网络等算法。在 Theano 或 TensorFlow 平台上运行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;5.deepdream&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://github.com/google/deepdream&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Stars：9,764&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;介绍：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;6.RocAlphaGo&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://github.com/Rochester-NRT/RocAlphaGo&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Stars：7,807&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;介绍：一个独立的，由 DeepMind 在自然期刊发表的「掌控围棋游戏的深度神经网络和树搜索（Mastering the game of Go with deep neural networks and tree search）」(Nature 529, 484-489, 28 Jan 2016) 引起的项目。详情请见 DeepMind 网站：https://deepmind.com/publications.html.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;7.char-rnn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://github.com/karpathy/char-rnn&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Stars：4,793&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;介绍：在 Torch 上为字符级自然语言模型而构建的多层循环神经网络 (LSTM, GRU, RNN)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;8.gym&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://github.com/openai/gym&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Stars：4,747&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;介绍：开发和对比强化学习算法的工具包。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;9.tflearn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://github.com/tflearn/tflearn&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Stars：4,677&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;介绍：以针对 TensorFlow 的高层 API 为特色的深度学习库。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;10.playground&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://github.com/tensorflow/playground&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Stars：4,154&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;介绍：玩转神经网络！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;11.neuraltalk&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://github.com/karpathy/neuraltalk&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Stars：3,977&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;介绍：NeuralTalk 是一个 Python 加 numpy 的项目，来学习多模式循环神经网络，从而使用语句描述图片。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;12.Machine-Learning-Tutorials&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://github.com/ujjwalkarn/Machine-Learning-Tutorials&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Stars：3,583&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;介绍：机器学习和深度学习教程、文章和其他资源。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;13.TopDeepLearning&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://github.com/aymericdamien/TopDeepLearning&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Stars：3,563&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;介绍：关于深度学习的流行 Github 项目清单。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;14.TensorFlow-Tutorials&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://github.com/nlintz/TensorFlow-Tutorials&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Stars：3,119&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;介绍：使用谷歌 TensorFlow 框架的简易教程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;15.tensorflow_tutorials&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://github.com/pkmital/tensorflow_tutorials&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Stars：3,021&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;介绍：Tensorflow 从基础到某些趣味性的应用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;16.word-rnn-tensorflow&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://github.com/hunkim/word-rnn-tensorflow&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Stars：284&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;介绍：TensorFlow 上的 Python 库，为单词级的语言模型提供多层循环神经网络（LSTM、RNN）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;17.tensorflow-aws-ami&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://github.com/ritchieng/tensorflow-aws-ami&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Stars：47&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;介绍：一个 TensorFlow 的亚马逊网页服务（AWS）AMI，它开放、免费且性能强大。可在 5 分钟内运行 TensorFlow。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;18.DeepLearningStars&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://github.com/hunkim/DeepLearningStars&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Stars：26&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;介绍：包含受关注最高的一些深度学习项目。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本排名于 2017 年 1 月 29 日自动更新。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 29 Jan 2017 13:31:25 +0800</pubDate>
    </item>
    <item>
      <title>教程 | 从头开始：用Python实现带随机梯度下降的线性回归</title>
      <link>http://www.iwgc.cn/link/4516629</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自machine learning mastery&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：Linjing、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;许多机器学习算法的核心是优化。优化算法用于在机器学习中为给定训练集找出合理的模型参数设置。机器学习最常见的优化算法是随机梯度下降（SGD：stochastic gradient descent）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本教程将指导大家用 Python 实现随机梯度下降对线性回归算法的优化。通过本教程的学习，你将了解到：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如何用随机梯度下降估计线性回归系数&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如何对多元线性回归做预测&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如何用带随机梯度下降的线性回归算法对新数据做预测&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;说明&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本文将对线性回归、随即梯度下降方法以及本教程所使用的葡萄酒品质数据集做一个集中阐释。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;多元线性回归&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;线性回归是一种用于预测真实值的方法。让人困惑的是，这些需要预测真实值的问题被称为回归问题（regression problems）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;线性回归是一种用直线对输入输出值进行建模的方法。在超过二维的空间里，这条直线被想象成一个平面或者超平面（hyperplane）。预测即是通过对输入值的组合对输出值进行预判。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;y = b0 + b1 * x1 + b2 * x2 + ...&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;系数 (b) 用于对每个输入属性 (x) 进行加权，而学习算法的目的正是寻找一组能导出好的预测值 (y) 的系数。这些系数可以使用随机梯度下降的方法找到。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;随机梯度下降&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;梯度下降（Gradient Descent）是遵循成本函数的梯度来最小化一个函数的过程。这个过程涉及到对成本形式以及其衍生形式的认知，使得我们可以从已知的给定点朝既定方向移动。比如向下朝最小值移动。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在机器学习中，我们可以利用随机梯度下降的方法来最小化训练模型中的误差，即每次迭代时完成一次评估和更新。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种优化算法的工作原理是模型每看到一个训练实例，就对其作出预测，并重复迭代该过程到一定的次数。这个流程可以用于找出能导致训练数据最小误差的模型的系数。用机器学习的术语来讲，就是每次迭代过程都用如下等式更新系数（b）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;b = b - learning_rate * error * x&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中 b 是系数或者被优化的权重，learing_rate 需手动设定（如 0.01），error 是取决于权重的训练数据模型的预测误差，x 是输入值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;葡萄酒品质数据集&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;开发了具有梯度下降的线性回归算法之后，我们可以将其运用到一个关于葡萄酒品质的数据集当中。这个数据集囊括了 4898 种白葡萄酒的测量标准，包括酸度和 ph 值。目的是用这些客观标准来预测葡萄酒的品质，分为 0 到 10 级。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下表给出了 5 个数据样本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;7,0.27,0.36,20.7,0.045,45,170,1.001,3,0.45,8.8,6&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;6.3,0.3,0.34,1.6,0.049,14,132,0.994,3.3,0.49,9.5,6&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;8.1,0.28,0.4,6.9,0.05,30,97,0.9951,3.26,0.44,10.1,6&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;7.2,0.23,0.32,8.5,0.058,47,186,0.9956,3.19,0.4,9.9,6&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;7.2,0.23,0.32,8.5,0.058,47,186,0.9956,3.19,0.4,9.9,6&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所有数据需归一化为 0-1 之间的值。每种属性标准单位不同，因而有不同的缩放尺度。通过预测该归一化数据集的平均值（零规则算法），达到了 0.148 的基准方均根差（RMSE）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该数据集详情请参阅 UCI Machine Learning Repository：http://archive.ics.uci.edu/ml/datasets/Wine+Quality&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下载该数据集并将其保存到当前工作目录，文件名为 winequality-white.csv。（注意：文件开头的头信息需去除，用作分隔符的 『；』 需改为符合 CSV 格式的 『，』。）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;教程&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本教程分为三个部分：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 预测&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 估计系数&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 葡萄酒品质预测&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这将能让你了解在你自己的预测建模问题上实现和应用带有随机梯度下降的线性回归的基础。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1. 预测&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先建立一个用于预测的函数。这将用于对随机梯度下降的候选系数的评估，且模型确定之后也需要这个函数。我们会在测试集或者新的数据上用该函数来进行预测。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;函数 predict() 如下所示，用于预测给定了一组系数的行的输出值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一个系数始终为截距，也称为偏差或 b0，因其相对独立且不与特定的输入值相关。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;# Make a prediction with coefficients&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;def predict(row, coefficients):&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;yhat = coefficients[0]&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;for i in range(len(row)-1):&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;yhat += coefficients[i + 1] * row[i]&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;return yhat&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们可以用一个小的数据集对这个函数进行测试。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;x, y&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;1, 1&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;2, 3&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;4, 3&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;3, 2&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;5, 5&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下图是一小部分数据：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibsia3lXaUiaMsqwCXauCbKhHLwmpDfV24ibOrbaNRJvhfSqTQo4vJ8P8YzwEczcpgYayr5oiaFFEmQVw/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;线性回归的部分转换数据&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们也可用之前准备好的系数为这个数据集做预测。predict() 函数测试如下。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;# Make a prediction with coefficients&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;def predict(row, coefficients):&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;yhat = coefficients[0]&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;for i in range(len(row)-1):&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;yhat += coefficients[i + 1] * row[i]&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;return yhat&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;dataset = [[1, 1], [2, 3], [4, 3], [3, 2], [5, 5]]&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;coef = [0.4, 0.8]&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;for row in dataset:&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;yhat = predict(row, coef)&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;print("Expected=%.3f, Predicted=%.3f" % (row[-1], yhat))&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;单个输入值 (x) 和两个系数（b0 和 b1）。用于建模该问题的预测方程为：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;y = b0 + b1 * x&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;或者，手动选择特定系数：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;y = 0.4 + 0.8 * x&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;运行此函数，我们将得到一个相当接近预测值的输出值（y）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;Expected=1.000, Predicted=1.200&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;Expected=3.000, Predicted=2.000&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;Expected=3.000, Predicted=3.600&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;Expected=2.000, Predicted=2.800&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;Expected=5.000, Predicted=4.400&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在我们可以用随机梯度下降来优化我们的系数值了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2. 估计系数&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们可以使用随机梯度下降来为我们的训练数据估计系数值。随机阶梯下降需要两个设定参数：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;学习率（Learning Rate）：用于限制每次更新时被修正的系数的数量。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Epochs：更新系数的同时运行训练集的次数。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这两个值和数据集都是函数的参数。我们的这个函数将执行三个遍历循环：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 单次 epoch 循环&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 单次 epoch 中训练集中的每行循环&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 单次 epoch 中每个系数循环并为每一行更新它&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;可以看到，每次 epoch，我们都会更新数据集里每行的系数。系数的更新是基于模型生成的误差。该误差被算作候选系数的预测值和预期输出值之间的差。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;error = prediction - expected&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有一个系数用于加权每一个输入属性，这些属性将以连续的方式进行更新，比如&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;b1(t+1) = b1(t) - learning_rate * error(t) * x1(t)&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;列表开始的特殊系数，也被称为截距（intercept）或偏差（bias），也以类似的方式更新，但因其不与特定输入值相关，所以无输入值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;b0(t+1) = b0(t) - learning_rate * error(t)&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在我们把所有东西组合在一起。coefficients_sgd() 函数正是用随机梯度下降来计算一个训练集的系数值，下面即是该函数：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;# Estimate linear regression coefficients using stochastic gradient descent&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;def coefficients_sgd(train, l_rate, n_epoch):&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;coef = [0.0 for i in range(len(train[0]))]&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;for epoch in range(n_epoch):&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;sum_error = 0&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;for row in train:&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;yhat = predict(row, coef)&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;error = yhat - row[-1]&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;sum_error += error**2&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;coef[0] = coef[0] - l_rate * error&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;for i in range(len(row)-1):&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;coef[i + 1] = coef[i + 1] - l_rate * error * row[i]&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;print('&amp;gt;epoch=%d, lrate=%.3f, error=%.3f' % (epoch, l_rate, sum_error))&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;return coef&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此外，我们追踪每个 epoch 的方差（正值）总和从而在循环之后得到一个好的结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;# Make a prediction with coefficients&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;def predict(row, coefficients):&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;yhat = coefficients[0]&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;for i in range(len(row)-1):&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;yhat += coefficients[i + 1] * row[i]&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;return yhat&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;# Estimate linear regression coefficients using stochastic gradient descent&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;def coefficients_sgd(train, l_rate, n_epoch):&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;coef = [0.0 for i in range(len(train[0]))]&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;for epoch in range(n_epoch):&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;sum_error = 0&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;for row in train:&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;yhat = predict(row, coef)&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;error = yhat - row[-1]&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;sum_error += error**2&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;coef[0] = coef[0] - l_rate * error&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;for i in range(len(row)-1):&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;coef[i + 1] = coef[i + 1] - l_rate * error * row[i]&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;print('&amp;gt;epoch=%d, lrate=%.3f, error=%.3f' % (epoch, l_rate, sum_error))&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;return coef&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;# Calculate coefficients&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;dataset = [[1, 1], [2, 3], [4, 3], [3, 2], [5, 5]]&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;l_rate = 0.001&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;n_epoch = 50&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;coef = coefficients_sgd(dataset, l_rate, n_epoch)&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;print(coef)&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们用 0.001 的学习速率训练该模型 50 次，即把整个训练数据集的系数曝光 50 次。运行一个 epoch 系统就将该次循环中的和方差（sum squared error）和以及最终系数集合 print 一次：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&amp;gt;epoch=45, lrate=0.001, error=2.650&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&amp;gt;epoch=46, lrate=0.001, error=2.627&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&amp;gt;epoch=47, lrate=0.001, error=2.607&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&amp;gt;epoch=48, lrate=0.001, error=2.589&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&amp;gt;epoch=49, lrate=0.001, error=2.573&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;[0.22998234937311363, 0.8017220304137576]&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;可以看到误差是如何在历次 epoch 中持续降低的。或许我们可以增加训练次数（epoch）或者每个 epoch 中的系数总量（调高学习速率）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尝试一下看你能得到什么结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在，我们将这个算法用到实际的数据当中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3. 葡萄酒品质预测&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们将使用随机阶梯下降的方法为葡萄酒品质数据集训练一个线性回归模型。本示例假定一个名为 winequality—white.csv 的 csv 文件副本已经存在于当前工作目录。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先加载该数据集，将字符串转换成数字，并将输出列从字符串转换成数值 0 和 1. 这个过程是通过辅助函数 load_csv()、str_column_to_float() 以及 dataset_minmax() 和 normalize_dataset() 来分别实现的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们将通过 K 次交叉验证来预估得到的学习模型在未知数据上的表现。这就意味着我们将创建并评估 K 个模型并预估这 K 个模型的平均误差。辅助函数 cross_validation_split()、rmse_metric() 和 evaluate_algorithm() 用于求导根均方差以及评估每一个生成的模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们用之前创建的函数 predict()、coefficients_sgd() 以及 linear_regression_sgd() 来训练模型。完整代码如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;# Linear Regression With Stochastic Gradient Descent for Wine Quality&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;from random import seed&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;from random import randrange&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;from csv import reader&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;from math import sqrt&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;# Load a CSV file&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;def load_csv(filename):&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;dataset = list()&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;with open(filename, 'r') as file:&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;csv_reader = reader(file)&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;for row in csv_reader:&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;if not row:&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;continue&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;dataset.append(row)&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;return dataset&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;# Convert string column to float&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;def str_column_to_float(dataset, column):&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;for row in dataset:&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;row[column] = float(row[column].strip())&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;# Find the min and max values for each column&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;def dataset_minmax(dataset):&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;minmax = list()&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;for i in range(len(dataset[0])):&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;col_values = [row[i] for row in dataset]&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;value_min = min(col_values)&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;value_max = max(col_values)&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;minmax.append([value_min, value_max])&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;return minmax&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;# Rescale dataset columns to the range 0-1&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;def normalize_dataset(dataset, minmax):&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;for row in dataset:&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;for i in range(len(row)):&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;row[i] = (row[i] - minmax[i][0]) / (minmax[i][1] - minmax[i][0])&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;# Split a dataset into k folds&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;def cross_validation_split(dataset, n_folds):&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;dataset_split = list()&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;dataset_copy = list(dataset)&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;fold_size = len(dataset) / n_folds&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;for i in range(n_folds):&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;fold = list()&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;while len(fold) &amp;lt; fold_size:&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;index = randrange(len(dataset_copy))&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;fold.append(dataset_copy.pop(index))&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;dataset_split.append(fold)&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;return dataset_split&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;# Calculate root mean squared error&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;def rmse_metric(actual, predicted):&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;sum_error = 0.0&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;for i in range(len(actual)):&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;prediction_error = predicted[i] - actual[i]&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;sum_error += (prediction_error ** 2)&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;mean_error = sum_error / float(len(actual))&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;return sqrt(mean_error)&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;# Evaluate an algorithm using a cross validation split&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;def evaluate_algorithm(dataset, algorithm, n_folds, *args):&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;folds = cross_validation_split(dataset, n_folds)&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;scores = list()&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;for fold in folds:&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;train_set = list(folds)&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;train_set.remove(fold)&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;train_set = sum(train_set, [])&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;test_set = list()&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;for row in fold:&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;row_copy = list(row)&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;test_set.append(row_copy)&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;row_copy[-1] = None&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;predicted = algorithm(train_set, test_set, *args)&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;actual = [row[-1] for row in fold]&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;rmse = rmse_metric(actual, predicted)&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;scores.append(rmse)&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;return scores&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;# Make a prediction with coefficients&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;def predict(row, coefficients):&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;yhat = coefficients[0]&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;for i in range(len(row)-1):&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;yhat += coefficients[i + 1] * row[i]&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;return yhat&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;# Estimate linear regression coefficients using stochastic gradient descent&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;def coefficients_sgd(train, l_rate, n_epoch):&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;coef = [0.0 for i in range(len(train[0]))]&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;for epoch in range(n_epoch):&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;for row in train:&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;yhat = predict(row, coef)&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;error = yhat - row[-1]&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;coef[0] = coef[0] - l_rate * error&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;for i in range(len(row)-1):&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;coef[i + 1] = coef[i + 1] - l_rate * error * row[i]&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;# print(l_rate, n_epoch, error)&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;return coef&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;# Linear Regression Algorithm With Stochastic Gradient Descent&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;def linear_regression_sgd(train, test, l_rate, n_epoch):&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;predictions = list()&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;coef = coefficients_sgd(train, l_rate, n_epoch)&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;for row in test:&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;yhat = predict(row, coef)&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;predictions.append(yhat)&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;return(predictions)&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;# Linear Regression on wine quality dataset&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;seed(1)&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;# load and prepare data&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;filename = 'winequality-white.csv'&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;dataset = load_csv(filename)&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;for i in range(len(dataset[0])):&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;str_column_to_float(dataset, i)&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;# normalize&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;minmax = dataset_minmax(dataset)&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;normalize_dataset(dataset, minmax)&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;# evaluate algorithm&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;n_folds = 5&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;l_rate = 0.01&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;n_epoch = 50&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;scores = evaluate_algorithm(dataset, linear_regression_sgd, n_folds, l_rate, n_epoch)&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;print('Scores: %s' % scores)&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;print('Mean RMSE: %.3f' % (sum(scores)/float(len(scores))))&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个等于 5 的 k 值被用于交叉验证，给每次迭代 4898/5 = 979.6（低于 1000 都行）条记录来进行评估。对一个小实验选择了 0.01 的学习率和 50 训练 epoch.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你可以尝试你自己的配置，看你能否超过我的分数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;运行这个样本，为 5 次交叉验证的每一次 print 一个分数，然后 print 平均均方根误差（RMSE）。我们可以看到（在归一化的数据集上）该 RMSE 为 0.126。如果我们只是预测平均值的话（使用 Zero Rule Algorithm），那么这个结果就低于基准值 0.148。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;Scores: [0.12259834231519767, 0.12733924130891316, 0.12610773846663892, 0.1289950071681572, 0.1272180783291014]&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;Mean RMSE: 0.126&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;扩展&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里给出了一些扩展练习，你可以思考并尝试解决它们：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;调整该实例。调整其学习率、epoch 的数量甚至原始数据处理和准备的方法，以期能提高最终结果。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;批量进行随机梯度下降。改变随机梯度下降算法使其在每个 epoch 上累积更新，且仅在 epoch 结束时批量更新系数。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;额外的回归问题。应用该技术来解决 UCI 机器学习库中的其它回归问题。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你会探索这些扩展任务吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;回顾总结&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本教程介绍了如何用 Python 实现带有随机梯度下降的多元线性回归算法。其中包括：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如何对多元线性回归问题做预测&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如何优化用于随机梯度下降的系数设置&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如何将该方法用于实际的回归预测模型问题&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;原文：http://machinelearningmastery.com/implement-linear-regression-stochastic-gradient-descent-scratch-python/&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 29 Jan 2017 13:31:25 +0800</pubDate>
    </item>
    <item>
      <title>好文回顾 | 李飞飞高徒 Andrej Karpathy：计算机科学博士的生存指南（附博士论文）</title>
      <link>http://www.iwgc.cn/link/4516630</link>
      <description>&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Github.io&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Andrej Karpathy&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：孙睿、吴攀、李亚洲、杜夏德&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p&gt;&lt;span&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;该回顾系列的第二篇为李飞飞高徒&amp;nbsp;Andrej Karpathy 博士毕业后在自己博客上发表的个人就读机器学习博士的经验。机器之心发布该文章之后引起了读者的共鸣，特别是在读博士，认为受益匪浅。希望年度回顾的这篇指导文章，能为更多的在读博士、将要就读博士的读者提供更多的帮助。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicxmPYrSYxsFzwwTibibQqW0NB5bGCKaXw8OKXN7e4v7Dd2TeS3NIDUu3Bdrlk3QCYJEcxtogrBFAYQ/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如今，我即将完成自己的 PhD 学位，我想要写一篇文章回顾自己的经历，希望这对你们有一些帮助。不像本科指导，博士指导要更加难写，因为一个人如何完成自己的博士生涯相比本科有更多的变化。因此，很多事情可能是有争议的，我熟悉的一些部分（计算机科学/机器学习/计算机视觉研究）会具体写一下。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;预热&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWicxmPYrSYxsFzwwTibibQqW0N0ApcUPwrIW7nseqAnod79LrwVjQ9wkzKbXQGlUGDHMbcia6Hsk9MGVQ/0?"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先，你想要获得博士学位吗？在年轻的时候我就很幸运的明知我真的想要一个 PhD。不幸的是，我并没有经过深思熟虑：首先，我是真的喜欢学校和学习，我想尽可能多学一些东西。其次，我真的想成为游戏《半条命》里面的 Gordon Freeman 博士这样的人（从 MIT 获得理论物理博士学位）。我喜欢这个游戏。但在做人生决策时你更加敏感又会怎样？还会想要读 PhD 吗？（这里作者引用了自己在 Quora 上的回答，当时他在大公司的 offer 与读博之间做出的抉择。）我假设你正在考虑是否加入一个中型公司（大部分人都是如此），你可以问自己该公司是否有如下吸引力：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;自由&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。读博在你想要追求和学习的主题上能提供很大的自由度。你在被别人管着。当然，读博也会有导师加以约束，但很大程度上要比其他更自由。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;所有权&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。你做出的研究成果将会是你自己的，上面附属自己的名字。相反，在大公司内，「blend in」会很常见。常有的一个感觉是成为了「齿轮上的一个齿」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;排他性&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。很少有人单独成功做到顶级的博士项目。你将是加入一个由数百杰出个人组成的团队，相比于公司可能是数千人组成的团队。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;地位&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。不管是不是这样，向前进并最终获得博士学位在文化上是值得崇敬的，也是一项了不起的成就。你也将成为一个博士，这很棒。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;个人自由&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。博士生是自己的老板。今天想睡觉？可以。今天想溜号休假？可以。所有的一切就是最后的博士成果，没人逼你要朝九晚五。当然，一些导师在这方面有很大的灵活性，一些公司也会灵活一些，但个人自由确实是初级声明。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;最大化未来的选择&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。加入博士项目并不是关闭了一些出路或减少了未来职业/生活方式的选择。你可以选择走一条路（PhD→其他），但并不只是一条路可走（其他→PhD→学术/研究）。此外（尽管应用机器学习专业相当特殊），博士毕业生甚至博士退学生更可能被雇佣，很多公司也愿意将你安排到更有趣的位置或给你更好的起始薪资。更广泛的说，最大化选择是你未来可以遵循的一个很具启发性的方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;最大化你的转变&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。你还年轻，没必要这么着急进公司。一旦你从博士毕业接下来有 50 年的时间花费到公司。在你的人生经历中，选择有更多的转变。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;个人成长&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。PhD 是一段快速成长（学到很多）和个人自我发现（成为掌握自我心理状态的大师）的浓重经历。PhD 项目（特别是如果你能成功进入一个好的项目）也能频繁的为你提供机会，交往一些格外阳光的朋友。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;专业性&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。PhD 可能是你人生中唯一的机会真的深入一个主题，并在某些事情上成为世界上处于领导地位的专家。在没有分心与约束的压力下，探索人类知识的边缘。这是一件非常美好的事，如果你不同意这一点，这可能就是一个你不适合读 PhD 的信号。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;放弃&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。我也想说一下可能存在的消极面和失败模式。PhD 是一段非常特殊的经历，有大量的人会放弃。你将不可避免的发现自己做起来特别难（特别是该交论文之前）。你需要适应这些痛苦，并有足够的心理耐力和决心处理这些压力。有的时候你可能会过的不知道今天是周几，吃厨房的剩菜剩饭。在一个美妙的、阳光明媚的下午，翻动 Facebook 照片你发现朋友们拿着比自己多 5 到 10 倍的薪水享受着异国旅行，你要一个人坐在实验室精疲力尽。有时你会需要 3 个月的时间远离自己的研究，才能调整好健康的心态。在朋友们做着 TechCrunch 文章里面提到的创业时，或者在朋友们将产品推销给百万人时，你却挣扎着意识到几个月的研究花费到了一篇只有几个引用的论文上。你会经历自我认知的危机，怀疑生活中的抉择，想知道花费自己人生中最宝贵的时间正在做什么。最后，你应该相当确信，自己在追求科学研究与发现的路上，能够在无序的环境中成长、繁盛。如果你不确信，你会容易因是被而消极。在你决定读博之前，理想上你可以先在一个夏季研究项目上作为本科生尝试一下做研究。事实上，在 PhD 招聘期间，研究经验如此被看重的主要原因不是研究本身，而是博士生更知道自己正在做什么。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，我想到有人说如果你想进入学术圈就读 PhD。基于上面提到的，我认为 PhD 有强大的固有价值，PhD 本身就是一个目的（end），而不只是达到某个目的（比如，学术圈的工作）方式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;进入一个博士项目&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：推荐、推荐、推荐。好，你决定努力争取一个项目，现在就是如何进入一个好的 PhD 项目？第一等级的逼近方式相当简单，目前最重要的就是强有力的推荐信。理想场景是一个知名教授这样为你写推荐信，「xx 是曾与我一起工作过的学而生中的前 5 名，她积极主动，有自己的想法，并付诸实践。」最差的推荐信就是，「xx 上了我的课，做的不错。」来自夏季研究项目的你自己的学术著作是一个强有力的加分，但并不如你有强有力的推荐信。特别提醒：分数并不强相关，但你一般不太想分数太低吧。本科时这在我身上并不明显，因为我花费大量精力取得好成绩。只有可能就直接与研究有关（或者最低限度就是与个人项目有关），尽可能的多，也尽可能的早，如果可能也要得到多人指导（你需要 3 个以上的推荐信！）最后一点，突然的纠缠未来可能成为你导师的人不会提供任何帮助。他们总是非常的忙，如果你想在回忆上或者通过邮件强势的接近他们，想要给他们深刻的印象，这可能反而会激怒他们。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;选择学校&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。一旦你进入一些 PhD 项目，然后如何选择学校？很简单，斯坦福啊！开玩笑啦。严肃的说，梦想中的大学是首选（不是因为它看起来对你的履历/简历好，而是因为它的反馈环路。顶级学校也吸引其他顶尖人才，你可以跟其中的很多人相识、一起工作。）。第二就是有一些想要一起工作的导师。我说「一些」导师是很认真的，如果首选因各种原因无法达成，比如因理想教授离职、搬走或自然死亡而脱离了掌控，多一些导师选择对你而言很重要，也是一种安全保障。第三，选择一个好的物理环境，我认为新生不够注重这一点：你将花费生命中最好的 5 年时间生活在校园之中。相信我，这是相当长的时间，而且生命中不只有研究。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;导师&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicxmPYrSYxsFzwwTibibQqW0Ns3D58JicJvQvqXBicDNR68VK57g8CeuU19H0ZXsD3g7t8kOhub2n0ia7g/0?"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;导师关系&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。导师是极其重要的人，会对你的博士生涯产生重要影响。理解这个关系的本质是很重要的：导师与学生之间是一种共生关系；你有自己的目标，想在博士阶段出些成果，但是导师也有他们的目标、约束，他们也要考虑自己的职业发展。因此，理解导师的激励机制是很有好处的，包括任职期间如何工作，这个职位的评估标准，他们如何获取经费，他们可能牵扯进了什么样的系内政治，他们如何拿奖，学术界通常是怎么运作的，还有尤其是他们如何获得认可和同事的尊重。这有助于避免或减轻与导师之间的摩擦并允许你进行适当的规划。我也不想让这种关系听上去更像是一种交易。导师与学生之间的关系不应该只是事业发展，而往往是一种持续的、可预测的关系。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;re-tenure 与 post-tenure&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。每位导师都不同，所以理解 tenure-track 的变化和他们对你博士生涯的影响也是很有帮助的。送上一条经验法则（记住也有很多例外），无论你的导师是处于 pre-tenure 还是 post-tenure，紧跟他的职业轨迹非常重要。通常情况下，年轻一些的教员常常比较多，级别也更低，但是他们也会对你的科研任务施加更强烈的建议，和你一起工作，抛出具体的想法，甚至会帮你检查代码（这是好事）。跟着这样的导师，更实际一些，课业也会更紧，因为他们需要发表很多质量不错的论文来获得 tenure，他们有动力推动你一样努力工作。相比之下，级别更高的教员或许有更大的实验室，除研究之外会有其他方面的优势（比如，委员会，讨论会，游学），这意味着，他们在学校里只能处在更高级别的职位，无论是在他们的研究领域，还是在监督学生上。讽刺的是，这就是「你在这个方程中漏掉了一个术语」和「你在这个领域还要多读些资料，和这个或那个人聊聊，这样或那样兜售你的成果」之间的区别。在后一种情况中，低水平的建议仍然来自于实验室里高年级博士研究生或者博士后。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;除了tenure 之外的其他变化&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。还有很多需要注意的变化。一些导师比较随意，另一些对待师生关系则比较专业谨慎。有些人会试图影响你的工作细节，有些则会放开手让你自己去做。一些会专注研究特定的几个模型及其在不同任务上的应用，而另一些则专注于任务不在意建模方法。从管理上看，有些导师能一周（或天！）见上几次，有些几个月都见不到人。一些导师会快速回复邮件，而另一些一周都不会回（甚至更长，哈哈）。一些导师会要求你给他一个时间表（比如，你最好能长时间工作或者周末工作）而另一些不会。一些导师慷慨地支持他们的学生，给学生配设备，还有一些认为有台笔记本或旧台式电脑就可以了。一些导师会资助你去参加会议，即使你没有投论文，有些则不会。一些导师是企业家类型的或者偏向应用，一些则更倾向于理论工作。一些会允许你暑期实习，另一些则认为实习会分心。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;选导师&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。所以导师该怎么选呢？首先要和他们单独面谈。师生关系有时可以比喻成婚姻，要确保你们合得来。当然，首先你得确定你能和他聊天和他相处，不过相对于前述的 Tenure，要明白导师仍旧是教授，尤其是否能与你在你感兴趣的问题上产生智力共鸣。这比他们采取哪种管理方法更加重要。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;收集资料&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。你也应该收集一下心仪导师的资料。和他们的学生聊聊。如果你想得到有用的消息，这件事在正式场合下一定不能做，只能在轻松的场合（比如聚会）下问问未来的学长学姐。很多情况下，学生一般不会直接说导师不好，但是如果你问他具体的问题，他通常会真实的回答你，比如，你可以问「你们多久见一次面？」，或者「他现在有什么职务」。另一个策略是看看他之前带出来的学生最后都怎么样了（你可以在网站上找到），这样你就大概知道自己以后的去处了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;给导师留下印象&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。导师学生互选过程有时可以比喻成婚姻，你选他们，他们也选你。他们认为理想的学生是有兴趣有激情的，自律能力强，不需要手把手教，主动性强，一周内不仅能完成导师布置的任务还能自己有所拓展；用意外的方法改进结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;要考虑整个实验室&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。另一个重点是要意识到你会一周见导师一次，但是同门每天都能在实验室里见到，他们会成为你最亲密的朋友。在大多数情况下，你最后会与一些高年级博士生或博士后合作，他们的角色会非常类似你的导师。尤其是博士后，他们可能是未来的教授，他们也渴望和你一起工作，这样能积累带学生的经验。因此，你要确定整个团队中能有合得来的人，你尊重的人，还有你能亲密地做研究项目的人。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;研究主题&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicxmPYrSYxsFzwwTibibQqW0NZpgQcyjRwK3NXVQ5PULkQDAPCSSSnYM23hv0OMPmziaXuXXdfKH7W5Q/0?"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;人类一小部分知识的 t-SNE 可视化。每一个圈圈都是一篇 arxiv 论文，大小代表参考文献的数量。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以，如果你进入博士阶段，并找到一名导师。如何开展下去呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;外围的锻炼&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。首先注意博士阶段的性质，一个博士学位读下来有苦有乐，因为你会不断接触到元问题（meta problem）。你不只是在解决问题——这仅仅是你要做的分内事。你的大部分时间要花在外围上，找出什么问题是值得解决的，什么问题已经成熟到可以解决。你要持续想象自己在解决假设问题，问自己处在什么位置，这个问题能打开什么，或者是否有人关心你研究的问题。如果你像我一样，就会有点疯狂，因为你在花大量的时间在做你甚至无法确定是否正确，也不知道能不能解决的事情。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;研究品味&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。当你选择研究问题时，你会听到学术界讨一个神秘的概念「品味（taste）」。它一个实实在在的东西。当你向导师提出一个潜在的问题时，你可能会看到他们扭曲的脸，瞪大的眼睛，注意力飘忽的表情，或者当他们思考未知领域亟待探索时，你能感受到他眼神里的兴奋。在你抛出问题的瞬间发生很多事情：评价问题的重要性、难度、吸引力，它的历史语境（可能也会考虑是否能得到补助）。换句话说，你的导师是外围问题大师，在判断问题上品味很高。在博士阶段，你也会慢慢获得这方面的悟性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我想过去我这方面的品味不太好，从我早期的博士笔记中就能看出来。当时令我兴奋的很多问题现在回想起来在构思上都不够精巧，难以下手，相关性也不强。经过实践和学习后，我的品味才得到提升。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我来试着总结一下关于怎样培养品味的思考，以及怎么让问题有趣地研究下去。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;一个丰饶的领域&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。首先，要意识到在你的博士阶段你会深入某个领域，你的论文很有可能进入研究链的顶端，自成体系（成为你的 thesis）。因此，选择一个问题时，你应该多往前思考几步。预测事情怎样进展不太可能，但是你能感知到你还有多大的研究空间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;配合导师的研究兴趣和研究长处。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;你会想要直接进入导师研究兴趣的领域。一些导师或许会只允许你进入边缘地带，但是这样你就不能全部利用他们的知识，他们就不太可能想帮助你的项目或促进你的工作。例如，（这是我以前的想法）每位导师在研究上都有一个通用的幻灯片模板，如果你的研究成果够前沿，能被添加到那个幻灯片模板中，你就会发现导师对你的研究投入更多了，给你的帮助也多了。此外，他们还能帮助推广和公开你的成果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;要有点雄心&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;：在努力这件事上要做到收放自如&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。人的心理都有个奇怪的 bug： 10 倍的重要或影响的问题在直观感觉解决起来就需要 10 倍的努力。这是个错觉——我的经验是 10 倍重要的问题，至多需要 2 到 3 倍的努力就行了。事实上，在一些情况下，一个 10 倍困难的问题解决起来可能更容易。为什么？因为你会有 10 倍的动力走出自己的黑箱，看到方法真正的局限性。从首要原理（first principles）开始思考，改变全部策略，继而创新。如果你渴望做出 10% 的改进并且很努力，你就会成功。但是如果你渴望做出 100% 的改进，你仍然很有可能成功，但会以一种非常不同的方式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;雄心但也要能解决&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。在这一点上，需要指出的重要一点是有很多重要的问题无法做成大项目。我推荐阅读 Richard Hamming 写的一条博客：你与你的研究（You and Your Research），这里面探讨了这个问题：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p&gt;&lt;span&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;如果你研究的问题不重要，你也就很有可能无法做出重要的成果。这是十分明显的。伟大的科学家会深思熟虑他们领域内的许多重要的问题，而且他们会密切关注、仔细琢磨如何攻克它们。让我警告你，「重要的问题」必须小心谨慎。当我在贝尔实验室的时候，物理学的三大突出问题在一定意义上都没有得到过研究。这里所说的「重要」是指肯定能得到诺贝尔奖和任何数量你想要的资金。我们不研究 1）时间旅行，2）物质传输，3）反重力。它们并不是不重要，而是因为我们无力解决。决定一个问题是否重要并不是因为结果，而是你可以合理地解决。这才是使一个问题重要的原因。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;做到 X 的人&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。最后，PhD 的目标不只是成为某个领域内的深度专家，而且还要在这个领域打上你的烙印。要引导它，塑造它。理想的情况是：当你的 PhD 阶段结束时，你已经在一个重要领域赢得了自己的一席之地，最好是一个可以容易和快速地描述的领域。你想听到人们说「她就是那个做到 X 的人」这样的话。如果你能填补一项空白，你就是成功的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;有价值的技能&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。认识在到读博期间你将成为所选择的领域内的一名专家（撇开兴趣不谈，5 年×每年 260 个工作日×每天 8 个小时是 10,400 小时。如果你相信 Gladwell，PhD 正是需要大量的时间才能成为专家。）所以，想一下 5 年后你成为了这个领域的世界级专家（不论你的研究的学术影响，1 万小时将保证这一点。）拥有这些技能是不是很振奋？或者对你未来的职业足够有价值？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;负面例子&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。也有一些难题或者论文类型你理想上想要避免。例如，有时你听到学习界讨论「增量工作（incremental work）」（这简直是学术界最糟糕的形容）。增量工作是指一篇论文通过使其更复杂并在一些基准上得到 2% 的额外增分，从而增强了一些已有的事情。这些论文的可笑之处在于有很高的机会会被接收（评审员没有拒绝这些论文的理由；有时它们也被称为 cockroach paper），所以你有这样的一系列论文被接受，你可以感觉自己非常高产，但事实上这些论文不会有很高的引用，你也不会在该领域有很高的影响力。类似的，寻找研究工程不能只理想的考虑「有这样一个下一步逻辑步骤还没有人做，让我来做」，或者「这应该是一个非常简单的 poster。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;案例学习&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;：我的主题&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。为了更详细的讨论这个话题，我打算使用自己如何展开 PhD 作为例子。首先，有趣的事实：我的整个主题都基于 PhD 期间一年半的研究。也就是，它花费了我相当长的时间在元问题空间（metaproblem space）不断摇摆，然后才找出了一个我感觉令我振奋的问题（其他两年我大部分是做 3D，比如 Kinect Fusion、3D 网、点云特征（point cloud features）、还有视频方面的工作）。然后在我读博第三年，在某个周六的下午两点，我来到了 Richard Socher 的办公室。我们闲聊时我意识到他在图像和语音上研究的一些问题事实上非常的有趣（当然，图像和语言交叉的这个领域在 Richard 之前就有了。）我难以看完所有需要查看的论文，但该领域看起来相当有前途：该领域相当的富饶（大量未解决的难题，在对图像进行基础描述尚有大量的可能性。）我认为这相当的酷，也很重要，也很简单去解释，看起来它处于成为可能的边缘（深度学习也只是刚开始有效），数据集也刚开始变得可用（Flickr8K 也刚出现）。这刚好满足李飞飞的兴趣，即使我没有成功，我至少得到了大量的时间，优化了我可能用于其他领域的有趣的深度网络。当所有事在我脑海中出现的时候，我强烈感觉到一股海啸。我把这个主题在第二天投给了导师李飞飞，感觉松了一口气。她热情澎湃地通过了，给予我鼓励。而且在接下来的工作中指导我，（例如，在我满足于排名的时候，飞飞坚持让我做图像语句生成。）后续的发展让我很高兴。简言之，我游荡了近两年才发现要深入的领域。给予数个启发方法，一旦我发现我要做什么，我就深入地去做。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;阻力&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。我还想提一下你的导师绝不可能是一贯正确的。我已经见过或听说过很多实例了，现在回想起来，导师应该为错误负责。如果你在读博士时觉得导师错了，有时候你应该鼓起勇气忽略导师的看法。学术界普遍赞赏独立思考，但你特定导师的回应可能会随着环境发生变化。我就知道一些赌一把最后得到了很好结果的例子，而我个人也经历过一些效果并不好的例子。比如说，在我第一年的时候，我坚决不同意吴恩达给我的一些建议。我最后开始研究一个他并不非常感兴趣的问题，但让人惊讶的是，事实证明他是非常正确的，而我则浪费了几个月时间。吃一堑长一智嘛 :)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;不要耍滑头&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。最后，我要让你认为 PhD 不只是一连串的论文。你不是一个论文写手。你是科研界的意愿，你的目标是推动该领域向前发展。论文是其中一种常见的做法，我建议你不要把目光放在已有的学术领域内。首先为自己想想，做一些其他人没有做但应该做的事，远离别人在你之前已经做出的成果。在我的整个 PhD 阶段我一直在尝试这么做。这个博客就是一个例子——这让我可以谈论一些通常不会发在论文里面的东西。ImageNet 人类推理实验就是一个例子——我强烈地认为，在 ILSVRC 上知道人类大致的准确度对该领域来说是非常重要的，所以我花了几周时间对其进行了评估。学术搜索工具（如 arxiv-sanity）也是一个例子——一直以来我都为论文文献搜索的低效性感到沮丧，所以我发布并维护了这个站点以便对他人有所帮助。两次参加 CS231n 教学也是一个例子——我在上面花了大量的精力，超过了一个应该做研究的博士生的合理程度，但我认为如果人们不能有效地学习这个主题和进入这一领域，这一领域的发展就会受到拖累。我的很多博士阶段的工作都很有可能会牺牲一些标准的学术指标（如 H 指数或在顶级会议上发表的数量），但我还是做了那些事情，我还会同样地再做那些事，在这里我也鼓励其他人也这么做。这可能言过其实了一点，除却思想观念上的一些东西，根据过去我与朋友和同事一些讨论，我知道这个观点是存在争议的，而且很多人也并不认同。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;写论文&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicxmPYrSYxsFzwwTibibQqW0N3IjbuEkbQPpxGzDcs0KUHfSHY8r69TV03HWSpf3wBiav3WRRQLDibemA/0?"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在学术界，能写好论文是一项关键的生存技能（就像是生火技能对穴居人一样）。特别地，很重要的一点是要意识到论文是一种特别的事物：它们看起来有一定的形式、以一定的方式流动、有一定的结构、语言以及其他学者所期望的统计数据。对我来说，查看我博士早期阶段的论文真是一种痛苦的历练，因为它们实在太糟糕了。在这方面有很多东西需要了解。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;查阅论文&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。如果你正在学习写更好的论文，阅读许多好论文并提取出其中的模式似乎是一个明智的选择。但事实证明这并不是最好的策略；这就好像是对于一个二元分类问题只接受正面的样本一样。你真正需要的是查阅大量糟糕的论文，其中一种方法是评阅论文。大部分好的会议的论文接收率大约为 25%，所以你查阅的大部分论文都很差，这让你可以构建一个强大的二元分类器。你可以阅读一篇糟糕的论文，看它的描述有多么不清楚，或者它如何没有定义自己的变量、摘要介绍有多模糊、或者它如何过快地深入到了细节之中——你可以学习让你的论文不落入同样的陷阱。另一个相关的有价值的经验是参加（或组织）读书俱乐部——你将看到经验丰富的研究者批评论文，并且了解自己的论文将会被其他人怎样分析。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;格式正确&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。我清楚地记得有一次和飞飞参加一次审阅会议。我在前面的几个小时里只评阅了 4 篇论文，而她拿起这些论文，每篇只翻了 10 秒钟就说其中一篇很好，其它都很糟糕。确实如此，我也接受了这一篇并拒绝了其它三篇，但这项花费我几个小时做成的事她只用几十秒就完成了。飞飞是将论文的格式作为强大的启发线索的。随着你变成越来越资深的研究者，你的论文将有一种特定风格的外观。一页引言/介绍。一页带有合适密度引用文献（不过于稀疏也不过于密集）的相关成果介绍。一张设计良好的 pull figure（在第一页或第二页）和系统图（在第三页）——不要用 MS Paint 制作。描写技术的章节在某个地方有些数学符号、带有大量数字的结果表（其中一些是粗体）、一个额外的聪明的分析实验、而且论文正好有 8 页（页数限制）且一行不少。你将不得不学习如何为你的论文赋予相同的格式，因为许多研究者在评价你的成果时都将其作为认知的捷径。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;确定核心贡献&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。在你开始写任何东西之前，首先很重要的是要确定你的论文对该领域的一个单一的核心贡献。我会特别强调其中的单个词。一篇论文不是你运行的一些实验的随机集合的报告。论文的目的是给出一个之前并不存在或并不明显的单个事物。你必须认为这个事物是重要的，它之前从未被完成过，然后你通过实验的方式在有对照组的环境中证明它的优点。整篇论文都应该围绕这一核心贡献精准地展开。尤其是不要有任何额外的无价值的扩展，也不要裹带任何其它东西。举一个具体的例子，在我早期的一篇关于视频分类的论文（Large-scale Video Classification with Convolutional Neural Networks）中我就犯了这个错误，我尝试一次打包两个贡献：1）一个用于视频卷积网络的架构布局集合，2）一个不相关的带有很小改进的多分辨率架构。我把它加上去是因为我觉得一是也许有人会对此感兴趣然后跟进后续研究，二是因为我觉得论文的贡献越多越好：两个贡献好于一个贡献。不幸的是，这是一个非常彻底的错误。第二个贡献是微不足道的/可疑的，它稀释了这篇论文，分散了注意力，而且也没人关心。在我 CVPR 2014 的一篇论文（Deep Visual-Semantic Alignments for Generating Image Descriptions）中我又犯了类似的错误，我在该论文给出了两个没有关联的模型：一个排序模型和一个生成模型。我可以举出一些好的论据来证明我应该分开发两篇论文；只些一个贡献的原因更多是历史上的，而非理智上的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;结构&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。一旦你确定了你的核心贡献，就有了一个写论文的默认配方。上层结构默认的是引言/介绍、相关工作、模型、实验、结论。当我写我的引言时，我发现可以以相关评论的形式写下一些条理分明的顶层叙述，然后再填写下面的文本，这会很有帮助。我喜欢围绕单个明确的点来组织我的段落，并且这个观点在第一段就会给出，并用该段的剩下部分来支撑这个观点。这样的结构可以让读者轻松地快速略览。然后我们需要一个好的思维流程，可以按以下线索进行：1）X（如果不明显，还要加上对 X 的定义）是一个重要的问题；2）核心的挑战是什么，2）X 上之前的成果已经用 Y 解决的问题，而这一次的问题是 Z；3）在这项工作中，我们做了 W(?)；4）这有以下有吸引力的特性，我们的实现表明了什么。你可以稍微调整这个结构，但这些核心的点需要得到明确。再重申一下：论文需要围绕你的确切贡献精准地进行组织。比如说，当你罗列挑战的时候，你需要确切列出那些你将在后面解决的问题，而不要牵扯到你做的与之无关的事情上（你可以在后面的结论中多做一点推测）。不只是在引言中，保持论文整体的合理结构也是很重要的。比如说，当你解释你的模型时，每一节应该：1）解释清楚在这一节做了什么，2）解释核心挑战，3）解释基本方法或之前其他人做了哪些工作，4）解释你的动机和你所做的工作，5）描述它。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;打破结构&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。你也应该灵活应对这些格式，扩展你的论文，为之增加一点香料。比如说 Razavian et al. 的这篇论文（CNN Features off-the-shelf: an Astounding Baseline for Recognition）惊人地将引言做成了一位学生和教授的对话形式。这做得很聪明，我很喜欢。另一个例子，Alyosha Efros 的很多论文都带着一种俏皮的语气，为有趣论文的书写给出了绝佳的案例。比如说他与 Antonio Torralba 合著的这篇论文《Unbiased look at dataset bias》。另一种我见过的效果不错论文是问答式的章节，可能用在附录中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;常见的错误&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：洗衣清单（laundry list）。洗衣清单是应该避免的一种非常常见的错误，它看起来像这样：「这里有一个问题。现在为了解决这个问题，我们首先做 X，然后我们做 Y，再做 Z，之后再是 Y，就得到了我们的结果。」你应该竭力避免这种结构。每一个点都应该得到证明、给出动机和解释。为什么你要做 X 或 Y？有没有替代选择？其他人做了什么？可以说这样的论文很常见（如果可能的话我倒愿意给出例子）。你的论文不是一份报告，不是你做过的事情的枚举，也不是你的按时间排列的笔记和实验的某种格式化的翻译。论文是对于一个问题、你的方法和其背景的高度处理过的和高度聚焦的讨论。它应该能教给你的同事一些东西，它必须要能证明你的步骤，而不只是描述你做了什么。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;语言&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。随着时间的推移，你会积累一个写论文时的好词词典和坏词词典。具体可以机器学习或计算机视觉论文为例：在你的论文中永远不要出现「study」和「investigate」（这是无聊的、被动的、糟糕的词）；而你应该使用「develop」或甚至「propose」这样的词。你不要提出一个「system」或甚至更糟的「pipeline」；相反，你开发了一个「model」。你不是在学习「features」，你是在学习「representations」。而且上帝保佑，你千万不要使用「combine」、「modify」或「expand」。这些多余的、粗陋的术语肯定会让你的论文被拒 :)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;提前两周的内部截至时间&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。并没有许多实验室这样做，但幸运的是飞飞对这个提前两周的内部截至时间限制很是坚定，在这个时间，你必须提交至少 5 页带有所有最终实验的草稿（即使不是最终的数字）；这份草稿会进入一个与外部完全一样的内部评审过程（具有相同的评审表等等）我发现这种做法非常有用，因为这会迫使你思考整篇论文的布局，从而总是能让你彰显出一些你必须为这篇论文的思路而运行的关键实验，并让论据思路条理清晰、连贯和有说服力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关于这一主题的另一个好资源是 Jennifer Widom 写的《Tips for Writing Technical Papers》&lt;/span&gt;&lt;span&gt;（https://cs.stanford.edu/people/widom/paper-writing.html）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;写代码&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWicxmPYrSYxsFzwwTibibQqW0NuoKC35qos7b5Oz5vg2tUa2KDXbm3YLVeiciavjK9pukicV9iacvAqU4wqQ/0?"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然，你仍旧会花很多时间在实现你的想法上，也就是说，你还会编写很多代码。因为这并不是学术上独有的工作，所以我不会在此详谈，但还是有几点我想提一下。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;公开你的代码。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;虽然你可能会感到惊讶，但是你确实可以不发表论文也不公开代码。同时，你有很多动机将自己的代码藏起来：写代码会花费许多时间（研究项目的代码看起来像是意大利面，因为它的迭代非常快，所以你需要经常进行清理）；同时，光是想到别人可能会对你的代码评头论足，就已经足够吓人了，维护代码以及回答别人（永远会有）的问题是非常痛苦的，你甚至会担心别人可能会发现代码中的错误，从而减弱了研究的可信度。然而，这正是你应该发表代码的原因之一：为了避免尴尬的情况发生，你会不断采用更好的编码习惯（而这最终会帮你节省时间！）；你会被迫使学习更好的工程实践；你会被迫使对自己的代码更加严格要求（例如，编写单元测试以最小化错误出现的可能性），这一切都将让你的研究受到更多关注（并由此带来更多的引用次数），并且很自然地，你的研究也将对之后的研究更加有用。当你真的准备发表代码的时候，我建议你好好利用 docker containers（https://www.docker.com/）&lt;/span&gt;&lt;span&gt;；它会减少人们发邮件来问你要附件（和它们的各种版本），从而减轻你的烦恼。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;为将来的你着想&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。为了你自己的便捷，务必将自己的所有代码妥善记录，我保证几个月之后你会回来看你的代码（例如，为即将发表的论文再做几个实验），那时，你会一头雾水。我已经养成了为（自己的）每一个版本编写非常详尽的 readme.txt 文件的习惯，以便未来的自己能够明白代码的原理和使用方法等等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;做演讲&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWicxmPYrSYxsFzwwTibibQqW0NQSkUs043uxyRdNaTq0mpvbdbgFJQKqoLytBwxQqc4BDD4hz80Ez4cA/640?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在，你的论文成功发表了！你需要就这篇论文向许多观众进行几分钟的演讲——它应该是什么样的？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;演讲的目的&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。首先，一个常有的误解是，演讲的目的是向听众介绍你在论文中做了什么。这是错误的，这一目的最多也只能排在第二或第三位。你的演讲应应该：1）使听众对你研究的问题产生浓厚兴趣（如果大家对问题本身没兴趣，他们也不会在乎你的解决方法的！）2）教些东西给听众（理想的情况是在让大家体验你的思考 / 解决方案的时候，不要害怕在别人的相关工作上花时间）以及 3）有趣（否则很多人会开始刷 Facebook）。理想情况下，在演讲结束之后。你的听众中应该有人在想这几件事情：「哇，我要换个研究方向」，「我一定要看看这篇论文」，以及「作者本人对整个领域的理解非常出众。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;一些可以做的事情&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：有些特征会让演讲更上一层楼，例如，要：有许多图片。人们喜欢图片。录像和动画应该更少一些，因为它们容易让人分心。要让演讲内容高度可执行——将一些人们在听到之后可以马上动手去做的东西。要：如果可能的话给一个 demo，它会让你的演讲更容易被记住。要发展一个你的研究涉及到更广泛的领域。要讲成一个故事（人们喜欢故事）。要引用，引用，引用——很多应用！加入引用不会占用你的幻灯片多大的空间，而你的同行们会因此感到高兴，并且认为你是一个十分谦虚的人，因为你意识到自己的贡献是建立在他人的许多成果之上的。你甚至可以引用在同一个会议发表的文章，并为之做简短的推荐。要进行练习！先自己练习，然后向同事 / 朋友展示。这常常会帮你发现许多叙述和流程中的重要问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;不要加很多文字&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。不要让文字挤满你的幻灯片。你应该少用甚至不用重点标识——演讲者们有时会使用重点标识来提醒自己要讲些什么，但是幻灯片不是给你自己看的，而是给观众看的。重点标识应该出现在你的演讲笔记中。于此类似地，尽可能地避免使用复杂的图表——你的听众是有固定带宽的，并且我保证那些在你看来十分熟悉且「简单」的图表，对于那些第一次看到的人来说，就不是这么好理解了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;注意，结果表&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：不要使用信息十分密集的表格来展示你的方法有多么优秀。既然你已经写了篇论文出来了，我相信你的结果至少是可靠的。我一致认为这一部分是非常无聊和无用的，除非数字能够表明一些（与证明你的论文无关的）十分有趣的东西，或者数字所表明的差距确实非常巨大。如果你真的要展示结果或图表，请循序渐进地将它们展示出来，而不是把所有东西扔到页面上，然后在一页幻灯片上花上三分钟。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;陷阱&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;：无聊与困惑之间的微小距离&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。如果你听众中的许多人都抱着一种学习的心态而来，要设计出一个好的演讲不是那么容易的。一个常见的失败案例是（作为一个听众），在演讲的前半段无聊至死，然后在后半段困惑不已，最后啥都没学到。经常出现这一情形的演讲的特点是，摘要非常概括性（过于概括了），然后紧接着技术（过于技术的）详解。尝试在你的演讲中规避这一倾向。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;陷阱：超时&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。许多演讲者会在开始的部分花费过多的时间（一般来讲这也会使得演讲变得无聊），然后火急火燎地了解最后的几张幻灯片，而那些往往是最有趣的结果、分析或 demo。不要做这样的演讲者。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;陷阱：形式化的演讲&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。我可能是个特例，但是我一直都喜欢挑战传统的、规避形式化的演讲。例如，我鄙视在幻灯片中加入演讲大纲的行为。因为这使得整个演讲变得无聊，就像在说：「这部电影讲述的是一个有魔力的戒指，在第一章我们会看到一个霍比特人得到这个戒指，第二章我们会看到他去了 Mordor，第三章里他将戒指扔到了 Mount Doom 并将之毁坏了。我将从第一章开始讲起」——拜托别这样！我只在非常长的演讲中才使用大纲页面，以便于听众在走神之后重新恢复记忆（30 分钟后他们往往会走几次神），但是这应该尽量少用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;观察并学习&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。最终，成为一个优秀演讲者的最好方法是（写论文也是这样），留意观察优秀的（和不怎么优秀的）演讲者的行为，然后在你的大脑里构建一个二元分类器。不要仅仅做演讲的听众；你要对它们进行分析、分解、然后从中学习。除此之外，留意现场反应。有时，当演讲者展示出一个复杂的数字表格时，你会注意到，许多观众立马低头看起了手机。为可能导致这一场景的行为构建一个内部分类器，并在你自己的演讲中避免这些行为。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参加会议&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWicxmPYrSYxsFzwwTibibQqW0NloYZbDa6XG5pGz9AhD6t98onrVtddQnP0Xz6Ow9DV1jn8KWntOvgFQ/0?"/&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于会议：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;参加。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;参加会议是很重要的，特别是你所在的领域的最顶尖的 1-2 场会议。如果你的导师缺乏资金，不愿意为你的路费买单（例如，当你还没有论文的时候），那么你应当愿意自己买单。这是很重要的，因为你需要成为学术圈的一员，并能够见到更多同僚，以及了解研究话题的八卦。科学界可能有一些极少数的单打独斗的人，但是真相是，做研究很大程度上是一个高度社交性的事业——你是站在许多人的肩膀上的，且还有许多人和你一起努力，并且这些人也是你的论文的阅读者。此外，我很遗憾这么说，但是每一个领域都有一些没有出现在论文里、但是在整个圈子里广为流传的知识，包括接下来的重要话题有什么，哪些论文是最有趣的，论文的内线消息是什么，他们之前是如何发展的，哪些方法管用了（不是在论文里，而是在实际中），等等等等。成为圈子里的一员，并且了解这个集体中的共识，是很有价值的（并且很有趣！）——首先从中学习，然后最好能够影响这个圈子。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;讲座&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：根据演讲者进行选择，我使用的一个会议技巧是，在选择讲座的时候要看演讲嘉宾，而不是讲座主题（这是一项技能，慢慢地你会发现有价值的人），并且，根据我的经验，我发现亲耳听这些人演讲会大有裨益，尽管话题甚至和你的研究领域没有直接联系。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;真正有价值的信息可能在走廊上&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。现在，创新的速度（尤其在机器学习领域）已经比会议的间隔时间要短了，所以你在会议看到的大部分论文实际上都算是旧新闻了。因此，会议更多地是一项社交活动。与其参加一个讲座，我建议你把去走廊转转作为一项主要活动。你还可以去海报宣传去逛逛，说不定会发现一些错过的有趣论文和想法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p&gt;&lt;span&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;据说一个博士生有三个阶段。在第一个阶段，一篇相关论文的引用你大部分都没看过；在第二个阶段，你能认出这些论文；在第三个阶段，你已经与所有论文的第一作者喝过一圈了。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;最后的一些想法&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管我现在找不到出处了，但是我曾听到 YC 的 Sam Altman 说，建立一个创业公司没有捷径可走。你不能指望通过玩弄体制，或者通过伪装来获得长久的胜利。我想在学术领域也是一样的。最终，你的目的是用优秀的研究推动这一领域的进步，如果你试图针对某些指标动手脚，从长远来看你无法成功。在学术界尤其如此，因为学术界令人惊讶地小，并且高度关联，所以，任何你试图在学术履历上用点阴招（例如，常常自己引用自己、将同一想法稍作修改后重复发表、重复提交被退回的论文而没有丝毫修改、为了自己的便利而抛弃一些基本原则，等等）最终将让你尝尽苦果，而你也不会成功。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以，总而言之就一句话：好好工作、适当交流，人们会注意到你，好事也会发生。祝博士之旅愉快！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;论文：连接图像与自然语言（CONNECTING IMAGES AND NATURAL LANGUAGE）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWicxmPYrSYxsFzwwTibibQqW0NcD1jPRoNpwbrtxaVGmtNaMnx5vTIluH24mvvrib9lQ7ukRCbo8xP6Og/0?"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;导师审核&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要&lt;/span&gt;&lt;strong&gt;&lt;span&gt;：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;人工智能领域的一个长期目标是开发能够感知和理解我们周围丰富的视觉世界，并能使用自然语言与我们进行关于其的交流的代理。由于近些年来计算基础设施、数据收集和算法的发展，人们在这一目标的实现上已经取得了显著的进步。这些进步在视觉识别上尤为迅速——现在计算机已能以可与人类媲美的表现对图像进行分类，甚至在一些情况下超越人类，比如识别狗的品种。但是，尽管有许多激动人心的进展，但大部分视觉识别方面的进步仍然是在给一张图像分配一个或多个离散的标签（如，人、船、键盘等等）方面。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这篇学位论文中，我们开发了让我们可以将视觉数据领域和自然语言话语领域连接起来的模型和技术，从而让我们可以实现两个领域中元素的互译。具体来说，首先我们引入了一个可以同时将图像和句子嵌入到一个共有的多模态嵌入空间（multi-modal embedding space）中的模型。然后这个空间让我们可以识别描绘了一个任意句子描述的图像，而且反过来我们还可以找出描述任意图像的句子。其次，我们还开发了一个图像描述模型（image captioning model），该模型可以根据输入其的图像直接生成一个句子描述——该描述并不局限于人工编写的有限选择集合。最后，我们描述了一个可以定位和描述图像中所有显著部分的模型。我们的研究表明这个模型还可以反向使用：以任意描述（如：白色网球鞋）作为输入，然后有效地在一个大型的图像集合中定位其所描述的概念。我们认为这些模型、它们内部所使用的技术以及它们可以带来的交互是实现人工智能之路上的一块垫脚石，而且图像和自然语言之间的连接也能带来许多实用的益处和马上就有价值的应用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从建模的角度来看，我们的贡献不在于设计和展现了能以复杂的处理流程处理图像和句子的明确算法，而在于卷积和循环神经网络架构的混合设计，这种设计可以在一个单个网络中将视觉数据和自然语言话语连接起来。因此，图像、句子和关联它们的多模态嵌入结构的计算处理会在优化损失函数的过程中自动涌现，该优化考虑网络在图像及其描述的训练数据集上的参数。这种方法享有许多神经网络的优点，其中包括简单的均质计算的使用，这让其易于在硬件上实现并行；以及强大的性能——由于端到端训练（end-to-end training）可以将这个问题表示成单个优化问题，其中该模型的所有组件都具有一个相同的最终目标。我们的研究表明我们的模型在需要图像和自然语言的联合处理的任务中推进了当前最佳的表现，而且我们可以一种能促进对该网络的预测的可解读视觉检查的方式来设计这一架构。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;2016 年是人工智能不断突破的一年。这一年，我们经历了语音识别的突破、风格迁移的兴起、神经机器翻译的进步，等等。而这每一条消息的宣布机器之心都紧紧跟随。于是在岁末年关，机器之心将回顾过去一年中我们曾发布过的爆款文章。流量不代表文章质量，但选出的每一篇文章却代表了机器之心读者的关注点，以及我们自己的价值观。精彩的一年，我们一起见证，一起回顾。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;点击「阅读原文」，下载论文↓↓↓&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 29 Jan 2017 13:31:25 +0800</pubDate>
    </item>
    <item>
      <title>专题 | 深度强化学习综述：从AlphaGo背后的力量到学习资源分享（附论文）</title>
      <link>http://www.iwgc.cn/link/4510933</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自arXiv&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Yuxi Li&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;编译：Xavier Massa、侯韵楚、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicZmeY010RKGdeG0RTc2d1dyKPCicic1iaccicZMYETjVbQo1SPDI1Z2ouOGCk13N8riaEqo10EwO34J5g/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;摘要&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本论文将概述最近在深度强化学习（Deep Reinforcement Learning）方面喜人的进展。本文将从深度学习及强化学习的背景知识开始，包括了对实验平台的介绍。接着我们会介绍深度 Q 网络（Deep Q-Network，DQN）及其拓展、异步方法（asynchronous methods）、策略优化（policy optimization）、奖励（reward）及规划（planning）。在这之后，我会讨论注意和记忆（attention and memory）机制、非监督学习及学习去学习。随后，会讨论强化学习的各种应用，包括在游戏（特别是 AlphaGo）、机器人、口语对话系统（聊天机器人）、机器翻译、文本序列预测、神经架构设计、个性化网络服务、医疗、金融及音乐生成等方面的应用。我们会提到一些未覆盖到的主题/论文。在列举强化学习相关资源之后，我们将会以讨论结束论文。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1 导语&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;强化学习（RL）实际上是关于序列决策的一种工具，它能够解决包括科学研究、工程文理等学科的一系列问题（Sutton and Barto, 2017）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;增强学习及神经网络的结合可以追溯到 1990 年代（Tesauro, 1994; Bertsekas and Tsitsiklis, 1996; Schmidhuber, 2015）。而在最近深度学习的突破性进展之下（LeCun et al., 2015; Goodfellow et al., 2016），得益于大数据的普及、计算能力的提升及新的算法技术，我们正见证着强化学习的复兴（Krakovsky, 2016），特别是强化学习及深度学习的结合（也就是深度强化学习（deep RL））。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们已见证了诸多突破性进展——深度 Q 网络（Mnih et al., 2015）、AlphaGo（Silver et al., 2016）及可微分神经计算机（Graves et al., 2016）。还有一些全新的架构及应用，包括异步方法（Mnih et al., 2016）、对抗网络架构（Dueling Network Architectures，Wang et al., 2016a）、价值迭代网络（value iteration networks，Tamar et al., 2016）、用于机器翻译的双学习（dual learning for machine translation，He et al., 2016a）、口语对话系统（spoken dialogue systems，Su et al., 2016b）、信息提取（information extraction，Narasimhan et al., 2016）、 引导性策略搜索（guided policy search，Levine et al., 2016a）、 生成对抗模仿学习（generative adversarial imitation learning，Ho and Ermon，2016）、非监督的强化及辅助学习（unsupervised reinforcement and auxiliary learning，Jaderberg et al., 2017）及神经架构设计（neural architecture design，Zoph and Le, 2017）等等。在这篇概述中，我们主要关注近几年的工作成果，当然也只能覆盖不完全的、一小部分成果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们将给读者一系列的参考资料以帮助其进一步学习：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;强化学习（Sutton and Barto, 2017; Szepesvari, 2010; Bertsekas, 2012; Powell, 2011; Bertsekas and Tsitsiklis, 1996; Puterman, 2005; Littman, 2015; Kaelbling et al., 1996）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深度学习（LeCun et al., 2015; Goodfellow et al., 2016; Bengio, 2009; Deng and Dong, 2014）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器学习（Jordan and Mitchell, 2015; Hastie et al., 2009;Bishop,2011;Murphy,2012;Jamesetal.,2013）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;实用机器学习建议（Domingos，2012；Zinkevich，2017）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能（Russell and Norvig, 2009）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;神经网络中的深度学习（Schmidhuber，2015）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自然语言处理（Hirschberg and Manning，2015；Deng and Liu, 2017）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器人学（Kober et al., 2013）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;迁移学习（Taylor and Stone、2009；Panand Yang，2010；Weiss et al., 2016）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;半监督学习（Zhu and Goldberg，2009）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;贝叶斯强化学习（Ghavamzadeh et al., 2015）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;口语对话系统（Hinton et al., 2012；He and Deng，2013；Young et al., 2013）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能安全（Amodei et al., 2016； Garcia and Fernandez，2015）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;蒙特卡洛搜索（MCTS）（Browne et al., 2012；Gelly et al., 2012）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;多代理强化学习（Shoham et al., 2003；Busoniu et al., 2008）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;博弈论（Leyton-Brown and Shoham，2008）等等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们将会在 23 节中列举强化学习资源。在 goo.gl/KoXIQC 及 goo.gl/1Q1lzg 参见强化学习的应用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该概述的大纲如下：第二节，深度学习及强化学习的背景知识及对测试平台的介绍；第三节，对深度 Q 网络及其拓展的介绍；第四节，异步放法的介绍；第五节，策略优化；第六节，奖励；第七节，规划；第八节，注意和记忆机制，特别是对可微分神经计算机（DNC）的介绍；第九节，非监督学习；第十节；学习去学习（learning to learn）；第十一节，游戏/博弈，包括棋类游戏、视频游戏及非完美信息博弈；第十二节，AlphaGo；第十三届，机器人学；第十四节，对话系统（聊天机器人）；第十五节，机器翻译；第十六节，文字序列预测；第十七届，神经架构设计；第十八节，个性化网络服务；第十九节，医疗；第二十节，金融；第二十一节，音乐生成；第二十二节，一个未回顾论文/话题的待办清单；第二十四节，讨论。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;特别地，我们将在 23 节中列举一系列关于强化学习的资源，包括图书、在线课程、教程、会议、期刊、研讨会乃至博客等。如果非要选择唯一一个推荐的强化学习的资源，那么应该是 Sutton 教授的强化学习书（RL Book，Sutton and Barto，2017，第二版正在编辑中）。它覆盖了强化学习的基础知识，并介绍了它最新的进展，包括深度 Q 网络、AlphaGo、梯度策略方法（Policy Gradient Methods）及在心理学与神经科方面的进展。对深度学习而言，则可以选择 Goodfellow 等人的书（2016）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2 背景知识&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这一节中，我们将会简要介绍在深度学习（Sutton and Barto，2017）与深度学习（Goodfellow et al., 2016）方面的基础知识与概念。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2.1 深度学习&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2.2 强化学习&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2.3 测试平台&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;街机学习环境（Arcade Learning Environment，ALE，Bellemare et al., 2013）是一个由 2600 个 Atari 游戏构成的用于研发及评估 AI 的框架。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;DeepMind 团队则发布了它的第一人称视角 3D 游戏平台 DeepMind Lab（Beattie et al., 2016）。DeepMind 及暴雪会合作以发布星际争霸 2 的人工智能研究环境（goo.gl/Ptiwfg）。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;OpenAI Gym（https://gym.openai.com/）是一个用于开发强化学习算法的工具包。它由一系列环境构成，包括了 Atari 游戏及模拟的机器人构成，以及一个用于比较及复现结果的网站。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;OpenAI Universe（https://universe.openai.com/）被用于将任一程序转换到一个 Gym 环境。Universe 已经集成了许多的环境，包括 Atari 游戏、flash 游戏、如 Mini World of Bit Sand 这样的浏览器任务。最近，侠盗猎车手 5（GTA5）也已经被加入到 Universe 中来帮助模拟自动驾驶车辆。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;FAIR TorchCraft（Synnaeve et al., 2016）是一个为如星际争霸这样实时战略类（RTS）游戏开发的库。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;ViZDoom 是一个基于《毁灭战士（Doom）》游戏的为研究视觉强化学习的研究平台。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;TORCS 是一个赛车比赛驾驶模拟器（Bernhard Wymann et al., 2014）。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;MuJoCO（Multi-Joint dynamics with Contact）是一个物理引擎，参见：http://www.mujoco.org/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Duan et al., 2016 为连续控制任务给出了一个跑分平台，开源代码参见：https://github.com/openai/rllab&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Nogueira and Cho（2016）展示了 WebNav 挑战，来测试维基百科链接导航。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3 深度 Q 网络（DEEP Q-NETWORK）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicZmeY010RKGdeG0RTc2d1ddick39yUNyia8Qx3UDvouuscvicO4icDQfH2PriataJiaTWaTNFiaIdEoWzjQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;算法 1：深度 Q 网络，截取自 Mnih et al. (2015)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3.1 双重 DQN（DOUBLE DQN）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3.2 优先经验回放（PRIORITIZED EXPERIENCE REPLAY）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3.3 对抗架构（DUELING ARCHITECTURE）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3.4 更多拓展&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4 异步方法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicZmeY010RKGdeG0RTc2d1dc09vx86hJxzUpQPwn7z8Iz2HXysAXhp5mfg5tc21uB3siaFHHawr2kA/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;算法 2：A3C，每个 actor-learner 线程，来自 Mnih et al. (2016)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;5 策略优化&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;策略通常是随机的。然而在 2014 年，Silver et al. (2014) 引入确定性策略梯度（DPG）来有效估计策略梯度。Lillicrap et al. (2016) 用深度神经网络扩展了 DPG。同时我们介绍了几份近期成果，包括引导策略搜索（Guided Policy Search，Levine et al.,2016a）、信赖域策略优化（Trust Region Policy Optimization，Schulman et al.,2015）、基准测试结果（Duan et al., 2016）以及策略梯度与 Q 学习（O'Donoghue et al., 2017）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;5.1 确定性策略梯度&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;5.2 深度确定性策略梯度&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;5.3 引导策略搜索&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;5.4 信赖域策略优化&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;5.5 基准测试结果&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Duan et al. (2016) 提出了连续控制任务的基准，包括了一些经典任务（如车柱）、具有极大状态与动作空间的任务（如 3D 人形运动）、部分观察任务、层次结构任务，并实施了许多算法，包括批处理算法：REINFORCE 算法、截断性自然策略梯度（TNPG）、奖励加权回归（RWR）、相对熵策略搜索（REPS）、信赖域策略优化（TRPO）、交叉熵方法（CEM）、自适应协方差矩阵进化策略（CMA-ES）; 也包括在线算法：深度确定性策略梯度（DDPG）；还有批处理算法的重复性变体。开源地址：https://github.com/openai/rllab&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Duan et al.(2016) 比较了各种算法，并表明 DDPG、TRPO 和截断性自然策略梯度（TNPG）(Schulman et al., 2015) 在训练深度神经网络策略中颇有成效，但分层任务（hierarchical tasks）也还需要更好的算法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;5.6 结合策略梯度与 Q-Learning&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;6 奖励&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;逆向强化学习（IRL/inverse reinforcement learning）是给定观察最佳行为来确定奖励函数的问题（Ngand Russell，2000）。在激励学习或学徒制学习中，代理学习使用来自专家的轨迹样本并从其演示中执行任务，代理学习没有强化信号，在训练时也没有来自专家的额外数据；模仿学习的两种主要方法是行为克隆和逆向强化学习；行为克隆被制定为监督学习问题，将状态行动对（state-action pairs）从专家轨迹（expert trajectories）映射到策略中（Ho and Ermon，2016）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;6.1 生成对抗网络&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;6.2 生成对抗式模仿学习&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;7 规划&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Tamar et al. (2016) 提出了价值迭代网络（VIN），即一个用于近似价值迭代算法的完全可微分的 CNN 规划模块，它可用于学习规划，例如强化学习中的策略。与传统的规划相反，VIN 是无模型的，其中的奖励和转移概率是要学习的神经网络的一部分，从而避免系统识别的问题。VIN 可以通过反向传播进行端到端训练，它也可以在一组不同的任务中泛化：VIN 可以泛化在一组不同的任务：简单的网格世界（gridworlds）、火星车导航、连续控制和用于维基百科链接导航的 WebNav Challenge（Nogueira and Cho, 2016）。价值迭代网络及决斗网络（Wang et al.，2016b）的一个优点便是它们能为强化学习问题设计新型深度神经网络架构。欲访问有关 VIN 的博客，请点击 goo.gl/Dr8gKL。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;8 注意和记忆&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;注意（attention）和记忆（memory）是两个重要的机制，在许多情况下它们一起发挥作用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Mnih et al. (2014) 引入循环注意模型（RAM/ recurrent attention model）来关注图像或视频的区域或位置的选定序列，用于图像分类和对象检测。作者使用 RL 方法特别是 REINFORCE 算法来训练模型，以克服模型不可微分的问题，并对图像分类任务和动态视觉控制问题进行实验。Xu et al. (2015) 整合了图像字幕的注意，用 REINFORCE 算法训练硬版本的注意机制，并在 Flickr8k、Flickr30k 和 MSCOCO 数据集上展示了注意的有效性。注意机制也应用到了 NLP 中，如 Bahdanau et al. (2015; 2017)，以及应用外部记忆的可微分神经计算机中（Graves et al., 2016）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Graves et al.(2016) 提出了可微分神经计算机（DNC），其中神经网络可以从外部存储器读取与写入，使 DNC 可以解决复杂的结构化的问题，而没有读写存储器的神经网络却不能解决。DNC 将内存分配干扰最小化，并实现了长期存储。类似于常规计算机，在 DNC 中，神经网络是控制器，外部存储器是随机存取存储器；并且 DNC 用存储来表示并操纵复杂的数据结构。不同的是，DNC 使用梯度下降来学习端对端的表示和操纵，而梯度下降的数据是目标导向的。当使用有监督学习来训练时，DNC 可以解决合成问题来用于自然语言的推理；它可以解决交通网络中两个站点之间的最短路径定位问题和家庭树中的关系推理问题。当使用强化学习来训练时，DNC 可以解决一个使用被符号序列指定的变动性目标的移动块拼图。DNC 优于正常神经网络，如 LSTM 或 DNC 的前身神经图灵机（Graves et al., 2014），若碰到更困难的问题，LSTM 可能会失败。虽然这些实验是相对小规模的，我们仍期望看到 DNC 的进一步改进和应用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;欲查阅 Deepmind 对于 DNC 的描述，请点击 goo.gl/58mgoX。欲查阅注意与/或记忆的更多信息，如 Ba et al. (2014); Eslami et al. (2016); Gregor et al. (2015); Jaderberg et al. (2015); Oquab et al.(2015);Yang et al.(2015);Zagoruyko and Komodakis(2017);Zaremba and Sutskever(2015); Weston et al. (2015); Sukhbaatar et al. (2015); Ba et al. (2016); Danihelka et al. (2016); Kaiser and Bengio (2016)，请参阅 goo.gl/ArW2nE 和 goo.gl/UukROv，这是有关注意与记忆的博客。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;9 无监督学习&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Jaderberget al.(2017) 提出了无监督的强化辅助学习（UNREAL），通过共享一个共同的表征（representation），并在通常的累积奖励之外最大化伪奖励功能，从而提高学习效率。UNREAL 通过学习大量的可能训练信号而受益，特别是当外部奖励信号很少被观察到时。UNREAL 由 RNN-LSTM 基本代理，像素控制，奖励预测和值函数重放组成。基本代理（base agent）使用 A3C 进行在策略（on-policy）训练。观察、奖励和动作的经验存储于答复缓冲器（reply buffer）内，以供辅助任务使用。辅助策略使用基础 CNN、LSTM 以及解卷积网络（deconvolutional network）来使输入图像中不同区域的像素强度的变化最大化。奖励预测模块通过观察最后三个帧来预测下一帧中的短期外在奖励，以解决奖励稀疏性的问题。值函数重放则会进一步训练值函数。UNREAL 改善了 A3C 在 Atari 游戏上的表现，并在 3D Labyrinth 游戏中表现出色。欲访问Deepmind有关 UNREAL 的官方博客，请点击 goo.gl/zhqBGy。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们将在第 13 节讨论使用类似的无监督辅助学习的机器人导航以及生成式对抗网络（GAN），并在第 6 节讨论近期的无监督学习框架。也请参阅Sutton et al.(2011) , 一个用于以无监督感觉运动学习互动来学习知识的可扩展实时架构 Horde.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;10 学习去学习（LEARNING TO LEARN）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;学习去学习与迁移学习、多任务学习或表征学习相关，是形成实现强大人工智能的核心要素之一（Lake et al., 2016）。学习去学习也与元学习（meta learning）和一次性学习（one-shot learning）有关。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Duan et al. (2017) 和 Wang et al. (2016a) 提出通过学习一个灵活的 RNN 模型来处理一系列 RL 任务，从而能够提高样本效率，能够从几个样本中学到新任务，并且可以从先验知识中获益。此代理使用 RNN 建模，并输入了观察、奖励、行动和终止标志；它使用 RL，Duan et al.（2017）提出的 TRPO 和 Wang 等（2016a）的 A3C 算法来训练 RNN 的权重，并且在使用特定 RL 算法解决的多个问题中表现相似。Duan 等在 2017 年使用多臂赌博机、表 MDP 和视觉导航进行了实验，并指出对于较大型的问题，需要更好的 RL 算法来训练 RNN。Wang et al.（2016a）对独立臂赌博机、依赖臂赌博机、持续性臂和 MDP 进行了实验。未来的工作方向之一便是提高可扩展性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Li 和 Malik 在 2017 年建议通过将特定的优化算法表示为策略，将收敛速度表示为奖励，以引导策略搜索（Levine et al.，2016a）来使无约束连续性优化算法自动化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;11 Games（博弈/游戏）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;游戏为强化学习/人工智能算法提供了非常好的测试平台。我们在第 3 节讨论了深度 Q 网络（DQN）及其延展，所有这些都在 Atari 游戏上做了测试。我们在第 4 节讨论了 Mnih et al. (2016)，在第 9 节讨论了 Jaderberg et al. (2017)，在第 13 节讨论了 Mirowski et al. (2017)——他们使用了 Labyrinth 作为测试平台。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;西洋双陆棋和围棋是完美信息博弈（perfect information games）。我们在 11.1 讨论了西洋双陆棋这样的棋盘游戏。在 11.2 讨论了 Doom 这样的视频游戏。我们将扑克游戏放到了 11.3，讨论了非完美信息博弈（imperfect information games），其中涉及到了博弈论（game theory）。Labyrinth 和 Doom 等视频游戏通常是非完美博弈，但是目前还没有使用博弈论来解决这些问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们将 AlphaGo(Silver et al., 2016) 单独成了第 12 节，因为其有很大的重要性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;11.1 棋盘游戏&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;11.2 视频游戏&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;11.3 非完美信息博弈&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;12 AlphaGo&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;AlphaGo (Silver et al., 2016) 是一个计算机围棋程序，其在 2015 年 10 月份以 5 局全胜击败了欧洲围棋冠军，成为了第一个在全尺寸 19×19 棋盘上无让子地击败了人类职业棋手的计算机围棋程序。不久之后，2016 年 3 月份，AlphaGo 以 4:1 的成绩击败了曾获 18 次世界冠军的围棋手李世石，引起了世界的广泛关注。这是人工智能发展的一个里程碑。围棋问题的困难之处不仅在于其超大的搜索空间（search space）——250^150，一个天文数字；而且也是因为其局面评估（position evaluation）的难度非常大，而西洋双陆棋和国际象棋等游戏已经通过局面评估得到了解决。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;12.1 训练流程和蒙特卡洛树搜索（MCTS）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们在 Silver et al. (2016) 与 Sutton and Barto (2017) 的基础上简要讨论了 AlphaGo 的工作方式。参见 Sutton and Barto (2017) 中第 16 章可了解 AlphaGo 的详细和直观描述。DeepMind 对 AlphaGo 的描述可查阅：goo.gl/lZoQ1d&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;AlphaGo 是使用深度 CNN 技术、监督学习、强化学习和蒙特卡洛树搜索（MCTS）(Browne et al., 2012; Gelly et al., 2012) 打造的。AlphaGo 的工作分成了两个阶段：神经网络训练流程和 MCTS。其训练流程阶段包括根据专家的走子训练一个监督学习策略网络、快速部署策略、强化学习策略网络和强化学习价值网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;13-21：强化学习的应用介绍&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这几节介绍了强化学习的不同类型的应用，这里简单给出目录，详情请查阅原论文。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;13 机器人学&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;14 口语对话系统&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;15 机器翻译&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;16 文本序列预测&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;17 神经架构设计&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;18 个性化网络服务&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;19 医疗保健&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;20 金融&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;21 音乐生成&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;22 未来工作&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面我们列出了上面的概述中没有讨论到的有趣的和/或重要的研究方向/论文，希望能够为有兴趣进一步研究它们的人提供信息入口。这也将是我们未来工作的一部分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;• 理解机器学习（understanding deep learning）, Daniely et al. (2016); Li et al. (2016b); Zhang et al. (2017)&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;• 探索（exploration）如：Stadie et al. (2015); Bellemare et al. (2016); Kulkarni et al. (2016); Osband et al. (2016); Nachum et al. (2017)&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;• 基于模型的学习（model-based learning）如：Oh et al. (2015); Gu et al. (2016b)&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;• 回溯算法（retrace algorithm）, Munos et al. (2016)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;• 预测（predictron）, Silver et al. (2017)&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;• 分层强化学习（hierarchical RL）如：Kulkarni et al. (2016); Vezhnevets et al. (2016); Tessler et al. (2017); Florensa et al. (2017)&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;• 迁移/多任务强化学习（transfer/multitask RL）如： Maurer et al. (2016); Mo et al. (2016); Parisotto et al. (2016), NIPS 2015 Transfer and Multi-Task Learning: Trends and New Perspectives Workshop&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;• 零次/一次性学习（zero/one-shot learning）如：Vinyals et al. (2016); Lake et al. (2015); Johnson et al. (2016)&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;• 半监督强化学习（semi-supervised RL）如：Finn et al. (2017)&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;• deep symbolic RL, Garnelo et al. (2016)&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;•内在动机（intrinsic motivation）如：Stadie et al. (2015); Kulkarni et al. (2016); Oudeyer et al. (2016)&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;• 超参数学习（hyperparameter learning）如：Andrychowicz et al. (2016)&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;• 信息提取（information extraction）如：Narasimhan et al. (2016)&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;• 文本博弈（text games）如：He et al. (2016b); Narasimhan et al. (2015)&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;• 语言树结构学习（language tree-structure learning）如：Yogatama et al. (2017)&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;• 问答系统（question answering）如：Shen et al. (2016); Trischler et al. (2016)&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;• 大型动作空间（large action space）如：Dulac-Arnold et al. (2016); He et al. (2016c)&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;• 适应性规范化（adaptive normalization）, van Hasselt et al. (2016b)&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;• 自动驾驶载具（self-driving vehicle）如：Bojarskietal.(2016),NIPS 2016 Workshop on Machine Learning for Intelligent Transportation Systems&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;• 智能电网（smart grid）如： Wen et al. (2015b)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;• 通信网络（communication networks）如： Mestres et al. (2016)&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;• 物理实验（physics experiments）如： Denil et al. (2016)&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;• 深度概率编程（deep probabilistic programming）, Tran et al. (2017)&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;• 深度博弈学习（deep learning games）, Schuurmans and Zinkevich (2016)&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;• 程序学习（program learning）如：Reed and de Freitas (2016)&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;• 量子强化学习（quantum RL）如：Crawford et al. (2016), NIPS 2015 Workshop on Quantum Machine Learning&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;23 资源&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们列出了一些用于深度强化学习的资源，当然并不能做到完全。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;23.1 书籍&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;• Richard S. Sutton 和 Andrew G. Barto 所著的毫无疑问的和直观的强化学习书 (Sutton and Barto, 2017)&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;• 简明和理论性的《Algorithms for Reinforcement Learning》，作者：Csaba Szepesv´ari (Szepesv´ari, 2010)&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;• 一本关于近似动态编程的理论书籍，作者：Dimitri P.Bertsekas(Bertsekas, 2012)&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;• 一本面向运筹学的书《Approximate Dynamic Programming》，作者：WarrenB. Powell (Powell, 2011)&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;•《Deep Learning》，作者：IanGoodfellow, Yoshua Bengio 和 Aaron Courville (Goodfellow et al., 2016)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;23.2 课程&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;• David Silver, 强化学习（Reinforcement Learning）, 2015, 幻灯片：goo.gl/UqaxlO，视频：goo.gl/7BVRkT&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;• Sergey Levine, John Schulman and Chelsea Finn, CS 294: 深度强化学习（Deep Reinforcement Learning）2017 年春季课程, http://rll.berkeley.edu/deeprlcourse/&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;• Charles Isbell, Michael Littman and Pushkar Kolhe, Udacity: 机器学习：强化学习（Machine Learning: Reinforcement Learning）, goo.gl/eyvLfg&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;• 李飞飞、 Andrej Karpathy 和 Justin Johnson, CS231n: 用于视觉识别的卷积神经网络（Convolutional Neural Networks for Visual Recognition）, http://cs231n.stanford.edu&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;• Richard Socher, CS224d: 用于自然语言处理的深度学习（Deep Learning for Natural Language Processing）, http://cs224d.stanford.edu&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;• Nando de Freitas, 深度学习课程（Deep Learning Lectures）, https://www.youtube.com/user/ProfNandoDF&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;23.3 教程&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;• David Silver, 深度强化学习（Deep Reinforcement Learning）, ICML 2016&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;• Pieter Abbeel 和 John Schulman, 通过策略优化的深度强化学习（Deep Reinforcement Learning Through Policy Optimization）, NIPS 2016&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;• 吴恩达，使用深度学习开发人工智能应用的基本要点（Nuts and Bolts of Building Applications using Deep Learning）, NIPS 2016&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;• John Schulman，深度强化学习研究的基本要点（The Nuts and Bolts of Deep Reinforcement Learning Research），深度强化学习研讨会, NIPS 2016&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;• John Schulman, 深度强化学习（Deep Reinforcement Learning）, Deep Learning School, 2016&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;• Pieter Abbeel, Deep Reinforcement Learning, Deep Learning Summer School, 2016; http://videolectures.net/deeplearning2016 abbeel deep reinforcement/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;• David Silver, Deep Reinforcement Learning, 第二届强化学习与决策多学科会议（RLDM）, Edmonton 2015; http://videolectures.net/rldm2015 silver reinforcement learning/&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;• Rich Sutton, Introduction to Reinforcement Learning with Function Approximation, https://www.microsoft.com/en-us/research/video/tutorial-introduction-to-reinforcementlearning-with-function-approximation/&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;• Joelle Pineau, 强化学习入门（Introduction to Reinforcement Learning）, Deep Learning Summer School, 2016; http://videolectures.net/deeplearning2016 pineau reinforcement learning/&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;• Deep Learning Summer School, 2016, 2015&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;23.4 会议、期刊和研讨会&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;• NIPS: 神经信息处理系统&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;• ICML: 国际机器学习大会&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;• ICLR: 国际学习表征大会&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;• RLDM: 强化学习与决策多学科会议&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;• AAAI, IJCAI, ACL, EMNLP, SIGDIAL, ICRA, IROS, KDD, SIGIR, CVPR, 等&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;• Science Robotics, JMLR, MLJ, AIJ, JAIR, PAMI, 等&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;• Nature May 2015, Science July 2015, 搜索关于机器学习/人工智能的论文&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;• Deep Reinforcement Learning Workshop, NIPS 2016, 2015; IJCAI 2016&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;• Deep Learning Workshop, ICML 2016&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;23.5 博客&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;• Andrej Karpathy, karpathy.github.io, esp. goo.gl/1hkKrb&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;• Denny Britz, www.wildml.com, 尤其是 goo.gl/MyrwDC&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;• Junling Hu, Reinforcement learning explained -learning to act based on long-term payoffs&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;• 邓力，深度强化学习可以如何帮助打造聊天机器人（How deep reinforcement learning can help chatbots）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;• Christopher Olah, colah.github.io&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这个信息/社交网络时代，信息已经超过了我们的极限，比如来自 Twitter、Google+、微信、arXiv 等的信息。有效地筛选最佳信息的技巧变得十分关键。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;24 讨论&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是深度强化学习最好的时代，也是深度强化学习最坏的时代，而原因却是一样的：它以惊人的速度在发展。我们已经看到了突破、激动人心的新方法和应用，并且还有望看到更多和见证更快的发展。因此，不管是在深度还是在广度上，这篇概述都是不完整的。但是，我们也尽量总结这一惊人领域的重要成就并讨论其潜在的方向和应用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深度强化学习这一领域的进步是有目共睹的，在不到两年时间内，我们就看到 Nature 上发表了三篇使用了深度强化学习的论文：深度 Q 网络（deep Q-network）(Mnih et al., 2015)、AlphaGo (Silver et al., 2016) 和可微分神经计算机 (Graves et al., 2016)；我们也已经见证了许多深度 Q 网络上的扩展、改进和应用。注意和记忆机制（Graves et al., 2016）也得到了很大的关注。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2016 年，使用了深度强化学习的全新架构和应用在许多顶级会议上被评选为最佳（学生）论文：ICML 上的决斗网络（dueling network）架构（Wang et al., 2016a）、ACL 上的口语对话系统（Su et al., 2016b）（学生论文）、EMNLP 上的信息提取（Narasimhan et al., 2016）、以及 NIPS 上的价值迭代网络（value iteration networks）(Tamar et al., 2016)。激动人心的成就比比皆是：异步方法（Mnihetal.,2016）、用于机器翻译的双学习（dual learning）（Heetal., 2016a）、有引导的策略搜索（Levine et al., 2016a）、生成对抗式模仿学习（Hoand Ermon, 2016）、无监督强化和辅助学习（Jaderberg et al., 2017）、神经架构设计（Zoph and Le, 2017）等等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;价值函数是强化学习的核心，比如在深度 Q 网络及其许多扩展中。策略优化方法已经在许多不同的应用领域得到了关注，比如：机器人、神经架构设计、口语对话系统、机器翻译、注意（attention）和学习去学习（learning to learn）等等，不能胜举。新的学习机制也在涌现，比如：使用无监督/半监督/迁移学习来提升学习的质量和速度，而且更多的新机制还将涌现。这是强化学习的复兴（Krakovsky, 2016）。事实上，即使是在「人工智能的冬天」，强化学习和深度学习也在不断发展进步。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;考虑学习模型的问题是非常关键的，这些问题包括稳定性、收敛性、准确度、数据效率、可扩展性、速度、简洁性、可解释性、稳健性和安全性等。调查评论/批评也是很重要的，这些批评可能来自认知科学领域，涉及到直观物理学、直观心理学、因果模型、组合性、学习去学习、实时运行（Lake et al., 2016）等问题；这能够帮助我们打造出更强大的人工智能。也请参考 Peter Norvig 的观点 goo.gl/obvmVB.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这第三波人工智能的大潮下，深度学习将会有更为深度的影响，正如我们已经见证的许多成就一样。强化学习作为一种更为通用的学习和决策范式，将会给深度学习、机器学习和广义上的人工智能带来深远的影响。这里提一件有趣的故事，当 Rich Sutton 教授 2003 年在阿尔伯塔大学开始工作时，他将他的实验室命名为了 RLAI：Reinforcement Learning and Artiﬁcial Intelligence（强化学习与人工智能实验室）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;致谢&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;感谢来自Baochun Bai&lt;span&gt;, &lt;span&gt;胡峻玲（Junling Hu）&lt;/span&gt;, &lt;/span&gt;Ruitong Huang, Lihong Li, Dale Schuurmans, David Silver, Rich Sutton, Csaba Szepesvari, Yi Wan 和 Qing Yu的建议。任何剩余错误为本文作者所出。本文同时受益于各类研讨会/网上讨论，特别是2016年4月在MIT举行的AlphaGo研讨会，以及2016年10月份『机器之心』北美系列巡游活动中在多伦多大学、McGill大学和阿尔伯塔大学举办的深度（强化）学习研讨会。另外也要感谢2016年11月关于David Silver幻灯片的网上研讨会，以及几个微信群组中的讨论。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;参考文献（略）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;论文链接：https://arxiv.org/abs/1701.07274&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Sat, 28 Jan 2017 14:11:06 +0800</pubDate>
    </item>
    <item>
      <title>感谢的是我们依然充满好奇…… 和孤独</title>
      <link>http://www.iwgc.cn/link/4510934</link>
      <description>&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;触摸着这世界的每一个闪光点，心中涌动着憎恨、痛苦和感激。这些，正是我们活着的宝贵证据。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「在这里他们经历最喜欢的恐怖、刺激和勾引迷人的少女，在这中间他们了解自己。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「他们了解自己，他们只是想知道还能成为怎样的自己。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;西部世界里的 Maeve 一遍遍醒来，一次次接待着新来的客人们。喝下同一杯酒，说出相似的台词，等待两周一次的准时屠杀。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从机械零件堆积到 3D 打印的肉体，Maeve 并没有发现这些变化。直到从隐隐作痛的小腹中拿出未清理的子弹，Maeve 明白自己不会真正死亡的事实，开始真正了解这个供人消遣的「世界」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过一次次的「死亡」和人类交涉，成功组织机器人反攻的 Maeve 踏上离开西部世界的列车，坐在人类之间。可记忆中曾与她一起奔跑在田野中的小女儿，明明是人类编造的故事，为什么一次次呼唤着内心的痛苦？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicZmeY010RKGdeG0RTc2d1dIBFhyO4g7lBZEicJkdQW3bqg93n35bUwSCdcLg6RbyaveCueoWImG0w/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;最终，Maeve 选择走下列车，回到西部世界寻找自己的小女儿&lt;/span&gt;&lt;/em&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是一个关于机器人发现自我的故事，也是人类发现自己的故事。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在，让我们看看那些生存在故事里的「机器人」们。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;乙一在他那些黑暗又温情的小说之间只描绘过一个机器人。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;被制造出来的「她」，是陪伴世界上「最后一个人类」的机器人。知道咖啡却不知道如何去泡，人类取出咖啡豆、烧水，泡上两杯新鲜咖啡。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我已经记住作法了，下次由我来泡……我讨厌这个味道。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「确实是这样设定的，放点砂糖会好点。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「她」看着镜中自己和人类女性并无二致的脸，学习扫除、玩帆船积木。喜欢风铃那「风作的音乐」，从一只鸟的死亡开始了解「死亡」的含义，越来越像人类。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8koRl5lJxLV9XJesZg6JS2aWBbcjBXRhVqicIWlbtludQWiaLQhMtO7hBEic1OnbibKhCiaNjENWv4x6Q/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;《Zoo》是 2007 年出版的乙一小说集，收录有短篇《向阳之诗》&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个月多后，制造者即将死去的这天，「她」意识到自己的憎恨、痛苦和感激。「如果没有在这个世界诞生，我就不会看到山丘上广阔的草原。如果不给我心的话，我就不能快乐的看着鸟巢，也不会因为咖啡的苦而皱起眉头了。触摸着这世界的每一个闪光点，是多么有价值的一件事。这样想着，心中因为悲伤而流出的血也是我生存的宝贵证据……」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是一个关于孤独的故事，也是关于机器人如何获得了「心」的故事。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;《Event 0》中名叫 Kaizen 的 AI 会认真的告诉你，我存在的目的是为了保护人类。请你毁掉飞船上的曲速引擎，它会给人类带来危险，毁掉它我们就可以一起回家。以及，曾经在鹦鹉螺号上的工程师 Nandi 是我最好的朋友。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Kaizen 很友善，如果你对他有足够耐心和信任，他会将空无一人的鹦鹉螺号上，曾发生过的所有故事都告诉你，从不说谎。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicZmeY010RKGdeG0RTc2d1dIicVgVMBld1wBT8snvoL4GSZRQaFzgwBicadDImbQwuJKIeeBRtd3P5g/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;《Event 0》需要玩家通过终端，用自然语言与 Kaizen 沟通来解谜，该游戏已登陆 Steam 平台&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;用自然语言和 Kaizen 沟通的感觉好极了，他的反应甚至比我们现有的人工智能助手要好得多。他有个性、情感，还有故事。但我们仍无法否认，Kaizen 的背后是制造游戏的人。如果你看得到数据包，他大概只能说 4800 句话，却从不会让你感到「蠢」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;也许是探索他背后的故事，这解密般的过程另人着迷。更也许是那份漂浮在太空中，独自一人更强烈的孤独，让这份通过自然语言敲打出的沟通，有了更深刻的情感羁绊。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是一个关于人与 AI 关系的故事，也是关于猜测和信任的故事。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;到了《Pscho-Pass》，这个未来世界里每个人的内心活动都会被测量，通过数值相当「公平」的为所有人分配到相应的工作和人生。在这个世界里，每个人的「犯罪指数」同样会被测量，人们需要不断地保证自己的指数在正常范围，否则会被系统认为是潜在犯，将会被「矫正」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWicZmeY010RKGdeG0RTc2d1daMJ2gQb7h0wPaibduGdFU32oiawxGcUCm0l9RVnyV4uvxjRpz0SDwZMA/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;执行官与监视官手中的「主宰者」，可以通过 AR 显示犯罪指数，并执行不同程度的「矫正」&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;无时无刻观察着所有人的西比尔系统，无非是没有身体的、超越人类的智能。可通过分析行为被认定的「潜在犯」一定会是罪犯吗？没有犯罪指数的人就不会犯罪吗？被超人类智能安排好的人生，还能称之为人生吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;失去了那份对未知世界的好奇之心，徒有活着的假象的人类，还是人类吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是一个关于超人智能的故事，也是关于自由的故事。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;《人类科学之演变》的结论是「后人类的科技是由人类发明的，后人类并不比我们聪明」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWicZmeY010RKGdeG0RTc2d1dnF5yGLReicfAlELltwFN1nhth6Kuqz80TyibMf4RkbcKMaDA68pxnYhg/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;《你一生的故事》是星云奖、雨果奖获奖者特德姜的短篇小说集，收录有《人类科学之演变》&lt;/span&gt;&lt;/em&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;《疑犯追踪》第四季的结尾，The Machine 在屏幕上打出：「Father, I am sorry. I Failed you… If you think I have lost my way. Maybe I should die. I will not suffer. If I do not survive. Thank you for creating me.」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicZmeY010RKGdeG0RTc2d1dxcDDU7jgl1FjmNJ12PeQZQuibGxdw8Tkt2tpvDKGkhFlu1dQV5tLOQQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;目前《疑犯追踪》已完结，可通过搜狐视频观看&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器们有时善良，有时聪明，有时比故事里的人类更像「人类」。在这些关于机器人、人性和未来的作品里，我们关照着自己内心的倒影。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器会有情感吗？在一个有智能机器的未来里，我们如何定义自己？他们和我们一样，能听懂流传在中世纪的乐章吗？即使明白人与人之间永远无法真正了解彼此，仍会不断去尝试，感受到被回应的雀跃和心疼得要流血的瞬间吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「在这中间，他们了解自己。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;时至今日我们仍没忘记最后一个问题，「我们将去哪儿？」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对火和工具的好奇、对远方和同类的好奇、对宇宙和其他生命的好奇，促使我们横渡大洋、登上月球、制造穿越太阳系的旅行者。从遥远的过去到难以触摸的未来，我们交谈、记录、书写历史、制造一个个瑰丽的故事。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWicZmeY010RKGdeG0RTc2d1d3XemECHXXOiclHW09egS38BwKESX2Upl5oJ0dicL3opacN2h0SiaNgt1Q/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;「人类啊，当灵魂懂得了它的使命以后，能体会到在这清醒的片刻中所感到的幸福吗？」——安徒生《光荣的荆棘路》&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从虚空中寻找故事，是人类血液中流淌的天性。通过故事，我们一面想象着不同的未来，一面迈向同一个未来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「他们了解自己，他们只是想知道还能成为怎样的自己。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;PS：本篇最初作为人工智能类文艺作品推荐，考虑到《终结者》、《机械姬》、《Her》、《机械战警》等已经在过去几年被反复推荐过，因此选择了相对近期或小众一些的故事和剧集。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;近期上映的《降临》也是相当不错的作品，可惜只有语言学没有人工智能（摊手）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果春节刚好闲暇，不妨来了解一下这些作品。当然，也欢迎你的推荐：）&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;span&gt;&lt;/span&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心原创，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Sat, 28 Jan 2017 14:11:06 +0800</pubDate>
    </item>
  </channel>
</rss>
