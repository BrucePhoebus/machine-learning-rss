<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>从TensorFlow到Theano：横向对比七大深度学习框架</title>
      <link>http://www.iwgc.cn/link/4740970</link>
      <description>&lt;div class="article-content"&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;section style="max-width: 100%; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; line-height: 28.4444px; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%; border: 0px currentcolor; font-family: 微软雅黑; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; max-width: 100%; border-style: solid none; font-family: inherit; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-top: -1.2em; max-width: 100%; min-height: 1em; font-size: 1em; border: currentcolor; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(255, 255, 255); line-height: 22.4px; font-size: 1em; font-family: inherit; text-decoration: inherit; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(117, 117, 118);"&gt;选自SVDS&lt;/span&gt;&lt;/p&gt;&lt;section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px; max-width: 100%; font-family: inherit; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-bottom: 5px; max-width: 100%; min-height: 1em; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(127, 127, 127); font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;作者：Matthew Rubashkin&amp;nbsp;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; max-width: 100%; min-height: 1em; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; font-family: inherit; text-decoration: inherit; color: rgb(127, 127, 127); font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong style="max-width: 100%; font-family: inherit; text-decoration: inherit; color: rgb(127, 127, 127); font-size: 12px; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; max-width: 100%; min-height: 1em; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(127, 127, 127); font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;参与：李泽南&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;br&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;&lt;em&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;在深度学习项目开始前，选择一个合适的框架是非常重要的事情。最近，来自数据科学公司 Silicon Valley Data Science 的数据工程师 Matt Rubashkin（UC Berkeley 博士）为我们带来了深度学习 7 种流行框架的深度横向对比，希望本文能对你带来帮助。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px; line-height: 1.75em;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px; line-height: 1.75em;"&gt;在 SVDS，我们的研发团队一直在研究不同的深度学习技术；从识别图像到语音，我们也在各类框架下实现了不少应用。在这个过程中，我们意识到需要一个简明的方式来获取数据、创建模型、同时评估这些模型的表现。但当我们一次次开始新的深度学习项目时，我们却一直没有找到一个可以参考的标准来告诉自己如何开始。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;现在，为了回馈开源社区，同时帮助后来者，我们决定以我们的经验对目前流行的几种工具&lt;/span&gt;&lt;span style="font-size: 14px;"&gt;（Theano、TensorFlow、Torch、Caffe、MXNet、Neon 和 CNTK）&lt;/span&gt;&lt;span style="font-size: 14px;"&gt;进行一次横向对比。以下图表展示了各类深度学习工具的优劣，希望对大家能有所帮助。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;先放结论&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487305834f8xtUT.jpg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;这组对比参考了多种公开基准评测，以及我们在图像/语音识别应用时对这些技术的 主观印象。此外，你需要注意：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;语言&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;当你开始一个深度学习项目时，你最好使用一个支持你所会语言的框架。比如 Caffe（C++）和 Torch（Lua）只能支持有限的语言（最近，随着 &lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722553&amp;amp;idx=1&amp;amp;sn=ce635e60fa8f1cc16982c5d6a9a6931b&amp;amp;chksm=871b1487b06c9d9180d7f881784e68d4b9785481c38aa86eccc183aed8254b2a452e073a0c9b&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722553&amp;amp;idx=1&amp;amp;sn=ce635e60fa8f1cc16982c5d6a9a6931b&amp;amp;chksm=871b1487b06c9d9180d7f881784e68d4b9785481c38aa86eccc183aed8254b2a452e073a0c9b&amp;amp;scene=21#wechat_redirect"&gt;PyTorch &lt;/a&gt;的出现，情况有所改观）。所以如果你希望选用上述两个框架，我们建议你事先熟悉 C++或 Lua 语言。相比之下，TensorFlow 与 MXNet 具有丰富的多语言支持，即使你对 C++感到陌生也可以使用它们。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487305834d6vqSQ.png"/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487305834nfEA10.png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;教程和资源&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;目前，各类深度学习框架的教程与可利用的资源在质量和数量上有着显著的不同。Theano，TensorFlow，Torch 和 MXNet 有着很详尽的文档教程，很容易被初学者理解和实现。与此相比，虽然微软的 CNTK 和英特尔的 Nervana Neon 也是强大的工具，我们却很少能见到有关它们的新手级资料。此外，在研究过程中，我们发现 GitHub 社区的参与度不仅可以用于准确地评价不同工具的开发水平，而且还是在搜索 StackOverflow 或 repo 的 Git Issues 时能否快速解决问题的参考性指标。当然，作为谷歌提供的框架，TensorFlow 理所当然地在教程，资源，开发者和社区贡献者的数量上遥遥领先。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487305834HzYUlk.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;CNN 建模能力&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;卷积神经网络（CNN）经常被用于图像识别、推荐引擎和自然语言识别等方向的应用。CNN 由一组多层的神经网络组成，在运行时会将输入的数据进行预定义分类的评分。CNN 也可用于回归分析，例如构成自动驾驶汽车中有关转向角的模型。在横评中，我们评价一种框架的 CNN 建模能力考虑到以下几个特性：定义模型的机会空间、预构建层的可用性、以及可用于连接这些层的工具和功能。我们发现，Theano，Caffe 和 MXNet 都有很好的 CNN 建模能力。其中，TensorFlow 因为易于建立的 Inception V3 模型，Torch 因为其丰富的 CNN 资源——包括易于使用的时间卷积集使得这两种框架在 CNN 建模能力上脱颖而出。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;RNN 建模能力&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;递归神经网络（RNN）常用于语音识别，时间序列预测，图像字幕和其他需要处理顺序信息的任务。由于预建的 RNN 模型不如 CNN 数量多，因此，如果你已经有一个 RNN 深度学习项目，优先考虑旧 RNN 模型是在哪种框架里实现的最重要。目前，Caffe 上的 RNN 资源最少，而 Microsoft 的 CNTK 和 Torch 有丰富的 RNN 教程和预构建模型。当然，最流行的 TensorFlow 中也有一些 RNN 资源，TFLearn 和 Keras 中更有很多使用 TensorFlow 的 RNN 示例。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;架构&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;为在特定框架中构建和训练新模型，易于使用和模块化的前端是至关重要的。TensorFlow，Torch 和 MXNet 都有直观而模块化的架构，让开发相对变得简单。相比之下，我们在 Caffe 这样的框架上需要进行大量的工作才能创建一个新层。另外我们发现在开发过程中，因为有 TensorBoard web GUI 等应用的存在，TensorFlow 极易在训练中和训练后进行 debug 和监控。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;速度&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Torch 和 Nervana 具有开源卷积神经网络基准测试的最佳性能：&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: left; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;https://github.com/soumith/convnet-benchmarks/blob/master/README.md&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Tensorflow 的性能在大多数测试中是具有竞争力的，而 Caffe 和 Theano 稍稍落后：&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: left; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;https://github.com/tobigithub/tensorflow-deep-learning/wiki/tf-benchmarks&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;微软声称他们的 CNTK 在一些 RNN 训练任务中有最快的速度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;在另一项对比 Theano、Torch 和 TensorFlow 的 RNN 性能的研究中，Theano 是其中最快的：&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: left; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;https://arxiv.org/abs/1511.06435&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;多 GPU 支持&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;大多数深度学习应用都需要用到巨量的浮点运算（FLOP）。例如，百度的 DeepSpeech 识别模型需要 10s ExaFLOPs 用于训练，这是大于 10e18 的计算量：&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: left; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;https://arxiv.org/abs/1512.02595&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;考虑到目前英伟达 Pascal 架构的 TitanX 等顶级显卡可以每秒执行 11e9 FLOP：&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: left; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;https://www.nvidia.com/en-us/geforce/products/10series/titan-x-pascal/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;因此，假如需要在大型数据集上训练一个新模型——用单 GPU 机器的话——可能会需要一个星期之久。为了减少构建模型所需的时间，我们需要使用多 GPU 并联的方式组建自己的机器。幸运的是，上述大部分架构都可以很好地支持多 GPU 运算。其中，据报道 MXNet 有着最好的多 GPU 优化引擎：&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: left; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;http://www.allthingsdistributed.com/2016/11/mxnet-default-framework-deep-learning-aws.html&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;Keras 兼容性&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Keras 是一个用于快速构建深度学习原型的高级库。我们在实践中发现，它是数据科学家应用深度学习的好帮手。Keras 目前支持两种后端框架：TensorFlow 与 Theano，而且 Keras 再过不久就会成为 TensorFlow 的默认 API：&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: left; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;http://www.fast.ai/2017/01/03/keras/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;尽管如此，Keras 的作者表示，这一高级库在未来仍会作为支持多种框架的前端存在：&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: left; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;https://github.com/fchollet/keras/issues/5050#issuecomment-272945570&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;总结&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;如果你想要开始深度学习，你应该从评估自己的团队技能和业务需求开始。例如，如果一个以 Python 为中心的团队想开发图像识别的应用程序，你应该使用 TensorFlow，因为它有丰富的资源，较好性能和完整的原型工具。如果一个有 Lua 能力的团队希望将 RNN 大规模应用到生产环境中去，他们则会受益于 Torch 的高速和强大的 RNN 建模能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;未来，我们将继续讨论在更大规模的应用中这些框架的表现。这些挑战包括多机并联时的多 GPU 优化，多种开源库的兼容性，如 CMU Sphinx 和 Kaldi 等，尽请期待。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px; text-decoration: none;"&gt;&lt;em&gt;原文链接：&lt;/em&gt;&lt;/span&gt;&lt;a style="color: rgb(136, 136, 136); font-size: 12px; text-decoration: none;"&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;&lt;em&gt;http://www.svds.com/getting-started-deep-learning/&lt;/em&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="min-height: 1em; text-align: justify; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="line-height: 25.6px; font-family: 微软雅黑; font-size: 14px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; color: rgb(127, 127, 127); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="color: rgb(62, 62, 62); line-height: 25.6px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; color: rgb(127, 127, 127); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;©本文为机器之心编译，&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; font-size: 18px; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(127, 127, 127); line-height: 25.6px; font-family: 微软雅黑; text-align: justify; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(217, 33, 66); font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(217, 33, 66); line-height: 1.6; font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-size: 12px; color: rgb(217, 33, 66); line-height: 1.6; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/div&gt;</description>
      <pubDate>Fri, 17 Feb 2017 12:06:43 +0800</pubDate>
    </item>
    <item>
      <title>学界 | OpenAI探讨人工智能安全：用对抗样本攻击机器学习</title>
      <link>http://www.iwgc.cn/link/4740971</link>
      <description>&lt;div class="article-content"&gt;&lt;section style="max-width: 100%; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; line-height: 28.4444px; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%; border: 0px currentcolor; font-family: 微软雅黑; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; max-width: 100%; border-style: solid none; font-family: inherit; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-top: -1.2em; max-width: 100%; min-height: 1em; font-size: 1em; border: currentcolor; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(255, 255, 255); line-height: 22.4px; font-size: 1em; font-family: inherit; text-decoration: inherit; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(117, 117, 118);"&gt;选自&amp;nbsp;OpenAI Blog&lt;/span&gt;&lt;/p&gt;&lt;section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px; max-width: 100%; font-family: inherit; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-bottom: 5px; max-width: 100%; min-height: 1em; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(127, 127, 127); font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;作者：IAN GOODFELLOW, NICOLAS PAPERNOT 等&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; max-width: 100%; min-height: 1em; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; font-family: inherit; text-decoration: inherit; color: rgb(127, 127, 127); font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong style="max-width: 100%; font-family: inherit; text-decoration: inherit; color: rgb(127, 127, 127); font-size: 12px; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; max-width: 100%; min-height: 1em; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(127, 127, 127); font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;参与：微胖、李亚洲、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;对抗样本是扮演攻击角色、试图用来引发模型出错的机器学习模型的输入；如同机器产生的光影幻觉。在这篇博文中，我们将为读者展示对抗样本在各种不同介质中的运作原理，还会讨论为什么系统难以防御它们。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;在 OpenAI , 我们认为，对抗样本问题属于人工智能安全研究（我们正在从事）好的一面，因为它们代表着一个能在短期内加以解决的具体问题，由于解决它们比较难，因此需要进行严肃的科学研究。（尽管为了确保打造出一个安全、广为分布的人工智能系统，我们需要研究许多机器学习安全许多方面的问题。）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;为了搞清楚对抗样本的庐山真面，请考虑一下这篇研究《解释并驯服对抗样本（Explaining and Harnessing Adversarial Examples）》中的例证：开始是一张熊猫图片，接着，攻击方给图片添加了小的扰乱，足以让这只熊猫被认定为一只长臂猿。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487305836meDz1Z.jpg"/&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 12px;"&gt;叠加在典型图片输入上的对抗输入会让分类器产生错觉，误将熊猫识别为长臂猿。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;这一办法十分稳健；近期的一些研究也已经表明，在标准论文上打印出对抗样本，用一部标准像素智能手机拍下来后，这些样本仍然可以捉弄系统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/148730583680plML.jpg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;em&gt;&lt;span style="font-size: 12px; color: rgb(136, 136, 136);"&gt;对抗样本可以在论文上打印出来，用标准像素手机拍下后，仍然可以捉弄分类器，在这个例子中，分类器将「洗衣机」识别为「保险箱」。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;对抗样本具有潜在危险性。比如，攻击者可能会用贴纸或者一幅画做一个对抗式「停止（stop）」交通标志，将攻击对象瞄准自动驾驶汽车，这样，车辆就可能将这一「标志」解释为「放弃」或其他标识，进而引发危险。Practical Black-Box Attacks against Deep Learning Systems using Adversarial Examples 讨论过这个问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;一些新近的研究，比如，伯克利，OpenAI 以及宾大联合发表的论文 Adversarial Attacks on Neural Network Policies, 内华达大学 Vulnerability of Deep Reinforcement Learning to Policy Induction Attacks ，表明强化学习智能体也能被对抗样本操控。研究表明，广为采用的强化学习算法，比如，DQN , TRPO 以及 A3C ，都经不起对抗样本的捉弄。这些对抗样本输入会降低系统性能，即使扰乱微妙地让人类也难以察觉，智能体会在应该往上移动的时候却将球拍向下移动，或者在 Seaquest 中识别敌人的能力受到干扰。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;iframe class="video_iframe" data-vidtype="1" allowfullscreen="" frameborder="0" height="417" width="556" data-src="https://v.qq.com/iframe/preview.html?vid=q0375nj0fyk&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0"&gt;&lt;/iframe&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;如果各位看官想玩坏自己的模型，不放试一下 cleverhans 这个开源库，它是 Ian Goodfellow &amp;nbsp;和 Nicolas Papernot &amp;nbsp;一起研发的，旨在测试面对对抗样本，你的人工智能模型有多脆弱。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;在人工智能安全问题方面，对抗样本提供了一些牵引力&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;当你思考人工智能安全时，经常会考虑这个领域中最难的问题——我们如何能确保成熟的强化学习智能体（比人类要智能得多）能按照最初设计意图行事？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;对抗样本向我们展示了这样一个事实：即使是简单的现代算法，不管是监督学习还是强化学习，都能以出乎人类意料的方式行事。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;力图防卫对抗样本&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;让机器学习模型更加稳健的传统技术，比如权重衰减或者 dropout，通常无法切实防范对抗样本。到目前为止，仅有两个办法可以提供显著的防范措施。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;对抗训练：这是一种蛮力解决方案。我们简单地生成许多对抗样本，明确训练模型不要被这些样本给骗了。cleverhans 库提供了一个开源的对抗训练实现，这个教程里有指南（https://github.com/openai/cleverhans/blob/master/tutorials/mnist_tutorial_tf.md）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;Defensive distillation (https://arxiv.org/abs/1511.04508): 在这一策略中，我们训练模型生成关于输入属于不同类别的概率，而不是硬让系统决定输入到底属于哪一类。这一概率由更早一些的模型提供，该模型是针对同一任务，用比较难的类别标签训练过的。这会让我们得到一种模型——其表面在对手通常会加以利用的方向上是平滑的，这会使得对手很难发现导致错误分类的对抗输入调整。（Distilling the Knowledge in a Neural Network (https://arxiv.org/abs/1503.02531) 最初将这个办法视为一种模型压缩技术，为了节省计算资源，小模型被训练用来模拟大模型。）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;然而，只要个敌方再添加些计算火力，这些专门的算法也会被轻易攻下。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;失败的防御：「梯度掩模（gradient masking）」&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;为了给出一个关于简单防御可能如何失败的案例，让我们思考一下为什么一种叫做「梯度掩模（gradient masking）」的技术没有效果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;「梯度掩模」是一个由 2016 年的论文《使用对抗样本对深度学习系统进行实际的黑盒攻击（Practical Black-Box Attacks against Deep Learning Systems using Adversarial Examples）》引入的术语，其描述了一整类试图通过拒绝攻击者对有用梯度（useful gradient）的访问权限而进行防御的失败方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;大多数对抗样本构建技术都使用了模型的梯度来进行攻击。打个比方，它们查看了一张飞机图片，它们测试在图片空间中哪个方向会使「猫」类别的概率增加，然后它们在那个方向上给予一点推动（换句话说，它们干扰输入）。这样，新的修改过的图像就会被认为是一只猫。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;但如果其中并没有梯度呢——如果图片上一个无穷小的修改不会给模型的输出造成任何改变呢？这似乎就能够提供一定程度的防御，因为攻击者无法获悉向哪个方向「推动」图像。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;我们可以轻松地想象出一些非常简单的避免梯度的方式。比如，大部分图像分类模型都可归于两种模式：一是它们仅输出识别出的最有可能的类别，二是它们输出概率。如果一个模型的输出是「99.9% 的概率是飞机，0.1% 的概率是猫」，那么对输入的一点微小改变也会给输出带来一点微小的改变，而梯度就会告诉我们哪些改变会增加属于「猫」类的概率。如果我们运行的模型的模式是仅仅输出「飞机」而没有概率，那么一点微小的改变就不会对输出产生任何影响，梯度也不会让我们了解任何东西。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;下面让我们进行一个思想实验，看我们的模型在处于「最有可能类别」模式而非「概率模式」类别时，可以如何防御对抗样本。攻击者不再需要寻找将被分类为「猫」的输入，所以我们可能已经有了一些防御。不幸的是，之前被分类为「猫」的图像现在仍然还是被分类为「猫」。如果攻击者可以猜测哪些点是对抗样本，那么这些点仍然可被错误地分类。所以这种方法不能让该模型更稳健；只是让攻击者在寻找模型防御的漏洞时没有那么多的线索罢了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;更不幸的是，事实证明攻击者在猜测防御漏洞时具有非常好的策略。攻击者可以训练一个他们自己的模型——一个有梯度的平滑的模型，并为他们的模型制作对抗样本，然后只需要部署这些对抗样本和我们的非平滑模型进行对抗即可。很多时候，我们的模型也会错误分类这些样本。最后，我们的思想实验表明：隐藏梯度不会给我们带来任何好处。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;执行「梯度掩模」的防御策略通常会导致得到一个在特定方向上和训练点的附近非常平滑的模型，这会使得对手更难以找到指示了好的候选方向的梯度，从而更难以以破坏性的方式干扰该模型的输入。但是，对手可以训练一个「替代（substitute）」模型：一个模仿被保护的模型的副本——这可以通过观察被保护模型分配给对手仔细选择的输入的标签而实现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;这篇黑盒攻击论文介绍了一种用于执行这种模型提取攻击（model extraction attack）的方法。然后对手可以使用这种替代模型的梯度来寻找被被保护模型错误分类的对抗样本。在上图（该图来自论文《关于机器学习中的安全和隐私的科学（Towards the Science of Security and Privacy in Machine Learning）》中关于梯度掩模的讨论）中，我们给出了这种攻击策略在一个一维机器学习问题上的应用。该梯度掩模现象（gradient masking phenomenon）在更高维的问题上会加剧，但这是难以描述的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;我们发现对抗训练和 defensive distillation 都会偶尔执行一定类型的梯度掩模。这两种算法明显都不是为梯度掩模而设计的，但当机器学习算法要进行保护自己的训练而未被给出明确的方法指令时，梯度掩模显然是该机器学习算法能相对轻松地发明的一种防御。如果我们将对抗样本从一个模型迁移到另一个也经过对抗训练或 defensive distillation 训练过的模型，那么这个攻击通常会成功——即使当对第二个模型的直接进攻会失败时。这表明这两种模型做得更多的是展平模型和移除梯度，而不是确保其正确分类更多的点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;为什么防御（defend）对抗样本很难？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;对抗样本难以防御是因为很难构造对抗样本处理过程的理论模型。对抗样本是许多机器学习模型非线性、非凸性优化问题的解决方案，包括神经网络在内。因为我们没有好的理论工具来描述这些复杂的优化问题的解决方案，所以也很难作出理论性争辩说一种防御能够排除一系列的对抗样本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;对抗样本难以防御也因为它们需要机器学习模型为每个可能的输入生成好的输出。大部分时间，机器学习模型做的很好，但只有在小量的可能输入的情况下它们可能会碰头。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;目前为止我们测试的每个策略都失败了是因为它不够自适应（adaptive）：它能够限制一种攻击，但对知道该防御手段的攻击者（attacker）而言，它有其它弱点。设计一种能够防御强大的、会自适应的攻击者的手段，这是一个重要的研究领域。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;结论&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;对抗样本表明能以惊人的方式打破许多现代机器学习算法。机器学习上的这些失败证明即使是简单的算法也能表现出与设计初衷相差甚远的行为。我们鼓励机器学习研究人员参与进来，设计提防对抗样本的方法，从而缩短设计者初衷与算法表现之间的差距。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="color: rgb(136, 136, 136); text-decoration: none;"&gt;&lt;em&gt;&lt;span style="color: rgb(136, 136, 136); text-decoration: none; font-size: 12px;"&gt;原文链接：&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;a style="font-size: 12px; color: rgb(136, 136, 136); text-decoration: none;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;https://openai.com/blog/adversarial-example-research/&lt;/span&gt;&lt;/em&gt;&lt;em&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="min-height: 1em; text-align: justify; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="line-height: 25.6px; font-family: 微软雅黑; font-size: 14px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; color: rgb(127, 127, 127); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="color: rgb(62, 62, 62); line-height: 25.6px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; color: rgb(127, 127, 127); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;©本文为机器之心编译，&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; font-size: 18px; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(127, 127, 127); line-height: 25.6px; font-family: 微软雅黑; text-align: justify; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(217, 33, 66); font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(217, 33, 66); line-height: 1.6; font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-size: 12px; color: rgb(217, 33, 66); line-height: 1.6; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/div&gt;</description>
      <pubDate>Fri, 17 Feb 2017 12:06:43 +0800</pubDate>
    </item>
    <item>
      <title>学界 | 2012-2016 年被引用次数最多的深度学习论文</title>
      <link>http://www.iwgc.cn/link/4740972</link>
      <description>&lt;div class="article-content"&gt;&lt;section style="max-width: 100%; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; line-height: 28.4444px; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%; border: 0px currentcolor; font-family: 微软雅黑; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; max-width: 100%; border-style: solid none; font-family: inherit; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-top: -1.2em; max-width: 100%; min-height: 1em; font-size: 1em; border: currentcolor; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(255, 255, 255); line-height: 22.4px; font-size: 1em; font-family: inherit; text-decoration: inherit; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(117, 117, 118);"&gt;选自Github&lt;/span&gt;&lt;/p&gt;&lt;section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px; max-width: 100%; font-family: inherit; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-bottom: 5px; max-width: 100%; min-height: 1em; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(127, 127, 127); font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;作者：Terry Taewoong Um&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; max-width: 100%; min-height: 1em; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; font-family: inherit; text-decoration: inherit; color: rgb(127, 127, 127); font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong style="max-width: 100%; font-family: inherit; text-decoration: inherit; color: rgb(127, 127, 127); font-size: 12px; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; max-width: 100%; min-height: 1em; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(127, 127, 127); font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;参与：吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;&lt;em&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;近些年来在深度学习热潮的推动下，人工智能领域的研究犹如机器之心的吉祥物土拨鼠在春天里一样不断涌现，到今天，一个人要阅读了解这一领域的所有研究已经不再具有任何实践的可能性。择其善者而读之已经成为了人工智能研究者的一项重要技能，而其中非常值得关注的一项指标就是论文的引用次数，尤其是近期的引用次数。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;滑铁卢大学博士、GitHub 用户 Terry Taewoong Um 就希望能在这方面做出贡献，他在 GitHub 上创建了一个项目，罗列了自 2012 年以来被引用最多的深度学习论文。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px; color: rgb(171, 25, 66);"&gt;项目地址：https://github.com/terryum/awesome-deep-learning-papers&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;这是一个持续更新的项目。机器之心曾在 2016 年 6 月编译发表过这个项目之前的一个版本《&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716071&amp;amp;idx=1&amp;amp;sn=7aa209732425c6a52536fbb9012a09fd&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716071&amp;amp;idx=1&amp;amp;sn=7aa209732425c6a52536fbb9012a09fd&amp;amp;scene=21#wechat_redirect"&gt;学界 | 2010-2016 年被引用次数最多的深度学习论文（附论文下载）&lt;/a&gt;》。近日，这个项目再次进行了更新，下面我们就来看看被引用最多的论文有哪些。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;背景及相关资源&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;在这份榜单前后，也有一些其它很棒的深度学习榜单，比如：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;深度视觉：https://github.com/kjw0612/awesome-deep-vision&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;循环神经网络：https://github.com/kjw0612/awesome-rnn&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;深度学习阅读路线图：https://github.com/songrotek/Deep-Learning-Papers-Reading-Roadmap&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;但要看完这些榜单中提及的内容就已经很困难了，更不要说还有更多不在这些列表中的内容。所以我在这里推出了深度学习论文百强列表，希望能对想要整体了解深度学习研究的人提供帮助。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;评选说明&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;1. 这份深度学习论文百强列表的论文来自 2012-2016 年之间发表的论文。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;2. 如果一篇论文被加入到了这个列表，那么就必然会有一篇论文被移出这个列表（因此，移出论文和加入论文一样都是对这份列表的贡献。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;3. 重要但是却无法被包含进这份列表的论文会收纳到 More than Top 100 列表。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;4.New Papers 和 Old Papers 分别包含了最近 6 个月和 2012 年之前发表的论文。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;评选标准&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;小于 6 个月：New Papers，按讨论加入&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;2016 年：至少 60 次引用&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;2015 年：至少 200 次引用&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;2014 年：至少 400 次引用&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;2013 年：至少 600 次引用&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;2012 年：至少 800 次引用&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;2012 年之前：Old Papers，按讨论加入&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;请注意我们更偏爱开创性的可以应用于多种研究的深度学习论文，而非应用论文。基于这样的原因，一些满足评选标准的论文也被排除了。具体还要依赖该论文的影响、这一领域其它研究的稀缺性等等。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;内容目录&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;理解/泛化/迁移&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;优化/训练技术&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;无监督/生成模型&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;卷积网络模型&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;图像分割/目标检测&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;图像/视频等&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;循环神经网络模型&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;自然语言处理&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;语音/其它领域&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;强化学习&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;2016 年其它论文&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;其它看点&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;新论文（New Papers）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;旧论文（Old Papers）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;HW/SW/数据集：技术报告&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;书籍/调查/概述&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;理解/泛化/迁移&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Distilling the knowledge in a neural network (2015), G. Hinton et al. [pdf]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Deep neural networks are easily fooled: High confidence predictions for unrecognizable images (2015), A. Nguyen et al. [pdf]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;How transferable are features in deep neural networks? (2014), J. Yosinski et al. [pdf]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;CNN features off-the-Shelf: An astounding baseline for recognition (2014), A. Razavian et al. [pdf]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Learning and transferring mid-Level image representations using convolutional neural networks (2014), M. Oquab et al. [pdf]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Visualizing and understanding convolutional networks (2014), M. Zeiler and R. Fergus [pdf]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Decaf: A deep convolutional activation feature for generic visual recognition (2014), J. Donahue et al. [pdf]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;重要研究者：Geoffrey Hinton, Yoshua Bengio, Jason Yosinski&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;优化/训练技术&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Batch normalization: Accelerating deep network training by reducing internal covariate shift (2015), S. Loffe and C. Szegedy [pdf]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Delving deep into rectifiers: Surpassing human-level performance on imagenet classification (2015), K. He et al. [pdf]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Dropout: A simple way to prevent neural networks from overfitting (2014), N. Srivastava et al. [pdf]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Adam: A method for stochastic optimization (2014), D. Kingma and J. Ba [pdf]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Improving neural networks by preventing co-adaptation of feature detectors (2012), G. Hinton et al. [pdf]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Random search for hyper-parameter optimization (2012) J. Bergstra and Y. Bengio [pdf]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;重要研究者：Geoffrey Hinton, Yoshua Bengio, Christian Szegedy, Sergey Ioffe, Kaming He, Diederik P. Kingma&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;无监督/生成模型&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Pixel recurrent neural networks (2016), A. Oord et al. [pdf]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Improved techniques for training GANs (2016), T. Sallmans et al. [pdf]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Unsupervised representation learning with deep convolutional generative adversarial networks (2015), A. Radford et al. [pdf]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;DRAW: A recurrent neural network for image generation (2015), K. Gregor et al. [pdf]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Generative adversarial nets (2014), I. Goodfellow et al. [pdf]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Auto-encoding variational Bayes (2013), D. Kingma and M. Welling [pdf]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Building high-level features using large scale unsupervised learning (2013), Q. Le et al. [pdf]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;重要研究者：Yoshua Bengio, Ian Goodfellow, Alex Graves&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;卷积网络模型&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Rethinking the inception architecture for computer vision (2016), C. Szegedy et al.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Inception-v4, inception-resnet and the impact of residual connections on learning (2016), C. Szegedy et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Identity Mappings in Deep Residual Networks (2016), K. He et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Deep residual learning for image recognition (2016), K. He et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Going deeper with convolutions (2015), C. Szegedy et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Very deep convolutional networks for large-scale image recognition (2014), K. Simonyan and A. Zisserman&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Spatial pyramid pooling in deep convolutional networks for visual recognition (2014), K. He et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Return of the devil in the details: delving deep into convolutional nets (2014), K. Chatfield et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;OverFeat: Integrated recognition, localization and detection using convolutional networks (2013), P. Sermanet et al.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Maxout networks (2013), I. Goodfellow et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Network in network (2013), M. Lin et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;ImageNet classification with deep convolutional neural networks (2012), A. Krizhevsky et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;重要研究者：Christian Szegedy, Kaming He, Shaoqing Ren, Jian Sun, Geoffrey Hinton, Yoshua Bengio, Yann LeCun&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;图像分割/目标检测&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;You only look once: Unified, real-time object detection (2016), J. Redmon et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Region-based convolutional networks for accurate object detection and segmentation (2016), R. Girshick et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Fully convolutional networks for semantic segmentation (2015), J. Long et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks (2015), S. Ren et al.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Fast R-CNN (2015), R. Girshick&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Rich feature hierarchies for accurate object detection and semantic segmentation (2014), R. Girshick et al.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Semantic image segmentation with deep convolutional nets and fully connected CRFs, L. Chen et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Learning hierarchical features for scene labeling (2013), C. Farabet et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;重要研究者：Ross Girshick, Jeff Donahue, Trevor Darrell&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;图像/视频/ETC&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Image Super-Resolution Using Deep Convolutional Networks (2016), C. Dong et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;A neural algorithm of artistic style (2015), L. Gatys et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Deep visual-semantic alignments for generating image descriptions (2015), A. Karpathy and L. Fei-Fei&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Show, attend and tell: Neural image caption generation with visual attention (2015), K. Xu et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Show and tell: A neural image caption generator (2015), O. Vinyals et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Long-term recurrent convolutional networks for visual recognition and description (2015), J. Donahue et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;VQA: Visual question answering (2015), S. Antol et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;DeepFace: Closing the gap to human-level performance in face verification (2014), Y. Taigman et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Large-scale video classification with convolutional neural networks (2014), A. Karpathy et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;DeepPose: Human pose estimation via deep neural networks (2014), A. Toshev and C. Szegedy&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Two-stream convolutional networks for action recognition in videos (2014), K. Simonyan et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;3D convolutional neural networks for human action recognition (2013), S. Ji et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;重要研究者：Oriol Vinyals, Andrej Karpathy&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;循环神经网络模型&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Conditional random fields as recurrent neural networks (2015), S. Zheng and S. Jayasumana.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Memory networks (2014), J. Weston et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Neural turing machines (2014), A. Graves et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Generating sequences with recurrent neural networks (2013), A. Graves. &amp;nbsp;[Key researchers] Alex Graves&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;自然语言处理&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;A character-level decoder without explicit segmentation for neural machine translation (2016), J. Chung et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Exploring the limits of language modeling (2016), R. Jozefowicz et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Teaching machines to read and comprehend (2015), K. Hermann et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Effective approaches to attention-based neural machine translation (2015), M. Luong et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Neural machine translation by jointly learning to align and translate (2014), D. Bahdanau et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Sequence to sequence learning with neural networks (2014), I. Sutskever et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Learning phrase representations using RNN encoder-decoder for statistical machine translation (2014), K. Cho et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;A convolutional neural network for modelling sentences (2014), N. Kalchbrenner et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Convolutional neural networks for sentence classification (2014), Y. Kim&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Glove: Global vectors for word representation (2014), J. Pennington et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Distributed representations of sentences and documents (2014), Q. Le and T. Mikolov&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Distributed representations of words and phrases and their compositionality (2013), T. Mikolov et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Efficient estimation of word representations in vector space (2013), T. Mikolov et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Recursive deep models for semantic compositionality over a sentiment treebank (2013), R. Socher et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;重要研究者：Kyunghyun Cho, Oriol Vinyals, Richard Socher, Tomas Mikolov, Christopher D. Manning, Yoshua Bengio&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;语音/其它领域&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;End-to-end attention-based large vocabulary speech recognition (2016), D. Bahdanau et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Deep speech 2: End-to-end speech recognition in English and Mandarin (2015), D. Amodei et al.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Speech recognition with deep recurrent neural networks (2013), A. Graves&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups (2012), G. Hinton et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Context-dependent pre-trained deep neural networks for large-vocabulary speech recognition (2012) G. Dahl et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Acoustic modeling using deep belief networks (2012), A. Mohamed et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;重要研究者：Alex Graves, Geoffrey Hinton, Dong Yu&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;强化学习&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;End-to-end training of deep visuomotor policies (2016), S. Levine et al.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Learning Hand-Eye Coordination for Robotic Grasping with Deep Learning and Large-Scale Data Collection (2016), S. Levine et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Asynchronous methods for deep reinforcement learning (2016), V. Mnih et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Deep Reinforcement Learning with Double Q-Learning (2016), H. Hasselt et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Mastering the game of Go with deep neural networks and tree search (2016), D. Silver et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Continuous control with deep reinforcement learning (2015), T. Lillicrap et al.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Human-level control through deep reinforcement learning (2015), V. Mnih et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Deep learning for detecting robotic grasps (2015), I. Lenz et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Playing atari with deep reinforcement learning (2013), V. Mnih et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;重要研究者：Sergey Levine, Volodymyr Mnih, David Silver&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;2016 年其它论文&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Layer Normalization (2016), J. Ba et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Learning to learn by gradient descent by gradient descent (2016), M. Andrychowicz et al.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Domain-adversarial training of neural networks (2016), Y. Ganin et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;WaveNet: A Generative Model for Raw Audio (2016), A. Oord et al.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Colorful image colorization (2016), R. Zhang et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Generative visual manipulation on the natural image manifold (2016), J. Zhu et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Texture networks: Feed-forward synthesis of textures and stylized images (2016), D Ulyanov et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;SSD: Single shot multibox detector (2016), W. Liu et al.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and&amp;lt; 1MB model size (2016), F. Iandola et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Eie: Efficient inference engine on compressed deep neural network (2016), S. Han et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Binarized neural networks: Training deep neural networks with weights and activations constrained to+ 1 or-1 (2016), M. Courbariaux et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Dynamic memory networks for visual and textual question answering (2016), C. Xiong et al.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Stacked attention networks for image question answering (2016), Z. Yang et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Hybrid computing using a neural network with dynamic external memory (2016), A. Graves et al.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation (2016), Y. Wu et al.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;新论文（New Papers）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;最近六个月内值得一读的论文：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Batch Renormalization: Towards Reducing Minibatch Dependence in Batch-Normalized Models, S. Ioffe.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Understanding deep learning requires rethinking generalization, C. Zhang et al&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;旧论文（Old Papers）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;2012 年之前发表的经典论文：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;An analysis of single-layer networks in unsupervised feature learning (2011), A. Coates et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&amp;nbsp;Deep sparse rectifier neural networks (2011), X. Glorot et al&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&amp;nbsp;Natural language processing (almost) from scratch (2011), R. Collobert et al&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&amp;nbsp;Recurrent neural network based language model (2010), T. Mikolov et al&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&amp;nbsp;Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion (2010), P. Vincent et al&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&amp;nbsp;Learning mid-level features for recognition (2010), Y. Boureau&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&amp;nbsp;A practical guide to training restricted boltzmann machines (2010), G. Hinton &amp;nbsp; Understanding the difficulty of training deep feedforward neural networks (2010), X. Glorot and Y. Bengio&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&amp;nbsp;Why does unsupervised pre-training help deep learning (2010), D. Erhan et al&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&amp;nbsp;Recurrent neural network based language model (2010), T. Mikolov et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&amp;nbsp;Learning deep architectures for AI (2009), Y. Bengio.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&amp;nbsp;Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations (2009), H. Lee et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&amp;nbsp;Greedy layer-wise training of deep networks (2007), Y. Bengio et al&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&amp;nbsp;Reducing the dimensionality of data with neural networks, G. Hinton and R. Salakhutdinov&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&amp;nbsp;A fast learning algorithm for deep belief nets (2006), G. Hinton et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&amp;nbsp;Gradient-based learning applied to document recognition (1998), Y. LeCun et al&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&amp;nbsp;Long short-term memory (1997), S. Hochreiter and J. Schmidhuber.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;HW/SW/数据集&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&amp;nbsp;OpenAI gym (2016), G. Brockman et al&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&amp;nbsp;TensorFlow: Large-scale machine learning on heterogeneous distributed systems &amp;nbsp;(2016), M. Abadi et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&amp;nbsp;Theano: A Python framework for fast computation of mathematical expressions, &amp;nbsp; &amp;nbsp; &amp;nbsp;R. Al-Rfou et al.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&amp;nbsp;MatConvNet: Convolutional neural networks for matlab (2015), A. Vedaldi and K. &amp;nbsp;Lenc&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&amp;nbsp;Imagenet large scale visual recognition challenge (2015), O. Russakovsky et al&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&amp;nbsp;Caffe: Convolutional architecture for fast feature embedding (2014), Y. Jia et al&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;书籍/调查/概述&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&amp;nbsp;Deep learning (Book, 2016), Goodfellow et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&amp;nbsp;LSTM: A search space odyssey (2016), K. Greff et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&amp;nbsp;Deep learning (2015), Y. LeCun, Y. Bengio and G. Hinton&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&amp;nbsp;Deep learning in neural networks: An overview (2015), J. Schmidhuber &amp;nbsp; &amp;nbsp; &amp;nbsp;Representation learning: A review and new perspectives (2013), Y. Bengio et al.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="min-height: 1em; text-align: justify; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="line-height: 25.6px; font-family: 微软雅黑; font-size: 14px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; color: rgb(127, 127, 127); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="color: rgb(62, 62, 62); line-height: 25.6px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; color: rgb(127, 127, 127); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;©本文为机器之心编译，&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; font-size: 18px; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(127, 127, 127); line-height: 25.6px; font-family: 微软雅黑; text-align: justify; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(217, 33, 66); font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(217, 33, 66); line-height: 1.6; font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-size: 12px; color: rgb(217, 33, 66); line-height: 1.6; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/div&gt;</description>
      <pubDate>Fri, 17 Feb 2017 12:06:43 +0800</pubDate>
    </item>
    <item>
      <title>观点 | 大西洋月刊：从AAAI看人工智能领域的中国崛起</title>
      <link>http://www.iwgc.cn/link/4740973</link>
      <description>&lt;div class="article-content"&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;section style="max-width: 100%; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; line-height: 28.4444px; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%; border: 0px currentcolor; font-family: 微软雅黑; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; max-width: 100%; border-style: solid none; font-family: inherit; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-top: -1.2em; max-width: 100%; min-height: 1em; font-size: 1em; border: currentcolor; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(255, 255, 255); line-height: 22.4px; font-size: 1em; font-family: inherit; text-decoration: inherit; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(117, 117, 118);"&gt;选自Theatlantic&lt;/span&gt;&lt;/p&gt;&lt;section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px; max-width: 100%; font-family: inherit; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-bottom: 5px; max-width: 100%; min-height: 1em; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(127, 127, 127); font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;作者：SARAH ZHANG&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; max-width: 100%; min-height: 1em; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; font-family: inherit; text-decoration: inherit; color: rgb(127, 127, 127); font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong style="max-width: 100%; font-family: inherit; text-decoration: inherit; color: rgb(127, 127, 127); font-size: 12px; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; max-width: 100%; min-height: 1em; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(127, 127, 127); font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;参与：晏奇、黄小天&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;每年冬天，来自全世界的成百上千个人工智能研究人员会相聚一年一度的 AAAI（Association of the Advancement of Artificial Intelligence）大会。去年，当 AAAI 宣布下一届会议将于明年 1 月在美国新奥尔良举办时，议程却遭到了一小部分人的反对。会址没有问题，但日期与中国春节相冲突。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487305840EwVRjh.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;span style="font-size: 12px; color: rgb(136, 136, 136);"&gt;&lt;em&gt;中国的大学与科技巨头正在人工智能研究与应用领域赶超美国&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;span style="font-size: 12px; color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;br&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;以往 AAAI 大会很少会为了节日而改期，但现在情况变了，中国参会人员已经变得重要，没有他们，会议简直就无法开展。最终会议还是不得不改期。现任 AAAI 主席 Subbarao Kambhampati（Rao）说：没人会在圣诞节举办 AAAI 大会。我们很快做出改变，重选了会址并推迟一周开幕。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;最终在上周，2017 AAAI 大会于旧金山圆满落幕。不出所料，中国研究人员在这个由美国主导的历史性会议上表现强劲。大会收录的中国论文的数量几近与美国持平。AAAI 主席 Rao 说：「这相当激动人心，如果倒回到 3、4 年之前，这一切难以想象」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;中国人工智能研究排名的迅速上升引人注目。10 月，白宫发布了一份关于人工智能研究的战略计划，指出在人工智能研究的热门子领域深度学习方面，美国的期刊论文数量不再领先世界。谁在赶超美国？毋庸置疑，中国。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;中国不仅在学术研究方面正在赶超美国。中国的技术公司也在人工智能上押注。百度、滴滴和腾讯都设立自己的人工智能研究实验室。由于拥有海量用户，它们可以轻易获得大数据以训练人工智能检测模型需求。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;和微软、谷歌一样，中国的科技公司也看到了人工智能的巨大潜力。在未来的 10 年，从面部识别到自动驾驶汽车，人工智能将推进整个系列的革命性技术。百度首席科学家、Coursera 和谷歌大脑的联合创始人吴恩达说：「没有产业不会被人工智能改造。」现在他正在硅谷的森尼韦尔主管百度的人工智能研究。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;中国在人工智能方面的成就部分原因来自政府在大学中对科研的总体投资。过去的十年中，中国政府在研究上的投资平均每年都以两位数的速度增长。如今年 3 月份发布的中国「五年计划」中我们可以看到，对于科学与技术研究的资助持续占有首要地位。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;Rao 回忆说，当他首次在国际人工智能会议上看见中国研究者时，他们一般都来自清华大学和北京大学，这两所大学被看作中国的麻省理工和哈佛大学。现在，Rao 可以看见来自中国全国各地研究者发来的论文，而不仅仅是那些最顶尖的学校。机器学习（包括了深度学习）最近一直以来都是热点话题。「在中国，关注应用机器学习的人数正在猛蹭」，Rao 说道。这个上升的趋势在白宫的人工智能战略研究中也被提及。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;中国的科技公司也在参与和投资大学的研究项目。香港科技大学的计算机科学家杨强就在与腾讯公司合作（腾讯为杨强实验室的学生提供了奖学金）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;微信是腾讯公司开发的消息应用，类似于 Facebook、iMessage 和 Venmo 三者功能的合一，学生从这里接触到海量数据。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;杨强说：「要做人工智能，我们必然需要大量的数据和一个测试它的平台才可以。」这也就是为什么与产业界的合作如此重要。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;作为回报，腾讯可以直接接触到学术界实验室最具创造力的研究。当然，这些实验室的一些学生毕业后，也会去腾讯工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;中国人工智能研究的质量也在显著上升，不过，美国美国研究者仍然主导许多最具基础突破性的研究。吴恩达说：「我发现，那些改变网络架构的聪明点子还是来自美国。」中国研究者一直擅长的是利用一个想法（比如机器学习），并就这一想法的不同应用为主题发表论文。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;然而，吴恩达说，随着中国人工智能研究的逐渐成熟，它也会形成自己独特的研究社区。他回忆说，巴塞罗那召开的国际会议结束后，有关会议演讲的中文报道立刻出来，但是，却没找到英文报道。语言造成了某种不对称：中国研究者通常使用英语，这有利于他们接触到所有英文研究。可是另一方面，英语主导的研究社区则不太有可能参与到中文人工智能社区当中去。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;「中国对英语世界发生的事情有着非常深度的关注，但是反之则不然，」吴恩达说道。他指出，在像谷歌和微软这样更有名的大公司之前，百度就率先推出了由人工智能技术支持的机器翻译和语音识别服务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;在推出新功能方面，中国公司会更加迅速。「中国研究的发展速度远超大部分硅谷企业，」吴恩达说道。「当你在中国发现了一个商机，给你敞开的反应时间通常来说非常短——比在美国更短。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;对于这一切，杨强将其归因于中国高度竞争的生态系统。例如微信已经围绕二维码、聊天、支付和朋友发现打造了一系列的功能，这些功能已经在中国公民的日常生活中变得必不可少。然而，美国社交媒体公司仅仅还在希望他们的用户拥有足够的忠诚度。杨强说：「腾讯的产品经理对于用户需求有着很好的判断，他们可以很快将技术投入应用，这个周期非常短。」并且为了保持竞争力，中国公司的首要任务是整合人工智能来改善它们的产品。中国科技公司是否在凭人工智能浪潮闯入国际市场还有待观察，但是在中国，它们已经在开始使用人工智能来争夺中国消费者了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;在学术界，现在 AAAI 已在着手确保中国研究人员的贡献和参与了。每一年的中国春节日期并不同，但多是在 1 月或 2 月，AAAI 通常也在这个时期举办。因此，我们一定要避免再次发生冲突。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 12px;"&gt;原文：&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;a style="font-size: 12px; color: rgb(136, 136, 136);"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;https://www.theatlantic.com/technology/archive/2017/02/china-artificial-intelligence/516615/?utm_source=fe&lt;/span&gt;&lt;/em&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px; text-decoration: none;"&gt;&lt;/span&gt;&lt;em&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;ed&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="min-height: 1em; text-align: justify; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="line-height: 25.6px; font-family: 微软雅黑; font-size: 14px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; color: rgb(127, 127, 127); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="color: rgb(62, 62, 62); line-height: 25.6px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; color: rgb(127, 127, 127); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;©本文为机器之心编译，&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; font-size: 18px; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(127, 127, 127); line-height: 25.6px; font-family: 微软雅黑; text-align: justify; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(217, 33, 66); font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(217, 33, 66); line-height: 1.6; font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-size: 12px; color: rgb(217, 33, 66); line-height: 1.6; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/div&gt;</description>
      <pubDate>Fri, 17 Feb 2017 12:06:43 +0800</pubDate>
    </item>
    <item>
      <title>学界 | 谷歌提交新论文提出认知型地图构建器和规划器：同时应对视觉导航的几何和语义任务</title>
      <link>http://www.iwgc.cn/link/4740974</link>
      <description>&lt;div class="article-content"&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;section style="max-width: 100%; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; line-height: 28.4444px; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%; border: 0px currentcolor; font-family: 微软雅黑; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; max-width: 100%; border-style: solid none; font-family: inherit; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-top: -1.2em; max-width: 100%; min-height: 1em; font-size: 1em; border: currentcolor; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(255, 255, 255); line-height: 22.4px; font-size: 1em; font-family: inherit; text-decoration: inherit; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(117, 117, 118);"&gt;选自Google&lt;/span&gt;&lt;/p&gt;&lt;section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px; max-width: 100%; font-family: inherit; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-bottom: 5px; max-width: 100%; min-height: 1em; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(127, 127, 127); font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;作者：Saurabh Gupta 等&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; max-width: 100%; min-height: 1em; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; font-family: inherit; text-decoration: inherit; color: rgb(127, 127, 127); font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong style="max-width: 100%; font-family: inherit; text-decoration: inherit; color: rgb(127, 127, 127); font-size: 12px; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; max-width: 100%; min-height: 1em; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(127, 127, 127); font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;参与：吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;论文题目：Cognitive Mapping and Planning for Visual Navigation&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;摘要&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;我们介绍了一种用于在全新的环境中导航的神经架构。我们提出的架构可以学习根据第一人称视角构建地图（mapping）和在环境中规划（planning）到达目的地的动作序列。这个认知型地图构建器和规划器（CMP/Cognitive Mapper and Planner）基于两个关键思想：a）一个用于地图构建和规划的统一联合架构，这样使得该地图构建可由规划者的需求来驱动；b）一个可以在关于世界的观察集合不完整时能够进行规划的空间记忆。CMP 能构建一个自上而下的关于世界的可信度地图（belief map）并应用一个可微神经网络规划器来在每一个时间步骤产生下一个动作。这种关于世界的积累的可信度使得该代理（agent）能够跟踪其环境中已经访问过的区域。我们的实验表明该 CMP 的表现超过了反应策略（reactive strategies）和标准的基于记忆的架构，并且可以在全新的环境中获得良好的表现。此外，我们还表明 CMP 也能够实现特定语义的目标，比如「go to a chair」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;问题陈述&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;在全新环境中的视觉导航。我们研究了几何任务（其中任务根据相对于机器人当前位置的偏移来确定）和语义任务（其中任务根据实现一个特定的目标类别来确定）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;方法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;我们的学习过的导航网络由一个地图构建器（mapper）和一个规划器（planner）模块构成。其中地图构建器写入对应于一个环境的自我中心地图的隐记忆（latent memory），而规划器则使用这个记忆来输出导航动作。这个地图并没有受到明确的监督，而是从学习过程中自然地融合得到的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/14873058424WlhJH.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;地图构建器模块可以处理来自机器人的第一人称图像并将其观察整合到隐记忆中，这个隐记忆对应于一个对于环境的顶视角的自我中心地图。这个地图构建的操作并没有收到明确的监督——该地图构建器可以自由地向记忆写入任何对规划器最有用的信息。除了填充障碍物之外，该地图构建器还能在地图中存储置信度值（confidence values），这允许其通过利用已学到的模式做出关于地图中未被观察的部分的概率预测。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487305842b4toQO.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;这种分层规划器利用了地图构建器输出的关于世界的以自我为中心的多尺度可信度（egocentric multi-scale belief），并使用了以卷积表示的值迭代和以通道（channel）方式的最大池化，以输出一个策略。该规划器是可训练和可微分的，并会将梯度反向传播给地图构建器。该规划器可在多种规模的问题上工作（规模 0 是最好的规模），这能实现高效的规划。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487305842ogFB31.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;结果&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;实验是在由 3D 真实扫描构成的静态环境中执行的。我们测算了到目标的平均距离、到目标的 75% 分位的距离和成功率，作为我们提出的方法（CMP）的步骤的函数，此外还测算了一个反应基线（reactive baseline）和一个基于 LSTM 的基线。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487305842CvUPhl.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;在这个视频中，我们展示了我们提出的算法的一些成功和失败的导航案例。注意视频中所给出的结果，该代理使用了第一人称的深度图像作为输入，而我们为了让可视化更容易而使用了 RGB 图像。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;strong&gt;视频&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;iframe class="video_iframe" data-vidtype="1" allowfullscreen="" frameborder="0" height="417" width="556" data-src="https://v.qq.com/iframe/preview.html?vid=k0375pbhot2&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0"&gt;&lt;/iframe&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 12px;"&gt;原文：&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;https://sites.google.com/view/cognitive-mapping-and-planning/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="min-height: 1em; text-align: justify; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="line-height: 25.6px; font-family: 微软雅黑; font-size: 14px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; color: rgb(127, 127, 127); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="color: rgb(62, 62, 62); line-height: 25.6px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; color: rgb(127, 127, 127); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;©本文为机器之心编译，&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; font-size: 18px; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(127, 127, 127); line-height: 25.6px; font-family: 微软雅黑; text-align: justify; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(217, 33, 66); font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(217, 33, 66); line-height: 1.6; font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-size: 12px; color: rgb(217, 33, 66); line-height: 1.6; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/div&gt;</description>
      <pubDate>Fri, 17 Feb 2017 12:06:43 +0800</pubDate>
    </item>
    <item>
      <title>重磅 | 谷歌召开首届TensorFlow开发者大会，正式发布TensorFlow 1.0</title>
      <link>http://www.iwgc.cn/link/4724267</link>
      <description>&lt;div class="article-content"&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;section style="white-space: normal; line-height: 28.4444px; background-color: rgb(255, 255, 255); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="border: 0px currentcolor; font-family: 微软雅黑; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; border-style: solid none; font-family: inherit; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="color: rgb(62, 62, 62); font-size: 1em; margin-top: -1.2em; min-height: 1em; border: currentcolor; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(255, 255, 255); background-color: rgb(117, 117, 118); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;选自Google&lt;/span&gt;&lt;/p&gt;&lt;section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px; font-family: inherit; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="color: rgb(62, 62, 62); font-size: 16px; margin-top: 5px; margin-bottom: 5px; min-height: 1em; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(127, 127, 127); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-top: 5px; margin-bottom: 5px; min-height: 1em; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color:#7f7f7f"&gt;&lt;span style="font-size: 12px;"&gt;&lt;strong&gt;参与：吴攀、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style="min-height: 1em; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; background-color: rgb(255, 255, 255); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;br style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/p&gt;&lt;p style="min-height: 1em; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-size: 14px; text-align: justify;"&gt;TensorFlow 发布一年以来已经帮助研究者、工程师、艺术家、学生等等许多人在语言翻译、皮肤癌早期检测和预防糖尿病致失明等许多方面取得了许多进展。如今，在网上已经有超过 6000 个使用 TensorFlow 的开源软件库和项目了。&lt;/span&gt;&lt;br&gt;&lt;span style="font-size: 14px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="min-height: 1em; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-size: 14px; text-align: justify;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;今天，在山景城召开了第一届年度 TensorFlow 开发者大会（TensorFlow Developer Summit），本次盛会也已经在 YouTube 上开启了直播。在本次大会上，谷歌也正式宣布发布 TensorFlow 1.0 正式版。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;TensorFlow 1.0：https://github.com/tensorflow/tensorflow/releases/tag/v1.0.0&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;直播地址：https://www.youtube.com/watch?v=LqLyrl-agOw&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;XLA：https://www.tensorflow.org/performance/xla&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;尽管在 &lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722208&amp;amp;idx=5&amp;amp;sn=392a6aa77f0f5eeb976636f4fe791cc7&amp;amp;chksm=871b0bdeb06c82c84cb811fa6e059b988f56249d027dbdcb5f28fe45a1167f27c1f1e1cd6de2&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722208&amp;amp;idx=5&amp;amp;sn=392a6aa77f0f5eeb976636f4fe791cc7&amp;amp;chksm=871b0bdeb06c82c84cb811fa6e059b988f56249d027dbdcb5f28fe45a1167f27c1f1e1cd6de2&amp;amp;scene=21#wechat_redirect"&gt;TensorFlow 1.0.0-alpha&lt;/a&gt; 发布的时候我们就预期到了本次大会上正式版的到来，但 TensorFlow 1.0 仍有一些值得我们关注的亮点（以下内容来自谷歌开发者博客）：&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;速度更快：TensorFlow 1.0 快得让人难以置信！XLA 更为未来进一步的性能提升奠定了基础，而且 tensorflow.org 上现在也已经包含了帮助指导你调整你的模型以使其达到最大速度的技巧和诀窍。我们将会很快发布几种流行的模型的新实现，以表明我们可以如何充分利用 TensorFlow 1.0——包括在 8 个 GPU 上给 Inception v3 带来的 7.3 倍的速度提升和在 64 个 GPU 上为分布式 Inception v3 训练所带来的 58 倍速度提升！&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;灵活性更高：TensorFlow 1.0 引入了一个高层面的 API，带有 tf.layers、tf.metrics 和 tf.losses 模块。我们还宣布包含进了一个新的 tf.keras 模块，提供了与另一个流行的高级神经网络库 Keras 的完全兼容。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;比以往任何时候都更适合生产：TensorFlow 1.0 保证了 Python API 的稳定性，使得你可以在无需担忧破坏你现有代码的情况下更容易地获取新功能。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;TensorFlow 1.0 的其它亮点：&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Python API 已改为更类似于 NumPy 的样子。为了应用这种和其它的为了支持 API 稳定性所做的后端兼容修改，请参考我们好用的移植指南（https://tensorflow.org/install/migration）和转换脚本（https://github.com/tensorflow/tensorflow/tree/r1.0/tensorflow/tools/compatibility）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;支持 Java 和 Go 的实验性 API&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;在集成了 skflow 和 TF Slim 后从 tf.contrib.learn 带来的高级 API 模块：tf.layers、tf.metrics 和 tf.losses&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;XLA 的实验性发布，这是一个用于 TensorFlow 图的特定领域的编译器，其面向 CPU 和 GPU。XLA 正在快速进化——在未来的版本中有望见证更多改进&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;引入 TensorFlow Debugger (tfdbg)，这是一个用于调试实时 TensorFlow 程序的接口和 API。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;新的关于目标检测和定位、基于相机的图像风格化的 Android 演示&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;安装提升：加入 Python 3 docker images，TensorFlow pip 包现在已兼容 PyPI。这意味着现在可以通过简单的调用 pip install tensorflow 来实现安装。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;在此届的 TensorFlow 开发者大会上，除了宣布发布 TensorFlow 1.0 正式版之外，还有许多其他亮点。其中一些演讲的视频已经公开，一些演讲正在进行中。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;主题演讲（Keynote）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;在开发者大会上，谷歌的 Jeff Dean、Rajat Monga 和 Megan Kacholia 做了主题演讲，他们讨论了 TensorFlow 的起源、开源之后的发展、TensorFlow 对社区繁荣作出的贡献、TensorFlow 的表现与延展性、TensorFlow 在全球的应用等。当然，也包括一些激动人心的消息的公布，比如 TensorFlow 1.0 的发布。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;iframe class="video_iframe" data-vidtype="1" allowfullscreen="" frameborder="0" height="417" width="556" data-src="https://v.qq.com/iframe/preview.html?vid=q0375ea3s9g&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0"&gt;&lt;/iframe&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;除了 Keynote 之外，还有许多精彩的演讲视频已经公开。这些演讲涉及到 TensorFlow 的方方面面：高层次的 API、应用（癌症图像分类）、分布式 TensorFlow 等。&lt;/span&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;其中讲解应用 TensorFlow 进行癌症图像分类的是斯坦福 Thrun 实验室的研究生 Brett Kuprel。&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722733&amp;amp;idx=2&amp;amp;sn=cc0f7f4ee6294f766f235267b73938ef&amp;amp;chksm=871b15d3b06c9cc57d31c803eb310722d9d93b05802bb0c502c1c574c5ab566410d8a5b821ac&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722733&amp;amp;idx=2&amp;amp;sn=cc0f7f4ee6294f766f235267b73938ef&amp;amp;chksm=871b15d3b06c9cc57d31c803eb310722d9d93b05802bb0c502c1c574c5ab566410d8a5b821ac&amp;amp;scene=21#wechat_redirect"&gt;该实验室的研究者成功训练了一个可以诊断皮肤癌的算法&lt;/a&gt;，相关论文《Dermatologist-level classification of skin cancer with deep neural networks》已经发表在 Nature 上，并成为了封面文章。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;iframe class="video_iframe" data-vidtype="1" allowfullscreen="" frameborder="0" height="417" width="556" data-src="https://v.qq.com/iframe/preview.html?vid=k03756n3r9k&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0"&gt;&lt;/iframe&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;以下为其他演讲的简介与视频观看链接：&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;XLA: TensorFlow, Compiled!&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;演讲者：Chris Leary 和 Todd Wang&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;链接：https://www.youtube.com/watch?v=kAOanJczHA0&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;简介：对于有效的机器学习而言，速度就是一切，XLA 就是为减少训练和推理时间而生的。在这个演讲中，Chris Leary 和 Todd Wang 描述了 TensorFlow 使用 XLA、JIT、AOT 和其它编译技术可以如何最小化执行时间和最大化地利用计算资源。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;上手 TensorBoard（Hands-on TensorBoard）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;演讲者：Dandelion Mane&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;链接：https://www.youtube.com/watch?v=eBbEDRsCmv4&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;简介：Dandelion Mane 的这个演讲展示了所有你可以使用 TensorBoard 做到的惊人的事情。你将学会如何可视化你的 TensorFlow Graph、监控你的训练表现以及探索你的模型表征你的数据的方式。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;TensorFlow 高级 API（TensorFlow High-Level API）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;演讲者：Martin Wicke&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;链接：https://www.youtube.com/watch?v=t64ortpgS-E&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;简介：TensorFlow 能让你使用高级与低级抽象定义模型。在此演讲中，Martin Wicke 将会介绍定义模型的层、评估器和 Canned Estimators，也会演示核心 TensorFlow 中的延展线路。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;整合 Keras 和 TensorFlow：扩展 Keras 工作流（Integrating Keras &amp;amp; TensorFlow: The Keras Workflow, Expanded）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;演讲者：Francois Chollet&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;链接：https://www.youtube.com/watch?v=UeheTiBJ0Io&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;简介：Keras 的目标是让每个人都能用上深度学习，它也是增长最快的机器学习框架之一。Keras 的主要作者 Join Francois Chollet 通过一个视频问答案例演示了可以如何在 TensorFlow 之中使用 Keras。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;TensorFlow at DeepMind&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;演讲者：Daniel Visentin&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;链接：https://www.youtube.com/watch?v=VdDmhOCw6J0&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;简介：在这个演讲中，来自 DeepMind 的 Daniel Visentin 谈论了 DeepMind 和 TensorFlow。他将解释选择一个平台的重要性，该团队的选择是迁移到 TensorFlow，并还给出了一些 DeepMind 使用 TensorFlow 的例子。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;皮肤癌图像分类（Skin Cancer Image Classification）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;演讲者：Brett Kuprel&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;视频：https://www.youtube.com/watch?v=toK1OSLep3s&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;简介：Join Brett Kuprel 介绍了斯坦福大学的人工智能实验室和医学院是如何使用 TensorFlow 来分类皮肤癌图像的。他描述了该项目的步骤：从获取数据集、训练深度网络到评估结果。最后，Brett 还将谈论皮肤癌图像分类的未来。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;移动和嵌入式 TensorFlow（Mobile and Embedded TensorFlow）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;演讲者：Pete Warden&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;链接：https://www.youtube.com/watch?v=0r9w3V923rk&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;简介：你知道 TensorFlow 模型可以在 iOS、安卓、甚至是树莓派上部署吗？在这个演讲中，Peter Warden 会讲解在这些上面部署 TensorFlow 模型所需要的所有东西，途中也会提供一些金点子。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;分布式 TensorFlow（Distributed TensorFlow）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;演讲者：Derek Murray&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;链接：https://www.youtube.com/watch?v=la_M6bCV91M&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;简介：TensorFlow 有很大的灵活性——可以扩展到数百个 GPU、训练带有大量参数的模型和自定义训练过程的每个细节。在这个演讲中，Derek Murray 将给你一个自底向上的关于分布式 TensorFlow 的介绍，并展示了所有可以用来利用这种力量的工具。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;TensorFlow 生态系统：整合 TensorFlow 和你的基础设施（TensorFlow Ecosystem: Integrating TensorFlow with Your Infrastructure）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;演讲者：Jonathan Hseu&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;链接：https://www.youtube.com/watch?v=yALzr4A2AzY&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;简介：生成输入数据、运行分布式 TensorFlow 训练和服务器模型都涉及到其他基础设施组件。Jonathan Hseu 将描述每个步骤之间的融合。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;在生产中使用 TensorFlow Serving 的 Serving 模型（Serving Models in Production with TensorFlow Serving）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;演讲者：Noah Fiedel&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;链接：https://www.youtube.com/watch?v=q_IkJcPyNl0&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;简介：serving 是指在你的应用中使用一个训练好的模型的过程。在这个演讲中，Noah Fiedel 介绍了 TensorFlow Serving——一个为生产环境设计的灵活且高性能的机器学习 serving 系统。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;机器学习工具包（ML Toolkit）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;演讲者：Ashish Agarwal&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;链接：https://www.youtube.com/watch?v=Tuv5QYKU-MM&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;简介：TensorFlow 是一个非常强大的框架，然而也一直以来都缺乏可以即时使用的解决方案。在这演讲中，Ashish Agarwal 将介绍一个向这个方面迈出了前进的一步的算法工具包。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;以上就是目前已经公开的演讲视频内容，更多内容可在这个会议网页查看：https://events.withgoogle.com/tensorflow-dev-summit/videos-and-agenda/#content&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="min-height: 1em; text-align: justify; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="line-height: 25.6px; font-family: 微软雅黑; font-size: 14px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; color: rgb(127, 127, 127); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="color: rgb(62, 62, 62); line-height: 25.6px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; color: rgb(127, 127, 127); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;©本文为机器之心编译，&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; font-size: 18px; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(127, 127, 127); line-height: 25.6px; font-family: 微软雅黑; text-align: justify; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(217, 33, 66); font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(217, 33, 66); line-height: 1.6; font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-size: 12px; color: rgb(217, 33, 66); line-height: 1.6; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/div&gt;</description>
      <pubDate>Thu, 16 Feb 2017 11:36:15 +0800</pubDate>
    </item>
    <item>
      <title>Science Robotics | 新型磁控方法可单个控制体内微型机器人，实现精准定向手术</title>
      <link>http://www.iwgc.cn/link/4724268</link>
      <description>&lt;div class="article-content"&gt;&lt;section style="white-space: normal; line-height: 28.4444px; background-color: rgb(255, 255, 255); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="border: 0px currentcolor; font-family: 微软雅黑; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; border-style: solid none; font-family: inherit; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="color: rgb(62, 62, 62); font-size: 1em; margin-top: -1.2em; min-height: 1em; border: currentcolor; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(255, 255, 255); line-height: 22.4px; font-size: 1em; font-family: inherit; text-decoration: inherit; background-color: rgb(117, 117, 118); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;选自IEEE Spectrum、Science Robotics&lt;/span&gt;&lt;/p&gt;&lt;section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px; font-family: inherit; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(127, 127, 127); font-size: 12px;"&gt;&lt;strong&gt;作者：Evan Ackerman 等&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="color: rgb(62, 62, 62); font-size: 16px; margin-bottom: 5px; min-height: 1em; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-family: inherit; text-decoration: inherit; color: rgb(127, 127, 127); font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong style="font-family: inherit; text-decoration: inherit; color: rgb(127, 127, 127); font-size: 12px; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(127, 127, 127); font-size: 12px;"&gt;&lt;strong&gt;参与：微胖、李泽南、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style="min-height: 1em; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; text-align: justify; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-size: 14px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/span&gt;&lt;br style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/p&gt;&lt;blockquote style="color: rgb(62, 62, 62); font-size: 16px; white-space: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/blockquote&gt;&lt;blockquote&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 12px;"&gt;最新一期的 Science Robotics 展示了机器人领域的新研究成果：以磁力远程驱动和控制的人体内微型机器人。本期的其它内容可在 http://robotics.sciencemag.org/content/2/3/eaal2845 查看。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/14872164865YWSki.jpg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px; text-align: justify;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px; text-align: justify;"&gt;控制机器人在人体内的运动有两种办法：试着打造一种复杂的自带推进和导航的微型机器人潜水艇（不过这类机器人很难做），或是打造响应磁场的小不点儿机器人（利用大磁铁从外部控制机器人的运动）。后一种方法要简单得多，不过有一个主要的不足：难以控制多个微型机器人。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;问题在于：磁场因为是场，因此不易局限在某个特定区域。实际上，如果你在使用诸如一台临床 MRI 扫描仪来创造磁场，那么，无论磁场梯度如何，都会影响到 MRI 内部的所有东西，无论是单个微型机器人还是一群机器人。如果你想让两个不同的机器人做不同的事情，对不起，那就不走运了。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;一个有希望的潜在解决方式就是让每个机器人彼此轻微差异化，这样，持续的控制输入就能对每个机器人产生并不一致的影响。不过，对于同质机器人（homogenous robots）来说，就要难得多。今天，发表在 Science Robotics 上的一篇论文（来自德国汉堡的飞利浦研究院，Philips Research in Germany）介绍了一种技术，可以利用磁场选择性地驱动单个机器人，或者这个机器人的某个组件，即使这些机器人都是同一材质制作的，并位于同一磁场中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;iframe class="video_iframe" data-vidtype="1" allowfullscreen="" frameborder="0" height="417" width="556" data-src="https://v.qq.com/iframe/preview.html?vid=a0375bwbpwy&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0"&gt;&lt;/iframe&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;这是这一技术的运作原理：设备中的整体磁场中有一个洞，也叫自由场点（a free field point，FFP），也是多个磁场（每个磁场都是有独立线圈生成的）相遇的地方。在 FFP 里面，磁场梯度很低，没办法协助你移动物体，不过，却能帮助你不移动物体，因为你可以在适当的地方，通过调大磁场梯度，「锁住」不在 FFP 中的任何东西。然后，采用一个温和的旋转磁场，它可以旋转 FFP 中任何东西而不会下锁。通过来回移动 FFP，你就可以选择要锁住的东西以及要自由转动的东西。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;在这一案例中，「锁」是一个利用磁场而一边倾斜的螺旋体（screws），这样它们就不能旋转，而 FFP 是零度倾斜区域，亦即螺旋体可以自由旋转。这一研究采用的硬件可以单个驱动螺旋体，而且这些螺旋体的间距可以低至 3 毫米左右。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216486QJ83vt.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;由磁场生成器（左）的图解可见有三套直角线圈，在 z 方向（灰色）有一个铁质内核。磁场生成器（中）有一个直径 12 厘米的钻孔。xy 平面（右）上理想磁场中心有一个 0 点，也就是自由场点（FFP），白色的箭头代表局部磁场向量。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;研究人员建议了一大堆不同的办法来让这一技术发挥实际作用：&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;有一类应用是以几个分别加以控制的螺旋体驱动机制为基础的。在整形外科中，可用于移植，被移植部分的形状能够根据恢复过程发生变化。在诸如下肢增长或早发性脊柱侧凸等案例应用中，基于几个可控旋转体机制或为可延伸假肢或增长棒提供更高灵活性。另外，这一办法能够用于微流体中，其中，可以想象一种简单微型磁泵以及阀门，无需电力或机械连接，即可单独进行驱动。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;另一类使用情况与用于局部治疗实现的简单微型机器有关，比如遥控一个可注射磁性微型药丸释放药物。遥控可切换放射性种子是一类特殊案例。可切换开关的机器人种子（Switchable seeds）能让资源的使用有更长的半衰期或更高的剂量率，因为达到所需的剂量后，放射性就可以被关闭。除此之外，最终距离健康组织或敏感器官太近的移动种子可以被关闭。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;使用带槽的螺旋盾，定向种子的远程调节方式可以被建立。这可能会让医疗领域中的精确用药和组织维护技术有进一步的提升。另外，我们证明了磁操纵可以达到微米级别的精确性。通过导管，我们可以把种子带入肿瘤和血栓的位置，完成任务后从血管中排出。在成像定位后，只有到达肿瘤位置的种子会被远程激活。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;论文题目：相同的螺旋微机器的空间选择性的远程磁致动（Spatially Selective Remote Magnetic Actuation of Identical Helical Micromachines）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/14872164862UjfHF.jpg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;作者：J. Rahmer、B. Gleich 和 C. Stehning&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;摘要：&lt;/span&gt;&lt;span style="font-size: 14px;"&gt;磁微电机可以在人体内通过外部磁场的进行远程控制，这种特点使得它成为微创局部手术的绝佳选择。在很多治疗方法中，医生都需要依赖复杂的微型机械进行手术，但目前仍然缺少用于控制这些机械的可靠机制。在本研究中，我们提出了基于空间位置的螺旋形微型机械的选择性控制方法，该微型机械是由均匀的旋转磁场操作的，而空间选址是由强场梯度在锁定除位于内侧的所有机器后以取得小活动范围的能力。我们的 3D 选择性驱动的实验证明，以毫米为单位的运动尺度足以应付临床应用。螺旋微型机械的选择性控制可以提高微创治疗水平，并可能带来更灵活的局部药物递送系统或自适应的医疗植入物。随后，作为一个例子，我们提出了基于的肿瘤内分布式放射源选择性切换在癌症上使用自适应放射治疗的概念。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;论文地址：http://robotics.sciencemag.org/content/2/3/eaal2845.full&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;最新一期 Science Robotics 的第二篇论文：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;标题：超越成像：临床磁共振扫描驱动下的巨型和微型医疗机器人（Beyond imaging: Macro- and microscale medical robots actuated by clinical MRI scanners）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/14872164874WlhIH.jpg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;作者：Sylvain Martel&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;摘要：磁共振驱动有望用于医疗。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216487FxWSki.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 12px;"&gt;与 MRI 结合的磁共振驱动技术为微观和宏观的医疗机器人提供了很大潜力&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: left; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;论文地址：http://robotics.sciencemag.org/content/2/3/eaam8119.full&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="min-height: 1em; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; text-align: justify; line-height: 1.75em; background-color: rgb(255, 255, 255); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="line-height: 25.6px; font-family: 微软雅黑; font-size: 14px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; color: rgb(127, 127, 127); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="color: rgb(62, 62, 62); line-height: 25.6px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; color: rgb(127, 127, 127); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;©本文为机器之心编译，&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; color: rgb(62, 62, 62); white-space: normal; font-size: 18px; line-height: 1.75em; background-color: rgb(255, 255, 255); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(127, 127, 127); line-height: 25.6px; font-family: 微软雅黑; text-align: justify; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; color: rgb(62, 62, 62); white-space: normal; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; background-color: rgb(255, 255, 255); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(217, 33, 66); font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; color: rgb(62, 62, 62); white-space: normal; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; background-color: rgb(255, 255, 255); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(217, 33, 66); line-height: 1.6; font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; color: rgb(62, 62, 62); white-space: normal; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; background-color: rgb(255, 255, 255); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-size: 12px; color: rgb(217, 33, 66); line-height: 1.6; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/div&gt;</description>
      <pubDate>Thu, 16 Feb 2017 11:36:15 +0800</pubDate>
    </item>
    <item>
      <title>Nature | 深度学习解码脑扫描图像：预测婴儿自闭症</title>
      <link>http://www.iwgc.cn/link/4724269</link>
      <description>&lt;div class="article-content"&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;section style="white-space: normal; line-height: 28.4444px; background-color: rgb(255, 255, 255); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="border: 0px currentcolor; font-family: 微软雅黑; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; border-style: solid none; font-family: inherit; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="color: rgb(62, 62, 62); font-size: 1em; margin-top: -1.2em; min-height: 1em; border: currentcolor; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(255, 255, 255); line-height: 22.4px; font-size: 1em; font-family: inherit; text-decoration: inherit; background-color: rgb(117, 117, 118); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;选自Nature&lt;/span&gt;&lt;/p&gt;&lt;section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px; font-family: inherit; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color:#7f7f7f"&gt;&lt;span style="font-size: 12px;"&gt;&lt;strong&gt;作者：Ewen Callaway&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="color: rgb(62, 62, 62); font-size: 16px; margin-bottom: 5px; min-height: 1em; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-family: inherit; text-decoration: inherit; color: rgb(127, 127, 127); font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong style="font-family: inherit; text-decoration: inherit; color: rgb(127, 127, 127); font-size: 12px; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color:#7f7f7f"&gt;&lt;span style="font-size: 12px;"&gt;&lt;strong&gt;参与：蒋思源、朱思颖、曹瑞&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style="min-height: 1em; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; text-align: justify; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-size: 14px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/span&gt;&lt;br style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/p&gt;&lt;blockquote style="color: rgb(62, 62, 62); font-size: 16px; white-space: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/blockquote&gt;&lt;blockquote&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 12px;"&gt;二十二年前，研究员们首次报道有自闭症谱系障碍（ASD）的青少年脑容量比同龄人更大。在这之后，对越来越小儿童的研究表明，这一脑容量增加在童年时期就已出现。研究员们没有办法确定幼小的婴儿在日后会不会被诊断出有自闭症，但现在有一个研究表明脑扫描可以帮助诊断这一问题，北卡莱罗纳教堂山分校的研究团队已经在 6 个月大的婴儿大脑中检测出与自闭症直接相关的脑增长变化。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;通过扫描兄弟姐妹中有自闭症的婴儿的大脑，研究员们可以作出合理准确的预测，并判断这些有高风险患自闭症的幼儿哪些日后会发展成自闭症。这一发现将诊断自闭症谱系障碍（ASD）的预测提前到儿童自闭症症状出现数月之前，这是之前很难实现的。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;为什么一直以来在幼儿时期诊断自闭症如此之难？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;儿童通常会显示出 ASD 的症状，例如在 2 岁之后很难有眼神交流。研究员们认为潜藏在 ASD 症状之下的脑部变化在症状出现很久之前已经存在了——甚至很可能在母亲子宫里就已开始。但是行为判定对预测哪些儿童将会有自闭症并没有多大作用，北卡莱罗纳教堂山分校的精神病学家 Joseph Piven 说，他也是这项发表在《自然》研究的联合领导人。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;「那些在 2 岁或 3 岁被确定有自闭症的儿童，在他们 1 岁的时候是看不出来他们有自闭症倾向的，」他说。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;有没有遗传学特征或者生物标记能够帮助预测做出自闭症的诊断？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;某些罕见突变是与 ASD 直接相关的，但是绝大多数的自闭症案例并不能与某一个或者多个遗传风险因子相对应。从 1990 年代开始，Piven 和其他研究员注意到自闭症儿童的脑部往往会比正常发育儿童的大脑更大，这一现象表明大脑的成长发育可能是 ASD 的一个生物标记。但是 Piven 和他在北卡教堂山分校的同事 Heather Cody Hazlett 对大脑何时开始过度增长并不知晓。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;他们最后的研究成果是怎样的？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;自闭症大概在一百个普通儿童中会有一个患病，但是家族成员如果有患病的历史，那么该婴儿将会有 1/5 的机会患上 ASD。作为美国国家卫生研究院所支持的婴儿脑成像研究（IBIS）中的一部分。Piven 和 Hazlett 研究团队使用磁共振成像技术扫描了 6、12、24 月大小的 106 个高患病风险儿童，他们希望弄清楚日常生活中他们的大脑是否会过度增长。他们同样调查了 42 个低风险婴儿。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;他们发现了什么？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;15 个有高风险患病婴儿在 24 个月的时候确诊患有自闭症。MRI 扫描表明，这些婴儿的脑容量增长速度在 12 个月到 24 个月之间比没有诊断出 ASD 的儿童的脑容量增长速度更快，与大脑过度增长同时出现的是这些婴儿的自闭症行为迹象。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;研究员们也发现婴儿在 6 个月和 12 个月之间脑部的变化，也即在 ASD 症状出现之前的脑变化。与日后没有诊断出有自闭症的婴儿相比，诊断出有自闭症的婴儿的大脑的皮质层表面积——用来估测脑外层褶皱的大小——增长更快。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216489woNJb9.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 12px;"&gt;彩色区域表示的是大脑皮层，在之后被诊断出自闭症的婴儿中，他们的这一区域增长非常快。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;这些大脑变化可以被应用到对婴儿自闭症的诊断预测当中吗？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Hazlett 和 Piven 的团队之后利用一个深度学习神经网络，一种机器学习的形式，在一个更大的高危儿群体当中来研究 6 个月和 12 个月的高危儿核磁共振扫描图像是否能够预测婴儿在 2 岁时的自闭症诊断。这一算法在 37 项自闭症诊断中正确预测出了 30 项（81%），在 142 个婴儿当中产生 4 个假阳性的结果，这些婴儿在之后也没有诊断出患自闭症。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Piven 说：「根据目前我们在高家族性风险的婴儿当中得出的这一结果，我们可以预测出 80% 我们认为会患自闭症的人。」他补充说，在那个年龄基于行为的预测结果不会超过 50%。他认为，「这具有重大的临床意义。」&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;这些研究结果该怎样应用到临床上面呢？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;其实有很多其他的研究都表明了对 Pivens 团队和其他专家研究结果是赞同的。首先，研究结果需要通过大量高患病风险婴儿的后续研究进行实验确认： Piven 的研究团队已经申请 NIH（美国国立卫生研究院）资助这项研究。他们同时还在寻求是否有其他的脑成像（brain-imaging）技术能够检测早期大脑的变化。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;国家心理卫生研究所（National Institute of Mental Health）的临床医学家 Armin Raznahan 说：「关键就是要复制这项研究成果到实际临床应用中。」因为即使该项研究是具有鲁棒性的，临床应用也可能会证明其是有很大的局限性。加州大学戴维斯分校（University of California, Davis）自闭症脑成像专家 Cynthia Schumann 表明这些研究成果只适用于高患病风险的婴儿，而并不适用于普通的婴儿。她说该项研究还需要大量的后进调查研究来测试普通婴儿是不是也能预测出患自闭症的风险。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Raznahan 补充说 MRI（磁共振成像）扫描的差异和提取数据方法的不同也可能对在研究中检测出微妙脑结构变化增加了困难。而将此项研究成果投入更广泛的应用还取决于能适用于一般人群的「大脑增长图谱（growth-chart for the brain）」，这将是一个巨大的挑战。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;如果说能够预测婴儿患自闭症，医生们可以对此做些什么呢？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Raznahan 说道，「没有证据表明婴儿患有自闭症的风险会减少。早期诊断的直接应用是为了让他们的家人了解到这一情况。」Piven 补充道，「拥有了早期诊断的可靠工具，将帮助研究者们对一些干预手段进行测试，因为这有助于他们决定哪些治疗方法是有效的，哪些是无效的。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 12px;"&gt;来源：&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;http://www.nature.com/news/brain-scans-spot-early-signs-of-autism-in-high-risk-babies-1.21484&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="min-height: 1em; text-align: justify; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="line-height: 25.6px; font-family: 微软雅黑; font-size: 14px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; color: rgb(127, 127, 127); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="color: rgb(62, 62, 62); line-height: 25.6px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; color: rgb(127, 127, 127); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;©本文为机器之心编译，&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; font-size: 18px; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(127, 127, 127); line-height: 25.6px; font-family: 微软雅黑; text-align: justify; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(217, 33, 66); font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(217, 33, 66); line-height: 1.6; font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-size: 12px; color: rgb(217, 33, 66); line-height: 1.6; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/div&gt;</description>
      <pubDate>Thu, 16 Feb 2017 11:36:15 +0800</pubDate>
    </item>
    <item>
      <title>前沿 | IBM科学家用探针首次「堆积」出新型分子，或用于量子计算</title>
      <link>http://www.iwgc.cn/link/4724270</link>
      <description>&lt;div class="article-content"&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;section style="white-space: normal; line-height: 28.4444px; background-color: rgb(255, 255, 255); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="border: 0px currentcolor; font-family: 微软雅黑; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; border-style: solid none; font-family: inherit; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="color: rgb(62, 62, 62); font-size: 1em; margin-top: -1.2em; min-height: 1em; border: currentcolor; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(255, 255, 255); line-height: 22.4px; font-size: 1em; font-family: inherit; text-decoration: inherit; background-color: rgb(117, 117, 118); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;选自Nature&lt;/span&gt;&lt;/p&gt;&lt;section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px; font-family: inherit; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="color: rgb(62, 62, 62); font-size: 16px; margin-bottom: 5px; min-height: 1em; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-family: inherit; text-decoration: inherit; color: rgb(127, 127, 127); font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong style="font-family: inherit; text-decoration: inherit; color: rgb(127, 127, 127); font-size: 12px; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color:#7f7f7f"&gt;&lt;span style="font-size: 12px;"&gt;&lt;strong&gt;参与：李泽南&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style="min-height: 1em; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; text-align: justify; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;br&gt;&lt;span style="font-size: 14px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 12px;"&gt;这种名为 triangulene 的不稳定分子无法通过正常化学方式合成，所以 IBM 的研究人员们使用显微镜进行了一次「分子手术」。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216491CuTPhf.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 12px;"&gt;基于铜表面上的分子扫描—探针—显微镜图像的 triangulene 3D 模拟&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;IBM 的研究人员通过使用显微镜的针状尖端敲击原子构建了一个难以捉摸的分子。这种平面、三角形的碳原子网格被称为 triangulene，它非常不稳定，目前还无法通过常规的化学方法生产，但或许可以为半导体行业打开一扇新的大门。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;这并不是人们第一次使用原子操作来尝试生成无法大量生产的不稳定分子，但这次的研究结果大有希望。「Triangulene 是第一个用手动堆积的方式制备出的一种化学家们无法制造的分子。」IBM 苏黎世实验室的负责人 Leo Gross 说道。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;「Tringuelene 验证了一种新的化学合成方式，」在诺丁汉大学同样从事分子操作的科学家 Philip Moriarty 说道。「在常规合成方法中，化学家让分子互相反应以构建更大的结构，而 IBM 研究者的方法与之相反，他们使用显微镜对原子进行物理操作。」&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;当然，这种制造分子的方法每次只能完成一个产品，只能应用于特殊情况。而且由于方法所限，它显然不能用于制造复杂结构的分子——因为某些分子中的原子数量太多了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216491nfEA1z.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;不稳定三角&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Triangulene 类似于石墨烯的碎片，后者是一种原子级厚度的超级材料，其中碳原子以六边形网格的形式互相连接。新分子由六个六边形的碳环组成，它们互相连接形成一个三角形，其周围还有氢原子（参考上图「Radical triangle」）。另外，其中两个外部碳原子包含不成对的电子，这意味着它们不能形成稳定的键。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;这种分子是高度不稳定的，因为其中不成对的电子倾向于与它们周围的任何物质发生反应。「每次我们和成了它，它很快就会被氧化掉，」IBM 团队的 Niko Pavliček 表示。目前为止，最接近这种分子的常规合成产物在这种形状的不稳定边缘上附着有大体积烃。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;在研究中，IBM 团队使用了扫描探针显微镜，顾名思义，它使用一个非常尖的针头来「感觉」被观测物的形状。这种显微镜可以通过测量尖端和样品之间的吸引力或在它们之间通过的电流来进行分子成像。IBM 的团队通过实验证明，如果探针尖端连接着一氧化碳分子，力显微技术可以对探测到的东西进行完美的成像——就像你在化学书上看到的球棒模型一样。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;在进一步的探索中，Gross 和他的团队展示了这种显微镜可以被用来控制化学反应的过程，并制造出不稳定的「中间物」分子。为了制造 triangulene，该团队首先制造了前体分子 dihydrotriangulene，它缺少易反应的未成对电子。这种前体曾被英国华威大学的化学家发现。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;研究人员们把 dihydrotriangulene 置于一个平面上——盐、固态氙或铜上都可以——随后在显微镜下观察他们。然后，他们使用探针尖端的两个连续电脉冲小心地在分子上方放电，以激活两个氢原子，产生不成对的电子，这项研究已被发表在Nature Nanotechnology 上。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;随后，该团队使用显微成像技术先拾取一个一氧化碳分子以获得高分辨率。显微镜获得的图像可以显示出 triangulene 具有对称性的形状。在高真空，低温的实验环境下，他们生产的分子可以在被观察到前保持足够长的时间不被氧化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216491g9ytVT.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;span style="font-size: 12px; color: rgb(136, 136, 136);"&gt;IBM 科学家 Leo Gross（左）领导了 triangulene 的研究，图右是团队成员 Niko Pavliček&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;量子应用&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;「据我所知，这是未取代 triangulene 的第一次合成，」大阪市立大学的科学家工位武治（Takeji Takui）说道，他此前曾经合成过 triangulene 类的其他分子。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Moriarty 认为这项研究非常优雅，而且令人惊讶的是人工合成的三角体在铜的表面上保持稳定，他原本认为它会与金属产生反应。「在几次实验中，」Pavliček 说道。「这些分子在研究人员制造完成后的第四天仍然保持完好。」&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;此外，研究人员还探究了 triangulene 的磁性。他们发现正如此前预测的，两个不成对的电子具有排列自旋的性质——这种量子力学性质为电子带来了磁定向。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;IBM 的研究者与工位武治都认为这种特性或许可以让 triangulene 应用于未来的电子产品中。后者更是认为这种新型分子可以在量子计算，量子信息处理和被称作自旋电子学的领域中获得应用，这些量子设备可以操纵电子自旋以编码及处理信息。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;然而，目前一次制造一个分子的速度看起来还不是很有前途，但 Gross 指出目前的量子计算机，如 IBM 的 Quantum Experience 都只能使用数十个量子比特（qubit），其中的每个量子比特对应一个分子。「即使你需要手工制作 100 个这样的分子，」Gross 解释道。「目前看来都是经济上可行的。」&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;同时，即使尚不清楚这种扫描探针技术在不平坦的微观平面上表现如何，研究人员宣称它已经可以一定程度地操纵 3D 结构的分子了。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;「即使仅仅把 triangulene 看做是石墨烯的一部分，这个发现也已为未来的科学研究打开了一扇大门，」Moriarty 说道。「IBM 的研究团队或许会进一步引领这一方向的研究。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 12px;"&gt;来源：&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;http://www.nature.com/news/elusive-triangulene-created-by-moving-atoms-one-at-a-time-1.21462&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="min-height: 1em; text-align: justify; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="line-height: 25.6px; font-family: 微软雅黑; font-size: 14px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; color: rgb(127, 127, 127); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="color: rgb(62, 62, 62); line-height: 25.6px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; color: rgb(127, 127, 127); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;©本文为机器之心编译，&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; font-size: 18px; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(127, 127, 127); line-height: 25.6px; font-family: 微软雅黑; text-align: justify; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(217, 33, 66); font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(217, 33, 66); line-height: 1.6; font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-size: 12px; color: rgb(217, 33, 66); line-height: 1.6; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/div&gt;</description>
      <pubDate>Thu, 16 Feb 2017 11:36:15 +0800</pubDate>
    </item>
    <item>
      <title>专栏 | 顾险峰：看穿机器学习的黑箱（II）</title>
      <link>http://www.iwgc.cn/link/4724271</link>
      <description>&lt;div class="article-content"&gt;&lt;section style="color: rgb(62, 62, 62); font-size: 16px; white-space: normal; line-height: 28.4444px; background-color: rgb(255, 255, 255); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="border-width: 0px; border-style: initial; border-color: currentcolor; font-family: 微软雅黑; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; border-style: solid none; font-family: inherit; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-top: -1.2em; min-height: 1em; font-size: 1em; border-width: initial; border-style: initial; border-color: currentcolor; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(255, 255, 255); background-color: rgb(117, 117, 118); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;转自老顾谈几何&lt;/span&gt;&lt;/p&gt;&lt;section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px; font-family: inherit; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-top: 5px; margin-bottom: 5px; min-height: 1em; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(127, 127, 127); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;公众号ID：conformalgeometry&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-top: 5px; margin-bottom: 5px; min-height: 1em; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(127, 127, 127); font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;作者：顾险峰&amp;nbsp;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style="min-height: 1em; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; background-color: rgb(255, 255, 255); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;br style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/p&gt;&lt;p style="min-height: 1em; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-size: 14px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216493iH62ts.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 12px;"&gt;图1. 基于最优传输映射（Optimal Mass Transportation Map）的保面积映射（area-preserving mapping）。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;span style="font-size: 14px;"&gt;&lt;br style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;今天老顾讲解了&lt;/span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650723168&amp;amp;idx=3&amp;amp;sn=41fcf2fb0408c7b6a9b82d55d91c2b9c&amp;amp;chksm=871b171eb06c9e082c4083ff32748104a617e5cb1e6bd4d296b4db431358b8a41f40908ea8a5&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650723168&amp;amp;idx=3&amp;amp;sn=41fcf2fb0408c7b6a9b82d55d91c2b9c&amp;amp;chksm=871b171eb06c9e082c4083ff32748104a617e5cb1e6bd4d296b4db431358b8a41f40908ea8a5&amp;amp;scene=21#wechat_redirect"&gt;&lt;span style="font-size: 14px;"&gt;Wasserstein GAN模型和最优传输理论的几何解释&lt;/span&gt;&lt;/a&gt;&lt;span style="font-size: 14px;"&gt;，详细给出了W-GAN中关键概念的几何理解，包括概率分布（probability distribution）、最优传输映射（Optimal Mass Transportation Map）、Brenier势能、Wasserstein距离等等。理论上，深度学习领域中常用的概率生成模型（Generataive Model）都可以用最优传输理论来分析，随机变量生成器都可以用最优传输映射来构造。相比于传统神秘莫测的深度神经网络（DNN），最优传输映射是完全透明的，用最优传输理论来探索深度神经网络，可以帮助我们更好的理解深度学习的本质。今天，很多研究生和几位教授听了老顾的讲座，随后和老顾展开了热烈的讨论，并对一些基本问题展开了深入的交流。下面，老顾开始撰写下一次的课程讲义。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;深度学习的方法强劲有力，几乎横扫视觉的所有领域，很多人将其归功于神经网络的万有逼近能力（universal approximation property）：给定一个连续函数或者映射，理论上可以用（一个包含足够多神经元的隐层）多层前馈网络逼近到任意精度。对此，老顾提出另外的观点：有些情况下，神经网络逼近的不是函数或映射，而是概率分布；更为重要的，逼近概率分布比逼近映射要容易得多。更为精密的说法如下：在理想情况下，即逼近误差为零的情形，如果神经网络逼近一个映射，那么解空间只包含一个映射；如果神经网络逼近一个概率分布，那么解空间包含无穷个映射，这些映射的差别构成一个无穷维李群。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;我们这一讲就是要证明这个观点，所用的工具是（包括无穷维）微分几何。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;二十年前，老顾在哈佛学习的时候，Mumford教授、师兄朱松纯就已经系统性地将统计引入视觉，他们提出了用图像空间中的概率分布来表示视觉概念的纲领。今天，一些深度学习的模型（例如GAN）所遵循的原则和他们的纲领是一脉相承的。这也正是老顾更为看好逼近概率分布，而非逼近映射的原因之一。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;section label="Copyright © 2015 Yead All Rights Reserved."&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section label="Copyright © 2015 Yead All Rights Reserved."&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p style="text-align: center;"&gt;&lt;strong&gt;概率生成模型&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;我们先看最简单的（伪）随机数生成器。我们选取适当的整数&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216493XQfaCA.jpg"/&gt;&lt;span style="font-size: 14px;"&gt;，计算序列&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216494phGC42.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;那么&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216494tlKG86.jpg"/&gt;&lt;span style="font-size: 14px;"&gt;给出了随机变量，符合单位区间的均匀分布（uniform distribution）。由均匀分布，我们可以生成任意的概率分布。例如，我们可以构造一个映射&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216494UMb7yx.jpg"/&gt;&lt;span style="font-size: 14px;"&gt;，&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216494VNc8Ay.jpg"/&gt;&lt;span style="font-size: 14px;"&gt;将单位正方形上的均匀分布映射成平面上的高斯分布：&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216494LE3Yqo.jpg"/&gt;&lt;span style="font-size: 14px;"&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216495jbAwYW.jpg"/&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 12px;"&gt;图2. 怪兽的最优传输映射。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;span style="font-size: 14px;"&gt;&lt;br style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;在&lt;/span&gt;&lt;span style="font-size: 14px;"&gt;上一讲&lt;/span&gt;&lt;span style="font-size: 14px;"&gt;中，我们给出了最优传输理论的几何解释。给定一个区域&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216495JC1Wom.jpg"/&gt;&lt;span style="font-size: 14px;"&gt;，其上定义着两个概率测度&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216495TLa6yw.jpg"/&gt;&lt;span style="font-size: 14px;"&gt;和&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216495YRgbDB.jpg"/&gt;&lt;span style="font-size: 14px;"&gt;，则唯一存在一个最优传输映射&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216495rkJE64.jpg"/&gt;&lt;span style="font-size: 14px;"&gt;，将概率分布&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216495TLa6yw.jpg"/&gt;&lt;span style="font-size: 14px;"&gt;映射成概率分布&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216495YRgbDB.jpg"/&gt;&lt;span style="font-size: 14px;"&gt;，亦即对于一切可测集合&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216496NG50sq.jpg"/&gt;&lt;span style="font-size: 14px;"&gt;，&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216496ZShcEC.jpg"/&gt;&lt;span style="font-size: 14px;"&gt;,&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;记为&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216496WPeaBA.jpg"/&gt;&lt;span style="font-size: 14px;"&gt;，并且极小化传输代价&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216496a3snPN.jpg"/&gt;&lt;span style="font-size: 14px;"&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;这个最优传输映射是某个凸函数的梯度映射，这个凸函数被称为是Brenier势能函数，满足蒙日-安培方程。如图2所示，我们将怪兽曲面（第一帧和第四帧）保角地映射到平面圆盘上面（第二帧），保角映射将曲面的面积元映射到平面上，诱导了平面圆盘上的一个概率测度。平面圆盘上也有均匀概率分布（第三帧），从第二帧到第三帧的映射为最优传输映射。图1和图3显示了基于最优传输映射的曲面保面积参数化（Surface Area-preserving Parameterization）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216497unMH97.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 12px;"&gt;图3. 基于最优传输映射（Optimal Mass Transportation Map）的保面积映射（area-preserving mapping）。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;在Wasserstein生成对抗网络中（Generative Adversarial Network）， 生成器（generator）可以被抽象为一个非线性映射&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216497b4toQO.png"/&gt;&lt;span style="font-size: 14px;"&gt;。&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216497ZShcEC.png"/&gt;&lt;span style="font-size: 14px;"&gt;将全空间映到自身，同时将均匀概率分布&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216495TLa6yw.jpg"/&gt;&lt;span style="font-size: 14px;"&gt;映射成概率分布&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216495YRgbDB.jpg"/&gt;&lt;span style="font-size: 14px;"&gt;，&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216497TLa6yw.jpg"/&gt;&lt;span style="font-size: 14px;"&gt;，同时尽量极小化概率分布&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216495YRgbDB.jpg"/&gt;&lt;span style="font-size: 14px;"&gt;和真实数据概率分布之间的Wasserstein距离。那么，我们的问题是：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;满足保持测度条件&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216497TLa6yw.jpg"/&gt;&lt;span style="font-size: 14px;"&gt;的映射&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216497b4toQO.png"/&gt;&lt;span style="font-size: 14px;"&gt;是否唯一？如果不唯一，又有多少？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;对于这个问题的彻底解答需要用到映射极分解理论（Mapping Polar Decomposition）。&lt;br style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;section label="Copyright © 2015 Yead All Rights Reserved."&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section label="Copyright © 2015 Yead All Rights Reserved."&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p style="text-align: center;"&gt;&lt;strong&gt;映射极分解理论&lt;/strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;我们考虑所有的可微双射&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216498unMH97.png"/&gt;&lt;span style="font-size: 14px;"&gt;，满足条件&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216498EwVRih.png"/&gt;&lt;span style="font-size: 14px;"&gt;。存在唯一的最优传输映射，它是Brenier势能函数&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/148721649881qmNM.png"/&gt;&lt;span style="font-size: 14px;"&gt;的梯度映射&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216499UNc7zx.png"/&gt;&lt;span style="font-size: 14px;"&gt;。映射的极分解理论就是说&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216499tmLG86.png"/&gt;&lt;span style="font-size: 14px;"&gt;可以分解成两个映射的复合（composition），&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216499JB0Wnm.png"/&gt;&lt;span style="font-size: 14px;"&gt;,&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;这里映射&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216499h9yuWU.png"/&gt;&lt;span style="font-size: 14px;"&gt;保持初始测度不变，因此&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216499h9yuWU.png"/&gt;&lt;span style="font-size: 14px;"&gt;的雅克比行列式处处为1。所有这种&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216499h9yuWU.png"/&gt;&lt;span style="font-size: 14px;"&gt;在映射复合的意义下构成一个李群（Lie Group），被称为是保体积微分同胚群（Volume-Preserving Diffeomorphisms），记为&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216500MF4Zrp.png"/&gt;&lt;span style="font-size: 14px;"&gt;。我们下面来说明，这个李群是无穷维的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/p&gt;&lt;p&gt;&lt;br style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/14872165005XmiKI.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 12px;"&gt;图4. 曲面上的光滑矢量场。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;如图4所示，我们在曲面上构造一个光滑切向量场&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216500e6vrSR.png"/&gt;&lt;span style="font-size: 14px;"&gt;，则切向量场诱导了曲面到自身的一个单参数微分同胚群&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216500DwVQig.png"/&gt;&lt;span style="font-size: 14px;"&gt;，满足常微分方程：&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216501G5uqRQ.png"/&gt;&lt;span style="font-size: 14px;"&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;直观上，切向量场可以视作曲面上的一个流场，每一点p依随这个流场流动，流动的速度向量等于矢量场在p点处的切向量。在时刻&amp;nbsp;t，流场初始点到终点的映射，就给出了微分同胚&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216501b4toQO.png"/&gt;&lt;span style="font-size: 14px;"&gt;。那么，如果切矢量场的散度（divergence）处处为0，则&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216501b4toQO.png"/&gt;&lt;span style="font-size: 14px;"&gt;的雅克比行列式处处为1，即不可压缩流场诱导保体积微分同胚。这一点，可以用嘉当的神奇公式来证明（Cartan's Magic Formula）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;我们来仔细解释嘉当的神奇公式。我们以平面为例，平面的面元是一个2阶微分形式（2-form）&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216501b4tpQP.png"/&gt;&lt;span style="font-size: 14px;"&gt;。考察任意一个区域&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216501TLa6yw.png"/&gt;&lt;span style="font-size: 14px;"&gt;，在微分同胚&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216501b4toQO.png"/&gt;&lt;span style="font-size: 14px;"&gt;下的像为区域&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216502JC1Won.png"/&gt;&lt;span style="font-size: 14px;"&gt;。像的面积为&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/14872165025XmiKI.png"/&gt;&lt;span style="font-size: 14px;"&gt;,&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;由此，我们定义所谓的拉回2-form&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216502DwVRih.png"/&gt;&lt;span style="font-size: 14px;"&gt;,&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216502kdCyZY.png"/&gt;&lt;span style="font-size: 14px;"&gt;,&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;那么&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216502DwVRih.png"/&gt;&lt;span style="font-size: 14px;"&gt;关于时间t的导数被称为面元&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216503ldCyZY.png"/&gt;&lt;span style="font-size: 14px;"&gt;关于矢量场&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216500e6vrSR.png"/&gt;&lt;span style="font-size: 14px;"&gt;的李导数（Lie Derivative），记为&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/14872165033WlgIG.png"/&gt;&lt;span style="font-size: 14px;"&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;嘉当的神奇公式具有形式：&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216503TLa6yw.png"/&gt;&lt;span style="font-size: 14px;"&gt;，&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;这里d是外微分算子。在平面上，&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216503ldCyZY.png"/&gt;&lt;span style="font-size: 14px;"&gt;为2-形式，因此&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216504OH61tr.png"/&gt;&lt;span style="font-size: 14px;"&gt;恒为0。如果矢量场&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216504NG50sq.png"/&gt;&lt;span style="font-size: 14px;"&gt;散度处处为0，则&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216504FxWSki.png"/&gt;&lt;span style="font-size: 14px;"&gt;恒为0。直接计算得到：&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216505OG51sr.png"/&gt;&lt;span style="font-size: 14px;"&gt;，&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;因此 我们得到&lt;br style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216505OH61tr.png"/&gt;&lt;span style="font-size: 14px;"&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;因此面元&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216503ldCyZY.png"/&gt;&lt;span style="font-size: 14px;"&gt;关于矢量场&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216500e6vrSR.png"/&gt;&lt;span style="font-size: 14px;"&gt;的李导数为零。微分同胚&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216501b4toQO.png"/&gt;&lt;span style="font-size: 14px;"&gt;保持面元不变，&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216501b4toQO.png"/&gt;&lt;span style="font-size: 14px;"&gt;的雅克比行列式处处为1。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;由此可见，曲面上不可压缩流场（散度为0的切矢量场）诱导保面积微分同胚。曲面上任选一个光滑函数，其梯度场旋量处处为0。在曲面上任意一点p处，我们将梯度向量围绕法向量逆时针旋转90度，所得的矢量场散度处处为0。我们知道，曲面上的函数是无穷维的，因此无散场也是无穷维的，保面积微分同胚群也是无穷维的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;我们现在可以回答上面提出的问题，满足保持测度条件&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216497TLa6yw.jpg"/&gt;&lt;span style="font-size: 14px;"&gt;的映射&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216497b4toQO.png"/&gt;&lt;span style="font-size: 14px;"&gt;不唯一；所有这种映射可以表示成保体积微分同胚和最优传输映射的复合；保体积微分同胚是无穷维的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216506VNc8Ay.png"/&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 12px;"&gt;图5. 两个满足保测度条件的映射，彼此相差一个保体积微分同胚&lt;/span&gt;&lt;/em&gt;&lt;em&gt;&lt;span style="font-size: 12px;"&gt;&lt;/span&gt;&lt;/em&gt;&lt;em&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216499h9yuWU.png"/&gt;&lt;span style="font-size: 12px;"&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;从理论上讲，如果我们两次训练GAN网络，其生成器所得到的映射之间相差一个保体积微分同胚&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216507rQfbCB.png"/&gt;&lt;span style="font-size: 14px;"&gt;。保体积微分同胚群内有一个自然的黎曼度量：我们在保体积微分同胚群内构造一条路径，&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216507c5upRP.png"/&gt;&lt;span style="font-size: 14px;"&gt;,&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;连接着两个同胚&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487216507ngFA20.png"/&gt;&lt;span style="font-size: 14px;"&gt;，&lt;/span&gt;&lt;img src="http://wxrss.b0.upaiyun.com/14872165074XmhJH.png"/&gt;&lt;span style="font-size: 14px;"&gt;。这条路径的长度可以计算&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;img data-ratio="0.1540785498489426" data-src="http://mmbiz.qpic.cn/mmbiz_png/JcQsXQ30gemEaNgyd7k1JI5UmqNxgY3jpvKGvaeGGTCbiaGKrxeibqBOYKyBBmsKDZGpMMy6acyN669CKff6segQ/640?wx_fmt=png" data-type="png" data-w="331" style="box-sizing: border-box !important; word-wrap: break-word !important; width: auto !important; visibility: visible !important;" title="This is the rendered form of the equation. You can not edit this directly. Right click will give you the option to save the image, and in most browsers you can drag the image onto your desktop or another program."&gt;&lt;span style="font-size: 14px;"&gt;,&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;两个保体积微分同胚之间的距离定义为连接它们的所有路径长度中最短者。用这个度量，我们可以定量测量两次训练结果的内在差异程度。保体积微分同胚群的度量几何（无穷维微分几何）在视觉领域和医学图像领域被作为形状空间的一种理论工具。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;section label="Copyright © 2015 Yead All Rights Reserved."&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section label="Copyright © 2015 Yead All Rights Reserved."&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p style="text-align: center;"&gt;&lt;strong&gt;小结&lt;/strong&gt;&lt;/p&gt;&lt;br style="max-width: 100%; font-variant-ligatures: normal; orphans: 2; widows: 2; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;通过以上讨论，我们看到如果用一个深度学习的网络来逼近一个映射，解空间只有一个映射；如果来逼近一个概率分布，则解空间为无穷维的保体积微分同胚群。因此，用深度学习网络来逼近一个概率分布要比逼近一个映射、函数容易得多。这或许可以用来解释如下的现象：基于老顾以往的经验，我们用神经网络来求解非线性偏微分方程，要比用神经网络给图像分类困难，因为前者需要精确逼近泛函空间中的可逆映射，而后者需要逼近图像空间中的概率分布。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="min-height: 1em; text-align: justify; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="line-height: 25.6px; font-family: 微软雅黑; font-size: 14px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; color: rgb(127, 127, 127); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="color: rgb(62, 62, 62); line-height: 25.6px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; color: rgb(127, 127, 127); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;©本文为机器之心转载文章，&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; font-size: 18px; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(127, 127, 127); line-height: 25.6px; font-family: 微软雅黑; text-align: justify; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(217, 33, 66); font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(217, 33, 66); line-height: 1.6; font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-size: 12px; color: rgb(217, 33, 66); line-height: 1.6; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/div&gt;</description>
      <pubDate>Thu, 16 Feb 2017 11:36:15 +0800</pubDate>
    </item>
  </channel>
</rss>
