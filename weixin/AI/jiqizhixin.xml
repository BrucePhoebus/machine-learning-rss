<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>百度将高性能计算引入深度学习：可高效实现模型的大规模扩展（附资源）</title>
      <link>http://www.iwgc.cn/link/</link>
      <description>
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自Baidu Research&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀、黄小天、晏奇&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote style="color: rgb(62, 62, 62); font-size: 16px; white-space: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;神经网络在过去几年中规模不断扩大，训练需要大量的数据和计算资源。为了提供所需的计算能力，我们可以使用高性能计算（HPC）中常见的技术将模型扩展到几十个 GPU，但该技术在深度学习中未被充分利用。这项技术，Ring Allreduce，还能减少不同 GPU 之间的通信时间，从而允许将更多时间用在有用计算上。在百度的硅谷人工智能实验室（SVAIL），我们已经成功地使用这些技术训练了当前最先进的语音识别模型。我们很高兴以库和 TensorFlow 软件补丁的形式推出 Ring Allreduce 的实现。我们也希望通过发布这些库可以使深度学习社区更有效地扩展他们的模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;引言&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在过去的几年中，神经网络已被证明是解决各种问题的非常有效的工具，并在规模和计算需求上快速增长。在用两个 GPU 运行一周并调节了 6000 万参数之后，用于图像识别的 SuperVision 卷积网络在物体识别方面取得了巨大成功 [1]。在 2016 年，对一个有超过 10 亿个参数的网络在 32 个 GPU 上训练了 3 周之后，研究人员在语言建模方面取得了突破性进展 [2]。在 SVAIL，2014 年我们的 Deep Speech 语音识别系统的第一次迭代约有 1100 万个参数 [5]，而一年后的下一次迭代已经增长到 1 亿个参数 [3]。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随着参数数量以及神经网络计算需求的不断增长，在多节点、多 GPU 上进行高效并行的神经网络训练已经变得越发重要，因为等待几个月时间训练大型网络会减慢试验进程，限制进一步开发。在这篇博文中，我们提出了一种来自高性能计算（HPC）领域的技术，并演示如何将其应用于深度学习以在神经网络训练中取得显著的表现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;通信问题&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当在多个 GPU 上并行训练一个神经网络，你必须选择如何将不同的运算分布到不同的 GPU 上。本文中，我们将介绍一种被称为数据并行随机梯度下降（data parallel stochastic gradient descent）的技术。在标准随机梯度下降（SGD）中，梯度下降通过使用数据的子集（minibatch）来完成，它们通过进行多次迭代来遍历整个数据集。然而，在数据并行训练中，每个 GPU 都有一个完整的神经网络模型的副本，并且每一次迭代只会被分配 minibatch 样本中的一个子集。对于每次迭代，每个 GPU 在自己处理的数据上将神经网络向前传播，随后再进行误差反向传播（error backpropagation）来计算相对于神经网络参数的损失的梯度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，GPU 通过相互通信来平均不同 GPU 计算的梯度，将平均梯度应用于权重来获取新权重。GPU 在锁步（lock-step）中都进行迭代，并且一旦一个 GPU 完成了自己的迭代，它必须要等待其它所有 GPU 都完成，这样以保证权重可以被适当地更新。这等价于在单块 GPU 上处理 SGD，但是我们通过把数据分配给多个 GPU 来并行运算，从而获得了计算速度的提升。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当你仅仅只有两块 GPU 和数以兆字节（MB）的参数时，这些 GPU 如何通信可能看上去没什么影响。但是，当你的模型有数十亿个参数时，梯度就会占用千兆字（GB）节的空间（因为每个参数都有一个梯度值），并且你还在同时协调几十个 GPU，那么此时 GPU 之间的通信机制就显得非常重要了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;例如，我们考虑一下可能的最直接的通信机制。每个 GPU 都在 minibatch 上的一个子集里计算一个梯度。然后，每个 GPU 都将该子集的梯度发送给同一个 GPU，让这个 GPU 来计算所有梯度的平均值，最后它会将平均值发送回给其它 GPU。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/2e452cd8c1f1703f8ff30c95b0a6f293f53254c6"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;与单个 reducer GPU 之间的数据传输&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果存在越多需要被发送的数据，那么发送的时间就越长；每个通信信道都有一个最大吞吐量（带宽）。例如，一个好的网络连接可以提供 15MB/s 的带宽，一个千兆以太网连接能提供 125MB/s 的带宽。搭载在高性能计算集群（HPC cluster）上的专业网络硬件（比如 InfiniBand）可以在结点之间提供高达数 GB/s 的带宽。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在数据于单个 GPU 上传输的直接机制（straight-forward mechanism）中，这个 GPU 必须接收来自所有其它 GPU 的所有参数，并且它还要将所有参数发回给所有 GPU。于是，系统中存在的 GPU 越多，通信成本就越大。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在，让我们来评估一下这种通信机制在真实模型上的能力，例如，有一个基于百度语音识别系统 Deep Speech 2 开发的语音识别网络 [3]，它有 3 亿个可训练参数，每个参数占 4 字节（Byte），也就是大概 1.2 GB 的数据量。让我们假设你系统上的网络硬件能够支持 1GB/s 的带宽，那也就是说，如此将你的系统在如上所述的两块 GPU 上并行训练，将会让每次迭代都变慢 1.2 秒。如果在 10 个 GPU 上并行训练，将会让每次迭代都变慢 10.8 秒。随着 GPU 数量的增加，处理每次迭代的时间都会线性增长。即便每个迭代会花个几秒钟，这种在通信成本中的快速线性增长也会使接下来的并行处理变得不现实，它大大降低了你训练的效率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一种替代办法就是放弃训练算法的同步性质，去除所有 GPU 在锁步中遍历梯度下降迭代的约束。然而，尽管这可以使得你模型的并行处理更加简便，去除了这些限制的算法（各种异步随机梯度下降）还是会很难调试，因为有些模型会收敛到欠佳的结果上。不过由于这篇博文意不在此，我们就不在这里考虑它了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不过，我们可以通过使用来自高性能计算领域的分布式简约算法（distributed reduction algorithms）并利用带宽优化环衰减（bandwidth-optimal ring allreduce）来解决通信问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Ring Allreduce&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;上述简单通信策略的主要问题是通信成本随系统中的 GPU 数量线性增长。相反，ring allreduce 是这样一种算法&amp;mdash;&amp;mdash;其通信成本是恒定的，与系统中的 GPU 的数量无关，并且仅由系统中的 GPU 之间的最慢连接来确定。事实上，如果在通信成本上你只考虑带宽这一因素（并忽略延迟），那么 ring allreduce 就是一个最佳的通信算法 [4]（当你的模型较大时，这是一个很好的通信成本估算，你需要在较少的次数内发送大量数据）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Ring Allreduce 中的 GPU 被布置在一个逻辑环路（logical ring）之中。每个 GPU 左右两个各有一个 GPU，并且只从左边的 GPU 接收数据，再把数据发送至右边的 GPU。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/8a9a5dce66dd7ea1dd970e73d342e17faee29947"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;被布置在逻辑环中的 GPU&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;算法的进行分两步：第一步，scatter-reduce；第二步，allgather。在第一步中，GPU 将交换数据，使得每个 GPU 最终都有一个最终结果的数据块。在第二步中，GPU 将交换那些块，使得所有 GPU 最终得到完整的最后结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Scatter-Reduce&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了简单起见，让我们假设目标是以元素方式求和浮点数的单个大数组的所有元素。在系统中有 N 个 GPU, 其中每个 GPU 有一个相同大小的数组。在 allreduce 的最后，每个 GPU 都应该有一个同样大小的包含了原数组中数值的和的数组。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一开始，GPU 把数组分割成 N 个较小的块（其中 N 是 GPU 在环中的数量）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/03e939dc2417a94c2e34f71b807b8d82552dbefc"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;接着，GPU 会执行 N-1 次迭代 scatter-reduce。在每一次迭代中，GPU 将发送其中一个块到右边的 GPU，并从左边的 GPU 接收一个块，把数据累积进该块。在每一次迭代中，被发送的块和被接收的块是不同的。第 n 个 GPU 以发送块 n 和接收块 n &amp;ndash; 1 开始，并从那儿接着向后运行。每次迭代发送的块即是上次迭代所接收的块。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;例如，在第一次迭代中，上图表中的 5 个 GPU 将会发送和接收以下的块：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GPU 发送 接收&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;0 Chunk 0 Chunk 4&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;1 Chunk 1 Chunk 0&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;2 Chunk 2 Chunk 1&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;3 Chunk 3 Chunk 2&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;4 Chunk 4 Chunk 3&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/298b2ddcdd9db2d061c6e93fd30daaee09f61540"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;在 scatter-reduce 的第一次迭代中的数据传输&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在第一次的发送和接收完成之后，每个 GPU 会有一个由两个不同 GPU 中的相同块的总和组成的块。例如，第二个 GPU 上的第一块将是来自第二个 GPU 和第一个 GPU 的那个块中的值的和。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/e0baa9c3f46ce9e6ca0157882a84d46b9bb330a8"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;scatter-reduce 的第一次迭代完成之后的中间和&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在下一次迭代中，进程继续，直到最后，每个 GPU 会有一个块包含所有 GPU 中的那块的所有值的和。下面的图像演示了所有的数据传输和中间结果，从第一次迭代开始，一直持续到 scatter-reduce 结束。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/298b2ddcdd9db2d061c6e93fd30daaee09f61540"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;scatter-reduce 数据传输（迭代 1）&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/5bf339f42ee7eb9bd7cb64b8025159a2599e61e7"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;scatter-reduce 数据传输（迭代 2）&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/e9ca1c34c3073bf201acd3eace03e168c7bf43be"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;scatter-reduce 数据传输（迭代 3）&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/6749cb889fbf498b6ae0b93800bc67c411c92d69"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;scatter-reduce 数据传输（迭代 4）&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/10445f6091c0b46aad4a80d3ce80a5a3a135f079"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;所有 scatter-reduce 传输结束之后的最后状态&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Allgather&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;scatter-reduce 这一步完成之后，每个 GPU 有一个值的数组，其中这些值（每个 GPU 一个块）中的一些是包含来自所有 GPU 贡献的最后值。为了完成 allreduce，GPU 必须交换这些块，从而所有的 GPU 获得所有的必需值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该环路的 allgather 的执行等同于 scatter-reduce（通过 N-1 次发送和接收的迭代），除了不是累加 GPU 接收的值，而是简单地重写块。第 n 个 GPU 通过发送第 n+1 个块和接收第 n 个块开始，并在未来的迭代中一直发送它刚接收的块。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;例如，在我们的 5 个 GPU 设置中的第一次迭代，GPU 会发送和接收以下的块:&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GPU 发送 接收&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;0 Chunk 1 Chunk 0&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;1 Chunk 2 Chunk 1&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;2 Chunk 3 Chunk 2&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;3 Chunk 4 Chunk 3&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;4 Chunk 0 Chunk 4&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/79e4e099a0881d4cebf0ebacc8c3be9f5b590779"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;allgather 的第一次迭代中的数据传输&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在首次迭代完成之后，每个 GPU 将有最终数组（final array) 的两个块。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在接下来的迭代中，该进程会继续运行，一直到最后每个 GPU 都会有整个数组的全部累计值。下面的图像演示了从第一次迭代到 allgather 完成的所有数据传输和中间结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/79e4e099a0881d4cebf0ebacc8c3be9f5b590779"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Allgather 数据传输（第 1 次迭代）&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/339944a59d36b68552fc323fa725a963f83639a6"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Allgather 数据传输（第 2 次迭代）&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/17f43e3b5060b7b6eab15ff1fa5e7ac5cc083a83"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Allgather 数据传输（第 3 次迭代）&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/836afc42d7f093cee4340503603b100396a61ac3"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Allgather 数据传输（第 4 次迭代）&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/d1667b21797b17d1d3718656cbc4835380fe3b1a"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;所有 allgather 完成后的最终状态&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Allreduce 通信成本&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;回到引言中描述的简单的通信算法，通信成本（communication cost）会随 GPU 的数量而线性增长。allreduce 效果良好的主要原因是情况已经发生了变化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在我们描述的系统中，每 N 个 GPU 都会因为 scatter-reduce 而接收 N-1 次值，还为 allgather 接收 N-1 次值。每一次，GPU 都会发送 K/N 个值，其中 K 是指数组中值的总数量，这是在不同 GPU 上相加得到的。因此，每个 GPU 的传入和传出数据总量为：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;被传输的数据=2(N&amp;minus;1)N&amp;sdot;K&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其独立于 GPU 的数量，这是很关键的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因为在离散的迭代中，所有的传输都是同时发生的，所以 allreduce 的速度受限于该环路中相邻 GPU 之间的最慢（最低带宽）的连接。为每个 GPU 选择合适的邻居，该算法能在所有 allreduce 上做到带宽最优并且可能是最快的算法（假设相比于带宽，其延迟成本可以忽略不计）[4]。总的来说，如果在一个节点上的所有 GPU 都临近该环路中的其它 GPU，那么该算法可以得到最好的效果；这能最小化网络连接的数量，从而显著增加这种 GPU-GPU 连接的有效带宽。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;将该 Allreduce 应用于深度学习&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;ring allreduce 是高性能计算领域内一个众所周知的算法，但在深度学习领域内的应用相对较少。在我们的实验室中，我们已经成功地将这种工具用作我们所有的数据并行训练的基础，让我们可以将训练有效地扩展到十余个 GPU。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了最小化通信负载，我们可以利用神经网络的结构。在每一次迭代中，每一个 GPU 都会运行前向传播来计算错误，然后再运行反向传播来为该神经网络的每一个参数计算梯度。反向传播是从输出层开始计算梯度，然后向输入层移动，这意味着输出层参数的梯度在更早的层的梯度之前是显著可用的。因为该 allreduce 能一次操作该网络的参数的一个子集，所以我们可以在其输出层参数上开始 allreduce，同时还能计算其它梯度。这样做使得该计算可以和反向传播步骤中的其它计算一起进行，所以可以减少每个 GPU 用于等待通信完成的总时间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;比如，假设有一个类似于 [2] 中的语言模型，但带有大约 3 亿个可学习的参数（因此总梯度大小为 1.2 GB）。使用 allreduce，每个 GPU 必须发送和接收大约 2.4 GB 的数据。使用一种 CUDA-aware MPI 实现（比如 OpenMPI），我们可以使用 GPUDirect RDMA 在 GPU 之间传输数据，带宽大约为 10 GB/s；但是，在我们的集群中的节点之间的连接更慢&amp;mdash;&amp;mdash;Infiniband 提供了大约 6 GB/s 的带宽。因为 Infiniband 连接是这里的限制因素，那么单次迭代就需要大约&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;每秒 2.4 GB/6.0 GB &amp;asymp; 每次迭代 400 ms&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因为更深入到网络中的层一开始就有可用的梯度，所以我们可以在整个反向传播通过完成之前就开始进行数据传输，所以其真正的开销可能会少于 400 ms；通信和计算之间的这种重叠可能会随被优化的神经网络的本质而发生改变。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们实现了之前提到的语言模型，并且在我们从单个 GPU（没有通信开销）扩展到 40 个 GPU 时测试了每次迭代所用的时间。这 40 个 GPU 被布置成了 5 个节点，每个节点 8 个 GPU，它们之间通过 Infiniband 连接。我们以 32 的批大小对该语言模型运行了 300 迭代，然后计算了其每秒所处理的样本的数量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/8a8cc4abeb192761ca7b5b9da99aa49ecb2def20"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;对于一个有 3 亿个参数的语言模型，每秒所处理的样本的数量会随同时进行同步训练的 GPU 的数量而线性增长。&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如你所见，整个系统的吞吐量会随 GPU 的数量线性扩展；但超过一个特定的点之后，增加更多 GPU 并不会导致每次迭代的显著减速。在 40 个 GPU 上运行该模型的时间是每次迭代 650-700 ms，而在单个 GPU 上该数字为大约 370 ms。因为据我们估计通信大约需要 400 ms，所以我们通过将反向传播和数据传输重叠起来进行而为每次迭代节省了 70-120 ms 的时间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;总结&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;来自于高性能计算领域的 Ring Allreduce 技术让我们可以高效地在跨多设备和多节点的神经网络上对梯度进行平均。通过在训练过程中使用这种带宽优化算法，你可以极大地减少通信负载并扩展到远远更多的设备，同时仍能保留同步随机梯度下降的确定性和可预测的收敛性。该算法并不特定于任何网络架构和深度学习框架，能够为数据并行训练的效率提供显著的和直接的好处，同时其部署实现也是相当直接和容易的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了让你能更轻松地使用这些技术，今天我们也发布了一个演示该 allreduce 算法的 C 语言库：，你可以将其嵌入到任何使用 MPI 的应用中。此外，我们也已经将该 allreduce 整合到 TensorFlow 中（可在 tensorflow.contrib.mpi 模块获取文档）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;C 语言 baidu-allreduce：https://github.com/baidu-research/baidu-allreduce&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;TensorFlow-allreduce：https://github.com/baidu-research/tensorflow-allreduce&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们希望其它深度学习框架也能在合适的地方使用类似的技术；通过使用这些工具，你可以轻松有效地将你的神经网络模型扩展到许多机器，而且不论你选择的是什么框架。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;参考文献&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;1.Krizhevsky, Alex, Ilya Sutskever, and Geoffrey E. Hinton.「ImageNet classification with deep convolutional neural networks.」Advances in neural information processing systems. 2012.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;2.Jozefowicz, Rafal, et al.「Exploring the limits of language modeling.」arXiv preprint arXiv:1602.02410 (2016).&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;3.Amodei, Dario, et al.「Deep speech 2: End-to-end speech recognition in english and mandarin.」arXiv preprint arXiv:1512.02595 (2015).&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;4.Patarasuk, Pitch, and Xin Yuan.「Bandwidth optimal all-reduce algorithms for clusters of workstations.」Journal of Parallel and Distributed Computing 69.2 (2009): 117-124.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;5.Hannun, Awni, et al.「Deep speech: Scaling up end-to-end speech recognition.」arXiv preprint arXiv:1412.5567 (2014).&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;February 21st, 2017&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文链接：&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;a style="font-size: 12px; color: rgb(136, 136, 136); text-decoration: none;"&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;http://research.baidu.com/bringing-hpc-techniques-deep-learning/&lt;/span&gt;&lt;/em&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Wed, 22 Feb 2017 12:55:17 +0800</pubDate>
    </item>
    <item>
      <title>Science | 量子计算机的首次性能测评，IBM成绩落后</title>
      <link>http://www.iwgc.cn/link/</link>
      <description>
&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自Science&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;strong&gt;作者：Gabriel Popkin&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李泽南、蒋思源&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote style="color: rgb(62, 62, 62); font-size: 16px; white-space: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/blockquote&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;在一项新研究中，两种使用完全不同技术的量子计算机在同一个算法任务中进行了对决。结果显示，其中一种更加可靠，而另一种运算速度更快。但科学家们认为，这项研究最重要的意义在于：第一次有人在完全相同的任务场景中对不同种类的量子计算机进行了比较。读者可点击阅读原文下载此论文。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「量子计算机技术一直没有发展成熟。长久以来，我们一直不能真正地把两个只含有五个量子比特的原型机拿来进行性能对比，」牛津大学的物理学家 Simon Benjamin 说道。「最近这一研究的出现证明了量子计算技术又前进了一步。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这项研究中，其中一台计算机来自马里兰大学的 Chris Monroe 团队（ionQ），该机器使用五个镱离子，以电磁阱和激光进行操纵。另一台计算机来自于 IBM，它的核心是五个超导金属环路，通过微波信号操控。IBM 的计算机也是目前世界上唯一一种可以由普通用户进行在线编程的量子计算机。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这两种计算机都不具备堪比普通架构计算机的运算性能，但它们都证明了量子计算的思路具有可行性。量子计算机的基本位&amp;mdash;&amp;mdash;量子比特的表示不像普通计算机只有 0 或 1，它多出了一种「叠加态」，可以同时是 0 和 1。在 Monroe 的量子计算机里，每个量子比特都由一个离子代表，其中电子的能级可以用来表示 0、1 或「叠加态」三种状态。而在 IBM 的超导环路中，电流可以以两种不同的强度循环，或同时在两种强度上循环&amp;mdash;&amp;mdash;这也构成了量子计算的三种状态。在目前的基础上，量子计算机可以叠加更多的量子比特，由于原理上的先进性，量子计算机具有超越普通架构的潜力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但量子位的状态是脆弱的，来自外界的扰动可以轻易地让叠加态坍缩回 0 或 1。因此在运行时，量子计算机必须能够小心地保证叠加态能够存在一段时间。在研究人员的测试中，这两台量子计算机都具有大约 97% 的双量子比特「门精度」&amp;mdash;&amp;mdash;成功计算双量子比特逻辑运算的概率，这意味着它们仍然难以用于执行现实世界的任务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/40756199c8246b168ce0415fd4c3c2519d09e7e2"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;（a）：IBM 的超导环路系统；（b）：马里兰大学的镱离子系统。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了测试设备的性能，Monroe 研究团队在每个设备上运行一组标准化算法，并对比其输出结果。离子计算机（The ion computer）在每一个测试中都能得到更正确的答案。而对于特定训练，对比非常具有戏剧性：离子计算机能达到 77.1% 的成功率，而超导计算机（the superconducting computer）的成功率仅仅只有 35.1%。科学家上一周在 arXiv 上发表了对比结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Monroe 认为，这种性能差异并不是从量子比特本身而引发的，这些差异是从连接量子比特的方法而来。在 Monroe 的架构中，每一个离子都能和其他任何一个离子产生交互，所以很多任务所需要的操作次数大大降低了，且叠加态（superposition）崩溃的机会也会相应降低。相比之下，IBM 计算机每四个超导回路连接一个中枢，所以超导计算机需要额外的操作在回路之间交换信息。因为没有任何操作是 100% 可靠的，所以整体的成功率就随着操作次数的增加而降低。「连通性是关键，」Monroe 说道。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;物理学家 Jerry Chow 领导着 IBM 的量子计算研究团队，他们的实验室位于纽约公司的 Yorktown Heights。他认同 Monroe 对于连接性的看法。但是他认为 IBM 计算机的量子比特叠加态会持续更长时间且更加「连贯」，这也就意味着从长远角度来看，计算机较低的连接性不一定会拖累它的整体的可靠性。他指出「如果有足够的连贯性，那么算法全部操作的时间就变得不那么重要了。」他还指出 IBM 的在线计算机现在比 Monroe 团队测试时拥有更多的量子比特连接，这将使得超导计算机的性能很可能至少是接近于离子计算机的。目前，上述两个实验室正在开发更可靠、拥有更多量子比特的下一代设备。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Benjamin 认为，该研究对比了两种通向量子计算这一「超前」方法的「原始形式」。由超导环路或离子构成的实用型量子计算机需要成千上万的量子位，并且这些量子位之间的互联网络会变得更加复杂。他认为，即使离子计算机目前拥有更高的可靠性，超导计算机理论上还是运行地更快。IBM 量子计算机在 250 到 450 纳秒内就能完成一个双量子比特的操作，这比离子计算机快了 1000 倍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该研究同样为量子软件开发者（如微软研究员 Krysta Svore）提供了新思路。理解量子计算机的特定架构如何影响未来优化算法的性能是很重要的，这将是开启实用量子计算的第一步。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;论文：Experimental Comparison of Two Quantum Computing Architectures&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/f26955de619093e7e2c735fe77c95d942c0030da"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：&lt;/span&gt;&lt;span&gt;我们在两个目前最先进，但架构不同的 5 量子比特的计算机上运行了一系列算法。一种是具有有限连接性的超导转导装置&amp;mdash;&amp;mdash;它可以被公众接触（IBM），另一种是完全连接的离子阱系统（ionQ）。即使两种系统的量子交互方式不同，但它们仍可以在对底层硬件不知情的情况下进行编程，这允许了我们对不同的物理系统进行相同的量子算法硬件性能对比。我们的实验表明，更具连通性的量子比特系统显然能使算法运算速度更快。虽然目前的量子系统还不够强大，无法匹敌常规架构的计算机，但本实验揭示了量子计算机未来发展需要解决的重要问题，如量子比特连通性与门表达性。此外，我们的实验结果也显示，为特定的硬件架构设计专有优化的量子应用是未来量子计算机成功的最重要因素。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文链接：http://www.sciencemag.org/news/2017/02/split-decision-first-ever-quantum-computer-faceoff&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Wed, 22 Feb 2017 12:55:17 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 谷歌结合机器学习技术「摘掉」VR 头盔，让共享体验更真实</title>
      <link>http://www.iwgc.cn/link/</link>
      <description>
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自Google blog&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;strong&gt;作者：Vivek Kwatra、Christian Frueh、Avneesh Sud&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：微胖、曹瑞&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;iframe allowfullscreen="" class="video_iframe" data-vidtype="1" frameborder="0" height="417" src="https://v.qq.com/iframe/preview.html?vid=g0377jl9k9u&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0" width="556"&gt;&lt;/iframe&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虚拟现实能带来很赞的沉浸式体验，提供全新看待世界的方式，还能帮助我们探索新奇的环境，无论它是现实的抑或想象的。不过，与物理现实相比，与他人共享这些体验却很难，因为虚拟现实头盔很难让用户看清共享对方的完整面部。&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;混合现实（Mixed Reality）可以减轻一些不连贯，因为它可以在一个二维视频格式中实现 VR 用户虚拟文本的共享，其他用户可以感受到该用户的虚拟体验。即使混合现实能让共享变得容易，但是，头盔仍然盖住了面部表情和目光注视，这严重妨碍了完整的沉浸体验，也没办法在虚拟现实中看到整个人。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌 Machine Perception 研究人员与 Daydream Labs 以及 Youtube Spaces 合作，看看怎么解决这个问题，能否通过虚拟地「揭开」头盔，看到用户的脸，进而创造出一种现实般的看穿效果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/7680bfa8b9b7d0d6e50c66dac3e91099680bb36d"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;一个绿色屏幕前的虚拟现实用户与虚拟背景融合起来，生成一种混合现实：传统的混合现实输出会挡到用户面部，但是我们的输入会让你看到脸。注意，如何用标记修改头盔，方便追踪。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们的办法结合了 3D 视觉、机器学习以及图形技术，最好在增强 MR 视频中加以说明（我们在 Google-VR blog 中也讨论过）。有三个部分：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;动态面部模型捕捉&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们技术的核心思想是，将一个用户面部的 3D 模型作为被隐藏面部的代理。这个代理被用来合成 MR 视频中的面部，因此，可以创造摘掉头盔后的效果。首先，我们使用所谓的注视依赖动态外观（gaze-dependent daynamic appearance）技术，捕捉到一个用户的个性化 3D 面部模型。初次校准需要用户做在一个色彩+深度摄像头（a color+depth camera）和一个监视器前面，然后，眼睛追踪监视器上的标记。我们使用这种一次校准程序（one-time calibration procedure）&amp;mdash;&amp;mdash;通常耗时不到一分钟&amp;mdash;&amp;mdash;来获取用户的 3D 面部模型，还要学习一套将外观图像（或文理质地）映射到不同注视方向和眨眼状态上的数据集。这个目光注视数据集（gaze database）能让我们在合成任何想要的注视状态时，显著改善面部外观，让合成表情更加自然生动。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/ad250d9384210ae1d44227b6cb57156333ac334b"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;左边，当她用眼睛跟踪显示器上的标记时，摄像头捕捉到了用户面部。右边，我们展示了重新建构 3D 面部模型的动态性质：移动或点击鼠标，我们就能模拟注视和眨眼状态。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;校准和对齐&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;创造混合现实视频需要一个专门的装备，包括一个外部摄像头，可校准并与头盔同步。这个摄像头用来捕捉绿色屏幕前虚拟现实用户的视频流，然后将用户剪影与虚拟世界混合起来，生成最终的混合虚拟现实视频。其中，很重要的一个环节就是准确估计测摄像头和头盔的对齐系统之间的校准（固定的 3D 转换，fixed 3D transformation）。这些校准技术通常包括显著的人工干扰，完成需要多个步骤。通过给头盔前端加上一个物理标记并在 3D 中进行虚拟跟踪，我们可以简化整个过程，因为这可以实现自动优化校准参数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因为「摘掉」了头盔，所以，我们需要将 3D 面部模型和摄像头流中的面部可见部分对齐，实现无缝对接。这一对齐的合理代理就是将面部模型放到头盔后面。上面描述的校准，连同虚拟现实头盔跟踪，能提供充足的信息来决定如何放置，这样，我们就能通过提供虚拟面部，修改摄像头流（camera stream）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;合成和渲染&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在处理完对齐之后，最后一步涉及到生成 3D 脸部模型适当渲染，要与摄像头流中的内容保持一致。通过将我们的动态注视数据库和 HTC Vive 头戴式设备结合，重现用户真正的眼睛注视（eye gaze），HTC Vive 的眼球追踪技术是由 SMI 公司提供。眼球追踪器产生的图像缺乏充分细节来直接再生被挡面部区域，但是，非常适合提供细致的注视信息。使用追踪器实时注视数据，我们合成了一个能够精确代表用户注意力和眨眼的面部代理。在运行过程中，会搜索预处理步骤时捕捉到的注视数据库，找寻最符合查询注视状态的面部图像，同时也兼顾了美学，例如时空光滑度（temporal smoothness）。另外，为了解决已获取的注视数据组与运行过程时面部之间的亮度变化不同，我们使用了色彩校正和羽化，让合成面部区域与其他面部区域匹配。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人们对面部的失真成分高度敏感，即使是被遮挡面部上非常小的瑕疵，也会让人感觉不自然，分散人的注意力。这种现象就是恐怖谷（Uncanny Valley）理论。为了减轻这一问题，我们不会完全移除头戴式设备，我们已经选择了一种用户体验，通过合成色彩校正过的面部代理与透明头盔，这种体验类似「潜水镜效应」。提醒体验者头盔的在场有助于人们避免恐怖谷体验，也能让我们的算法稳健，不受对齐和色彩校正中一些小误差的干扰。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种修正后的摄像头流，源自潜水镜般透明头盔，由于用户面部可见，还再造了真实的注视状态，因此，接下来可以与虚拟环境融合起来，生成最终的虚拟现实影像。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;结果和扩展&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们已经使用头戴设备去除技术来增强混合现实，这让媒介不仅将 VR 用户的互动传递给虚拟的环境，还能够以一种自然有力的方式展示他们的面部。下面的例子就展示了一位艺术家对我们这项科技的应用，她使用谷歌 Tilt Brush 在虚拟环境中进行创作：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/2ca7058c36dd8e184bbb48fd9d15531a5a763b35"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;一位艺术家运用谷歌的 Tilt Brush 在 3D 环境中进行创作，在混合现实中展示。上面是传统的混合现实结果，图中的人脸被隐藏在头戴式设备之后。下方的是我们的结果，在这张图中，整个脸部和眼睛都可以看到，这种体验更加的自然有趣。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们已经展示了该技术的潜力，它的应用已经延伸到了混合现实之外。头戴式设备去除技术将会增强虚拟现实本身的交流和社会互动，会产生很多多样的应用，例如虚拟现实视频会议、多人虚拟现实游戏、和朋友家人一起探索等。在照相写实主义（Photographic Realism）的鼓舞下，从完全空白的头戴式设备，到可以看见 VR 用户的面部是虚拟现实世界中一个重大的转折，我们非常高兴成为这一转折中的一部分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;原文链接：&lt;/span&gt;&lt;/em&gt;&lt;em&gt;&lt;span&gt;https://research.googleblog.com/2017/02/headset-removal-for-virtual-and-mixed.html&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Wed, 22 Feb 2017 12:55:17 +0800</pubDate>
    </item>
    <item>
      <title>学界 | 不同硬件不同网络，横向对比五大深度学习框架（附论文第七版）</title>
      <link>http://www.iwgc.cn/link/</link>
      <description>
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自arXiv.org&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote style="color: rgb(62, 62, 62); font-size: 16px; white-space: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/blockquote&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;2016 年 8 月，香港浸会大学褚晓文团队的研究者发表了一篇论文，对业界主流深度学习工具进行了基准评测 ，之前机器之心也报道了&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722774&amp;amp;idx=4&amp;amp;sn=e38ed07e2a47b60c37d4679d66710410&amp;amp;chksm=871b15a8b06c9cbee0d1daa51d3e4a003a3a8d363da3b8a935c59fab87acb36d0812ae63bf25&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722774&amp;amp;idx=4&amp;amp;sn=e38ed07e2a47b60c37d4679d66710410&amp;amp;chksm=871b15a8b06c9cbee0d1daa51d3e4a003a3a8d363da3b8a935c59fab87acb36d0812ae63bf25&amp;amp;scene=21#wechat_redirect" target="_blank"&gt;该论文的第六版更新&lt;/a&gt;（把 MXNet 加入了评估对象内）。近日，该论文又放出了第七版更新，此次更新修正了 MXNet 中的 ResNet-50 配置；增加了在 TensorFlow 中多 GPU 更快速的实现 ResNet-56。读者可点击阅读原文下载此论文。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;摘要&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深度学习已被证明是一种可成功用于许多任务的机器学习方法，而且它的广泛流行也将很多开源的深度学习软件工具开放给了公众。训练一个深度网络往往是一个非常耗时的过程。为了解决深度学习中巨大的计算难题，许多工具利用了多核 CPU 和超多核 GPU 这样的硬件特性来缩短训练时间。但是，在不同的硬件平台上训练不同类型的深度网络时，不同的工具会有不同的特性和运行性能，这让终端用户难以选择出合适的软件和硬件搭配。在这篇论文中，我们的目标是对当前最先进的 GPU 加速的深度学习软件工具（包括：Caffe、CNTK、MXNet、TensorFlow 和 Torch）进行比较研究。我们在两种 CPU 平台和三种 GPU 平台上使用三种流行的神经网络来评测了这些工具的运行性能。我们做出了两方面的贡献。第一，对于深度学习终端用户，我们的基准评测结果可用于指导合适的软件工具和硬件平台的选择。第二，对于深度学习软件开发者，我们的深度分析为进一步优化训练的性能指出了可能的方向。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;实验数据展示地址：http://dlbench.comp.hkbu.edu.hk/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;项目开源地址：https://github.com/hclhkbu/dlbench&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1 评测软件版本&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/d814e6f4c87d331f6f857d33ab2039c2c40362bd"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2 评测中的神经网络设置&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/a537270b8b0cc3e3c8c2fad96a57aac698e9777c"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;全连接网络&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;卷积神经网络: AlexNet、ResNet&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;循环神经网络&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3 评测硬件配置&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/64be6e7f449b9943ac4a4e858159a956c59ba786"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;评测硬件配置&amp;mdash;&amp;mdash;并行数据&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/909426890de87d7610cc19141202ebb68d861d93"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4 实验概览及结果&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下表给出了不同的网络、框架和硬件组合下进行的实验：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/7686fc18191e98abfab909791f6ae2d09474c73d"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;实验结果概览&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下表给出了实验结果比较数据，更清晰的结果可在上文给出的地址查看。这里给出的数据是实验的速度比较，比较了每个 mini-batch 处理所需的时间（单位：秒）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/4ddec7f84bb17492e2f64ceb53a493bdbc3cfed9"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下表给出了在单个 GPU 和多个 GPU 上的实验比较数据，比较了每个 mini-batch 处理所需的时间（单位：秒）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/a6be5dd27b436a25d7da3a94a52d6572d345e3d4"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4.1. CPU 评测结果&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;根据我们之前的研究 [31]，在 CPU 平台上测试特定的 mini-batch 大小 d 的实验能够获得最好的运行时间表现。不同网络使用的 mini-batch 的大小在表 9 中有展示：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/329126776356b1d31a46f6f1c9d0df01955d9d19"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/f444cc25358d7e18baa40c3c31a6a42c8ffd0645"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 2：FCN-S 在 mini-batch 大小为 64 时在 CPU 平台上的表现的比较（越低越好）&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/ee0d6e24be16a3944f75f218d941234ee78c092a"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 3：AlexNet-S 在 mini-batch 大小为 16 时在 CPU 平台上的表现的比较（越低越好）&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/55d86bd8d9617fabb296c50f2dfacc6c62372d4e"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 4：ResNet-50 在 mini-batch 大小为 16 时在 CPU 平台上的表现的比较（越低越好）&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/a3ae1acccb29301b2f3dac76407b644c405a508c"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 5：FCN-R 在 mini-batch 大小为 1024 时在 CPU 平台上的表现的比较（越低越好）&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/f4b9e97c91180c61390f00168365cf6a42cdd1e6"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 6：AlexNet-R 在 mini-batch 大小为 1024 时在 CPU 平台上的表现的比较（越低越好）&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/7c4af7235ae17d724bed1c987ad8d23edb02ef39"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 7：ResNet-R 在 mini-batch 大小为 128 时在 CPU 平台上的表现的比较（越低越好）&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/0c7e104c62560cd5f406e4a4aa9f0ea06b8f4b40"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 8：LSTM 在 mini-batch 大小为 256 时在 CPU 平台上的表现的比较（越低越好）&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4.2. 单 GPU 卡评测结果&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在单 GPU 卡的对比上，我们也展示了不同 mini-batch 大小的结果，从而演示 mini-batch 大小对表现的影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4.2.1. 合成数据（Synthetic Data）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/c0103a16797b848f2444a0d5604b42b5aa1d1351"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 9：在不同 GPU 平台运行 FCN-S 时，不同框架的表现对比&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/6f6ed9592396c0e164058293ba8153e72a0a930e"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 10 ：在不同 GPU 平台运行 AlexNet-S 时，不同框架的表现对比&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/b80e5056a50de172a2b12dc486d3e7f67af7c61e"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 11：在不同 GPU 平台运行 ResNet-50 时，不同框架的表现对比&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4.2.2. 真实数据（Real Data）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/ab65c678d9616527d75126e2216613db45a9ad50"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 12:在不同 GPU 平台运行 FCN-R 时，不同框架的表现对比&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/7f82142aafa51eeab743c86e76c6a89448ebb1f9"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 13：在不同 GPU 平台运行 AlexNet-R 时，不同框架的表现对比&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/4c44828d8d86833daddfbc523e5f8bc9c2d50111"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 14：在不同 GPU 平台运行 ResNet-56 时，不同框架的表现对比&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/1967fe434598c029324080914fe386edd35bd485"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 15：在不同 GPU 平台运行 LSTM 时，不同框架的表现对比&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4.3. 多 GPU 卡评测结果&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;FCN-R：在我们的测试中，mini-batch 的大小设置为 4096，结果如图 16 所示。在图 16(a) 中，我们可以看到 Caffe、CNTK 和 MXNet 的速度非常接近单 GPU 的情况；而在 TensorFlow 和 Torch 上的表现则相对好一点。当 GPU 数量翻倍时，CNTK 和 MXNet 的可扩展性最好，均实现了约 35% 的提速，Caffe 实现了大约 28% 的提速，而 Torch 和 TensorFlow 较差，只有约 10%。当我们把 GPU 数量从 2 个增加到 4 个时，TensorFlow 和 Torch 没有实现进一步的提速。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/09e0b44088bf0447fc393dd896d89310bdb87ef0"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 16：(a) FCN-R 在多 GPU 平台上的性能比较，(b) 在多 GPU 平台上的收敛速度&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/4e69dd13685fa466a93b522395275058e7c7bc4a"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 17：(a)AlexNet-R 在多 GPU 平台上的性能比较，(b) 在多 GPU 平台上的收敛速度&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/e1e017223f42de5b79529d61b8355b38701e5bc2"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 18：(a)ResNet-56 在多 GPU 平台上的性能比较，(b) 在多 GPU 平台上的收敛速度&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;结论&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本研究旨在对比现代深度学习软件工具的运行性能，测试它们在不同类型的神经网络和不同的硬件平台上的执行效率。我们的实验结果表明，目前所有经过测试的工具都可以很好地利用 GPU，和使用 CPU 相比有着很大优势。然而，没有任何一个工具可以在所有方面胜过其他软件工具，这意味着也许存在进一步优化性能的方向。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在未来的研究中，首先，我们会将更多的深度学习软件工具（如百度的 Paddle）和硬件平台（如 AMD 的 GPU 和英特尔 Xeon Phi）纳入这项基准研究。其次，我们计划评估在高性能 GPU 集群上这些工具的可扩展性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Wed, 22 Feb 2017 12:55:17 +0800</pubDate>
    </item>
    <item>
      <title>公告｜机器之心完成 Pre A 轮融资，今日头条领投，源码、讯产投及晨兴跟投</title>
      <link>http://www.iwgc.cn/link/</link>
      <description>
&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/d115a6434e65917d44a1f8fe1e201f5c646b8e01"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;近日，机器之心完成 Pre A 轮融资，本轮融资由今日头条领投，源码资本、讯产投和晨兴资本跟投。接下来，机器之心将与这四家战略投资者以及此前的天使投资方联想之星 Comet Labs 一起，在全球人工智能领域的内容、投资、产业服务、项目孵化和技术研究等方面展开深入合作，具体合作事宜将会阶段性公布。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器之心是国内首家系统性关注人工智能的科技媒体，在过去三年时间里，机器之心一直恪守正确的内容价值观和原则，坚持提供高质量内容，使人工智能从业者及爱好者能够真正获取有价值的信息及学习知识，我们希望借助优质内容的力量来正确引导甚至影响人工智能行业的发展，而非刻意炒作 AI 概念或者进行不负责任的内容输出。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;也正因如此，机器之心得到了国内外众多技术专家、科技公司高管和人工智能从业者的高度认可，机器之心也积累了广泛的影响力和知名度，形成了富有特色的自我品牌。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器之心对邓力、吴恩达、Richard Sutton、杨强、黄学东、MXNet 团队、Greg Corrado、Lawrence Carin、 Jack Gallant、Randy Schekman、洪小文、王永东、俞栋、刘庆峰、胡郁、林元庆、戴文渊、孙剑、李磊等人工智能专家做过深度专访，对 NIPS 2016 、CDLM 2016 等进行了现场深度报道。也获得了「微软中国 2016 年度媒体奖」、今日头条 2016「年度科技头条号」、「虎嗅 2015 年度十佳作者」和「今日头条 2015 年度最佳自媒体」等荣誉，与 O'Reilly 一起成为 AI Frontiers 合作媒体，也是唯一一家受邀参加神经科学顶级大会 Brain Froum 2016 的中文媒体。同时，机器之心也是中国人工智能学会「吴文俊人工智能科学技术奖」战略合作伙伴。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前机器之心在各平台拥有共计 50 万高质量用户，微信端日均 PV 5 万，活跃用户 6 万人。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在活动方面，机器之心举办了「北美七大城市人工智能系列活动」、「CVPR 2016 华人学者聚会」等活动，覆盖了近千名优秀海外人工智能人才。在国内打造了人工智能精品线下活动「Interface」，协办了「BOT 数据应用竞赛」、「中国人工智能产业大会暨吴文俊奖颁奖典礼」等多场重要活动。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在媒体业务之外，机器之心一直深耕人工智能领域的产业服务，为各类参与者提供包括投融资对接、产业上下游需求匹配、人才招聘和国际合作等多项服务，并积累了多个成功案例。同时，已经完成了孵化器、基金和数据开放平台的筹备工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前，机器之心拥有完善且专业的国际化团队，建立了覆盖全球所有人工智能核心区域和华人技术人才的渠道和网络，与世界范围内上百家科技巨头、实验室、研究机构、孵化器和创业公司都建立了紧密合作关系，这将使我们源源不断的获取优质内容、创业项目、人才和合作机会等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器之心深知自己的定位和使命，并坚守自己的原则、品味和价值观，媒体业务将一如既往的生产更多高质量内容，并推出视频和行业报告等新型内容产品，永远朝着「经济学人」、「彭博」和「纽约客」这样的业界榜样而努力，希望真正成为一家国际化的严肃科技媒体；在产业方面，机器之心将一直定位于「服务者」，通过自身踏实的积累和具体落地的业务，审慎谦卑的为各类人工智能参与者提供服务，以帮助他们解决实际问题，而不会去做（也不可能做到）一个所谓的「AI 平台」或「AI 生态」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;领投方今日头条表示，今日头条一直致力于大规模运用人工智能技术，根据用户兴趣为用户个性化匹配推荐内容，在信息分发效率上不断寻求优化和提升。我们相信未来 AI 将更为深远地影响各行各业，给人们的生活带来更大的便利。机器之心作为人工智能领域的重要产业媒体，创造生产了大量 AI 领域的优质内容，在产业界、学界和社会发挥着重要的连接作用。未来希望今日头条能携手机器之心，通过深度合作，更广泛地促进人工智能领域信息、资源、资本和人才方面的交流合作，进一步助推人工智能产业整体更好的发展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;源码资本一直关注人工智能结合实际应用的多个领域做投资布局，具体而言：在信息领域，如今日头条，就在利用 AI 做信息分发；金融领域，如趣店、用钱宝，基于人工智能做个人信贷；医疗领域，机器人医生的辅助诊断等。对于本次投资，源码资本认为，「智能+」在不断的改造这个社会，从长期看，技术会渗透到人类生活、生产的各个方面，趋势不可阻挡。相信机器之心的专业报道和产业服务有助于提升产业内信息、人才、资金、资源的流动速度和效率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;晨兴资本认为，机器之心深耕 AI 领域，在产业和学术两方面都具有极高的敏感度，未来将会在汇集行业人才、资讯、资本上有更深入的发展。晨兴一直致力于携手优秀的创业者创建伟大的科技企业，AI 是晨兴长期关注的重点领域，先后在早期投资了地平线机器人、图普科技、追一科技和康夫子等项目。晨兴一直寻求在数据和商业两方面都有闭环能力、由算法驱动的新创业机会。未来晨兴资本将携手机器之心，共同探索 AI 底层技术驱动下的新产品、新市场。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，讯产投代表胡郁表示：「伴随着中国乃至世界人工智能的不断发展，机器之心在过去的几年当中深入到科技与产业的核心，已经成为连接中国人工智能科技产业界与世界前沿的桥梁。科大讯飞在创业以来的十八年中以『在中国用人工智能改变世界』为自己的座右铭，与机器之心在核心价值观方面高度一致。我们期待携手机器之心在将来中国人工智能引领世界的路程中一同努力，共创辉煌！」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器之心正朝着正确的方向狂奔，我们期待更多国内外的优秀人才加入，详细请查看机器之心「&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722163&amp;amp;idx=5&amp;amp;sn=ffdda8d22220932d4227df95d5c9731e&amp;amp;chksm=871b0b0db06c821bd2d86b40d2a38c9d881f814ca0cc0b887eb892382a5cb3ad9e560ade759f&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722163&amp;amp;idx=5&amp;amp;sn=ffdda8d22220932d4227df95d5c9731e&amp;amp;chksm=871b0b0db06c821bd2d86b40d2a38c9d881f814ca0cc0b887eb892382a5cb3ad9e560ade759f&amp;amp;scene=21#wechat_redirect" target="_blank"&gt;全球人才招聘&lt;/a&gt;」。&lt;/span&gt;&lt;/p&gt;
</description>
      <pubDate>Wed, 22 Feb 2017 12:55:17 +0800</pubDate>
    </item>
    <item>
      <title>入门级解读：小白也能看懂的TensorFlow介绍</title>
      <link>http://www.iwgc.cn/link/</link>
      <description>
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自medium&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;strong&gt;作者：Soon Hin Khor&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：Jane W、邵明、微胖&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote style="color: rgb(62, 62, 62); font-size: 16px; white-space: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p&gt;&lt;span&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;本文是日本东京 TensorFlow 聚会联合组织者 Hin Khor 所写的 TensorFlow 系列介绍文章的Part 3 和 Part4，自称给出了关于 TensorFlow 的 gentlest 的介绍。&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718466&amp;amp;idx=1&amp;amp;sn=016f111001e8354d49dd4ce279d283cd&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718466&amp;amp;idx=1&amp;amp;sn=016f111001e8354d49dd4ce279d283cd&amp;amp;scene=21#wechat_redirect" target="_blank"&gt;在之前发布的前两部分介绍中&lt;/a&gt;，作者谈到单一特征问题的线性回归问题以及训练（training）的含义，这两部分将讲解&amp;nbsp;TensorFlow（TF）进行多个特征的线性回归和逻辑回归。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;矩阵和多特征线性回归&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;快速回顾&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;之前文章的前提是：给定特征&amp;mdash;&amp;mdash;任何房屋面积（sqm），我们需要预测结果，也就是对应房价（$）。为了做到这一点，我们：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="list-style-type: decimal;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;我们找到一条「最拟合」所有数据点的直线（线性回归）。「最拟合」是当线性回归线确保实际数据点（灰色点）和预测值（内插在直线上的灰色点）之间的差异最小，即最小化多个蓝线之和。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;使用这条直线，我们可以预测任何房屋的价格。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/963481037d7566bb2b7ffe393f86589927fa23db"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;使用单一特征线性回归进行预测&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;多特征线性回归概述&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;实际上，任何预测都依赖于多个特征，于是我们从单特征的线性回归进阶到 带有两个特征的线性回归；之所以选择两个特征，是为了让可视化和理解简明些，但这个思想可以推广到带有任何数量特征的线性回归。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们引进一个新的特征&amp;mdash;&amp;mdash;房间数量。当收集数据点时，现在我们需要在现有特征「房屋面积」之上收集新特征「房间数」的值，以及相应的结果「房屋价格」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们的图表变成了 3 维的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/38ad5af7eb37dcd1f0288eb0b785be105dad89a9"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;结果「房屋价格」以及 2 个特征（「房间数」，「房屋面积」）的数据点空间&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然后，我们的目标变成：给定「房间数」和「房屋面积」，预测「房屋价格」（见下图）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/429f1ebc82fd87cc7be5162b24429688ffd629cf"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;由于缺少数据点，有时无法对给定的 2 个特征进行预测&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在单一特征的情形中，当没有数据点时，我们需要使用线性回归来创建一条直线，以帮助我们预测结果房屋价格。在 2 个特征的情形中，我们也可以使用线性回归，但是需要创建一个平面（而不是直线），以帮助我们预测（见下图）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/1ea37af70804bf4f8899cde87793485e8f026e31"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;使用线性回归在 2 个特征空间中的创建一个平面来做预测&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;多特征线性回归模型&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;回忆单一特征的线性回归（见下图左边），线性回归模型结果为 y，权重为 W，房屋大面积为 x，偏差为 b。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于 2 个特征的回归（参见下图右侧），我们引入另一个权重 W2，另一个自变量 x2 来代表房间数的特征值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/79fbe951113b74b0002019a394c4a8badebfbdad"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;单特征 vs. 2 个特征的线性回归方程&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如之前讨论的那样，当我们执行线性回归时，梯度下降算法能帮助学习系数 W、W2 和 b 的值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Tensorflow 的多特征线性回归&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1.快速回顾&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;单特征线性回归的 TF 代码由 3 部分组成（见下图）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;构建模型（蓝色部分）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;基于模型构建成本函数（红色部分）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;使用梯度下降（绿色部分）最小化成本函数&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/a4c3ab928f3c22eb8b7ff9b4fb2c3d8f1cac3604"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;用于单特征线性回归的 Tensorflow 代码&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2.Tensorflow 的 2 个特征的线性回归&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;TF 代码中 2 个特征的线性回归方程（如上所述）的变化（相比单特征）用红色显示。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/aa5dc2b9176ddcda4c3f12f9d2aa951165729fc9"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;注意，增加新特征的这种方式效率低；随着特征数量的增长，所需的变量系数和自变量的数量会增加。实际的模型有更多的特征，这恶化了这个问题。那么，如何能有效地表示特征呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;解决方法：矩阵&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先，让我们将表征两个特征的模型推广到表征 n 个特征的模型：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/c622645f91b9cee532afeea782011720ec9ae89a"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;复杂的 n 特征公式可以用矩阵简化，矩阵被内置于 TF 中，这是因为：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;数据可以用多维表示，这契合我们表征具有 n 个特征的数据点（左下方，也称为特征矩阵）以及具有 n 个权重模型（右下，也称为权重矩阵）的方式&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/29a188068963c1b73f2a9c68d704429ca869fc5e"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;单个数据点的 n 个特征与模型的矩阵形式的 n 个权重&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 TF 中，它们将被写为：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;x = tf.placeholder（tf.float，[1，n]）&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;W = tf.Variable（tf.zeros [n，1]）&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;注意：对于 W，我们使用 tf.zeros，它将所有 W1，W2，...，Wn 初始化为零。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在数学上，矩阵乘法是向量乘法的加总；因此自然地，特征（中间的一个）和权重（右边的）矩阵之间的矩阵乘法给出（左边的）结果，即等于 n 个特征的线性回归公式的第一部分（如上所述），没有截距项。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/7ac2e1e392b9f5b74f0085604971c7e97d895b59"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;特征和权重矩阵之间的矩阵乘法给出结果（未添加截距项）&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 TF 中，这种乘法将表示为：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;y = tf.matmul(x, W)&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;多行特征矩阵（每行表示数据点的 n 个特征）之间的矩阵乘法返回多行结果，每行代表每个数据点的结果/预测（没有加入截距项）；因此一个矩阵乘法就可以将线性回归公式应用于多个数据点，并对应地产生多个预测（每个数据点对应一个结果）（见下文）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;注意：特征矩阵中的 x 表示变的更复杂，即我们使用 x1.1、x1.2，而不是 x1、x2 等，因为特征矩阵（中间矩阵）从表示 n 个特征（1 行 x，n 列）的单个数据点扩展到表示具有 n 个特征（m 行 x，n 列）的 m 个数据点。因此，我们扩展 x &amp;lt;n&amp;gt;（如 x1）到 x &amp;lt;m &amp;gt;.&amp;lt;n&amp;gt;（如 x1.1），其中，n 是特征数，m 是数据点的数量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/6cd712fff08efb1e637a2b03e80e9162cb1bb3bf"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;具有模型权重的多行矩阵乘法产生矩阵的多个行结果&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 TF 中，它们将被写为：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;x = tf.placeholder（tf.float，[m，n]）&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;W = tf.Variable（tf.zeros [n，1]）&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;y = tf.matmul（x，W）&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;最后，向结果矩阵添加常数，也就是将常数添加到矩阵中的每一行&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 TF 中，用矩阵表示 x 和 W，无论模型的特征数量或要处理的数据点数量，矩阵都可以简化为：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;b = tf.Variable(tf.zeros[1])&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;y = tf.matmul(x, W) + b&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Tensorflow 的多特征备忘单&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们做一个从单一特征到多特征的线性回归的变化的并行比较：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/eb844cac0b776bfd2bc8f1e30523670b430acaf2"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Tensorflow 中的单特征与 n 个特征的线性回归模型&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;总结&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在本文中，我们介绍了多特征线性回归的概念，并展示了我们如何将模型和 TF 代码从单特征的线性回归模型扩展到 2 个特征的线性回归模型，并可以推广到 n 特征线性回归模型。最后我们为多特征的 TF 线性回归模型提供了一张备忘单。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;逻辑回归&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;逻辑回归综述&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们已经学会了如何使用 Tensorflow（TF）去实现线性回归以预测标量值得结果，例如给定一组特征，如住房大小，预测房价。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而，有时我们需要对事物分类（classify）而不是去预测一个具体的数值，例如给定一张含有数字（0-9 十个数字中的一个）的图片，我们需要将其分类为 0，1，2，3，4，5，6，7，8，9 十类。或者，我们需要将一首歌曲进行归类，如归类为流行，摇滚，说唱等。集合 [0,1,2，...，9]、[流行，摇滚，说唱，等等] 中的每一个元素都可以表示一个类。在计算机中，我们通常用数字对抽象名词进行表示，比如，pop = 0, rock = 1, 等等。为了实现分类，我们使用 TF 来实现逻辑回归。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在本文中，我们将使用逻辑回归将数字图片归类为 0，1，2，3，4，5，6，7，8，9 这十类。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;逻辑回归的细节&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;线性回归中的许多概念仍然用于逻辑回归之中。我们可以再次使用公式 y = W.x + b，但是有一些不同的地方。让我们看看线性回归和逻辑回归的公式：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/eb5a2145fb3331650eeb918def1cebbb9b90daa1"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;线性回归与逻辑回归的区别与相似&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;区别：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;结果（y）：对于线性回归，结果是一个标量值（可以是任意一个符合实际的数值），例如 50000，23.98 等；对于逻辑回归，结果是一个整数（表示不同类的整数，是离散的），例如 0,1,2，... 9。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;特征（x）：对于线性回归，特征都表示为一个列向量；对于涉及二维图像的逻辑回归，特征是一个二维矩阵，矩阵的每个元素表示图像的像素值，每个像素值是属于 0 到 255 之间的整数，其中 0 表示黑色，255 表示白色，其他值表示具有某些灰度阴影。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;成本函数（成本）：对于线性回归，成本函数是表示每个预测值与其预期结果之间的聚合差异的某些函数；对于逻辑回归，是计算每次预测的正确或错误的某些函数。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;相似性：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;训练：线性回归和逻辑回归的训练目标都是去学习权重（W）和偏置（b）值。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;结果：线性回归与逻辑回归的目标都是利用学习到的权重和偏置值去预测/分类结果。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;协调逻辑回归与线性回归&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了使逻辑回归利用 y = W.b + x，我们需要做出一些改变以协调上述差异。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1.特征变换，x&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们可以将二维的图片特征（假设二维特征有 X 行，Y 列）转换成一维的行向量：将第一行以外的其它行数值依顺序放在第一行后面。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/1745831307c3ceccae44bdebf689d7b6c4393f1a"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;转换图像特征以适用于逻辑回归公式&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2.预测结果转换，y&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于逻辑回归，y 不能作为标量，因为预测可能最终为 2.3 或 11，这不在可能的类 [0,1，...，9] 中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了解决这个问题，y 应该被转换成列向量，该向量的每个元素代表逻辑回归模型认为属于某个特定类的得分。在下面的示例中，预测结果为类'1'，因为它具有最高得分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/0b9d136bf7486c4863bb6f5cc6a260a561df4e7b"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;每个类的分数和具有最高分数的类成为被预测的类&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于给定的图片，为求这个分数向量，每个像素都会贡献一组分数（针对每一类），分数表示系统认为这张图片属于某类的可能性，每个像素分数之和成为预测向量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/1ef15fd09376f861d2b68362c434789e301d4b48"/&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;每个像素提供一个分数向量；每个类别有一个分数，最后变成预测向量。所有预测向量的总和变成最终预测。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3.成本函数的变换&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;涉及到预测结果和实际结果之间数值距离的任何函数都不能作为成本函数。对于数字图片「1」，这样的成本函数将使预测值「7」（7-1=6）更严重地惩罚预测值「2」（2-1=1），尽管两个预测结果都是错误的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们即将使用的成本函数，交叉熵（H），用以下几个步骤实现：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 将实际图片的类向量（y'）转化成 one-hot 向量，这是一个概率分布。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 将预测类 (y) 转化成概率分布。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 使用交叉熵函数去计算成本函数，这表示的是两个概率分布函数之间的差异。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一步：One-hot 向量&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由于我们已经将预测 (y) 转换成分数向量，因此，我们也应该将实际图片类（y』）转换成相同维数的向量；one-hot 向量是将对应于实际类的的元素为设为 1，其它元素为 0。下面，我们展示表示 0-9 十个类中一个类的 one-hot 向量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/6f7bd24e1fab945239a15fea1c8958ddbd23ea7a"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图片类和它们的 one-hot 向量表示&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;假设实际图像上是数字「1」(y')，它的 one-hot 向量是 [0,1,0,0,0,0,0,0,0,0]，假设其预测向量 (y) [1.3, 33, 2, 1.2, 3.2, 0.5, 3, 9.2, 1]，绘制比较如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/47de5f78b7bd3b18cc8f003e45b99628793af2c6"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;真实图片 one&amp;mdash;hot 向量（顶）预测类别概率&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二步：用 softmax 实现概率分布&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了在数学上比较这两个「图」的相似性，交叉熵是一个好方法。（这里是一个很棒但比较长的解释，如果你对细节感兴趣的话。https://colah.github.io/posts/2015-09-Visual-Information/）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而，为了利用交叉熵，我们需要将实际结果向量（y'）和预测结果向量（y）转换为「概率分布」，「概率分布」意味着：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;每个类的概率/分数值在 0-1 之间；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;所以类的概率/分数和必须是 1；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;实际结果向量（y'）如果是 one-hot 向量，满足了上述限制。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为预测结果向量（y）, 使用 softmax 将其转换为概率分布：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/5059bfe852e174850c2a618f040e2a9a0e51ab55"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;softmax 函数，这里 i 是表示 0, 1, 2, &amp;hellip;, 9 十类&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个过程只需要简单的两步，预测向量（y）中的每个分量是 exp(y_i) 除以所有分量的 exp() 的和。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/249c0f2ca5d0f6c5f6893bb66118e6bf46ceda3d"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;注意：softmax（y）图形在形状上与 prediction (y) 相似，但是仅仅有较大的最大值和较小的最小值&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/020dd3419516d64bb1cf369f4a4fd85cf44f2c41"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;使用 softmax 前后预测（y）曲线&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第三步：交叉熵&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在，我们将预测向量分数概率分布（y'）和实际向量分数概率分布 (y) 运用交叉熵。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;交叉熵公式：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/2e1a604b189e0130a6652254be9f44ab96317348"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;交叉熵作为我们想最小化的成本函数&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了快速理解这个复杂的公式，我们将其分为 3 部分（见下文）。注意，本文中的符号，我们使用 y_i 表示 y 的第 i 个分量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/315fdc75081652f64cbe386d973237d4d003da60"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;交叉熵（H）公式可视为三个部分：红，蓝，绿&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;蓝：实际图像类（y'）对应的 one-hot 图，参看 one-hot 向量部分：&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;红：由预测向量元素（y）经过softmax(y)，-og(softmax(y）一系列变化而来：&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;绿：每一图片类别 i，其中，i = 0, 1, 2, &amp;hellip;, 9, 红蓝部分相乘的结果&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以下图例会进一步简化理解。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;蓝色制图只是真实图片类别（y'）one-hot 向量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/06af77c4e66f08413c8355ffd8773056c1b85953"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;每个预测向量元素，y，转换成 -log(softmax(y)，就得到红图：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/fb89a0181847cc580d84b0488132c641bf337366"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;预测类别向量（y）一系列转换后，得到红图&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你想完全地理解第二个变换 -log(softmax(y)) 与 softmax(y) 为什么成反比，请点击 video or slides（参见文末资源部分）.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;交叉熵（H），这个绿色的部分是每个类别的蓝色值和红色值的乘积和，然后将它们做如下相加：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/8536e3265247dc8a2577d283a142d6c33001e5e7"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;交叉熵是每个图像类的蓝色值和红色值的乘积之和。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由于这张蓝色图片对应一个 one-hot 向量，one-hot 向量仅仅有一个元素是 1，它对应一个正确的图片类，交叉熵的其它所有元素乘积为 0，交叉熵简化为：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/4e238dfa3195852a4d4662e006975be2465c7ac7"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;将所有部分放到一起&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有了三个转换后，现在，我们就可以将用于线性回归的技术用于逻辑回归。下面的代码片段展示的是本系列文章第三部分线性回归代码和代码适用逻辑回归所需要的变化之间的对比。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;逻辑回归的目标是最小化交叉熵（H），这意味着我们只需要最小化 -log（softmax（y_i）项；因为该项与 softmax（y_i）成反比，所以我们实际上是最大化该项。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使用反向传播去最小化交叉熵 (H ) 将改变逻辑回归的权重 W 和偏置 b。因此，每张图片的像素值将会给出对应图片类最高分数/概率!（最高分数/概率对应于正确的图片类）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/697681a421b61e7ebef4054b46be857cc203419a"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;将线性回归方法用于逻辑回归之中，「total_class」是欲分类问题的总类数量，例如，在上文手写数字体识别例子中，total_class=10。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 将特征变换成一维特征；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 将预测结果向量、实际结果向量变化成 one-hot 向量；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 将成本函数从平方误差函数变化到交叉熵。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/fc6a122f2019982de9974d4510c8cbd013b557e5"/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;总结&lt;/span&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;线性回归对基于给定特征的预测（数值）是有帮助的，逻辑回归根据输入特征实现分类是有帮助的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们展示了如何调整线性回归 y = W.x + b 实现逻辑回归：（1）转换特征向量；2）转换预测/结果向量；（3）转换成本函数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当你掌握了 one-hot 向量，softmax，交叉熵的知识，你就可以处理谷歌上针对「初学者」的图片分类问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;资源：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;针对初学者的图像识别的谷歌代码：&lt;/span&gt;&lt;span&gt;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/mnist/mnist_softmax.py&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;slideshare 上的幻灯片：&lt;/span&gt;&lt;span&gt;http://www.slideshare.net/KhorSoonHin/gentlest-introduction-to-tensorflow-part-3&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;油管上的视频：&lt;/span&gt;&lt;span&gt;https://www.youtube.com/watch?v=F8g_6TXKlxw&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文链接：https://medium.com/all-of-us-are-belong-to-machines/gentlest-intro-to-tensorflow-4-logistic-regression-2afd0cabc54#.glculhxzi&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Tue, 21 Feb 2017 12:26:02 +0800</pubDate>
    </item>
    <item>
      <title>教程 | 七个小贴士，顺利提升TensorFlow模型训练表现</title>
      <link>http://www.iwgc.cn/link/</link>
      <description>
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自deeplearningweekly&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Malte Baumann&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀、蒋思源、微胖&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;初来乍到的 TensorFlow 在 2015 年推出之后已经飞速成长为了 2016 年被用得最多的深度学习框架。我（Malte Baumann）在 TensorFlow 推出后几个月入了坑，在我努力完成硕士论文阶段开始了我的深度学习之旅。我用了一段时间才适应计算图（computation graph）和会话模型（session model）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这篇短文并不是一篇 TensorFlow 介绍文章，而是介绍了一些有用的小提示，其中大多都是关于性能表现上的，这些提示揭示了一些常见的陷阱，能帮助你将你的模型和训练表现提升到新的层次。本文将从预处理和你的输入流程开始，然后介绍图构建，之后会谈到调试和性能优化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;预处理和输入流程：&lt;/span&gt;&lt;span&gt;让预处理整洁精简&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你是否疑惑过：为什么你的简单模型需要那么长的训练时间？一定是预处理做得不好！如果你的神经网络输入还需要做一些类似于转换数据这样的繁重的预处理工作，那么你的推理速度就会被大大减缓。我就遇到过这种情况，那是我正在创建了一个所谓的「距离地图（distance maps）」，其使用了一个自定义的 Python 函数而将「Deep Interactive Object Selection」所使用的灰度图像作为附加输入。我的训练速度顶多只达到了大约每秒 2.4 张图像&amp;mdash;&amp;mdash;即使我已经换用了一个远远更加强大的 GTX 1080。然后我注意到了这个瓶颈，经过修复之后，我将训练速度提升到了每秒 50 张图像。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你也遇到了类似的瓶颈，通常你的第一直觉是应该优化一些代码。但减少训练流程的计算时间的一个更有效的方法是将预处理作为一个一次性的操作先完成&amp;mdash;&amp;mdash;生成 TFRecord 文件。这样，你只需要执行一次繁重的预处理工作；有了预处理训练数据之后得到的 TFRecord 文件之后，你需要在训练阶段加载这些文件即可。即使你想引入某种形式的随机性来增强（augment）你的数据，你考虑的也应该是创建不同的变体，而不是用原始数据来填充你的训练流程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;注意你的队列&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一种关注成本高昂的预处理流程的方法是使用 TensorBoard 中的队列图（queue graph）。如果你使用框架 QueueRunners，那么就会自动生成队列图并将总结存储在一个文件中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该图能够显示你的机器是否能够保持队列充盈。如果你在该图中看到了负峰值，那就说明你的系统无法在你的机器想要处理一个批（batch）的时候生成新数据。这种情况的原因有很多，而根据我的经验，其中最常见的是 min_after_dequeue 的值太大。如果你的队列想要在内存中保存大量记录，那么这些记录会很快充满你的容量，这会导致 swapping 并显著减慢你的队列。其它原因还可能是硬件上的问题（比如磁盘速度太慢）或数据太大超过了系统处理能力。不管原因是什么，解决这些问题就能帮助你获得更高的训练速度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;图构建和训练：&lt;/span&gt;&lt;span&gt;完成你的图&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;TensorFlow 独立的图构建和图计算模型在日常编程中十分少见，并且可能让初学者感到困惑。这种独立的构架可以应用于在第一次构建图时代码所出现的漏洞和错误信息，然后在实际评估时再一次运行，这个是和你过去代码只会评估一次这样的直觉相反的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一个问题是与训练回路（training loops）结合的图构建。因为这些回路一般是「标准」的 Python 循环，因此能改变图并向其添加新的操作。在连续不断地评估过程中改变图会造成重大的性能损失，但一开始却很难引起注意。幸好 TensorFlow 有一个简单的解决方案，仅仅在开始训练回路前调用 tf.getDefaultGraph().finalize() 完成你的图即可。这一段语句将会锁定你的图，并且任何想要添加新操作的尝试都将会报错。这正是我们想要达到的效果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;分析你的图的性能&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;TensorFlow 一个少有人了解的功能是性能分析（profiling）。这是一种记录图操作的运行时间和内存消耗的机制。如果你正在寻找系统瓶颈或想要弄清楚模型能不能在不 swapping 到硬件驱动的情况下训练，这种功能会十分有效。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了生成性能分析数据，你需要在开启了 tracing 的情况下在你的图上执行一次运行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;之后，会有一个 timeline.json 文件会保存到当前文件夹，tracing 数据在 TensorBoard 中也就可用了。现在你很容易就看到每个操作用了多长时间和多少内存。仅仅只需要在 TensorBoard 中打开图视窗（graph view），并在左边选定你最后的运行，然后你就可以在右边看到性能的详细记录。一方面，你能根据这些记录调整你的模型，从而尽可能地利用你机器的运算资源。另一方面，这些记录可以帮助你在训练流程（pipeline）中找到瓶颈。如果你比较喜欢时间轴视窗，可以在谷歌 Chrome 的事件追踪性能分析工具（Trace Event Profiling Tool，https://www.chromium.org/developers/how-tos/trace-event-profiling-tool）中加载 timeline.json 文件。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一个很赞的工具就是 tfprof（http://dwz.cn/5lRNeQ），将同样的功能用于内存和执行时间分析，但能提供更加便利的功能。额外的统计需要变换代码。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;注意你的内存&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;就像前部分解释的，分析（profiling）能够让你跟踪特定运行的内存使用情况，不过，注意整个模型的内存消耗更重要些。需要始终确定没有超出机器内存，因为 swapping 肯定会让输入流程放慢，会让你的 GPU 开始坐等新数据。简单地 top，就像前文讲到的 TensorBoard 队列图就应当足够侦测到这样的行为。然后使用前文提过的 tracing，进行细节调查。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;调试：&lt;/span&gt;&lt;span&gt;print 会帮到你&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我主要用 tf.Print 来调试诸如停滞损失（stagnating loss）或奇怪的输出等问题。由于神经网络天性的缘故，观察模型内部张量原始值（raw value）通常并没多大意义。没人能够解释清楚数以百万的浮点数并搞清楚哪儿有问题。不过，专门 print 出数据形状（shape）或均值就能发现重要见解。如果你正在试着实现一些既有模型，你就能比较自己模型值和论文或文章中的模型值，这有利于解决棘手问题或发现论文中的书写错误。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有了 TensorFlow 1.0，我们也有了新的调试工具（http://suo.im/4FtjRy）&amp;mdash;&amp;mdash;这个看起来似乎还蛮有前途的。虽然我还没有用过，不过呢，肯定会在接下来的时间里尝试一下啦。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;设定一个运算执行的超时时间&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你已经实现了你的模型，载入了会话，但却没动静？这经常是有空列队（empty queues）造成的，但是如果你并不清哪个队列才是罪魁祸首，一个很简单的解决办法：在创造会话时，设定运行超时时间&amp;mdash;&amp;mdash;当运行超过你设定的时限，脚本就会崩溃。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使用栈进行追踪，找出让你头疼的问题，解决问题然后继续训练。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文链接：http://www.deeplearningweekly.com/blog/tensorflow-quick-tips&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Tue, 21 Feb 2017 12:26:02 +0800</pubDate>
    </item>
    <item>
      <title>资源 | 如何用Kur训练百度的DeepSpeech模型？</title>
      <link>http://www.iwgc.cn/link/</link>
      <description>
&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自deep gram&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李泽南、黄小天、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你想要训练一个可用于语音识别的深度神经网络吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我也是。两年前我获得了密歇根大学的博士学位成了一名粒子物理学家。我懂一些 C/C++和 Python，并且认识 Noah Shutty。我和 Noah 联合创建了 Deepgram，Noah 是一个精力充沛、学习速度极快的人。我们俩都没有语音识别背景知识，但是懂一点编程和机器学习应用的知识，有大量鼓捣数据处理/系统的经验。我们确实很清楚一件事&amp;mdash;&amp;mdash;如何快速解决问题（一个建造深度地下暗物质探测器时练就的本领）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那时，我们发现自己建造了世界上第一个基于深度学习的语音搜索引擎。为了发展我们需要一个可以理解语音的 DNN。我们成功了，现在你也可以。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;项目地址：http://blog.deepgram.com/how-to-train-baidus-deepspeech-model-with-kur/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面是基本问题：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/fa9f5ca264baf4fe931e76d413f3386152177495"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;将下面这段音频：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;iframe allowfullscreen="" class="video_iframe" data-vidtype="1" frameborder="0" height="417" src="https://v.qq.com/iframe/preview.html?vid=x0377zo8zm9&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0" width="556"&gt;&lt;/iframe&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;一段普通人说：「I am a human saying human things」的声谱。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;转换成下面这句文本：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/dcf07c37fa1044f3f3879752ea254ab8f93977fd"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;听到了「I am a human saying human things」音频文件的一个 DNN 的预测结果&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该怎么做？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/8c40ec037a71b2fe4252f4c40c8cba72ff282466"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;在易于使用的 Kur 框架中训练一个 DNN&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;我们为什么这样做&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你可以这么想：我们正在一个搜索音频的谷歌，我们需要一个用于语音识别的深度学习模型来完成这一目标。两年前我们开始的时候，百度首次公开了关于 Deepspeech 的论文，这对我们来讲是一件大好事。这将帮助我们搞明白深度学习可以如何用于搜索语音。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;照片中是吴恩达，站在深度语音 RNN 的前面，看起来像是电影《A.I.》里的大坏蛋。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/1842de719babd2e98452fd0054664fa318df15ea"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;在英伟达的 GTC 大会上，来自百度的吴恩达正在做关于 Deepspeech 的演讲&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一步就是建立一个端对端的深度学习语音识别系统。我们已经做这个超过一年了，现在我们拿出来共享，就像当初百度共享给我们一样（好吧，事实上百度共享给了全世界）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们将给每一个人一个完全有效的 Deepspeech DNN。在 Deepgram 的开源 Python 软件包 Kur 中：http://kur.deepogram.com/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们不是东拼西凑胡搞一通让它工作的。我们打造了一个运行在 TensorFlow 上的高质量抽象框架，使深度学习变的真正容易起来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;插播一句：为了 Deepgram 的生存我们不得不打造 Kur。现在人工智能领域已是一片红海，除非胸有成竹，否则你不可能快速建立前沿的模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从前，运行 DNN 很麻烦，现在，这变的简单起来。我们的系统从基础做起，一步一步使其简单起来，使你可以描述模型，并且无需做繁杂的工作即可使其运转。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Kur 软件包刚刚发布。它免费且开源，以第一个神话之中的龙（dragon）来命名，Kur 由 Deepgram 人工智能小组全体成员倾力打造，希望你们会喜欢它。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;我们要创造一些人工智能&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;四个轻松的部分：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 安装 Kur&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 运行 Deepspeech 示例&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 观察你的计算机如何学习人类语音&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4. 你变成了邪恶的人工智能统领，请放声大笑&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;简介结束，现在进入实际操作！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一些小的说明：当你看到这起效时，你会认为自己是上帝。学习语音的训练网络是一种变革性的东西。考虑一下这种情况：你在自己的计算机上创造出来的人工智能现在能理解人类说出的话。你的所作所为要负责任。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;额外补充：训练端到端的语音识别深度学习模型需要很多计算。你需要耐心。毕竟你自己也不是在几分钟之内就学会了听人说话。如果你耐心有限，可以使用强大的 GPU&amp;mdash;&amp;mdash;Kur 支持。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;下载并安装 Kur（这很简单）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于安装，如果你已经安装了 Python3.4 或以上版本，你就只需要在你的终端运行$ pip install kur 即可。如果你需要指导，或者一个轻松的操作环境，请访问 kur.deepgram.com 查看完整的安装指导。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;运行 Deepspeech 例子&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;安装 Kur，运行$ kur -v train speech.yml，该文件应该保存在 kur/examples/目录中。如果你想要直接训练而不显示目前的工作状态，可以省略-v。当然，加入-v 可以让你了解 Kur 的工作方式，如果你希望了解更多的细节，请用-vv。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;你的模型会开始训练&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一开始输出的基本是乱码，随后，它的表现将会越来越好。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;训练 1 小时后：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;真实转录： these vast buildings what were they&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;DNN 预测：he s ma tol ln wt r hett jzxzjxzjqzjqjxzq&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;训练 6 小时后：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;真实转录：the valkyrie kept off the coast steering to the westward&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;DNN 预测：the bak gerly cap dof the cost stkuarinte the west werd&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;训练 24 小时后：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;真实转录：it was a theatre ready made&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;DNN 预测：it was it theater readi made&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;经过训练，模型输出了真正的英语。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这个示例中，我总共训练了 48 小时。还记得「i am a human saying human things」文件吗？让我们看看人工智能对它的预测。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;iframe allowfullscreen="" class="video_iframe" data-vidtype="1" frameborder="0" height="417" src="https://v.qq.com/iframe/preview.html?vid=c0377wq80w7&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0" width="556"&gt;&lt;/iframe&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;训练 48 小时后：&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;True transcript: i am a human saying human things&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;DNN prediction:i am a human saying human things&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;仅仅诞生 48 个小时，它就可以和人一样听懂别人说的话了！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;看看这个表格吧：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/9441848be5261d7453f98a02d23ecaff5e6b9688"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;在 Kur speech.yml 例子中训练和验证数据的 loss 和 batch 的函数&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;就这样，你训练出了目前最先进的语音识别模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;很棒不是吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为什么会如此简单？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是因为我们为这项任务深度优化了整个模型，这就是 Kur 带来的提升。另一些优势则来自于 Kur 的可描述性。在这里，你可以直接表达自己想要的东西，它就会实现。阅读 Deepspeech Kurfile，你就会明白这是什么意思。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/d17e65951a94f51e299b0f9cade510d797c3e124"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;事例中 Deepspeech 的超参数&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些是构造 DNN 所需的超参数，有一个一维 CNN 对 FFT 输出的时间片进行操作。然后有一个 3 层的 RNN 组，每个有 1000 个节点。词汇的尺度取决于我们的选择（在本例中是 a 到 z，外加空格和撇号&amp;mdash;&amp;mdash;总共有 28 种字符）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;超参数在 Kurfile 的模型部分（speech.yml）中被抓取。CNN 层就是这样构建的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/d85e0095a5ab8490e476124ffb636b84b0402f09"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;CNN 层的规格&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这里，整流线性单元（ReLU）激活层上的几个明显的超参数直击单个 CNN 层。这些超参数使用 Jinja2（http://jinja.pocoo.org/docs/2.9/）模板引擎填充。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;RNN 层的堆栈是由一个 for 循环中构建的，因为 depth 超参数而有三个层。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/58bdef8c78c814ab5faa239d0a378a1b309a5145"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;RNN堆栈规格&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中，批规范化层用来保持权重分布的稳定，提高训练速度。RNN sequence 超参数只意味着你想要在输出文本与测时按顺序输出（语音片段时间顺序）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Quick Summary：CNN 层采集 FFT 输入，然后连接到 RNN，最终形成一个完整的、可预测 28 个字符的层。这就是 Deepspeech。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;工作方式概述&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当训练语音 DNN 时，你通常会将音频分为每个约 20 毫秒的小块，使用像快速傅里叶变换（FFT）这样的方法将这些分块按顺序输入 DNN 里，并生成对当前块的预测。这个过程不断持续，直到结束这个序列，处理完整个文件（其中的所有预测都被保存）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这就是 Deepspeech 在 Kur 中运行的方式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Kur 需要使用 wav 音频文件，它会抓取文件的频谱图（时间 FFT），并将其同 CNN 层和三个 RNN 层的堆叠一同插入 CNN 层里。输出拉丁语字符的概率预测，从而形成单词。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在模型训练时，将会有验证步骤为你提供随机音频文件的即时预测。你能看到系统每一步的预测。你可以观看当前预测输出的文本，了解神经网络是如何被训练的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一开始，它会先学习空格，随后它会了解元音和辅音的比例关系，从而开始学会一些简单词的表述（如 the、it、a、good），开始具有自己的词汇量。这是一个令人着迷的过程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/aea2839c4683d2b648d7c81f3d7175718b13b186"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;输入语音片段，预测即将出现的字母，从左到右以时间顺序排列。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相关链接：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650723269&amp;amp;idx=3&amp;amp;sn=0fd9eb3e5d3856401739e1354bf6fd68&amp;amp;chksm=871b17bbb06c9eadba1f78353f5d4a33cc4746750a3d8dec7980ca96d2a34d7e5ea66d160a07&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650723269&amp;amp;idx=3&amp;amp;sn=0fd9eb3e5d3856401739e1354bf6fd68&amp;amp;chksm=871b17bbb06c9eadba1f78353f5d4a33cc4746750a3d8dec7980ca96d2a34d7e5ea66d160a07&amp;amp;scene=21#wechat_redirect" target="_blank"&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;The most cited deep learning papers&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;：https://github.com/terryum/awesome-deep-learning-papers&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Kur：Descriptive Deep Learninghttps://github.com/deepgram/kur&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;KurHub：http://www.kurhub.com/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文链接：http://blog.deepgram.com/how-to-train-baidus-deepspeech-model-with-kur/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Tue, 21 Feb 2017 12:26:02 +0800</pubDate>
    </item>
    <item>
      <title>专栏 | 卷积神经网络简介</title>
      <link>http://www.iwgc.cn/link/</link>
      <description>
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;转自知乎&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;strong&gt;作者：张觉非 阿里巴巴 友盟+&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心经作者授权转载&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://zhuanlan.zhihu.com/p/25249694&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;一、卷积&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们在 2 维上说话。有两个&lt;/span&gt;&lt;img src="http://img04.iwgc.cn/mpimg/cf56dc453b92ceaf1ae6d5227cd87fcdbcf0c32b"/&gt;&lt;span&gt;的函数 f(x,y) 和 g(x,y)。f 和 g 的卷积就是一个新的 &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/cf56dc453b92ceaf1ae6d5227cd87fcdbcf0c32b"/&gt;&lt;span&gt;的函数。通过下式得到：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/ca6dcdf7edaee06e5e4139711407d7532d20403f"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这式子的含义是：遍览从负无穷到正无穷的全部 s 和 t 值，把 g 在 (x-s,y-t) 位置上的值乘上 f 在 (s,t) 位置上的值之后「加和」（积分意义上的加和）到一起，就是 c 在 (x,y) 上的值。说白了卷积就是一种「加权求和」。以 (x,y) 为中心，把 g 距离中心 (-s,-t) 位置上的值乘上 f 在 (s,t) 的值，最后加到一起。把卷积公式写成离散形式就更清楚了：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/8a85dae5f02fdfb809de7ae6b062e5c8be335410"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果 G 表示一幅 100 x 100 大小的灰度图像，G(x,y) 取值 [0,255] 区间内的整数，是图像在 (x,y) 的灰度值。范围外的位置上的 G 值全取 0。令 F 在 s 和 t 取 {-1,0,1} 的时候有值，其他位置全是 0。F 可以看作是一个 3 x 3 的网格。如下图：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/387da2c636f298ee51a335d53d7dc58319d4a7b7"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 1&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;G 每个小格子里的值就是图像在 (x,y) 的灰度值。F 每个小格子里的值就是 F 在 (s,t) 的值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/4376533b5e5d70acbcc556c4f6bfc8517dcc45c4"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 2&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如上图所示，将 F 的中心 (0,0) 对准 G 的 (5,6)。把 F 和 G 对应的 9 个位置上各自的函数值相乘，再将 9 个乘积加在一起，就得到了卷积值 C(5,6)。对 G 的每一个位置求 C 值，就得到了一幅新的图像。其中有两个问题：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="list-style-type: decimal;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如果 F 的所有值之和不等于 1.0，则 C 值有可能不落在 [0,255] 区间内，那就不是一个合法的图像灰度值。所以如果需要让结果是一幅图像，就得将 F 归一化&amp;mdash;&amp;mdash;令它的所有位置之和等于 1.0 ；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;对于 G 边缘上的点，有可能它的周围位置超出了图像边缘。此时可以把图像边缘之外的值当做 0。或者只计算其周围都不超边缘的点的 C。这样计算出来的图像就比原图像小一些。在上例中是小了一圈，如果 F 覆盖范围更大，那么小的圈数更多。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;上述操作其实就是对数字图像进行离散卷积操作，又叫滤波。F 称作卷积核或滤波器。不同的滤波器起不同的作用。想象一下，如果 F 的大小是 3 x 3，每个格子里的值都是 1/9。那么滤波就相当于对原图像每一个点计算它周围 3 x 3 范围内 9 个图像点的灰度平均值。这应该是一种模糊。看看效果：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/2d42eca75096693ee3e713bc4165c8fdc29f411b"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 3&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;左图是 lena 灰度原图。中图用 3 x 3 值都为 1/9 的滤波器去滤，得到一个轻微模糊的图像。模糊程度不高是因为滤波器覆盖范围小。右图选取了 9 x 9 值为 1/81 的滤波器，模糊效果就较明显了。滤波器还有许多其他用处。例如下面这个滤波器：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/33745fffea53568f259e7345a777482d9b7ec50a"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尝试用它来滤 lena 图。注意该滤波器没有归一化（和不是 1.0），故滤出来的值可能不在 [0,255] 之内。通过减去最小值、除以最大／最小值之差、再乘以 255 并取整，把结果值归一到 [0,255] 之内，使之成为一幅灰度图像。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/922804cd2c653b0f6fd474ccff4478180b1d7b9b"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 4&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该滤波器把图像的边缘检测出来了。它就是 Sobel 算子。图像模糊、边缘检测等等都是人们设计出来的、有专门用途的滤波器。如果搞一个 9 x 9 的随机滤波器，会是什么效果呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/1ede2bd2d89f07c08d48da51f3b2dd605615b1a2"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 5&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如上图，效果也类似于模糊。因为把一个像素点的值用它周围 9 x 9 范围的值随机加权求和，相当于「捣浆糊」。但可以看出模糊得并不润滑。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这时我们不禁要想，如果不是由人来设计一个滤波器，而是从一个随机滤波器开始，根据某种目标、用某种方法去逐渐调整它，直到它接近我们想要的样子，可行么？这就是卷积神经网络（Convolutional Neural Network, CNN）的思想了。可调整的滤波器是 CNN 的「卷积」那部分；如何调整滤波器则是 CNN 的「神经网络」那部分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;二、神经网络&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工神经网络（Neural Network, NN）作为一个计算模型，其历史甚至要早于计算机。W.S. McCulloch 和 W. Pitts 在四十年代就提出了人工神经元模型。但是单个人工神经元甚至无法计算异或。人工智能领域的巨擘马文. 明斯基认为这个计算模型是没有前途的。在那时人们已经认识到将多个人工神经元连接成网络就能克服无法计算异或的问题，但是当时没有找到多层人工神经网络的训练方法，以至于人工神经网络模型被压抑多年。直到人们找到了多层人工神经网络的训练方法，人工神经网络才迎来了辉煌。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工神经元就是用一个数学模型简单模拟人的神经细胞。人的神经细胞有多个树突和一个伸长的轴突。一个神经元的轴突连接到其他神经元的树突，并向其传导神经脉冲。一个神经元会根据来自它的若干树突的信号决定是否从其轴突向其他神经元发出神经脉冲。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/744f93d9b7bd7c15002519f6b68ea918bedf7bdf"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 6&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个人工神经元就是对生物神经元的数学建模。见下图。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/b6a5d806304ae4aed3ac3206304736ab36fb5b20"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 7&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/651291b27daf6b8fbfcddbf42f00af5e5d5324d4"/&gt;&lt;span&gt;是人工神经元的输入。a 是人工神经元的输出。人工神经元将输入&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/651291b27daf6b8fbfcddbf42f00af5e5d5324d4"/&gt;&lt;span&gt;加权求和后再加上偏置值 b，最后再施加一个函数 f，即：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/405269b37885368806c6415306557ef40e01857b"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;上式最后是这个式子的向量形式。P 是输入向量，W 是权值向量，b 是偏置值标量。f 称为「激活函数」。激活函数可以采用多种形式。例如 Sigmoid 函数：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/6808b325cfec8126c5d4f9cbae032f5949805c4d"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是单个人工神经元的定义。人工神经网络就是把这样的人工神经元互联成一个网络：一个神经元的输出作为另一个神经元的输入。神经网络可以有多种多样的拓扑结构。其中最简单的就是「多层全连接前向神经网络」。它的输入连接到网络第一层的每个神经元。前一层的每个神经元的输出连接到下一层每个神经元的输入。最后一层神经元的输出就是整个神经网络的输出。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如下图，是一个三层神经网络。它接受 10 个输入，也就是一个 10 元向量。第一层和第二层各有 12 个神经元。最后一层有 6 个神经元。就是说这个神经网络输出一个 6 元向量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/ae0a471aff9e243798bd2d0396e4389f74dcf388"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 8&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;整个神经网络的计算可以用矩阵式给出。我们给出人工神经网络单层的式子。每层的神经元个数不一样，输入／输出维度也就不一样，计算式中的矩阵和向量的行列数也就不一样，但形式是一致的。假设我们考虑的这一层是第 i 层。它接受 m 个输入，拥有 n 个神经元（n 个输出），那么这一层的计算如下式所示：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/e7ece040f06fefe1f4ca273f43bdafa6ab10ca58"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;上标 i 表示第 i 层。是输出向量，n 元，因为第 i 层有 n 个神经元。第 i 层的输入，即第 i-1 层的输出，是 m 元向量。权值矩阵 W 是 n x m 矩阵：n 个神经元，每个神经元有 m 个权值。W 乘以第 i-1 层输出的 m 向量，得到一个 n 向量，加上 n 元偏置向量 b，再对结果的每一个元素施以激活函数 f，最终得到第 i 层的 n 元输出向量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;若不嫌繁琐，可以将第 i-1 层的输出也展开，最终能写出一个巨大的式子。它就是整个全连接前向神经网络的计算式。可以看出整个神经网络其实就是一个向量到向量的函数。至于它是什么函数，就取决于网络拓扑结构和每一个神经元的权值和偏置值。如果随机给出权值和偏置值，那么这个神经网络是无用的。我们想要的是有用的神经网络。它应该表现出我们想要的行为。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;要达到这个目的，首先准备一个从目标函数采样的包含若干「输入－输出对儿」的集合&amp;mdash;&amp;mdash;训练集。把训练集的输入送给神经网络，得到的输出肯定不是正确的输出。因为一开始这个神经网络的行为是随机的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;把一个训练样本输入给神经网络，计算输出与正确输出的（向量）差的模平方（自己与自己的内积）。再把全部 n 个样本的差的模平方求平均，得到 e ：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/99b910739c246c2d20e77f07fb6dec5968190271"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;e 称为均方误差 mse。e 越小则神经网络的输出与正确输出越接近。神经网络的行为就与想要的行为越接近。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目标是使 e 变小。在这里 e 可以看做是全体权值和偏置值的一个函数。这就成为了一个无约束优化问题。如果能找到一个全局最小点，e 值在可接受的范围内，就可以认为这个神经网络训练好了。它能够很好地拟合目标函数。这里待优化的函数也可以是 mse 外的其他函数，统称 Cost Function，都可以用 e 表示。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;经典的神经网络的训练算法是反向传播算法（Back Propagation, BP）。BP 算法属于优化理论中的梯度下降法（Gradient Descend）。将误差 e 作为全部权值和全部偏置值的函数。算法的目的是在自变量空间内找到 e 的全局极小点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先随机初始化全体权值和全体偏置值，之后在自变量空间中沿误差函数 e 在该点的梯度方向的反方向（该方向上方向导数最小，函数值下降最快）前进一个步长。步长称为学习速率（Learning Rate, LR）。如此反复迭代，最终（至少是期望）解运动到误差曲面的全局最小点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下图是用 matlab 训练一个极简单的神经网络。它只有单输入单输出。输入层有两个神经元，输出层有一个神经元。整个网络有 4 个权值加 3 个偏置。图中展示了固定其他权值，只把第一层第一个神经元的权值&lt;/span&gt;&lt;img src="http://img03.iwgc.cn/mpimg/181179dc12e22c6af7189a1dd03a9a531f3c4c96"/&gt;&lt;span&gt;和偏置&lt;/span&gt;&lt;img src="http://img03.iwgc.cn/mpimg/4f1d699233cf032ff30868562d758a25b41c17e8"/&gt;&lt;span&gt;做自变量时候的 e 曲面，以及随着算法迭代，解的运动轨迹。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/0a9d3914d306036f3496d3e652898732728ca1ba"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 9&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最终算法没有收敛到全局最优解（红 +）。但是解已经运动到了一个峡谷的底部。由于底部过于平缓，解「走不动」了。所得解比最优也差不到哪去。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于一个稍复杂的神经网络，e 对权值和偏置值的函数将是一个非常复杂的函数。求梯度需要计算该函数对每一个权值和偏置值的偏导数。所幸的是，每一个权值或偏置值的偏导数公式不会因为这个权值或偏置值距离输出层越远而越复杂。计算过程中有一个中间量&lt;/span&gt;&lt;img src="http://img04.iwgc.cn/mpimg/fa5596c2e0d440f4a8b7c6cccf55668934720464"/&gt;&lt;span&gt;，每层的权值和偏置值的偏导数都可根据后一层的&lt;/span&gt;&lt;img src="http://img05.iwgc.cn/mpimg/93930d127184e32537afc96bd7d221f68861d441"/&gt;&lt;span&gt;以统一形式计算出来。每层再把计算过程中产生的&lt;/span&gt;&lt;img src="http://img04.iwgc.cn/mpimg/fa5596c2e0d440f4a8b7c6cccf55668934720464"/&gt;&lt;span&gt;传递给前一层。这就是「反向传播」名称的由来&amp;mdash;&amp;mdash;&lt;/span&gt;&lt;img src="http://img03.iwgc.cn/mpimg/b238a668613c86a76cf7047972f818ca2b7a56ac"/&gt;&lt;span&gt;沿着反向向前传。这与计算网络输出时，计算结果向后传相反。如此可逐层计算出全部权值和偏置值的偏导数，得到梯度。具体推导这里不给出了，可以参考［1］第八章和［2］第十一章。正是反向传播能够让我们训练神经网络「深处」的参数，这就是「Deep Learning」的含义。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;梯度下降法有很多变体。通过调整学习速率 LR 可以提高收敛速度；通过增加冲量可以避免解陷入局部最优点。还可以每一次不计算全部样本的 e，而是随机取一部分样本，根据它们的 e 更新权值。这样可以减少计算量。梯度下降是基于误差函数的一阶性质。还有其他方法基于二阶性质进行优化，比如共轭法、牛顿法等等。优化作为一门应用数学学科，是机器学习的一个重要理论基础，在理论和实现上均有众多结论和方法。参考［1］。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;三、卷积神经网络&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在把卷积滤波器和神经网络两个思想结合起来。卷积滤波器无非就是一套权值。而神经网络也可以有（除全连接外的）其它拓扑结构。可以构造如下图所示意的神经网络：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/6639ed96fa7c61be9b51c3780aef1fc7d965b63c"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 10&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该神经网络接受&lt;/span&gt;&lt;img src="http://img04.iwgc.cn/mpimg/c6f55b70e561370cbbaf9b0db2a7f7cf5bcd2345"/&gt;&lt;span&gt;个输入，产生&lt;/span&gt;&lt;img src="http://img05.iwgc.cn/mpimg/c6f55b70e561370cbbaf9b0db2a7f7cf5bcd2345"/&gt;&lt;span&gt;个输出。图中左边的平面包含 n x n 个格子，每个格子中是一个 [0,255] 的整数值。它就是输入图像，也是这个神经网络的输入。右边的平面也是 n x n 个格子，每个格子是一个神经元。每个神经元根据二维位置关系连接到输入上它周围 3 x 3 范围内的值。每个连接有一个权值。所有神经元都如此连接（图中只画了一个，出了输入图像边缘的连接就认为连接到常数 0）。右边层的&lt;/span&gt;&lt;img src="http://img04.iwgc.cn/mpimg/c6f55b70e561370cbbaf9b0db2a7f7cf5bcd2345"/&gt;&lt;span&gt;个神经元的输出就是该神经网络的输出。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个网络有两点与全连接神经网络不同。首先它不是全连接的。右层的神经元并非连接上全部输入，而是只连接了一部分。这里的一部分就是输入图像的一个局部区域。我们常听说 CNN 能够把握图像局部特征、AlphaGO 从棋局局部状态提取信息等等，就是这个意思。这样一来权值少了很多，因为连接就少了。权值其实还更少，因为每一个神经元的 9 个权值都是和其他神经元共享的。全部&lt;/span&gt;&lt;img src="http://img03.iwgc.cn/mpimg/c6f55b70e561370cbbaf9b0db2a7f7cf5bcd2345"/&gt;&lt;span&gt;个神经元都用这共同的一组 9 个权值，并且不要偏置值。那么这个神经网络其实一共只有 9 个参数需要调整。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;看了第一节的同学们都看出来了，这个神经网络不就是一个卷积滤波器么？只不过卷积核的参数未定，需要我们去训练&amp;mdash;&amp;mdash;它是一个「可训练滤波器」。这个神经网络就已经是一个拓扑结构特别简单的 CNN 了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;试着用 Sobel 算子滤出来的图片作为目标值去训练这个神经网络。给网络的输入是灰度 lena 图，正确输出是经过 Sobel 算子滤波的 lena 图，见图 4。这唯一的一对输入输出图片就构成了训练集。网络权值随机初始化，训练 2000 轮。如下图：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;img src="http://img03.iwgc.cn/mpimg/4f40bab43b22247d6e134810a4a174df92666f2b"/&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 11&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从左上到右下依次为：初始随机滤波器输出、每个 200 轮训练后的滤波器输出（10 幅）、最后一幅是 Sobel 算子的输出，也就是用作训练的目标图像。可以看到经过最初 200 轮后，神经网络的输出就已经和 Sobel 算子的输出看不出什么差别了。后面那些轮的输出基本一样。输入与输出的均方误差 mse 随着训练轮次的变化如下图：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/7687b79d3e22a560efbbf54480cd66678444fb20"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 12&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1500 轮过后，mse 基本就是 0 了。训练完成后网络的权值是：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/cf7fc93ce30a2c625abf7146f02ac18a7687ab25"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;与 Sobel 算子比较一下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/7103c31c34c73b7e29acbea797649acbc5ee5792"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;注意训练出来的滤波器负数列在右侧而不是左侧。因为用 Sobel 算子算卷积的时候也许库函数（scipy.ndimage.filters.convolve）是把滤波器「反着扣上去」的。这并不重要。关键是一正列、一负列，中间零值列。正／负列值之比近似 1:2:1。它就是近似的 Sobel 算子。我们以训练神经网络的方式把一个随机滤波器训练成了 Sobel 算子。这就是优化的魔力。AlphaGO 之神奇的核心也在于此&amp;mdash;&amp;mdash;优化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 CNN 中，这样的滤波器层叫做卷积层。一个卷积层可以有多个滤波器，每一个叫做一个 channel，或者叫做一个 feature map。可以给卷积层的输出施加某个激活函数：Sigmoid 、Tanh 等等。激活函数也构成 CNN 的一层&amp;mdash;&amp;mdash;激活层，这样的层没有可训练的参数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;还有一种层叫做 Pooling 层（采样层）。它也没有参数，起到降维的作用。将输入切分成不重叠的一些 n x n 区域。每一个区域就包含&lt;/span&gt;&lt;img src="http://img05.iwgc.cn/mpimg/c6f55b70e561370cbbaf9b0db2a7f7cf5bcd2345"/&gt;&lt;span&gt;个值。从这&lt;/span&gt;&lt;img src="http://img04.iwgc.cn/mpimg/c6f55b70e561370cbbaf9b0db2a7f7cf5bcd2345"/&gt;&lt;span&gt;个值计算出一个值。计算方法可以是求平均、取最大 max 等等。假设 n=2，那么 4 个输入变成一个输出。输出图像就是输入图像的 1/4 大小。若把 2 维的层展平成一维向量，后面可再连接一个全连接前向神经网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过把这些组件进行组合就得到了一个 CNN。它直接以原始图像为输入，以最终的回归或分类问题的结论为输出，内部兼有滤波图像处理和函数拟合，所有参数放在一起训练。这就是卷积神经网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;四、举个栗子&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;br&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;手写数字识别。数据集中一共有 42000 个 28 x 28 的手写数字灰度图片。十个数字（0～9）的样本数量大致相等。下图展示其中一部分（前 100 个）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/5929ceb7971f3a6048b89b3ae0c74911d9645dea"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 13&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;将样本集合的 75% 用作训练，剩下的 25% 用作测试。构造一个结构如下图的 CNN ：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/3a810135a7c64256bcf1f65f1cdcb362980d589a"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 14&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该 CNN 共有 8 层（不包括输入层）。它接受 784 元向量作为输入，就是一幅 28 x 28 的灰度图片。这里没有将图片变形成 28 x 28 再输入，因为在 CNN 的第一层放了一个 reshape 层，它将 784 元的输入向量变形成 1 x 28 x 28 的阵列。最开始那个 1 x 表示只有一个 channel，因为这是灰度图像，并没有 RGB 三个 channel。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;接下来放一个卷积层。它包含 32 个滤波器，所以它的输出维度是 32 x 28 x 28。32 个滤波器搞出来 32 幅图像（channel），每个都是 28 x 28 大小。后面又是一个 32 个滤波器的卷积层，输出维度也是 32 x 28 x 28。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;后面接上一个 Pooling 层，降降维。一个 2 x 2 的取平均值 Pooling 层，把输出维度减小了一半：32 x 14 x 14。接着是一个展平层，没有运算也没有参数，只变化一下数据形状：把 32 x 14 x 14 展平成了 6272 元向量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该 6272 元向量送给后面一个三层的全连接神经网络。该网络的神经元个数是 1000 x 1000 x 10。两个隐藏层各有 1000 个神经元，最后的输出层有 10 个神经元，代表 10 个数字。假如第六个输出为 1，其余输出为 0，就表示网络判定这个手写数字为「5」（数字「0」占第一个输出，所以「5」占第六个输出）。数字「5」就编码成了：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/fa985eb424ab13125f7e3b3347666e9ea173a7b6"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;训练集和测试集的数字标签都这么编码（one-hot 编码）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;全连接神经网络这部分的激活函数都采用了 Sigmoid。这出于我一个过时且肤浅的理解：用「弯弯绕」较多的 Sigmoid 给网络贡献非线性。实际上当代深度学习从生物神经的行为中得到启发，设计了其它一些表现优异的激活函数，比如单边线性 Relu。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;误差函数采用均方误差 mse。优化算法采用 rmsprop，这是梯度下降的一个变体。它动态调整学习速率 LR。训练过程持续 10 轮。注意这里 10 轮不是指当前解在解空间只运动 10 步。一轮是指全部 31500 个训练样本都送进网络迭代一次。每次权值更新以 32 个样本为一个 batch 提交给算法。下图展示了随着训练，mse 的下降情况：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/406b187881d6efef7f862ea3e38d3457ea8bf38e"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 15&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下图是分类正确率随着训练的变化情况：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/7be4d48aefb0b5245dbcdb3e1bf5ad8d9af07a89"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图16&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该 CNN 在测试集上的正确率（accuracy）是 96.7%，各数字的准确率 / 召回率 / f1-score 如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/3ec242826c6e5953cd6e0611226dbf7742ee5f58"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该 CNN 对测试集 10 种数字分类的混淆矩阵为：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/ca9050aca19ebd15cc721777b254eeae2399d8a0"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图17&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;训练完成神经网络后，最有趣的是将其内部权值以某种方式展现出来。看着那些神秘的、不明所以的连接强度最后竟产生表观上有意义的行为，不由让我们联想起大脑中的神经元连接竟构成了我们的记忆、人格、情感 ... 引人遐思。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 CNN 上就更适合做这种事情。因为卷积层训练出来的是滤波器。用这些滤波器把输入图像滤一滤，看看 CNN 到底「看到」了什么。下图用第一、二卷积层的 32 个滤波器滤了图 13 第 8 行第 8 列的那个手写数字「6」。32 个 channel 显示如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/14e080aebef72f2a472355808c88d88e57a6437a"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 18&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/6b33454935b8181dd3d7f976fa64c7d576d4bd4f"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 19&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中有些把边缘高亮（输出值较大），有些把「6」的圈圈高亮，等等。这些就是 CNN 第一步滤波后「看到」的信息。再经过后面的各神经层，抽象程度逐层提高，它就这样「认出」了手写数字。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后把代码附上。CNN 使用的是 keras 库。数据集来自 kaggle ：https://www.kaggle.com/c/digit-recognizer/data。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;import pandas as pd&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;from keras.models import Sequential&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;from keras.layers import Dense, Flatten, Reshape, AveragePooling2D, Convolution2D&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;from keras.utils.np_utils import to_categorical&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;from keras.utils.visualize_util import plot&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;from keras.callbacks import Callback&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;from sklearn.model_selection import train_test_split&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;from sklearn.metrics import classification_report, accuracy_score, confusion_matrix&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;class LossHistory(Callback):&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;def __init__(self):&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;Callback.__init__(self)&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;self.losses = []&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;self.accuracies = []&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;def on_train_begin(self, logs=None):&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;pass&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;def on_batch_end(self, batch, logs=None):&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;self.losses.append(logs.get('loss'))&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;self.accuracies.append(logs.get('acc'))&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;history = LossHistory()&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;data = pd.read_csv("train.csv")&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;digits = data[data.columns.values[1:]].values&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;labels = data.label.values&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;train_digits, test_digits, train_labels, test_labels = train_test_split(digits, labels)&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;train_labels_one_hot = to_categorical(train_labels)&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;test_labels_one_hot = to_categorical(test_labels)&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;model = Sequential()&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;model.add(Reshape(target_shape=(1, 28, 28), input_shape=(784,)))&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;model.add(Convolution2D(nb_filter=32, nb_row=3, nb_col=3, dim_ordering="th", border_mode="same", bias=False, init="uniform"))&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;model.add(Convolution2D(nb_filter=32, nb_row=3, nb_col=3, dim_ordering="th", border_mode="same", bias=False, init="uniform"))&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;model.add(AveragePooling2D(pool_size=(2, 2), dim_ordering="th"))&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;model.add(Flatten())&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;model.add(Dense(output_dim=1000, activation="sigmoid"))&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;model.add(Dense(output_dim=1000, activation="sigmoid"))&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;model.add(Dense(output_dim=10, activation="sigmoid"))&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;with open("digits_model.json", "w") as f:&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;f.write(model.to_json())&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;plot(model, to_file="digits_model.png", show_shapes=True)&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;model.compile(loss="mse", optimizer="rmsprop", metrics=["accuracy"])&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;model.fit(train_digits, train_labels_one_hot, batch_size=32, nb_epoch=10, callbacks=[history])&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;model.save_weights("digits_model_weights.hdf5")&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;predict_labels = model.predict_classes(test_digits)&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;print(classification_report(test_labels, predict_labels))&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;print(accuracy_score(test_labels, predict_labels))&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;print(confusion_matrix(test_labels, predict_labels))&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;五、参考书目&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;［1］《最优化导论》（美）Edwin K. P. Chong（美）Stanislaw H. Zak&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;［2］《神经网络设计》（美）Martin T.Hagan（美）Howard B.Demuth（美）Mark Beale&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&amp;copy;本文为机器之心转载文章，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Tue, 21 Feb 2017 12:26:02 +0800</pubDate>
    </item>
    <item>
      <title>业界 | Bot完全指南：从与机器人平台的区别到知名框架</title>
      <link>http://www.iwgc.cn/link/</link>
      <description>
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自marutitech&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：赵华龙、黄小天&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote style="color: rgb(62, 62, 62); font-size: 16px; white-space: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;今年聊天机器人备受瞩目。科技巨头诸如 Facebook 和微软已经大规模发布了 Bot 框架，旨在量产聊天机器人。在 Facebook Messenger 上开发了超过 11,000 个聊天机器人，并且有近 23,000 个开发人员注册了 Facebook 机器人引擎&lt;/span&gt;&lt;span&gt;。此外，大量初创公司拥有自属开发框架和功能性产品。较小的交流平台，如 Telegram 和 Slack，也推出了「机器人商店」（「Bot Stores」），并成立基金吸引开发人员。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;什么是 Bot 框架？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;简单地解释，Bot 框架用来制造机器人并定义其行为。作为聊天机器人开发者，开发和定向如此之多的交流平台与聊天机器人开发 SDKs 常会感到无所适从。Bot 开发框架是这样一种软件框架，它能对聊天机器人开发过程中的人工内容做抽象化处理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而，尽管很多 Bot 开发框架宣称「代码一旦写好可部署到任何地方」，你还是很可能为你的每一个目标交流平台开发一个单独的聊天机器人。Bot 开发框架包括机器人制造者 SDK（Bot Builder SDK）、机器人连接器（Bot Connector）、开发者入口（Developer Portal）、机器人目录（Bot Directory）以及一个用来测试已开发机器人的模拟器。此外，Bot 框架并不适合初学者用来学习聊天机器人开发。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;机器人框架与机器人平台的差别？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Bot 框架（Bot Framework）有时错误地与 Bot 平台（「Bot Platform」）通用。在开发应用程序时，Bot 平台的作用是提供部署和运行应用程序的，Bot 框架的作用是开发和绑定各种组件到应用程序。Bot 平台是在线生态系统，其中聊天机器人可以被部署并与用户进行交互，代表用户执行操作，包括与其他平台交互。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Bot 开发框架是一组预定义函数和开发人员用来加快开发的类，一组可以使你更快更好编码的工具。简单来说，初学者或非技术用户可以用 Bot 平台来开发不需要写代码的机器人，而 Bot 开发框架则被开发人员和码农借助编程语言从头开始构建机器人。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;例如 Bot 平台 Motion.ai 可使用户无需编码便能快速创建强大的机器人。原因在于 Motion.ai 提供了一个能创建聊天机器人的工具包，使得机器人可与 APIs 相连并部署到任何一个可用的交流平台。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/ab3aec8562b2838068f525787602d85b3f415ccf"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;一些著名的 Bot 框架&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Facebook bot 引擎&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2016 年 4 月，Facebook 实现了基于 Wit.ai 技术的 Facebook Bot 引擎。Wit.ai 在自己的云服务器运行，Bot 引擎是一个包装器，用于在 Facebook Messenger 平台上部署机器人。Facebook 作为社交巨头的力量在于海量用户，因此他们不需要任何其他的 Bot 开发平台，并且聊天机器人将仅限于 Facebook Messenger（其本身即是一个巨大的空间）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Facebook 正在为 Facebook Bot 引擎采用一种新策略。如果开发人员获得框架，Facebook Messenger 用户将享有各种专业聊天机器人&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Facebook Bot 引擎依赖于机器学习。提供 Bot 框架示例对话之后，它可以处理同一问题的很多不同变体。随着开发人员不断完善聊天机器人，它们的潜力也会越来越巨大。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Wit.ai 提供一些选项：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1.它能提取出一些预定义的实体，比如时间、日期等等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2.提取用户的意图。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 提取情绪。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4. 它可进行自我定义和提取。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;微软 Bot 框架&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微软几乎与 Facebook 同时宣布了其 Bot 框架。尽管微软的哲学和方法有点不同。就像 Facebook 的产品一样，微软的 SDK 可以被看作是 2 个彼此独立的组件。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. Bot 连接器，集成框架&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. LUIS.ai，自然语言理解组件&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微软 Bot 框架的集成组件适用于 Slack、Facebook Messenger、Telegram、Webchat、GroupMe、SMS、电子邮件和 Skype，令人印象深刻。此外，Azure 上有一个 PaaS 选项，就是用于 Bots。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微软 Bot 框架是一个全面的产品，用于构建和部署高质量的聊天机器人供用户享受最喜欢的对话体验。机器人开发人员都面临着同样的问题：机器人需要基本的输入和输出；它们必须具备语言和会话能力；机器人必须具有高性能，响应性和可扩展性；并且它们必须能够向用户提供理想的对话体验。微软 Bot 框架提供了我们构建，连接，管理和发布智能聊天机器人所需要的一切，无论是通过文字/SMS，还是其他平台诸如 Slack、Skype、 Facebook Messenger、Kik 等，聊天机器人都可以和用户自然地交流。微软 Bot 框架由许多组件组成，包括 Bot 创建者 SDK（Bot Builder SDK）、开发人员门户（Developer Portal）和 Bot 目录（Bot Directory）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;API.ai&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;API.ai 是另一个基于 Web 的 bot 开发框架。API.ai 似乎已经发现了让用户通过输入多个话语来定义实体和意图的缺陷，并因此提供了一个巨大的领域集（a huge set of domains）。API.ai 为 bot 开发提供的一些 SDK 和库，包括 Android、iOS、Webkit HTML5、JavaScript、Node.js、Python 等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;API.ai 建立在如下几个概念上：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1.代理器：代理器对应于应用。一旦我们训练并测试一个代理器，我们就可以把它集成到我们的 app 或设备中去。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2.实体：实体表示那些通常专用于某一领域的概念，作为将 NLP（自然语言处理）短语映射到捕获其含义的批准短语的方式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3.意图：意图表示用户说什么和软件需要采取什么动作之间的映射。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4.动作：动作对应于您的应用在用户的输入触发特定的意图时所采取的步骤。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;5.上下文：上下文是表示用户表达的当前上下文的字符串。这对于区分可能是不明确的并且因取决于前面的话而具有不同含义的短语是有用的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;API.ai 能被集成在很多流行的交流平台、物联网和虚拟个人助理平台。它们中的一些包括 Actions on Google、Slack、Facebook Messenger、Skype、Kik、Line、Telegram、Amazon Alexa、Twilio SMS 和 Twitter 等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Aspect CXP 和 Aspect NLU&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Aspect 客户体验平台（CXP）是设计，实施和部署多渠道客户服务应用程序的平台。Aspect NLU 是一个给出人类语言感觉的组件，其采用的方法与 Wit.ai、API.ai 和微软 Bot 框架完全不同，并能为 Facebook Messenger 上的自助服务对话带来人性化的交谈口吻。这使它能够通过自动化以聊天机器人特有的方式进行扩展。Aspect CXP 使得设计、实现和在多种交流渠道（诸如文本、语音、移动网、社交网络）部署聊天机器人变得容易起来。这很适合那些需要复杂聊天机器人、客服应用和企业软件的地方；不太适合对简单机器人、嵌入式应用和物联网应用的需求。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些是市场上可用的、开发人员构建机器人的 Bot 框架。如果你的组织要花费大量的金钱和时间与客户交流，你可以尝试建立一个机器人来处理这种情况。对话用户界面的时代（The era of Conversational User Interfaces）已经到来，成为掌握趋势的先行者之一吧。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文链接：&lt;/span&gt;&lt;/em&gt;&lt;em&gt;&lt;span&gt;http://www.marutitech.com/complete-guide-bot-frameworks/?utm_content=buffer9b406&amp;amp;utm_medium=social&amp;amp;utm_source=twitter.com&amp;amp;utm_campaign=buffer&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Tue, 21 Feb 2017 12:26:02 +0800</pubDate>
    </item>
  </channel>
</rss>
