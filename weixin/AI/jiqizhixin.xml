<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>FPGA 2017最佳论文出炉：深鉴科技ESE语音识别引擎获奖（附解读）</title>
      <link>http://www.iwgc.cn/link/</link>
      <description>
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;font color="#ffffff"&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/font&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：姚颂、韩松&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote style="color: rgb(62, 62, 62); font-size: 16px; white-space: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/blockquote&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;FPGA 芯片领域顶级会议 FPGA 2017 于 2 月 24 日在加州 Monterey 结束。在本次大会上，斯坦福大学在读 PhD、深鉴科技联合创始人韩松等作者的论文 ESE: Efficient Speech Recognition Engine with Sparse LSTM on FPGA 获得了大会最佳论文奖。得知此消息后，机器之心对深鉴科技科技创始人兼 CEO 姚颂与联合创始人韩松（本论文的第一作者）进行了联系，他们对该文章进行了技术解读。可点击阅读原文下载此论文。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/790a23ccaf77f01dcba9b345d1d0b5c389b6b6bc"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;span&gt;韩松在&lt;span&gt;FPGA'17&lt;/span&gt;会场讲解&amp;nbsp;&lt;span&gt;ESE&amp;nbsp;&lt;/span&gt;硬件架构&lt;/span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;FPGA 领域顶级会议 FPGA 2017 于 2 月 24 日在加州 Monterey 结束。在本次大会上，深鉴科技论文《ESE: Efficient Speech Recognition Engine with Sparse LSTM on FPGA》获得了大会最佳论文奖（Best Paper Award）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/00ce5a52362f2e052e6b864ba62fbb827121902f"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;图1:韩松提出的深度学习部署方案。跟传统的「训完即用」的方案相比，「训练后经过压缩再用硬件加速推理」的方案，可以使得推理更快、能耗更低。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该项工作聚焦于使用 LSTM 进行语音识别的场景，结合深度压缩（Deep Compression）、专用编译器以及 ESE 专用处理器架构，在中端的 FPGA 上即可取得比 Pascal Titan X GPU 高 3 倍的性能，并将功耗降低 3.5 倍。而此前，本文还曾获得 2016 年 NIPS Workshop on Efficient Method for Deep Neural Network 的最佳论文提名。据悉，本文所描述的 ESE 语音识别引擎，也是深鉴科技 RNN 处理器产品的原型。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/7d639da2d903798ba22de0c7947cf85294df9194"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 2：ESE 语音识别引擎工作全流程&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;LSTM 全称为 Long-Short Term Memory，&lt;/span&gt;&lt;span&gt;在语音识别、机器翻译、&lt;/span&gt;&lt;span&gt;Image Captioning&lt;/span&gt;&lt;span&gt;中有较多的应用。对于语音识别而言，LSTM 是其中最重要一环，也是计算耗时最多的一环，通常占到整个语音识别流程时间的 90% 以上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/a85e72b0b2c3bdf1ff700c88c9682dbd5f26c8cd"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 3：LSTM 在语音识别中的位置&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Deep Compression 算法可以将 LSTM 压缩 20 倍以上。但在以往的纯算法压缩上，并没有考虑多核并行时的负载均衡，这样在实际运行时，实际的运行性能被负载最大的核所限制。本文提出了一种新的 Load Balance Aware Pruning，在稀疏化时保证剪枝后分配到每个核的计算量类似，从而进一步加速的计算。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/e76b0f787bfca4800b28a021214ff2ee333835ca"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 4：Load-Balance-Aware Pruning示意：保证稀疏性的同时保证多核负载均衡&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;结合新的模型压缩算法以及 ESE 专用处理架构，在一个可实际使用的 LSTM 模型上测试，相同情况下，深鉴基于中等 FPGA 平台的耗时为 82.7us，功耗为 41W；而 Pascal Titan X GPU 则需要 287.4us 的运行时间，并且耗能 135W。这也再次证明了稀疏化路线的作用：在价格、资源全面弱于 GPU 的专用硬件上，通过算法与硬件的协同优化，的确可以取得更好的深度学习运算能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深鉴科技成立于 2016 年 3 月，&lt;/span&gt;&lt;span&gt;创始成员来自清华大学和斯坦福大学&lt;/span&gt;&lt;span&gt;，公司致力于结合深度压缩与深度学习专用处理架构，提供更高效与便捷的深度学习平台。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;公司聚焦于稀疏化神经网络处理得技术路线，提出的 Deep Compression 算法可以将模型尺寸压缩数十倍大小而不损失预测精度，并结合专用的深度学习处理架构来实现加速。而 ICLR 2016 和 FPGA 2017 两篇最佳论文的获奖，也证实深鉴科技所聚焦的稀疏化路线越来越得到深度学习界的关注。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;论文：ESE: Efficient Speech Recognition Engine with Sparse LSTM on FPGA&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/cb50a6068739d10c32178609f60c4beab348c211"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：长短期记忆网络（LSTM）被广泛用于语音识别领域。为实现更高的预测精度，机器学习研究者们构建了越来越大的模型。然而这样的模型十分耗费计算和存储资源。部署此类笨重的模型会带数据中心来很高的功耗，从而带来很高的总拥有成本（TCO）。为了增加预测速度，提高能源效率，我们首次提出了一种可以在几乎没有预测精度损失的情况下将 LSTM 模型的尺寸压缩 20 倍（10 倍来自剪枝和 2 倍来自量化）的负载平衡感知剪枝（load-balance-aware pruning）方法。这种剪枝后的模型对并行计算很友好。另外，我们提出了可以对压缩模型进行编码和分割成 PE 以进行并行化的调度器（scheduler），并编排了其复杂的 LSTM 数据流。最后，我们设计了一种可以直接在这种压缩模型上工作的硬件框架&amp;mdash;&amp;mdash;Efficient Speech Recognition Engine (ESE)。该框架使用了运行频率为 200 MHz 的 Xilinx XCKU060 FPGA，具有以 282 GOPS 的速度直接运行压缩 LSTM 网络的性能，相当于在未压缩 LSTM 网络上 2.52 TOPS 的速度；此外，该框架执行一个用于语音识别任务的全 LSTM 仅需 41 W 功耗。在基于 LSTM 的语音基准测试中，ESE 的速度为英特尔 Core i7 5930k CPU 的 43 倍，英伟达 Pascal Titan X GPU 的 3 倍。它的能量效率分别为以上两种处理器的 40 倍和 11.5 倍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&amp;copy;本文为机器之心原创，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Sat, 25 Feb 2017 15:24:24 +0800</pubDate>
    </item>
    <item>
      <title>特写 | 探访Facebook应用机器学习团队：如何构建研究与应用之间的桥梁？</title>
      <link>http://www.iwgc.cn/link/</link>
      <description>
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自BackChannel&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Steven Levy&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote style="color: rgb(62, 62, 62); font-size: 16px; white-space: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/blockquote&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;在 Facebook，应用机器学习（Applied Machine Learning）团队正在帮助这家社交网络公司看见、说话和理解，他们甚至可能会帮助根除假消息。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/b00768c6004582381915d7918cd8a4a3a7740754"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Joaquin Candela，Facebook 应用机器学习团队工程开发主管&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当被要求领导 Facebook 的应用机器学习团队来推动这个世界上最大的社交网络全面进军人工智能时，Joaquin Qui&amp;ntilde;onero Candela 犹豫了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;原因倒不是因为这个西班牙出生的、自称「机器学习（ML）人」的科学家的还没见证过人工智能帮助 Facebook 的方式。实际上，自从 2012 年加入该公司之后，他就一直在监管该公司广告运行的转型&amp;mdash;&amp;mdash;使用机器学习方法来使受赞助的帖子更相关和更高效。值得注意的是，他是通过让其团队中的工程师都使用人工智能而完成的，尽管他们中有一些人之前并未接受过相关的训练，但最后他成功让广告部门的机器学习技能变得丰富了起来。但他并不确定同样的魔法是否能在 Facebook 整个公司的更大疆土上起效，这里有十几亿人连接在一起，而连接所基于的价值却远比衡量广告的硬数据更模糊。对于这次升职，他评论说：「我需要确信这么做是有价值的。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管有这样的怀疑，但 Candela 还是接受了这个职位。而现在，还不到两年的时间，他的犹豫看起来却像是很荒唐的一件事。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有多荒唐？上个月，Candela 在纽约一场大会上对在场的工程师讲了话。「我要做出一个非常明确的声明。」他警告说：「没有人工智能，今天的 Facebook 就不会存在。每天你使用 Facebook 或 Instagram 或 Messenger 的时候，你可能没有意识到，但你的体验之下都是人工智能在驱动。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;去年 11 月，为了采访 Candela 和他团队的一些成员，我拜访了 Facebook 位于 Menlo Park 的巨型总部，所以我可以看到人工智能是如何突然就变成了 Facebook 的「氧气」的。到目前为止，人们对 Facebook 在人工智能领域的关注都主要还是集中在其世界级的 Facebook 人工智能研究团队（FAIR/Facebook Artificial Intelligence Research）&amp;mdash;&amp;mdash;该团队的领导者是大名鼎鼎的神经网络专家 Yann LeCun。FAIR 以及谷歌、微软、百度、亚马逊和苹果（这家善于保密的公司现在已经允许其研究者发表论文了）的相应机构是人工智能领域的毕业生精英最偏爱的目标选择。这些机构是脑启发数字神经网络领域重大突破的顶级生产者，是近来计算机科学领域发展的主要推动力&amp;mdash;&amp;mdash;让计算机具备了看见、听懂甚至交谈的能力。而 Candela 的应用机器学习团队（AML/Applied Machine Learning）的任务是将 FAIR 与其它前沿研究机构的研究成果整合到 Facebook 实际的产品中&amp;mdash;&amp;mdash;而也许更重要的是，助力该公司所有的工程师将机器学习整合到他们的工作中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因为没有人工智能，Facebook 就无法生存，所以它需要其所有的工程师都能用人工智能来进行开发。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我的拜访是在美国总统大选之后两天进行的，而在一天之前，Facebook 的 CEO Mark Zuckerberg 曾表示：「Facebook 上虚假新闻的流通有助于 Donald Trump 赢得大选」是个「疯狂的看法（it's crazy）」。这么评价就好比是说：认为 Facebook 是 News Feed 上虚假信息疯狂传播的共犯就像是说驾驶一辆油罐车冲向一团不断蔓延的凶猛大火。尽管这些争议中很多不是 Candela 职业之内的事情，但他知道 Facebook 对虚假新闻的最终回应将会依靠有他的团队所参与的机器学习工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但为了减轻我们采访过程中坐在我们旁边的公关人员所带来的压力，Candela 向我们展示了一些其它东西&amp;mdash;&amp;mdash;一个展示他们团队的成果的演示。让我惊讶的是，这看起来像是一个微不足道的小玩意：它以一位风格独特的画家的杰作的风格来重新绘制一张照片或一段视频流。事实上，它让我联想到了你可以在 Snapchat 上看到的数字特效，而且这种将照片转换成毕加索的立体主义风格的点子之前已经被实现了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「这背后的技术叫做神经风格迁移（neural style transfer），」他解释说，「需要训练一个大型神经网络来使用一种特定的风格来重新描绘一张原始照片。」他拿出他的手机拍了一张照片。一次点击和滑动之后，它变成了梵高的《The Starry Night》风格。更惊人的是，它可以风格渲染正在播放中的视频流。但他说，真正的不同之处在于一些我无法用眼睛看见的东西：Facebook 已经构建了可以使其在手机上工作的神经网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这同样并不新鲜&amp;mdash;&amp;mdash;苹果之前就吹嘘过自己在 iPhone 上执行过一些神经计算。但对 Facebook 来说，这项任务却难得多。因为它并不生产硬件。Candela 说他能执行这个小应用是多亏了该团队的工作积累的成果&amp;mdash;&amp;mdash;一个项目会让另一个项目更简单，综合起来可以让未来的工程师无需接受太多培训就能开发出类似的产品&amp;mdash;&amp;mdash;从而使得这样的东西可以被快速地开发出来。他说：「从开始开发这个到我们把这个成果投入公开测试，我们用去了八周时间，这是相当疯狂的。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/f26bd5b5dae16039d9b1f4c2a86432538263d842"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;从左到右）AML 工程总监 Joaquin Candela；应用计算机视觉团队负责人 Manohar Paluri;技术产品经理 Rita Aquino；工程经理 Rajen Subba&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他说，完成这样的任务的另一个秘密是协作（collaboration），这也是 Facebook 公司文化的砥柱。在这个案例中，Facebook 内部团队间的轻松可接触性使得从数据中心的图像渲染可跳跃到手机端实现该工作，尤其是移动团队密切熟悉手机硬件。这种好处不只是让你能够把朋友或亲人的照片做成名画「The Scream」中的女性那种风格的电影。而是让 Facebook 的一切都变得更强大所迈出的一步。短期内，这使得从解析语言和理解文本中得到更快的回应成为了可能。长期而言，它能够使得实时分析听见的和看见的成为可能。他说，「我们说的是秒，或者更短的时间。它必须是实时的。我们是社交网络，如果我们要根据一点内容预测人们的反馈（feedback），我们的系统需要即时作出反应，对吧？」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Candela 看了一眼刚拍的、并转成了梵高绘画风格的自拍照，骄傲溢于言表。他说，「在手机上运行复杂的神经网络，也就是要把人工智能放到每个人的手中。这并非偶然所得，而是 Facebook 内部民主化人工智能的一部分。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「这是一段漫长的旅程。」他补充说。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Candela 出生于西班牙，在他三岁时全家搬迁到了摩洛哥，于是他在那里上法语学校。虽然他的理科和文科成绩都很高，但他决定去马德里上大学，希望在那里学习他认为最难的课题：电信工程&amp;mdash;&amp;mdash;这门不仅需要掌握如天线、放大器等实物的有关知识，也要读得懂数据的「极酷」课程。他被一位解构自适应系统的教授施了魔咒。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Candela 开发了一个使用智能过滤器来改善漫游手机信号的系统；他称其为「一个婴儿神经网络」。2000 年他在丹麦度过了一个学期，那段时间的研究使他对训练算法愈加迷恋，并没有仅仅停留在研究代码的层面。在那里他与 Carl Rasmussen 不期而遇&amp;mdash;&amp;mdash;一位曾与传奇人物 Geoff Hinton（在机器学习领域有「cool kid」之称的机器学习教授）在多伦多共同研究。在临近毕业时，他本打算加入宝洁公司的一项管培计划，但当 Rasmussen 邀请他攻读博士学位时，他选择了机器学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2007 年，他来到英国剑桥的微软研究实验室工作。工作不久，他便得知一个公司内部的竞争：微软即将推出 Bing，但需要改进搜索广告的关键组件&amp;mdash;&amp;mdash;准确地预测用户何时会点击广告。而公司决定开展内部竞争。公司会测试团队的解决方案，以确认是否值得采用，而获胜团队的成员将获得一次免费的夏威夷之旅。19 支队伍进行了比赛，而 Candela 的队伍取得了胜利。他获得了免费旅行的奖励，但他感觉自己受到了欺骗&amp;mdash;&amp;mdash;他认为微软更大的奖赏在于他的成果能在通过测试后成功发布。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Candela 接下来的一系列行为显示了他的决心。为了让公司给他一个机会，他开始了「疯狂远征」。他进行了 50 多次内部会谈，并建立了一个模拟器来显示他的算法的优势；他跟踪了这个有权力做出这个决定的副总裁&amp;mdash;&amp;mdash;在等自助餐的时候站在他旁边，故意和他一起上洗手间，然后在便池那里鼓吹自己的系统；他搬到了这位高管的办公室旁边一块未被使用的地方，然后毫无预警地出现在了这个人的办公室，争辩着「说到就要做到，我的算法更好」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;将自己定位于站在自助餐线的人的身旁并同步化他的浴室之旅，而后从邻近的小便池推荐他的系统；他躲进行政部门附近的闲置空间，并突然出现在行政部门的办公室，争辩着「说到就要做到，我的算法更好」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2009 年，Candela 的算法与 Bing 一同发布。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2012 年初，Candela 拜访了在 Facebook 工作的朋友，周五在位于门洛帕克的园区待了一天。当他发现这家公司的职员不必申求成果的测试权，而是随时都可以测试时，他惊呆了。于是三天后，他去 Facebook 进行了面试，当周的周末便拿到了 offer。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Candela 加入了 Facebook 的广告团队，他的任务是领导一个能够为用户展示相关性更强的广告的团队。尽管当时他们系统确实在使用机器学习，但他说：「我们使用的模型并不高级，它们非常简单」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/5c6503d0f33fbce43a3c8ef08298013495cbd688"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Facebook 20 号楼内部场景。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一位同时加入 Facebook 的工程师是 Hussein Mehanna（他们一起参加了新员工的「代码启动训练营（code boot camp）」），他同样对公司的系统中构建人工智能方面进展的缺乏感到惊讶。Mehanna 说：「当我进入 Facebook 之前，看到产品的质量时，以为所有技术都已经成熟，但很显然不是这样。开始工作的几周内，我告诉 Joaquin：Facebook 真正缺少的是一个合适的世界级机器学习平台。我们有机器，但缺乏能够使其从数据中尽可能学习的合适软件」。（Mehanna 是如今 Facebook 的核心机器学习主任，同样是一个微软老员工&amp;mdash;&amp;mdash;和其他被采访工程师一样。这是巧合吗？）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Mehanna 所说的「机器学习平台」，是指采用大致基于大脑行为方式的模型&amp;mdash;&amp;mdash;这一范式将人工智能从上世纪荒芜的「冬天」（早期实现「会思考的机器」的希望已然渺茫）变成了如今的「百花齐绽」。在广告领域，Facebook 需要它的系统完成一个没人做得到的事情：即时（并准确！）地预测有多少人会点击指定的广告。于是 Candela 和他的团队开始创建一个基于机器学习程序的新系统。由于该团队希望将系统构建为一个所有在该部门工作的工程师都能访问的平台，他们便以一种能使建模和训练被推广与复制的方式来实现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;构建机器学习系统的一个关键因素便是获得高质量数据&amp;mdash;&amp;mdash;越多越好。这恰好是 Facebook 最大的资产之一：当每天有超过十亿人与你的产品交互，便能收集大量的数据作为训练集，并且一旦你开始测试，就能够得到无尽的用户行为实例。因此广告团队能够从几周发布一个新模型转变为每周运送多个模型。另外，因为这将会变为一个允许其他人在内部使用，以构建自己的产品的平台，所以 Candela 确保以多团队参与的方式来完成他的工作。这是一个有条不紊的三步过程。他说：「首先你应专注于性能，而后是效用，最后建立一个社区」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Candela 的广告团队已经证明，机器学习在 Facebook 可以具有多大的变革性。他说：「我们在预测点击次数、点赞、转发次数等方面取得了难以置信的成功」。自然而然，将这种方法向更大型服务推广的想法便产生了。事实上，FAIR 的领导 LeCun 已经在支持一个致力于将人工智能应用到产品中的团队&amp;mdash;&amp;mdash;特别是以一种能够使机器学习向公司内部更广泛传播的方式。LeCun 说：「我确实在努力实现它，因为你需要具有杰出的才能的工程师组织在一起，他们不会直接关注产品，而是注重能够被多种产品使用的基础技术」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2015 年 10 月，Candela 成为新的 AML 团队主管（在一段时间里，出于谨慎，他还保留着在广告部门的职位，两者兼顾）。他与位于纽约、巴黎和门洛帕克的 FAIR 保持着密切联系，那里研究人员与 AML 工程师平起平坐。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个在开发中的产品可以说明这种协作的方式，这个产品为 Facebook 上发布的图片提供语音描述。在过去几年，训练一个系统去识别场景中的物体或者进行基本总结，来判定照片是在室外还是室内拍摄，成为了一种人工智能标准实践应用。不过，最近 FAIR 的科学家已经可以训练神经元网络去识别图像中几乎每一个有意义的物体，并通过物体的位置和与其他物体的关系，来判断照片的内容&amp;mdash;&amp;mdash;通过分析姿势，来判断一张照片里的人在拥抱，或者一个人在骑马。「我们把这个给 AML 的人看了，」LeCun 说，「他们想了一会儿，说『你知道的，这在有些情况下可能会非常有用。』」最终出现的是一个为视力障碍人士准备的一项功能的原型，它可以在视力障碍人士将手指放在图片上时，让手机读出照片的描述。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们一直在交流，」Candela 说起他的兄弟团队（指代 FAIR）。「从更大的层面来说，科学理论到实际的项目，你需要『胶水』，我们就是『胶水』。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Candela 将人工智能的应用分为四个领域：视觉、语言、语音和摄像头效果。他说，所有这些，都会为一个「内容理解引擎」服务。通过掌握理解内容的方法，Facebook 试图检测到评论中的隐含意图、从口语中提取出细微的差别、从视频中识别出你朋友短暂出现的面部，以及理解你的表达，并将其绘制在虚拟现实地图中的图标上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们正在做的是人工智能的泛化，」Candela 说。「随着需要理解、分析的内容量的爆炸，我们生成可判断内容的标签的能力跟不上了。」问题的解决方案，就是开发泛化的系统，这样一个项目的工作成果可以用到其他团队的相关项目上。Candela 说，「开发出可以将知识从一个任务迁移到其他任务的算法，会非常棒，对不对？」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种知识迁移对于 Facebook 产品产出速度意义重大。拿 Instagram 来说。从这个照片服务产品的初始，用户的照片就是时间倒序呈现。不过在 2016 年年初，Instagram 决定使用相关性 sr'fa 排列照片。好消息是，因为 AML 已经在类似 News Feed 这样的产品中应用过了机器学习，「Instagram 不需要从零开始」，Candela 说。「Instagram 有一两个专业的机器学习工程师和数十个其他使用各种排序算法的团队对接。这样，他们就可以复制工作流，并且有问题可以直接沟通。」最终，Instagram 仅用了几个月就完成了这项巨大的产品改动。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于可以将其神经网络的威力与其他团队结合而产出「Facebook 规模」的功能的使用案例，AML 团队时刻准备着。「我们正在使用机器学习技术，来增强我们的核心能力，以取悦我们的用户，」AML 认知团队的带头工程师 Tommer Leyvand 说道。（他来自&amp;hellip;&amp;hellip;嘿嘿&amp;hellip;&amp;hellip;微软。）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/61d5586231d52ffa7ca3a091bec55a753587f860"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Rita Aquino, Facebook 技术产品经理&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个案例就是最近推出的社交推荐功能。一年前。一名 AML 工程师和一个 Facebook 分享团队的产品经理正在讨论一个强社交场景，即用户向朋友要求推荐当地的餐厅或者其他服务。「问题是，怎样将这个功能呈现给用户？」Rita Aquino，AML 的自然语音团队产品经理说道。（她之前也是产品经理，供职于&amp;hellip;&amp;hellip;算了，不说了）分享团队一直在尝试匹配推荐请求的词语。「那种方式并不精确，在一天 10 亿条的消息下，也无法扩大规模，」Aquino 说。通过训练神经网络，并在生活行为模型上测试，团队随后可以监测到非常细微的语言变化，并能准确检测用户是否在询问某个地区内的餐厅或者需要购买鞋子。之后，合适的联系人的 News Feed 上就会出现一条请求。下一步&amp;mdash;&amp;mdash;也由机器学习驱动&amp;mdash;&amp;mdash;判断是否有人提供了合理的推荐，并将商铺或者餐厅的地址，显示在用户的 News Feed 上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Aquino 说，在她为 Facebook 工作的一年半时间里，人工智能从产品中的罕见部分，变成了深植于产品概念中。「大家希望自己交互的产品能够更加聪明，」她说。「很多团队看到了社交推荐这样的产品，看了我们的代码，然后就问『我们怎么实现这种功能？』给你的团队实验这种用户体验，并不需要太多机器学习背景。」就自然语言处理来说，团队开发了一个可供其他团队方便访问的系统，叫做 Deep Text。这个系统可帮助使用 Facebook 翻译功能背后的机器学习技术，每天超过 40 亿条消息都会用到这项技术。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于图像和视频，AML 团队开发了名叫 Lumos 的机器学习视觉平台。该平台始于当时还是 FAIR 实习生的 Manohar Paluri。他当时正在开发一个他称为 Facebook 视觉大脑的大型机器学习视觉项目，这是一个用于处理和理解 Facebook 上发布的所有的图像和视频的工具。2014 年的黑客马拉松上，Paluri 和同事 Nikhil Johri 在一天半的时间里完成了产品的原型，并展示给激动不已的 Zuckerberg 和 Facebook COO Sheryl Sandberg。Candela 创建 AML 后，Paluri 加入了小组，并负责计算机视觉团队，开发 Lumos，帮助所有的 Facebook 工程师（包括 Instagram、Messenger、WhatsApp 以及 Oculus）使用这一视觉大脑。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有了 Lumos，「公司里的任何人都可以使用多个神经网络的功能，为自己的使用场景建立模型，检测效果，」在 AML 和 FAIR 有联合职位的 Paluri 说道。「在工作流程中，其他团队可以有人参与进来，纠正系统、进行再训练，然后上线，这并不需要 AML 团队参与。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Paluri 给我做了一个快速演示，他在他的笔记本上启动 Lumos，我们进行一个样本任务：优化神经网络识别直升机的能力。一个包含图像的网页&amp;mdash;&amp;mdash;如果我们继续刷屏，图像数量将达到 5000 张&amp;mdash;&amp;mdash;出现在屏幕上，充满了直升机的图片，还有一些不是直升机的图片。对于这些数据集（Facebook 使用公开发布的图像），这些图像具有仅限朋友查看或其他分组不受限制的属性。尽管我完全不是一个工程师，更不是人工智能专家，点击负样本以训练直升机图像分类器对我来说并不难，我就像行家一样完成了它。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最终，这种分类步骤&amp;mdash;&amp;mdash;被称为监督学习&amp;mdash;&amp;mdash;可能变得自动化，就像公司追求的机器学习圣杯「无监督学习」那般，神经网络有能力自己找出所有这些图片中都有些什么。Paluri 说：「公司正在取得进展，他说，在下一年我们的目标是把人工标注的数量降低 100 倍。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;长远来看，为了 Candela 所说的通用内容理解引擎（generalized content understanding engine），Facebook 会将视觉皮层与自然语言平台的融合。Paluri 说：「无疑我们最终会把它们结合在一起，接着我们会把它做成皮层（cortex）。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最终，Facebook 希望用于取得进步的核心原理通过论文发表等方式扩展到公司之外，从而使其民主化方法论（democratizing methodology）更广泛地传播机器学习。Mehanna 说：「摈弃花费数年时间努力建构一个智能应用的方式，其实你可以更快地构建应用。想象一下其在医药、安全和交通领域的影响。我认为这些领域应用的构建将快上 100 倍。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/280554584432d237fc32aa375bb3b8939b025c14"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;2017 年 2 月 6 号，Facebook 应用计算机视觉团队负责人 Manohar Paluri 在加利福尼亚 Menlo 公园 20 号楼，照片由 Stephen Lam 拍摄&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管 AML 深度参与了帮助 Facebook 产品能看能听能解释的史诗般进程，扎克伯格也看到其对 Facebook 作为一家社会公益公司的愿景至关重要。在扎克伯格关于构建未来社区的 5700 词的宣言中，他 7 次引用了「人工智能」，并且全部是在机器学习及其他技术如何使未来社区更安全、更加信息化的背景下引用的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;实现这些目标并不容易，相同原因是 Candela 首先担心参加 AML 工作。当你试图连接几十亿人并为其提供主要的信息源时，问题就会出现，即使机器学习也不能完全解决这些来自人的问题。这就是为什么持续更新算法以决定用户在其新闻推送中将看到什么。当你并不确定那是什么时，你如何训练一个网络来传递最优组合。Candela 说：「我认为这个问题几乎不可能解决。我们随机推送新闻故事意味着你在浪费自己的时间，不是吗？我们只推送一个朋友的新闻故事，赢者通吃。你可以彻底结束这个一轮又一轮的讨论，其中没有最优解。我们尝试做一些探索。」Facebook 将会继续用人工智能来解决这个问题，人工智能不可避免地成为了问题的通用解决方案。Candela 看起来满怀希望地说：「在机器学习和人工智能方面有一系列的行动研究来优化探索的恰当水平。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然，当 Facebook 发现自己受假新闻牵连并被当成罪魁祸首时，它会快速召集人工智能团队从服务中清除虚假新闻。这是一次不同寻常的集体行动，其中甚至包括眼光长远的常被作为顾问的 FAIR 团队。LeCun 说。结果证明，FAIR 的努力产生了一个解决问题的工具：被称作 World2Vec 的模型（「vec」是科技术语向量（vector）的缩写，参阅：http://www.pamitc.org/cvpr15/files/lecun-20150610-cvpr-keynote.pdf）。World2Vec 给神经网络带来了一种记忆能力，帮助 Facebook 用信息标注每一条内容，比如内容是谁发的，谁又分享了该内容。（不要把它和谷歌的 Word2Vec 搞混了，一开始我就这样）有了这些信息，Facebook 可以理解假新闻的特征及分享模式，使得通过机器学习策略根除假新闻有了可能。「事实证明，验证假新闻与找到用户最想看的网页并没有什么大不同。」LeCun 说。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Candela 团队建立的平台使得 Facebook 能够最快的速度推出需要审查的产品。它们实际表现如何仍有待观察。Candela 说，目前讨论这些算法减少假新闻的能力还为时过早。但无论这些新措施是否有效，目前的困境提出了另一个问题：一个解决问题的算法&amp;mdash;&amp;mdash;即使是机器学习算法&amp;mdash;&amp;mdash;也可能会产生意想不到的甚至有害的后果。有些人认为在 2016 年这样的事已经发生了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Candela 反对这种观点。「我认为我们已经使世界变得更美好了。」他说道，并讲了一个故事。在采访的前一天，Candela 打电话给一位只有一面之缘的 Facebook 用户&amp;mdash;&amp;mdash;一个朋友的父亲。他看到那个人在 Facebook 上发布了支持特朗普的故事，并对此感到困惑。然后 Candela 意识到他的工作是根据数据做出决定，他缺少重要的信息。所以他联系了这个人并请求进行谈话。对方同意之后他们进行了电话沟通。「这没有改变我的世界，但让我学会了以一个非常不同的方式来观察事情的方法，」Candela 说。「在一个没有 Facebook 的世界里，我永远不会和他出现交集。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「换句话说，虽然人工智能是必要的&amp;mdash;&amp;mdash;甚至是决定性的&amp;mdash;&amp;mdash;但对于 Facebook 来说，人工智能并不是唯一的答案。「目前的挑战是人工智能还处于起步阶段，」Candela 说。&lt;/span&gt;&lt;span&gt;「我们只是刚刚上路。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文链接：https://backchannel.com/inside-facebooks-ai-machine-7a869b922ea7#.vjhbmd6zx&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Sat, 25 Feb 2017 15:24:24 +0800</pubDate>
    </item>
    <item>
      <title>学界 | 普林斯顿联手英特尔：用机器学习和高性能计算破解大脑密码</title>
      <link>http://www.iwgc.cn/link/</link>
      <description>
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自Princeton&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Catherine Zandonella&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀、晏奇、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote style="color: rgb(62, 62, 62); font-size: 16px; white-space: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/blockquote&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;近日，普林斯顿大学和英特尔的研究者在 Nature Neuroscience 上发表了一篇论文《Computational approaches to fMRI analysis》，介绍了普林斯顿和英特尔在破解大脑思维上的研究成果：实现了对 fMRI 脑扫描的实时计算分析，点击文末「阅读原文」可查看原论文。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今年早些时候，大约 30 位神经科学家和计算机程序开发者聚集到了一起，试图提升他们读取人类心智的能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这场黑客马拉松（hackathon）是普林斯顿大学和世界最大的计算机处理器制造商英特尔联合举办的一系列活动中的一个，这些活动的目的是为了构建能够实时读取人们的想法的程序。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;普林斯顿大学和英特尔的这个研究合作推动了解码数字大脑数据（来自功能性磁共振成像（fMRI）方面的快速发展，有望帮助揭示出带来学习、记忆和其它认知功能的神经活动。近日，一篇关于解码大脑扫描的计算方法上进展的概述论文被发表在了 Nature Neuroscience 上，作者包括普林斯顿神经科学研究所和普林斯顿计算机科学与电气工程系的研究人员，以及英特尔的 Intel Labs 的研究者。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「实时监测大脑功能的能力对于提升对大脑疾病的诊断和治疗以及对心智工作方式的基础研究都有很大的潜力。」普林斯顿神经科学研究所联合主任、Robert Bendheim and Lynn Bendheim Thoman 教授 Jonathan Cohen 说，他也是与英特尔的这个合作的创始成员之一。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自从这项合作两年前开始以来，这些研究者已经将从大脑扫描中提取想法的时间从数天减少到的不到一秒钟，Cohen 说，他同时还是一位心理学教授。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种实验受益于在黑客马拉松期间诞生的对思想的实时解码。这项研究由普林斯顿神经科学研究所的前博士后 J. Benjamin Hutchinson（现在是东北大学的助理教授）设计，目的是探索当一个人关注其环境或注意力游移到其它想法或记忆时的大脑活动。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这个实验中，Hutchinson 要求一位研究志愿者（一位躺在 fMRI 扫描仪中的研究生）查看一张关于一家拥挤的咖啡馆里人们的细节丰富的照片。Hutchinson 可以在控制室的计算机上实时地分辨出该研究生是否正在关注这张图片，还是说其思想已经游移到别处去了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然后 Hutchinson 可以给该研究生反馈她关注这张图片的程度&amp;mdash;&amp;mdash;当她正关注这张图片时，图片会变得更清晰更明亮；当她思想飘走时，图片就会变得暗淡。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这项正在进行的研究可以帮助想要更加了解大脑的神经科学家，也可以帮助想要设计更高效的算法和快速处理大规模数据集的处理方法的计算机科学家。位于俄勒冈 Hillsboro 的 Intel Labs 的资深首席科学家 Theodore Willke 如是说，他同时也是英特尔的 Mind's Eye Lab 的负责人和这项合作中英特尔团队的领导。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「英特尔感兴趣的是为高性能计算开发新兴的应用，与普林斯顿的合作为我们带来的新的挑战。」Willke 说，「我们也希望将我们从对人类智能和认知的研究中所收获的东西导入到机器学习和人工智能中，从而实现其它重要的目标，比如更安全的自动驾驶、更快的药物发现和更容易的癌症早期检测。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自从 fMRI 在 20 年前发明以来，研究者就一直在不断提升从每一次扫描的巨量数据中进行筛选的能力。fMRI 扫描仪可以获取血流变化的信号&amp;mdash;&amp;mdash;这些信号会在我们时时刻刻思考的大脑中产生。但要从这些测量中读到一个人的真正想法还很困难，要做实时那更是难上加难。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;普林斯顿及其它机构已经开发出了一些处理这些数据的技术。比如，普林斯顿大学的 Peter Ramadge 教授的研究工作可以通过结合来自多人的脑扫描数据来识别对应于特定想法的脑活动模式。设计计算机化的指令（即算法）来执行这些分析仍然还是一个重大的研究领域。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;强大的高性能计算机帮助减少了执行这些分析的时间，因为我们可以将一个任务分成不同的块然后并行执行。据普林斯顿计算机科学 Paul M. Wythes '55 P86 and Marcia R. Wythes P86 教授 Kai Li 说，这项合作中更好的算法与并行计算的结合最后帮助实现了实时的脑扫描处理。Kai Li 教授也是该合作的创始人之一。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;iframe allowfullscreen="" class="video_iframe" data-vidtype="1" frameborder="0" height="417" src="https://v.qq.com/iframe/preview.html?vid=s0378is1akq&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0" width="556"&gt;&lt;/iframe&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;普林斯顿大学和 Intel Labs 已经开发出了能够在大脑被 fMRI 扫描时实时解读想法的软件。其目标是揭示出对应于学习、记忆和其它脑功能的神经活动。在该视频中，心理学教授 Nicholas Turk-Browne 解释了一个典型的实验&amp;mdash;&amp;mdash;在控制室的研究者可以监控躺在 fMRI 扫描仪中的志愿者关注一张繁忙的咖啡馆场景图片中特定人物的能力。该实验由 J. Benjamin Hutchinson 设计。普林斯顿计算机科学博士及现 Intel Labs 的研究者 Yida Wang 帮助设计了实现对 fMRI 数据的实时分析的软件。视频中出现的另一个人是研究生 Anne Mennen，其正使用这种实时分析技术来研究学习和记忆。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;一次真正的合作&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自 2015 年合作开始，英特尔为普林斯顿提供了价值超过 150 万美元的计算机硬件设备与帮助来支持学校研究生与博士后的研究工作。同时，英特尔也专门雇了 10 个计算机科学家与普林斯顿合作开发此项目，这些专家与普林斯顿的教师、学生、博士后进行了深度合作以改进提升软件效能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些算法通过机器学习技术来在数据中对思维进行定位，就像面部识别技术可以帮助用户在社交媒体平台（比如 Facebook）上搜索自己的朋友。机器学习技术需要让计算机获得足够大量的学习样本，从而以便计算机能够对它们从未见过的事物进行分类。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此次合作的一个结果是一套名为 Brain Imaging Analysis Kit (BrainIAK：http://brainiak.org/ ) 的软件工具包。目前，它已经在网上开源可供任何想处理 fMRI 数据的研究者使用。团队现在正在开发一款实时分析服务。「我们的想法是，即便是那些没有能力接触到高性能计算设备的研究者，或者是那些不太清楚如何在这样的计算设备上编写程序来运行分析的人，也可以使用我们开发的这些工具来对大脑扫描数据进行实时解码分析。」Li 说道。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些科学家对大脑的研究也许最终可以帮助人们克服在注意力或者其它需要及时反馈的疾病上的困难。比如，实时反馈也许可以帮助病人训练他们的大脑来削弱闯入记忆（Intrusive Memory）。尽管这种「大脑训练」的方法需要进一步验证以确定大脑是在学习新的模式而不是变得仅仅擅长于训练任务，但是这些反馈方法提供了新的治疗潜力，Cohen 说道。对大脑的实时分析也可以帮助临床医生做出诊断。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「这种实时解码大脑的能力已经在对脑的基础研究中得到应用。」普林斯顿神经科学系心理学教授 Kenneth Norman 说道，「作为认知神经科学家，我们对于大脑是如何产生思维这件事非常感兴趣。」他继续道「对这些信息的实时处理大大提升了我们科研能力的范围。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;一扇了解人类思维的窗口&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这项技术还可以被用来研究我们人类是如何学习的。例如，当一个人正在听一堂数学讲座，特定的神经模式就会被激活。据 Norman 说，通过观察那些能跟上讲座内容的人的神经模式，研究者能够来分析它们是如何与那些跟不上讲座的人的神经模式相区别的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这项合作正在致力于通过改进技术以获得对人类思考的更清楚的探究。例如，它可以实时解码当一个人看到一张特定面孔时其意识活动的情况。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;计算机科学家需要克服的一个挑战是如何把机器学习应用到扫描大脑生成的数据类型上。一个面部识别算法能够扫描成千上万张照片，从而学会分类。但在扫描大脑上，研究人员通常只有每个人的数百份扫描。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管扫描的数量有限，每个扫描却包含丰富的数据。软件把大脑图像分到小的立方体中，每个立方体大约 1 毫米宽。这些立方体被称为体素（voxel），是二维图像中像素的三维版本。每个立方体中的大脑活动是持续变化的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而更为复杂的问题是大脑区域间的连接带来了我们的思想。一次典型的扫描包括 10 万个体素，如果每个体素能与其他的体素进行交流，可能存在的交流就是无限的。而且这些交流能一秒接一秒的变化。英特尔与普林斯顿计算机科学家之间的合作克服了这些计算挑战。参与这一工作的有 Li 和计算机科学助理教授 Barbara Engelhardt，以及 2016 年在普林斯顿获得计算机科学博士学位，如今在英特尔实验室工作的 Yida Wang。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;普林斯顿心理学教授 Nicholas Turk-Browne 说，在此之前研究人员需要花费数月时间来分析数据集。有了实时的 fMRI 之后，研究人员能够在进行中调整试验。他说：「如果我的假设涉及到大脑的某个区域，实时检测的时候发现试验并不符合该脑区。那么我们就能让志愿者调整到更好的符合该脑区，这能极大地节省时间，能加速科学发现。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;顾一段特别的记忆，比如童年，我们希望能够在屏幕上生成这段经历的照片。这仍旧很遥远，但我们在不断进步。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由 Jonathan Cohen、 Nathaniel Daw 等人合著的论文「Computational approaches to fMRI analysis」发表到了 Nature Neuroscience 的 3 月刊上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;论文：fMRI 分析的计算方法（Computational approaches to fMRI analysis）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/497fc0689317410d39099326d5a01ad7346e6179"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：认知神经科学领域的分析方法（analysis methods）并不总是能够应付 fMRI 数据的丰富度。早期的方法的关注重点是估计单个体素（voxel）或区域内的神经活动，求的是试验或块上的平均，然后再分别对每个参与者建模。这种方法基本上忽略了体素上神经表征的分布式本质、任务过程中神经活动的连续动态、对多个参与者执行联合推理的统计学优势以及使用预测模型来约束分析的价值。最近一些探索性的和理论驱动的方法已经开始尝试追求这些机会。这些方法强调了在 fMRI 分析中计算技术的重要性，尤其是机器学习、算法优化和并行计算。这些技术的采用正在实现新一代的实验和分析，并有望改变我们对一些大脑中最复杂的&amp;mdash;&amp;mdash;也明显是人类的&amp;mdash;&amp;mdash;信号的理解，即认知行为，比如思想、意图和记忆。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文链接：http://www.princeton.edu/main/news/archive/S48/77/80I20/index.xml?section=topstories&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Sat, 25 Feb 2017 15:24:24 +0800</pubDate>
    </item>
    <item>
      <title>干货 | 机器学习需要哪些数学基础？</title>
      <link>http://www.iwgc.cn/link/</link>
      <description>
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自data conomy&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：WALE AKINFADERIN&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：马亚雄、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote style="color: rgb(62, 62, 62); font-size: 16px; white-space: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;过去的几个月中，有几人联系我，诉说他们对尝试进入数据科学的世界，以及用机器学习的技术去探索统计规律并构建无可挑剔的数据驱动型产品的热忱。然而，我发现一些人实际上缺乏必要的数学直觉和知识框架去得到有用的结果。这便是我决定写这篇博文的主要原因。最近涌现出了很多易于使用的机器学习和深度学习的软件包，例如 scikit-learn, Weka, Tensorflow 等等。机器学习理论是统计学、概率学、计算机科学以及算法的交叉领域，是通过从数据中的迭代学习去发现能够被用来构建智能应用的隐藏知识。尽管机器学习和深度学习有着无限可能，然而为了更好地掌握算法的内部工作机理和得到较好的结果，对大多数这些技术有一个透彻的数学理解是必要的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/5b94fb144ae003969b1b7bd63c78a5c8c1c073c6"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;逻辑回归和神经网络的代价函数的计算方法&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;为什么要重视数学？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器学习中的数学是重要的，有很多原因，下面我将强调其中的一些：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 选择正确的算法，包括考虑到精度、训练时间、模型复杂度、参数的数量和特征数量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 选择参数的设置和验证策略。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 通过理解偏差和方差之间的 tradeoff 来识别欠拟合与过拟合。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4. 估计正确的置信区间和不确定度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;你需要什么水平的数学？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当你尝试着去理解一个像机器学习（ML）一样的交叉学科的时候，主要问题是理解这些技术所需要的数学知识的量以及必要的水平。这个问题的答案是多维的，也会因个人的水平和兴趣而不同。关于机器学习的数学公式和理论进步正在研究之中，而且一些研究者正在研究更加先进的技术。下面我会说明我所认为的要成为一个机器学习科学家/工程师所需要的最低的数学水平以及每个数学概念的重要性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 线性代数：我的一个同事 Skyler Speakman 最近说过，「线性代数是 21 世纪的数学」，我完全赞同他的说法。在机器学习领域，线性代数无处不在。主成分分析（PCA）、奇异值分解（SVD）、矩阵的特征分解、LU 分解、QR 分解、对称矩阵、正交化和正交归一化、矩阵运算、投影、特征值和特征向量、向量空间和范数（Norms），这些都是理解机器学习中所使用的优化方法所需要的。令人惊奇的是现在有很多关于线性代数的在线资源。我一直说，由于大量的资源在互联网是可以获取的，因而传统的教室正在消失。我最喜欢的线性代数课程是由 MIT Courseware 提供的（Gilbert Strang 教授的讲授的课程）：http://ocw.mit.edu/courses/mathematics/18-06-linear-algebra-spring-2010/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 概率论和统计学：机器学习和统计学并不是迥然不同的领域。事实上，最近就有人将机器学习定义为「在机器上做统计」。机器学习需要的一些概率和统计理论分别是：组合、概率规则和公理、贝叶斯定理、随机变量、方差和期望、条件和联合分布、标准分布（伯努利、二项式、多项式、均匀和高斯）、时刻生成函数（Moment Generating Functions）、最大似然估计（MLE）、先验和后验、最大后验估计（MAP）和抽样方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 多元微积分：一些必要的主题包括微分和积分、偏微分、向量值函数、方向梯度、海森、雅可比、拉普拉斯、拉格朗日分布。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4. 算法和复杂优化：这对理解我们的机器学习算法的计算效率和可扩展性以及利用我们的数据集中稀疏性很重要。需要的知识有数据结构（二叉树、散列、堆、栈等）、动态规划、随机和子线性算法、图论、梯度/随机下降和原始对偶方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;5. 其他：这包括以上四个主要领域没有涵盖的数学主题。它们是实数和复数分析（集合和序列、拓扑学、度量空间、单值连续函数、极限）、信息论（熵和信息增益）、函数空间和流形学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一些用于学习机器学习所需的数学主题的 MOOC 和材料是（链接经过压缩）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;可汗学院的线性代数（http://suo.im/fgMNX）、概率与统计（http://suo.im/CqwY9）、多元微积分（http://suo.im/xh6Zn）和优化（http://suo.im/1o2Axs）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;布朗大学 Philip Klein 的「编程矩阵：计算机科学应用中的线性代数（Coding the Matrix: Linear Algebra through Computer Science Applications）」：http://codingthematrix.com&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;得克萨斯大学的 Robert van de Geijn 在 edX 上的 Linear Algebra &amp;ndash; Foundations to Frontiers：http://suo.im/hKRnW&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;戴维森学院 Tim Chartier 的新课程 Applications of Linear Algebra；第一部分：http://suo.im/48Vary，第二部分：http://suo.im/3Xm3Lh&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Joseph Blitzstein 的 Harvard Stat 110 lectures：http://suo.im/2vhVmb&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Larry Wasserman 的书《All of statistics: A Concise Course in Statistical Inference》，下载：http://suo.im/v9u7k&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;斯坦福大学的 Boyd 和 Vandenberghe 的关于凸优化的课程：http://suo.im/2wdQnf&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Udacity 的 Introduction to Statistics 课程：http://suo.im/1enl1c&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;吴恩达授课的 Coursera/斯坦福大学的机器学习课程：http://suo.im/1eCvp9&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这篇博文的主要目的是给出一些善意的关于数学在机器学中的重要性的建议，一些一些必需的数学主题以及掌握这些主题的一些有用的资源。然而，一些机器学习的痴迷者是数学新手，可能会发现这篇博客令人伤心（认真地说，我不是故意的）。对于初学者而言，你并不需要很多的数学知识就能够开始机器学习的研究。基本的吸纳觉条件是这篇博文所描述的数据分析，你可以在掌握更多的技术和算法的过程中学习数学。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Sat, 25 Feb 2017 15:24:24 +0800</pubDate>
    </item>
    <item>
      <title>一周论文 | 2016年最值得读的NLP论文解读（3篇）+在线Chat实录</title>
      <link>http://www.iwgc.cn/link/</link>
      <description>
&lt;h3 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;引言&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;本期Chat是PaperWeekly第一次尝试与读者进行互动交流，一共分享和解读3篇paper，均选自2016年最值得读的自然语言处理领域paper，分别是：&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="margin-top: 15px; margin-left: 20px; max-width: 100%; font-size: 16px; font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); color: rgb(68, 68, 68); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;li&gt;&lt;p&gt;End-to-End Reinforcement Learning of Dialogue Agents for Information Access&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Dual Learning for Machine Translation&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;SQuAD: 100,000+ Questions for Machine Comprehension of Text&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;h3 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="1. End-to-End Reinforcement Learning of Dialogue Agents for Information Access"&gt;&lt;/a&gt;&lt;strong&gt;1.&amp;nbsp;End-to-End Reinforcement Learning of Dialogue Agents for Information Access&lt;/strong&gt;&lt;/h3&gt;&lt;h4 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="作者"&gt;&lt;/a&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;Bhuwan Dhingra, Lihong Li, Xiujun Li, Jianfeng Gao, Yun-Nung Chen, Faisal Ahmed, Li Deng&lt;/p&gt;&lt;h4 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="单位"&gt;&lt;/a&gt;&lt;strong&gt;单位&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA&lt;br&gt;Microsoft Research, Redmond, WA, USA&lt;br&gt;National Taiwan University, Taipei, Taiwan&lt;/p&gt;&lt;h4 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="关键词"&gt;&lt;/a&gt;&lt;strong&gt;关键词&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;Dialogue Agent, Reinforcement Learning&lt;/p&gt;&lt;h4 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="文章来源"&gt;&lt;/a&gt;&lt;strong&gt;文章来源&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;arXiv&lt;/p&gt;&lt;h4 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="问题"&gt;&lt;/a&gt;&lt;strong&gt;问题&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;用强化学习构造一个端到端的任务驱动的基于知识图谱的对话系统。&lt;/p&gt;&lt;h4 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="模型"&gt;&lt;/a&gt;&lt;strong&gt;模型&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;一个任务驱动的对话系统，一般通过自然语言与用户进行多轮交流，帮助用户解决一些特定问题，例如订机票或检索数据库等。一般由下面四部分组成：&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="margin-top: 15px; margin-left: 20px; max-width: 100%; font-size: 16px; font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); color: rgb(68, 68, 68); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;li&gt;&lt;p&gt;Language Understanding Module(LU): 理解用户意图并提取相关slots。例如用户想找一部电影，那么就需要提取出电影名称，演员，上映时间等相关slots信息。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Dialogue State Tracker: 追踪用户的目标和对话的历史信息。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Dialogue Policy: 基于当前状态选择系统的下一步action, 例如向用户询问电影上映时间的action是request(year)。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Natural Language Generator(NLG):将系统的action转化成自然语言文本。例如将request(year) 转换成：电影什么时候上映的？&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;在Dialogue Policy这一步，传统方法一般是生成一个类似SQL的查询语句，从数据库中检索答案，但是这会使模型不可微从而只能分开训练。本文使用了基于概率的框架，因此是可微的，从而实现了端到端的训练过程。&lt;/p&gt;&lt;p&gt;论文中用到的数据库，是来自IMDB的电影数据库。每一行代表一部电影，每一列是一个slot，信息有可能存在缺失。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;a rel="gallery0" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="enter image description here"&gt;&lt;img src="http://img05.iwgc.cn/mpimg/9b5e879ba672ea62e728b9710b8e191634abfbd9"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;整体框架如下图：&lt;/p&gt;&lt;p&gt;&lt;a rel="gallery0" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="enter image description here"&gt;&lt;img src="http://img05.iwgc.cn/mpimg/279938fd5081fd881560ab40146f245c48a72c45"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;下面分别介绍各个部分：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Feature Extractor&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;将用户每轮的输入文本转化成一个向量，这里使用了ngram词袋模型(n=2)。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Belief Trackers&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;用于追踪对话状态和历史信息。&lt;/p&gt;&lt;p&gt;这里针对每一列的slot,分别有一个belief tracker。每个belief tracker的输入是从feature extractor得到的向量，用GRU处理以后，得到一个状态向量。根据这个状态向量，分别计算得到两个输出：pj和qj。&lt;/p&gt;&lt;p&gt;pj是当前slot下所有值的概率分布，qj是用户不知道这个slot值的概率。&lt;/p&gt;&lt;p&gt;因为在和用户交互的过程中，应当尽可能询问用户知道的信息，询问用户不知道的信息对后面的查询没有任何意义。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Soft-KB Lookup&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;根据Belief Trackers的输出，计算数据库中每个值的概率分布。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Beliefs Summary&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;由Belief Trackers和Soft-KB Lookup,可以得到当前的对话状态向量st。st向量包含了数据库中所有值的概率分布户是否知识等信息，实在是太大了，直接送给Policy Network会导致其参数过多，难以训练。因此这一步把slot-values转化成了加权的熵统计信息。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Policy Network&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这里使用策略网络，根据Beliefs Summary的输入状态向量，来输出各个action的概率分布&amp;pi;。具体结构是GRU+全连接层+softmax的方式。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Action Selection&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这里从策略分布&amp;pi;采样，得到下一步的action。如果action是inform(),说明到了对话的最后一步，需要给用户返回Top k的查询结果。这里按照Soft-KB Lookup步骤中得到的每一行电影的概率，进行采样来返回Top K候选。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;NLG&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这里的NLG部分和上面是独立的，使用了sequence-to-sequence模型，输入action,输出包含slot的对话模板，然后进行填充，得到自然语言文本。&lt;/p&gt;&lt;h4 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="训练"&gt;&lt;/a&gt;&lt;strong&gt;训练&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;这里用的基于策略梯度的强化学习模型进行训练，目标是最大化reward的期望。最后一轮inform部分的reward是由正确答案在Top K候选中的排序位置决定，排序越靠前，reward越高。如果候选没有包含正确答案，那么reward是-1。&lt;/p&gt;&lt;p&gt;对话交互训练数据是通过一个模拟器从电影数据中采样生成得到。&lt;/p&gt;&lt;h4 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="Baselines"&gt;&lt;/a&gt;&lt;strong&gt;Baselines&lt;/strong&gt;&lt;/h4&gt;&lt;ul class=" list-paddingleft-2" style="margin-top: 15px; margin-left: 20px; max-width: 100%; font-size: 16px; font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); color: rgb(68, 68, 68); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;li&gt;&lt;p&gt;End2End-RL：本文提出的模型。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Rule-based：Belief Trackers和Policy部分都是人工规则。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Simple-RL：只有Belief Trackers是人工规则，而Policy部分是基于GRU。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;实验结果如下图：&lt;/p&gt;&lt;p&gt;&lt;a rel="gallery0" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="enter image description here"&gt;&lt;img src="http://img04.iwgc.cn/mpimg/a66cfedcd0149ff52dde459e6ba85e32b3929aa5"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;h4 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;br&gt;&lt;/strong&gt;&lt;/h4&gt;&lt;h4 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="相关工作"&gt;&lt;/a&gt;&lt;strong&gt;相关工作&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;对话的相关工作很多，包括传统基于Markov Decision Processes的POMDPs, 基于Q-Learning的SimpleDS，基于API查询的方法，基于最小化熵的EMDM等等，感兴趣的读者可以查询相关文献。&lt;/p&gt;&lt;h4 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="简评"&gt;&lt;/a&gt;&lt;strong&gt;简评&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;深度强化学习在对话系统的应用越来越多，本文最大的贡献，是提出了一个可微的基于概率的框架，从而使End-to-End训练成为可能，相比传统方法各部分分别训练，联合训练可以有效的减少错误传递。而基于深度强化学习的训练方式，相比传统基于规则的方式，在高噪音输入的情况下，有着更好的表现。&lt;/p&gt;&lt;h4 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="完成人信息"&gt;&lt;/a&gt;&lt;strong&gt;完成人信息&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;王哲，中国科学技术大学，xiaose@mail.ustc.edu.cn。&lt;/p&gt;&lt;hr style="max-width: 100%; font-size: 16px; font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); color: rgb(68, 68, 68); box-sizing: border-box !important; word-wrap: break-word !important;"/&gt;&lt;p&gt;&lt;strong&gt;Chat实录&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;br&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;问&lt;/strong&gt;：我对&amp;ldquo;因此这一步把slot-values转化成了加权的熵统计信息&amp;rdquo;的合理性和物理意义有些不明，我在最近的论文中很少看到这样的做法，请问是因为效果的原因吗？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;答&lt;/strong&gt;：&amp;nbsp;这个熵指的是信息熵，不是物理中的热力学熵。信息熵把一个系统的不确定性，按照其可能出现结果的概率分布，进行定量化计算，得到的是可以获取的信息量大小。信息熵越大，不确定性就越大，我们可以获取的信息量也就越大。任务驱动的问题系统，在得到最终查询结果前，希望尽可能多的从用户那里获取信息，减少系统本身的不确定性，因此我们在知道一个slot中各种实体概率的情况下，用信息熵来度量一个slot的不确定性，还是挺合理挺自然的。&lt;br&gt;熵的用法在深度学习网络中还是挺多的,例如我们经常用交叉熵做损失函数。同时文本分类任务中，经常用TFIDF值作为特征，而TFIDF值是可以由信息熵推导出来的。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;问&lt;/strong&gt;：论文中提到：&amp;rdquo;Moreover, instead of defining an attention distribution directly over the KB entities, which could be very large, we instead induce it from the smaller distributions over each relation (or slot in dialogue terminology) in the KB&amp;rdquo; 这里smaller distributions ， 以及each relation怎么理解，为什么能小？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;答&lt;/strong&gt;：&amp;nbsp;这里的relation，指的是slots,也就是表格的各个列属性，例如year,actor等。 和entities的数目相比，一个slot对应的属性值数目要小很多。entity概率计算的时候，是把各个属性的概率相乘得到的。而一个属性的概率，取决于这个属性有多少值，假设我们有3个属性，每个属性的值的数目分别是k1,k2,k3，那么entities可能的计算量就是k1 * k2 * k3。现在作者假设每个属性之间是相互独立的,因此实际计算量可以理解成k1+k2+k3，所以slots的属性分布和entities分布相比，是smaller distributions。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;问&lt;/strong&gt;：增强学习在chatbot研究中使用时相比监督学习有哪些优势和劣势？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;答&lt;/strong&gt;：&amp;nbsp;先说说强化学习的优势：&lt;/p&gt;&lt;p&gt;监督学习当前研究比较多的，是以seq2seq为代表的生成模型。 它目前一个比较大的问题，是生成结果缺乏多样性，倾向于生成比较安全比较常见的回答，例如&amp;ldquo;谢谢&amp;rdquo;，&amp;ldquo;不知道&amp;rdquo;。 这个主要是因为，训练目标是用最大似然拟合训练数据，而经常在训练数据中出现的回答，会占一些优势，因此后续有很多工作试图改进这个问题，例如用互信息作为目标函数，在解码搜索过程中，对常见结果进行惩罚，提高生成结果的多样性等等。&lt;/p&gt;&lt;p&gt;监督学习的另外一个问题，是训练过程和预测过程不一致。训练的时候，当我们解码生成一个句子的下一个词的时候，是基于训练语料中的正确结果，而预测的时候，我们并不知道标准答案是什么，因此解码下一个词的时候，是基于我们预测的结果。这种不一致会影响最终结果，就像考试我们遇到之前没有见过的题型，我们的考试成绩可能会变差一样。增强学习，有希望解决这两个问题的。&lt;/p&gt;&lt;p&gt;针对第一个问题，我们借助增强学习的reward,引入一些明确的的奖励目标，用来指导对话的生成。例如，如果我们想训练一个淘宝客服的对话系统，我们可以用商品最终是否购买，来作为奖励目标，这样可以引导对话向着商品成功购买的方向发展，因此可以产生更好的对话结果。目前还有一个最新的工作，是将生成对抗网络，引入对话系统，因为当前对话系统一个很大的问题，是缺乏可靠的自动化评价指标，而对抗生成网络中，我们有一个生成模型，也就是我们的对话生成系统，还有一个判别模型，这个判别模型的目标，是判断这个对话，是机器生成的，还是人写的，这样就引入了一个比较明确的奖励目标，也更接近图灵测试，而连接生成网络和判别网络的桥梁，就是强化学习。因为NLP的词，相比图像，是离散的，我们可以借助类似AlphaGo中的蒙特卡洛搜索，来采样得到训练样本，送给判别模型。针对第二个问题，强化学习在训练的过程中，生成模型是通过采样产生样本，这个过程和预测是一致的，因此也避免了不一致带来的问题。&lt;/p&gt;&lt;p&gt;综上所述，增强学习在对话系统中有很大的优势。&lt;/p&gt;&lt;p&gt;下面说说他的劣势：&lt;/p&gt;&lt;p&gt;和监督学习相比，强化学习的训练是比较困难的，因为训练的过程很不稳定。而且具体的对话系统中，reward的奖励一般是基于一个完整的句子，而如何把reward奖励分配到具体的词，是一个很大的挑战。而在多轮对话中，reward一般只出现在最后一轮，如何对前面的几轮对话分配reward,也同样是一个问题。同时为了稳定强化学习的训练过程，我们不能完全离开监督学习，一般还需要借助监督学习的方法，来做初始化训练，甚至在训练过程中，需要穿插监督学习过程，起到稳定网络的作用。&lt;br&gt;以上就是增强学习在对话系统中的优劣。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;问&lt;/strong&gt;：论文中的pr(Gj＝i｜j＝0)为什么等于1/N呢？也就是在用户不知道第值时，目标是i的概率为什么等于1/N？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;答&lt;/strong&gt;：&amp;nbsp;用户不知道第j个属性，也就是说，在第j个属性上，用户不能提供有效信息。那么我们从属性j的角度，看各个实体的时候，实际上是没有什么区别的。因此最保险的方式，就是假设各个实体的概率相等，因此概率是1/N。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;问&lt;/strong&gt;：增强学习在chatbot中的reward函数是否都是根据相应的需求来手动给出，而非学习得来？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;答&lt;/strong&gt;：&amp;nbsp;有些是可以手动给出的，例如Bengio的An Actor-Critic Algorithm for Sequence Prediction这篇论文，就把BLEU作为reward，用于机器翻译模型的训练。reward也可以学习得来，例如GAN应用到对话系统的时候，生成模型的reward就是由判别模型给出的，而在对偶学习中，一个模型的reward由它对应的对偶模型给出。&lt;/p&gt;&lt;hr style="max-width: 100%; font-size: 16px; font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); color: rgb(68, 68, 68); box-sizing: border-box !important; word-wrap: break-word !important;"/&gt;&lt;h3 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;br&gt;&lt;/h3&gt;&lt;h3 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="2. Dual Learning for Machine Translation"&gt;&lt;/a&gt;&lt;strong&gt;2.&amp;nbsp;Dual Learning for Machine Translation&lt;/strong&gt;&lt;/h3&gt;&lt;h4 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="作者"&gt;&lt;/a&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;Yingce Xia, Di He, Tao Qin, Liwei Wang, Nenghai Yu, Tie-Yan Liu, Wei-Ying Ma&lt;/p&gt;&lt;h4 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="单位"&gt;&lt;/a&gt;&lt;strong&gt;单位&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;中科大，北大，微软亚研院&lt;/p&gt;&lt;h4 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="关键词"&gt;&lt;/a&gt;&lt;strong&gt;关键词&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;NMT，monolingual data, dual learning&lt;/p&gt;&lt;h4 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="文章来源"&gt;&lt;/a&gt;&lt;strong&gt;文章来源&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;NIPS 2016&lt;/p&gt;&lt;h4 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="问题"&gt;&lt;/a&gt;&lt;strong&gt;问题&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;利用双向NMT模型，在少量双语数据，大量单语数据的情况下，如何提高NMT的性能。&lt;/p&gt;&lt;h4 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="模型"&gt;&lt;/a&gt;&lt;strong&gt;模型&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;主要的思想是通过two-agent communication game，用单语语料和语言模型来提升双向NMT的性能。利用A语言的单语语料进行学习的two-agent communication game过程如下：&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="margin-top: 15px; margin-left: 20px; max-width: 100%; font-size: 16px; font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); color: rgb(68, 68, 68); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;li&gt;&lt;p&gt;agent1读入语言A的单语句子， 通过A到B的NMT模型转换成语言B的句子，并且发送给agent2。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;agent2接收到agent1发送的语言B的句子，通过语言B的语言模型LM_B，给出一个reward r_1。再通过B到A的NMT模型，将句子转换成语言A并且发送给agent1。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;agent1接收到agent2发送的语言A的句子，和最初的单语句子做比较，给出另一个reward r_2。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;那么r=alpha* r_1+(1-\alpha) r_2，agent1和agent2就能根据reward r对A到B和B到A的NMT模型进行学习。&lt;/p&gt;&lt;p&gt;如果用公式表达，这个过程的目标函数就是：&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/21625a8d269c8149ce4d76b0e71dc01b30d71924"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;由于s_mid的sample space无穷大，需要做一些近似来求期望。 文中考虑到random sampling会有较大的variance和一些不合理的翻译，采用了N-best来近似（N=2, 用beam search得到）。&lt;/p&gt;&lt;p&gt;整个训练分成3个step:&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="margin-top: 15px; margin-left: 20px; max-width: 100%; font-size: 16px; font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); color: rgb(68, 68, 68); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;li&gt;&lt;p&gt;用双语语料，普通的MLE training来学习A到B和B到A的NMT模型，作为warm start。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;每一个minibatch里面一部分单语语料，一部分双语语料，对双语语料用MLE作为目标函数，单语语料用上面的公式作为目标函数；随着training的进行，减少双语语料的比例。训练交替地从语言A或者语言B开始。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;最后完全用单语语料，通过上面的公式作为目标函数进行训练。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h4 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="相关工作"&gt;&lt;/a&gt;&lt;strong&gt;相关工作&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;这篇文章和Semi-Supervised Learning for Neural Machine Translation以及Neural Machine Translation with Reconstruction比较相似，都是用双向NMT模型来互相学习增强，区别在于这篇引入了语言模型。和Minimum Risk Training for Neural Machine Translation也有一定的相关性，相当于MRT中的loss function用了语言模型和反向NMT进行定义。&lt;/p&gt;&lt;h4 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="简评"&gt;&lt;/a&gt;&lt;strong&gt;简评&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;这篇文章从reinforcement learning的角度，将单语语料很好地融入到双向NMT的训练中，在使用10%双语语料的情况下也能取得较好的翻译结果。整体上来说非常有意思，也可以推广到更多的tasks in dual form。&lt;/p&gt;&lt;h4 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="完成人信息"&gt;&lt;/a&gt;&lt;strong&gt;完成人信息&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;陈云，香港大学，yun.chencreek@gmail.com。&lt;/p&gt;&lt;h4 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;br&gt;&lt;/h4&gt;&lt;hr style="max-width: 100%; font-size: 16px; font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); color: rgb(68, 68, 68); box-sizing: border-box !important; word-wrap: break-word !important;"/&gt;&lt;p&gt;&lt;strong&gt;Chat实录&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;br&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;问&lt;/strong&gt;：论文中的相关工作部分提到了另外两篇neural machine translation的相关工作，请问作者可否简单介绍一下那两个模型的主要方法呢？以及它们和dual learning的最大区别。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;答&lt;/strong&gt;：&amp;nbsp;另外两篇论文分别是semi-supervised Neural Machine Translation 以及Neural Machine Translation with Reconstruction。 semi-supervised这篇是利用autoencoder，将源端和目标端的单语语料引入，进行双向NMT联合训练；reconstruction这篇，是在普通MLE目标函数的基础上，增加了从目标端的hidden state重建源句子的概率这一项。首先我谈一下他们的区别。&lt;/p&gt;&lt;p&gt;出发的角度不一样：&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="margin-top: 15px; margin-left: 20px; max-width: 100%; font-size: 16px; font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); color: rgb(68, 68, 68); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;li&gt;&lt;p&gt;semi-supervised：如何将source和target端的单语语料引入，通过双向NMT提高NMT的性能。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;recosntruction：解决translation adequacy的问题, 避免翻译的句子太短或者重复翻译某一部分。利用双向NMT优化原来的MLE目标函数。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;dual learning：在少量平行语料，大量单语语料的情况下，如何利用双向NMT提高NMT的性能。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;语料需求不一样：&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="margin-top: 15px; margin-left: 20px; max-width: 100%; font-size: 16px; font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); color: rgb(68, 68, 68); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;li&gt;&lt;p&gt;semi-supervised: source,target端的单语语料，文中实验双语语料比单语语料多。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;reconstruction: 没用单语语料。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;dual learning: 10%的双语语料，大量单语语料。并且用了预先用单语语料训练好的语言模型。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;解释的角度不一样：&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="margin-top: 15px; margin-left: 20px; max-width: 100%; font-size: 16px; font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); color: rgb(68, 68, 68); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;li&gt;&lt;p&gt;semi-supervised: 双向NMT联合训练，目标函数包括两个方向的MLE，以及source&amp;amp;target autoencoder的reconstruction probability。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;reconstruction: 目标函数在普通的MLE基础上增加了由reconstructor定义的reconstruction probability。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;dual learning: 基于policy gradient的增强学习。用two agents play games这样的形式来解释。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;而他们也有一些相同的地方:&lt;/p&gt;&lt;p&gt;都是用双向NMT来提高普通MLE训练的单向NMT的性能。reconstruction一篇相当于在原来的目标函数上加了reconstruction error，由于只用了双语语料，所以目标句子y是已知的。而semi-supervised和dual learning都会处理单语语料。在处理源端单语句子时，目标端的y是未知的。这二者都可以看成是一种句子级别的模型，通过正向的NMT产生一些句子来近似整个目标端输出空间，然后通过反向NMT给出句子的feedback(dual learning同时用了LM给出的feedback)。&lt;/p&gt;&lt;p&gt;大家可以对比一下他们的目标函数，能够比较明显地看出区别和联系来。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;问&lt;/strong&gt;：可以用dual-learning这样的framework来解决的其他问题吗？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;答&lt;/strong&gt;：&amp;nbsp;有很多dual tasks都可以用这个框架，比如 speech recognization &amp;amp; text to speech, Image captioning &amp;amp; Image generation, Question answering &amp;amp; Question generation, 还有 Query-document matching &amp;amp; Query/keyword suggestion。这篇文章之前MSRA的&lt;a rel="external" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" target="_blank"&gt;刘铁岩老师&lt;/a&gt;和&lt;a rel="external" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" target="_blank"&gt;秦涛博士&lt;/a&gt;有在斗鱼上直播过，大家可以看一下。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;问&lt;/strong&gt;：Dual Learning 中语言模型 LM 没看到在那里有详细的说明？刚才说的 Autoencoder，是在哪里提到的呢&lt;/p&gt;&lt;p&gt;&lt;strong&gt;答&lt;/strong&gt;：&amp;nbsp;语言模型在文章中的第四页第二段可以看到：&amp;ldquo;This middle step has an immediate reward r1 = LMB(smid), indicating how natural the output sentence is in language B.&amp;rdquo; Reward包括r1和r2, r1就是语言模型给的reward。 语言模型是用单语语料提前训练好的，在NMT的整个training过程中固定不变。&lt;/p&gt;&lt;p&gt;Autoencoder在dual learning这篇没有提到，是在semi-supervised那篇提到的。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;问&lt;/strong&gt;：请问dual learning和GAN是否有相似之处 还是完全不相关的两种思路&lt;/p&gt;&lt;p&gt;&lt;strong&gt;答&lt;/strong&gt;：&amp;nbsp;是有相似之处。作者之一秦涛在斗鱼直播有提到，GAN在某种程度上可以看成是dual learning的一种特殊情况。将generator看成是primal task，discriminator看成是dual task, 通过f和g共同学习来互相增强。dual task主要是为了给primal task提供feedback。个人觉得dual learning和GAN最大的区别在于对discriminator的定义不一样，GAN定义成分类问题，而dual learning定义的是一个重建问题。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;问&lt;/strong&gt;：论文中的算法提到了一个参数alpha，它的意义是什么呢？是需要手动调参还是一个机器学习优化得到的参数呢？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;答&lt;/strong&gt;：&amp;nbsp;这个alpha其实是LM reward跟反向NMT reward的一个trade-off，是手动调的。 文章后面有写，设置成0.005能取得较好的效果。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;问&lt;/strong&gt;：reconstruction error 以前常见于投影 project 重建 rebuild，或者是编码重建 encode/decode。图像上，一般常用 residual 来表示，例如子空间算法，KSVD 分解等等。这种对偶重建的方法，有没有可能发展成一种泛化的投影重建？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;答&lt;/strong&gt;：&amp;nbsp;我觉得你可以尝试一下，图像上的东西不太懂。如果可以做成这种对偶tasks的形式,一个task take 某个action的reward可以由另外一个task给出，应该就可以试试。&lt;/p&gt;&lt;hr style="max-width: 100%; font-size: 16px; font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); color: rgb(68, 68, 68); box-sizing: border-box !important; word-wrap: break-word !important;"/&gt;&lt;h3 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;br&gt;&lt;/h3&gt;&lt;h3 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="3. SQuAD: 100,000+ Questions for Machine Comprehension of Text"&gt;&lt;/a&gt;&lt;strong&gt;3.&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;SQuAD: 100,000+ Questions for Machine Comprehension of Text&lt;/strong&gt;&lt;/h3&gt;&lt;h4 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="作者"&gt;&lt;/a&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, Percy Liang&lt;/p&gt;&lt;h4 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="单位"&gt;&lt;/a&gt;&lt;strong&gt;单位&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;Computer Science Department, Stanford University&lt;/p&gt;&lt;h4 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="关键词"&gt;&lt;/a&gt;&lt;strong&gt;关键词&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;Question Answering, Dataset Creation&lt;/p&gt;&lt;h4 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="文章来源"&gt;&lt;/a&gt;&lt;strong&gt;文章来源&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;EMNLP 2016&lt;/p&gt;&lt;h4 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="问题"&gt;&lt;/a&gt;&lt;strong&gt;问题&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;创建一个large and high quality reading comprehension dataset。&lt;/p&gt;&lt;h4 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="模型"&gt;&lt;/a&gt;&lt;strong&gt;模型&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;数据收集&lt;/p&gt;&lt;p&gt;用PageRanks搜寻出top 10000 English Wiki articles，然后uniformly sample 536 articles，做相关数据清洗后得到23215 paragraphs。这部分数据被分成三部分，training set(80%)，development set(10%)，test set(10%)。&lt;/p&gt;&lt;p&gt;下一步我们将这些paragraphs都放到Amazon Mechanical Turk上让用户创建问题以及回答问题。这样我们便得到了一个新的QA数据集。&lt;/p&gt;&lt;p&gt;为了评估human在这个QA数据集上的表现，development set和test set中的每个问题被至少发给了两个额外的crowdworkers，其中有2.6%的问题被crowdworkers标记为unanswerable。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;数据集分析&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;我们把答案分成了两部分，numerical和non-numerical。对non-numerical answers再做一次constituency parsing和POS Tagging，发现答案分布如下图所示。&lt;/p&gt;&lt;p&gt;&lt;a rel="gallery0" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="enter image description here"&gt;&lt;img src="http://img04.iwgc.cn/mpimg/486b437625696bb57434faa18104a7668153e64a"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Baselines&lt;/strong&gt;&lt;br&gt;作者做了sliding window baseline和logistic regression baseline，用accuracy和F1 Score做评估。结果如下图所示。&lt;/p&gt;&lt;p&gt;&lt;a rel="gallery0" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="enter image description here"&gt;&lt;img src="http://img04.iwgc.cn/mpimg/e0f30d944e6d9ac2da218c57d25216a8c19aa9a8"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;h4 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="资源"&gt;&lt;/a&gt;&lt;strong&gt;资源&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;在&lt;a rel="external" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" target="_blank"&gt;Stanford Question Answering dataset&lt;/a&gt;可以看到所有dataset的信息，test set leaderboard上有各种Model的performance。&lt;/p&gt;&lt;h4 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="相关工作"&gt;&lt;/a&gt;&lt;strong&gt;相关工作&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;Question Answering方面的dataset有不少，最近比较popular的有：MCTest by Microsoft，BAbI dataset by Facebook，WikiQA by Microsoft，CNN/Daily Mail by DeepMind, Children&amp;rsquo;s Book Test by Facebook。有兴趣的读者可以查阅相关文献。&lt;/p&gt;&lt;h4 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="简评"&gt;&lt;/a&gt;&lt;strong&gt;简评&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;SQuAD是一个高质量的Reading comprehension dataset。作者花费了大量的人力物力，让Crowdworkers根据Wikipedia Paragraph出题和答题。构建的dataset数量巨大且质量高，对未来Reading Comprehension Question Answering的研究非常有帮助。&lt;/p&gt;&lt;h4 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="完成人信息"&gt;&lt;/a&gt;&lt;strong&gt;完成人信息&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;Zewei Chu，The University of Chicago，zeweichu@gmail.com。&lt;/p&gt;&lt;hr style="max-width: 100%; font-size: 16px; font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); color: rgb(68, 68, 68); box-sizing: border-box !important; word-wrap: break-word !important;"/&gt;&lt;p&gt;&lt;strong&gt;Chat实录&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;br&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;问&lt;/strong&gt;：请介绍一下这个reading comprehension dataset和其他dataset之间的主要区别？以及该dataset的优势是？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;答&lt;/strong&gt;：&amp;nbsp;这篇paper相对于前面两篇内容简单一些，主要就是介绍了一个新构建的QA数据集。所以我和大家交流分享一下我比较熟悉的最近一些比较popular的QA Dataset吧。&lt;/p&gt;&lt;p&gt;MCTest: 数据集本身质量不错，像普通的阅读理解，是根据一篇文章提出问题，然后在给定的四个选项中选出一个。但是数据集太小，现在比较主流的RC model都是基于deep learning的，数据量太小很难让model学习到有用的信息。所以个人认为小数据集上的Model多少会给人一种强凑答案的感觉。&lt;/p&gt;&lt;p&gt;CNN/Daily Mail, CBT: 这个数据集我比较熟悉，数据集比较大，也是比较火的一个数据集。问题的答案只是一个单词或者一个entity，SQuAD的答案有比较长的phrase。the entities are anonymized。在anonymized dataset上训练的一个问题是，容易训练出没有semantics的模型来。因为训练集上的参考答案都是entity1，entity2，到了真实情况下碰到很大的vocabulary模型未必work。&lt;/p&gt;&lt;p&gt;安利一下&lt;a rel="external" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" target="_blank"&gt;我同学的一篇paper&lt;/a&gt;，分析了一下几个在CNN/DM/CBT上面比较好的几个模型attention sum/gated attention sum/stanford reader其实本质是差不多的。然后stanford reader虽然在这个数据集上效果很好但是一旦数据集不anonymize就很容易不work了。&lt;/p&gt;&lt;p&gt;WDW dataset:Passage: 直接给一个例子。&lt;/p&gt;&lt;blockquote style="max-width: 100%; color: rgb(62, 62, 62); font-size: 16px; font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p&gt;Britain&amp;rsquo;s decision on Thursday to drop extradition proceedings against Gen. Augusto Pinochet and allow him to return to Chile is understandably frustrating &amp;hellip; Jack Straw, the home secretary, said the 84-year-old former dictator&amp;rsquo;s ability to understand the charges against him and to direct his defense had been seriously impaired by a series of strokes. &amp;hellip; Chile&amp;rsquo;s president-elect, Ricardo Lagos, has wisely pledged to let justice run its course. But the outgoing government of President Eduardo Frei is pushing a constitutional reform that would allow Pinochet to step down from the Senate and retain parliamentary immunity from prosecution. &amp;hellip;&lt;/p&gt;&lt;p&gt;Question: Sources close to the presidential palace said that Fujimori declined at the last moment to leave the country and instead he will send a high level delegation to the ceremony, at which Chilean President Eduardo Frei will pass the mandate to XXX.&lt;/p&gt;&lt;p&gt;Choices: (1) Augusto Pinochet (2) Jack Straw (3) Ricardo Lagos&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;还有一个dataset叫wiki QA我也没有在上面实验过，也给一个例子。&lt;/p&gt;&lt;blockquote style="max-width: 100%; color: rgb(62, 62, 62); font-size: 16px; font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p&gt;Question: Who wrote second Corinthians? Second Epistle to the Corinthians The Second Epistle to the Corinthians, often referred to as Second Corinthians (and written as 2 Corinthians), is the eighth book of the New Testament of the Bible. Paul the Apostle and &amp;ldquo;Timothy our brother&amp;rdquo; wrote this epistle to &amp;ldquo;the church of God which is at Corinth, with all the saints which are in all Achaia&amp;rdquo;.&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;个人觉得open domain以及需要external knowledge的QA DATASET其实很难，但是很重要，因为可以应用在其他更多的方面。&lt;/p&gt;&lt;p&gt;另外提一个LAMBADA dataset，虽然他的问题是last word prediction，不过我们发现用reading comprehension models也可以做出很好的效果。详细信息可以看&lt;a rel="external" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" target="_blank"&gt;我的一篇paper&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;facebook有个babi dataset，&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/79ff8c41ae69726556f8e8480a8d0e663378ba98"/&gt;&lt;/p&gt;&lt;p&gt;需要一些logical thinking，facebook自己搞了一些memory network的模型在上面效果比较好，但是其实我觉得memory network和attention模型非常相似。&lt;/p&gt;&lt;p&gt;至于本文构建的squad dataset主要的特点就是答案可能比较长，而且不给候选答案，所以难度应该会大一些 数据集的质量也比较高，因为都是人工出的问题和标准答案，数据量也很大，容易训练处有用的模型。&lt;/p&gt;&lt;p&gt;个人认为构建大的，有意义的数据集对于QA的工作是很关键的。现在还是比较缺乏能够推广到实际生活中的问题的QA模型。&lt;/p&gt;&lt;p&gt;我大致就分享这一些。给想做QA方面问题的同学一点参考。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;活动预告&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;下一期Paper Note+Chat活动将会继续分享和解读&lt;span&gt;3&lt;/span&gt;篇&lt;span&gt;2016&lt;/span&gt;年最值得读的自然语言处理领域&lt;span&gt;paper，&lt;/span&gt;分别是&lt;span&gt;：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1.LightRNN Memory and Computation-Efficient Recurrent Neural Network&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2.Text understanding with the attention sum reader network&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3.Neural Machine Translation with Reconstruction&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;br&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为保证讨论的质量&lt;span&gt;，&lt;/span&gt;在讨论之前要求各位同学至少读过其中的一篇&lt;span&gt;paper&lt;/span&gt;。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;活动报名请&lt;span&gt;扫码&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/6d9603ac83b35e4af02ed4ccd0fb9db4c2519d53"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;关于PaperWeekly&lt;/span&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;PaperWeekly是一个分享知识和交流学问的学术组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;微信公众号：PaperWeekly&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/74e43d689e2973dc494ef5c2c85c981e72b56552"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;微博账号：PaperWeekly（&lt;a rel="external" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" target="_blank"&gt;http://weibo.com/u/2678093863&lt;/a&gt;&amp;nbsp;）&lt;br&gt;微信交流群：微信+ zhangjun168305（请备注：加群交流或参与写paper note）&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;
</description>
      <pubDate>Sat, 25 Feb 2017 15:24:24 +0800</pubDate>
    </item>
    <item>
      <title>斯坦福大学实现高性能低功耗人工突触，可用于神经网络计算</title>
      <link>http://www.iwgc.cn/link/</link>
      <description>
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自Stanford&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;作者：TAYLOR KUBOTA&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：微胖、晏奇&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;斯坦福研究人员打造出一种新的有机人工突触，更好地支持计算机再现人类大脑信息处理方式。该研究还能改善脑机（brain&amp;mdash;machine）技术。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管这些年来，计算机技术取得不少进展，但是，在再造大脑低能耗、简洁的信息处理过程这方面，我们仍然步履蹒跚。现在，斯坦福大学和桑迪亚国家实验室的研究人员取得了重要进展，该研究可以帮助计算机模拟某块大脑高效设计，亦即人工突触。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/a7dc11591bf333cc590e0d2b1208c302eb9388fd"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Alberto Salleo，材料科学与工程学副教授，研究生 Scott Keene 在确知用于神经网络计算的人工突触的电化学性能。他们是创造这一新设备团队的成员。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Alberto Salleo 说，它运行起来就像是真的突触，不过，它是一个可以制造出来的电子设备。Alberto Salleo 是斯坦福大学材料科学与工程学副教授，也是这篇论文的资深作者（senior author）。「这是一套全新的设备系列，之前并没有看到过这类架构。许多关键标准测评后，我们发现，这款设备的性能要比其他任何非有机设备要好。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相关研究发表在了 2 月 20 日 的 Nature Materials上，该人工突触模仿了大脑突触从通过其中的信号中进行学习的方式。较之传统计算方式，这种方式要节能得多，传统方法通常分别处理信息然后再将这些信息存储到存储器中。就是在这里，处理过程创造出记忆。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;或许有一天，这款突触能够成为一台更接近大脑计算机的一部分，它特别有利于处理视觉、听觉信号的计算过程。比如，声控接口以及自动驾驶汽车。过去，这一领域已经研究出人工智能算法支持下的高效神经网络，但是，这些模仿者距离大脑仍然比较遥远，因为，它们还依赖传统的能耗计算机硬件。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;建造一个大脑&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人类学习时，电子信号会在大脑神经元之间传递。首次横穿神经元最耗费能量。再往后，连接所需的能力就少了。这也是突触为学习新东西、记住已学内容创造便利条件的方式。人工突触，和所有其他类脑计算版本不同，可以同时完成（学习和记忆）这两项任务，并能显著节省能量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深度学习算法非常强大，不过，仍然依赖处理器来计算、模拟电子状态并将其保存在某个地方，就能耗和时间而言，这可不够高效，Yoeri van de Burgt 说，他之前是 Salleo lab 的博士后研究人员（postdoctoral scholar），也是这篇论文的第一作者。「我们没有模拟一个神经网络，而是试着制造一个神经网络。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这款人工突触是以电池设计为基础的。由两个灵活的薄膜组成，薄膜带有三个终端，这些终端通过盐水电解质连接起来。它的功能就像一个晶体管，其中一个终端控制其与其他两个终端之间的电流。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;就像大脑中的神经通路可以通过学习得到加强，研究人员通过重复放电、充电，为人工突触编程。训练后，他们就能预测（不确定性仅为 1%）需要多少伏电，才能让突触处于某种特定电信号状态（electrical state），而且一旦抵达那种状态，它就可以保持该状态。易言之，不同于普通电脑，关掉电脑前，你会先将工作保存在硬件上，人工突触能回忆起它的编程过程而无需任何其他操作或部件。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;测试人工突触网络&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;桑迪亚国家实验室的研究者目前只制造了一个人工神经突触，但是，他们使用有关突触实验中获得的 15,000 个测量结果来模拟某一列（array）突触在神经网络中的运行方式。他们测试了模拟网络识别手写数字 0 到 9 的能力。三个数据集上的测试结果显示其识别手写数字准确度达 93%~97%。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管这项工作对于人类来说显得相对简单，但是对于传统计算机而言，要解释视觉与听觉信号曾经是非常困难的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们期望计算设备能做的工作越来越多，这就需要模拟大脑工作方式的计算方式，因为用传统计算来完成这些工作，能耗巨大，」A. Alec Talin 说，「我们已经证实这款设备很适合实现这些算法，而且很节能。」A. Alec Talin 是桑迪亚国家实验室的杰出技术研究员，也是这篇论文的资深作者。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该设备极其适合于传统计算机执行起来很费劲的信号识别和分类工作。数字晶体管只能处于两种状态，比如 0 或 1，但是研究人员在一个人工突触上成功编码了 500 种状态，对于神经元类计算模型来说，这很有用。从一种状态切换到另一种状态所使用的能耗约为当前最先进计算系统的 1/10，最先进的计算系统需要这些能耗将数据从处理单元移动到存储器。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而，较之一个生物突触引发放电所需的最低能耗，这款人工突触仍然不够节能，所需能耗是前者的 10000 倍。研究人员希望，一旦他们测试用于更小的设备的人工神经突触，他们可以实现类似生物神经元级别的能耗水平。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;有机材料的潜力&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;设备的每一部分都由便宜的有机材料制成。虽然在自然界中找不到这些材料，但是它们大部分都由氢、碳两种元素构成，而且与大脑化学物质兼容。细胞已经可以在这些物质上生长，并且已经被来打造用于神经递质（neural transmitters）的人工泵。用于训练这类人工突触的电伏也和穿行人类神经元所需的能量相同。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些都使得人工神经突触与生物神经元之间的交流成为可能，可借此改进脑机接口。同时，设备的柔软性与灵活性也使得它可被用于生物环境。但是，进行任何生物学方面应用之前，团队计划先打造一列人工神经突触，用于进一步研究与测试。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文链接：http://news.stanford.edu/2017/02/20/artificial-synapse-neural-networks/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Fri, 24 Feb 2017 12:16:21 +0800</pubDate>
    </item>
    <item>
      <title>业界 | Facebook开源大规模预测工具Prophet：支持Python和R</title>
      <link>http://www.iwgc.cn/link/</link>
      <description>
&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自Facebook&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀、黄小天、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;今天，Facebook 宣布开源了一个可以通过 Python 和 R 语言使用的预测工具 Prophet。以下是 Facebook 研究博客对该工具的介绍，后面还附有机器之心对该开源项目 README.md 文件和相关论文摘要的编译介绍。相关论文也可点击文末「阅读原文」查看。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Prophet 项目地址：https://github.com/facebookincubator/prophet&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;预测（forecasting）是一个数据科学问题，也是很多组织机构内许多活动的核心。比如说，像 Facebook 这样的大型组织必须进行能力规划（capacity planning）以有效地分配稀缺资源和目标配置，以便能基于基准对业绩表现进行测量。不管是对于机器还是对于分析师而言，得出高质量的预测都并非易事。我们已经在创建各种各样的业务预测（business forecasts）的实践中观察到了两大主要主题：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;完全自动化的预测技术可能会很脆弱，而且往往非常不灵活，不能整合有用的假设或启发。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;能够产生高质量预测的分析师相当少，因为预测是一种需要大量经验的数据科学领域的专业技能。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这两个主题会导致一个结果：对高质量预测的需求往往超出分析师能够得出的预测速度。这个情况是我们创造 Prophet 的动力：我们想要让专家和非专家都能轻松地做出高质量的预测来满足自身的需求。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于「规模（scale）」的通常考虑涉及到计算和存储，但这些都不是预测的核心问题。我们发现预测大量时间序列（time series）的计算和基础设施问题是相对简单的&amp;mdash;&amp;mdash;通常这些拟合过程可以很容易地并行化，而预测本身也能容易地被存储在 MySQL 这样的关系数据库或 Hive 这样的数据仓库中。据我们观察，「规模」在实践中面临的问题涉及的是由多种预测问题所引入的复杂性（complexity）和在得出预测后如何在大量预测结果中构建信任（trust）。Prophet 已经成为了 Facebook 创建大量可信预测的能力的关键组成部分，这些预测可被用于决策制定甚至用在产品功能中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Prophet 有什么用？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;并非所有的预测问题都可以通过同一种程序（procedure）解决。Prophet 是为我们在 Facebook 所遇到的业务预测任务而优化的，这些任务通常具有以下特点：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;对于历史在至少几个月（最好是一年）的每小时、每天或每周的观察&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;强大的多次的「人类规模级」的季节性：每周的一些天和每年的一些时候&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;事先知道的以不定期的间隔发生的重要节假日（如，超级碗）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;合理数量的缺失的观察或大量异常&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;历史趋势改变，比如因为产品发布或记录变化&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;非线性增长曲线的趋势，其中有的趋势达到了自然极限或饱和&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们发现默认设置的 Prophet 能产生往往和经验丰富的预测师得到的一样准确的预测，而所花费的工作却更少。使用 Prophet，如果该预测不令人满意，你也不用局限于一个完全自动化的程序&amp;mdash;&amp;mdash;即使一个没有接受过任何时间序列方法训练的分析师也能够使用各种各样的可轻松解读的参数来改进或调整预测。我们已经发现：通过在特定案例上将自动化预测和分析师参与的预测（analyst-in-the-loop forecasts）结合到一起，它有可能可适用于非常大范围的业务用例。下图给出了我们发现的可以大规模使用的预测过程：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/a199a014c55f4e0c1e37fe3c11c0b83f97007f14"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于该预测过程的建模阶段，目前仅有有限数量的工具可用。Rob Hyndman 的出色的预测 R 语言的预测软件包（http://robjhyndman.com/software/forecast/）可能是目前最受欢迎的选择，而且谷歌和 Twitter 也都分别发布了带有更加特定的时间序列功能的软件包&amp;mdash;&amp;mdash;CausalImpact（https://google.github.io/CausalImpact/）和 AnomalyDetection（https://github.com/twitter/AnomalyDetection）。就我们所知，在使用 Python 的预测上，还少有开源的软件包可用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们常常在许多设置中使用 Prophet 作为预测（forecast）软件包的替代，因为其有如下两个主要优点：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1.Prophet 让我们可以更加简单直接地创建合理且准确的预测。该预测包包含了许多不同的预测技术（比如 ARIMA、指数平滑等），其中每一个都有它们自己的长处、短处和调整参数。我们发现错误的模型或参数选择往往会导致糟糕的结果，而在这样的选择阵列下，即使是经验丰富的分析师也不太可能能够有效地选择出正确的模型和参数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2.Prophet 预测可以通过对非专家而言很直观的方式进行自定义。有关于季节性的平滑参数让你能调整与历史周期之间的接近程度，以及关于趋势的平滑参数让你能调整跟随历史趋势变化的激进程度。对于增长曲线而言，你可以手动设定「capacity」或增长曲线的上限，这能让你注入关于你预测的增长或下降情况的先验信息。最后，你还可以为模型指定没有规律的节假日，比如超级碗、感恩节和黑色星期五的日期。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Prophet 如何工作&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本质上讲，Prophet 程序是一个可加性回归模型（additive regression model），它包含 4 个主要组件：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;分段线性或者 logistic 增长曲线趋势。通过从数据中选择变化点，Prophet 自动探测趋势变化。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;使用傅立叶级数建模每年的季节分量。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;使用虚变量（dummy variables）的每周的季节分量。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;用户提供的重要节假日列表。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;例如，下面是一个特征预测：使用 wikipediatrend 包（https://cran.r-project.org/web/packages/wikipediatrend/index.html）下载的 Peyton Manning 的维基百科页面的查看数量的日志。由于 Peyton Manning 是一名美式橄榄球运动员，你可以看到他每年季节性的重要程度变化，同时每周的周期性也明显存在。最后你看到特定事件（比如他参加的季后赛）也可能被建模了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/6a07881fdc7dd2e068ab6d53319dcd5cc2e5e7f2"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Prophet 将提供一个组分图，用图形描述它所拟合的模型：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/b638af6ff277eadc284d7c7265f40e898569ba77"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个组分图更加清晰地展示了与浏览 Peyton Manning 的网页（橄榄球常规赛与季后赛）相关的每年的季节性，以及每周的季节性：（星期日和星期一）比赛当天和比赛之后有更多的访问。你也可以注意到趋势组件自他最近退休以来的下行调整。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Prophet 的重要思想是：通过更好地灵活拟合趋势组分，我们可以更精确地建模季节性，并且有更准确的预测结果。对于这个任务我们更喜欢使用非常灵活的回归模型（有一点像曲线拟合）而不是传统的时序模型，因为前者可以使我们建模更灵活，更容易拟合模型，更优雅地处理丢失数据或离群值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过模拟时间序的未来趋势变化，Prophet 默认地会为趋势组分提供不确定的间隔。如果你希望对未来季节性或假期影响的不确定性进行建模，你可以运行数百个 HMC 迭代（花费几分钟），你的预测就将会包括季节性不确定评估。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们使用 Stan（http://mc-stan.org/）调整 Prophet 模型，并在 Stan 的概率编程语言中实现了 Prophet 流程的核心部分。Stan 对参数的 MAP 优化有着极快的速度（&amp;lt;1 秒），让我们可以选择使用 Hamiltonian Monte Carlo 算法评估不确定的参数，也使得我们能够在多种接口语言上重复使用该拟合程序。目前，我们提供了 Python 和 R 语言的 Prophet 实现。它们有着几乎相同的特征，而且通过提供这两种实现，我们希望该预测方法能够在数据科学社区有更广泛的用途。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;如何使用 Prophet&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使用 Prophet 的最简单方法是从 PyPI（Python）或 CRAN（R）里安装这个软件包。你可以阅读我们的快速入门指南，以及阅读综合文档以进行深入的了解。如果你正在寻找一个有趣的时序数据资源，我们建议你尝试一下 wikipediatrend 软件包，它可以从维基百科页面上下载历史页面点击数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以下是机器之心对 Prophet 项目上 README.md 文件的编译介绍：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Prophet 是一个预测时序数据的程序。它基于加法模型（additive model），其中非线性趋势可与按年和按周的季节性、以及节假日进行拟合。借助至少一年的历史数据，它在每日预测数据上表现最好。在数据丢失、趋势变换以及大离群值方面，Prophet 表现也很稳健。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Prophet 是由 Facebook 的 Core Data Science 团队发布的一个开源软件，可从 CRAN 和 PyPI 上下载。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;重要链接&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;主页：https://facebookincubator.github.io/prophet/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;HTML 文档：https://facebookincubator.github.io/prophet/docs/quick_start.html&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;问题跟踪：https://github.com/facebookincubator/prophet/issues&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;源代码库：https://github.com/facebookincubator/prophet&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Prophet R 软件包： https://cran.r-project.org/package=prophet&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Prophet Python 软件包：https://pypi.python.org/pypi/fbprophet/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;在 R 中安装&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Prophet 是一个 CRAN 软件包，因此你可以使用 install.packages：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;# R&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&amp;gt; install.packages('prophet')&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;完成安装，你就可以开始了！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Windows&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 Windows 中，R 需要一个编译器，你可以遵循 rstan 提供的指导：https://github.com/stan-dev/rstan/wiki/Installing-RStan-on-Windows。关键一步是在试图安装软件包之前安装 Rtools：http://cran.r-project.org/bin/windows/Rtools/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;在 Python 中安装&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Prophet 在 PyPI 上，因此你可以用 pip 安装它：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;# bash&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;$ pip install fbprophet&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Prophet 的主要依赖包是 pystan。PyStan 有自己的安装说明：http://pystan.readthedocs.io/en/latest/installation_beginner.html&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;完成安装，你就可以开始了！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Windows&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 Windows 中，PyStan 需要一个编译器，因此你将遵循这个指导：&lt;/span&gt;&lt;span&gt;http://pystan.readthedocs.io/en/latest/windows.html。关键一步是安装一个最新的 C++编译器：http://landinghub.visualstudio.com/visual-cpp-build-tools&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;论文：Forecasting at Scale&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/76891959af79a55c013f189410687dfe99324cdf"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：要在各种时间序列（time series）上产生大量预测，我们面临着各种各样的挑战。我们实现大规模预测（forecasting at scale）的方法是将可配置的模型和全面的分析师参与的（analyst-in-the-loop）性能分析结合到一起。我们提出了一种基于一种可分解模型（decomposable model）的预测方法，这种模型带有可解释的参数，这些参数可被分析师直观地进行调整。我们描述了我们可以用来比较和评估预测程序的表现分析，并且自动标记了需要人工审查和调整的预测。这些能帮助分析师最有效地使用他们的专业知识工具实现了对许多类型业务时间序列的可靠预测。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Fri, 24 Feb 2017 12:16:21 +0800</pubDate>
    </item>
    <item>
      <title>教程 | 你来手绘涂鸦，人工智能生成「猫片」：edges2cats图像转换详解</title>
      <link>http://www.iwgc.cn/link/</link>
      <description>
&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自Affinelayer&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：黄小天、曹瑞、蒋思源&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;edges2cats 是最近网络中火爆的开源应用，它能以你随手鼠绘的单色线图为基础自动生成一张「真实图片」。其中绘制猫的版本最受欢迎。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/5806c20920aaf720b6b4fc11f7e52f495052a109"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 2 月 19 日推出以后，这个实现很快受到了大家的关注，甚至连 Yann LeCun 这样的重量级人物也在其中开始了自己的「创作」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/c72079f203e7a26dba60e18b66ab5be4ab0ead90"/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/4f5233110fcb0f4132d1725a3568db3ddb3937e5"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这一神奇的应用是如何实现的？让我们看看作者 Christopher Hesse 带来的教程吧。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相关链接：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Edges2cats：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;http://affinelayer.com/pixsrv/index.html&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Github：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://github.com/phillipi/pix2pix&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Isola 等人在 pix2pix 中得到的结果看起来很不错，它是对抗性网络的一种绝佳实现，所以我将 Torch 上的代码移植到了 Tensorflow 中。在 Github 上单文件版（single-file）的实现 pix2pix-tensorflow 已经可供下载：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://github.com/affinelayer/pix2pix-tensorflow&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面是 pix2pix 的一些例子，我将从论文开始一步步解释这到底是什么。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/e49a65d55baaa61dc98889c9ac8f3c54c7a29b5a"/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;「术士的宝石，是魔力无边的宝石，它能点石成金、创造不朽、复生鬼魂、杀死巨魔，它无所不能。」&amp;mdash;&amp;mdash;&lt;span&gt;Wizard People, Dear Readers&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;pix2pix 也许不能复生鬼魂，但是如果你给它一个包含了普通石头和其相对金子形态的数据集，那么 pix2pix 还真能点石成金。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;运行代码&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;code style=" box-sizing: inherit; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; "&gt;&lt;span&gt;&lt;span&gt;# make sure you have Tensorflow 0.12.1 installed first&lt;/span&gt;python -c &lt;span&gt;"import tensorflow; print(tensorflow.__version__)"&lt;/span&gt;&lt;span&gt;# clone the repo&lt;/span&gt;&lt;span&gt;git&lt;/span&gt; clone https://github.com/affinelayer/pix2pix-tensorflow.git&lt;span&gt;cd&lt;/span&gt; pix2pix-tensorflow&lt;span&gt;# download the CMP Facades dataset http://cmp.felk.cvut.cz/~tylecr1/facade/&lt;/span&gt;python tools/download-dataset.py facades&lt;span&gt;# train the model# this may take 1-9 hours depending on GPU, on CPU you will be waiting for a bit&lt;/span&gt;python pix2pix.py \
 &amp;nbsp;--mode train \
 &amp;nbsp;--output_dir facades_train \
 &amp;nbsp;--max_epochs 200 \
 &amp;nbsp;--input_dir facades/train \
 &amp;nbsp;--which_direction BtoA&lt;span&gt;# test the model&lt;/span&gt;python pix2pix.py \
 &amp;nbsp;--mode &lt;span&gt;test&lt;/span&gt; \
 &amp;nbsp;--output_dir facades_test \
 &amp;nbsp;--input_dir facades/val \
 &amp;nbsp;--checkpoint facades_train&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;终端&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在经过一段时间的训练后，你大概会得到类似于以下的输出：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/7c23dced4f6482610d164d4d552b280a3b278151"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;pix2pix 是怎样运作的？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;pix2pix 使用了一种条件生成式对抗网络（Conditional Generative Adversarial Networks）来学习从输入图像到输出图像的映射。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个网络由两个主要部分组成，生成器（generator）和辨别器 (discriminator)。生成器接收了输入图像，经过转变来得到输出图像。辨别器将输入图像与未知图像（不管是数据集中的目标图像，或是辨别器产生的输出图像）进行比较，并尝试猜测该图像是否由生成器生成。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个数据集的例子就是输入图像是黑白图片，但是目标图像是这个图像的彩色版本：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/c0456629d9da0240bf6370bc5b974bf2a7cbdb9e"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这种情况下，生成器就会去尝试学习如何让黑白图像变为彩色：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/08b365d9684ac5248cc465c5eaf6c07c4cdaf827"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;辨别器看到生成器彩色化的尝试，就会去试着学习分辨生成器彩色化的图像和数据集中真正有颜色的目标图像之间的区别。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/a32f19b5aace5ee2d0aed8c13f7d781b5faa0b60"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为什么要这么麻烦呢？这篇论文其中的一个重点就是辨别器为训练生成器提供了一个损失函数，你不需要手动指定。人工设计（Hand-engineered）的转换代码已经由经过训练的神经网络所替代，所以为什么不能把手动设计的损失函数运算也替代了呢？如果这起作用的话，在你还在担忧计算机会取代你的工作时，它们就已经开始接管工作了。让我们来看一看对抗式网络的两个组成部分：生成器和辨别器。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;生成器&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;生成器的工作就是对一张输入图像进行我们想要的转换，以生成目标图像。输入图像应该是黑白图像，输出图像我们想让它成为彩色版本。生成器的结构叫做「编码器&amp;mdash;解码器」（encoder-decoder），在 pix2pix 模型中，编码器&amp;mdash;解码器看起来就如下图所示：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/18e307d8a98b2b050a65b3c11bb09894a9739988"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里的容量给你一种紧挨着张量维度的形状感。样例中的输入是一个带有 3 个颜色通道（红、绿、蓝，全部等于一个黑白图像）的 256x256 图像，并且输出相同。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;生成器获得一些输入，并试图用一系列的编码器（卷积+激活函数）减少它，直到成为一个较小的表征。想法是通过这种方式压缩它我们希望在最后一个编码层之后有一个更高层面的表征。解码层执行相反操作（去卷积+激活函数），并且反转编码层的行动。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/fa96e2d1e6189fc872a1e813a3339389eeed17e9"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了提高论文中图到图传输的表现，作者使用 「U-Net」取代了 encoder-decoder。它们在做同样的事，不同的是有了直接连接编码层和解码层的跳跃连接。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/cebb74a96bf13cbe7f21162245630f8b0c0c58c7"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;跳跃连接给了网络一个忽略编码／解码部分的选择，如果它对其毫无用处。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些图解略有简化。例如，网络的第一层和最后一层之间没有批标准层，中间的个别层有丢失的单元。论文中使用的着色模式对于输入和输出层有着很多不同的通道。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;辨别器&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;辨别器（The Discriminator）的目标就是接收两张图像，一张是输入图像，另一张是未知图像（其可能是辨别的目标或者是生成器输出的图像），辨别器的工作就是识别第二张图像到底是不是从生成器（the generator）输出的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/fc4f9e7316185b218a3351955281c33bff50f74d"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该结构看起来就像是生成器的编码部分一样，只不过稍微复杂一点。输出是 30&amp;times;30 的图像，其中每一个像素值（从 0 到 1）表示未知图像相应部分的置信度。在 pix2pix 的实现中，30&amp;times;30 图像中每一个像素都对应着 70&amp;times;70 块输入图像的置信度（因为输入图像是 256&amp;times;256 的，所以这些图像块有很多重叠）。这种构架就称之为「区块生成对抗网络（PatchGAN）」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;训练&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了训练该网络，我们需要分两步进行：即训练辨别器（discriminator）和训练生成器（generator）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了训练辨别器，首先生成器需要生成一张输出图像。辨别器再根据输入/目标对（input/target pair）和输入/输出对（input/output pair）判定该图像有多大程度看起来是真实的。然后基于输入/输出对（input/output pair）和输入/目标对（input/target pair）的分类误差来调整辨别器的权重。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/1895194fe83b847b593d109ed7071d297006b8a7"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;根据鉴别器的输出和输出与目标图像之间的差异来调节生成器的权重。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/d6e1425ac4ec181e10c57dd9c37fb3c428c6b125"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里有一个技巧：当你在鉴别器的输出结果上训练生成器时，你实际上是在计算鉴别器的梯度，这意味着当鉴别器性能提升时，你是在训练生成器打败鉴别器。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中的原理是这样：当鉴别器变的越来越好时，生成器也是。如果鉴别器擅长这项任务，生成器有能力通过梯度下降学习正确的映射函数，你应该得到一个逼真的生成输出。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;验证&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们从一台装有 Nvidia GTX 750 Ti 显卡（~1.3 TFLOPS）的 Linux 主机上执行代码进行验证。由于计算能力的欠缺，验证并不广泛，并且只有 200 个 epoch 中的 facades 数据集被测验。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;终端&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;code style=" box-sizing: inherit; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; "&gt;&lt;span&gt;&lt;span&gt;git&lt;/span&gt; clone https://github.com/affinelayer/pix2pix-tensorflow.git&lt;span&gt;cd&lt;/span&gt; pix2pix-tensorflow
python tools/download-dataset.py facades&lt;span&gt;sudo&lt;/span&gt; nvidia-docker run \
 &amp;nbsp;--volume &lt;span&gt;$PWD&lt;/span&gt;:/prj \
 &amp;nbsp;--workdir /prj \
 &amp;nbsp;--env PYTHONUNBUFFERED&lt;span&gt;=&lt;/span&gt;x \
 &amp;nbsp;affinelayer/pix2pix-tensorflow \
 &amp;nbsp;python pix2pix.py \
 &amp;nbsp; &amp;nbsp;--mode train \
 &amp;nbsp; &amp;nbsp;--output_dir facades_train \
 &amp;nbsp; &amp;nbsp;--max_epochs 200 \
 &amp;nbsp; &amp;nbsp;--input_dir facades/train \
 &amp;nbsp; &amp;nbsp;--which_direction BtoA&lt;span&gt;sudo&lt;/span&gt; nvidia-docker run \
 &amp;nbsp;--volume &lt;span&gt;$PWD&lt;/span&gt;:/prj \
 &amp;nbsp;--workdir /prj \
 &amp;nbsp;--env PYTHONUNBUFFERED&lt;span&gt;=&lt;/span&gt;x \
 &amp;nbsp;affinelayer/pix2pix-tensorflow \
 &amp;nbsp;python pix2pix.py \
 &amp;nbsp; &amp;nbsp;--mode &lt;span&gt;test&lt;/span&gt; \
 &amp;nbsp; &amp;nbsp;--output_dir facades_test \
 &amp;nbsp; &amp;nbsp;--input_dir facades/val \
 &amp;nbsp; &amp;nbsp;--checkpoint facades_train&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;出于对比，验证集中的第一个图像看起来像这样：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/75175bb1a2c2f6cfbdbf489bd9a20a9b9548048e"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;验证结果集：&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://affinelayer.com/pix2pix/validation.zip&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;实现&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;实现是一个单一文件 pix2pix.py ，尽可能在 TensorFlow 图谱之内。移植过程多是观察现有的 Torch 实现和 Torch 源代码，搞明白什么种类的层和设置被使用，以确保 TensorFlow 版本与原始版本尽可能一致。调试一个有问题的实现很耗时间，因此我细心地尝试这次转化以规避掉大量的调试。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;pix2pix.py：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;https://github.com/affinelayer/pix2pix-tensorflow/blob/master/pix2pix.py&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;实现开始于创建生成器图，接着是鉴别器图，最后是训练系统。在运行时使用 Torchpix2pix 代码打印生成器和鉴别器图。我在 Torch 框架源中寻找不同的图层类型，并发现了当前的设置和操作，以及如何在 Tensorflow 中将其实现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最理想的情况是能把 pix2pix 训练的网络权重导进 Tensorflow 以验证图形构造。但是这令人厌烦，而且我很不擅长 Torch，所以我没有那样做。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本代码中的大多数错误与 Tensorflow 的 build-graph-then-execute 模型相关，如果你习惯于命令式代码，那么 Tensorflow 会让你感到一点惊讶。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;论文：&lt;strong&gt;Image-to-Image Translation with Conditional Adversarial Networks&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/5db86ea99d77ef6930b5d73a750a1f257c66018f"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：&lt;/span&gt;&lt;span&gt;为实现图像到图像转化（image-to-image translation）任务，我们研究了条件对抗网络。这些网络不仅会学习从输入图像到输出图像的映射，而且还学习损失函数来训练映射。这使得我们不必在此类任务中加入通常需要的不同的损失公式。我们的实验证明了这种方法在从有标记的地图中生成照片，利用单色线图生成照片，为黑白图填充色彩等任务中是有效的。我们证明了在此类模型的训练中，人类不再需要手动输入的映射函数以及损失函数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文链接：https://affinelayer.com/pix2pix/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Fri, 24 Feb 2017 12:16:21 +0800</pubDate>
    </item>
    <item>
      <title>专栏 | 顾险峰：看穿机器学习的黑箱（III）</title>
      <link>http://www.iwgc.cn/link/</link>
      <description>
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;转自老顾谈几何&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;公众号ID：conformalgeometry&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：顾险峰&amp;nbsp;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;这篇文章是顾险峰老师所写的《看穿机器学习的黑箱》的第三篇，&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650723168&amp;amp;idx=3&amp;amp;sn=41fcf2fb0408c7b6a9b82d55d91c2b9c&amp;amp;chksm=871b171eb06c9e082c4083ff32748104a617e5cb1e6bd4d296b4db431358b8a41f40908ea8a5&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650723168&amp;amp;idx=3&amp;amp;sn=41fcf2fb0408c7b6a9b82d55d91c2b9c&amp;amp;chksm=871b171eb06c9e082c4083ff32748104a617e5cb1e6bd4d296b4db431358b8a41f40908ea8a5&amp;amp;scene=21#wechat_redirect" target="_blank"&gt;第一篇&lt;/a&gt;与&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650723249&amp;amp;idx=5&amp;amp;sn=a0b0d42b3a55456ba680b756592aade9&amp;amp;chksm=871b17cfb06c9ed9905f24bbe84366002e01915a3a2991992114c15125249f2f5166d025f695&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650723249&amp;amp;idx=5&amp;amp;sn=a0b0d42b3a55456ba680b756592aade9&amp;amp;chksm=871b17cfb06c9ed9905f24bbe84366002e01915a3a2991992114c15125249f2f5166d025f695&amp;amp;scene=21#wechat_redirect" target="_blank"&gt;第二篇&lt;/a&gt;可点击超链接查看。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;上周，老顾访问了UCLA的师兄朱松纯教授和吴英年教授，向他们学习计算机视觉的统计观点。早在二十多年前，以Mumford先生，朱松纯教授为代表的计算机视觉领域的哈佛学派就大力提倡将统计概率系统性地引进到视觉领域，用统计方法来解释和处理视觉领域的基本问题。目前，这一方法论早已在视觉领域深入人心，实际上也是机器学习的理论基础之一。最优传输理论描述了概率分布的几何，因此有助于我们研究视觉方面的机器学习。下面，我们开始撰写第三次讲稿。&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;概览&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;直观而言，视觉领域机器学习的统计观点如下：我们将所有可能的图像构成的空间设为&lt;img src="http://img03.iwgc.cn/mpimg/334ef486bf2a83bd5bc2b82a63debc67d6234b28"/&gt;，其中n是总的像素个数，每张图像视为全图像空间中的一个点&lt;img src="http://img04.iwgc.cn/mpimg/9ed6e8be86fada6feb22aa01c28823828a5d62e0"/&gt;。每个有意义的视觉&amp;ldquo;概念&amp;rdquo;（例如所有猫的图像）是全空间&lt;img src="http://img05.iwgc.cn/mpimg/9c1c3851f6c56ae19cd4fd7920a1a0b65acb301c"/&gt;的一个可测子集，&lt;img src="http://img05.iwgc.cn/mpimg/746e39b2e5006318db52d1bd82e6c9e318d6485b"/&gt;。固定一个概念&lt;img src="http://img03.iwgc.cn/mpimg/1119b2a4bed0d12afe60942fd0723cf5510dd3ab"/&gt;，每张图片是否表达了这个概念就给出了一个概率分布&lt;img src="http://img03.iwgc.cn/mpimg/ccfd860e808c2e9f761931353d771e4c64be3024"/&gt;。这样，视觉中的问题就被转化为概率统计的问题：如何表示概率分布，如何衡量概率分布间的距离，如何近似一个概率分布，如何生成满足特定概率分布的随机变量，如何根据概率分布进行统计推断，等等。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;近年来，依随Internet技术的发展，人类已经积累了大量的视觉数据，这使得估计各种概率分布成为可能。同时，GPU技术的发展，使得各种统计计算方法的实现成为可能。因此，我们迎来了机器学习的科技大潮。但是，我们依然无法严密解释机器学习算法的有效性。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;老顾倾向于认为，从基础理论角度而言，研究概率分布的一个强有力工具是最优传输理论（optimal mass transportation theory），这个理论着重揭示概率分布这一自然现象的内在规律，因此并不从属于某个学派，也不依赖于具体的算法。相反，这一理论会为算法的发展提供指导，同时真正合理有效的算法（例如机器学习算法），应该可以被传输理论来解释。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;简而言之，传输理论给出了概率分布所构成空间的几何。给定一个黎曼流形，其上所有的概率分布构成一个无穷维的空间：Wasserstein空间，最优传输映射的传输代价给出了Wasserstein空间的一个黎曼度量。Wasserstein空间中的任意两点可以用Wasserstein距离来测量相近程度，自然也可以用测地线来插值概率分布。每个概率分布有熵，沿着测地线熵值的变化规律和黎曼流形的曲率有着本质的关系。这一几何事实在网络领域已经被应用，但在视觉领域，似乎还没有相关工作。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;但在实际计算中，高维的最优传输映射，Wasserstein距离计算复杂。一个自然的想法是降维，将高维空间的概率分布投影到低维子空间，在低维空间上计算边际分布之间的变换。这有些象盲人摸象，每次得到局部信息，如果摸得充分，我们也可以恢复大象的整体信息。&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;回顾&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;在&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650723168&amp;amp;idx=3&amp;amp;sn=41fcf2fb0408c7b6a9b82d55d91c2b9c&amp;amp;chksm=871b171eb06c9e082c4083ff32748104a617e5cb1e6bd4d296b4db431358b8a41f40908ea8a5&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650723168&amp;amp;idx=3&amp;amp;sn=41fcf2fb0408c7b6a9b82d55d91c2b9c&amp;amp;chksm=871b171eb06c9e082c4083ff32748104a617e5cb1e6bd4d296b4db431358b8a41f40908ea8a5&amp;amp;scene=21#wechat_redirect" target="_blank"&gt;第一讲&lt;/a&gt;（看穿机器学习W-GAN的黑箱）中，我们给出了最优传输问题的凸几何解释：给定两个概率分布&lt;img src="http://img04.iwgc.cn/mpimg/8ca611df353e4cf31c990a209457126e593bd4f2"/&gt;，存在唯一的最优传输映射&lt;img src="http://img04.iwgc.cn/mpimg/446342b8670e34d5858d379ad4b094f10a6b8dea"/&gt;，将初始概率分布&lt;img src="http://img03.iwgc.cn/mpimg/7031586284b57d593bceb9d714ab281bd6fa2195"/&gt;变换成目标概率分布&lt;img src="http://img04.iwgc.cn/mpimg/f2fa01a0bd990574a517ef9a0d1561956d369bc9"/&gt;，&lt;img src="http://img04.iwgc.cn/mpimg/6362b39c375266a41ac533764bae0917b71ae563"/&gt;，同时极小化传输代价，&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/fdf1cb2368cbfad33b2de1874589b86c09ef0dc0"/&gt;,&lt;/p&gt;&lt;p&gt;这里&lt;img src="http://img03.iwgc.cn/mpimg/3f6ad912b9d8ee8a1f7258487d70572828b7dffe"/&gt;被称为是两个概率分布&lt;img src="http://img05.iwgc.cn/mpimg/8ca611df353e4cf31c990a209457126e593bd4f2"/&gt;之间的Wasserstein距离。同时，最优传输映射是某个凸函数&lt;img src="http://img04.iwgc.cn/mpimg/2034158271aefbb67356ad6f2d0509f34fb62369"/&gt;的梯度映射，&lt;img src="http://img04.iwgc.cn/mpimg/6cfbf997f986d042cc7048c9dc21439387cdaf85"/&gt;，这个函数满足蒙日-安培方程。我们的理论给出了一种几何变分方法来求解最优传输映射。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;在&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650723249&amp;amp;idx=5&amp;amp;sn=a0b0d42b3a55456ba680b756592aade9&amp;amp;chksm=871b17cfb06c9ed9905f24bbe84366002e01915a3a2991992114c15125249f2f5166d025f695&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650723249&amp;amp;idx=5&amp;amp;sn=a0b0d42b3a55456ba680b756592aade9&amp;amp;chksm=871b17cfb06c9ed9905f24bbe84366002e01915a3a2991992114c15125249f2f5166d025f695&amp;amp;scene=21#wechat_redirect" target="_blank"&gt;第二讲&lt;/a&gt;（看穿机器学习的黑箱（II））中，我们澄清了这样的观点：相比于学习一个映射，学习一个概率分布要容易很多。满足&lt;img src="http://img03.iwgc.cn/mpimg/6362b39c375266a41ac533764bae0917b71ae563"/&gt;的映射构成了一个无穷维的李群。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;但是，在视觉问题中，通常图像全空间的维数非常高，计算难度较高。因此，我们可以放弃理论上的最优性，寻找计算更加简单有效，同时又和最优传输距离等价的算法。下面，我们就讨论这些更为实用的算法及其背后的理论。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;直方图均衡化&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/d2d56486a79542bc441231e1b228ecade300acca"/&gt;&lt;br&gt;&lt;span&gt;图1. 直方图均衡化结果（histogram equalization）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;直方图均衡化是提高灰度图像对比度的常见算法。如图1所示，左侧输入图像的灰度分布在一个狭窄区域，朦胧昏暗；右侧是直方图均衡化的结果，清晰明亮，对比鲜明。我们设输入图像像素的灰度为一随机变量，其取值范围为单位区间&lt;/span&gt;&lt;img src="http://img03.iwgc.cn/mpimg/ec15b0300f1ea8fdcec1fbd7ff1230432c86d044"/&gt;&lt;span&gt;，其概率测度为&lt;/span&gt;&lt;img src="http://img05.iwgc.cn/mpimg/b6f0a0c634feef3c4823d4fc0edcb15e9b475946"/&gt;&lt;span&gt;，直方图均衡化算法的核心就是求灰度空间（单位区间）到自身的一个映射&lt;/span&gt;&lt;img src="http://img03.iwgc.cn/mpimg/e940702c4be1dd332bb90a1866bfaca028d21ce8"/&gt;&lt;span&gt;，这一映射将&lt;/span&gt;&lt;img src="http://img03.iwgc.cn/mpimg/b6f0a0c634feef3c4823d4fc0edcb15e9b475946"/&gt;&lt;span&gt;变换成均匀分布。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;实际上，传统的直方图均衡化就是一维的最优传送映射。假设我们有两个连续的概率分布&lt;img src="http://img03.iwgc.cn/mpimg/8ca611df353e4cf31c990a209457126e593bd4f2"/&gt;，其对应的累积分布函数（CDF）是&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/de348a01ed43fd00d082a52e7b6847df49e23a6d"/&gt;&lt;span&gt;,&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那么直方图均衡化映射就是传输映射：&lt;/span&gt;&lt;img src="http://img05.iwgc.cn/mpimg/e939050a9df93f0acc8306492280654315e3d146"/&gt;&lt;span&gt;。首先，我们可以证明这个映射满足两个条件：&lt;/span&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;li&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/6362b39c375266a41ac533764bae0917b71ae563"/&gt;&lt;span&gt;，&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;单调递增。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;span&gt;另一方面，我们应用最优传输理论：存在一个凸函数，其梯度映射给出最优传输映射。由函数&lt;/span&gt;&lt;img src="http://img05.iwgc.cn/mpimg/e3fdb1561a38907777403c264110e644c20e9d19"/&gt;&lt;span&gt;的凸性，我们得到最优传输映射也满足上面两条性质。更进一步，我们可以证明，在一维情形，满足上面两条的映射是唯一的。这意味着，&lt;span&gt;一维直方图均衡化映射就是最优传输映射&lt;/span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此，一维的最优传输映射非常容易计算。下面，我们应用一维最优传输映射来近似高维最优传输映射。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;迭代分布传输算法&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;有多种最优传输映射的近似算法。我们先讨论&lt;span&gt;迭代分布传输算法&lt;span&gt;（Iterative Distribution Transfer ）：给定单位向量&lt;img src="http://img03.iwgc.cn/mpimg/fa6f69777b2b699e38ec03eb5568b3f1c2dae34a"/&gt;，我们将整个空间投影到一维线性子空间&lt;img src="http://img05.iwgc.cn/mpimg/982e6367dff9320669161b479c18c762a43c0e8a"/&gt;上，投影映射为：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="http://img03.iwgc.cn/mpimg/2b8c43a8fb2b56b306199f8b35c07c796b6b227d"/&gt;，&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;投影诱导的概率分布（边际概率分布）记为&lt;img src="http://img03.iwgc.cn/mpimg/fc672a395be95680b6107e2b77b368533d63ae49"/&gt;。&lt;/span&gt;在算法第k步，假设当前源空间的概率分布为&lt;img src="http://img03.iwgc.cn/mpimg/11146d8a512ed950049a708d4a92bab72ab9c169"/&gt;；我们随机选取欧氏空间&lt;img src="http://img03.iwgc.cn/mpimg/76d35129fabc9645c7e3cd4a2d8271d1553152ab"/&gt;的一个标准正交基&lt;img src="http://img04.iwgc.cn/mpimg/5618be7f68aea3f4e8a7a643c086cf66da30ffe4"/&gt;；为每一个基底向量&lt;img src="http://img04.iwgc.cn/mpimg/0711ec5b8cfc8aa61a76603d7e7a890c81049c50"/&gt;构造一维的最优传输映射&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/66cf6d1b581122078cc575e605e052ab750b845f"/&gt;，&lt;/p&gt;&lt;p&gt;由此构造映射，在标架&lt;img src="http://img05.iwgc.cn/mpimg/54867b137003a90b759b7cdd1d16a3c5b3088f01"/&gt;下&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/5b707522f37f0e45f42366fe17fb6e5049ab26df"/&gt;，&lt;/p&gt;&lt;p&gt;其诱导的概率分布为&amp;nbsp;&lt;img src="http://img05.iwgc.cn/mpimg/8d001a45f2364b80ffc916efbcc3e074c7f2a323"/&gt;。不停地重复这一步骤，对于足够大的n，复合映射：&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/b78d3f03b5476731d68a880b6bea93bee8b72757"/&gt;,&lt;br&gt;&lt;/p&gt;&lt;p&gt;将初始概率分布&lt;img src="http://img03.iwgc.cn/mpimg/7031586284b57d593bceb9d714ab281bd6fa2195"/&gt;映成了目标概率分布&lt;img src="http://img05.iwgc.cn/mpimg/f2fa01a0bd990574a517ef9a0d1561956d369bc9"/&gt;。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/aef25add2f575d6b3775264ba384595c7b45ef4d"/&gt;&lt;/p&gt;&lt;p&gt;图2. 从拉东变换恢复的医学图像。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;这一论断的证明需要用到拉东变换（Radon Transform）：给定&lt;img src="http://img04.iwgc.cn/mpimg/6b096794bd1c6c051f336fdfd30195a1f9668cda"/&gt;中的一个概率分布&lt;img src="http://img03.iwgc.cn/mpimg/d5d8b0894f29c3116d9f267b5b09b6383d109ef7"/&gt;，&lt;img src="http://img03.iwgc.cn/mpimg/d5d8b0894f29c3116d9f267b5b09b6383d109ef7"/&gt;的Radon transform&amp;nbsp;&lt;img src="http://img04.iwgc.cn/mpimg/8b4ccc2f5dd547ef39b8f3de8c2a510b003bbb05"/&gt;是一族一维的概率测度，&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/dfaa19c9d2685de459ee617c23b8d6b243d5a276"/&gt;，&lt;/p&gt;&lt;p&gt;换句话说，给定一个单位向量，它生成一条直线，我们将全空间向这条直线投影，得到边际概率分布。拉东变换的基本定理断言：如果两个概率测度的拉东变换相等，则两个概率测度相等。如图2所示，这一定理是医学图像上CT断层扫描技术的基本原理。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;迭代算法如果最后达到一个平衡状态，则在任意一条过原点的直线上，&lt;img src="http://img03.iwgc.cn/mpimg/54ff51041ea207e924652f4c9e618649dbe565c5"/&gt;的边际概率分布等于&lt;img src="http://img05.iwgc.cn/mpimg/d5d8b0894f29c3116d9f267b5b09b6383d109ef7"/&gt;的边际概率分布，因此由拉东变换原理&lt;img src="http://img04.iwgc.cn/mpimg/54ff51041ea207e924652f4c9e618649dbe565c5"/&gt;收敛于&lt;img src="http://img05.iwgc.cn/mpimg/d5d8b0894f29c3116d9f267b5b09b6383d109ef7"/&gt;，&lt;img src="http://img05.iwgc.cn/mpimg/c48f737594a8d8148f15785d9dee4094d6f39d63"/&gt;。这样，我们将高维的传输映射转换成一维传输映射的复合，降低了计算难度。&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;投影Wasserstein距离梯度下降法&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;另外一种迭代算法想法比较类似。给定两个&lt;img src="http://img03.iwgc.cn/mpimg/6b096794bd1c6c051f336fdfd30195a1f9668cda"/&gt;上定义的概率测度&lt;img src="http://img05.iwgc.cn/mpimg/d5d8b0894f29c3116d9f267b5b09b6383d109ef7"/&gt;和&lt;img src="http://img05.iwgc.cn/mpimg/e7a7b2f1a6598ade5934559d32908b6fc547808c"/&gt;，对于任意一个单位向量&lt;img src="http://img04.iwgc.cn/mpimg/684261aa71ebf97946c6abfba921696361ce99e4"/&gt;，我们考虑投影映射&lt;img src="http://img04.iwgc.cn/mpimg/8e2097948bcbe2d638f77f73e77211af221973aa"/&gt;。投影映射诱导两个直线上的概率分布&lt;img src="http://img04.iwgc.cn/mpimg/fd6ff791c76903a5d33bc118f0923d255a30e56d"/&gt;和&lt;img src="http://img04.iwgc.cn/mpimg/a96e9e9e13899e7c22f9d405d716de0d8d7330b3"/&gt;，它们之间的最优传输映射记为&lt;img src="http://img04.iwgc.cn/mpimg/3334ef49cd010079295e9ce9ec82b8a9fbda5b07"/&gt;。由此，每个点都沿着&lt;img src="http://img04.iwgc.cn/mpimg/c4fd8664b9651991ed2e90b091c6d4e721f469f6"/&gt;平移一个向量：&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/8da24be78ade0060773e212ddeeb7a36cd8aceb8"/&gt;。&lt;/p&gt;&lt;p&gt;我们考察所有的单位向量，然后取平均&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/7342a3600b5a58e960294de05cc93c298d3b451b"/&gt;，&lt;/p&gt;&lt;p&gt;去一个步长参数&lt;img src="http://img03.iwgc.cn/mpimg/99e5cd1618c4c8a9b80d8967af063bfcaf11c8b6"/&gt;，每个点&lt;img src="http://img03.iwgc.cn/mpimg/1b6688e7eaa77ee72ec5eb105364833446781611"/&gt;平移到&lt;img src="http://img04.iwgc.cn/mpimg/ccdc25bf738196f333feea5e03f95e4c91347ac5"/&gt;，相应的概率分布变为&lt;img src="http://img04.iwgc.cn/mpimg/542c757674eee47afe8188a16924040ef7373c08"/&gt;。重复以上步骤，我们可以证明所得的概率分布沿着&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="http://img04.iwgc.cn/mpimg/1c42161fc297a21ffdf6b9cf28afec47587f8ca7"/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;距离收敛。这里&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="http://img04.iwgc.cn/mpimg/1c42161fc297a21ffdf6b9cf28afec47587f8ca7"/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;距离是所谓的&lt;span&gt;投影Wasserstein距离&lt;/span&gt;，其具体定义如下：&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/18547b1be059dc9109252deb83a839eb2f709c41"/&gt;，&lt;/p&gt;&lt;p&gt;这里&lt;img src="http://img04.iwgc.cn/mpimg/c79880e0caee14ae1a0f2b1a416ccae126c1c7ff"/&gt;是Wasserstein距离。投影Wasserstein距离和Wasserstein距离诱导Wasserstein空间同样的拓扑，但是计算起来相对容易很多。&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/8f80c48bb01e8ef0e00a3a4413a9e45d50c5de43"/&gt;&lt;/p&gt;&lt;p&gt;图3. 用于愚弄深度神经网的图像（A. Nguyen, J. Yosinski and J. Clune, Deep Neural Networks are Easily Fooled: High Confidence Predictions for Unrecognizable Images, CVPR2015.）&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;局限性和脆弱性&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;拉东变换将联合概率分布转换成向所有一维子空间投影所得的边际概率分布，从而实现了降维，简化了计算。但是，如果有一些子空间的边际分布缺失，我们无法精确恢复原来的联合分布。在视觉问题中，每个线性子空间被视为一个特征，向子空间投影，等价于特征提取。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;深度神经网在解决视觉分类问题中表现出色，但是也非常容易被愚弄。如图3所示，人类可以轻易看出这些是非自然图像，在现实生活中不具备任何意义。但是深度神经网络非常自信地将它们归结为训练过的类别。如果，我们以欣赏现代抽象艺术的心态来研究这些图像，我们能够领会到深度神经网络分类结果的内在合理性：这些图像的确具有它们所对应类别的内在&amp;ldquo;神韵&amp;rdquo;。从纹理层次而言，它们和对应类别的纹理非常&amp;ldquo;神似&amp;rdquo;；从语义层面而言，这些图像则是无意义的和荒谬的。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;我们可以给出一种解释：那就是投影子空间选得不够，因此即便是在这些子空间上边际概率分布相似，但是联合概率分布依然相差很大。深度神经网所得到的训练集是自然图像，图3这些图像都在自然图像空间之外，但是投影在所选择的子空间后，自然图像和非自然图像无法进行分别。由此，引发了深度神经网络脆弱性。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/5885563f9dac73ee15f0ca70ec39d31afd5c96ff"/&gt;&lt;/p&gt;&lt;p&gt;图4. 视网膜到大脑皮层的映射是保角变换。（A. Fazl, S. Grossberg and E. Mingolla, Visual Search， Eye Movements and Object Recognition)&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;讨论&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;人类的低级视觉在很大程度上依赖于统计特性，因此可以归结为对概率分布的处理和演算。人脑是否真的在计算最优传输映射、计算Wasserstein距离？在历史上，人类经常首先发现某些数学原理，然后又发现这些原理在生物器官上早已应用。例如，人类首先发现了傅里叶分解原理，然后发现人类耳蜗神经结构就是在对声音信号进行傅里叶分解；又如，人类首先发现了保角变换（共形变换），后来发现从视网膜到第一级的视觉中枢就是保角变换，如图4所示。这项工作曾经获得过诺贝尔奖。因此，如果若干年后，人们证实大脑的确在计算概率分布之间的距离，老顾也不会觉得意外。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;因此，我们相信在一些视觉应用中，深度神经网络隐含地构建概率模型，我们可以直接用概率的工具，例如最优传输理论及其各种降维近似，直接取代神经网络，从而使得黑箱透明。&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Fri, 24 Feb 2017 12:16:21 +0800</pubDate>
    </item>
    <item>
      <title>学界 | 剑桥与微软提交ICLR 2017论文提出DeepCoder：组合其它程序代码生成新程序</title>
      <link>http://www.iwgc.cn/link/</link>
      <description>
&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自New Scentist&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;作者：Matt Reynolds&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：曹瑞、蒋思源、李泽南&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器学习系统第一次获得了自我编码的能力，剑桥与微软联合提交ICLR 2017的论文提出DeepCoder，可以组合其它程序代码生成新程序。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「走开吧，人类，我自己能搞定了。」&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是第一次，有机器学习系统获得了自我编码的能力。这个机器学习系统叫做 DeepCoder，是由微软和剑桥大学的研究人员所创造的，这一系统可以解决编程竞赛设置的基本挑战。这种方法让人们编写简单程序容易了许多，甚至可以让不会编写代码的人完成任务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「突然之间，人们的工作效率就提高了很多，」麻省理工学院的 Armando Solar-Lezama 说道。「人造系统此前是无法做到这一点的。」Marc Brockschmidt 是英国剑桥微软研究院 Deepcoder 的开发者之一，它认为这种方法最终可以让那些不懂编码的人只要简单描述一个建立程序的想法，就能够让系统来构建。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;DeepCoder 利用了一种叫做「程序合成」（program synthesis）的技术：它创造新程序的方法就是将从现有软件中提取出来的一行一行的代码组合起来&amp;mdash;&amp;mdash;就像是程序员一样。列出每一个代码片段的输入和输出，DeepCoder 就会知道要总体上完成预期结果需要哪些代码。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;利用这种方法，那些不懂编码的人只要能够简单描述一个建立程序的想法，就能够让系统来构建。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这样放任人工智能的一个优势在于，比人类程序员相比，它能够更全面、更广泛地进行搜索，这样组合源代码的方式可能是人类都没有想到的。此外，DeepCoder 利用机器学习来搜寻源代码数据库，并根据它们对这些源代码可能存在的可用性的判断挑出一些代码片段。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些特性使得该系统比之前的其他系统要快得多。DeepCoder 在一秒钟的时间内就可以建立可用的程序。以前的系统在将可用的代码组合起来之前，要花费好几分钟来追踪不同代码的组合。因为 DeepCoder 知道哪种源代码的组合可用，哪些不可用，在每次解决新问题的时候它都能随之改进。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;构建 IPS 系统需要解决两个问题。首先是搜索问题：我们需要搜索一组可能的程序而找到一致性程序（consistent programs）。我们需要定义数据集（如程序空间）和搜索进程。其次是排序问题：如果有多个程序和输入-输出样本具有一致性，哪一个程序是需要返回的结果？这两个问题都取决于问题构想（problem formulation）的具体细节。因此，构想程序合成方法（program synthesis approach）的第一个要点就是选择特定域语言（Domain Specific Language）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这一技术可以应用到很多不同的地方。2015 年，麻省理工学院的研究人员建立了一个自动修复软件漏洞的程序，可以将程序中错误的代码行用其他程序中可以使用的代码行替代。&lt;/span&gt;&lt;span&gt;Brockschmidt 说，未来的版本将会让建立常规程序变得非常简单，例如它可以从网站上搜寻信息，或者自动将 Facebook 上的照片进行分类，而人类程序员连动动手指都不需要。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Solar-Lezama 表示：「这种科技所蕴含的自动化的潜力或许真的意味着编写代码耗费的经历将大幅减少。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是他不认为这些系统会让程序员失业。我们可以通过程序合成（program synthesis）自动编译一些最繁杂的代码，而程序员可以花更多的时间来做一些更复杂的工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前，DeepCoder 仅仅只能解决五行代码内的编程难&lt;/span&gt;&lt;span&gt;题。但是在优良的编程语言中，少量几行代码可以完成相当复杂的程序。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Solar-Lezama 说：「一次性生成大段代码是非常困难的，甚至是不切实际的，但是那些真正大量的代码都是由许多小块代码所拼接的。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，经过不断的训练，系统会变得更加聪明，如果 DeepCoder 能找出哪些程序块在一起能更好地运行，以及什么时候使用一个代码块替换另一个，那么将大大减轻程序员的工作，这也将会是深度学习系统一个非常好的应用。DeepCoder 是一个会学习的系统，随着构建越来越多的程序块，它将越来越强大。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;论文：DEEPCODER: LEARNING TO WRITE PROGRAMS&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/c20ea8cb883c7a9ac28135ef8bafbd1665c0ec5d"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：&lt;/span&gt;&lt;span&gt;我们开发了一种使用输入-输出样本的深度学习来解决编程竞赛风格（programming competition-style）问题。该方法通过训练神经网络来预测由输入到输出生成的程序属性。我们使用神经网络的预测来增强在编程中进行搜寻的技术，其包括了枚举搜寻（enumerative search）和基于 SMT 的解算器（SMT-based solver）。实证表明，我们的方法可以在强非增强型基线（strong non-augmented baselines）和递归神经网络（Recurrent Neural Network）方法上产生一个数量级的加速，并且我们能够解决和在编程竞赛中比最简单问题更复杂一些的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文链接：https://www.newscientist.com/article/mg23331144-500-ai-learns-to-write-its-own-code-by-stealing-from-other-programs/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Fri, 24 Feb 2017 12:16:21 +0800</pubDate>
    </item>
  </channel>
</rss>
