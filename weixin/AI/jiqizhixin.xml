<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>教程 | 没有博士学位，照样玩转TensorFlow深度学习</title>
      <link>http://www.iwgc.cn/link/4468818</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Codelabs&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：侯韵楚、王宇欣、赵华龙、邵明、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;本文内容由机器之心编译自谷歌开发者博客的 Codelabs 项目。据介绍，Google Developers Codelabs 提供了有引导的、教程式的和上手式的编程体验。大多数 Codelabs 项目都能帮助你了解开发一个小应用或为一个已有的应用加入新功能的过程。这些应用涉及到很多主题，包括 Android Wear、Google Compute Engine、Project Tango、和 iOS 上的 Google API。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;本项目的原文可参阅：https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/#13&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1、概述&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdO9nh6G6U3pVLCbOeUqDhb7FmXngMrVGicdQjKCicL42g3lfvr6eYvpjdQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 codelab 项目中，你将学习如何构建并训练出能够识别手写数字的神经网络。在这过程中，当这个神经网络的准确度提升至 99％时，你还会发现深度学习专业人士用来有效训练模型的贸易工具。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个 codelab 项目使用的是 MNIST 数据集，这个包含 60,000 个有标记数字的集合是几届博士努力近二十年的成果。你将会用不到 100 行的 Python/TensorFlow 代码来解决上述问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你将学到：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;①神经网络的定义及如何训练神经网络&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;②如何使用 TensorFlow 构建基本的 1 层神经网络&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;③如何添加多层神经网络&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;④训练提示和技巧：过拟合、dropout、学习速率衰减等...&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;⑤如何解决深度神经网络的问题&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;⑥如何构建卷积网络&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对此，你将需要：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;①Python 2 或 3（建议使用 Python 3）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;②TensorFlow&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;③Matplotlib（Python 的可视化库）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;安装说明会在下一步中给出。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2. 准备：安装 TensorFlow，获取示例代码&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在你的计算机上安装必要软件：Python、TensorFlow 和 Matplotlib。完整的安装说明如下：INSTALL.txt&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;克隆 GitHub 存储库：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;p&gt;$ git clone https://github.com/martin-gorner/tensorflow-mnist-tutorial&lt;/p&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;这个库包含了多个文件，而你将只在mnist_1.0_softmax.py中操作。其它文件是用于加载数据和可视化结果的解决方案或支持代码。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当你启动初始python脚本时，应当能够看到训练过程的实时可视化：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;p&gt;$ python3 mnist_1.0_softmax.py&lt;/p&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOdnYBxdmmHG4vX3OQgQvn6NGt0uhzibIk0paGTXTcEibibMsolGOn4lhcA/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;疑难解答：如果无法运行实时可视化，或者如果你只想要使用文本输出，则可以通过注释掉一行并取消另一行的注释来禁用可视化。请参阅文件底部的说明。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为 TensorFlow 构建的可视化工具是 TensorBoard，其主要目标比我们在这里所需的更宏大。它能使你能够跟踪你在远程服务器上的分布式 TensorFlow 工作。而对于我们的这个实验，matplotlib 将作为替代，并且我们还有额外收获——实时动画。但是如果你使用 TensorFlow 进行严谨的工作，你一定要试试 TensorBoard。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3、理论：训练一个神经网络&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们首先来观察一个正在训练的神经网络。其代码会在下一节解释，所以现在不必查看。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们的神经网络可以输入手写数字并对它们进行分类，即将它们识别为 0、1、2……9。它基于内部变量（「权重（weights）」和「偏差（bias）」，会在后面进行解释），需要有一个正确的值来分类才能正常工作。这个「正确的值」通过训练过程进行学习，这也将在后面详细解释。你现在需要知道的是，训练回路看起来像这样：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Training digits =&amp;gt; updates to weights and biases =&amp;gt; better recognition (loop)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;让我们逐个通过可视化的六个面板，了解训练神经网络需要什么。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdODmcm4QKaZDng3wwLkeibiamawibQcicyhaNAHz5GLGmIibN1W5UnnMibQ8lA/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你可以看到训练数字每次 100 个被送入训练回路；也可以看到当前训练状态下的神经网络是已将数字正确识别（白色背景）还是误分类（红色背景，左侧印有正确的标示，每个数字右侧印有计算错误的标示）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此数据集中有 50,000 个训练数字。我们在每次迭代（iteration）中将 100 个数字送入训练循环中，因此系统将在 500 次迭代之后看到所有训练数字一次。我们称之为一个「epoch」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOVEQLNmqgibCGDVcSE09IZ2oxCmz4icXcNZFWc7DIsEuGsemBCia7F2BibQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了测试在现实条件下的识别质量，我们必须使用系统在训练期间从未看过的数字。否则，它可能记住了所有的训练数字，却仍无法识别我刚才写的「8」。MNIST 数据集包含了 10,000 个测试数字。此处你能看到每个数字对应的大约 1000 种书写形式，其中所有错误识别的数字列在顶部（有红色背景）。左边的刻度会给你一个粗略的分辨率精确度（正确识别的百分比）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOzPxBLL5PPnnv2e57GHJVN9PEBK3afcHsCnlIiaBmI0gSLndIrSm2H0A/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了驱动训练，我们来定义损失函数，即一个展示出系统数字识别能力有多糟的值，并且系统会尽力将其最小化。损失函数（loss function，此处为「交叉熵」）的选择稍后会做出解释。你会看到，随着训练的进行，训练和测试数据的损失会减少，而这个现象是好的，意味着神经网络正在学习。X 轴表示了学习过程中的迭代。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOQPiaHohibpPRNuEhnibDEV4KZmen8ibE82RcXk6vLr5TksJv2t1e0BPTWg/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个准确度只是正确识别的数字的百分比，是在训练和测试集上计算出的。如果训练顺利，它便会上升。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdO5sAVy5w2AziaPMgf5tqgpjIblWuLnXWXneDbFgtwjWRn53YP0RdW2Dg/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOVgpWsytn7tSJicLGnibvibMPFvyTOTq5Y9WnqFBrmrdzVM7UriaI2wzaZQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后的两幅图表说明了内部变量所取的所有值的扩展，即随训练进行而变化的权重和偏置。比如偏置从 0 开始，且最终得到的值大致均匀地分布在-1.5 和 1.5 之间。如果系统不能很好地收敛，那么这些图可能有用。倘若你发现权重和偏差扩展到上百或上千，那么就可能有问题了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图中的条带为百分数。此处有 7 条带，所以每条带是所有值的 100/7，也就是 14%。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;用于可视化 GUI 的键盘快捷键&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1 ......... display 1st graph only 仅显示第 1 张图&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2 ......... display 2nd graph only 仅显示第 2 张图&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3 ......... display 3rd graph only 仅显示第 3 张图&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4 ......... display 4th graph only 仅显示第 4 张图&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;5 ......... display 5th graph only 仅显示第 5 张图&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;6 ......... display 6th graph only 仅显示第 6 张图&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;7 ......... display graphs 1 and 2 显示 1 和 2 图&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;8 ......... display graphs 4 and 5 显示 4 和 5 图&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;9 ......... display graphs 3 and 6 显示 3 和 6 图&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;ESC or 0 .. back to displaying all graphs 返回，显示所有图&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;空格 ..... pause/resume 暂停/继续&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;O ......... box zoom mode (then use mouse) 框缩放模式（然后使用鼠标）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;H ......... reset all zooms 重置所有缩放&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Ctrl-S .... save current image 保存当前图像&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;什么是“权重”和“偏置”？“交叉熵”又是如何被计算的？训练算法究竟是如何工作的？请到下一部分一探究竟。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;4、理论 : 单层神经网络&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOZkicgjjyjxtjQIfmXckY18Ca5BNCe24kiaDZxfIHsMSWWibclAibqYG4QA/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;MNIST 数据集中，手写数字是 28x28 像素的灰度图像。将它们进行分类的最简单的方法就是使用 28x28=784 个像素作为单层神经网络的输入。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOBam4JXCrGU4sCnBnEyLTRAMibRJfomUdt3icX24JoKh9yGPfFOrwqpjQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;神经网络中的每个「神经元」对其所有的输入进行加权求和，并添加一个被称为「偏置（bias）」的常数，然后通过一些非线性激活函数来反馈结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了将数字分为 10 类（0 到 9），我们设计了一个具有 10 个输出神经元的单层神经网络。对于分类问题，softmax 是一个不错的激活函数。通过取每个元素的指数，然后归一化向量（使用任意的范数（norm），比如向量的普通欧几里得距离）从而将 softmax 应用于向量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOwjPHhA5qHOn4vV1qIO86TqTwcS7BWKTn30HKUiazMaNkha65ib1icUibcQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那么为什么「softmax」会被称为 softmax 呢？指数是一种骤增的函数。这将加大向量中每个元素的差异。它也会迅速地产生一个巨大的值。然后，当进行向量的标准化时，支配范数（norm）的最大的元素将会被标准化为一个接近 1 的数字，其他的元素将会被一个较大的值分割并被标准化为一个接近 0 的数字。所得到的向量清楚地显示出了哪个是其最大的值，即「max」，但是却又保留了其值的原始的相对排列顺序，因此即为「soft」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOsc1iaUWm9iaowsZT8apdVvSIticX9yA0lG7tAaszNxaUR0t5KSic1eALYw/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们现在将使用矩阵乘法将这个单层的神经元的行为总结进一个简单的公式当中。让我们直接这样做：100 个图像的「mini-batch」作为输入，产生 100 个预测（10 元素向量）作为输出。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使用加权矩阵 W 的第一列权重，我们计算第一个图像所有像素的加权和。该和对应于第一神经元。使用第二列权重，我们对第二个神经元进行同样的操作，直到第 10 个神经元。然后，我们可以对剩余的 99 个图像重复操作。如果我们把一个包含 100 个图像的矩阵称为 X，那么我们的 10 个神经元在这 100 张图像上的加权和就是简单的 X.W（矩阵乘法）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;每一个神经元都必须添加其偏置（一个常数）。因为我们有 10 个神经元，我们同样拥有 10 个偏置常数。我们将这个 10 个值的向量称为 b。它必须被添加到先前计算的矩阵中的每一行当中。使用一个称为 "broadcasting" 的魔法，我们将会用一个简单的加号写出它。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「Broadcasting」是 Python 和 numpy（Python 的科学计算库）的一个标准技巧。它扩展了对不兼容维度的矩阵进行正常操作的方式。「Broadcasting add」意味着「如果你因为两个矩阵维度不同的原因而不能将其相加，那么你可以根据需要尝试复制一个小的矩阵使其工作。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们最终应用 softmax 激活函数并且得到一个描述单层神经网络的公式，并将其应用于 100 张图像：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOGZkKwmpUrRscOIzbso4YjUhEwicnicGMXu3wSYGassaosNUv4oRDlgww/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;顺便说一下，什么是「tensor（张量）」？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「张量（tensor）」像一个矩阵，但是却有着任意数量的维度。一个 1 维的张量是一个向量。一个二维的张量是一个矩阵。然后你可以有 3, 4, 5 或者更多维的张量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;5、理论：梯度下降&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在我们的神经网络从输入图像中产生预测，我们需要知道它们可以做到什么样的程度，即在我们知道的事实和网络的预测之间到底有多大的距离。请记住，我们对于这个数据集中的所有图像都有一个真实的标签。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;任何一种定义的距离都可以进行这样的操作，普通欧几里得距离是可以的，但是对于分类问题，被称为「交叉熵（cross-entropy）」的距离更加有效。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOUNDMfnZ1HG2frK0f9UFjPUiaH2DwAD0ehdJy8wOiaNDyerSyWY8YfcQw/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「one-hot」编码意味着你使用一个 10 个值的向量，其中除了第 6 个值为 1 以外的所有值都是 0。这非常方便，因为这样的格式和我们神经网络预测输出的格式非常相似，同时它也作为一个 10 值的向量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「训练」一个神经网络实际上意味着使用训练图像和标签来调整权重和偏置，以便最小化交叉熵损失函数。它是这样工作的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;交叉熵是一个关于权重、偏置、训练图像的像素和其已知标签的函数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果我们相对于所有的权重和所有的偏置计算交叉熵的偏导数，我们就得到一个对于给定图像、标签和当前权重和偏置的「梯度」。请记住，我们有 7850 个权重和偏置，所以计算梯度需要大量的工作。幸运的是，TensorFlow 可以来帮我们做这项工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;梯度的数学意义在于它指向「上（up）」。因为我们想要到达一个交叉熵低的地方，那么我们就去向相反的方向。我们用一小部分的梯度更新权重和偏置并且使用下一批训练图像再次做同样的事情。我们希望的是，这可以使我们到达交叉熵最小的凹点的低部。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOPic4LeNISGUVD9NSvUNbsAIEWt0hkJSic3b9RLZmh0Idv5kxsk1MYLbQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这副图片当中，交叉熵被表示为一个具有两个权重的函数。事实上，还有更多。梯度下降算法遵循着一个最陡的坡度下降到局部最小值的路径。训练图像在每一次迭代中同样会被改变，这使得我们向着一个适用于所有图像的局部最小值收敛。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「学习率（learning rate）」： 在整个梯度的长度上，你不能在每一次迭代的时候都对权重和偏置进行更新。这就会像是你穿着七里靴却试图到达一个山谷的底部。你会直接从山谷的一边到达另一边。为了到达底部，你需要一些更小的步伐，即只使用梯度的一部分，通常在 1/1000 区域中。我们称这个部分为「学习率（Learning rate）」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;总结一下，以下是训练过程的步骤：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Training digits and labels =&amp;gt; loss function =&amp;gt; gradient (partial derivatives) =&amp;gt; steepest descent =&amp;gt; update weights and biases =&amp;gt; repeat with next mini-batch of training images and labels&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;训练数字和标签 =&amp;gt; 损失函数 =&amp;gt; 梯度（部分偏导数）=&amp;gt; 最陡的梯度 =&amp;gt; 更新权重和偏置 =&amp;gt; 使用下一个 mini-batch 的图像和标签重复这一过程&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为什么使用 100 个图像和标签的 mini-batch？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你当然也可以只在一个示例图像中计算你的梯度并且立即更新权重和偏置（这在科学文献中被称为「随机梯度下降（stochastic gradient descent）」）。在 100 个样本上都这样做可以得到一个更好地表示由不同样本图像施加约束的梯度并且可能更快地朝着解决方案收敛。mini-batch 的大小是可调整的参数。还有一个更加技术化的原因：使用批处理也意味着使用较大的矩阵，而这些通常更容易在 GPU 上优化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;常见问题&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为什么交叉熵是在分类问题中合适的定义距离？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;解答链接：https://jamesmccaffrey.wordpress.com/2013/11/05/why-you-should-use-cross-entropy-error-instead-of-classification-error-or-mean-squared-error-for-neural-network-classifier-training/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;6、实验：让我们来看看代码&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;单层神经网络的代码已经写好了。请打开 mnist_1.0_softmax.py 文件并按说明进行操作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你在本节的任务是理解开始代码，以便稍后对其改进。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你应该看到，在文档中的说明和启动代码只有微小的差别。它们对应于可视化的函数，并且在注释中被标记。此处可忽略。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;mnist_1.0_softmax.py：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://github.com/martin-gorner/tensorflow-mnist-tutorial/blob/master/mnist_1.0_softmax.py&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOtia4weAo34TUtWxxY9wEopFEAPobvdKO4LTCnvdYfyjZFBSOzXF8zVw/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们首先定义 TensorFlow 的变量和占位符。变量是你希望训练算法为你确定的所有的参数。在我们的例子中参数是权重和偏差。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;占位符是在训练期间填充实际数据的参数，通常是训练图像。持有训练图像的张量的形式是 [None, 28, 28, 1]，其中的参数代表：&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;28, 28, 1: 图像是 28x28 每像素 x 1（灰度）。最后一个数字对于彩色图像是 3 但在这里并非是必须的。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;None: 这是代表图像在小批量（mini-batch）中的数量。在训练时可以得到。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;mnist_1.0_softmax.py：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://github.com/martin-gorner/tensorflow-mnist-tutorial/blob/master/mnist_1.0_softmax.py&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOfMVLI9BQdgEia1kjzmicN4CnmhDRphQkd6XNPiaNics2nKsic9Un0b3PmRw/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一行是我们单层神经网络的模型。公式是我们在前面的理论部分建立的。tf.reshape 命令将我们的 28×28 的图像转化成 784 个像素的单向量。在 reshape 中的「-1」意味着「计算机，计算出来，这只有一种可能」。在实际当中，这会是图像在小批次（mini-batch）中的数量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然后，我们需要一个额外的占位符用于训练标签，这些标签与训练图像一起被提供。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在我们有模型预测和正确的标签，所以我们计算交叉熵。tf.reduce_sum 是对向量的所有元素求和。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后两行计算了正确识别数字的百分比。这是留给读者的理解练习，使用 TensorFlow API 参考。你也可以跳过它们。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;mnist_1.0_softmax.py：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://github.com/martin-gorner/tensorflow-mnist-tutorial/blob/master/mnist_1.0_softmax.py)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;optimizer = tf.train.GradientDescentOptimizer(0.003)&lt;/p&gt;&lt;p&gt;train_step = optimizer.minimize(cross_entropy)&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;才是 TensorFlow 发挥它力量的地方。你选择一个适应器（optimiser，有许多可供选择）并且用它最小化交叉熵损失。在这一步中，TensorFlow 计算相对于所有权重和所有偏置（梯度）的损失函数的偏导数。这是一个形式衍生（ formal derivation），并非是一个耗时的数值型衍生。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;梯度然后被用来更新权重和偏置。学习率为 0.003。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，是时候来运行训练循环了。到目前为止，所有的 TensorFlow 指令都在内存中准备了一个计算图，但是还未进行计算。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;TensorFlow 的 “延迟执行（deferred execution）” 模型：TensorFlow 是为分布式计算构建的。它必须知道你要计算的是什么、你的执行图（execution graph），然后才开始发送计算任务到各种计算机。这就是为什么它有一个延迟执行模型，你首先使用 TensorFlow 函数在内存中创造一个计算图，然后启动一个执行 Session 并且使用 Session.run 执行实际计算任务。在此时，图形无法被更改。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由于这个模型，TensorFlow 接管了分布式运算的大量运筹。例如，假如你指示它在计算机 1 上运行计算的一部分 ，而在计算机 2 上运行另一部分，它可以自动进行必要的数据传输。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;计算需要将实际数据反馈进你在 TensorFlow 代码中定义的占位符。这是以 Python 的 dictionary 的形式给出的，其中的键是占位符的名称。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;mnist_1.0_softmax.py：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://github.com/martin-gorner/tensorflow-mnist-tutorial/blob/master/mnist_1.0_softmax.py&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOD46e8viatjtbtvYPibFy9aVC11EDpIjib3qia7D2up4RrMDdwDrwzP7Ofw/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这里执行的 train_step 是当我们要求 TensorFlow 最小化交叉熵时获得的。这是计算梯度和更新权重和偏置的步骤。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最终，我们还需要一些值来显示，以便我们可以追踪我们模型的性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在训练回路中使用该代码来计算准确度和交叉熵（例如每 10 次迭代）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;p&gt;# success ?&lt;br/&gt;a,c = sess.run([accuracy, cross_entropy], feed_dict=train_data)&lt;/p&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过在馈送 dictionary 中提供测试而不是训练数据，可以对测试数据进行同样的计算（例如每 100 次迭代计算一次。有 10,000 个测试数字，所以会耗费 CPU 一些时间）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;p&gt;# success on test data ?&lt;br/&gt;test_data={X: mnist.test.images, Y_: mnist.test.labels}&lt;br/&gt;a,c = sess.run([accuracy, cross_entropy], feed=test_data)&lt;/p&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;TensorFlow 和 Numpy 是朋友：在准备计算图时，你只需要操纵 TensorFlow 张量和命令，比如 tf.matmul, tf.reshape 等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而，只要执行 Session.run 命令，它的返回值就是 Numpy 张量，即 Numpy 可以使用的 numpy.ndarray 对象以及基于它的所有科学计算库。这就是使用 matplotlib（基于 Numpy 的标准 Python 绘图库）为本实验构建实时可视化的方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个简单的模型已经能识别 92% 的数字了。这不错，但是你现在要显著地改善它。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOibE6mhmHev14JgswcB4wMnd5qXxqlfRjgicUYwluOFG7tGoUglMrLqQw/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;7、实验:增加层&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOCqnO54VTEZxPX6IzSXuiciaiaCWZib92gyUic9UmETCiblUt10bncHT8NpuA/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了提高识别的准确度，我们将为神经网络增加更多的层。第二层神经元将计算前一层神经元输出的加权和，而非计算像素的加权和。这里有一个 5 层全相连的神经网络的例子：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOuGfYSFT74kbFNvs4eWZMt9DL8hrzoH5MrDfELW5sFWusmLbC6bCMibQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们继续用 softmax 来作为最后一层的激活函数，这也是为什么在分类这个问题上它性能优异的原因。但在中间层，我们要使用最经典的激活函数：sigmoid：在这一节中你的任务是为你的模型增加一到两个中间层以提高它的性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOB4k0BWGoiaW2UF4dic0QsNpH0Rgap3ed508yIQthD8t9juRwOVqXI0uA/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;答案可以在 mnist_2.0_five_layers_sigmoid.py 中找到。只有当你实在想不出来的时候再使用它！为了增加一个层，你需要为中间层增加一个额外的权重矩阵和一个额外的偏置向量：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;p&gt;W1 = tf.Variable(tf.truncated_normal([28*28, 200] ,stddev=0.1))&lt;br/&gt;B1 = tf.Variable(tf.zeros([200]))&lt;br/&gt;&lt;br/&gt;W2 = tf.Variable(tf.truncated_normal([200, 10], stddev=0.1))&lt;br/&gt;B2 = tf.Variable(tf.zeros([10]))&lt;/p&gt;&lt;/pre&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对，就这么做。通过 2 个中间层以及例子中 200 个和 100 个神经元，你现在应该能够把你的神经网络的准确度推高到 97% 了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOBQPDQRdByiaeZjCeBJvnPgT7uamialK5OQ3w3nccMwMKuXuF6J4ocfCg/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;8、实验：深度网络需要特别注意的地方&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOAz0DeOvpRIo3FmjXthdgCkx0zcQ0zp6r1cdKThYBILcsNA9eWTFjIw/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随着层数的增加，神经网络越来越难以收敛。但现在我们知道如何控制它们的行为了。这里是一些只用 1 行就可以实现的改进，当你看到准确度曲线出现如下情况的时候，这些小技巧会帮到你：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdO0ibWQnsgUnI8KAHfqOshQE1dLV1XVnIfUmhStP5nwtft6yv3bjtkAtQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;修正线性单元（ReLU）激活函数&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在深度网络里，sigmoid 激活函数确实能带来很多问题。它把所有的值都挤到了 0 到 1 之间，而且当你重复做的时候，神经元的输出和它们的梯度都归零了。值得一提的是，出于历史原因，一些现代神经网络使用了 ReLU（修正线性单元），它大致是如下这个样子：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOdvfO7WTTNy8iaqgJuWTQAbE2FAFVXoYxOGcEWvnb3Xvvib2X36xAzicpw/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;升级 1/4：用 RELU 替换你所有的 sigmoid，然后你会得到一个更快的初始收敛并且当我们继续增加层的时候也避免了一些后续问题的产生。仅仅在代码中简单地用 tf.nn.relu 来替换 tf.nn.sigmoid 就可以了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个更好的优化器&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在一个特别多维的空间里，就像当前这个情况——我们有 10K 量级的权值和偏置值——「鞍点 (saddle points）」会频繁出现。这些点不是局部最小值点，但它的梯度却是零，那么梯度降的优化会卡在这里。TensorFlow 有一系列可以用的优化器，包括一些带有一定的惯性，能够安全越过鞍点的优化器。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;升级 2/4：现在将你的 tf.train.GradientDescentOptimiser 替换为 tf.train.AdamOptimizer。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随机初始化&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;准确性一直卡在 0.1？你把你的权值初始化成随机值了没？对于偏置值，如果用 ReLU 的话，最好的办法就是把它们都初始化成小的正值，这样神经元一开始就会工作在 ReLU 的非零区域内。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;p&gt;W = tf.Variable(tf.truncated_normal([K, L] ,stddev=0.1))&lt;br/&gt;B = tf.Variable(tf.ones([L])/10)&lt;/p&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;升级 3/4：现在检查是否你所有的权值和偏置值都被初始化好了。上图所示的 0.1 会作为偏置值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不定值（NaN）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOOnxOofUfcz3ephxl0UhxeqOB6s1OapSoZrlNUHRzTIu9c359vyqotA/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你看到你的精确曲线陡然下滑并且调试口输出的交叉熵是 NaN，不用感到头疼，你其实是正在尝试计算 log(0)，而这肯定是个不定值（NaN）。还记得吗，交叉熵的计算涉及到对 softmax 层的输出取对数。鉴于 softmax 基本上是一个指数，它肯定不是 0，我们如果用 32 位精度的浮点运算就还好，exp(-100) 基本上可以算作是 0 了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;很幸运，TensorFlow 有一个非常方便的函数可以在单步内计算 softmax 和交叉熵，它是以一种数值上较为稳定的方式实现的。如果要使用它，你需要在应用 softmax 之前将原始的权重和加上你最后一层的偏置隔离开来（在神经网络的术语里叫「logits」）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你模型的最后一行是这样的：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;p&gt;Y = tf.nn.softmax(tf.matmul(Y4, W5) + B5)&lt;/p&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你需要把它替换成：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;p&gt;Ylogits = tf.matmul(Y4, W5) + B5
Y = tf.nn.softmax(Ylogits)&lt;/p&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;并且你现在能以一种安全的方式计算交叉熵了：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;p&gt;cross_entropy = tf.nn.softmax_cross_entropy_with_logits(Ylogits, Y_)&lt;/p&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;同样加上下面这行代码使得测试和训练的交叉熵能够同框显示：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;p&gt;cross_entropy = tf.reduce_mean(cross_entropy)*100&lt;/p&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;升级 4/4：请把 tf.nn.softmax_cross_entropy_with_logits 加到你的代码里。你也可以跳过这一步，等你真在你的输出里看到 NaN 以后再来做这步。现在，你已经准备好实现「深度」了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;9、实验：学习速率衰退&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOBXiae4PSfty9lGiahnT8icSXVLZqCzulJicVNX2DAfuDqicwmp27o6LUicrA/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过两个、三个或者四个中间层，你现在可以将准确度提升至接近 98%，当然，你的迭代次数要达到 5000 次以上。不过你会发现你并不总是会得到这样的结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOfz5Jt3iaGqYJ1MUS2IFg9JfKJBYiaTZv8HBwcj6xE2Dsbzh4zpjo14Og/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些曲线很嘈杂，看看测试精确度吧：它在全百分比范围内跳上跳下。这意味着即使 0.003 的学习率我们还是太快了。但我们不能仅仅将学习率除以十或者永远不停地做训练。一个好的解决方案是开始很快随后将学习速率指数级衰减至比如说 0.0001。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个小改变的影响是惊人的。你会看到大部分的噪声消失了并且测试精确度持续稳定在 98% 以上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOibZOXe6pMQUaoxekhItByZ6XpxLgOdkzD3vBic8MT3bHqdFn6nqo0tjw/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;再看看训练精确度曲线。在好多个 epoch 里都达到了 100%（一个 epoch=500 次迭代=全部训练图片训练一次）。第一次我们能很好地识别训练图片了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;请把学习率衰退加到你的代码里。为了把一个不同的学习率在每次迭代时传给 AdamOptimizer，你需要定义一个新的占位符（placeholder）并在每次迭代时通过 feed_dict 赋给它一个新的参数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里是一个指数级衰减的方程：lr = lrmin+(lrmax-lrmin)*exp(-i/2000) 答案可以在这个文件里找到：mnist_2.1_five_layers_relu_lrdecay.py。如果你被卡住了可以用它。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdO6ibEW0PFjTz2o5vAKGS182t8KX4pYydL5CiaA89MQmG8R7gdtEWNkPvw/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;10、实验：dropout、过拟合&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOW3aDx7CC1MavglFrxicfoY8IKibMRlwoEqVJxicu1qcdw0KgOkXrwRUibQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你可能已经注意到在数千次迭代之后，测试和训练数据的交叉熵曲线开始不相连。学习算法只是在训练数据上做工作并相应地优化训练的交叉熵。它再也看不到测试数据了，所以这一点也不奇怪：过了一会儿它的工作不再对测试交叉熵产生任何影响，交叉熵停止了下降，有时甚至反弹回来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOFK4z7czD5rGCWNufmbCAiap36XmnMNWFpcIKT7dzPgYaX160DdJVI3Q/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;它不会立刻影响你模型对于真实世界的识别能力，但是它会使你运行的众多迭代毫无用处，而且这基本上是一个信号——告诉我们训练已经不能再为模型提供进一步改进了。这种无法连接通常会被标明「过拟合（overfitting）」，而且当你看到这个的时候，你可以尝试采用一种规范化（regularization）技术，称之为「dropout」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOgqW2ZHGOGEvhibC0bPuGx4LksibJwGQdJuzrdm4RRLeTLrGXdlvrDY8Q/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 dropout 里，在每一次训练迭代的时候，你可以从网络中随机地放弃一些神经元。你可以选择一个使神经元继续保留的概率 pkeep，通常是 50% 到 75% 之间，然后在每一次训练的迭代时，随机地把一些神经元连同它们的权重和偏置一起去掉。在一次迭代里，不同的神经元可以被一起去掉（而且你也同样需要等比例地促进剩余神经元的输出，以确保下一层的激活不会移动）。当测试你神经网络性能的时候，你再把所有的神经元都装回来 (pkeep=1)。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;TensorFlow 提供一个 dropout 函数可以用在一层神经网络的输出上。它随机地清零一些输出并且把剩下的提升 1/pkeep。这里是如何把它用在一个两层神经网络上的例子。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;p&gt;# feed in 1 when testing, 0.75 when training&lt;br/&gt;pkeep = tf.placeholder(tf.float32)&lt;br/&gt;&lt;br/&gt;Y1 = tf.nn.relu(tf.matmul(X, W1) + B1)&lt;br/&gt;Y1d = tf.nn.dropout(Y1, pkeep)&lt;br/&gt;&lt;br/&gt;Y = tf.nn.softmax(tf.matmul(Y1d, W2) + B2)&lt;/p&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你现在可以在网络中每个中间层以后插入 dropout。如果你没时间深入阅读的话，这是本项目里的可选步骤。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该解决方案可以在 mnist_2.2_five_layers_relu_lrdecay_dropout.py：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;(https://github.com/martin-gorner/tensorflow-mnist-tutorial/blob/master/mnist_2.2_five_layers_relu_lrdecay_dropout.py)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;里找到。如果你被难住了，可以用它。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOyxN9yZ3yrdbVytBxsXycQhPfIz42BFIIqBInJ76J7aEGQKiav7U76Fw/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你会看到测试损失已经被搞回来了，已经在可控范围内了，不过至少在这个例子中噪声重新出现了（如果你知道 dropout 的工作原理的话，这一点也不奇怪）。测试的准确度依然没变，这倒是有点小失望。这个「过拟合」一定还有其它原因。在我们继续进行下一步之前，我们先扼要重述一下我们到目前为止用过的所有工具：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdO2QJiaBHKYTv46tchksDiauciarcnNmDWVZKfL6NvoByQicemibQwGAiaPRrw/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;无论我们做什么，我们看上去都不可能很显著地解决 98% 的障碍，而且我们的损失曲线依然显示「过拟合」无法连接。什么是真正的「过拟合」？过拟合发生在该神经网络学得「不好」的时候，在这种情况下该神经网络对于训练样本做得很好，对真实场景却并不是很好。有一些像 dropout 一样的规范化技术能够迫使它学习得更好，不过过拟合还有更深层的原因。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOPDUSb8c5dUQGsCo7mPsibNibfNCia51RDvd5LZ0rnUZmcpWIORcUEtZgw/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;基本的过拟合发生在一个神经网络针对手头的问题有太多的自由度的时候。想象一下我们有如此多的神经元以至于所组成的网络可以存储我们所有的训练图像并依靠特征匹配来识别它们。它会在真实世界的数据里迷失。一个神经网络必须有某种程度上的约束以使它能够归纳推理它在学习中所学到的东西。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你只有很少的训练数据，甚至一个很小的网络都能够用心学习它。一般来说，你总是需要很多数据来训练神经网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，如果你已经做完了所有的步骤，包括实验了不同大小的网络以确保它的自由度已经约束好了、采用了 dropout、并且训练了大量的数据，你可能会发现你还是被卡在了当前的性能层次上再也上不去了。这说明你的神经网络在它当前的形态下已经无法从你提供的数据中抽取到更多的信息了，就像我们这个例子这样。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;还记得我们如何使用我们的图像吗？是所有的像素都展平到一个向量里么？这是一个很糟糕的想法。手写的数字是由一个个形状组成的，当我们把像素展平后我们会丢掉这些形状信息。不过，有一种神经网络可以利用这些形状信息：卷积网络（convolutional network）。让我们来试试。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;11、理论：卷积网络&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOsics1Sdpp40BwcnX6wuY2SEfSQjEy51ib7a3HVyytJ7qH3OyZ9AUjVDA/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在卷积网络层中，一个「神经元」仅对该图像上的一个小部分的像素求加权和。然后，它通常会添加一个偏置单元，并且将得到的加权和传递给激活函数。与全连接网络相比，其最大的区别在于卷积网络的每个神经元重复使用相同的权重，而不是每个神经元都有自己的权重。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在上面的动画中，你可以看到通过连续修改图片上两个方向的权重（卷积），能够获得与图片上的像素点数量相同的输出值（尽管在边缘处需要填充（padding））。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;要产生一个输出值平面，我们使用了一张 4x4 大小的彩色图片作为出输入。在这个动画当中，我们需要 4x4x3=48 个权重，这还不够，为了增加更多自由度，我们还需要选取不同组的权重值重复实验。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdODjLZnxbJw0tUXQ8L0PuemMOpibdnDSRqAhgq3bvqrU8WnqxyCib4wYrg/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过向权重张量添加一个维度，能够将两组或更多组的权重重写为一组权重，这样就给出了一个卷积层的权重张量的通用实现。由于输入、输出通道的数量都是参数，我们可以开始堆叠式（stacking）和链式（chaining）的卷积层。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOPULsoCEKvD5glEjlx6nfrNnO0zicyeXKHiaFNS22jOboB4nE5EJgJnjA/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，我们需要提取信息。在最后一层中，我们仅仅想使用 10 个神经元来分类 0-9 十个不同的数字。传统上，这是通过「最大池化（max-pooling）」层来完成的。即使今天有许多更简单的方法能够实现这分类任务，但是，「最大池化」能够帮助我们直觉地理解卷积神经网络是怎么工作的。如果你认为在训练的过程中，我们的小块权重会发展成能够过滤基本形状（水平线、垂直线或曲线等）的过滤器（filter），那么，提取有用信息的方式就是识别输出层中哪种形状具有最大的强度。实际上，在最大池化层中，神经元的输出是在 2x2 的分组中被处理，最后仅仅保留输出最大强度的神经元。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里有一种更简单的方法：如果你是以一步两个像素移动图片上的滑块而不是以每步一个像素地移动图片上的滑块。这种方法就是有效的，今天的卷积网络仅仅使用了卷积层。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOGkibWblVcuxBusHNJicMS0YfjUB9W0WictqKoTnQ2B8FhQwmIqsszzW5g/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;让我们建立一个用于手写数字识别的卷积网络。在顶部，我们将使用 3 个卷积层；在底部，我们使用传统的 softmax 读出层，并将它们用完全连接层连接。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOw2YCBMDXTOmZVAa6xqVNTKibeYFEqUrCANiaWRhByCgsrw8fC4Uv9SdA/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;注意，第二与第三卷积层神经元数量以 2x2 为倍数减少，这就解释了为什么它们的输出值从 28x28 减少为 14x14，然后再到 7x7。卷积层的大小变化使神经元的数量在每层下降约为：28x28x14≈3000-&amp;gt;14x14x8≈1500 → 7x7x12≈500 → 200。下一节中，我们将给出该网络的具体实现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;12、实现：一个卷积网络&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOw2YCBMDXTOmZVAa6xqVNTKibeYFEqUrCANiaWRhByCgsrw8fC4Uv9SdA/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了将我们的代码转化为卷积模型，我们需要为卷积层定义适当的权重张量，然后将该卷积层添加到模型中。我们已经理解到卷积层需要以下形式的权重张量。下面代码是用 TensorFlow 语法来对其初始化：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOf8ytOJXpaOxhDdKvJCOYCdNYZN9UAuoCNwlicDvghIs8Tr6V3IuSVyg/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;p&gt;W = tf.Variable(tf.truncated_normal([4, 4, 3, 2], stddev=0.1))&lt;br/&gt;B = tf.Variable(tf.ones([2])/10) # 2 is the number of output channels&lt;/p&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 TensorFlow 中，使用 tf.nn.conv2d 函数实现卷积层，该函数使用提供的权重在两个方向上扫描输入图片。这仅仅是神经元的加权和部分，你需要添加偏置单元并将加权和提供给激活函数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;p&gt;stride = 1 &amp;nbsp;# output is still 28x28&lt;br/&gt;Ycnv = tf.nn.conv2d(X, W, strides=[1, stride, stride, 1], padding='SAME')&lt;br/&gt;Y = tf.nn.relu(Ycnv + B)&lt;/p&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不要过分在意 stride 的复杂语法，查阅文档就能获取完整的详细信息。这里的填充（padding）策略是为了复制图片的边缘的像素。所有的数字都在一个统一的背景下，所以这仅仅是扩展了背景，并且不应该添加不需要的任何样式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在该你了。修改你的模型并将其转化为卷积模型。你可以使用上图中的值来修改它，你可以减小你的学习速率但是务必先移除 dropout。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你的模型的准确率应该会超过 98%，并且最终达到约 99%。眼看目标就要实现，我们不能停止！看看测试的交叉熵曲线。在你的头脑中，此时，是否解决方案正在形成？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOMbUHpFafiarW1jfE9cyjSBSZw9nWic0FGRicKzrRQhTVZtAYjSM2qRbYg/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;13、99% 准确率的挑战&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;调整你的神经网络的一个好方法：先去实现一个限制较多的神经网络，然后给它更多的自由度并且增加 dropout，使神经网络避免过拟合。最终你将得到一个相当不错的神经网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;例如，我们在第一层卷积层中仅仅使用了 4 个 patch，如果这些权重的 patch 在训练的过程中发展成不同的识别器，你可以直观地看到这对于解决我们的问题是不够的。手写数字模式远多于 4 种基本样式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此，让我们稍微增加 patch 的数量，将我们卷积层中 patch 的数量从 4，8，12 增加到 6，12，24，并且在全连接层上添加 dropout。它们的神经元重复使用相同的权重，在一次训练迭代中，通过冻结（限制）一些不会对它们起作用的权重，dropout 能够有效地工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOSUDKaRejmOTlOBxOofAHtEXQ1RNQMv08iaX43293TuLQicQXu8a902uA/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;加油吧，去打破 99％的限制。增加 patch 数量和通道的数量，如上图所示，在卷积层中添加 dropout。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdO5gK1hCdfdOlmhc1Jwet6DQsecEYoaGeoicgABFJOk8MEXGia58LBRulQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;解决方案可以在文件 mnist_3.1_convolutional_bigger_dropout.py 中找到。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使用上图所示的模型，在 10000 个测试的数字中，结果仅仅错误了 72 个。你可以在 MNIST 网站上发现，数字识别准确率的世界纪录大约为 99.7%，这仅比我们用 100 行 Python/TensorFlow 代码构建的模型的准确率高 0.4%。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，不同的 dropout 使我们能够训练更大的卷积网络。增加神经网络的额外自由度，使模型的最终准确率从 98.9% 达到 99.1%。向卷积层中增加 dropout 不仅减少了测试误差，而且使我们模型的准确率突破 99%，甚至达到了 99.3%。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOFJnyJdibkIkWrnFic0OqfB7miab9ADhErO6feoRHvqVrafwibc7MNFQslQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;14、恭喜！&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你已经建立了你的第一个神经网络，并且训练精度达到了 99%。在这个学习过程中，你所学到的技术，并不局限于 MNIST 数据集。实际上，这些技术在训练神经网络的过程中被广泛使用。作为礼物，下面提供的内容可以用来帮助你回忆已经所学的内容。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOWGSBND1vSh4DaMfFJQwQiazcapvHmbKAA2BMgo3kQHoOoueZoDkbcBg/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在完成了完全神经网络和卷积网络后，你应该学习循环神经网络：https://www.tensorflow.org/tutorials/recurrent/。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在本教程中，你已经学习了如何在矩阵层次构建 TensorFlow 模型。Tensorflow 还有更高级的 API，称为 tf.learn：https://www.tensorflow.org/tutorials/tflearn/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;要在云上的分布式框架上训练，我们提供 Cloud ML 服务：https://cloud.google.com/ml&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;最后，我们希望收到你的反馈。如果你在发现了本实验中的些许错误，或者你认为有什么需要改进的地方，请告诉我们。我们通过 GitHub 处理反馈。反馈链接：https://github.com/googlecodelabs/feedback/issues/new?title=[cloud-tensorflow-mnist]:&amp;amp;labels[]=content-platform&amp;amp;labels[]=cloud&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 24 Jan 2017 12:32:21 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 蚂蚁金服与UC Berkeley RISE实验室启动合作，加速数据人才培养</title>
      <link>http://www.iwgc.cn/link/4468819</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心报道&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：老红&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;近日，蚂蚁金服与美国加州伯克利大学近期新成立的 RISE 实验室达成合作意向。据悉，本次蚂蚁金服和 RISE 实验室的合作，是对海内外数据技术人才引进的布局。蚂蚁金服董事长彭蕾曾在内部讲话中表明蚂蚁金服对大数据技术的人才引进将&lt;span&gt;「&lt;/span&gt;不拘一格，不遗余力&lt;span&gt;」&lt;/span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;RISE 实验室的前身是著名伯克利 AMP 实验室，主导研发了当今大数据计算领域最前沿的开源系统：Apache Spark 和 Apache Mesos。以 Apache Spark 为例，作为大数据分析处理的计算引擎，它具备 DAG 执行引擎以及基于内存的多轮迭代计算等优势，使得其在数据分析等工作负载上表现优秀，成为大数据领域最活跃的开源项目之一。从 AMP 实验室在大数据领域取得成果可以看到，其升级版 RISE 实验室在大数据方面的技术基础以及人才培养与储备都是领域内领先的。此次蚂蚁金服和 RISE 实验室合作，除了对基础技术深度研究之外，更是对人才长期的持续投资。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdO5aWNPsPia4o3ncJ0SOIhbBZMCJzX8UziaGwNr7EoFl1BgOAkxmFkj9XQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此前，蚂蚁金服和清华大学、同济大学等高校就基础科研进行了合作。本次和 UC Berkeley 的合作向国际高校基础科研合作迈出了第一步，旨在结合双方资源优势，进一步拓展与升级合作的领域及范围，深化高科技人才的培养与合作交流，共同探索数据技术人才培养的新模式与新机制。该项合作的背后是对高科技人才尤其数据技术人才的极度渴望。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;RISE 实验室的成立，标志着世界顶级计算机科学系在大数据计算领域种下一个五年重大研究计划。这个新实验室专注于下一代大数据计算系统「Real-Time Intelligence &amp;nbsp;with Secure &amp;nbsp;Execution &amp;nbsp;(RISE)&lt;span&gt;」&lt;/span&gt;的研发，世界十一家顶级科技公司成为该实验室的创始成员：蚂蚁金服、谷歌、微软、亚马逊、CAPITAL ONE、英特尔、华为、爱立信、 IBM、VMWare 和通用电气。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;RISE 实验室主任 Ion Stoica 教授描绘了实验室的使命愿景：解决大规模数据计算中长期未能很好解决的世界难题，机器如何在实时数据环境中快速地做出智能决策。这项技术适用于许多未来场景，从地震监控，无人车／无人机指挥与导航、到网络安全等等，需要在复杂环境交互中做出实时计算决策。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Ion Stoica 教授评价本次与蚂蚁金服的合作：「基于最新的强安全数据的智能决策技术将开启一个与数十亿用户息息相关的新应用时代，提高用户的隐私性的同时提供更精准实时的建议。我们非常高兴能与蚂蚁金服合作开发新系统和算法来赋能更多应用和服务，这将从根本上改变人们消费行为并从一系列持续变化的金融、健康、消费、娱乐等数据流中获得价值。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;蚂蚁金服首席技术架构师胡喜说：「蚂蚁金服的核心愿景让全球数十亿普通人享受普惠而便利的金融服务。低成本的实时安全智能决策能力对我们提升客户体验和业务效率都具有极大的价值。我们将与 RISE 实验室合作共同应对某些基础研究的挑战，提供更创新和智能的金融服务。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;ISE 实验室的主要教授包括 Ion Stoica , Michael Jordan 等在内的涵盖了大数据系统及人工智能等领域的世界顶级专家。本次合作中实验室的初创成员都是各领域极具代表性的领先企业，RISE 实验室五年计划的启动将是来自世界各地代表不同产业的人才精英汇聚在一起共同合作创新的尝试。与蚂蚁金服的合作，建立在双方共同的使命和远景基础上，致力于用科技给人们带来智能、安全、低成本的数字普惠金融服务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心报道，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 24 Jan 2017 12:32:21 +0800</pubDate>
    </item>
    <item>
      <title>学界 | DeepMind牵手UCL启动机器学习顶级培训计划</title>
      <link>http://www.iwgc.cn/link/4468820</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;作者Demis Hassabis&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李泽南&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;作为谷歌旗下的人工智能公司，DeepMind 一直以学术性氛围著称，从不断发表论文，参加所有大型学术会议，到开源技术平台，这家公司的所有动作都着眼于长远利益。昨天，该公司创始人 Demis Hassabis 撰文宣布，DeepMind 又启动了与伦敦大学学院（UCL）合作的一项顶级培训计划，致力于培养机器学习领域的顶尖人才，让我们看看他是怎么说的。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 90 年代中期，当我还是一名大学生的时候，很少会有人会去推动学界与业界公司的互动——而后者是几乎所有大学生毕业后的去向。这对于学生而言也许意味着失去机会。同时，虽然私人机构时常受益于大学的研究成果，但这些技术突破带来的好处却很少被两者共享。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相比之下，DeepMind 的研究环境是一种介于学界与业界的混合体，我们在进行计划时会以学术的思维进行长远考虑，同时像最好的初创公司那样，保持专注与速度。学术背景对于我们所有人而言非常重要，机器学习领域的所有突破性理念都是由学术先驱开创的，包括 Geoff Hinton，包括 Rich Sutton。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这就是为什么我们总是公开自己的研究成果，包括超过一百篇同行评议论文，以及总是出现在大型会议（如 NIPS）上的原因。在上个月巴塞罗那举行的 NIPS2016 上，DeepMind 提交了 20 篇论文，参加了 42 次海报论文讨论，21 次研讨会，随后开源了我们的旗舰研究平台：DeepMind Lab，我们所做的还不止于此。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在，我们希望为学术界做出更多的贡献，为教育训练下一代机器学习人才提供自己的帮助。所以从本月开始，我们将和伦敦大学学院（UCL）计算机系一道启动顶级培训计划「Advanced Topics in Machine Learning」。这项计划由 DeepMind 的 Thore Graepel 牵头，其他应邀参与授课的学者包括机器学习领域各方向的领先人物，涵盖深度学习、强化学习、自然语言识别等方面。他们包括 Hado van Hasselt、Joseph Modayil、Koray Kavukcuoglu、Raia Hadsell、James Martens、Oriol Vinyals、Simon Osindero、Ed Grefenstette、Karen Simonyan、Volodymyr Mnih、David Silver 和 Alex Graves。他们中的一些人曾是 DeepMind 在 Nature 上发表的三篇论文的主要作者。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdO7ZHEpp06fPJUFQPmtnVNG5hV9LpictKKoCe7HpOTvfQ21TpS7bvbBDQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;DeepMind 研究科学家 Hado van Hasselt 在 UCL 上的授课，在 Advanced Topics in Machine Learning 训练营上&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今年一月，牛津大学计算机系也开展了自然语言处理中的先进深度学习课程。这项应用课程重点介绍使用循环神经网络分析和生成语音及文本方向上的最新进展，它由 Phil Blunsom 主讲，DeepMind 语言研究小组协助，向大四、研究生和博一学生开放。除此以外，我们还开办了暑期国际训练营，其中 DeepMind 成员会轮流授课，这样的活动已在德国、中国、南非和其他地区举行过。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们一直确保来到 DeepMind 的研究者不会失去他/她在学术上的影响力。我们的很多成员目前同时隶属于各家大学，包括 UCL、牛津、剑桥、MIT 和弗莱堡大学、里尔大学等等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们认为更多的独立学术机构对于人工智能领域的发展大有益处。因此，我们向众多实验室和其中的博士学生提供资助，帮助他们开展自己的研究。我们资助的大学包括阿尔伯塔大学、蒙特利尔大学、阿姆斯特丹大学、UCL 的 Gatsby Unit、纽约大学、牛津大学等等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们认为公司研究部门和学界的紧密联系对于未来人工智能意义重大。通过分享各自拥有的天分、专业知识和研究突破——不仅仅是以技术为导向，而是把合作扩展到伦理、安全和社会影响这样的广泛话题上去，这样才能为人工智能和它的未来创造更好的条件，让新技术拥有正能量，造福整个社会。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 24 Jan 2017 12:32:21 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 扎克伯格夫妇基金会收购Meta：将免费开放人工智能论文搜索引擎</title>
      <link>http://www.iwgc.cn/link/4468821</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心报道&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：蒋思源、朱思颖、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Mark Zuckerberg 和 Priscilla Chan 的 450 亿美元慈善机构正在进行第一笔收购，这笔收购的目的是为了让科学家们更容易实现对 2600 多万科研论文的搜索、阅读和文章之间联系的构建。他们的慈善机构（Chan Zuckerberg Initiative/CZI）正在收购 Meta——一家人工智能驱动的研究搜索引擎初创公司。在完成现有产品的优化之后，Meta 将会在近几个月免费开放自己的工具给所有人。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOoemW02JAF3ORDttfprjq5rJyXSlfqrg5EDrNeAIuooWzNq05bqLjag/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Meta 可以帮助科学家找到与自己项目相关的最新论文，另一方面也能协助投资机构与研究员之间的合作并且确立值得投资和作用的高潜力方向。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Meta 的特别之处在于通过人工智能识别不同论文的作者和引用，从而挖掘出最重要的研究而不只是找到有最佳 SEO 的论文。此外，还免费提供对 1 万 8 千个期刊和文献资料的全文入口。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Meta 的联合创始人、CEO Sam Molyneux 写道：「向前发展，我们的目的不是从 Meta 的数据和数据体量中获利；而是确保把这些资源能跨越不同的地区以最快的速度提供给最需要的人，从而让全世界获益。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对收购的这家多伦多的初创公司的技术和团队，CZI 还没有透露任何风声。Meta 于 2010 年创立，包括 Rho Canada Ventures 和 HIGHLINEvc 在内等投资机构对其注入 750 万美金。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这家初创公司之前对提供订阅服务或个性化解决方案的用户收费，但是现在 Meta 的所有产品将会免费给所有人。但是这次收购还需要一定的时间才能完成。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Cori Bargmann，Science 和 Brain Pinkerton 的董事长，CZI 的技术主管，介绍 Meta 将如何被使用时写道：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这类平台的潜力几乎是无限制的：一个研究员可以用 Meta 来发现可以用来理解冠心病的新兴技术；一个研究生可以看到两种不同的疾病激活相同的免疫防御途径的资料；临床医生能够更快找到研究最有前景的 Zika 诊治方案的科学家。从长远来看，Meta 还可以扩展到其他知识领域：例如，可以帮助教育者时刻关注人类学的研究进展，从而更好的理解小孩子是如何学习的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这一个收购案例中，因为 Meta 已经将自己打造成聚合研究（aggregation of research）的领导者，那么收购这家公司并将它的工具公开而不是建立一些新的就很有意义了。Zuckerberg 和他夫人的组织机构已经投资了一个初创作为 CZI 的教育提升，其包括了 Andela（非洲科技工作工程师预备学习）和 Byju（印度的视频学习平台）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过将 Meta 从商业领域转出来而聚焦并最大化其价值，CZI 能在更大范围社区内解决科研最大的障碍，也就是任何科学家或者是研究团队都无法查看极其巨量的研究论文这一问题。单单在生物制药上，每天就有 2 千到 4 千的新论文发表出来，因此研究人员很难从如此多的论文中找出哪些是最好的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Meta 原来称之为 Sciencescape，是通过文献检索系统（PubMed）和网页爬取建立整个论文库的索引，并且在作者分析引用了谁或链接了什么的时候进行识别并建立配置文件。这有效地将 Google PageRank 用于科学，从而很容易挖掘相关论文并对查看论文的优先度进行排序。它甚至能从以前的搜索中提供其新发表论文的一个更新反馈。下面是它如何在不同地方帮助研究界：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;科学家可以找到他们研究领域的最新数据和分析，确定已经完成的实验从而他们不需要再重复进行，他们还可以寻求调查研究的新机遇。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如同大学或基金会那样的资助机构可以与作者联系以支持他们未来的研究，也可以通过它发现科技突破点，从而确保他们的投资是正确的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;学生可以根据精确的词语匹配和搜索引擎优化（SEO）来排序结果，而不是寻找与他们研究最相关的论文或仅仅只是通过已有引用来查论文。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;学校可以确保他们的课程是最新的，并以最具潜力的方式训练学生在科学领域的进步。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这起收购之前，机器之心曾向 Meta 公司的 CSO Ofer Shai 了解过该公司的目标和状况，Shai 说：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;我们仍然在继续提升我们的算法和扩展我们的内容源，目前我们关注的重点是生物医学，但我们也正在从专利开始延伸到计算机科学、物理、化学等领域；所以我们关注的重点还是很多的。另一件激动人心的事情是我们启动了一个新项目来帮助发现和提取概念（concept）之间的『深度语义连接（deep semantic connections）』，这能帮助我们更好地理解科学。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;要指出一篇论文是关于神经网络的很简单，但要总结这篇论文并且给出总结的方式则会困难得多——而这正是我们正在解决的问题。所以我们目前正在大幅地采纳人工智能策略，并且也有而且还在聘请专业的资源来帮助我们变革。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当 CZI 刚宣布建立时，其灵活的 LLC 状态受到了人们的批评，因为这与慈善机构传统的结构不同。但是，能够收购 Meta 这样的营利性公司使其重复使用其获取的利润，这也正是 Zuckerburg 选择这种形式的原因。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「帮助科学家将能带来良性的循环，因为他们又能为更快的进展开发出新的工具，」Molyneux 写道，「Chan Zuckerberg Initiative 对这种『超（meta）』效应的认识是 Meta 成为了其中的关键环节的原因。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Chan Zuckerberg Initiative 知道即使有这个家庭有如此巨大的财富，他们也无法为科学的每个领域都提供赞助。但如果他们可以为每一位科学家提供可扩展的工具，从而让这些科学家不用再自己费心追求利益而实现更高的效率，那么 CZI 就能成为为人类服务的慈善。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心报道，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 24 Jan 2017 12:32:21 +0800</pubDate>
    </item>
    <item>
      <title>前沿 | 李飞飞团队新论文：通过迭代式信息传递的场景图生成</title>
      <link>http://www.iwgc.cn/link/4468822</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自arXiv&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicKlJibSVAicqxlFTC2znL3MfJWzJGay6vmrp2icxicBia2vLxyfdVEiav0C2nYhmle6LC2lOXc8wczdWrA/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;理解一个视觉场景（visual scene）不只是要理解单独的一个个物体。物体之间的关系也能提供丰富的有关这个场景的语义信息（semantic information）。在我们这项工作中，我们使用场景图（scene graphs）明确地对物体及其关系进行了建模。我们提出了一种全新的端到端模型，其可以从输入图像中生成这种结构化的场景表征（scene representation）。该模型可以使用标准 RNN 解决场景图推理问题（scene graph inference problem）以及通过消息传递（message passing）学习迭代式地提升其预测能力。我们的联合推理模型可以利用语境线索（contextual cues）来更好地预测物体及其关系。我们的实验表明我们的模型在使用 Visual Genome 数据集生成场景图和使用 NYU Depth v2 数据集推理支持关系（support relations）上的表现显著超越了之前的方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicKlJibSVAicqxlFTC2znL3MfQcIMp0fOMCIiaibibkKt7zloOjuibTP9NseS7VHd8IiaBFlHMY3SoMVhG0Q/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;图 1：目标检测器通过关注单个的物体来感知一个场景。这使得即使是一个完美的检测器也会在两个语义上有明显区别的图像上得到相似的输出（第一行）。我们提出了一种场景图生成模型，其以图像作为输入，然后可以生成基于视觉的（visually-grounded）场景图（第二行右图），该场景图捕获到了图像中的物体（蓝色节点）以及它们之间配对的关系（红色节点）。&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicKlJibSVAicqxlFTC2znL3Mf5uNnK7xKICG7tTiaSYXvpicGbo3LXbK5QGPX2xHPV5bpUH840B0z9Ukg/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 2：我们的模型的架构概览。给定一张图像作为输入，该模型首先使用一个 Region Proposal Network (RPN) [32] 产出一个目标提议（object proposals）集合，然后将从目标区域提取出来的特征传递给我们全新的图推理模块（graph inference module）。该模型的输出是一个场景图 [18]，其包含一个本地化的目标集合、每个目标的类别以及每个目标对之间的关系类型。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicKlJibSVAicqxlFTC2znL3MfDd9ypOwHXbzqmronrSgib4QloRTfib0upibI7OnoTgBNV7tD3tG7GeWJw/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 3：我们模型的架构图示。该模型首先会从目标提议集合中提取出节点和边（edge）的视觉特征，然后边 GRU 和节点 GRU 将这些视觉特征作为初始输入并得出一个隐藏状态的集合 (a)。然后一个节点消息池化函数（node message pooling function）在下一次迭代中计算从隐藏状态传递到节点 GRU 的消息。类似地，一个边消息池化函数（edge message pooling function）也会计算传递到边 GRU 的消息和推送 (b)。⊕ 符号表示学习到的加权和。该模型可以迭代式地更新 GRU 的隐藏状态 (c)。在最后一个迭代步骤，该 GRU 的隐藏状态可以被用于预测目标类别、bounding box offsets 和关系类别 (d)。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicKlJibSVAicqxlFTC2znL3Mf1dFjvAP9zr2z0RRemZnx1p8gJfF5KOPHdCcgBVBvQXWRXwJTTsWywg/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 6：我们的模型在 NYU Depth v2 数据集 [28] 上的支撑关系预测（support relation predictions）样本。尖头箭头表示从下面支撑，圆头箭头表示从旁边支撑。红色的箭头表示不正确的预测。我们还给不同的代码结构类涂上了不同的颜色：地面是蓝色的、结构是绿色的、家具是黄色的、工具是红色。紫色表示缺失的结构类别。注意分割掩码（segmentation masks）在这里仅用作可视化的目的。我们的模型使用了目标边界框作为输入，而不是这些掩码。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 24 Jan 2017 12:32:21 +0800</pubDate>
    </item>
    <item>
      <title>2016中国人工智能大事件：从百度深度学习平台到中国脑计划</title>
      <link>http://www.iwgc.cn/link/4456043</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：李亚洲、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote style="color: rgb(62, 62, 62); font-size: 16px; white-space: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;2017 年元旦，机器之心以 3 分钟视频的方式回顾了全球人工智能在过去一年中取得的发展。开源、无人驾驶、创业、深度学习等词汇似乎成为了人工智能领域的表征，一次又一次的拨动我们的神经。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721913&amp;amp;idx=1&amp;amp;sn=61fa411795fac54aacfa771959f0cba5&amp;amp;chksm=871b0a07b06c83118bf01830b545b89571d1550efab887e4369eef22ce5893fc0d9da3197df2&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721913&amp;amp;idx=1&amp;amp;sn=61fa411795fac54aacfa771959f0cba5&amp;amp;chksm=871b0a07b06c83118bf01830b545b89571d1550efab887e4369eef22ce5893fc0d9da3197df2&amp;amp;scene=21#wechat_redirect"&gt;元旦的视频总结&lt;/a&gt;中，我们能够明显的看到中国在整个人工智能领域的参与度。MXNet、百度无人车、科大讯飞都让我们看到了中国对人工智能发展的推动。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在为春发蓄势的年末，机器之心回顾了国内在 2016 年发生的人工智能大事件。百度无人车体验、开源深度学习平台 PaddlePaddle，多种算法、应用竞赛的举办，商汤、旷视、图普等创业公司新一轮融资的成功，这些种种让我们相信中国会成为人工智能的前沿阵地，如同高盛报告中提到的「人工智能前沿的重要参与者可能会继续来自美国和中国」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;百度开源深度学习平台 PaddlePaddle&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 2016 年 9 月 1 日百度世界大会上，百度首席科学家 Andrew Ng（吴恩达）宣布正式对外开放百度内部 3 年内不断丰富、优化的深度学习平台 Paddle，并更名为 PaddlePaddle：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9iaSgfTFRChrskKuUMbnjjpYicPfqxFR5BWtJichEEsuzCRaGTnzam4qPmZ9olBa9CNXFRrK9micibTUQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;深度模型：广泛支持各种深度学习模型，包括 DNN，CNN，RNN，复杂记忆（Memory）模型，NTM 等，支持多种优化算法&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;模型训练：支持多机多显卡训练，充分利用机器性能，支持稀疏更新&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;模型预测和评估：支持线下多语言（Python/C++）预测接口&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;据介绍，PaddlePaddle 有着极大的易用性、灵活性、高效性与扩展性。随着亚马逊年底宣布使用 MXNet，深度学习框架之间的竞争是愈演愈烈。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;第三届世界互联网大会，百度无人车体验&lt;/span&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;iframe class="video_iframe" data-vidtype="1" allowfullscreen="" frameborder="0" height="417" width="556" data-src="https://v.qq.com/iframe/preview.html?vid=h0346g9f437&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0"&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2015 年底，百度宣布正式成立自动驾驶事业部，且表示「计划三年实现自动驾驶汽车的商用化，五年实现量产。」一年将近，在第三届世界互联网大会在乌镇召开之际，百度无人车邀请了多位嘉宾切身体验百度已经从「测试」走向「试乘」的无人车。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这成为百度继 2013 年启动无人车项目、2015 年底完成多种路段测试、今年 9 月和 10 月分别获得美国加州自动驾驶汽车道路测试许可证和完成加州首次公共道路测试，无人车项目的有一个重大进展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这也是国内首次第四级别的自动驾驶汽车全程无干预的在全开放城市道路上行驶，投入乌镇运营无人车 15 辆，3 天内超过 200 位乘客规模化试乘，应付了多时段的复杂气象条件。更加重要的是，这是支持 5 款车型的跨平台无人驾驶技术。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;参考文章：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720582&amp;amp;idx=3&amp;amp;sn=998e786926ccae181bd2cfb915a6fa69&amp;amp;chksm=871b0d38b06c842eab4405aa07ade9ea08dbfd0de6a2a8eea2b60ea5f1d93428d6c8614d83d2&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720582&amp;amp;idx=3&amp;amp;sn=998e786926ccae181bd2cfb915a6fa69&amp;amp;chksm=871b0d38b06c842eab4405aa07ade9ea08dbfd0de6a2a8eea2b60ea5f1d93428d6c8614d83d2&amp;amp;scene=21#wechat_redirect"&gt;业界 | 体验百度无人车，系统性人工智能技术让自动驾驶越来越近&amp;nbsp;&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;腾讯 AI Lab 研究院成立&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今年，腾讯成立了人工智能研究院腾讯 AI Lab，专注机器学习、计算机视觉、语音识别、自然语言处理等人工智能领域的研究。但腾讯一直没有对外做过多宣传，机器之心是报道腾讯 AI Lab 研究的第一家媒体。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;后来，腾讯副总裁、AI Lab 院长姚星在 2016 年腾讯研究院年会上正式向外公布了腾讯 AI Lab 所关注 AI 四个基础研究领域和 4 个专属研究方向，并且强调说，「AI 对腾讯来说是非常重要的，对整个中国互联网都很重要。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;参考文章：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722553&amp;amp;idx=3&amp;amp;sn=5a9b6e4dfe30957744b9331c65dbfdca&amp;amp;chksm=871b1487b06c9d91e37b9cc02f910ac7460a23fa9dc4cd5929835b497b811128f87ee9083e20&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722553&amp;amp;idx=3&amp;amp;sn=5a9b6e4dfe30957744b9331c65dbfdca&amp;amp;chksm=871b1487b06c9d91e37b9cc02f910ac7460a23fa9dc4cd5929835b497b811128f87ee9083e20&amp;amp;scene=21#wechat_redirect"&gt;演讲 | 腾讯副总裁姚星：人工智能真实的希望与喧哗的隐忧&lt;/a&gt;；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720536&amp;amp;idx=1&amp;amp;sn=76e38d366841b567d38c4334df175eeb&amp;amp;chksm=871b0d66b06c8470d96d6faf9c636e0e0eed6d0e89e74abd3ecfe52c68f384a906c95efd1329&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720536&amp;amp;idx=1&amp;amp;sn=76e38d366841b567d38c4334df175eeb&amp;amp;chksm=871b0d66b06c8470d96d6faf9c636e0e0eed6d0e89e74abd3ecfe52c68f384a906c95efd1329&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;独家专访 | 腾讯 AI Lab 公布首项研究：提出独特神经网络实现实时视频风格变换&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;腾讯大数据开源高性能计算平台 Angel&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 12 月 18 日于深圳举办的腾讯大数据技术峰会暨 KDD China 技术峰会上，腾讯大数据宣布推出了面向机器学习的「第三代高性能计算平台」——Angel，并表示将于 2017 年一季度开放其源代码。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;据腾讯数据平台部总经理、首席数据专家蒋杰介绍，Angel 是腾讯大数据部门发布的第三代计算平台，使用 Java 和 Scala 语言开发的面向机器学习的高性能分布式计算框架，由腾讯大数据与香港科技大学、北京大学联合研发。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9iaSgfTFRChrskKuUMbnjjpNQwV6YI4AibLP62GprMXOiaW86w1MB3WhfZibyWC5oq1z2ic1fjPHrdzKw/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;采用参数服务器架构，解决了上一代框架的扩展性问题，支持数据并行及模型并行的计算模式，能支持十亿级别维度的模型训练。不仅如此，Angel 还采用了多种业界最新技术和腾讯自主研发技术，性能更高、系统更具易用性。自今年年初在腾讯内部上线以来，Angel 已应用于腾讯视频、腾讯社交广告及用户画像挖掘等精准推荐业务。Angel 更是腾讯大数据下一代的核心计算平台。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;参考文章：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721559&amp;amp;idx=1&amp;amp;sn=0ca5ad4d7ce70c260cb596c8eae76d97&amp;amp;chksm=871b0969b06c807feba50561c516c9987e0a0b354f0ab554d14de2b8e7035134f879f1419b77&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721559&amp;amp;idx=1&amp;amp;sn=0ca5ad4d7ce70c260cb596c8eae76d97&amp;amp;chksm=871b0969b06c807feba50561c516c9987e0a0b354f0ab554d14de2b8e7035134f879f1419b77&amp;amp;scene=21#wechat_redirect"&gt;腾讯大数据将开源高性能计算平台 Angel，机器之心专访开发团队&amp;nbsp;&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;人工智能华人力量&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;就像前面所说的「人工智能前沿的重要参与者可能会继续来自美国和中国」，2016 年，我们看到了华人对人工智能发展所做出的贡献，华人力量也逐渐被国际所认可。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;华人力量的彰显可从两个维度得见：1. 中国力量在国际学术组织和会议上的存在感和影响力愈发强大，可以看成是中国人工智能快速发展的一个标志；2. 一批优秀的华人学者为产业界所看重，其中最具代表性的美籍华人李飞飞。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 百度副总裁王海峰当选 ACL 会士&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;11 月 28 日晚，国际计算语言学会（The Association for Computational Linguistics：ACL）公布了 2016 年 ACL 会士名单。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;截至目前，ACL 历史上在全球范围内累计评出过 40 位会士。而王海峰则成为了首位获此荣誉的中国大陆科学家，同时也是 ACL 目前最年轻的会士。ACL 会士评选委员会在对王海峰的评语中写道：王海峰在机器翻译、自然语言处理和搜索引擎技术领域，在学术界和工业界都取得了杰出成就，对于 ACL 在亚洲的发展也做出了卓越贡献。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;参考文章：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720823&amp;amp;idx=3&amp;amp;sn=e0670a173ef0af638625f4eda6a78355&amp;amp;chksm=871b0e49b06c875f13241f75027892adc1b7e01daf521d7dcc26e04d681c08041b13709ab979&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720823&amp;amp;idx=3&amp;amp;sn=e0670a173ef0af638625f4eda6a78355&amp;amp;chksm=871b0e49b06c875f13241f75027892adc1b7e01daf521d7dcc26e04d681c08041b13709ab979&amp;amp;scene=21#wechat_redirect"&gt;资讯 | 百度副总裁王海峰当选 ACL 会士，成为中国大陆首位获此殊荣的科学家&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 黄学东、周志华当选 2016ACM Fellow&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2016 年 12 月 8 日，世界领先的计算机学会、全球最大的计算机领域专业性学术组织 Association for Computing Machinery（ACM）正式公布了 2016 年当选的 ACM Fellow 名单。今年共有 53 名成员入选。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;新当选的 ACM Fellow 中，仅有两位华人：一位是美国微软首席语音科学家黄学东博士，贡献是「对口语语言的处理」；另一位是中国大陆学者、南京大学的周志华教授，当选理由是「对机器学习和数据挖掘的贡献」（for contributions to machine learning and datamining）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 李飞飞加入谷歌&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2016 年 11 月 16 日，谷歌宣布其雇佣了两位人工智能领域的顶级研究者：斯坦福大学人工智能实验室主任李飞飞、前 Snapchat 研究主管李佳，这两位华裔女科学家都是计算机视觉行业的专家。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在人工智能风起的今天，科技巨头从学术界拉拢人才已经成为了一种常态，而李飞飞加入谷歌的消息无疑也掀起了轩然大波。从另一个角度来讲，李飞飞作为第一代中国移民，最后成为谷歌人工智能团队新任领导者，也让我们看到了华人力量的崛起。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;参考文章：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720553&amp;amp;idx=1&amp;amp;sn=c88e48aab2d789d744ac1629ffec9a8a&amp;amp;chksm=871b0d57b06c844121d6fdf6fda546996e87c1cc395bef55fde20cb910b2fe1bbcdf8d1ce6c9&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720553&amp;amp;idx=1&amp;amp;sn=c88e48aab2d789d744ac1629ffec9a8a&amp;amp;chksm=871b0d57b06c844121d6fdf6fda546996e87c1cc395bef55fde20cb910b2fe1bbcdf8d1ce6c9&amp;amp;scene=21#wechat_redirect"&gt;深度 | 谷歌新人李飞飞：击碎玻璃天花板的华裔女科学家&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;中国脑计划一体两翼战略，推动人工智能发展&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2016 年 11 月份时，中国科学院神经科学研究所、中国科学院脑科学与智能技术卓越创新中心、香港科技大学生命科学部和分子神经科学国家重点实验室、中国科学院自动化研究所在《Neuron》上联合发表了一篇概述论文《China Brain Project: Basic Neuroscience, Brain Diseases, and Brain-Inspired Computing》，介绍了「中国脑计划」在基础神经科学、脑疾病和脑启发计算上的研究进展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在论文中，作者们写到，「神经科学的一个普遍目标——理解人类认知的神经基础——应该成为「中国脑计划（China Brain Project）」的核心。此外，中国也应该投入资源和研究能力，以满足迫切的社会需求。由主要脑疾病造成的社会压力逐渐上升，所以现在迫切需要一种预防、诊断和治疗脑疾病的新方法。在大数据的新时代，受大脑启发而得的计算方法和系统对于实现更强的人工智能和更好地利用越来越多的信息至关重要。正是由于对这些问题的考虑，中国脑计划项目提出了「一体两翼」战略（图 1）。其中对基本神经回路机制的认知的基础研究提供了输入并且接受来自脑疾病的诊断/干预和脑启发智能技术（两翼）的反馈。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9iaSgfTFRChrskKuUMbnjjpicvEXkvvHm2CdoibU9I9do7dWUhPCgG1jdzGZysGfo6fRB2OS0HdRBXw/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此篇论文的作者包括：蒲慕明（Mu-ming Poo）、杜久林（Jiu-lin Du）、熊志奇（Zhi-Qi Xiong）、叶玉如（Nancy Y. Ip）、徐波（Bo Xu）、谭铁牛（Tieniu Tan）。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;参考文章：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720765&amp;amp;idx=1&amp;amp;sn=d023cbc68ce9cec7e00ebc44d940a7d9&amp;amp;chksm=871b0d83b06c84952a94754e60f22126dd64a9c198deaeccc7ae3c6dc04eb0f190c9877de4f3&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720765&amp;amp;idx=1&amp;amp;sn=d023cbc68ce9cec7e00ebc44d940a7d9&amp;amp;chksm=871b0d83b06c84952a94754e60f22126dd64a9c198deaeccc7ae3c6dc04eb0f190c9877de4f3&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-align: justify;"&gt;深度 | 全面解读中国脑计划：从基础神经科学到脑启发计算&lt;/a&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;神经机器翻译，不止谷歌一家&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2016 年 9 月底，谷歌宣布将其神经机器翻译技术（GNMT）整合到了其谷歌翻译应用中，引起了很大关注。但实际上，利用人工智能做机器翻译的企业并不只有谷歌一家，中国的百度、讯飞、搜狗等公司都在 2016 年拿出了一些值得关注的机器翻译上的新应用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在机器之心 2016 年对百度 NLP 团队和百度首席科学家吴恩达的采访中，他们就曾谈到百度其实也非常早的就进入到了神经网络机器翻译领域。已当选 ACL Fellow 的百度副总裁王海峰博士就曾告诉机器之心：「我们从 2014 年开始便尝试做基于神经网络的翻译系统，2015 年发布在线翻译系统的时，BLEU（Bilingual Evaluation Understudy）指标已经比传统的 SMT（统计机器翻译）系统高六、七个点。我们同时还开发了离线版本，可以在手机上使用，当时学术界对于深度学习的翻译方法到底是否实用还有一番争论，我们很早就发现基于 Attention 机制的 Seq2Seq 深度学习模型是有用的，经过多次实验验证，在很多集合上超过了传统方法。同时，针对 NMT 本身存在的一些问题，进行了技术攻关，短短 3 个月的时间便完成了开发和上线。当大家还在讨论 Attention 机制时，我们已经结合了原有的统计方法上线。可以说，百度翻译是全球首个互联网神经网络翻译系统。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除了百度外，讯飞和搜狗也在持续投入机器翻译技术。2015 年，科大讯飞曾在美国国家标准技术研究院（NIST）组织的机器翻译大赛（Open Machine Translation Evaluation，NIST 2015）中取得了全球第一的好成绩。而在 2016 科大讯飞年度发布会上，该公司正式发布了「晓译翻译机」。据介绍：这款机器基于科大讯飞机器翻译的国际领先技术，达到了英语大学六级的水平，能够实现语音输入后中英、汉维的实时翻译，具有易用性、稳定性、安全性等特点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;搜狗也在 2016 年 5 月份上线了英文搜索（后在 12 月份升级为搜狗海外搜索频道并新增了搜狗翻译频道）。搜狗英文搜索可提供跨语言检索功能，可自动将中文翻译成英文进行查询，再生成英文查询结果。在 11 月的乌镇世界互联网大会上，搜狗展示了机器同传技术，可将演讲者的中文同步翻译成英文并实时上屏。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;参考文章：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719470&amp;amp;idx=1&amp;amp;sn=3368dea980517ea7d7942967da2740dc&amp;amp;chksm=871b0090b06c89863620be4e75c757940d03d8a43cd3c1d9a8309b6594c1bccd769cab193177&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719470&amp;amp;idx=1&amp;amp;sn=3368dea980517ea7d7942967da2740dc&amp;amp;chksm=871b0090b06c89863620be4e75c757940d03d8a43cd3c1d9a8309b6594c1bccd769cab193177&amp;amp;scene=21#wechat_redirect"&gt;重磅 | 谷歌翻译整合神经网络：机器翻译实现颠覆性突破&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721480&amp;amp;idx=1&amp;amp;sn=191cb46a8ebbb71519d5d668705aa81b&amp;amp;chksm=871b08b6b06c81a0265fc5de459f78cd5e1e887f3569f57a2e7ccb4ff7835d73c66699cc483a&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721480&amp;amp;idx=1&amp;amp;sn=191cb46a8ebbb71519d5d668705aa81b&amp;amp;chksm=871b08b6b06c81a0265fc5de459f78cd5e1e887f3569f57a2e7ccb4ff7835d73c66699cc483a&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;机器之心独家对话吴恩达：很多技术其实是中国最先开始应用的&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717168&amp;amp;idx=2&amp;amp;sn=462ac989178d34f15ab56947416b8b5f&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717168&amp;amp;idx=2&amp;amp;sn=462ac989178d34f15ab56947416b8b5f&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;机器之心专访 | 讯飞研究院王士进：如何让机器拥有阅读推理能力？&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716160&amp;amp;idx=1&amp;amp;sn=871d9d398de5cf665265e5eeab3dc040&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716160&amp;amp;idx=1&amp;amp;sn=871d9d398de5cf665265e5eeab3dc040&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;专访 | 搜狗的人工智能研发与应用：让技术在产品中创造更多用户价值&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722227&amp;amp;idx=2&amp;amp;sn=4dd4514c3e957422697a8854a2dae8d6&amp;amp;chksm=871b0bcdb06c82dbf69d2f2157b287318471692720449c5f12001188b26830f7fcf0e4d9ce17&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722227&amp;amp;idx=2&amp;amp;sn=4dd4514c3e957422697a8854a2dae8d6&amp;amp;chksm=871b0bcdb06c82dbf69d2f2157b287318471692720449c5f12001188b26830f7fcf0e4d9ce17&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;业界 | 搜狗知音引擎再进一步，实现语音实时翻译&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;算法与应用大赛&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据竞赛是今年中国人工智能领域的又一亮点，学术界、产业界纷纷举办数据竞赛来争取人才，挖掘新技术的产业应用。当然，以下三场竞赛并不代表 2016 年内举办过的全部竞赛，但管中窥豹，希望大家能从中洞见数据竞赛在人工智能发展中带来的益处。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今日头条 2016 Byte Cup 世界机器学习比赛：2016 年，中国人工智能学会主办，今日头条、电气电子工程师学会（IEEE）中国代表处协办了 2016ByteCup 国际机器学习竞赛。这场数据分析竞赛的主题是：如何在社交问答系统中精准地匹配专家和问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;据了解，此次数据竞赛共有 1000 多支队伍参赛，冠亚季军队伍分别是 brickmover、天穹战队和西电战队。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;参考文章：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721644&amp;amp;idx=2&amp;amp;sn=f2145ab0797a722b6887cc8a9ebb219d&amp;amp;chksm=871b0912b06c8004ffb4338f6c790c7b9b50f69b6bf638414ec9e28fab1c5ec5beddbd139ab9&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721644&amp;amp;idx=2&amp;amp;sn=f2145ab0797a722b6887cc8a9ebb219d&amp;amp;chksm=871b0912b06c8004ffb4338f6c790c7b9b50f69b6bf638414ec9e28fab1c5ec5beddbd139ab9&amp;amp;scene=21#wechat_redirect"&gt;专访 | 今日头条 2016 Byte Cup 大赛实战经验分享：要充分挖掘模型本身的信息&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;上海 BOT 大数据应用大赛：今年上海大数据产业基地（市北高新）、上海大数据联盟、英特尔（中国）有限公司和华院数据技术（上海）有限公司联合主办，机器之心协办了国内首个专业化人工智能大赛「2016 上海 BOT 大数据应用大赛」。在计算机视觉与人工智能聊天机器人商业应用这两大热门赛题上，全球近 400 支专业团队进行了角逐。本次大赛从 2016 年 9 月 1 日初赛开始到 11 月 11 日总决赛结束，经历了三个多月。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;参考文章：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720516&amp;amp;idx=3&amp;amp;sn=80ed2bde64e872e29dbeb2bab36e8c0b&amp;amp;chksm=871b0d7ab06c846c28886012b6c117597f5ee3b8617b0095253139a1170aef63f91d09022098&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720516&amp;amp;idx=3&amp;amp;sn=80ed2bde64e872e29dbeb2bab36e8c0b&amp;amp;chksm=871b0d7ab06c846c28886012b6c117597f5ee3b8617b0095253139a1170aef63f91d09022098&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;业界 | 2016 上海 BOT 大数据应用大赛闭幕：决赛 11 个聊天机器人项目盘点&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;滴滴 Di-Tech 算法大赛：今年上半年，滴滴研究院举办首届 Di-Tech 算法大赛，这是一场面向全球大数据人才的算法竞赛。滴滴通过开放国内真实的出行数据，用最炙手可热的研究课题征集更聪明的解决方案。而且此次比赛中获得的解决方案有机会直接应用于「滴滴出行」产品端。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;参考文章：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717305&amp;amp;idx=3&amp;amp;sn=abc06a528c76ed2cb2c16c1991508e07&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717305&amp;amp;idx=3&amp;amp;sn=abc06a528c76ed2cb2c16c1991508e07&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;业界 | 滴滴算法大赛背后，是对人工智能人才与技术的呼唤&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;融资：图像识别公司屡获巨额融资&lt;/span&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;创业、融资是体现人工智能热度的另一个维度。2016 年，我们看到人工智能成为了最受资本市场追捧的领域之一，机器之心很早就关注的一批创业公司接连获得高额融资。下面这三家融资的成功引起了业内极大的关注。当然，这并非完全性统计。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 旷视科技：旷视科技（Face++）是一家专注于机器视觉和人工智能的技术公司，是国内人脸识别领域知名的创业公司。据机器之心获得的消息称，旷视科技获 2000 万美元新一轮融资。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9iaSgfTFRChrskKuUMbnjjpaaXibhfkFkk6z9l8mvoOUQ6jkIduoShibS8EEfJRfpFKiaqouEPWMLvicQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;旷视科技成立于 2011 年，创业之初获得了联想之星的一笔天使融资；2013 年获得创新工场百万美元 A 轮投资。2014 年 11 月，获得 2200 万美元 B 轮融资，2015 年完成 B 轮 4700 万美元融资。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;延展文章：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722208&amp;amp;idx=3&amp;amp;sn=a1f217aa810783e9dfb137072f11d969&amp;amp;chksm=871b0bdeb06c82c853d4d6d4177523e33cd35d10e3c59f6f98b2e1924381cffbc06ace4520b3&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722208&amp;amp;idx=3&amp;amp;sn=a1f217aa810783e9dfb137072f11d969&amp;amp;chksm=871b0bdeb06c82c853d4d6d4177523e33cd35d10e3c59f6f98b2e1924381cffbc06ace4520b3&amp;amp;scene=21#wechat_redirect"&gt;专栏 | 旷视 (Face++) 孙剑：创业公司里的研究之美&amp;nbsp;&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 图普科技：据机器之心一手消息称，图普科技已经于今年 9 月完成了新一轮融资，金额为千万美元，由晨兴资本领投，北极光创投跟投。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图普科技由微信创始团队成员之一的李明强创办，主要做基于图像识别技术的第三方内容审核服务，在识别色情、暴恐、时政敏感信息、小广告等违规图片和视频方面市场占有率领先。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;延展文章：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717202&amp;amp;idx=2&amp;amp;sn=31b6924db5eb4500fa4a57d9669878fc&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717202&amp;amp;idx=2&amp;amp;sn=31b6924db5eb4500fa4a57d9669878fc&amp;amp;scene=21#wechat_redirect"&gt;专访 | 图普科技李明强：用产品思维打造图像识别的场景化应用&amp;nbsp;&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 商汤科技：2016 年 12 月 14 日，商汤科技宣布完成 1.2 亿美元新一轮融资，本轮由鼎晖投资，万达集团、IDG 资本、StarVC 等投资方共同参与。此前商汤科技，曾于 2014 年 11 月获得 IDG 资本的千万美元投资；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;商汤集团是一家科技创新公司，致力于引领人工智能核心「深度学习」技术突破，构建人工智能、大数据分析行业解决方案。目前，商汤汇聚了一支庞大的深度学习算法研究团队，拥有上百名深度学习研究人员。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;延展文章：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716578&amp;amp;idx=2&amp;amp;sn=471e5e957b51feedc88062532a5a041c&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716578&amp;amp;idx=2&amp;amp;sn=471e5e957b51feedc88062532a5a041c&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;CVPR2016 | 商汤科技论文解析：服饰识别搜索技术&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716578&amp;amp;idx=2&amp;amp;sn=471e5e957b51feedc88062532a5a041c&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716578&amp;amp;idx=2&amp;amp;sn=471e5e957b51feedc88062532a5a041c&amp;amp;scene=21#wechat_redirect"&gt;CVPR 2016｜商汤科技论文解析：人脸检测中级联卷积神经网络的联合训练&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716180&amp;amp;idx=2&amp;amp;sn=e217c6b32ee5ef5eb8a6a7470c872e8a&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716180&amp;amp;idx=2&amp;amp;sn=e217c6b32ee5ef5eb8a6a7470c872e8a&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;CVPR 2016｜商汤科技论文解析：行为识别与定位&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716355&amp;amp;idx=2&amp;amp;sn=da3bae2c4352773db3660ca113977245&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716355&amp;amp;idx=2&amp;amp;sn=da3bae2c4352773db3660ca113977245&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;CVPR 2016 | 商汤科技论文解析：物体分割&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 23 Jan 2017 12:33:02 +0800</pubDate>
    </item>
    <item>
      <title>专访 | 搜狗+NMT+团队：神经机器翻译将消除跨语言沟通障碍</title>
      <link>http://www.iwgc.cn/link/4456044</link>
      <description>&lt;p&gt;&lt;span&gt;2016 年 5 月 19 日，搜狗正式上线英文搜索。搜狗英文搜索可提供跨语言检索功能，可自动将中文翻译成英文进行查询，再生成英文查询结果。对于不擅长英文的用户，可以节省很多「先翻后搜」的搜索时间；在 11 月的乌镇世界互联网大会上，搜狗展示了机器同传技术，可将演讲者的中文同步翻译成英文并实时上屏；12 月 21 日，搜狗英文搜索正式升级为搜狗海外搜索频道（overseas.sogou.com），并同步上线了搜狗翻译频道 (fanyi.sogou.com)。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9iaSgfTFRChrskKuUMbnjjpNEibSNticR6Vkhaeo4T0YsHibxsI7HlXCH4GUx0NsnJj2csfbJialvJGJg/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;近三年来，「神经网络机器翻译技术」成为人工智能翻译主流。该技术通过「端到端」的方法将翻译平行语料进行映射，以「编码器—注意力机制—解码器」的结构，解决翻译问题。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自 2016 年 8 月搜狗 NMT 团队成立至今，其自主研发的「机器翻译·一期系统」基本搭建完成。近日，人工智能媒体《机器之心》对搜狗 NMT 团队进行了专访。搜狗搜索技术负责人许静芳、搜狗搜索机器翻译负责人翟飞飞、清华计算机系副教授刘洋，就「搜狗神经机器翻译」的优势、团队组建和技术拓展等问题，展开了深度的分享。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;采访如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;搜狗翻译可生成更流畅的翻译结果&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：神经机器翻译（NMT）将整个输入句子视作翻译的基本单元，相比于之前的基于短语的翻译系统，除了所需的工程设计更少这个优点外，句子意思理解的精确度有哪些提升？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;刘 洋： &lt;/span&gt;&lt;/strong&gt;&lt;span&gt;NMT 有两个关键的技术很重要，一个是 gating，另外还有一个是 attention，这两个特别适合处理语言中长距离调序，比如中英文结构差异特别大，词语顺序存在全局变化，NMT 处理这种情况特别有优势，生成的译文要比传统的方式生成的译文流利很多，这是 NMT 很突出的特点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;翟飞飞：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;在统计机器翻译中，我们使用调序模型来处理不同语言之间词序不同的问题。但在处理长距离调序时，由于搜索空间太大，调序模型很难做到有效建模，导致许多统计机器翻译系统生成的译文存在较多词序错误，难以看懂。但 NMT 的模型架构对处理长距离调序问题特别有效，生成的译文更为流利。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;搜狗翻译有望实现「多场景即时对话翻译」&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心：在更高层次上自然语音处理上，实现两种语言的实时对话还需要多久？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9iaSgfTFRChrskKuUMbnjjp33XWRUozgicndicD4mckwkaicShp6icv2cp6u9OArC3jAiaGTSUFFepaVHQ/0?wx_fmt=jpeg"/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;搜狗搜索技术负责人许静芳&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;许静芳：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我觉得这个会很快，当然有一个前提，就是提出什么样的要求，如果要求特别流畅，包括上下文的理解，那不一定能做到。但由于语言的障碍，至少可以从以前的不能交流变成现在能够辅助理解和交流，这个会非常快。在某些场景口语交互或者日常的生活场景上，达到非常流利地交流，我觉得这也是在一两年的时间内可以做得非常好的一件事情。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然这里面也会涉及到更多的口语上的交互，又会和语音挂上钩，涉及到多种语音识别，包括和口音、设备关联在一起，会很复杂。但单纯在翻译这个层面，这个会非常快，现在已经做到有帮助。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9iaSgfTFRChrskKuUMbnjjpbUMVvicyX1wtNkKpkF9oISqtq6zwiaHFTJmqpKCUTTaiaEbZujJ0acDVw/0?wx_fmt=jpeg"/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em style="color: rgb(136, 136, 136);"&gt;&lt;span&gt;清华计算机系副教授刘洋&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em style="color: rgb(136, 136, 136);"&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;刘 洋：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我个人觉得在「多场景即时对话翻译」领域至少有两个挑战。从方法层来说，最难的就是语言歧义性问题，这是自然语言处理所最大的挑战。人类语言和机器语言不一样，机器语言要求精准、没有歧义，比如 C+，JAVA。但是自然语言的歧义性很高，比如英文词「bank」，既可能是指「银行」，也可能是指「堤岸」。口语交互过程中歧义现象很严重。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从数据层面来说，无论是语音识别、机器翻译还是语言合成，都是数据驱动的方法，系统性能严重依赖于标注数据的规模、质量和覆盖率。对于开放领域的即时对话翻译而言，目前还缺乏大规模、高质量、广覆盖的标注语料库。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;搜狗翻译水平已部分超越 Google 等巨头&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：通过深度学习来搭建的实时翻译技术与数据密不可分，搜狗的 NMT 在大型数据集上工作有哪些挑战？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;许静芳：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我想这个挑战应该是对所有机器翻译团队都类似的一个有趣的现象是业内翻译做得好的团队大多来自搜索公司。搜索和翻译本身是密不可分的，这个密不可分首先是数据层面，语料的挖掘，搜索本身天然有优势，在这里面，其实都涉及很多自然语言处理、数据挖掘的问题，搜索积累的经验可以很快地应用到翻译上来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：相较于谷歌和百度的神经机器翻译，搜狗这次发布的神经机器翻译有哪些差异性的特征？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;许静芳：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;首先，对翻译问题的理解、重视和投入问题，在不同的公司不同的阶段是有差异的。其次，聚焦在技术上面，NMT 从发展到应用在商业系统里也就这一、两年左右的事情，本身这个技术正处在非常快速的迭代的过程中。如果现在要去比较我们（搜狗）和百度、谷歌的差异，我们自己本身在翻译的模型，语料的挖掘，特别是深度学习模型很大，用的语料很多。在模型在分布式训练上，搜狗也有自己的创新。我们和谷歌最新的工作去对比，在某些方法上，可以看出我们比谷歌做得好，最终在中英两种语言互译的效果优于也验证了这个事情。搜狗比谷歌更有动力去做好翻译这件事情。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;搜狗翻译技术持续改进，未来可期&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：刚才谈到模型，现在 seq2seq+attention 的模型已经在 NMT 及其他众多 NLP 任务上取得了非常好的效果，我也注意到搜狗的神经网络做到了 5 层。之前有些论文提到了通过增加更多层的网络来取得更好的效果，您认为这个准确吗，通过不断增加网络层数来提升效果？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;许静芳：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我觉得这是方法之一，但不是唯一的方法，而且层数变深了以后，在数据和模型训练，包括网络的结构和优化方法上，都应该去适配这样的网络结构，所以我觉得适当加深层数是一种有效的方法，但不是唯一的途径。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;刘 洋：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;增加层数肯定有帮助，能够提高模型的表达能力，但是层数增加的越多，训练的难度也越大，需要更先进的技术。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：这种模型（seq2seq+attention）在效果方面是否已经达到了上限，从而需要新的模型解决？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;许静芳：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我觉得远远没有，从算法层面，这种网络的结构只是其中之一，包括损失函数的设置、先验知识连接、模型后处理等方面都有很多工作要做。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;刘 洋：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;肯定有提升空间。目前看来，有两个问题非常明显。第一个问题是漏词。很多用户反映神经机器翻译系统在生成译文时经常漏掉重要的词没有翻译，严重影响了译文的忠实度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一个问题是缺乏篇章一致性。目前的翻译都按照句子为基本单位进行翻译，没有考虑篇章层面的上下文信息，会导致翻译同一个篇章出现同一个词在不同句子中的译法不一样。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;搜狗独创的「深度学习」训练模型&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：除此之外，搜狗的 NMT 还有哪些正在应用的模型？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9iaSgfTFRChrskKuUMbnjjpzqR3TxWV0ljQibGR5FG7vo3ia6iarrexib9quvIKVV7QRvswshQw67LeIQ/0?wx_fmt=png"/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;搜狗搜索机器翻译负责人翟飞飞&lt;/span&gt;&lt;/em&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;翟飞飞：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;目前很多通用的 NMT 相关方法我们都在使用，同时依托天工研究院，我们和清华的机器翻译团队也合作进行了很多模型技术上的探索，取得了不错的成果，翻译性能稳步提升。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;刘 洋：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;清华的机器翻译团队由孙茂松教授领导，我是技术负责人。在这次与搜狗合作研发机器翻译系统的过程中，我们多年积累的技术和经验得到充分体现。另外，我们也受到最新的前沿技术的启发，如生成对抗网络和 zero-shot learning。相关的技术目前正在申请专利和撰写论文，预计不久会公开。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：不同语言的语料规模差别很大，英文中的语料非常多，但中文语料就显得非常少。请问，是否能将 NMT 的研究成果应用在不同语言语料构建上，从而提升其他语言 NLP 研究水平？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;翟飞飞：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我个人觉得是可以的，比如现在有各种各样的工作用来自动生成训练语料，但具体怎么操作，还要针对不同的任务，生成的数据能不能拿来使用，也需要经过评测之后，才能判定。。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：搜狗的 NMT 有应用在外部的对准模型吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;翟飞飞：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;外部对准模型是一个相对比较通用的技术，我们也在使用，同时也在探索其他的相关技术。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：在哪些具体场景，搜狗 NMT 的表现会比较好？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;许静芳：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt; 搜狗的机器翻译整体来说有非常好的调序能力，翻译译文流畅，利于理解。英文我们利用翻译的主场景是跨语言检索，所以书面语言的翻译效果比口语还要更好一些，英翻中比中翻英效果的领先优势更突出。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;四个月上线，搜狗翻译打通华语世界与英语世界&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：这次根据机器翻译推出了海外搜索，国内获取英文信息一直是非常困难的事情，川总在演讲中也提到过这个。用先进的机器翻译技术切入这个刚需变成产品，而这个产品又会因为用户频繁使用来产生更多数据并优化技术。这可能是我们目前所看到的机器翻译技术最恰当的产品形态。当初我们是怎么想到这种产品思路的？以及海外搜索和机器翻译的良好互动将实现什么样的一种目标？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;许静芳：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;海外搜索的前身叫英文搜索，是 2016 年 5 月份发的一款产品。有几个背景，首先全世界的信息 10% 是中文，90% 是英文。不管是国情还是文化，英文的质量在某些领域是明显高于中文的质量，并且平均水平还是高于中文的水平。其次国人随着各方面的进步，有非常迫切打开眼界与国际接轨的需求。世界是平的，有这样的需求存在。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;搜狗 5 月份发布英文搜索是让用户搜索更优质的英文内容。由于各种原因，国内并没有特别好用的英文搜索，搜狗英文搜索是将优质的英文信息引入，给大家提供这样的入口，才能接触到这样的信息。在 5 月份上线的时候就附带一个小的功能，举个例子，在爆发魏则西的事件的时候，大家要查滑膜肉瘤，查细胞免疫疗法，大家知道中文的概念，而且也明白，更权威性的信息与知识在国外。但是当用户在用搜索英文信息的时候，首先遇到的第一个门槛就是不知道如何用英文拼写出」滑膜肉瘤」，」细胞免疫疗法」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以搜狗英文搜索当时就有一个功能是允许用户用中文查询词，通过机器翻译自动翻译成英文查询词，再找到英文信息。当时面向的用户，是英文相对还可以，但在一些专业术语上需要补足的用户，尤其在不太熟悉的领域，构建英文表达很困难。但是如果返回英文结果，能读懂但比中文结果要困难。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个功能上线以后，在这个主打英文语言的搜索频道，中文的查询词占 20% 以上，而且随着时间的推移，还在逐步的提升。可以说这样的功能是很受用户欢迎，所以我们想把目标用户范围扩得更大一点，英文水平再差一点的同学，也能帮助他去阅读。进一步想法：把搜索结果能够翻译成中文，让不懂英文的用户在这里基本能看懂；懂英文的，借助机器翻译，也能更快到去找到他想要的信息。所以海外搜索的想法是在英文搜索发布不久，就已经萌生出来的，只不过翻译很难，搜索也很难，要把这两件事结合在一起，是难上加难。我们在英文搜索发布之后，大概花了四个月左右的时间，在建立团队的基础上，首先构建自己自主的机器翻译的能力，而且机器翻译的第一场景就是跨语言检索。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;机器之心：现在有很多企业都和高校实验室建立了非常紧密的合作关系，能介绍下搜狗在 NMT 上和清华大学的合作吗？&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;许静芳：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;这是非常成功的校企合作的案例。2016 年搜狗捐赠清华大学打造天工智能计算研究院，机器翻译也是天工智能研究院下面的第一个合作项目，将搜狗的技术能力与清华刘洋教授的机器翻译团队的长期积累相结合充分发挥两个团队各自的优势，最终也取得非常好的效果。机器翻译的技术门槛很高，业内很多团队做机器翻译都是一年以后上线，或者两年以后再上线的，我们其实只花了四个月，这也体现搜狗在人工智能上的优势与决心。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;天工智能计算研究院是 2016 年成立的，但是这个研究院的前身是搜狗和清华计算机系的搜索技术联合实验室，这个实验室已经有 9 年的时间。搜狗一直以都非常支持学术界的研究，我们对学术界开放了最多的数据集，也有着广泛的合作，可以说搜狗在这方面是推动了国内相关方向的发展，也推动了全世界关于中文的研究。2016 年联合实验室进一步升级成研究院，还有很多其他项目正在进行中，相信马上会有一些其他的成果会出来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 23 Jan 2017 12:33:02 +0800</pubDate>
    </item>
    <item>
      <title>演讲 | 中科院徐波：中国脑计划的现状和发展方向</title>
      <link>http://www.iwgc.cn/link/4456045</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;编辑：虞喵喵、李泽南&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;去年 11 月底，中国科学院神经科学研究所、中国科学院脑科学与智能技术卓越创新中心、香港科技大学生命科学部和分子神经科学国家重点实验室、中国科学院自动化研究所在《Neuron》上联合发表了一篇概述论文&lt;/span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720765&amp;amp;idx=1&amp;amp;sn=d023cbc68ce9cec7e00ebc44d940a7d9&amp;amp;chksm=871b0d83b06c84952a94754e60f22126dd64a9c198deaeccc7ae3c6dc04eb0f190c9877de4f3&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720765&amp;amp;idx=1&amp;amp;sn=d023cbc68ce9cec7e00ebc44d940a7d9&amp;amp;chksm=871b0d83b06c84952a94754e60f22126dd64a9c198deaeccc7ae3c6dc04eb0f190c9877de4f3&amp;amp;scene=21#wechat_redirect" style="font-size: 14px;"&gt;《China Brain Project: Basic Neuroscience, Brain Diseases, and Brain-Inspired Computing》&lt;/a&gt;&lt;span&gt;，介绍了「中国脑计划」在基础神经科学、脑疾病和脑启发计算上的研究进展。中国脑计划引起了人们的广泛关注。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最近，该论文联合作者之一，中国科学院自动化研究所所长，中国科学院脑科学与智能技术卓越创新中心（CEBSIT）副主任徐波在中国中文信息学会第八次全国会员代表大会上做了「类脑智能研究及发展方向」的主题演讲，以下是机器之心现场整理的内容。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8pKMq7FfCv5GPQGsEnoqGPiczSpylOd5ZXiauvheaUaeXhq6icDJibtNFvic6PQlhHoSbicy9DwViaI5bqg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;非常高兴有机会能和大家一起分享，类脑研究出现的时间不长，这个领域里有很多不成熟的地方，希望我们的研究能为大家带来新思考。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;众所周知，人工智能是目前科学界的研究热点。在人工智能领域里，除了深度学习以外，类脑计算这个词出现的也越来越多了。类脑计算通常是指研发新类型的芯片，电子器件和体系结构等等，在软件上与信息处理研究，构建模型和算法等等相关。类脑计算还有一种提法，在 863 的课题里面叫做类人智能。类人智能主要是行为级别的考量，目标是在功能上产生与人可以相比较的智能，但不关注达到目标需要使用什么样的方法，所以这里面有一些细微的差别。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在英文里，类脑在学界存在着不同的说法。有人喜欢用 brain like，顾名思义，通过研究复制或者部分复制人类大脑，这种说法忽略了如何复制大脑；另外一种是 brain inspire，受脑启发的智能，或者受脑启发的计算，简称类脑。这是基本名词和概念的解释。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在内容的第一部分中，我选择了和计算学习相关的一些方向进行介绍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;脑科学对人工智能的启发&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今年 1 月初 AlphaGo 打败众多围棋冠军是人工智能快速发展的标志。但其实人工智能最大的前景在于它会在未来 5 到 10 年中与各个行业深度融合。这是一个艰难的过程，因为每个行业都有它的门槛，但是不管怎么样，人工智能已经成为一个国家层面的战略方向。我们现有的大多数的智能可称为大数据智能，或监督数据学习，它的最大特点是：这个系统呈现出多大的智能，它的背后就存在着多少人力的投入。包括围棋的应用、语音识别、图像识别，都需要大量的人工标注性的工作。但是，我们看到的大数据的智能，有两种问题无法解决：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一类问题被称作超大规模空间，这意味着状态空间非常大，数据再多，对这样的问题而言都是稀疏的。此类问题用现有的方法很难解决。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一个问题在于现有人工智能都是专用的智能。下围棋的系统不能下象棋，扫地的不会擦桌子，它基本上没有自我学习，举一反三，触类旁通的能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;反过来看看人类的大脑，欧盟 2012 年的脑计划报告中写道：在自然界里，除人脑以外，还没有一个自然或者人工系统，能够具有对新环境新挑战的自适应能力。新信息与技能自动获取能力在复杂信息进行有效的决策，并稳定工作，直至几十年的能力。也没有任何系统能够在多处损伤的情况下，保持像人脑一样的鲁棒性。而且与其他人工智能相比，人脑的功耗非常低。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;受脑启发的智能，据我们的理解，实际上是横跨脑科学、认知科学到智能科学，并持续发展的一个方向。在脑科学中，有很多个尺度的大脑的观察机理可供借鉴。其实在很多的脑计划里面，比如美国的脑计划（2013 年启动），它的重点是在突破大脑的观察的技术，测量的技术，希望能看到每个神经元的放电活动。而日本的脑计划（2014 年启动）主要关注于脑疾病。欧盟的脑计划（2012 年启动）主要是做大脑模拟，为新一代的信息处理的研究提供依据。从其他国家的类似计划中我们可以获得很多信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8pKMq7FfCv5GPQGsEnoqGPtgvPVGblKUicLQRFV1eU5jSQ92TRuIiaAP8nCOAmECmCkfk0g3Aj9Vsw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外，在认知科学中，我们也可以获得很多的信息。比如近年来，我们在大脑中的视觉、听觉、语言中对于认知通路的研究正在变得越来越清晰。在这其中视觉通路的研究是最多的，这些研究为我们理解脑认知功能奠定了基础。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;智能科学大家都比较熟悉了，本来就存在一套计算方法在这个领域发展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8pKMq7FfCv5GPQGsEnoqGPDPVUrCy7sF1bj0jzd33G358F8RyFbRhsAtibNwTCPgNjMGObnXSKWpA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;类脑智能的核心问题在于：我们能不能把脑科学、认知科学和智能科学里面的一些研究成果整合起来，来产生比我们现有的人工智能、神经网络、深度学习，更好的算法和模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如图所示，类脑研究有两个源头，一个是神经科学。这是一个统计，过去三十年产生的神经科学的知识，大概是 80 年代以前的 46 倍。现在的神经科学发展速度更快，因为神经科学的发展，主要依赖于新技术的出现。现在每年神经科学新发现的数字，是 80 年代以前的 100 倍，这个速度还在不断加快，越来越很多的知识可供我们使用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从类脑智能角度，人们可以借用什么东西呢？从大的角度来说，或者多尺度的大脑信息处理，这些机制能不能被我们所用呢？我们现在知道神经元的类型非常多，人脑中有上百种神经元，粗略分类至少有有抑制性的跟兴奋性的两类的神经元。然而，现在的人工神经元都是单点式的简化的模型，还有人在做有树突的人工神经元模型。第二，神经突触的形成跟消亡，是我们最基本的学习的机制。现有的人工神经网络输出都是一类函数，而生物的神经网络，是一种神经兴奋发放模式，一个被称为尖峰神经网络的机制，它和现有的计算机神经网络不一样。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;现有认知模型&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关于可塑性机制，最基本的可塑性机制比较简单，但在整个大脑中又会产生非常复杂的现象。关于连接，就是神经元的前项连接、后项连接跟撤销的意志，这在生物体内都可以观察到，这就是所谓的神经元。从脑区级别来看，像神经回路、功能环路、基底神经节、丘脑型这样的感知决策模型，和像前额叶脑区、运动脑区等形成的模仿学习功能，像多感知的突兀，它是视觉、听觉、触觉向外脑区上颞叶，与整合区形成了一个多通道学习和记忆方式。它是不同的认知和不同的脑区相互协作的结果，从通用智能角度来看，生物体中还有很多机制可以借鉴。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从认知来看，我们对人脑处理外界信息的方式已经有了大致的了解。人类拥有视觉、听觉、触觉、嗅觉、味觉，结合短时记忆经过工作记忆的处理，可以慢慢地把信息进行理解抽象，变成长时记忆，人类会在成长过程中慢慢形成自我的概念，形成过去的经验。长时记忆会对后来的视觉、听觉、触觉产生反馈与影响。所以从认知的角度来说，记忆模型各不相同，不同类型的记忆实际上利用了不同的通路。像程序性的记忆，我们一旦掌握了某些技能，比如学会了骑自行车，学会了游泳，你就可能永远会都不会忘记，所以这些程序性的记忆，还有像无意识的条件反射，大多被称为内涵式记忆，当然还有外显式的记忆等等。我们在认知科学里面可以做很多认知实验，这些问题将来我们都会去验证、去发现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从认知科学中我们将获得什么？其实最典型的就是很多人都在用的 random、推理、tension memory 这样的模型。此类模型有三个部分，其中一个就是短时记忆。比如我们进行小组对话，用这个模型做关于对话的理解，那整个对话的意思就是一个短时记忆，系统进行编码以后再进行工作记忆处理，随后你对这个对话可以提出任何问题，系统会产生响应。但在这个对话里面，在理解一个问题的时候，可能需要很多背景的支持，这些内容可能存储在长时记忆模块里。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是一种典型的模型，我个人认为它是受到认知科学启发的。深度学习研究者们正在进行这方面的研究，这也是我们做的，我们把 tension 机制细化到词级别的颗粒度上，通过多轮的迭代，最后获得需要的答案。由此观之，类脑就是人工智能的发展动力，至少是一个可以参考的路径。除了欧盟、日本，在美国脑计划中专门有一个项目叫做 mapping，通俗来讲，它是要研究一立方毫米体积的一个脑区，把它整个从外面到突出极的所有连接结构绘制出来，美国在这个项目上投入了 1 亿美元作为启动资金。他们下一步计划把探究出来的结构用到人工智能里面。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;中国在 2016 年的人大上通过了十三五的发展规划，其中脑科学与类脑研究成为了 100 个重大项目里面的第四位，这些部分都是和脑科学相关的，不仅是疾病研究，还有类脑研究。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;换个角度，从人工智能的角度求解这个问题。面对常规的一个问题，系统的求解需要把一个问题形式化，不论是律师、媒体还是下象棋，一定首先需要人的介入，把这个问题分解成几块，其中每一块都可以转化为一个图灵机的问题。然后再用现有的计算机结构来实现人工智能问题的求解。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从类脑智能的角度来看，我们希望计算机能够通过像人一样用序列化的学习方式来减少对人工形式化的依赖。如果我们实现了这一设想，我们就非常接近通用的人工智能了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这就是第一部分内容：类脑研究主要将不断从神经科学、认知科学，尤其是神经科学中受到启发。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8pKMq7FfCv5GPQGsEnoqGPicZxTgBeJWTzDYC50rfCqgR9dd3KevVFCqX72ac7BeZqKVgFzI0MW1Q/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;类脑研究的主要方向&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;类脑研究具体是哪几个方向？我们正在探究各种可能性，我们认为大脑具有高度可塑性机制。未来的人工神经网络或许可以受此启发。这是一个 STDP，它描述了人类局部神经元之间突触的连接强度，随着相邻两个神经元先后放电的时间差异——增强或减弱而产生不同表达的神经的机制。这是生物学习机制中最基本的元素，它实现的功能是通过有持续地激活神经元集群，产生神经连接发生有序的强化，可用于储存信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这样一个简单的、生物化的学习机制。它是无监督的，非数学化的。例如在空间维度信息的学习和记忆、手写数字识别、图像存储与提取、以及机器人的动作序列学习，还有短周期节律的学习都可以借鉴这种机制。实际上研究人员已经在进行此类探索了。这样的学习机制将会与目前不同的人工神经网络，包括现有的监督学习去比较。它目前的性能比生物体中的效率要差一点，但是仍然达到了 95% 的准确率。目前的探索证明了生物学机制的潜力。纯生物 STDP 可适应机制可以让机器人学会绕着某一条线走路。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是一种轻监督的任务，机器自己理解路的概念，理解需要沿着路前进。我们在加油站外广场的 24 小时监控图像里，通过人工智能分析，可以识别图像内容，而且对内容进行分类。此外，我们开发了序列记忆系统，它可以识别音乐节拍，然后重现出来。所有这些都应用了这样的机制。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从微观角度来看可熟悉机制，无监督的学习方法已经在上述的一些任务里取得了一定的进展。但是它引出了认知范围的能力的问题。目前的无监督学习只能适用于有限范围内的任务处理，因为它基本没有在结构上面做特别多的处理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这一领域的研究还有很多方向可以进一步深化。比如秒量级的节律信息处理，就是说研究节拍之间，比如节拍超过几百毫秒的时候，STDP 怎么如何记录这种节拍。如果希望使用生物的学习方式，一定要有结构的配合，包括信息的无监督编码的提取和复杂特征的编码。在这一方面，比如 spike，这个神经网络功耗非常低，同时是弱监督的。生物机制中的 bottom-up 与数学上的 top-down（目标函数驱动）的方法如何整合，来形成新一代的人工神经网络，是未来我们研究的方向。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8pKMq7FfCv5GPQGsEnoqGPymZoPBXpHk6P7icBE1jUfqEgUGMRfx3Inic7QxAYM80WaZEjg3PibriaibQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在有很多其他领域的学者跨界在进行这方面的研究。本次讨论的关键词，可塑性机制，脉冲神经网络（脉冲神经网络和人工神经网络的输出不同，它不可微分，所以数学上的原有的理论不能适用）还有强化数据深度学习。这些概念，如何整合在一起？如果可以提出一个新的模型，它的学习效率更高，对数据的依赖性、监督性、标记的依赖更弱，会是非常有意思的工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8pKMq7FfCv5GPQGsEnoqGPIIaA324YuuicXTwUFAPN0MiatJfkRNpWaOoImNAeDO2pOYH7kUOEQ1icg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二个方向，实际上认知功能都是由若干个环路或者是一个通路组成的，是若干脑区构成的一个通路。这个体系作为整体呈现出人类的认知功能，从计算的角度来看，最核心的问题在于，不同脑区之间是什么样的协同关系？刚才的讨论中已经提到了一部分，很多的功能，包括模仿、决策、整合，都需要十几个脑区协同合作（假如细分的话，这个数字会更大），但整合起来才能产生复杂强大的认知功能。脑区有几种组织方式？我的看法倾向于层次化的方式，尤其在感知方面，在视觉方面这种方式非常明显，从感官到第一要区，再到高级的认知功能和记忆、判断推理、眼动、控制四肢手、运动规划都有这种方式的痕迹。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8pKMq7FfCv5GPQGsEnoqGPYH6ztxz1Zrpia7d45WndFjXD42aUIs2ROcsALz7QJC5qeeNwzfDwDQg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一种组织方式体现在高级认知系统中，我认为是模块化的。不同的脑区之间有相互反馈和信息的交互。比如记忆系统的沟通，强化学习性，它的连接关系相对来说是层次性的，比视觉系统复杂。在研究协同方面，我们也做了很多工作，比如视觉和层次的研究，我们根据现有的神经科学数据，构建了视觉的各种模型，它和以前的此类模型，包括 20 年前的听觉模型等方式大不相同。在新的视觉模型中，我们通过多层次构建了一个符合生物进化机制的目标函数，来求解区域之间的连接强度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然模型每层之间也有新的特性，例如侧向连接。模型中神经元的数量来自于一些生理数据。受到这些结构启发的模型，它在感受、空间分布，还有相应的神经元细胞的响应，实际观察来看同步性是非常相似的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然，模型还包含有类结蹄组织结构，神经元的倾向分位，差异分布等等特性。我们看到的协同，就是层次化的脑区的协同，我们希望能够构造符合生物进化机制的目标函数，使得它能量消耗最低。具体表现为突出的、连接的低能耗，还有表征的低能耗。另外我们从多脑区、高级定制、协同等方面也进行了研究，开发出了进阶模型。模拟了十几个脑区，完成从视觉编码开始，到最后做出决策的所有任务。这种模型被称为运动感知和决策模型。其中包含兴奋性通路和抑制性通路，还有内部的连接关系及扩散结构，不同的脑区相互作用等等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;应该说，这个模型基本上是用仿生的思路开发的。另外，我们对单个神经元的类型也做了很多的尝试。我们用不同类型的神经元构造出整个网络，模拟了脑区之间的竞争的机制，学习行为选择和权重更新等机制。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个模型最终展现出来的学习机制总体而言比较简单，就是通过多巴胺的释放来调节学习的速度，这有点类似于奖惩信度分配——强化学习里面的逻辑机制。它呈现出了类似强化学习的功能，但它的复杂度、学习的速度都比后者要快。我们把刚才提到的视觉层次化与运动决策模块化整合在一起，研究无人机躲避障碍和处理突发事件的新方法，这些实验也是我们研究的一部分。这类研究最大的特点就是它具有可解释性，它完成每个决策时，每个脑区，每个神经网络发挥的作用都可以解释的，研究者可以清楚地观察到。这是我们新一代人工神经网络的重要特征。它不像现有的监督学习方式，在训练后处于黑箱状态，人们无法获知神经网络每一层的功能。我们的模型从仿生角度设计，可以较清晰地观察特定脑区在发挥什么样的作用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第三部分更加复杂，但对于类脑智能的价值也非常大。就是探究如何构造一个可以发育演化的模型。现有的神经网络学习与人类最大的区别在于时间尺度。人类的学习也许会经历几年或几天，它的时间序列非常长。我们目前的感知系统无法这样学习。我们的机器学习始终把目标函数作为优化的唯一的机制。而且在优化过程中，我们能看到其中有很多表示，其中印证了神经科学的一些发现，包括刚刚讲到的脑区细胞类型、分子状态、计算和存储的机制。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在最早神经科学把神经元的概念引入到机器学习中，启发了深度学习等方式之后，最新的成功研究和神经科学的关系越来越少了。但是，我们现在看到神经科学与机器学习融合的新机会正在出现。我们首先意识到机器学习的目标函数正在变得越来越复杂。现有的大多数神经网络都是单一目标函数，但有很多的神经网络可以随着不同的神经层、深度、时间产生变化。比如学习次数不同导致目标函数的不同, 它可能会有持续的捆绑性，我们在底层机器学习的设计中也许需要把它考虑在内。还有大家最熟悉的对抗式学习，它是由两个神经网络组成的，用一个网络修正另一个网络的输出的目标函数。这些方向为我们未来的机器学习模型打开了思路。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了使优化更加高效。机器学习已经发展出了不同的网络结构。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;神经科学与人工智能之间的关系存在三大假设：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1、大脑具有优化目标函数的能力。大脑特定的脑区，特定的结构具有在数学层面上优化目标函数的能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2、目标函数在不同脑区和发育阶段是不同的，现代机器学习的发展，实际上也是从这里受到启发的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3、大脑中存在大量的专用机制，这是天生的、在进化中得来的，可以有效地解决一些关键的计划问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从大脑优化目标函数的方式中，我们可以观察到人类在运动过程中其实有很多的策略，从进化角度考虑，人类必须减少能量的消耗，减少运动的风险，降低受到伤害的几率。我们目前认为目标优化策略机制在大脑中广泛存在，它们形成了不同的特定处理方式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那么大脑目标函数优化的确切含义是什么？有很多的网络结构，比如馈增网络，有些存在反向通道，STDP 机制和一些相关结构。在经过学习后可以产生和数学上的 BP（错误反穿）一样的效果的学习机制。但目前有关大脑中存在 BP 学习机制还是一种假设。在神经科学中，哪一种运行机制假说是对的还没有定论。但这些假设可以给人带来很多启发。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二个假设是目标函数在不同脑区和不同发育阶段是不同的。这很容易让人理解，在构造神经网络应用的时候，可能一个网络被用于进行分类、决策，另一个网络会不断地随时间、环境，或者被其他动机驱动，产生变动的目标函数，因此，这个神经网络就会更加适应环境，具有更好的表现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8pKMq7FfCv5GPQGsEnoqGPzzNE8D9tdwNb7lEw5exzhofjCZU9dM5P0ztUibc8x6vZbQrXAevvN3w/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前的深度学习正在向无监督方向发展，人脑是否存在真正的无监督学习？我们现在仍然只能进行假设，因为大脑实在太复杂了，目前的神经科学还难以支撑这样的结论。顺着假说的思路，利用无监督学习来解决特定的问题是目前研究者面临的挑战，如果按照刚才的优化目标来看，大脑目标函数是随着时间和不同的发育阶段而变化的。因此，我们需要探讨的问题是，真正的演化是不是根据当前的状态？我们能不能通过一系列目标函数来建立回路和行为？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们总是希望用较少的数据来训练完美的模型，人类的大脑在进行学习时不需要一个具有数百万已标记数据的数据集来训练。人类只需要一些简单的逻辑和少量事例，就可以触类旁通，仅需要非常少的数据即可完成训练。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在，我们希望计算机可以把复杂的问题分解成若干的不同的阶段，每阶段只需少量数据进行训练，输出相应的目标函数，如果这个方向出现了成果，那么人工智能就向前迈进了一步。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二，在增强学习上，我们目前认为大脑中普遍存在此类机制。增强学习和深度学习正在不断地被整合，此类研究也已经出现了很大的进展。它的基本思想就是用强化学习来产生定义的目标，也就是说所谓的有效错误反弹，它也可以理解为通过学习需要达到的目标，加上强化的过程。我们可以把这种学习方式理解为不断变化的 cost function，加上半监督学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第三，专业系统如何进行有效计算的问题，这与实现机制结构相关。不同模式的信息在不同领域中被用来解决各种类型的问题。有些区域是 highly recurrent，有些区域是在不同的激活状态，有些区域好像在做信息的路由，基底区在做增强学习跟离散的决策。在大脑中可能存在一些较为固化的结构在做无监督学习，这意味着深层次的模型可能是大脑中的固定结构，因为深层次模型是不需要监督的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;还有一些有关物理世界固有特性的目标函数，比如说一个物体，我们推动它会产生惯性。在特定结构下做出优化，即使有一组强大的基因来决定，我们的 cost-function 要在一个空白的网络上演化出复杂的认知也是非常困难的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8pKMq7FfCv5GPQGsEnoqGPFDq1kmYspzFKU2iah0ibItZ4Gyd6XAIZHouDubxmKV0TpmSHiaMq9HfoQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;从大脑中寻找灵感&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;预设一个结构对解决复杂问题而言是必要条件，优化公式的学习是在复杂的动态的协同过程中完成的。我们知道大脑中存在很多特殊结构，用于完成各种类型的任务，这种机制并不需要经过大量学习。目前，智能研究社区非常关心大脑到底有没有反向传播（backpropagation）机制，我们可以设计一种模型，实现类似大脑的反向传播，但从生物学中更复杂的技术层面上看，类脑的角度是非常有益的。无论如何，一旦生物运算机制被我们破解，我们就可以把它复制到计算机领域中，使得人工智能程序的学习变得更加简单、更加有效。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在演化部分里有这样一个结论：假如我们目前的技术向内容的认知能力方向发展，最后出现的算法将会远远超出目前硬件技术所能容纳的范围。从大脑的角度来看，目前人造的数据驱动方式都无法达到人脑的运行效率。所以，我们需要转变思路，吸收很多的模块化机制，反应偶然性的推理方式，原始物理和心理机制，来构建能够理解感知现实世界的模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;DARPA（美国国防高级研究计划局）的局长在 2014 年的一份报告中讲到：生物是自然界的终极创新者，任何直观创新的机构如果不从作为复杂系统的大脑中寻求灵感，都将是愚蠢的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大脑拥有上千亿个神经元细胞，百万亿的突触形成的网络，其复杂程度也许让我们一时难以复制。我可以先用一个简单的模型来说明这个问题：亚马逊蚂蚁，上千只蚂蚁组成的群体，当它形成一个环形的运动状态，它会一直爬行，直到所有蚂蚁都累死为止。但是当遇到阻碍的时候，它们又能搭桥；碰到蛇的时候，它们可以互相配合进行抵抗。蚂蚁的行为非常简单，但它们可以通过协同合作来完成个体无法做到的任务。对于大脑来说，原理也是类似的。当我们最终了解了大脑的复杂系统信息共享，自主性和实际性信号处理等等机制的秘密，人类的科技水平将会出现新的突破。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8pKMq7FfCv5GPQGsEnoqGPdT1IYKAocGibMRuADOic5r079uy0Pwic5DmUnwo8dOKmcaYeQdM3QaicCQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有人说现代科学已经进入了复杂性微积分时代，我们正在从多种研究角度，从心理、计算、动力学、混沌、进化等不同的角度在研究复杂性。但是整个生物学领域里面，越来越多信息处理的思想来正在形成我们理解动物行为的理论框架。虽然在生命系统中，信息的处理和计算的完整概念还非常的模糊，科学家们对于它定义的形式化都还没有形成共识。但是，可以预见的是，计算机科学及更广泛的计算领域终将从类脑智能的研究中获益。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以上是我个人对于类脑智能的一些见解。这是我们目前正在进行的研究，把一个鼠脑的几百个脑区，七千多万个神经元用一些现有的信息处理方法进行完整的模拟。现在，我们的研究还处于初始阶段。在全脑的尺度中，即使是一些非常初级的功能也需要进行大量的探索，但我们的征途已经开始。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谢谢大家。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编辑，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 23 Jan 2017 12:33:02 +0800</pubDate>
    </item>
    <item>
      <title>干货 | 创业经验分享：如何打造一家硬科技创业公司？</title>
      <link>http://www.iwgc.cn/link/4456046</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自backchannel&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：邵明、微胖、杜夏德&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;人工智能时代的黎明已经到来，在科技创业这个领域，旧的规则已经不再适用，Lytro 公司 CEO Jason Rosenthal 近日在 Backchannel 上发表了一篇文章分享了他打造硬科技（Hard Tech）创业公司的经验。百度首席科学家吴恩达也在其社交网络上分享了这篇文章并评论说：「比起大多数消费产品（主要是消费者风险），硬科技产品（带有技术风险）需要更耐心的投入。」&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote style="color: rgb(62, 62, 62); font-size: 16px; white-space: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicKlJibSVAicqxlFTC2znL3Mf9u3t5kywibwDVm6P2brqrDPxyvvg5lYJQVzxP1kV6mplJnfoAq7M98w/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;几年前，我有一个惊人的发现。我用了不少于 15 年时间去开发和发布科技产品，但是突然间，过去练就的技能和直觉变得没啥用了。实际上，如果我还坚守着这些旧东西，它们会把我的公司毁掉。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是我创办自己的公司 Lytro（打造用于电影、电视节目和虚拟现实体验创作的新型摄像头和软件）的一点领悟。创办 Lytro 后，我开始面临着一种新的挑战——一种「硬科技初创公司（hard tech startup）」面临的挑战。创办这样的公司，你一开始并不知道发明所需的核心技术到底能否奏效。物理学、生物学和摩尔定律都以意想不到的方式折磨着你。设计一款赢得市场的产品已经够难的了，但是这些赢科技创业公司面临的困难更大。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Lytro 的目标是向释放虚拟现实、传统电影和电视行业的创作自由。有了 Lytro Cinema，导演和摄影师就能在后期制作中，借助计算机控制镜头的更多方面——比如焦距、曝光、帧速率。为此，我们不得不开发世界上最高分辨率、帧速率最高的图像传感器；发明一种新型的光学器件；解决海量数据带来的存储难题；创造一种全新的成像算法（imaging algorithms）。当初着手时，我们并不知道能不能做到这些。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;面对这种挑战的初创公司必须抛弃传统创业智慧。在过去的十年间，Eric Ries 的经典书籍《精益创业（The Lean Startup）》已经为开发成功的产品和公司设置了默认准则。全球互联网用户的数量急剧增加，基础设施的成本大幅度减少（如亚马逊网络服务），企业家可以快速、低成本迭代某个想法并实现产品/市场匹配。智能手机的爆炸性增长和社交网络的兴起扩大了产品分布渠道，年轻的公司接触自己的目标客户变得容易得多。但是，这些经验规则不适用于硬科技初创公司。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我采取了全新的思维方式，并对这种思维演进感到非常振奋，我相信我们正处于将科幻小说主题转化为现实的边缘。如今，最活跃的创业领域之一就是硬科技领域，包括自动驾驶汽车，太空、人工智能、虚拟现实和基因组学。较之传统互联网产品。这些硬科技公司的产品可能更激动人心，意义也更加深远。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以下就是我的硬科技创业经验。尽管这个例子是 Lytro 特有的，但是我相信它们广泛适用于那些正在试图利用全新尖端技术的公司。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1.从最小可行技术性验证（the Minimal Viable Technical Validation，MVTV）开始&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;众所周知，一种流行的产品研发方法就是最小可行性产品（MVP），其目标就是开发只具备足够功能的产品，看看早期客户群体反响如何。这个过程通常很快、节约资本还能迭代成功方式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是，这套方法对硬科技产品却不起作用。这里，你通常要解决尚未有人成功解决的问题，所以，你不得不想出最快最节约成本的方式去确定自己的建议是否可行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2015 年初，我们遇到过一个典型案例，当时我们开始尝试在系统核心部位加一个光场图像传感器。光场相机不仅能像传统相机那样捕获光的强度，还能捕获给定场景中其他光学特征，例如光的传播方向。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了实现产品目标，我们需要一个能记录每秒 300 帧的 755 兆像素（MP）的传感器。这像素大约是当前行业标准（8.3 MP）的 90 倍。我们自己打造这样的传感器将会花费 3 年多时间以及 1000 多万美元——如果我们可以做到的话。所以，我们首先要知道这个核心想法是否具有技术可行性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们的团队由 Jon Karafin 和 Brendan Bevensee 领导，我们的团队不是试图白手起家构建目标传感器，而是决定将许多现成的图像传感器拼接成一个巨大的单片传感器，实现 755 兆像素（MP）的目标。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一步，确定是否使其中两个传感器很好地协调工作。单单这一过程就需要相当多供应链管理工作和校准工作。这是我们团队制作的第一个测试图像：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicKlJibSVAicqxlFTC2znL3Mf138YVvj8qcWcoOZ811XibDB46PX3STJwnlSrVkegOeYMTSWJpLCELUQ/0?wx_fmt=png"/&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Lytro 的业务发展副总裁 Jim Migda 不情愿地为 Lytro 相机拍摄第一张测试图像摆姿势。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;结果，MVTV 给了我们继续往下走的信息构建小规模、低分辨率的光场视频采集系统。尽管我们保持分辨率和 MVTV 一样，但是，我们增加了所有能将其转化成光场系统的软硬件。我们整个项目的代码是 Trillion, 所以，我们将该原型命名为 Mini-T。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicKlJibSVAicqxlFTC2znL3MfpAzggCglT49ZDEC9cpH7jlNgM6IJtYicZacOm9iaoTKIMkMNrn36hCLQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Mini-Tin 的实验室和野外测试拍摄&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使用 Mini-Tin，我们开发了一套 demo 和概念验证，它们给我们继续构建完整系统提供了信心。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;iframe class="video_iframe" data-vidtype="1" allowfullscreen="" frameborder="0" height="417" width="556" data-src="https://v.qq.com/iframe/preview.html?vid=p0369ylpobh&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0"&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;/span&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;我们的第一个低分辨率光场视频显示了 Lytro Cinema 的一些计算能力。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然后，我们又用了 8 个月打造出产品的第一个版本，并在 2016 年 4 月（距离项目启动时，仅过去 12 个月）的 National Association of Broadcasters (NAB）会展上发布了该版本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicKlJibSVAicqxlFTC2znL3MfYvVMdia0ia2yJI6vrJqQwT8FdVDP8JJg47aFZtXhLWCpiaa8aWibG9lqvQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2.如果破译供应链没能杀死你，那么它会使你更强大&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;专注于融合专有硬件和软件的硬科技初创公司的最大挑战之一是关键组件可能不以你需要的形式存在——如它们存在的话。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当我创办 Lytro 时，我天真地认为解决这个问题很简单，就像去中国深圳或者其它一些制造中心一样，与领先的供应商和合同制造商对话，要么找到现成的东西，要么去说服供应商调整现有的零件。毕竟，为什么这些供应商不和一家能开发很酷的产品并且具有开创性的硅谷公司合作呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWicKlJibSVAicqxlFTC2znL3MfOJiaqb1aGFNIU3LbXwcXfF97ibzWj2cwCvjhIcMrLeoJ0cQNsCjgbXJA/0?wx_fmt=jpeg"/&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;中国深圳是技术世界里的制造中心。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;结果证明我完全错了。找出最能够为你提供所需产品的供应商们本身就是一种暗黑艺术。大型科技公司经常利用市场的力量确保别人不能够利用它们供应链中特别重要的部分。智能手机行业里经常使用这种策略，这里的竞争超过显示器、镜头、光学、房产和其它组件行业。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一次经历这个过程是艰难的。我们必须找到图像传感器、相机的电子产品、光学产品的适当组合方式。很多时候我都觉得我们完成不了，路走到头了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicKlJibSVAicqxlFTC2znL3MfHlu4CZ0SvXCIUF4TO2kqunrMAzQRZ5CWhWP65UybN9ibHdUhh3jnVKg/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随着时间的推移，我开始发现这个挑战是发明过程中的有趣部分。这是既是一个寻求合适供应商的寻宝活动，也是一个解谜游戏。因为在此过程中我们要学着改进我们的设计，找到我们想要的东西。在第一次解决这个问题的过程中经常会产生一整套改进现有设计的新思路。并且这些新思路可以成为一家公司竞争优势的来源。在我们的案例中，最符合我们要求的供应商自于美国和欧洲，而不是亚洲。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3. 从原型到产品的过程比你想象的更难、更漫长&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以，你已经成功建立了一个改变游戏规则的产品的原型。所有的主要功能都像你设想的那样，甚至更好。你丢掉了第一个测试版客户。你相信自己可以改变整个产业或者人们的生活方式，这种信念非常强大。这一路上，你唯一需要面对的是将你的产品原型转化成强大的产品，并准备好面对顾客对你产品的严格审查。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;预测任何技术从原型转化成产品所需要的时间、努力和资本都是困难的。但是，根据我经验来看，预测硬科技产品周期特别困难。一个好的经验法则是，在最保守的时间、成本估计的基础上，投入双倍的时间和成本。原因是，你正在硬件和软件水平上试图去做从来没有做过的事情，面临的是完全未知的境况。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 Lytro Cinema 的案列中，我们发现关于系统的每个部分，包括机械、电子、光学部分都至少要进行一次重大返工才能满足未来客户的需求。（我们的目标客户是大型预算电影和电视节目，毫不奇怪，这些客户是世界上最需技术和创造性的客户之一）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;许多硬科技企业家在首次将硬科技从原型转换成产品的阶段中，大大地低估了这一阶段所需要的时间和成本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在我与许多在 Kickstarter 上发起项目的企业创始人的对话中，我发现从原型到产品的这个过程中，许多项目比预期延长了数月、甚至数年，这远远超出了最初的预测。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4.&amp;nbsp;先慢后快&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;建立一个硬科技初创公司会让你面对一系列有趣的智力问题，这些问题有潜在的巨大社会影响。在这里，竞争通常没有主流产品间的竞争激烈，不受硅谷「超速发展」的魔咒的束缚，但是却极需创业者的耐心。当你要打造一个极具颠覆性的技术或公司，其依赖的核心是全新的技术时，小心选择最初的客户是至关重要的事情。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对我们而言，这就意味着要密切关注最初几个客户的成功和满足感，这是我们业务的基础。如果从 20 个或者更多个客户着手，成功地抓住了一些客户目标，同时丢失了另外一些客户目标，这是一条更困难、更具风险路。为什么呢？因为，最先满足最先成功的客户将会是你最好的伙伴，会为你的产品吸引更多的客户，一个接着一个。要留出一些时间和空间去了解你的最初客户，去解释未知的未知事情，从少量的客户出发，去了解客户对产品所期盼的、需要加强的部分更容易。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;许多领域的技术创新都有它的起源，今天我们有越来越多的企业家正雄心勃勃地去着手于改变世界的难题。低成本的云计算、机器学习的复兴、基因组学的快速发展已经为用计算机解决新的问题打开了大门。全球供给链的形成、智能手机行业的大力驱动，已经使产品的制造越来越快、越来越便宜。硬科技初创公司深入挖掘这些新的领域，将硬件和软件相结合、软件和生物领域相结合，其复杂度远远超过了 5-10 年前的企业家们处理的难题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了在这些领域取得成功，我们要与时俱进，不断更新创业公司成功案例。这是我们成功的法则。我们的 Lytro Cinema 旅程刚刚启程，毫无疑问，这一路上，我们还会面对更多艰难的旅程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 23 Jan 2017 12:33:02 +0800</pubDate>
    </item>
    <item>
      <title>业界 | CMU人机德扑大战进入中场，人工智能豪取46万筹码</title>
      <link>http://www.iwgc.cn/link/4456047</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自CMU&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀、李泽南、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote style="color: rgb(62, 62, 62); font-size: 16px; white-space: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/blockquote&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;当地时间 1 月 11 日，在宾夕法尼亚州匹兹堡的 Rivers 赌场，由卡耐基梅隆大学（CMU）开发的名为 Libratus 的人工智能系统与人类顶级职业德州扑克玩家开始了奖金 20 万美元的比赛。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;据官网介绍，此次比赛共持续 20 天。由 4 名人类职业玩家 Jason Les、Dong Kim、Daniel McAulay 和 Jimmy Chou 对战人工智能程序 Libratus。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;iframe class="video_iframe" data-vidtype="1" allowfullscreen="" frameborder="0" height="417" width="556" data-src="https://v.qq.com/iframe/preview.html?vid=m0366yacxu6&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0"&gt;&lt;/iframe&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722085&amp;amp;idx=5&amp;amp;sn=6628c3a29d6cccfe1f56e2a6f39678ca&amp;amp;chksm=871b0b5bb06c824d587b32c60e9f76e34faf8b8f7811ad2f1738da44b1cdf5068967a555b13e&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722085&amp;amp;idx=5&amp;amp;sn=6628c3a29d6cccfe1f56e2a6f39678ca&amp;amp;chksm=871b0b5bb06c824d587b32c60e9f76e34faf8b8f7811ad2f1738da44b1cdf5068967a555b13e&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;Libratus 是一个玩无限德州扑克的人工智能程序&lt;/span&gt;&lt;/a&gt;&lt;span&gt;，由卡耐基梅隆大学的 Tuomas Sandholm 教授与 Noam Brown 博士所开发。Libratus 的策略并非基于专业玩家的经验，所以它的玩牌方式可能有明显的不同。基于在匹兹堡超级计算机中心大约 1500 万核心小时（core hours）的计算，它使用算法分析德扑规则，建立自己的策略。在此次的比赛中，Libratus 将继续提升自己的策略。据介绍，创造 Libratus 使用的算法并非为扑克专门设计的。在面临不完全或误导信息时，该人工智能进行推论的能力有着广泛的潜在应用，包括业务谈判、医疗、网络安全、竞拍等等。&lt;/span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在，人机德州扑克大战已经进入中场阶段，卡耐基梅隆大学（CMU）的人工智能程序「Libratus」面对四位世界级职业选手，处于大幅领先位置。截止第 12 天，Libratus 在已经结束的 49,240 局对决中已经获得了价值 459,154 美元的筹码。对此，参与对决的职业选手 Jimmy Chou 表示，他和其他牌手此前完全低估了 Libratus 的能力，现在他们正面临艰难的挑战。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「这个人工智能程序每天都在进步，」Chou 说道。「在牌桌上，我们就像在面对加强版的自己。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在为期 20 天的比赛里，四位德州扑克 1 对 1 顶尖高手将共与电脑进行 120,000 局无限制德州扑克对决。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然职业玩家为了人类的荣耀而战（也为了赢取 20 万美元奖金），但卡耐基梅隆大学的研究人员希望它们的计算机项目通过与世界上最顶级玩家的比赛，为人工智能建立新基准。Libratus 由 CMU 的计算机科学教授 Tumas Sandholm 和他的博士生 Noam Brown 建立。除了进行德州扑克比赛，Libratus 也可被用于进行商业谈判、设立军事策略、或为医疗制定流程等所有这些基于完美信息进行复杂决策的活动。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2015 年，在首次 Brains Vs. AI 的比赛中，4 位职业玩家与名为 Claudico 的人工智能进行了比赛。但 Sandholm 说随着比赛的进行，他认为 Libratus 的机会非常大，「算法的表现非常棒。算法在应对策略上做的越来越好，在驱动策略上也越来越好，在进行中的策略改进上也做的很好。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Chou 说他和其他专家每天都会分享笔记和想法，寻找他们也许可以利用的弱点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「在比赛开始的前一两天，我们看起来有很大的希望。」Chou 说，「但每当我们找到计算机的一个弱点，它就会向我们学习，第二天这个弱点就消失了。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种每天都会发生的变化出乎了人们的意料，Sandholm 说。每天晚上扑克比赛结束后，匹兹堡超级计算中心（Pittsburgh Supercomputing Center）的 Bridges 超级计算机都会执行能够提升该人工智能的策略能力的计算。自比赛开始以来，该中心已经为该扑克竞标赛分配了 Bridges 的更多计算节点。该比赛每天早上 11 点开始，下午 8 点结束。观众也可以在现场观看这场比赛，就在 Rivers 赌场的 Poker Room。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;感兴趣的场外观众也可以查看网络直播&lt;/span&gt;&lt;span&gt;：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://www.riverscasino.com/pittsburgh/BrainsVsAI&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Brain vs. AI 比赛得到了 GreatPoint Ventures、Avenue4Analytics、TNG Technology Consulting GmbH、Artificial Intelligence 杂志、英特尔和 Optimized Markets, Inc. 的赞助。该比赛由卡耐基梅隆计算机科学学院和 Rivers Casino 赌场合作举办，并且得到了匹兹堡超级计算中心（PSC）通过 XSEDE 的同行评议。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 23 Jan 2017 12:33:02 +0800</pubDate>
    </item>
  </channel>
</rss>
