<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>机器之心独家专访：首度揭秘地平线语音战略与研究</title>
      <link>http://www.iwgc.cn/link/4359143</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;作者：李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从创立之初，地平线的愿景就是为包括智能家电、服务机器人、自动驾驶汽车在内的众多设备装上「大脑」，让它们具有从感知、交互、理解到决策的智能。人机之间的自然交互一直是人工智能领域的一个美好愿景，而语音是人机交互中最重要的手段之一。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然过去的一年中，我们听到更多的是地平线关于图像、芯片方面的研究，但据机器之心了解，地平线在创立之初（2015 年）就拥有了一支十分强大的语音团队，很早就在进行语音方面的研究，积累起独特的技术优势。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在近日，机器之心对地平线联合创始人、算法副总裁黄畅博士以及首席语音算法工程师牛建伟进行了专访，从公司的整体战略、语音技术两个角度揭开地平线语音的神秘面纱。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8vVyKicyjQ1yA6SicZOZvAA1jDtT9IOuaCq6lXGQicTL1kaXh6oa8vrVDsZhMMPcB5zPrROWyXStjhg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;黄畅博士，地平线机器人技术联合创始人、算法副总裁。深度学习专家，前百度主任架构师 ( T10 )。长期从事计算机视觉、机器学习、模式识别和信息检索方面的研究，作为相关学术界和工业界的知名专家，发表的论文被引用超过 3350 次，拥有多项国际专利。他开发的人脸检测技术，创造了世界上首次计算机视觉技术被大规模应用的成功范例，占领 80% 数码相机市场，并且被苹果 iPhoto 等诸多图像管理软件所采用。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibUP7CVr6GmhKQCDxRNzfzZh6OLxla2Wy4dmeIojEA5zAse75j3PTyY7clMDDNzicut3ldf9vArbfw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;牛建伟，地平线机器人技术首席语音算法工程师、语音识别团队负责人。牛建伟毕业于西北工业大学语音识别专业。曾任百度语音技术部资深工程师，在百度期间研发了国内第一个采用深度学习技术的大规模商用语音识别系统，并建立了一套国内领先的离线语音识别系统。牛建伟 2015 年加入地平线后，主导搭建了地平线的语音识别系统。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;地平线的语音战略&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：请黄畅博士介绍一下地平线在语音方面所做的工作？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;黄畅&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：请容许我首先介绍一下我在语音方面的同事牛建伟。牛建伟在加入地平线之前就职于百度语音技术部，是国内语音行业中最早一批接触并运用深度学习算法的人，至今从事语音方面的研发工作已经 7 年有余。事实上，地平线从创立伊始就开始语音技术的研发，原因很简单——万物智能意味着人机交互需要变得更加自然，而语音正是其中最重要的手段之一。在家居场景中，各种智能终端上的语音技术与手机上的相比，会复杂很多，具体表现为：语音的获取从近场变为远场、对交互响应时间的要求更为苛刻、需要对接的服务种类更加繁杂。这些特点决定了智能终端不能简单沿用手机上的语音技术架构。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了更好地处理远场语音问题，我们开展了语音信号处理（包括麦克风阵列）相关的算法和硬件研发；为了降低交互响应时间，我们采用了云端+嵌入式的语音识别架构；在嵌入式端，受限于计算资源，我们仅仅运行信号处理、唤醒、命令词和小规模通用语音识别模型，以保证低延时的交互响应以及网络条件不好情况下的用户体验；而在云端我们可以采用更大规模的声学模型、更复杂的解码器和语言模型，在网络条件良好的情况下确保更好的用户体验；最终，通过语义理解、知识库和对话系统，做出决策并对智能设备进行有效的控制，将用户和广泛的服务对接起来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：现在的语音团队大约发展到了多少人？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;黄畅&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：除了北京，我们还在南京设立了语音研发中心，整个团队加起来正式员工有 20 多人。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：国内也有一批语音方面的人工智能创业公司，比如思必驰、云知声等，我们和他们比起来有什么不同？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;黄畅&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：我们的角度是不一样的。首先据我所知，他们还是非常偏重云端的。地平线的语音则一开始就强调云端+嵌入式。语音信号处理、唤醒、命令词以及语音小模型放在嵌入式端，以保证实时性和网络不佳条件下的必要功能，而将语音大模型和语义理解放在云端，以提供更佳的性能并能对接服务，这种云端+嵌入式端的整体方案，可以提供更好的用户体验。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们注重的是语音全自然交互的解决方案，也就是前端语音信号处理与后端语音识别、语义理解相结合。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;	&lt;/p&gt;&lt;p&gt;&lt;span&gt;语音信号处理、语音识别、语义理解这三个环节组成了一个完整的解决方案，尤其需要注意的是前端语音信号处理，它发挥了很重要的作用。举个简单例子，在语音识别环节很重要的就是对数据进行扰动、加噪。那么加噪怎么加？加多少？这其实跟音频信号处理关系是非常大的。如果只专注于语音识别这件事情而不做音频前端的信号处理、优化，就会导致在具体产品上出现性能不好，或者成本过高等问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，我们在软硬件配合方面做了大量工作。硬件体现在两方面，一方面是在前端信号处理上的麦克风阵列，另一方面是在中间的语音识别，尤其在嵌入式的语音识别，需要我们设计专用的、针对深度学习优化的计算架构芯片。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以我们认为语音交互这件事情，首先是云端+嵌入式；其次是语音信号处理、语音识别、语义理解三个环节都要做；最后，你要软硬结合。这三个维度缺一不可。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：地平线之前推出的雨果平台、安徒生平台上面使用到的语音交互解决方案也都是我们自己的？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;黄畅&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：雨果 1.0 平台是一个基于 FPGA 的平台，它主要面对的是汽车市场。安徒生平台面向的是智能家居。现阶段，车载语音暂时还没有放在我们的工作范畴之内，我们专注的是智能家居的语音应用。所以说我们的语音目前主要是在安徒生平台上的应用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这其实也反映了另外一个问题。表面上看车载语音和家居语音都是语音应用，但实际上因为场景不同，可以接受的功耗和成本不一样，这导致你所采用的技术方法的差距非常大。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以在研究方面我们要把信号处理、语音识别和语义理解三个环节都做。但在其他的维度上，比如在具体应用场景中，我们要有所收敛。因为毕竟我们不可能像一个大公司一样，投入非常多的资源在所有的维度上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：地平线之前一直在做图像识别方面的研究，也有语音识别方面的研究。如果两者部署到同一个平台，比如说同一个机器人平台上，它们是相互促进？还是彼此独立的存在？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;黄畅&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：这恰恰是我们努力在做的。表面上看语音和图像好像是是两个不同的东西，但实际在交互的过程中我们追求的是一种多模态的交互。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;举个简单的例子，我们通常说语音是比较自然的交互，但是在有些场景中你会发现手势、人脸这些来自于图像的信号也能够很好的辅助你进行交互。尤其是在复杂的场景中，比如说开 party，你会发现在嘈杂的声音中把语音分离出来是很难的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;针对这种复杂场景中的问题，虽然我们有增强的方法，但是你一开始甚至不知道应该往哪个方向进行增强。所以我们可以结合一些来自于图像的 indicator，比如说手势识别，比如说类似前段时间 DeepMind 做的唇语识别。它（指 DeepMind 的 LipNet）是个很有意思的应用，也是在做语音识别，但它不是靠语音信号而是靠图像信号，而且准确率十分惊人。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这就说明一个很有趣的问题：如何让机器所感知的信息，像人机交互一样，也是一种多模的交互？从逻辑上来讲，是把语音和图像的交互结合起来。从执行上来讲，你必须把两个东西放在一套系统里面，非常完美地同时运行这两个东西。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;再往深处去挖，图像和语音发展到现在，在计算模式上已经有了非常大的相似性，这使得我们可以设计一套对这两种问题通用的计算架构，这也是我们之所以非常看重专用的芯片架构设计的原因。因为我们相信用一套专门设计的新架构，能够做好包括语音、图像、决策在内的很多人工智能问题的运算。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：把语音技术部署到产品上面接下来有什么计划吗？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;黄畅：前期主要是在智能家居方面，比如说跟科沃斯的合作，将语音识别技术用于智能扫地机器人上。此外我们也在跟其它家电厂商研发基于语音识别的技术应用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地平线认为 2017 年是语音识别广泛应用的关键年。所以我们在这一年会非常重视整个语音的技术研发和产品推广，包括市场拓展，这是今年公司最重要的方向之一。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;地平线的语音技术&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：两位能从技术角度讲解下地平线的语音研究吗？模型与算法？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;牛建伟&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：前面也讲到了，地平线在很多方面都有一些工作：音频信号处理、语音识别、语义理解、语音合成等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;具体到其中的「语音识别」，它包括两大模型：在语言模型上我们现在用的是 n-gram 结合 RNN 的模型；识别模型在嵌入式端主要用 CNN 和 DNN 模型，服务器上采用 CLDNN 模型结构。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们在算法上做的提升包括：一个是前端音频信号处理，我们正在做一套完整的前端模块或者说是算法套件。有了前端的提升之后，我们的识别系统对强噪声干扰、人声干扰就会有更好的鲁棒性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一个提升是针对语音识别场景的打磨。因为扫地机器人或者是空调，都有一些本体噪声。我们需要模型能够适应这种本体噪声。此外，就是一些建模方法、模型结构上的改变或者改进，比如 Deep CNN 模型、LSTM 模型以及进一步引入 CTC 准则。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8vVyKicyjQ1yA6SicZOZvAA1NPeE3iaqbXBGeocLoy0m5DvBVvAoW2LKFGv5BIYiaCvtNkdsMtPZDypw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;span&gt;刚才提到的 LSTM 模型、CLDNN 模型，在一些数据集上我们都已经能够验证效果，并将逐步将算法移植到我们自己的芯片上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;语音合成上，我们现在用的是基于 BLSTM 模型的一套参数合成系统，现在也在追踪 WaveNet。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;黄畅&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：现在很多学术界或者业界的新发展，基本上都是基于大规模的服务器、GPU 去完成的。我们在跟踪这些最新的方法同时，非常关注哪些更加适合部署在嵌入式平台，部署在低成本、低功耗的通用处理器以及我们设计的专用芯片架构上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：这整套方法的准确率大约在多少呢？有没有测试出一个结果？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;牛建伟&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：根据我们的内部评测结果，在 1000 小时的数据上，CLDNN+CTC 模型相比于之前公司的 DCNN 模型性能大概提升了 15%～20%。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：在语音合成方面刚才你提到的追踪 WaveNet，能补充说明一下吗？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;牛建伟&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：我们现在已有的是一个相对来说比较主流的技术框架。文本处理前端就是利用 NLP 相关算法、资源进行文本的规整，提取词法和语法信息。后端主要集中在参数合成，这一环节比较容易放到嵌入式的端上面进行，因为它的资源量比较小。这样的话 TTS 系统只需要占用几十 MB 的空间，对计算的要求也可控。后端我们用的就是一个相对主流的 BLSTM 模型，这基本上也是各家都在用的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;至于 WaveNet，它相对来说提高了合成语音的自然度，还有舒适度，但是它存在一个问题就是计算量很大。语音是 16K 采样，一秒钟它就要预测 16000 次。当然可以再做加速，但现在加速的效果还没有那么好，现在基本上还是 100 倍的实时率，就是合成一秒钟语音还需要 100 多秒的计算时间。这没办法直接用到产品上面，所以我们还是在追踪 WaveNet 的阶段。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：吴恩达今年在 NIPS 2016 上提到了端到端学习在语音识别上的应用，我们在这方面有没有深入的研究呢？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;牛建伟&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：吴恩达的「端到端」，在英文识别中是指从一个频率的特征直接建模到音素这一级，中文指 从一个频率特征建模到拼音声母跟韵母这一级。从目前主流的实践上看，这其实就是一个 LSTM 和它的变形，然后加上一个 CTC 目标函数。之所以认为是一个端到端，是因为它省略了以前语音识别三音素表述的概念。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;再进一步发展的话就不限于一定是频率的特征，可能就是从原始的波形一直到因素或声韵母，这相当于是更宽的端到端。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;黄畅&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：其实端到端不是一个新的概念，而且端到端也是相对而言的。你现在听到的端到端是相对于过去的工作而言，过去工作是什么呢？是把输入到输出的中间部分分成两三个不同的阶段，然后分别去做优化。现在是把这两三个阶段合在一起，直接做输入到输出的端到端优化。但如果把视线放到端到端之外，其实输入前还有信号处理、特征抽取，输出后还有解码、语言模型、语义理解。所以你现在所看到的端到端如果放到我前面提过的序列中还只是整个语音识别链条中的很小一部分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;端到端的思想其实来源于深度学习的一个核心思想，这只是深度学习方法应用于问题中不断的延展。理想情况就是提供一个或者多个麦克风，不做信号处理就直接读取录音内容，然后通过深度学习模型最终直接输出意义。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：如果要促进语音识别更加地实用，还要做些什么样的工作呢？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;黄畅&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：现在看来语音识别问题好像已经基本解决了，但这仅限于近距离安静场景中和发音相对比较规范情况下。就好比人脸识别，很多人觉得好像是个已解决问题，但仍只是在限定条件下。但当你实际应用的时候，会出现各种问题。典型的问题就是：第一个，远场情况下，混响、噪声干扰怎么解决？第二个，语义是否能够正确理解？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们以前讨论过，如果只是做一个通用语音识别，可以把字打出来。本质上来讲，它只能够替代输入法，作用是十分有限的。如果要把它用在交互上，形成一个闭环的话，它必须能够理解人的语义。所以只在中间这段语音识别做好还不够，真正应用中要形成一个闭环，前面的语音信号处理、后面语义理解都要做得好。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以我们不应该单纯的、狭义的说语音识别问题已经解决了。广义的语音识别应该是从声音信号开始，到最终的语义。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：那我们在语义理解方面做了哪些工作？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;牛建伟&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：我们现在主要还是针对于对话或者是交互系统来做，包括我们在用强化学习做对话的一些生成，还有对话状态的管理。同时我们也做一些 NLP 方面的工作，用 Deep CNN 或者 LSTM 做一些名词的标注，或者是实体的识别，另外还有些语言模型方面的工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;黄畅&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：泛泛的那种对话、聊天式的机器人意义不大，我们关注的对话是针对某个特定的场景、应用或者类型的知识，使它成为有独特性的，有「知识背景」的对话。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：地平线在语音研究上的数据能做一下介绍吗？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;黄畅&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：关于数据，其实有些新的趋势不仅是在语音上，而在各种各样的技术性问题中，比如如何做迁移学习（transfer learning）？在一个有大规模数据的场景中训练出模型，在另外一个相似、相仿的场景中，怎么把这个大规模数据场景中训练出的模型迁移到小规模数据场景中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一方面是生成型模型，尤其是对抗式生成式模型，它提出了一种非常新的概念，就是重新设定学习的范式（paradigm）和框架，重新看待学习这件事情。它一个很重要的产出就是，利用生成式模型帮助你产生更多的、特定属性的数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;再往前推，其实 RL（强化学习）是非常有价值，尤其是在交互的过程中。对语义理解互动这件事情，RL 天生就是为这种交互的模式设计的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：在语音识别算法方面，还可以朝着哪些方面改进？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;牛建伟&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：主要有三方面的改进。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一，降低数据量的需求。即我们通过一些方式生成数据，或者学习一些数据共有的特征或属性，以此降低数据量需求。比如说为了达到一个比较高的识别率，现在可能需要 2 万小时的数据量，以后只需要 2000 小时。举个例子，DNN 取代以前的 GMM 模型的时候，DNN1000 小时的性能其实已经超过了在 3000 小时训练数据上训练的 GMM 的性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二，更好的语音信号的特征表示。因为现在语音识别最大的一个问题是有比较大的干扰之后，识别效果就不太好。其实人在 0dB 或者更低信噪比的情况下（噪音跟声音的能量是一致的时候），还能够识别，但机器就没办法处理的很好。说明我们现有的特征表示的鲁棒性还不够好，距离人还有很大差距。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;针对于此，我们可以对人耳听觉进行更精确的数字描述。或设计现在已有的神经网络结构，更好地提取出语音信号里面对识别来说作用更大的特征。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第三，解码。我们现在一直在提端到端，但其实一直没有把解码包含进来。语音识别最终做的还是把固定特征表示成一个更高维的信息，还是时间序列上的表示，需要解码的过程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;解码是除了模型外计算量比较大的一块。但其实解码也能通过模型表示出来。也就是通过模型的方式把高维的时序信息结合起来，最终直接就预测出一句话，那这样就相当于在时序上的端到端的识别。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果能做到这样，后面优化识别模型的过程就变得更容易了。因为虽然解码还是工程化的东西，但它会比较明显的影响到识别结果。如果我能把它放到机器学习的框架里面去优化，这样相当于整体的优化。有可能性能会更好，解码的效率也会更高。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：不久之前 Facebook 提出了新的语言模型方法 Gated Convolutional Network，相比于 LSTM 取得了一定进展。对此研究有何看法？这个研究是否有很大的意义？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;牛建伟&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：Gated CNN 跟 9 月份的 WaveNet 其实有点类似，因为它相当于是把显示的那种循环结构改了一下。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;LSTM 的提出从想法上还是比较简单：因为这是一个时序的问题，需要历史指导来做下一步的预测。但现在我们来看，它存在一些问题：优化算法没有那么稳定。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;LSTM 之前是 Simple RNN，为什么 LSTM 比 RNN 好？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从理论上来说，两者的表达的能力应该是一样的。通过调整结构（引入门），来适应现有的一些学习算法，让它的性能变得比较好。但同时也说明现有的优化算法是有些问题的，包括它的收敛性、稳定性上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在的一个趋势是利用 CNN 结构的组合来替代 RNN 模型，优化的时候就可以用一个 SGD（随机梯度下降）或者类似 SGD 的优化算法，它的稳定性相对来说会高一些，不会存在很明显的梯度爆炸问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8vVyKicyjQ1yA6SicZOZvAA1pY6pdaRTBDqzuIF62cZmumehdDjYH8XvFKVx1N7vvcN5TUulvIROJg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外，还因为卷积网络用 CNN 这种结构直观上比较合理一些。比如说三个单词，我先把它们变成一个连续域表示，就像它们论文中的一张图就是把 word graphic 转到连续域场（如上图）。然后把连续域的特征通过卷积，就看前三个，提出一个特征然后一层层加上去，之后再做一个预测。预测的词出来之后，再放到输入上面，就这样一层一层过。其实它也是类似循环的结构，但这种结构依赖的历史相对就比较明确了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;LSTM 其实是一个隐含的。你可以说它学到了历史，因为它有一个保存信息的 cell，但到底它学了多长的历史是未知的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;至于这个研究，模型的话我觉得可能意义没那么大。我个人认为，如果能在优化算法上有更好的改进，普通的模型结构可能也能取得这样的效果。但现在优化算法上突破性的改进，好像还不多。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;黄畅&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：我补充一点。关于 LSTM，不管你是单向的、双向的、摞一起的、不摞一起的，其实都有一个问题：信息传导的约束很强。换句话说，不管是做前向预测还是后向 BP（反向传播），一个信息从左边到右边，或者从开始到结束，都要经过很长的路径。而且在整个过程中，会有很多非线性的变化，尤其是 LSTM 这种典型的、很容易进入自我限制状态的模型。经过很多次这样的事情，就导致整个优化变得异常困难。这个结构天生就使得优化变得非常困难。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是 LSTM 的弊病，它的结构设计有很大限制性。你可以类比一些其他结构，比如 ResNet，它通过建立 free-way 的方式，人为地架了很多 short-pass（短路径），使得本来在网络上距离很远的两个单元之间建立一些高速的快速通道。直观的理解就是可以让它们之间的信息沟通更加顺畅，减轻我前面说的那个问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;更进一步，你会发现在语音识别中有人用完整的 CNN 替代 LSTM，包括讯飞、微软、百度。刚开始的时候 CNN 用得很浅，只是作为基本的局部表达，后来发现可以用 CNN 不断堆积，而且堆的很有技巧。在计算量不显著增加的情况下，这样就可以用 CNN 覆盖很大的语境。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;就是说优化算法本身也许没有很好的进步，但是通过网络结构的设计可以规避目前主要基于 SGD 的优化算法难以解决的 LSTM 问题，直接构造一个更适合目前优化算法去优化的网络结构。所以本质上很难说哪个结构更好，你只能说这个结构更适合现在主流的这种优化方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其实论文出来时我稍微看了一点，它本质上好像和 attention model 很像。attention model 的概念是不管语境是怎么传过来的，总是有选择的看所有东西，做决策（比如生成一个词）的时候有选择的去做。这时候会产生一个 attention mask，这可以理解成一个 gate，封住一些不想看的东西，保留想看的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个在图像和 NLP 里面已经得到很好的验证。NLP、语音、图像其实都是相通的，你会发现很多思想、结构、设计理念会越来越相似。这也给了我们信心，让我们可以实现语音图像识别一体化交互，用一套统一的专用架构去做解决各种各样的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 16 Jan 2017 12:57:41 +0800</pubDate>
    </item>
    <item>
      <title>深度 | Yann LeCun最新演讲再谈预测学习：记忆网络和对抗训练是很有前景的方向</title>
      <link>http://www.iwgc.cn/link/4359144</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;作者：&lt;/span&gt;&lt;span&gt;叶兀&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;当地时间 2017 年 1 月 13 日，Yann LeCun 在爱丁堡大学做了一个题为《预测学习（Predictive Learning）》的演讲。在这篇文章中，我很高兴能向大家分享我在这个演讲中的收获。虽然我并没有完全理解他在讲座中提到的所有概念，但我会尽我所能分享我了解到的知识。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibUP7CVr6GmhKQCDxRNzfzZ881XUZhicUNbAYR59IQxpq9rjs5XbZZXA6PLQByAF4coO1CvUl9CXBQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能在过去几年的快速进展很大程度上可归功于深度学习和神经网络算法的进步，当然还有大规模数据集和高性能 GPU 的可用性。我们现在已经具有准确度可媲美人类的图像识别系统了，而这也引发了一些领域的革命性发展，其中包括信息存取（information access）、自动运输系统（autonomous transportation）和医学影像分析（medical image analysis）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是所有这些系统目前都在使用监督学习，即使用人工标记的数据作为机器的输入。所以接下来几年内的挑战就是让机器能从原始、未标记的数据（如视频或文本）中进行学习，这就是人们称为预测学习或无监督学习的方法。智能系统如今并不能掌握「常识」，而在人类和动物的世界里，常识是通过观察世界、参与世界和理解世界的物理约束而获得的。Yann LeCun 认为机器学习世界的预测模型的能力将会是人工智能的重大进步。然而主要的难点在于世界只是部分可预测的。接下来将会介绍无监督学习的一种一般形式，其能够应对部分可预测的世界。这种形式连接了许多众所周知的无监督学习方法以及一些新的和令人兴奋的方法（如对抗训练）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Yann LeCun 简介&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Yann LeCun 是 Facebook 的人工智能研究主管，纽约大学的 Silver 教授，隶属于纽约大学数据科学中心、Courant 数学科学研究所、神经科学中心和电气与计算机工程系。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Yann LeCun 在 1983 年在巴黎 ESIEE 获得电气工程学位，1987 年在 Université P&amp;amp;M Curie 获得计算机科学博士学位。在完成了多伦多大学的博士后研究之后，他在 1988 年加入了 AT&amp;amp;T 贝尔实验室（AT&amp;amp;T Bell Laboratories /Holmdel, NJ），后来在 1996 年成为 AT&amp;amp;T Labs-Research 的图像处理研究部门主管。2003 年，他加入纽约大学获得教授任职，并在 NEC 研究所（普林斯顿）呆过短暂一段时间。2012 年他成为纽约大学数据科学中心的创办主任。2013 年末，他成为了 Facebook 的人工智能研究中心（FAIR）负责人，并仍保持在 NYU 中兼职教学。从 2015 到 2016 年，Yann LeCun 还是法兰西学院的访问学者。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;LeCun 目前感兴趣的研究领域包括人工智能、机器学习、计算机感知、机器人和计算神经科学。他最出名的是对深度学习和神经网络的贡献，特别是广泛用于计算机视觉和语音识别应用的卷积神经网络模型。他在这些主题以及手写字体识别、图像压缩和人工智能硬件等主题上发表过 190 多份论文。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;LeCun 是 ICLR 的发起人和常任联合主席（general co-chair），并且曾在多个编辑委员会和会议组织委员会任职。他是加拿大高级研究所（Canadian Institute for Advanced Research）机器与大脑学习（Learning in Machines and Brains）项目的联合主席。他同样是 IPAM 和 ICERM 的理事会成员。他曾是许多初创公司的顾问，并是 Elements Inc 和 Museami 的联合创始人。LeCun 位列新泽西州的发明家名人堂，并获得 2014 年 IEEE 神经网络先锋奖（Neural Network Pioneer Award）、2015 年 IEEE PAMI 杰出研究奖、2016 年 Lovie 终身成就奖和来自墨西哥 IPN 的名誉博士学位。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;概述&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这篇演讲中，LeCun 一开始介绍了最近人工智能的发展情况，然后谈到了人工智能面临的难题。接着，他深入论述了预测性学习以及 Goodfellow 在 2014 年提出的新概念：生成对抗性网络。除此之外，「常识」也是这篇演讲中多次提及的重要概念，我稍后会做解释。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这篇演讲的主题分为 4 个部分：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;人工智能当前发展情况概览&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;人工智能所面临的难题&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;预测学习（无监督学习）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;对抗训练&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;监督学习&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;实际上，去年取得的所有成功都是基于监督学习。我们在大量样本上（比如桌子、椅子、狗、汽车和人）训练机器，不过，机器可以识别之前没有见过的桌子、椅子等吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibUP7CVr6GmhKQCDxRNzfzZRRXSD2CqWibOdqXtyAPicibiaiaGb8oicquSMy03cJ4aGTRRdpBfCOvBOssA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibUP7CVr6GmhKQCDxRNzfzZDXwq3ahvfGYKoCRQwlruoibNg0MPm08yiaZPbWYHj8lTRGZM2NEIPb0w/0?wx_fmt=png"/&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibUP7CVr6GmhKQCDxRNzfzZickN7Iibftuu3XzYWTP2HAVy3iaAnaF2GcnFlgxjvF3RXvxYqs40r8qVQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这两张幻灯片讲的是训练深度神经网络的过程，所有灰色图片是每一层提取的特征。当然，如果你觉得这些幻灯片内容很难理解，可以首先学习卷积神经网络以及反向传播算法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他也介绍了 深度卷积网络的架构：VGG、GoogleNet 和 ResNet&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibUP7CVr6GmhKQCDxRNzfzZHv8qTDsIZJsMXgsO70icWzeJJiaicashEJVsXeA4YibcG11vYthO018Zfg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;接着，他介绍了一些驾驶方面的研究——使用卷积网络对行驶中的汽车进行图像标注和语义分割。另外，他也给出了一些图像识别的例子。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibUP7CVr6GmhKQCDxRNzfzZia27XdQiaZZaWIB74tOz7GoPdQFDFXlQWZZ4eQ80BnZJ59RuoPRv5ZHQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这一过程中，我们使用了计算机视觉和卷积网络方面的知识。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;Obstacles to Progress in AI [33:50]&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;人工智能发展中所面临的难题&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibUP7CVr6GmhKQCDxRNzfzZkBbw2j2sugPRjyFLHB6a2WIs3mNbRkh9KD1T5lj4s4ACkeFO10XdTA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;上面这张幻灯片告诉我们，机器需要通过观察和行动来获取某种程度的常识，这样才能准确预测、规划以及关注重要事项。记忆相关事件并预测如何行动才能得到我们想要的世界的状态。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;智能&amp;amp;常识=感知+预测模型+记忆+推理&amp;amp;规划&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;常识是一种填空能力&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;从部分信息推出世界状态&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;从过去和现在推断未来&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;从当前状态推断过去事件&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;补充视觉盲点的视野内容&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;补充被遮挡的图像&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;补充文本、语音缺失部分&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;预测行动结果&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;预测导致结果的行动序列&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人类有常识。比如，看看下面这幅图片&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibUP7CVr6GmhKQCDxRNzfzZb9pP91xEM0qoefjia4VJLpETXHd4Tx5CAd4tIImyk2rDOqEl93WsSgA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们知道这个人拿起包并要离开房间。我们之所以有常识是因为我们知道世界运行原理，不过，机器怎么学会常识呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从提供的任何信息预测过去、现在以及未来的任何一部分。这就是预测学习（predictive learning）。不过，这是很多人对无监督学习（unsupervised learning）的定义。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;无监督学习/预测学习的必要性&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;训练大型学习机器所需的样本数量（无论为了完成何种任务）取决于我们需要预测的信息量大小。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你需要机器回答的问题越多，样本数量就要越大。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果想用很多参数训练一个非常复杂的系统，就需要海量训练样本让系统预测很多内容&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「大脑有 10 的 14 次方个突触，我们却只能活大概 10 的 9 次方秒。因此我们的参数比我们所获得的数据会多的多。这一事实激发了这一思想：既然感知输入（包括生理上的本体感受）是我们每秒获取 10^5 维度约束（10^5 dimensions of constraint）的唯一地方，那么，就必须进行大量的无监督学习。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;预测人类提供的标签，一个价值函数（value function）是不够的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然后 LeCun 举了个例子，解释了不同的学习算法进行预测需要多少信息。如下幻灯片所示。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随后，他使用两篇预测视频帧的论文阐述了强化学习系统，这是 Facebook 赢得 VizDoom 2016 比赛的研究结果。[Wu &amp;amp; Tian, submitted to ICLR 2017] 和 Plug: TorchCraft: interface between Torch and StarCraft [Usunier, Synnaeve, Lin, Chintala, submitted to ICLR 2017].&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他在这里还提到了人工智能的成功案例 AlphaGo，不过很难将其用于真实世界。因为围棋的世界一步步的，我们的学习系统可以通过许多训练样本获得经验。但真实的世界是存在许多问题的，我们永远不能加速真实世界来进行训练模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibUP7CVr6GmhKQCDxRNzfzZkbmWQA9dyH8oQjP7LwSXkMI4iaUkbMYJJKH8lyS0N8mnYSqRC9RkCSw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;智能系统的架构&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这一部分是关于人工智能系统架构的，我认为这对我们很重要，所以我把四张 PPT 贴到这里。但是，除了 PPT 上的内容，Yann 并没有展开太多。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibUP7CVr6GmhKQCDxRNzfzZiaSx2ficHLLb2xPz7TSBWt1Kaf4ou1a86WMQJKGfFqkT0xQOxDJn6ADQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;上述理论非常类似于下述的控制论。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibUP7CVr6GmhKQCDxRNzfzZjj2Owywm1df7Ht7NHCCl1uZd7KeLluE6J3csAa55Yn3UtfjthLbelQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面的这个幻灯片简单但非常清楚地勾勒了人工智能的架构，如果读者了解模式识别的基本过程，你也能理解这个架构。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibUP7CVr6GmhKQCDxRNzfzZqWmG3uRM0LBH8wLJvibGiakJvswPHKjWIHoRAg66SJlcN50yiaELenhNw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里的关键词是模拟世界和目标函数（objective function）。因此，你要懂它们的意思。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibUP7CVr6GmhKQCDxRNzfzZPydYrPTduyfgvrBde1iazibDojqg4oarNxxUsv0EndrvMpEMjXliamNQg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;学习关于世界的预测性正演模型&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Yann 介绍了一个预测落体轨迹的模型，其使用了非真实的游戏引擎，它与真实世界的真实物体略微不同，因此，也只是在游戏引擎中有效。后来，他讨论了真实世界中的真实物体的情况。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibUP7CVr6GmhKQCDxRNzfzZuoOxffKoo3L9421v4rc6QdicUIdnStVEE7OvPrQiafh3W2biaCwibUiaoAw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibUP7CVr6GmhKQCDxRNzfzZFLyoJLDuTU8skP9EStkfc3UaZ7sLDur8IEVuqWw94uFXJWdG08wQcg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;从文本中进行推断：实体 RNN&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管监督式 ConvNet 已经取得了重大的进展，我们仍需要记忆增强网络赋予机器进行推论的能力。Yann 用 PPT 的形式帮助我们理解记忆\堆栈增强循环网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;使用记忆模块增强神经网络&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;循环网络不能进行长期记忆&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;皮层记忆只能持续 20 秒&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;神经网络需要一个「海马体」（一个单独的记忆模块）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;LSTM [Hochreiter 1997]，暂存器&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Memory networks [Weston et 2014] (FAIR)，联合存储器&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;堆栈增强循环神经网络 [Joulin &amp;amp; Mikolov 2014] (FAIR)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;神经图灵机 [Graves 2014]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;可微分神经计算机 [Graves 2016]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibUP7CVr6GmhKQCDxRNzfzZ7GSicGEZHwVlPs7iawl2wIkPdM8grtibOUBt7d1EXniakvBWZ6OhC3m6XA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibUP7CVr6GmhKQCDxRNzfzZqla2e2XIkK4MibVD9Bwwic0aF2Qqcj65AVLLPYl4PIzia2V0GTryCFicfA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此外，他也给出了一个例子演示 MemNN 的结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibUP7CVr6GmhKQCDxRNzfzZNX7Sr3t6XClKjDKicdglfxUA9kuBskerkdrhG7ArkuIrMQjhLmvQBFQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibUP7CVr6GmhKQCDxRNzfzZiaLCpuJva8cJlK5LuEZb7G1qoEThDzj3ndnTm1eCuIpv5QGcAOcQhwQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;EntNet 是第一个解决所有 20 个 bAbi 任务的模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;无监督学习&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;基于能量的无监督学习&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibUP7CVr6GmhKQCDxRNzfzZjPoZpxVia4ic8R2wDZHIdGRuFB0c0RJPKmGhEViaQwBKfyqx2k9qmyBgA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibUP7CVr6GmhKQCDxRNzfzZUGHoOJg5xjowcWKETkabePx4iaGwkIoqtYZn7xxykBp6UZhUs1glaicA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibUP7CVr6GmhKQCDxRNzfzZfoMqqh6ktEfVXtohecebDaDKg0cicicavQM6K8iaP0rGia6Ta2yJ6CHwwA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibUP7CVr6GmhKQCDxRNzfzZeRtM2xibNADgN7AIr4bWzMLSjHEltFVeLWyeIV4ytAa5miaia6jbXZWQQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;塑造能量函数的 7 种策略&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 建立低能量体量（the volume of low energy stuff）不变的机器&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;PCA、K-means、GMM、square ICA&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 数据点能量的下推（push down），其他位置能量都提高（push up)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;最大似然（需要易操作的配分函数）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 数据点能量的下推（push down），在选择出的点上进行提高&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;contrastive divergence、Ratio Matching、Noise Contrastive Estimation、Minimum Probability Flow&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4. 围绕数据点最小化梯度，最大化曲率（curvature）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;score matching&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;5. 训练一个动态系统，以便于动态进入 manifold&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;降噪自编码器&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;6. 使用正则化进行限制有低能量的空间体量&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Sparse coding、sparse auto-encoder、PSD&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;7. 如果 E(Y) = ||Y - G(Y)||^2, 尽可能的使得 G(Y) 不变&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Contracting auto-encoder, saturating auto-encoder&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;对抗训练&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然后，他谈到了 2014 年由 Ian Goodfellow 提出的对抗训练（GAN），这是改进机器预测能力的一种方式。GAN 包括一个生成器、一个判别器，它们同时进行学习。你可以通过阅读引用 [5],、[6] 了解更多。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面是在现实世界进行预测的一个例子。比如图中演示，当你松手时笔倒下可能指向不同的方向。我们如何准确的预测笔的指向？这是一个难题，与学物理的学生多交流会有帮助。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibUP7CVr6GmhKQCDxRNzfzZ4YiattCU4zC09fz3zQZzw7EYbQNPZ3CSgIicxMvDv5VxfGFE99SfZJXg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然后，Yann 给出了一个解决方案，基于能量的无监督学习：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibUP7CVr6GmhKQCDxRNzfzZlsD3rPiaAibE7D8SBmCGZLGdvia96dHNbOovvH9sS4ok5qmD5NVrHyptQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibUP7CVr6GmhKQCDxRNzfzZ4Jw1hZACr43jOyu6MLZhYpC0x16ckkZMs9I5rplWB7C3ugiaMgvy6vw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面我附上了 PPT，有一些关于基于能量的 GAN 的函数：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibUP7CVr6GmhKQCDxRNzfzZQzY4xwADZBVsr7QfnYxAk5tbmOyzOk15Wfpiacu2FED2ayqZmialPRvQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibUP7CVr6GmhKQCDxRNzfzZ6S1eEpXlmmCwlDib6epqHLq1jNOrBYJwbUiaK5QPHzlqXXMGxOkria9pg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;视频预测&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最终，Yann 向我们演示了关于视频预测的有趣例子，使用不带有池化（pooling) 的多尺度 ConvNet。Yann 说他也不知道为什么这里的池化不起作用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibUP7CVr6GmhKQCDxRNzfzZzhxOGqoJcfib1BdicbH5QZHh3yYWBgicLnhAELdrq5AabGGxFHSls6dxQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;我们的大脑是一台「预测机器」。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;我们能否训练机器来预测未来？&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;一些使用「对抗训练」获得的成功。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;但我们离完全的成功还很远。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;总结&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;总而言之，Yann 在演讲中总结了去年人工智能领域的进展，并介绍了监督学习的一些知识点。然后，Yann 聚焦于无监督学习。他认为无监督学习会成为未来的主流，能解决我们的学习系统难以处理的众多问题。我们如今正在面临无监督和预测性前向模型（predictive forward model）的建立，这也可能会是接下来几年的挑战。此外，对抗训练在未来可能会逐渐扮演更重要的角色，而如今的难题是让机器学习「常识」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我个人看来，我也从 Yann 身上获得了一些特别的东西。他非常友好、乐于助人。现场有一个学生问了一个非常耗时间的 问题，他同样给出了解答，这超乎了我的想象。此外，他告诫我们多与其他领域的人交流，比如物理学，这可能帮助我们解决上面提到的预测笔倒下之后指向的问题。最后，我们来了一个合照。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;References&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;[1] Goodfellow, Ian, et al. "Generative adversarial nets." *Advances in Neural Information Processing Systems*. 2014.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;[2] Athans, Michael, and Peter L. Falb. *Optimal control: an introduction to the theory and its applications*. Courier Corporation, 2013.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;[3] https://research.fb.com/projects/babi/_ (https://research.fb.com/projects/babi/)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;[4] https://iot-for-all.com/yann-lecuns-keynote-on-predictive-learning-mixed-reality-as-imagined-by-magic-leap-and-marc-f2adfecf7ab6#.7q1xepw2u_&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;(https://iot-for-all.com/yann-lecuns-keynote-on-predictive-learning-mixed-reality-as-imagined-by-magic-leap-and-marc-f2adfecf7ab6)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;[5] https://arxiv.org/pdf/1511.06434v2.pdf&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;[6] https://tryolabs.com/blog/2016/12/06/major-advancements-deep-learning-2016/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;[7] http://datascience.inf.ed.ac.uk/events/data-science-distinguished-lecture&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心原创，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 16 Jan 2017 12:57:41 +0800</pubDate>
    </item>
    <item>
      <title>资源 | 英特尔开源分布式深度学习库BigDL：支持高性能大数据分析</title>
      <link>http://www.iwgc.cn/link/4359145</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Github&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;近日，英特尔开源了一个运行在 Apache Spark 上的分布式深度学习库 BigDL，其可以利用已有的 Spark 集群来运行深度学习计算，并且还能简化从 Hadoop 的大数据集的数据加载。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;开源地址：https://github.com/intel-analytics/BigDL&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;据介绍，在 Xeon 服务器上的测试表明，BigDL 相比于 Caffe、Torch 或 TensorFlow 等开源框架实现了显著的速度提升。其速度可与主流的 GPU 相媲美，而且 BigDL 也能扩展到多达数十个 Xeon 服务器。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;BigDL 库支持 Spark 1.5、1.6 和 2.0，并且允许将深度学习嵌入到已有的基于 Spark 的程序中。其中包含了将 Spark RDD（Resilient Distributed Datasets，弹性分布式数据集）转换成 BigDL 定义的 Dataset 的方法，并且也可以直接运用到 Spark ML Pipelines 上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了进行模型训练，BigDL 应用了一个同步小批量随机梯度下降（synchronous mini-batch SGD），该过程在跨多个执行器（executor）的单个 Spark 任务中执行。每一个执行器都执行一个多线程引擎并处理一部分微批量数据（micro-batch data）。在当前的版本中，所有的训练和验证数据都会加载到内存（memory）中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;BigDL 是用 Scala 实现的，并且模仿了 Torch。类似于 Torch，它也提供了一个 Tensor 类，其使用了 Intel MKL 库进行计算。Intel MKL 是英特尔的数学核心函数库（Math Kernel Library）的缩写，其中包含了一系列为计算优化过的历程，其中包括 FFT（快速傅立叶变换）和矩阵乘法等等，这些计算在深度学习模型训练中有广泛的应用。另外受到 Torch 的 nn 包（https://github.com/torch/nn）的启发，BigDL 借鉴了 Torch，提出了 Module 的概念，用于表示单个神经网络层、Table 和 Criterion。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;BigDL 还提供了一个 AWS EC2 镜像和一些案例，其中包括：文本分类（使用卷积神经网络）、图像分类、以及将 Torch 或 Caffe 中预训练的模型加载到 Spark 中用于预测计算的方法。目前社区讨论区上大多数用户请求 BigDL 支持 Python，以及开发 MKL-DNN（MKL 的深度学习扩展）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以下是 BigDL GitHub 项目的 README.md 介绍：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;BigDL：在 Apache Spark 上的分布式深度学习&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;BigDL 是什么？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;BigDL 是一个用于 Apache Spark 的分布式深度学习库。使用 BigDL，用户可以像编写标准 Spark 程序一样编写深度学习应用，并且可以直接将其运行在已有的 Spark 或 Hadoop 集群上。BigDL 有哪些优点呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;丰富的深度学习支持。类似 Torch，BigDL 提供了全面的深度学习支持，包括数值计算（通过 Tensor）和高层面的神经网络；此外，用户还可以使用 BigDL 将预训练的 Caffe 或 Torch 模型加载到 Spark 程序中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;极高的性能。为了实现高性能，BigDL 在每一个 Spark 任务中都使用了 Intel MKL 和多线程编程。从而使得 BigDL 在单节点 Xeon（与主流 GPU 媲美）上能够实现比当前开源的 Caffe、Torch 或 TensorFlow 快几个数量级的表现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有效的扩展。BigDL 可以利用 Apache Spark（一种超快的分布式数据处理框架）以及同步 SGD 的有效实现和在 Spark 上的 all-reduce 通信来进行有效地扩展，从而可在「大数据规模」上执行数据分析。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;为什么选择 BigDL？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你满足以下条件，你就应该使用 BigDL 来编写你的深度学习程序：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你想在数据存储（比如以 HDFS、HBase、Hive 等方式）于的同一个大数据（Hadoop/Spark）集群上进行大量数据的分析。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你想为你的大数据（Spark）程序和/或工作流添加深度学习功能（不管是训练还是预测）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你想使用已有的 Hadoop/Spark 集群来运行你的深度学习应用，然后将其动态地共享给其它工作负载（如 ETL、数据仓库、特征工程、经典机器学习、图分析等等）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;如何使用 BigDL？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;要学习如何在 Linux 或 macOS 上安装和编译 BigDL，你可以查看：https://github.com/intel-analytics/BigDL/wiki/Build-Page&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;要学习如何运行 BigDL 程序（作为本地 Java 程序或 Spark 程序），你可以查看：https://github.com/intel-analytics/BigDL/wiki/Getting-Started&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;要在 EC2 上尝试 BigDL，你可以查看：https://github.com/intel-analytics/BigDL/wiki/Running-on-EC2&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;要学习如何使用 BigDL 在几分钟内创建一个实用的神经网络，你可以查看教程：https://github.com/intel-analytics/BigDL/wiki/Tutorials&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;了解更多细节，请查阅文档（包含教程、案例、编程指南等）：https://github.com/intel-analytics/BigDL/wiki/Documents&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;支持&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;更多关于 BigDL 的问题和讨论，请加入 BigDL 谷歌讨论组（https://groups.google.com/forum/#!forum/bigdl-user-group）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;或订阅邮件列表（请发邮件至：bigdl-user-group+subscribe@googlegroups.com）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你也可以在 GitHub 问题页面报告错误或提交你想要的新功能：https://github.com/intel-analytics/BigDL/issues&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 16 Jan 2017 12:57:41 +0800</pubDate>
    </item>
    <item>
      <title>资源 | 任何阶段的学习者都适用的参考：机器学习领域书目全集</title>
      <link>http://www.iwgc.cn/link/4359146</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Machine Learning Mastery&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李泽南、朱思颖&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;来自 Swinburne 科技大学的 Jason Brownlee 博士为我们带来了最新一期的机器学习书目，内容覆盖科普、各级教材以及不同编程语言的机器学习应用。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;学习是一种理性的投资，每当花费十几个小时读完一本书，你就能领略到前人数年积累的经验。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在阅读了市面上大多数机器学习书籍后，作者列出了最新机器学习领域推荐图书，并使用了使用不同分类方式进行了整理：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;按类型：教科书，热门学科等；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;按主题：Python，深度学习等；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;按出版商：Packt，O'Reilly 等；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;……&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;如何使用&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 找到你最感兴趣的分类方式，找到需要的主题；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 在你选择的主题中挑选；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 购买图书；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4. 从头到尾阅读；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;5. 继续找下一本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;拥有一本书和了解它的内容是完全不同的两种概念——你必须真正阅读它们。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;请先问问自己：你有没有读完过一本机器学习的书？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;机器学习图书——按类型分&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;最流行机器学习科普图书&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以下图书适用于大多数读者。它们点到了机器学习和数据科学的精华之处，却没有使用枯燥的理论或应用细节。这份书单也包括了一些流行的「统计思想」科普书籍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;The Master Algorithm: How the Quest for the Ultimate Learning Machine Will Remake Our World&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：http://www.amazon.com/dp/0465065708?tag=inspiredalgor-20&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Predictive Analytics: The Power to Predict Who Will Click, Buy, Lie, or Die&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：http://www.amazon.com/dp/1119145678?tag=inspiredalgor-20&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;The Signal and the Noise: Why So Many Predictions Fail–but Some Don't&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：http://www.amazon.com/dp/0143125087?tag=inspiredalgor-20&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Naked Statistics: Stripping the Dread from the Data&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：http://www.amazon.com/dp/039334777X?tag=inspiredalgor-20&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;The Drunkard's Walk: How Randomness Rules Our Lives&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：http://www.amazon.com/dp/0307275175?tag=inspiredalgor-20&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibUP7CVr6GmhKQCDxRNzfzZsP4AewK4EoDPz1F9gde4g7ibXWBKibnR4WjsyE3Syiarzuibogycwzicmmw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;其中最值得推荐的一本是：《The Signal and the Noise》。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;适用于机器学习初学者的书籍&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以下列出最适用于初学者的书籍。希望入门的读者同时也需要参考科普图书（上一条）以及行业应用图书（下一条）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Data Science for Business: What You Need to Know about Data Mining and Data-Analytic Thinking&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：http://www.amazon.com/dp/1449361323?tag=inspiredalgor-20&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Data Smart: Using Data Science to Transform Information into Insight&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：http://www.amazon.com/dp/111866146X?tag=inspiredalgor-20&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Data Mining: Practical Machine Learning Tools and Techniques&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：http://www.amazon.com/dp/0128042915?tag=inspiredalgor-20&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Doing Data Science: Straight Talk from the Frontline&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：http://www.amazon.com/dp/1449358659?tag=inspiredalgor-20&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibUP7CVr6GmhKQCDxRNzfzZVFrcyojvkandTacfSvbo89iaMzp6lnGGAtJg5M9p18VqfekVVuDYWyg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;在这其中最重要的一本是：《Data Mining: Practical Machine Learning Tools and Techniques》。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;机器学习入门书籍——高级&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以下是适用于希望入门机器学习的本科学生和开发者的书籍，内容包含了机器学习的很多话题，注重如何解决问题，而不是介绍理论。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Machine Learning for Hackers: Case Studies and Algorithms to Get You Started&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：http://www.amazon.com/dp/B007A0BNP4?tag=inspiredalgor-20&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Machine Learning in Action&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：http://www.amazon.com/dp/1617290181?tag=inspiredalgor-20&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Programming Collective Intelligence: Building Smart Web 2.0 Applications&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：http://www.amazon.com/dp/0596529325?tag=inspiredalgor-20&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;An Introduction to Statistical Learning: with Applications in R&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：http://www.amazon.com/dp/1461471370?tag=inspiredalgor-20&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Applied Predictive Modeling&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：http://www.amazon.com/dp/1461468485?tag=inspiredalgor-20&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibUP7CVr6GmhKQCDxRNzfzZU0PIsuOgyEf6zZsicjqrKuUxqGibw6oobU8NWVFibPBOttMOics3M8ZdJg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;其中最值得推荐的一本是：《An Introduction to Statistical Learning: with Applications in R》&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;机器学习教材&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以下列出了机器学习领域目前最流行的教科书。它们会在研究生课程中出现，包含方法与理论的解读。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;The Elements of Statistical Learning: Data Mining, Inference, and Prediction&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：http://www.amazon.com/dp/0387848576?tag=inspiredalgor-20&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Pattern Recognition and Machine Learning&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：http://www.amazon.com/dp/0387310738?tag=inspiredalgor-20&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Machine Learning: A Probabilistic Perspective&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：http://www.amazon.com/dp/0262018020?tag=inspiredalgor-20&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Learning From Data&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：http://www.amazon.com/dp/B00YDJC98K?tag=inspiredalgor-20&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Machine Learning&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：http://www.amazon.com/dp/0070428077?tag=inspiredalgor-20&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Machine Learning: The Art and Science of Algorithms that Make Sense of Data&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：http://www.amazon.com/dp/1107422221?tag=inspiredalgor-20&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Foundations of Machine Learning&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：http://www.amazon.com/dp/026201825X?tag=inspiredalgor-20&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibUP7CVr6GmhKQCDxRNzfzZ1ib0Z4KQYu8iaTql0UzO6QjgYefhvRBHg2O72636Ccn22cNmvtsDq2bA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;其中的重点是：《The Elements of Statistical Learning: Data Mining, Inference, and Prediction》&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;机器学习图书——按主题分&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有关 R 语言在机器学习中如何应用的图书。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;The Elements of Statistical Learning: Data Mining, Inference, and Prediction&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：http://www.amazon.com/dp/0387848576?tag=inspiredalgor-20&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Pattern Recognition and Machine Learning&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：http://www.amazon.com/dp/0387310738?tag=inspiredalgor-20&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Machine Learning: A Probabilistic Perspective&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：http://www.amazon.com/dp/0262018020?tag=inspiredalgor-20&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Learning From Data&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：http://www.amazon.com/dp/B00YDJC98K?tag=inspiredalgor-20&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Machine Learning&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：http://www.amazon.com/dp/0070428077?tag=inspiredalgor-20&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Machine Learning: The Art and Science of Algorithms that Make Sense of Data&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：http://www.amazon.com/dp/1107422221?tag=inspiredalgor-20&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Foundations of Machine Learning&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：http://www.amazon.com/dp/026201825X?tag=inspiredalgor-20&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这方面的首选图书是：《The Elements of Statistical Learning: Data Mining, Inference, and Prediction》。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Python 机器学习&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以下列出 Python 机器学习热门书籍&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Python Machine Learning&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：http://www.amazon.com/dp/1783555130?tag=inspiredalgor-20&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Data Science from Scratch: First Principles with Python&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：http://www.amazon.com/dp/149190142X?tag=inspiredalgor-20&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Hands-On Machine Learning with Scikit-Learn and TensorFlow: Concepts, Tools, and Techniques for Building Intelligent Systems&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：http://www.amazon.com/dp/1491962291?tag=inspiredalgor-20&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Introduction to Machine Learning with Python: A Guide for Data Scientists&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：http://www.amazon.com/dp/1449369413?tag=inspiredalgor-20&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Vital Introduction to Machine Learning with Python: Best Practices to Improve and Optimize Machine Learning Systems and Algorithms&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：http://www.amazon.com/dp/B01N4FUDSE?tag=inspiredalgor-20&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Machine Learning in Python: Essential Techniques for Predictive Analysis&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：http://www.amazon.com/dp/1118961749?tag=inspiredalgor-20&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Python Data Science Handbook: Essential Tools for Working with Data&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：http://www.amazon.com/dp/1491912057?tag=inspiredalgor-20&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Introducing Data Science: Big Data, Machine Learning, and more, using Python tools 地址：http://www.amazon.com/dp/1633430030?tag=inspiredalgor-20&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Real-World Machine Learning&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：http://www.amazon.com/dp/1617291927?tag=inspiredalgor-20&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibUP7CVr6GmhKQCDxRNzfzZFlylgbNH4DXnULqSBsSpkGsjsibx86lQib35jOgmTAEhCsyFDcvpkOMQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;最值得注意的当然是《Python 机器学习》了。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;深度学习&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;注意：深度学习的图书目前还比较稀缺，以下这份列表只能保证数量，而不是质量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Deep Learning&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：http://www.amazon.com/dp/0262035618?tag=inspiredalgor-20&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Deep Learning: A Practitioner's Approach&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：http://www.amazon.com/dp/1491914254?tag=inspiredalgor-20&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Fundamentals of Deep Learning: Designing Next-Generation Machine Intelligence Algorithms&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：http://www.amazon.com/dp/1491925612?tag=inspiredalgor-20&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Learning TensorFlow: A guide to building deep learning systems&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：http://www.amazon.com/dp/1491978511?tag=inspiredalgor-20&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Machine Learning with TensorFlow&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：http://www.amazon.com/dp/1617293873?tag=inspiredalgor-20&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;TensorFlow Machine Learning Cookbook&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：http://www.amazon.com/dp/1786462168?tag=inspiredalgor-20&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Getting Started with TensorFlow&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：http://www.amazon.com/dp/1786468573?tag=inspiredalgor-20&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;TensorFlow for Machine Intelligence: A Hands-On Introduction to Learning Algorithms&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：http://www.amazon.com/dp/1939902452?tag=inspiredalgor-20&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibUP7CVr6GmhKQCDxRNzfzZwkBq02sAOZpCRb0bmNaHp6jZwkPpa5aECXpCrh7rgotM86zuLJCSxA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;其中最重要的一本书当然是：Yoshua Bengio 和 Ian Goodfellow 所著的《Deep Learning》。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;时序序列预测&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前时序序列预测在实际应用中主要是由 R 语言的平台所主导。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Time Series Analysis: Forecasting and Control&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：http://www.amazon.com/dp/1118675029?tag=inspiredalgor-20&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Practical Time Series Forecasting with R: A Hands-On Guide&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：http://www.amazon.com/dp/0997847913?tag=inspiredalgor-20&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Introduction to Time Series and Forecasting&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：http://www.amazon.com/dp/3319298526?tag=inspiredalgor-20&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Forecasting：principles and practice&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：http://www.amazon.com/dp/0987507109?tag=inspiredalgor-20&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibUP7CVr6GmhKQCDxRNzfzZekauaQ2ZQL2HJiaZCXWsxia9F1ekEN5VhaR6ibe9d25xRSibtfXe7Lqzug/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibUP7CVr6GmhKQCDxRNzfzZmCDBTHcbcVQgQiaS8J2msAlExTbB7K7F0uSRYdibib8gcyDeId9h3evpw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;最优质的入门介绍书籍是 Forecasting：principles and practice。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;时序序列最优质的教科书是 Time Series Analysis: Forecasting and Control。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;机器学习图书——按照出版商分类&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前活跃在机器学习领域的出版商主要有： O'Reilly, Manning 和 Packt。它们出版了数量可观的相关图书，但质量良莠不齐，从精心设计和编纂的到搜集科技博客内容整合到一起的都有。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;O'Reilly 的机器学习书籍&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;O'Reilly 的「data」标签下有一百本书，其中大部分都是与机器学习相关的，以下是一些最畅销的书籍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Programming Collective Intelligence: Building Smart Web 2.0 Applications&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：http://www.amazon.com/dp/0596529325?tag=inspiredalgor-20&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Introduction to Machine Learning with Python: A Guide for Data Scientists&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：http://www.amazon.com/dp/1449369413?tag=inspiredalgor-20&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Deep Learning: A Practitioner's Approach&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：http://www.amazon.com/dp/1491914254?tag=inspiredalgor-20&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Fundamentals of Deep Learning: Designing Next-Generation Machine Intelligence Algorithms&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：http://www.amazon.com/dp/1491925612?tag=inspiredalgor-20&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Data Science from Scratch: First Principles with Python&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：http://www.amazon.com/dp/149190142X?tag=inspiredalgor-20&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Python Data Science Handbook: Essential Tools for Working with Data&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：http://www.amazon.com/dp/1491912057?tag=inspiredalgor-20&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibUP7CVr6GmhKQCDxRNzfzZBqNbicvwRwO7r8RrGNgcm2Sr8BHCuFKt77Ctm4HhJjia4B2DdW7GyqLw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Programming Collective Intelligence: Building Smart Web 2.0 Applications&amp;nbsp;这本书代表了机器学习火热的开始而且已经流行了很长一段时间。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;相关链接&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;O'Reilly 的数据门户&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：https://www.oreilly.com/topics/data&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;O'Reilly 的数据产品&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：http://shop.oreilly.com/category/browse-subjects/data.do&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器学习初学者工具包：依据数据模式的自动化分析&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：http://shop.oreilly.com/category/get/machine-learning-kit.do&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;曼宁机器学习书籍&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;曼宁的书总是很实用且质量很高，但他们没有类似 O'Reilly 和 Packt 列出的机器学习 100 本书籍的清单。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Machine Learning Action&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：http://www.amazon.com/dp/1617290181?tag=inspiredalgor-20&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Real-World Machine Learning&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：http://www.amazon.com/dp/1617291927?tag=inspiredalgor-20&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Introducing Data Science：Big Data, Machine Learning, and more, using Python tools&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：http://www.amazon.com/dp/1633430030?tag=inspiredalgor-20&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Practical Data Science with R&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：http://www.amazon.com/dp/1617291560?tag=inspiredalgor-20&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相关链接&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;曼宁数据科学书籍&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：https://www.manning.com/catalog#section-68&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;曼宁机器学习书籍&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：https://www.manning.com/catalog#section-73&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Packt 的机器学习书籍&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;似乎 Packt 上有所有的数据科学和机器学习的书籍。Packt 有一个大范围的书籍库，库里的书是机器学习方面比较深奥的书籍。同时也有一些当下很流行的机器学习主题的书如 R 语言和 Python。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面是一些比较流行的书籍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Machine Learning with R&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址 ：http://www.amazon.com/dp/1784393908?tag=inspiredalgor-20&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Python Machine Learning&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：http://www.amazon.com/dp/1783555130?tag=inspiredalgor-20&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Practical Machine Learning&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：http://www.amazon.com/dp/178439968X?tag=inspiredalgor-20&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Machine Learning in Java&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：http://www.amazon.com/dp/1784396583?tag=inspiredalgor-20&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Mastering .NET Machine Learning&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：http://www.amazon.com/dp/1785888404?tag=inspiredalgor-20&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;其他资源&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以下资源是我用来完成本书目所参考的资料，同时也可能是对大家有用的机器学习的额外书单。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;亚马逊机器学习最畅销书&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：http://amzn.to/2iXxccZ&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;很棒的机器学习书籍&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://github.com/josephmisiti/awesome-machine-learning/blob/master/books.md&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我是怎样学习机器学习的？Quora 上的回答百科&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://www.quora.com/How-do-I-learn-machine-learning-1&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Reddit 的机器学习常见问题与回答&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://www.reddit.com/r/MachineLearning/wiki/index&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以上就是目前最为完整的机器学习书目，你读过其中的哪几本？欢迎与大家分享自己的看法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;原文链接：http://machinelearningmastery.com/machine-learning-books/&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 16 Jan 2017 12:57:41 +0800</pubDate>
    </item>
    <item>
      <title>AI Talk | 小度战平人类最强大脑后，我们和吴恩达聊了聊</title>
      <link>http://www.iwgc.cn/link/4347269</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编辑部&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;继上周五百度的小度机器人在《最强大脑》节目中的&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722118&amp;amp;idx=1&amp;amp;sn=1934dfd96eedb777b506a7f9fca1c44a&amp;amp;chksm=871b0b38b06c822e4419d7263ece28aa7ad683c4478eb908397c2fae2aa7505529f9708c72d4&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722118&amp;amp;idx=1&amp;amp;sn=1934dfd96eedb777b506a7f9fca1c44a&amp;amp;chksm=871b0b38b06c822e4419d7263ece28aa7ad683c4478eb908397c2fae2aa7505529f9708c72d4&amp;amp;scene=21#wechat_redirect"&gt;跨年龄人脸识别任务&lt;/a&gt;中击败了人类顶级选手后，周五晚上，小度再次在声纹识别任务上迎战了人类最强大脑，并最终以 1:1 的成绩和人类打成了平手。节目之后，机器之心对百度首席科学家吴恩达进行了独家专访，请他谈论了小度在这场比赛中所用到的技术、百度的人工智能研究和团队以及他对中国和世界人工智能研究的思考。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;iframe class="video_iframe" data-vidtype="1" allowfullscreen="" frameborder="0" height="417" width="556" data-src="https://v.qq.com/iframe/preview.html?vid=e0366l4b003&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0"&gt;&lt;/iframe&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;作为机器之心新栏目 AI Talk 的一部分，我们对这次视频专访的内容进行了剪辑，完整采访可见下面文字整理版本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;关于小度和声音/语音技术&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：简单介绍一下，小度在本期节目中使用到的识别技术及其原理？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;吴恩达&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：在比赛中，小度使用了 2 种前沿的声纹识别算法，为了识别出某个人，会把两种算法的结果结合在一起。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中一种方法是基于卷积神经网络，这是一种端对端的方式。卷积网络把输入切成声音片段，然后尝试识别这些片段是不是来自同一个人。这个神经网络是在 2 万多人的大约 5000 多小时的音频数据上训练出来的。这是一个很大的音频数据集，它使得神经网络变得相当准确。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们的第二个系统也有神经网络，但结构不同。第二个系统采用声音片段作为输入，神经网络输出 5000 维表征语音，并基于此进行统计建模。通过统计建模后的结果，抽离出说话人相关的信息，选择出 500 个特征来表征说话人的属性，而不是说话的内容。随后，使用这 500 个特征匹配两个说话人，并判断出是否是同一个说话人。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最终，我们用这两个神经网络让它们投票，从而做出最终决策。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：看起来语音识别要比语义识别更简单一些，你认为什么时候可以实现人类水平的机器语义识别，从而让人类可以和机器顺畅地交流？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;吴恩达&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：让计算机以人类的水平来完全理解自然语言，这还需要很长的时间，可能需要几年，也可能是几十年，我们难以确定。但我们可以预见在一些非常垂直的应用领域，比如询问天气、叫外卖、拿快递，或者推送今天的新闻这样的基础问题。这些方向非常的垂直，我们看到了自然语言处理在这些方向上的快速发展。以百度的度秘为例，你已经能与这个机器人进行交流，它可以给你合理的答案。在垂直领域它可以做得很好，研究人员有时间考虑到所有的可能性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我认同你所说的语音识别在过去两年已经取得了巨大的发展。事实上，语音识别如今很准确，使得更多用户用它作为文本输入。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;几个月前，斯坦福大学联合百度与华盛顿大学做了一项研究，表明目前的手机端语音输入要比键盘输入快 3 倍还要多。事实上，过去 12 个月里，我们看到所有百度产品上的语音日使用量增加了一倍，也就是语音服务的使用增长了一倍。所以，那些想要更高效、更便利地使用手机的用户更倾向于使用语音输入。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：百度语音平台免费提供了一些 API，它能实现什么功能？如何从中受益？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;吴恩达&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：语音已经变成一个非常重要的人机交互方式，在百度大脑，我们正在努力实现越来越多的语音功能并帮助人们用上这种强大的能力。在我们的网站上，最受欢迎的语音功能是语音识别、TTS（尤其是情感 TTS）以及语音唤醒。我们的团队在不断努力将越来越多百度的最好语音技术放到网站上。我们知道，对于第三方公司来说，获取这些技术是非常有用的，但也还需要知道如何有效地使用这些技术。所以百度大脑做的另一件事情是创造能够帮助第三方组织、开发者和公司了解如何最有效地在他们的产品中使用这些技术的材料。所以我们也正在将越来越多这些训练材料放到我们的面向公众的网站上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：百度是如何提升语音输入法的识别精度的？其中最困难的部分是什么？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;吴恩达&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：你知道，机器学习系统得到最好表现的一种最可靠的方式是在大量的数据上训练大型模型。如今百度的语音识别系统是建立在 5 万小时的数据上的，这是一个超过 5 年的音频数据。此外，我们在超级计算机上训练模型，它给了我们非常大的计算能力，从而建立足够大的神经网络吸收这些数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除此之外，我们面临的一些挑战是在缺少资源的语言和方言中。我们在尝试让百度语音识别系统覆盖更多的方言。在有很小数据集的方言上，我们尝试了在普通话上学到的东西，并将这些知识用到不同的方言上。所以，百度有很多积极性的研究是关于在没有普通话那样大量数据的情况下，研究在方言上做到最好的算法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一个研究挑战是如何让语音识别在没有很多数据的新领域、新应用场景中有好的表现。例如，在不同的语音应用场景，语音片段听起来也各不相同，比如很多口语化的语音的识别问题。在这些小的新垂直应用中，我们没有很多的数据。所以我们也在做大量的研究，想要搞清楚从现有收集到的 5 万小时的数据中能学到什么，然后专门应用到新的垂直领域与新应用中，这些领域中的音频质量或说话方式与我们的训练数据有很大不同。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你知道，语音识别有了极大的发展，在很多领域有很大的应用。但在语音上，仍有许多的研究需要完成。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：在 CES 2017 上，百度发布了 DuerOS，你也曾提到今年是对话机器元年，应该如何理解？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;吴恩达&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：我认为我们进入了语音对话接口成为必要事物的计算新时代。20 年前，我们大部分使用台式计算机或笔记本的键盘。大约 10 年前，乔布斯发布了 iPhone，开启了手触屏幕与手机以及其他设备交互的时代。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我认为人机交流的下一个时代是语音交流接口，而且我认为这一趋势如今刚好起飞。因为这一技术刚好到达了这样一个点，你可以坐在家中与对话计算机进行交流，询问航班以及其他信息，而且它们能了解你说的什么，并为你提供有用的信息和服务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以，我对对话计算时代黎明的到来非常乐观。事实上，我们在中国感受到的一件令人激动的事是我们看到了很多的创新，不同的团队建立了不同的很有创意的硬件。比如，小鱼在家、智能音箱、电视盒子等等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有了 DuerOS，我们希望能帮助所有的这些硬件制造者将人工智能、语音对话智能加入到硬件中，从而让更多这样的设备进入家庭。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：你认为语音识别技术未来将在哪些领域发挥最大作用？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;吴恩达&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：我认为语音在 4 个类别中将会快速起飞。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一个是手机。因为在智能手机上语音输入要比键盘输入更快，所以百度在手机的语音识别上增长迅速。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二个是家居场景。我们看到了智能音响（smart speakers）的崛起，出了智能音响，我认为小鱼在家、电视盒子这样的设备也在增加。我们把这种坐在家的体验叫做背靠式体验（lean back experience），也就是你能背靠沙发发号施令，然后各种家居设备会了解你的需求并作出回应。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第三种是汽车场景。在你驾驶的时候，手放在方向盘上用说的方式与汽车交流，它就知道你想做什么。所以我认为在这个场景中也会发展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后是可穿戴设备。大部分可穿戴设备没有很大的界面，比如智能手表等。所以我认为在这个垂直领域，语音会慢慢发展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以，我认为语音是让你与机器交流如此高效的一个接口，它会在这些垂直领域有很快的发展。可能也有其他领域。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：您怎么看语音识别技术的商业前景？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;吴恩达&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：在手机百度、百度地图、百度输入法等许多百度的产品中，我们可以看到过去几年中语音的使用变得越来越频繁了，因为这对用户来说是一个方便得多的文本输入方式。所以有大量第三方硬件制造商、软件开发商和开发者想使用语音来帮助他们的用户与他们的应用或设备进行更加自然和方便的交流；百度大脑项目也是一样，我们通过我们免费的语音识别 API 发布了我们的产品，让第三方也能用上我们的技术。语音识别是最难、门槛最高的技术之一，在百度，我们有幸能够使用足够的资源开发出非常好的语音系统。所以我们希望能够通过我们的技术来帮助许多开发者和企业组织，让他们的用户也能将语音作为一种输入方式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;百度的人工智能研究团队&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：百度人工智能团队的日常工作是怎样的？是什么创新机制在支撑团队保持创造力？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;吴恩达&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：现在正是从事人工智能工作的好时候，你能看到有人将人工智能比作是「新型电力（new electricity）」——就像一百年前电力变革了一个又一个的行业一样。我认为人工智能也将类似地给交通和通信等许多行业带来变革。我们很幸运有这么多出色的人才在百度工作，他们不仅在努力使用百度的数据和计算资源来提升这些技术，而且也在寻找新的语音识别和人脸识别等技术并将它们投入到可以真正帮助人们的新场景、新产品和新应用中。每天我到百度工作时，我都为我们有这些能够帮助很多人的技术而感受振奋。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这里我想额外补充一点。我想对所有还在考虑自己的职业生涯的年轻人说一句，我知道当你很年轻的时候，有时候你无法确定该追求怎样的事业。我认为我们现在正生活在一个人工智能领域有无穷机会的时代，如果你还不确定你该做什么，可以考虑加入我们来开发人工智能、研究人工智能，未来几年这一领域将有非常大的机会。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：在将人工智能研究成果产品化的过程中，百度人工智能团队是如何与其它业务部门协作的？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;吴恩达&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：将最新的人工智能投入到产品中通常需要多个不同职能的团队的协同。比如说，将语音识别技术集成到手机百度应用中，实际上是有很好的语音识别技术的语音技术团队和有很好的搜索技术的搜索团队的合作成果；正是这种互相理解的合作才让我们的手机百度具备了出色的语音输入能力。再举另一个例子，今天在进行金融交易时，我们会使用人脸识别来确认人们的身份，这也是我们 IDL 的计算机视觉团队与金融服务团队（他们有金融产品和深度的领域知识）合作的成果。所以在百度工作，这方面还是非常好，我们的技术团队可以很容易去创造或发明新技术，并且可以轻松地和其它出色的产品团队合作，将这些新技术快速投入到产品中从而为他们的海量用户提供帮助。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：百度在招募人才、组建人工智能团队方面，有哪些经验可以分享？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;吴恩达&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：你知道如今人工智能发展迅速。我认为百度持续在做的一件事是在职员上做投资，扩展我们的团队。据我所知，百度在职员培养、训练上的投资要比其他公司都大，我们进行常规的课程从而让团队了解最新的人工智能技术，所以我们的团队会变得越来越好。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在美国和中国，我认为百度正在获得这样的声誉：如果你想要学习人工智能，这里就是你该去的地方。也许很多人不了解，但我认为对全世界的科技巨头而言，李彦宏是第一个意识到深度学习巨大潜力的领导者。我认为李彦宏具有很深的技术背景，同时对人工智能技术有着透彻的理解。我们很幸运在百度成立 17 年的时间里，有他一直在带领着公司建立并且积累基础的人工智能科技。我认为我们现在的这些成果都是建立在李彦宏打下的基础之上的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们都知道 IDL（百度深度学习实验室）主任是林元庆，但很少有人知道其实 IDL 的第一位主任是李彦宏本人。他预见了深度学习的发展趋势，并希望百度首先投入其中。不仅仅是在中国，放眼全世界的科技公司，你很难找出一个和李彦宏相似这样有预见性的领导者了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;对人工智能领域的看法和期望&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：小度在《最强大脑》的节目中表现优异，但人工智能技术在实际应用层面还面临诸多挑战，比如无人驾驶汽车的安全性等，您怎么看待这一类难题？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;吴恩达&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：当飞机在大雾或雨天着陆的时候，基本上都是在用基于计算机软件的全自动驾驶。所以，我认为如今已经有了能做出与性命相关决定的软件。我认为，如今有了人工智能，这些重要决定将会更容易作出。无论它是设定在自动驾驶内，还是医疗领域中（比如自动诊断）。当然，我认为人工智能研究者还面临着一个重大责任——就是在各个垂直领域内作出谨慎的评估，这才能够让人们更加相信人工智能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;说到自动驾驶汽车，这是近年来快速发展的另一领域。它面临的一个重大挑战就是：现有的交通法规大部分是为人类驾驶员所写的。所以自动驾驶在发展中面临的最大挑战就是需要制定既适用于人类又适用于计算机驾驶员的新法规。我认为这是加速全球自动驾驶普及的关键。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：很多人说可怕的不是人工智能，而是人工智能落到的坏人手里。您怎么看待这一说法？如何防止出现这样的现象？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;吴恩达&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：之前我们将人工智能比作是新时代的电力——就像是一百年前电力是新出现的超级力量一样，现在的超级力量就是人工智能。在绝大多数情况下，电力都给我们这个世界带来巨大的好处，我们现在几乎不能想象没有电的生活；但不幸的是，电力也被用在一些不好的方面。幸运的是，我认为现在绝大多数人工智能领域内的人都是好人，我们做人工智能是因为我们希望帮助人类。所以我相信总的来说，人工智能将给这个世界带来很大的积极影响。我也认为每一个人工智能工程师和研究者都有个人责任，确保其成果能够有益于这个世界。基于我对全球人工智能业界的了解，我认为现在全球人工智能行业整体上都在做着非常有益于这个世界的事情。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：你曾经在《哈佛商业评论》中撰文呼吁各大公司设立首席人工智能官（Chief AI Officer），你认为首席人工智能官需要具备什么样的特质？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;吴恩达&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：百度是世界上最好的人工智能公司之一，我们在公司的每一天都在思考人工智能。我希望能够将我们的一些想法和人工智能社区以及世界上的其他人分享，从而帮助推动全球人工智能的发展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关于首席人工智能官，我认为目前人工智能所面临的难题之一是：将这种我们已经拥有的技术应用到能够真正有助于我们的业务的使用案例中。所以我认为首席人工智能官应当具备两种关键技能：一是理解这种技术（这很重要却也很难），二是了解自己公司的业务并且搞清楚如何将这些让人惊叹的人工智能技术和你的业务匹配起来，从而让你能够创造出重要的价值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：大公司都在重金投资人工智能领域，它们也在数据量上拥有绝对优势，您认为初创型公司还有机会在竞争中占据主导位置吗？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;吴恩达&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：我们最好的语音识别系统大约是在 5 万小时的数据上训练的。我们的语音识别系统，也就是小度这次使用的这套系统是在 2 万说话人数据的基础上训练的。所以如今就有一些问题，如果你想要获得顶级系统，我们就需要大量的数据。所以在一些领域中，小公司使用如今已有的科技建立百度这样有效的系统还是很有挑战的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但我认为在一些垂直领域中，例如，在罕见疾病的医疗成像上，全世界在这些领域可能都没多少图像。所以，我认为在这些垂直领域中，即使少量的数据也可能建立有相当好表现的系统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管如此，我也认为百度的数据、资本、超级计算机，再加上我们的人才，确实使得我们能更快地建立最好的人工智能系统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：人工智能的技术研究在哪些方面改变了百度，又将如何渗透到更多的行业？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;吴恩达&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：人工智能已经完全变革了百度——从网页搜索到我们组织外卖送递的方式，再从我们推荐内容的方式到我们进行人脸识别、身份认证、语音识别的方式等等。所以这些都已经用到了人工智能。我认为除了变革百度的产品之外，我们也很高兴能将人工智能技术提供给第三方，让它们也能使用我们的语音、计算机视觉、NLP 等等各种不同的人工智能技术来变革自己的产品。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我认为，人工智能会在未来改变所有行业的形态。有的时候我的朋友会和我打赌，看看某个行业在最近几年不会被人工智能所改变。你也可以尝试想想看，实际上我们很难想出在未来几年不会受到人工智能影响的行业。我最喜欢的例子是理发师，实际上我发现创造一个能够理发的机器人是很困难的。曾经我在台上演讲也说过类似的话，但我有一位机器人学教授朋友告诉我，她说对于大部分的发型来说确实如此，机器人很难帮他们理发；但她也指出：「至于你的发型嘛，我可以让个机器人剪出来。」所以我觉得实际上我们很难确定一个不会被人工智能改变的领域，我认为不管你的业务是什么，都可以考虑一下利用人工智能来增强你的优势。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：你想对中国的人工智能从业者和机器之心说些什么？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;吴恩达&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：我认为中国很幸运有机器之心这样的顶尖媒体将全世界的人工智能进展快速分享给中国的读者。实际上，中国和世界的信息传播有一种奇怪的不对称——全球的人工智能进展可以非常快速地传播到中国，但有时候百度等在中国发布或发表的进展却很少让世界其它地方的人知晓，这可能是因为他们并不阅读中文的媒体。当然我希望这种世界向中国的知识共享能够继续，我也希望我们能做些什么来帮助世界其它地方的人更快地了解中国的人工智能发展和前沿成果，这样我们就能让整个世界的人工智能研究社区都更快速地进步了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicS08ZFjdibpLIeOjg73NAOyRulPA7upc5nBHVHQV4nEe1VYKJ0oCNRDHIgfRdEjDQg3atmJKUrSEg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;「AI Talk」&amp;nbsp;是机器之心最新出品的视频访谈栏目，旨在邀请国内外人工智能顶级专家分享对技术和行业的观点，为大家呈现更为直观、丰富的内容。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心原创，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 15 Jan 2017 12:11:12 +0800</pubDate>
    </item>
    <item>
      <title>干货 | Andrej Karpathy CS294课程总结：可视化和理解深度神经网络</title>
      <link>http://www.iwgc.cn/link/4347270</link>
      <description>&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;机器之心&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;I. 介绍&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;这篇文章中，我们将回顾一些目前用来可视化理解深度神经网络的方法。我不会深入探讨这些材料中的细节，而是阐述一些个人观点以及我在学习这些材料时的个人体会。所有原始材料来自 Andrej Karpathy 在伯克利大学的客座讲座，CS294 课程。该讲座的演讲视频可点击文末「阅读原文」查看。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicS08ZFjdibpLIeOjg73NAOy8VhBzt7u8O4BAIHRfwZenvgWSJSj2u42Tv5yD8yzEzu8YIgeDkBTiaA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;II. 凸优化（Convex Optimization）vs. 非凸神经网络（Non-Convex Neural Networks）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;凸优化是一个数学上非常严谨的问题，人们对此也一直颇有研究。它的优美之处在于能够推导出易实现的、达到全局最优的下降算法。而非凸优化问题，却很难证明其最优性。也因此，我们会担心针对这些问题提出的优化算法会停滞在局部最小值。然而，这并不是说我们不能证明非凸问题最优解。我已经碰到过一些技术，这些技术使用了区间分析（interval analysis）方法，只要函数在某些阶上（some odrder)Lipschitz 连续，并且它的解（局部最小值）并不会产生组合性爆炸。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;神经网络本质上是一个非凸问题。因此，对其最优性的形式证明寥寥无几。在过去，担心差在局部最小值是真的，特别是神经网络刚刚开始发展的阶段（上世纪 80 年代）。其中一篇关于探讨这个话题的论文： 多层网络的损失面（The Loss Surfaces of Multilayer Networks by Choromanska etal. 2015），实证表明，随着问题维数增加（可视为隐藏层更多了），你的最终解的损失方差会下降。因此，基本上，最优解和最差解之间的间隔在不断锐减，你的所有的局部最小值会变得相同。因此，非凸优化解决方案不过是走开了，人们并没有真正的解决这个问题，它仅仅是变得不重要了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicS08ZFjdibpLIeOjg73NAOyQgRBxj2tNlH6RcSH3pTqsgu8yXGoCwWf5Z1aibLoglAfIXYDgic4BtRg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;III. 层图表达以及 t-SNE 可视化&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（编者注： t-SNE 是 t-distributed stochastic neighbor embedding 的缩写，即 t 分布随机邻域嵌入算法）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;卷积神经网络，简单来说，就是一个多层巨无霸三明治。一种用来视化理解这些网络的方法就是从网络中取出一个单独神经元，观察让这个神经元兴奋的是什么。本质上，我们经验使用这些激活反应来可视化神经元响应的对象。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicS08ZFjdibpLIeOjg73NAOy2icgyiawiagVM2Q2nnKZ5mUx1j1cyTiauOtT4KXkhricGiaeroicicDQoX2meA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;图注：可视化激活神经网络的事物&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;br/&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一个技术是可视化网络权重。这需要训练自己的神经网络然后显示它学习到的 Gabor 过滤器。不过这种办法只对卷积神经网络首层有效，因为针对输入的图片所得出的权重在第一层后又会再做卷积操作。当你不断深入网络，我们就不太能解释 这些滤波器的结果了，因为每一层的权重都是在前一层输出结果上进行了卷积操作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicS08ZFjdibpLIeOjg73NAOy9f4Nc49sVe3sibJPl5bkEhEfGM5EFXl1h13leib5dvu9WwqdqcCgaUMA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图注：可视化网络权重&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在此，Andrej 给出了一个关于使用 ConvNetJS 来实现可视化技术的链接（https://cs.stanford.edu/people/karpathy/convnetjs/），该项技术能把网络逐层分解，你可以利用这个来观察网络在输出最终分类结果前每一层的梯度、激活函数、 权重等。此外，Andrej 还推荐了一下 TensorFlow Playground：http://playground.tensorflow.org/，以及 Jason Yosinski 的博客：http://yosinski.com/deepvis&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;IV. 不仅仅是单个神经元的可视化&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有一种观察卷积神经网络的方法是看其全局表达，即卷积神经网络对任何一张图片，其顶层的输出结果。我们将一张图片传入卷积神经网络网络去处理。这个网络的每一层将对该图片进行重新的表达，而对于每一层，我们可以学习到原始的图片是如何被整合到这一层中的。因此，为了可视化这一过程，我们希望能将这些表达整合到 2 维空间。这时候，就需要用到一种超炫的技术，叫做 t-SNE 可视化技术（Van der Maaten, Hinton**）。**这种技术将高维的点嵌入到低维空间，而局部的成对距离被保留了（在低维空间相邻的点在高维空间也依然相邻）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicS08ZFjdibpLIeOjg73NAOyNI2rmIG2KD0Rt7k8dmD8Up3tThKuOCqHcXzcF6bfbCXPrAqxDic8KAQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;图注：t-SNE 可视化，了解更多可查阅 http://cs.stanford.edu/people/karpathy/cnnembed/&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicS08ZFjdibpLIeOjg73NAOyMwQKoVCLFn6ClUQGvK9svpcPeklqEy18sV6PJS6lclFH7CvMGUqCGg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;图注：用强化学习玩 Atari 游戏的可视化&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;V. 遮盖实验&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种用于可视化网络究竟学到了什么的技术是把网络视作黑盒，修改它的输入然后观察输出。假设我们有一张被这个网络能准确地分类成博美犬的图片，现在，我们要做的是将这个图片的某一块「屏蔽（block）」（将这个地方的像素值设置为 0 或 255，或者颜色设置为黑或白即可）。这样，这个网络的输出是对这张被屏蔽的图片的输出。我们可以发现，当我们屏蔽的部位越是重要，比如脸部，那么这个网络做出正确分类可能性就越低。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicS08ZFjdibpLIeOjg73NAOydl55lhUUwkvLcR9YdWKBj58FBSFQmIxNZPm4gTkeKWcdU8yuPSL88A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个有趣的发现是，比如，我们有一张照片，其正中部位有一只阿富汗猎犬，旁边是一位男子，网络能正确的将其标记为阿富汗猎犬。但是，如果将男人的脸用像素为 0 的方块遮盖，网络认为是阿富汗猎犬的概率激增。发生这种现象的原因在于，每一张图片只被分配了一个正确的标签，当我们遮盖一些可能会引起网络会做出其他决定的部位，那么，得出这个正确的标签的概率就大大提高了。这也是一种完整性检查，这样网络可以一种通过调整图片可能所属类别标签的概率大小来做出合理判断。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;VI. 去卷积方法（Deconvolution Approaches）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通常，我们尝试去计算出关于网络权重的损失函数梯度，这样当我们每做一次更新操作，我们就能优化权重。现在，让我们思考一个问题：给出一张图片，怎样才能得出网络中任何一个随机神经元的梯度？有一种可行的方案是：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicS08ZFjdibpLIeOjg73NAOyzopePic8E8atv0YLgwOBOnbT1eWic6KSekfNrXmCHFqUoOFiba2e9fbUg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1）将图片输入网络，对于网络深处的某一个神经元，我们将其命名为神经元 a。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2）将它的梯度设置为 1，同层的所有其他神经元的梯度设置为 0。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3）一路将梯度反向传播回图片，得到一张略古怪的噪声图片。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管这张梯度图片很难解释，但至少可以告诉你，如果把这张图片和原始图片叠加，将会提高神经元 a 的激活函数值。而反向传播过程只会改变修正线性单元 ReLU 层。这里的直觉就是：沿着梯度（反向）传递到 ReLU 层的某一个神经元，那么说明这个神经元被激活了。否则，传递就会停止。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一种替代方法是不使用简单的反向传播，而是使用所谓的导向反向传播（guided backpropagation）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicS08ZFjdibpLIeOjg73NAOyW24FbfSlbpOUZ2PAzUenJdBgyjvsQegh5R60AMBZIQHwfibiaz8CK0ng/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种技术并不仅能够识别一个修正线性单元 ReLU 是否被激活，而且可以识别所有值为负的梯度。本质上，除了能把所有不被激活的修正线性单元 ReLU 关闭，所有反向传播时遇到的负信号还能被设置到阈值 0。最终，我们只需要反向传递梯度为正的值即可。这样的话，反向传播最后获得的图片就会更加清晰，因为我们去除了所有负梯度对我们所选的神经元造成的影响，只保留了正面的影响（详见： Striving for Simplicity: The all Convolutional Net, Springenberg, Dosovitskiy, et al., 2015 for more information）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicS08ZFjdibpLIeOjg73NAOybEMtz4r9wXQNuGqczSpSgjgpjRgOxX2yXchzV40ZB2DeRn0T7eDYSA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图注：使用 guided backpropagation 后噪声明显减少&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;VII. 对图像进行最优化&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;i. 类别可视化&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicS08ZFjdibpLIeOjg73NAOyN1SR0SwT4GgMgyNXBHn3EgPwQsrFNdBvw5QnUqVBYeTiboJslI7q4RA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;接下来讲授的技巧涉及在图像上进行最优化操作。考虑如下问题：我们能否找到一个图像，它能够最大化某些类别的分数？为达到该目的，我们希望保持神经网络架构不变，而使用不同损失函数以在图像上进行最优化。这个方法包括如下步骤：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicS08ZFjdibpLIeOjg73NAOy3tvUV7zUS53Gwrmp1edlFWmianbIv0FL7ZA4RYSeEibA9RWDlbCadicYA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;(1) 向神经网络中传入一个随机的图像；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;(2) 设定梯度分数向量为 [0,0,…,1,0,...0]（将感兴趣的那一类设为 1，不感兴趣的则为 0），接着对对象进行反向传播；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicS08ZFjdibpLIeOjg73NAOyvW28YTasoWC1iavB7UfznibHzzhWMueDrw5LEpLO4DMgV7emMTLiaTOrw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;(3) 进行一个小规模「图像更新」；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;(4) 将更新的图像进行正向传播；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;(5) 重复 (2) 以设定其他的梯度分数向量。我们基于一个随机噪声的图像开始，并对目标类（也就使用了上述的梯度分数向量进行逆传播的那一类）进行梯度上升操作，我们会生成一个图像，它能改进神经网络对目标类的激活状态。从数学上来说，令 I 代表一个图像，y 代表一个目标类，Sy(I) 则是神经网络赋给图像 I 在 y 类上的分数。我们希望解决如下的最优化问题：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicS08ZFjdibpLIeOjg73NAOyUYzPog4uDVTiabicWN7YkuiaMmAgGez0eXXQica42EltWAsnSWP99g2iaibg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;也就是说，我们希望找到一个图像 I∗，它能够最大化神经网络赋给 y 类的分数。在如上的等式中，R 是一个正则化项。正则化项改进了输出图像的可视化程度（参见 Simonyan 等人，Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps，ICLR Workshop 2014）。这个内容在去年完成，它论述了类的分数问题。但是，该技巧可以被应用到神经网络中的所有节点上。我们从某个随机图像开始正向传播，直到到达了我们想要研究以及可视化的层为止。对该层中的任一神经节点，重复该步骤（即设定其他梯度分数为 0、目标对象梯度值为 1、在图像上反向传播），以检查哪种图像会最大程度地激活神经网络中的神经节点。注意，这些技巧中都有正则化项，以避免对抗的图像。不同的正则化方案侧重图像的不同方面，以判断我们认为的「正常的」图像。所以，它们会对这些试验的结果有很大影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;ii. 特征反演（Feature Inversion）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一个可以探讨的问题是：给定一个卷积神经网络的「编码」（特征代表，可以理解为是神经网络中某一层的输出值），能否根据其重构原来图像？如下的技巧就试图实现这一功能。它分为三步：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;(1) 向网络中传入一些输入图像；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;(2) 忽略输入图像；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;(3) 在某些层对输入进行反向传播，直到在网络中找到这样的层，能够生成与输入图像相同的「编码」（在这一层学到的特征表示）的图像。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从数学上看，令 I 代表一个输入图像，φl(I) 为卷积神经网络 φ 中的激活层 l。我们希望解决如下优化问题：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicS08ZFjdibpLIeOjg73NAOygwQiabQ7ZtIbwCXx8icL2L6BOLkDwBEIku50e7CvCXEJtBOGJdPjxjCQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;也就是说，我们希望找到一个图像 I∗，它与图像 I 在神经网络 φ 中的 l 层有相似的特征表示。其中 ||.||2 是代表 L2 范数，R 是正则项（可能是隐式的）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;概括来说，我在这里的想法是，要储存一个图像，只需存储图像的「编码」就行了。我们可以根据上述方法使用这些「编码」来重构图像（尽管有损失）（参见 Yosinski 等人，"Understanding Neural Networks Through DeepVisualization"，ICML 2015 Deep Learning Workshop）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;总的来说，这项技术允许我们看到，图像是如何通过一组特定「编码」（特征代表）在神经网络上被恢复的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;VIII. 卷积网络中的对抗图像&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对抗图像，是对原有图像加入很小的扰动而构成的图像；这些扰动由数据集的数据构成，被特意设定为最坏情况。由此，神经网络会错误地给这个新形成的图像很高的概率。在实践中，我们可以取任一被正确标记的传入神经网络的图像，并基于其它对抗图像对其添加扰动值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicS08ZFjdibpLIeOjg73NAOyicdcxTpVpQN9EL6CSwfMeZOASqXnF5yzic14DIoMERalwUXwbFfczhew/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们无意探讨过深的数学细节，但这种情况发生的原因是因为神经网络常有很高的维度，因此，它有着内在的线性本质。直觉上说，我们考虑如下的线性例子：令 x 为一输入图像，w 为该模型的权重值，则获得输出的运算就是 x 和 w 之间的内积，即 wTx。如果我们以 η 来轻微地对输入进行扰动，我们则得到 x¯ = x + η。那么，输出就便成了 x¯ = wT x + wTη。这种对抗扰动导致激活值增长了 wTη。进而，我们可以在某些关于 η 的限制条件下（通常是正则化约束）最大化该项以引起模型中的问题。但是，随着问题维度的不断增加，我们可以在满足正则化条件的情况下，对 η 向量施加很多小的扰动。这些细微的变化加在一起，最终会对输出造成很大的变化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一种考察不同模型间对抗图像的方法，是将他们视为对抗扰动在模型权重向量下高度对齐的结果。这是因为如上解释中所说的内容：这些小的改变迫使该线性模型专注某一个信号，该信号和模型的权重值最相近；即便其它 (从正确图像中得来的) 信号有更大的振幅也是如此。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;IX. Deep Dream 实验&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicS08ZFjdibpLIeOjg73NAOyhLF59tZIOVmWictnicoQjUL2k9DZ8yYAtRTaj2IhhLwkz6sxLngvtDXQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图注：Deep Dream GitHub：https://github.com/google/deepdream&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Deep Dream 实验背后的机理实际上是很简单的。基本上我们只要修改一下图像，以增强网络中选定的某层的激活情况。具体地，我们需要：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicS08ZFjdibpLIeOjg73NAOySawBpic1kuZJdUuR59theSuZAViarib8t0yATZ98SNjOSM3TibRXUic0F4g/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;(1) 从神经网络中选择某一层；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;(2) 向其中传入某些输入图像，以确定给定层的特征；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;(3) 设定那一层的的梯度值为激活值自身；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;(4) 对该图像进行反向传播。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;X. 神经风格实验&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicS08ZFjdibpLIeOjg73NAOyNnVBJdQeKSicpfxMSMrkLwjVpsxcBIHa9bB9W6LjgSXCtECwGSBuZyA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;考虑如下的情景：我们有两个图像，一个为内容图像 Ic, 一个为风格图像 Is，我们想生成第三个图像，使之能够具有 Ic 的内容及 Is 的风格。也就是说，我们要做的是从 Ic 中解析出内容，从 Is 中解析出风格。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicS08ZFjdibpLIeOjg73NAOytM9KibrUS7H21ibCtDNyOicv4ibsjkJKH9dZUPOSGrdWVocCMx1D7LBt5Q/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了解析出内容，我们将 Ic 传入我们的神经网络并储存每一层的激活值。但解析风格的过程却有所不同。我们将 Is 传入神经网络，并计算每一层激活值的 Garmian 矩阵（G=VTV）。从代数的观点来看，Garmian 矩阵 G 仅仅是 V 的列内积值。例如，CONV1 层由 244×244×64 个激活值构成，我们则计算得一 64×64 的 Gram 矩阵，它是由每个区域内配对激活值的协方差求和而成。从图像的角度来说，我们是将一层由三维（244×244×64）矩阵构成的激活值转换到一个二维矩阵（（244×244）×64），并对其取外积以得到该 64×64 的矩阵。对矩阵中的每个项 gi,j，我们都是将输出通道 i 及 j 在那一层上的激活值乘在一起。如果通道 i 及 j 的神经元交结在一起，那么它们会加在一起，我们也会得到一个更大的 gi,j。所以 Gram 矩阵 G 含有在对整个空间位置平均后哪些神经元交结在一起的数据。我们对神经网络中的每一层都计算一个 Gram 矩阵。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicS08ZFjdibpLIeOjg73NAOyrJujw2MqB5PiawWplXxqNGticiboW86t6ORzAr3It10IPVGCYZuw1T8jQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最终，我们有了这些信息之后，就能够对整个图像进行最优化以得到： Ic 的内容及 Is 的风格（详见 Leon A. Gatys 等人，《A Neural Algorithm of Artistic Style》，2015）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicS08ZFjdibpLIeOjg73NAOy2cONrJ6Mxfsugn0lKjEFk4ticjHnC99QzJYTpP6U5hAumCGjnmqWjeg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;最后，Andrej 还推荐了一个快速神经风格迁移项目，可以实时通过网络摄像头实现风格迁移：https://github.com/jcjohnson/fast-neural-style，参见机器之心文章《&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719733&amp;amp;idx=3&amp;amp;sn=950a7adb4e93bca22e4ef975877482a9&amp;amp;chksm=871b018bb06c889ddc87bccaa0f35de5ca5a35c156cf1164d134d5010065d68dd06ba6e7cdfa&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719733&amp;amp;idx=3&amp;amp;sn=950a7adb4e93bca22e4ef975877482a9&amp;amp;chksm=871b018bb06c889ddc87bccaa0f35de5ca5a35c156cf1164d134d5010065d68dd06ba6e7cdfa&amp;amp;scene=21#wechat_redirect"&gt;开源 | 怎么让你的照片带上艺术大师风格？李飞飞团队开源快速神经网络风格迁移代码&lt;/a&gt;》。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicS08ZFjdibpLIeOjg73NAOyyOJBPFfloh0F9nibLIu0C8BVgLFZUPbPdcgTSPZ0eDBgxqsBboibxXGw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;XI. 结语&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这篇回顾中，我们回顾了一些能够用于理解及可视化神经网络的技术。这些技术是从各种资源中搜集来的，其呈现的顺序与重要性无关。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们探讨了如何可视化那些能最大化激活神经元的区块，检查了其权重值及其对激活值的影响（第三节）；我们亦讨论了使用如 t-SNE 这样的技术来可视化全局表达（第四节）；在所讨论的遮盖实验中，我们修改了输入并观察了输出改变情况（第五节）；然后，我们谈到了几种去卷积方法（第六节），接着对图像进行最优化（第七节）以最大化一个类、神经元之间的激活率（firing rates）或是匹配一个特定的编码。此外，我们还基于简化的线性解释，讨论了卷积网络中的对抗输入。最后，我们涉及到了一些关于最优化图像的一些应用（在最后关于 Deep Dream、神经风格的两节中）。这些技术表明，神经网络中的「层」或特性并非仅仅是随机模式，有着能够直觉被理解的特性。我们能够使用这些可视化技巧来发现模型的中的问题，以获得更好的结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，我们想提及一个也许更具价值的观点：如今神经网络给出的解决方案，在神经网络不断增长的情况下的被证明是经验最优的——也就是说，在所谓「好」与「差」的答案之间的鸿沟消失了。所以，困在一个局部最优点，也许不再是一个问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心原创，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 15 Jan 2017 12:11:12 +0800</pubDate>
    </item>
    <item>
      <title>开源 | Udacity发布无人驾驶汽车工程师纳米学位项目：在模拟器中克隆人类行为</title>
      <link>http://www.iwgc.cn/link/4347271</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Github&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：杨旋、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Udacity 无人驾驶车工程师纳米学位（Nanodegree）系列计划第三个项目&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;项目地址：&lt;/span&gt;&lt;span&gt;https://github.com/upul/behavioral_cloning&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;行为克隆：模拟（人类）驾驶汽车&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;概述&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本项目的目标是使用一个深度神经网络来模拟人类的驾驶行为。为了达成这个目标，我们会使用一个简单的汽车模拟器。在训练阶段，我们使用键盘在模拟器内对我们的车进行导航。当我们驾驶汽车时，模拟器会记录训练图像和相应的转向角度。然后我们使用这些记录的数据来训练我们的神经网络。训练模型会在两个轨道上进行测试，即训练轨道和验证轨道。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;依赖包&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此项目需要安装 Python 3.5 和以下 Python 库：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Keras：https://keras.io/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;NumPy：http://www.numpy.org/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;SciPy：https://www.scipy.org/&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;TensorFlow：http://tensorflow.org/&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Pandas：http://pandas.pydata.org/&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;OpenCV：http://opencv.org/&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Matplotlib (可选)：http://matplotlib.org/&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Jupyter (可选)：http://jupyter.org/&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在终端提示符处运行此命令安装 OpenCV。适用于图像处理：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&amp;nbsp;&lt;span&gt;conda install -c https://conda.anaconda.org/menpo opencv3&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;如何运行模型&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此资源库包含了已经进行训练好的模型，你可以使用以下命令直接测试。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;python drive.py model.json&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;实现&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;获取数据&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在训练期间，模拟器以 10Hz 的频率来获取数据。此外，在给定的时间间隔内，它将依次&lt;/span&gt;&lt;span&gt;记录左、中和右部的摄像机拍摄的三个图像。下图显示了我在训练期间收集的示例。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicS08ZFjdibpLIeOjg73NAOytX3u34ta13CKiaVpicOrjMNHhro3ql1LK4kZmKcF9KekaPWaus66c5UA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;收集到的数据在传送给深度神经网络之前会被预处理，相应的预处理步骤将在本文的后半部分描述。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;数据集统计&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该数据集包含 24108 张图像（每个方向的摄像机拍摄了 8036 张图像）。训练轨道包含许多缓弯和直线路段。因此，记录中的大多数转向角都是零。所以，对图像和相应的转向角度进行预处理非常必要的，以便将此训练模型推广到那些未经训练的路线（例如我们的验证轨道）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;接下来，我们将解释我们的数据处理流程（data processing pipeline）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;数据处理流程&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下图显示了我们的数据预处理流程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicS08ZFjdibpLIeOjg73NAOyHpsbKuu8tRViacM7ObwblgFj4mjvUuDoMU8ca03WcY1qJOlgsoXxdUA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当处于流程中的第一个阶段时，我们会应用随机剪切操作。然而，我们只选择了 90% 的图像来进行随机剪切过程，保留了 10% 的原始图像和转向角，以帮助汽车在训练轨道中导航。下图显示了样本图像剪切操作的结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicS08ZFjdibpLIeOjg73NAOyXggRulfIFDj1D9iaxXpxlbHibhKuTBXbEDCwgjia4zVicaBOyriaiccssXgA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;模拟器捕获的图像有很多细节，它们对于模型构建过程没有直接的帮助。这些细节除了会占用的额外空间还需要额外的处理资源。因此，我们从保留的那 10% 的图像的起始处开始删除了 35％ 的原始图像。这个过程在修剪阶段（crop stage）完成。下图显示了图像的裁剪操作的结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicS08ZFjdibpLIeOjg73NAOyia71tcLrqz69ibP6IiaN1nRKChicib6icc6JibEgsKce7nZkmttR2QVSGkQQQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据处理流程的下一阶段被称为随机反转阶段（random flip stage）。在这个阶段，我们会随机（概率设定为 0.5）翻转图像。这样做的原因是因为是训练轨道中的左弯曲比右弯曲更普遍。因此，为了增加我们的模型的泛化性，我们采取了翻转图像和相应的转向角的方案。下图显示图像的翻转操作的结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicS08ZFjdibpLIeOjg73NAOycnIPv5HFibd0FicQVOxCUKlu4mEETmQSHibhTWeTqLBE0icVvxDjEjgSUQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在流程的最后阶段，为了减少训练的时间，我们将图像大小调整为 64×64。样本调整大小的图像如下图所示。进行调整过后的图像传送给神经网络。下图显示了图像的调整大小操作的结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicS08ZFjdibpLIeOjg73NAOysF9VMmzyoLoeffxRAvsGzuwPbVY7kOvJwlw2ibUezJwict8sov4OXdew/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;接下来我们将讨论我们的神经网络架构。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;网络架构&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们设计卷积神经网络架构的灵感来自于 NVIDIA 的论文《用于自动驾驶汽车的端到端学习（End to End Learning for Self-Driving Cars）》。我们的模型和 NVIDIA 的模型的主要区别是我们在每个卷积层之后又使用了最大池化（MaxPooling）层来减少训练时间。有关我们的网络架构的更多详细信息，请参见下图。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicS08ZFjdibpLIeOjg73NAOymMl2RdEPFnnVwBeURZx7h8B6FEBxlIZpZhXVvAITlSbLcHalyQYszg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;训练&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;即使在对训练图像进行裁剪和调整（所有图像都进行了增强）之后，训练数据集还是非常大，所以不能将它们完全存于主存。因此，我们使用 Keras 库的 &lt;span&gt;&lt;strong&gt;&lt;em&gt;fit_generator&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt; API 来训练我们的模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们创建了两个生成器（generator），即：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;train_gen = helper.generate_next_batch()&lt;/span&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;validation_gen = helper.generate_next_batch()&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;train_gen&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;span&gt; 和 &lt;strong&gt;&lt;em&gt;&lt;span&gt;validation_gen&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt; 的批量规模是 64。我们在每个训练阶段使用 20032 张图像。应当注意，我们现在所说的图像是经过上文中所提及数据处理管道处理后生成的。除此之外，我们还使用 6400 张图片（同样也是数据处理管道处理过后的）进行验证。我们使用 &lt;strong&gt;&lt;em&gt;&lt;span&gt;Adam&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt; 优化器和 &lt;strong&gt;&lt;em&gt;&lt;span&gt;1e-4&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt; 的学习速率。最后，当涉及到选择训练代数（training epoch）值的时候，我们尝试了几种不同的数据，如 5、8、10、25 和 50。然而，我们发现 8 在训练和验证轨道上的效果都很好。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;结果&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在项目的初始阶段，我使用了我自己生成的数据集。该数据集很小，并且是使用笔记本电脑键盘在导航汽车时记录的。然而，使用该数据集构建的模型不足以在模拟器中自主导航汽车。后来我使用了 Udacity 发布的数据集。使用该数据集开发的模型（在增强数据的帮助下）在两个轨道上的工作情况都很好，如以下视频所示。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;训练轨道&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;iframe class="video_iframe" data-vidtype="1" allowfullscreen="" frameborder="0" height="417" width="556" data-src="https://v.qq.com/iframe/preview.html?vid=a03662bfirm&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0"&gt;&lt;/iframe&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;验证轨道&lt;/span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;iframe class="video_iframe" data-vidtype="1" allowfullscreen="" frameborder="0" height="417" width="556" data-src="https://v.qq.com/iframe/preview.html?vid=f0366jm8ct1&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0"&gt;&lt;/iframe&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;总结和未来的方向&lt;/strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这个项目中，我们对自动驾驶汽车上下文中的回归问题进行了研究。在初始阶段，我们主要致力于寻找合适的网络架构，并使用我们自己的数据集训练模型。根据均方误差（MSE）显示，我们的模型运行良好。然而，当我们使用模拟器测试模型时，它没有像预期的那样执行。因此，这清楚地表明了，MSE 不是一个评估该项目的性能的优质的指标。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在项目的下一阶段中，我们开始使用一个新的数据集（实际上，它是由 Udacity 发布的数据集）。同时，在构建我们的最终模型时，我们没有完全依赖于 MSE。此外，我们使用相对较少的训练代数（即 8 个阶段）。数据扩增和新的数据集的工作效果令人惊讶，我们的最终模型在了两个轨道上都表现出了出色的性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当谈到一些延伸的事情和未来的方向时，我想强调以下几点：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在真实的道路条件下训练模型。为此，我们可能需要找到一个新的模拟器。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;尝试其他可能的数据增强技术（data augmentation technique）。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;当我们驾驶汽车时，我们的一系列行为比如改变方向盘的角度和踩刹车不仅仅基于即时的驾驶决策。事实上，驾驶决策是基于当前的交通/道路状况在短暂的几秒钟发生的。因此，使用循环神经网络（RNN）模型（如 LSTM 和 GRU）来执行这个问题会非常有趣。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;最后，训练（深度）强化代理（reinforcement agent）也将是一个有趣的附加项目。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 15 Jan 2017 12:11:12 +0800</pubDate>
    </item>
    <item>
      <title>一周论文 | 多模态机器翻译</title>
      <link>http://www.iwgc.cn/link/4347272</link>
      <description>&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;span&gt;&lt;strong&gt;引&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;多信息融合是一个重要的研究趋势，尤其是对于训练数据缺乏的任务来说，如何融入其他相关信息来提高本任务的准确率是一个非常值得研究的问题。机器翻译是一个热门的研究领域，随着训练数据规模地增加，各种NN模型的效果也取得了突破的进展，google和百度均已部署上线NMT系统；融合图像、音频、视频、文本等各种模态数据的多模态研究也是一个非常热门的研究方向，本期PaperWeekly将为大家带来NMT和多模态交叉研究的paper解读，共3篇paper：&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;1、Attention-based Multimodal Neural Machine Translation, 2016&lt;br/&gt;2、Multimodal Attention for Neural Machine Translation, 2016&lt;br/&gt;3、Zero-resource Machine Translation by Multimodal Encoder-decoder Network with Multimedia Pivot, 2016&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;strong&gt;Attention-based Multimodal Neural Machine Translation&lt;/strong&gt;&lt;/h1&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="作者" style="color: rgb(67, 149, 245); max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Po-Yao Huang, Frederick Liu, Sz-Rung Shiang, Jean Oh, Chris Dyer&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="单位" style="color: rgb(67, 149, 245); max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;单位&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;CMU&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="关键词" style="color: rgb(67, 149, 245); max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;关键词&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Visual Features, Attention, Multimodal NMT&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="文章来源" style="color: rgb(67, 149, 245); max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;文章来源&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;ACL 2016&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="问题" style="color: rgb(67, 149, 245); max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;问题&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;多模态神经机器翻译，在传统的seq2seq翻译模型上，利用图像特征信息帮助提高机器翻译的结果&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="模型" style="color: rgb(67, 149, 245); max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;模型&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;在WMT16的多模态神经网络机器翻译新任务上的工作。&lt;br/&gt;提出了3种如何将visual feature加入到seq2seq网络中的encoder，从而使得decoder更好的attention到与图像，语义相关部分的模型： global visual feature， regional visual feature，paralle threads.&lt;/p&gt;&lt;p&gt;&lt;a title="global_visua" rel="gallery0" style="color: rgb(67, 149, 245); max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmm909CYrpybXBB3vCicafPTSngP0DhpPssYJMf5vpzbdZFcxDujcPdGq4q1G4ly3GhwAzO9ZTAWnQ/640?wx_fmt=png"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;global visual： 直接将VGG中的fc7抽出的feature加入到encoder的first step(head)或者是last step(tail)&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;a title="region_visua" rel="gallery0" style="color: rgb(67, 149, 245); max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmm909CYrpybXBB3vCicafPTWiaHUMibJ8wwxhftWiaAOplrp23YtQpWUABOQzIn3s2MxsXgibnicGr3IdQ/640?wx_fmt=png"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;regional visual： 先用R-CNN抽出region box的信息，再用VGG得到fc7的特征，将top4对应的region feature，以及global visual feature分别作为每一个step输入到encoder中&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;a title="parallel_threads" rel="gallery0" style="color: rgb(67, 149, 245); max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmm909CYrpybXBB3vCicafPT1RNOvtxdNic1TIWJwia2AUAxialQzNTEvpNPAx6QCY0NUlb0bBWFaYvnQ/640?wx_fmt=png"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;parallel threads: 与regional visual相对应的是，每个thread只利用一个region box的feature，和global visual一样的网络，将top 4对应的4 threads和gloabl thread一起做average pooling，每个therad的参数共享; attention则对应所有threads中的所有hidden states&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;同时本文还提出了三种rescoring translation的结果的方法， 用 1）language model 2）bilingual autoencoder 3）bilingual dictionary分别来挑选translation的句子，发现bilingual dictionary来删选翻译的句子效果最好&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="资源" style="color: rgb(67, 149, 245); max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;资源&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;数据集： WMT2016 (En-Ge)&lt;br/&gt;图像特征提取： VGG， R-CNN&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="实验结果" style="color: rgb(67, 149, 245); max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;实验结果&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;在En-Ge的结果如图：&lt;br/&gt;&lt;a title="en-ge" rel="gallery0" style="color: rgb(67, 149, 245); max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmm909CYrpybXBB3vCicafPTibgeI77NWJf95Ehib43c2ibicZ52tYyhBkowIJelGSAWXu7Wlic5UtwN8bQ/640?wx_fmt=png"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="相关工作" style="color: rgb(67, 149, 245); max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;相关工作&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;NMT： Kalchbrenner and Blunsom 2013&lt;br/&gt;Attention NMT： Bahdanau 2014&lt;br/&gt;Joint Space Learning： Zhang 2014，Su 2015，Kiros 2014&lt;br/&gt;多模态上相关工作目前并没有很多，值得快速入手&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="简评" style="color: rgb(67, 149, 245); max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;简评&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;本文提出了一种针对图像和文本结合的神经网络翻译模型，非常自然的将图像特征加入到seq2seq模型的encoder部分，使decoder不仅能够attention在文本上，同时也能够focus到图像上(global或者region)；并且模型的设计比较简单，没有加入太多复杂的模块。&lt;br/&gt;不过只是简单的将图像的特征作为seq中的一个step，并没有考虑文本和图像之间的相关关系，如joint space，相信加入joint learing会有提升。&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="完成人信息" style="color: rgb(67, 149, 245); max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;完成人信息&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Lijun Wu from SYSU.&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;strong&gt;Multimodal Attention for Neural Machine Translation&lt;/strong&gt;&lt;/h1&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="作者" style="color: rgb(67, 149, 245); max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Ozan Caglayan, Loïc Barrault, Fethi Bougares&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="单位" style="color: rgb(67, 149, 245); max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;单位&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;University of Le Mans, Galatasaray University&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="关键词" style="color: rgb(67, 149, 245); max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;关键词&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;NMT, Attention&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="文章来源" style="color: rgb(67, 149, 245); max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;文章来源&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;arXiv 2016.09&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="问题" style="color: rgb(67, 149, 245); max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;问题&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;给定图片和源语言描述的情况下，基于attention机制,生成目标语言的图片描述。&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="模型" style="color: rgb(67, 149, 245); max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;模型&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;模型有两个encoder，一个是textual encoder,是一个双向GRU，用于获取源语言文本的向量表示$A^{txt} = {a^{txt}_1,a^{txt}_2,…}$，另外一个是visual encoder,使用的是现成由ImageNet数据集训好的ResNet-50网络，用于获取图片的向量表示。$A^{im} = {a^{im}_1,a^{im}_2,…}$. Decoder部分，是两层的stakced GRU,先用attention方式，分别获取文本部分和图像部分的context向量$c^{txt}$和$c^{im}$,然后将两个向量concat在一起，作为新的context 向量$c$。&lt;br/&gt;如图：&lt;/p&gt;&lt;p&gt;&lt;a title="mul_attention" rel="gallery0" style="color: rgb(67, 149, 245); max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgmm909CYrpybXBB3vCicafPTwThgdb7WD1jEFIiahORTOkia0IEZwnCTKOfjfXY60byk60Hlwg4B70Jw/640?wx_fmt=jpeg"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;这样decoder部分的解码翻译的时候，不仅可以考虑到源语言的文本信息，也可以考虑到原始图片的信息。&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="资源" style="color: rgb(67, 149, 245); max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;资源&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;IAPRTC-12 dataset for English and German&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="相关工作" style="color: rgb(67, 149, 245); max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;相关工作&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;2014年Bahdanau的Neural Machine Translation by Jointly Learning to Align and Translate，使NMT超过了传统的PBMT，后来的NMT论文基本都是在这个文章基础上进行的改进。&lt;br/&gt;2015年Elliott的工作Multi-language image description with neural sequence models. 也是在给定源语言和图片的情况下，生成目标语言。不过并没有使用attention机制。&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="简评" style="color: rgb(67, 149, 245); max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;简评&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;该文章的创新之处，在于对图片描述文字进行翻译的时候，考虑到了图片本身的特征信息并引入attention机制。在源语言文本生成出错的情况下，因为有图片信息参考，在一定程度上，可以减轻这种错误带来的影响。不过文章并没有利用外部英德平行语料，这可以考虑作为后面的改进方向。&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="完成人信息" style="color: rgb(67, 149, 245); max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;完成人信息&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;xiaose@mail.ustc.edu.cn&lt;/p&gt;&lt;p&gt;中国科学技术大学&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;strong&gt;Zero-resource Machine Translation by Multimodal Encoder-decoder Network with Multimedia Pivot&lt;/strong&gt;&lt;/h1&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="作者" style="color: rgb(67, 149, 245); max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Hideki Nakayama，Noriki Nishida&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="单位" style="color: rgb(67, 149, 245); max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;单位&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;The University of Tokyo&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="关键词" style="color: rgb(67, 149, 245); max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;关键词&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;pivot, multimodal, NMT&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="文章来源" style="color: rgb(67, 149, 245); max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;文章来源&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;arXiv, 2016.11&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="问题" style="color: rgb(67, 149, 245); max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;问题&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;在没有平行语料的情况下，用image当作pivot来实现机器翻译&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="模型" style="color: rgb(67, 149, 245); max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;模型&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;整体上讲，模型分成两部分。第一部分是多模态embedding，采用pairwise ranking loss来定义损失函数；第二部分是用RNN来实现的decoder,跟image caption里面的decoder类似。对这个问题来说，我们的训练数据包括$i^{s}$：源端的图片，$d^{s}$：源端图片对应的句子描述；$i^{t}$：目标端的图片，$d^{t}$：目标端图片对应的句子描述，和源端用的不一样的语言。文中提出了2个模型来解决这个问题：&lt;br/&gt;&lt;a title="21-1" rel="gallery0" style="color: rgb(67, 149, 245); max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmm909CYrpybXBB3vCicafPTkW8rSj5Pvet0ZP9dObewEpbVOtJWYu9GpTDnCRVBzOY9Ig8pW20TlA/640?wx_fmt=png"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;模型1的多模态端包括了图片的encoder和源句子的encoder。图片encoder可以对源图片和目标图片通用。多模态端用$i^{s}$,$d^{s}$进行训练，损失函数为：&lt;/p&gt;&lt;p&gt;&lt;a title="21-2" rel="gallery0" style="color: rgb(67, 149, 245); max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmm909CYrpybXBB3vCicafPTcWiaNxmzWTY0Jml3EXcgCjj5iato4wfqYibYBqySk6ujXOKYv5K15axYA/640?wx_fmt=png"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;$E^{v}$表示图片的encoder(比如用VGG-16提取图片的feature), $E^{s}$表示源句子的encoder(比如用RNN)，$d^{s}_{ng}$表示和源端图片不相关的描述。Decoder端用$i^{t}$,$d^{t}$进行训练，损失函数为标准的 cross-entropy loss（称作图片损失):&lt;/p&gt;&lt;p&gt;&lt;a title="21-3" class="" rel="gallery0" style="color: rgb(37, 143, 184); max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmm909CYrpybXBB3vCicafPTJY257PqrjW2OIcRQr3nmGzKs0GYQkIGtRSibIOG9hj4dINfuVfY90FA/640?wx_fmt=png"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;模型2比模型1更复杂一点。在源端增加了一个目标句子描述的encoder。因此，在多模态embedding的学习中，损失函数增加了目标图片和目标图片描述的pairwise ranking loss.&lt;/p&gt;&lt;p&gt;&lt;a title="21-4" rel="gallery0" style="color: rgb(67, 149, 245); max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmm909CYrpybXBB3vCicafPTFVmcib5e2mdza7nybQVctzDQIPYCXfv4DmibOoZn5gliboc5WibDO2eyfA/640?wx_fmt=png"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;在decoder的学习中，模型2除了前面的公式2定义的图片损失外，还增加了目标描述的reconstruction loss，即从多模态端输入目标描述，希望通过embedding和decoder重建这个目标描述。&lt;br/&gt;&lt;a title="21-5" rel="gallery0" style="color: rgb(67, 149, 245); max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmm909CYrpybXBB3vCicafPTgDT95zsMhXLRMR2hicBibmzq7qmVv1yiabg5y65dKp693uV0RGMyUWhXw/640?wx_fmt=png"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="资源" style="color: rgb(67, 149, 245); max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;资源&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;两个Multilingual image-description的数据集：IAPR-TC12（包含2万图片以及英语和德语的描述）和 Multi30K（包含3万图片以及英语和德语的描述)&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="相关工作" style="color: rgb(67, 149, 245); max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;相关工作&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;对于没有平行语料的机器翻译，多数文章是用某种常见语言作为pivot，比如“Neural Machine Translation with Pivot Languages”, 用英语作为西班牙语法语以及德语法语之间的pivot。缺点是翻译的时候还是要经过pivot那一步。 另外，还要一些工作是用一个模型实现many to many的翻译。在这种情况下，没有平行语料的语言对也能用这个模型进行翻译。不需要经过pivot那个中间层，但是效果一般会差一点。比如“Google’s Multilingual Neural Machine Translation System”这篇文章。&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="简评" style="color: rgb(67, 149, 245); max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;strong&gt;简评&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;这篇文章的思路很新颖，考虑用图片来作为pivot，实现没有平行语料的语言对之间的翻译。训练完成后可以直接从源语言到目标语言进行翻译，不需要经过图片。但是正如文中提到的，这种方法跟有语料训练出来的翻译效果比起来还是差很多，并且翻译的句子都比较短。另外，对一些图片难以表达的信息很难通过这种方式学到。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;完成人信息&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;yun.chencreek@gmail.com&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;a title="总结" style="color: rgb(67, 149, 245); max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;span&gt;&lt;strong&gt;总结&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;交叉领域的研究总是会带给大家惊喜，交叉领域的交叉领域更是如此，这个领域刚刚开坑，欢迎各位有志之士跳坑。并且在2016年举办了第一届多模态机器翻译（Multimodal Machine Translation）和多语看图说话（Crosslingual Image Description）比赛，比赛主页&lt;a target="_blank" rel="external" style="color: rgb(67, 149, 245); max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;http://www.statmt.org/wmt16/multimodal-task.html&lt;/a&gt;, 总结性的paper&amp;nbsp;&lt;a target="_blank" rel="external" style="color: rgb(67, 149, 245); max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;http://anthology.aclweb.org/W/W16/W16-2346.pdf&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;扫码下载本期paper&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmm909CYrpybXBB3vCicafPTCCVAYsuNMVd4p8QiaJ3gBZQjeAogHTh88GT7PRe0nDicYoWyonwfWO9w/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;相关阅读&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1、&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720765&amp;amp;idx=5&amp;amp;sn=1389fc0efe57457a0e167f7215ffc6d4&amp;amp;chksm=871b0d83b06c8495b2ef85f3746a5518211edd0dc45bb8322bad32fbc197d1bfe639cac390f8&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720765&amp;amp;idx=5&amp;amp;sn=1389fc0efe57457a0e167f7215ffc6d4&amp;amp;chksm=871b0d83b06c8495b2ef85f3746a5518211edd0dc45bb8322bad32fbc197d1bfe639cac390f8&amp;amp;scene=21#wechat_redirect"&gt;PaperWeekly 第十五期---Attention模型在NMT任务中的应用和进展&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2、&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719529&amp;amp;idx=5&amp;amp;sn=c0163856784320377a52fbc18ba5ef7c&amp;amp;chksm=871b0157b06c8841f53629e5fb1e4499703b684862fa619acf2b36ce0c887c2fd1b42e4a60e3&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719529&amp;amp;idx=5&amp;amp;sn=c0163856784320377a52fbc18ba5ef7c&amp;amp;chksm=871b0157b06c8841f53629e5fb1e4499703b684862fa619acf2b36ce0c887c2fd1b42e4a60e3&amp;amp;scene=21#wechat_redirect"&gt;PaperWeekly 第七期&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;关于PaperWeekly&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;PaperWeekly是一个分享知识和交流学问的学术组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;微信公众号：PaperWeekly&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkSMlEJFo90NY8rCXr3mJMBibduVHxMKSHzQtVkHz8kNwpjCKBiccGuqLE0WpPuAbdtEs6cTF5iabpAQ/640?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;微博账号：PaperWeekly（&lt;a target="_blank" rel="external" style="color: rgb(67, 149, 245); max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;http://weibo.com/u/2678093863&lt;/a&gt;&amp;nbsp;）&lt;br/&gt;微信交流群：微信+ zhangjun168305（请备注：加群交流或参与写paper note）&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 15 Jan 2017 12:11:12 +0800</pubDate>
    </item>
    <item>
      <title>重磅 | 微软收购NLP明星公司Maluuba，Bengio将成为微软顾问</title>
      <link>http://www.iwgc.cn/link/4336298</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心报道&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：微胖、李泽南、朱思颖&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote style="color: rgb(62, 62, 62); font-size: 16px; white-space: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/blockquote&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;2017 年 1 月 13 日，微软宣布收购加拿大初创公司 Maluuba。Maluuba 由加滑铁卢大学毕业生 Kaheer Suleman 和 Sam Pasupalak 所创，关注服务于通用人工智能的自然语言处理研究。在此次收购中，担任 Maluuba 顾问的 Yoshua Bengio 也同时与微软达成了协议，进而成为微软的顾问。目前该交易的金额尚未披露。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8vVyKicyjQ1yA6SicZOZvAA1TMa0dZdE0UkFIfibUen3VDKkiaibIchiaBtR3FRTn2svE8aXEDEkP2SOMA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;公司背景&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;加拿大滑铁卢大学（University of Waterloo）以计算机学科闻名，2011 年 8 月 18 日，学校在读研究生 Kaheer Suleman 发明了一款智能程序，取名 Maluuba。同年，他与几位同学创立了 Maluuba 公司，他们最初的想法是做一款智能语音旅行工具，用户可以通过语音搜寻航班。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2012 年 2 月，Maluuba 从三星风投获得 200 万美元种子轮投资。半年后，他们的第一款产品出现在公众视野中，这款程序能把用户的语音请求转化为有用的信息或行动。虽然不少媒体将之称为「Android 平台的 Siri」，但 Maluuba 的初衷却是要挑战 Siri，而后续发展也表明，Maluuba 的确比 Siri 更出色。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Maluuba 通过绑定第三方服务来实现语音助手功能。2012 年 11 月，公司对外发布了自然语音处理 API 接口，移动开发者可以在自己的应用中添加类似 Siri 的语音处理功能。2012 年 12 月份推出了语音购物功能，用户可以通过语音进行购物。在语音助手领域，Maluuba 的步伐比较快。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2013 年，随着越来越多消费类电子产品公司和设备制造商乐于将一些新技术融入自己产品，Maluuba 也加快了与智能手机、电视、自动驾驶汽车等公司的合作。比如，LG 旗舰 G 系列手机的 voicemate 应用就采用了 Maluuba 的技术。2013 年 2 月，Maluuba 正式宣布向 Windows Phone 平台迁移。Maluuba 的 Windows Phone 8 版本拥有 Android 版本的大部分功能，例如可以搜索餐馆、影院、新闻和企业（以及进行语音购物）、设置闹钟、提醒和会议安排、打电话、发短信和邮件、指示方向和天气，甚至还集成了 Outlook 日历。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Maluuba 最初愿景是想让机器拥有人类水平的理解力。人工智能面临的重大挑战之一就是那些缺乏大规模标记数据集的领域，或者难以对相关环境进行较好模拟的领域。语言就是一个很好例子。互联网上包含有无穷无尽的网页，但上面全都是文字，没有一个地方找得到以机器能够理解的形式所书写的关于这些文字意思的内容。因此，机器学会阅读将是人工智能在处理和理解人类语言进程中一个里程碑式事件，也是一个真正人工智能必须达到的标准。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不过，Maluuba 成立之初就认识到，深度强化学习的基础研究和技术成熟尚需时日。2014 年，时机趋于成熟。标志性事件就是 DeepMind 采用了深度学习技术的人工智能程序在无需监督的情况下，就可以掌握多种电子游戏。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2015 年 8 月，Maluuba 融资 900 万加元（A 轮）用于进一步推进深度学习研究。同年 12 月，Maluuba 在深度学习重镇——加拿大蒙特利尔开设了一个新的研发实验室（有 13 名深度学习研究人员，负责人是公司 CTO Kaheer Suleman）。Maluuba 关注机器学习中的两个细分研究领域：对话和机器理解。同时，像 Maluuba 也更关心研发解决通用问题的人工智能，对解决真实世界问题更感兴趣。他们相信自己能找出更好的人机交互方式，并与蒙特利尔大学教授、人工智能专家 Yoshua Bengio 和阿尔伯塔大学教授、强化学习专家 Richard Sutton 等展开合作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前，全世界已有超过 5000 万台移动电子设备（比如，智能手机、自动驾驶汽车等）采用了 Maluuba 的自然语言处理服务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;重要成果：EpiReader&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2016 年 3 月，Maluuba 登上新闻头条。研究人员发布论文（http://arxiv.org/abs/1603.08884v1），介绍了他们最新的进展。论文描述了一个能够阅读几百个童话故事的算法。训练结束后，该算法可以正确地回答算法并不熟悉文本的多选题，准确率超过 70%。研究人员还在《哈利波特和魔法石》上进行测试，该算法能够以近似的准确率回答相关文本问题。这一成绩超过当时最好的神经网络方法 15%，也比当时最好的特征工程解决方案好 2%。Yoshua Bengio 说：「从数字上看，这是一次大的飞跃。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4 月，Maluuba 将一段技术演示视频放上了 YouTube，视频中的人工智能机器人 Marcy 在阅读了第五季《权利的游戏》梗概后，马上领会了故事的复杂情节。好比对这部美剧一无所知的普通人在简单阅读维基百科剧情介绍后，立刻弄懂了整个故事。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;iframe class="video_iframe" data-vidtype="1" allowfullscreen="" frameborder="0" height="417" width="556" data-src="https://v.qq.com/iframe/preview.html?vid=c0317lhzz68&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0"&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;技术演示表明，Maluuba 已经可以处理大批量的文字数据，并且能回答更加复杂困难的开放性问题了。在机器学习和人工智能领域，这是一个巨大的突破。Maluuba 的产品副总裁 Mohamed Musbah 表示：「人们在未来的几个月中会看到一些非常有趣的事情。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2016 年 6 月 7 日，Maluuba 在 arXiv 上发表了一篇论文《Natural Language Comprehension with the EpiReader》（arXiv:1606.02270），介绍了一种全新的机器文本理解模型 EpiReader。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在之前机器之心的专访中，Maluuba 介绍说，EpiReader 采取两个步骤来确定问题答案。第一步 (Extractor), 我们使用了一个双向 GPU 逐字阅读故事和问题，接着采用一种类似 Pointer Network 中的 Attention 机制在故事中挑选出可能作为答案备选的单词。第二步 ( Reasoner )，这些备选答案被插入「完型填空」式的问题中，构成一些「假设」，接着卷积神经网络会将每个假设与故事中的每个句子加以比较，寻找文本蕴涵 ( Textual Entailment ) 关系。简单来说, 蕴涵是指，两个陈述具有很强的相关性。因此，最近似故事假设的蕴涵得分最高。最后，将蕴涵得分与第一步得到的分数相结合，给出每一个备选答案正确的概率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最近，Maluuba 发布了一篇新的技术博客，介绍他们在通用人工智能上的研究（参阅《&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722208&amp;amp;idx=2&amp;amp;sn=0a123e1f1c922ac6fcdf502c84ceb88d&amp;amp;chksm=871b0bdeb06c82c85dfdd9b0f6a33d46ff10081d4c1f123b390eee8300c4ef95f29a49875dc8&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722208&amp;amp;idx=2&amp;amp;sn=0a123e1f1c922ac6fcdf502c84ceb88d&amp;amp;chksm=871b0bdeb06c82c85dfdd9b0f6a33d46ff10081d4c1f123b390eee8300c4ef95f29a49875dc8&amp;amp;scene=21#wechat_redirect"&gt;构建好奇的机器，Maluuba 的通用人工智能探索（附论文）&lt;/a&gt;》）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;与微软合作的原因：通用人工智能&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Maluuba 在官方博客上解释道：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;到目前为止，我们关注的领域是机器阅读理解，对话和理解以及通用（人类）智能，比如记忆、常识推理以及资讯搜寻行为。这些领域的早期研究成果加快了我们扩展团队的需求，显然，我们需要用重要资源来支持我们的团队以推进终极目标的实现。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;微软非常契合我们的公司。微软大众化人工智能的雄心让这个星球上每个人和组织与人工智能技术使用方式从根本上保持一致。微软为我们提供了将我们的研究传递给百万个人用户和公司用户的机会，他们可以从真正智能机器的出现中受益良多。另外，微软庞大的技术资源——包括后端基础架构（如微软Azure和其完备的硬件基础设施）以及工程人员将帮助我们加速研究和提供市场解决方案的步伐。简言之，我们的新拍档能让我们更加快速的走向当初的愿景。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微软也表示，Maluuba 在深度学习和强化学习方面的专业知识将帮助我们解决问题和决策系统推进我们的人工智能民主化策略，并使其可以为每个人服务——所有消费者，企业和开发者。随着最近微软在语音识别和图像识别上使用深度学习技术的巨大成果，以及今天来自 Maluuba 成员的新力量，公司相信「更好的还在后面，我们将向机器阅读和写作发起新的进攻。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此外，不久之前微软在其官方博客上开放了一个包含 10 万个问题和答案的数据集 &lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721463&amp;amp;idx=1&amp;amp;sn=6ff5c103c36e10af4362bda180c834ca&amp;amp;chksm=871b08c9b06c81dfdec9851515c91d2700719c9bdad65a3b7c831e70dd2c0978879a86d4e7f5&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721463&amp;amp;idx=1&amp;amp;sn=6ff5c103c36e10af4362bda180c834ca&amp;amp;chksm=871b08c9b06c81dfdec9851515c91d2700719c9bdad65a3b7c831e70dd2c0978879a86d4e7f5&amp;amp;scene=21#wechat_redirect"&gt;MS MARCO&lt;/a&gt;。通过将数据集免费开放给领域内更多的研究者，微软希望能够推进机器阅读领域的突破性研究。这个开源数据集的负责人 Rangan Majumder 曾说，「为了实现人工通用智能的目标，我们首先需要机器能够像人类一样阅读和理解文档。这个数据集是向这个方向迈出的一步。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微软的长期目标一直是通用人工智能，Maluuba 的研究能够助力微软实现这一宏伟目标。优势互补，微软收购 Maluuba 也就不足为奇了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;蒙特利尔的人工智能领域地位正在获得认可&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这次收购表明，蒙特利尔在人工智能领域的重要地位最近正在逐渐被全球各大公司认可。在微软之前，谷歌曾在 2016 年 11 月宣布在蒙特利尔成立一个新的人工智能研究机构，并对该市的几所大学进行了投资。值得一提的是，谷歌在这一动作中试图拉拢的 Yoshua Bengio——Maluuba 的顾问也随着这次收购与微软产生了联系。在所有大公司都在争抢人工智能领域人才的环境中，微软的努力或许另有深意。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Maluuba 表示，「没有 Yoshua Bengio 教授（深度学习创始人之一）、Richard Sutton（最重要的强化学习先驱）以及蒙特利尔日益壮大的研究生态圈的巨大帮助，我们无法走到今天。特别是，Bengion 教授为我们的研究人员的研究工作提供了非常宝贵的常规咨询和指导。过去几年中，Bengio 教授也因为他的远见——将蒙特利尔打造成人工智能研究的核心而得到了特别认可。通过蒙特利尔大学和麦克吉尔大学的研究，这座城市已经发展成为世界上最大的深度学习学术中心；现在，这个区域大学中有大约 150 深度学习研究人员。加拿大的学院、公司以及创业公司生态系统正为人工智能领域带来巨大创新，证明加拿大，特别是蒙特利尔能够与硅谷试比高下。在这一新的篇章里，我们会继续积极地与蒙特利尔以及发表世界顶级人工智能研究的学术社区合作。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;成功的秘诀&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;前一段时间，在接受机器之心专访时，Maluuba 给其他人工智能创业者和研究人员给出的一些建议或许可以作为公司迈入今天这一新篇章的重要经验之一。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;人工智能方面。我想说，此时创业正当时，也很让人兴奋，因为这里需要解决很多令人激动的问题，这个行业已经到了这样一个阶段：我们正处在解决这些问题的前沿，而且公司非常高兴支持真正的创业者来解决这些问题，无论是资金上还是策略能力上。现在成为这个领域的创业者，很让人激动。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;br/&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;但是，我想提醒需要注意的几点。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;br/&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;首先，区分事实和虚构。很多人工智能领域里的信息都过分夸张了，因为对现状缺乏基本了解，而且对人工智能持过于兴奋态度也源于人类本性。区分事实和虚构能帮助你真正理解自己所处的位置，帮助你准确定位所要解决的问题。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;br/&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;第二点就是挑选别人没有解决过的独特问题，然后试着如何用人工智能加以解决，看看自己解决的情况如何，和别人有什么不同。我认为几年后，这个领域的公司就要比拼：看谁能利用最先进的技术做出没有人想到新产品，解决别人没有解决的问题。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;援引 T.S. Eliot 一句话作为本文的结束：「In our end is our beginning.」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心原创，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Sat, 14 Jan 2017 11:05:11 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 麦肯锡发布自动化未来报告：深度预测其对就业和市场的影响（附报告）</title>
      <link>http://www.iwgc.cn/link/4336299</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自麦肯锡&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;自动化正在发生，并且必将给全世界的商业和经济带来巨大的好处，但全面的自动化不是朝夕之间就能实现的。近日，麦肯锡全球研究所（McKinsey Global Institute）发布了一份报告《A FUTURE THAT WORKS: AUTOMATION, EMPLOYMENT, AND PRODUCTIVITY》，该报告表示如果要实现自动化的全部潜力，就需要人们和技术携手并进。机器之心在此对这份报告进行了简短的介绍，报告原文请点击文末「阅读原文」下载。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;近来在机器人、人工智能和机器学习领域的进步将我们推到了新的自动化时代的边缘。现在的机器人和计算机不仅能在很多体力工作上比人类做到更好更廉价，而且它们也正越来越胜任需要认知能力的任务，比如进行判断和决策、感知运动、甚至驾驶汽车。自动化将会改变我们每一个人的日常生活，不管你是矿工还是园艺师，还是银行家、时尚设计师、焊工或是 CEO。但自动化还需要多久才会成为工作领域的现实？它们对全球经济中的就业和生产又会有什么影响呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;麦肯锡全球研究所（MGI）正在进行一场持续的关于自动化技术及其影响的调研项目，该项目今天发布了一份新报告《Automation, employment, and productivity》，这里简单介绍一下其中的几个关键发现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自动化可以通过减少错误和提升质量与速度来帮助企业提升效益，并且能在一些情况下实现超越人类水平的收益。自动化也有助于提升生产力，正如我们在历史中已经见证过的一样。当生产力增长乏力时，这就能为经济的增长和繁荣提供必需的推动力。它也将有助于抵消许多国家劳动人口比例下降的影响。基于我们的情景建模（scenario modeling），我们估计自动化每年将能给全球生产力带来 0.8% 到 1.4% 的增长。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;分析自动化影响的合适程度是分析某种职业中的单个活动，而不是直接分析整个职业。每一种职业都包含了很多种活动，每一种都有不同的自动化需求。对于目前已有的技术，只有很少的职业（少于 5%）有可能实现完全自动化。但是，几乎每一种职业都有可能实现部分自动化，即其中的一部分活动是可以自动化的。我们估计全世界工作场景中的大约一半的活动都可能通过现在已有的技术实现自动化。这大约相当于 16 万亿美元的工资。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最有可能被自动化的活动是在高结构化和可预测环境中的体力活动，以及数据的收集和处理。在美国，这些活动占据了经济中总活动的 51%，大约相当于 2.7 万亿美元工资。它们在制造业、住宿和食品服务、零售领域最为普遍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而且并不只是低技能、低工资的工作会被自动化；中等技能和高收入、高技能的工作也有一定程度的自动化潜力。随着人们工作流程中的单个活动被自动化所变革，人的工作将会成为机器工作的补充；反之亦然。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管如此，自动化并不是一朝一夕就能实现的。尽管存在这样的技术潜力，但我们估计要让自动化对当前工作活动的影响完全显现，可能还需要很多年的时间。自动化的速度及其对工作者的影响将会因活动、职业、工资和技能水平的差异而有很大的不同。决定自动化的速度和影响程度的因素包括：技术能力、技术成本、与劳动力的竞争（包括技能和供需动态）、效益增益（包括但不限于劳动力成本节省）、社会和监管的接受度。我们的情景模型表明今天我们半数的活动将在 2055 年被自动化，但因为各种影响因素和经济状况的不确定性，这个时间可能会早 20 年，也可能会晚 20 年。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在宏观层面上，自动化的影响可能会很缓慢，比如在整个行业或经济内的影响。但在微观层面上，自动化的影响是相当的快，因为个人工作者的工作可能会被自动化，或者是公司被使用自动化的竞争对手所摧毁。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然目前大部分关于自动化的争论在于它会造成大规模的失业，人们还是会继续与机器一起工作，从而促进人均国内生产总值的增长，这是全球每个国家都在追求的。因此，我们对生产力的评估是假设被自动化取代的人们会找到其他的职位。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大多工人必须要做出改变，而且我们预期业务流程也会发生转变。然而，自动化技术能造成的劳动力的转换（shift）规模在过去几十年中并非史无前例的。它的规模类似于 21 世纪，科技在发展中国家农业劳动力上造成的长期转换的级别。这些转换并没有造成长期的大规模失业，因为它伴随着新类型工作的创造。但我们的分析表明，人类劳动力还是所需要的：我们评估所能获得的全部生产力是只有在人类与机器一起工作的情况下得到的。这反过来将会转变劳动力，需求工作人员与技术有新的配合。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Sat, 14 Jan 2017 11:05:11 +0800</pubDate>
    </item>
  </channel>
</rss>
