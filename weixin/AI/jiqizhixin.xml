<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>AI Talk | 百度IDL院长林元庆：击败最强大脑王昱珩背后的技术是什么？</title>
      <link>http://www.iwgc.cn/link/4447945</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编辑部&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;本周五《最强大脑》最后一场人机大战——视频捕捉影像的人脸识别完美谢幕。最后一场比赛中，小度战平人类顶级微观辨识高手王昱珩。至此小度以两胜一平的好成绩进入年后的脑王大战。我们专访了百度深度学习研究院院长林元庆，请其解读视频识别的关键技术点及整个小度团队的幕后工作。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;iframe class="video_iframe" data-vidtype="1" allowfullscreen="" frameborder="0" height="417" width="556" data-src="https://v.qq.com/iframe/preview.html?vid=s0368iawvtu&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0"&gt;&lt;/iframe&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;作为机器之心新栏目 AI Talk 的一部分，我们对这次视频专访的内容进行了剪辑，完整采访可见下面文字整理版本。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：这次视频识别主要使用了哪些技术方法？识别过程的实现路径是怎样的？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;林元庆&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：我们的系统首先对视频里出现的人脸进行检测和跟踪。直观的来讲检测和跟踪，就是系统去看视频里有几个人的人脸各自在哪里，是怎么移动的。系统在这个检测跟踪过程完成之后，在每个人的人脸图片里挑选几张质量比较好的去做下一步的人脸识别。通过随后的识别过程识别出这些照片中的人具体都是谁。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：对视频内容进行结构化分析时，如何用有效的特征对内容进行表达？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;林元庆&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：其实我们这个系统主要由两部分组成，一部分是实现检测和跟踪，另外一部分就是人脸识别识别。我们都是通过深度学习的方法学习出有用的特征。目前在特征提取上，我们很少运用人为设计的特征去对内容进行表达，大部分的特征都是运用深度学习，从海量数据里，通过机器学习去学到这些有效的特征。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：与静态识别相比，动态人脸识别有哪些区别？主要挑战是什么？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;林元庆&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：动态人脸识别比静态更为困难，动态的人脸识别里需要能检测出不同角度的人脸，而且动态的人脸整体质量偏低，有些帧的图片甚至会是模糊的，因为动态的情况下人是有移动的。那么在这些挑战下，我们需要有比较好的检测算法，在很多单帧的静态图片里检测出人脸图片质量比较好的图片，然后用这些质量比较好的图片去做下一步的人脸识别。主要的挑战也在这里，怎么更好的检测出人脸以及怎么判断出质量比较好的可以用于识别的人脸图片。另外，动态识别的视频每一秒有 30 帧，这里的又一个挑战是如何做到人脸实时检测。在静态人脸识别里，你需要做的只是处理一张图片；而动态的情况下你有很多图片，那么怎么快速计算，怎么选择出质量最好的图片甚至多帧的学习融合都是需要仔细考虑的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：这一技术训练时对硬件、数据要求高吗？所使用的样本量规模和训练时间的情况是怎样的？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;林元庆&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：我们现在开发出的这套人脸识别系统，在设计时特别考虑弱光条件下和有遮挡条件下人脸识别的实现。这次比赛里所用的人脸识别系统，是通过两个步骤来实现的。第一步是通用人脸识别模型的训练，我们花了很大力气来做。比赛系统里的模型，我们是用大概 200 万个人，总共 2 亿张的照片来训练的。2 亿张照片本身是一个非常大的数据，需要非常大的计算量和非常好的算法，能做到这一点借助了百度的 PaddlePaddle 平台，通过 PaddlePaddle，我们可以在多台机器上实现高效的并行计算。在这一步我们得到一个人脸识别基础能力非常好的通用模型。有了通用模型，下一步就是实现在不同的场景下的人脸识别。第一期的人机大战，比的是跨年龄的人脸识别，这一期比的场景是有暗光和遮挡的场景。我们在通用模型之上会特别去准备一些跟这个环境相近的数据集来进一步训练通用模型，最后得到弱光和遮挡环境下较好的人脸识别系统。后面的这个数据集相比之前的通用模型的数据集就小很多了，这样的数据本身也比较难收集，我们最后的数据集大概是 1 万人的量级。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：王昱珩在答题过程中其实改过答案但最终改错了，机器会出现类似的问题吗？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;林元庆&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：机器可能不太会出现（这种情况），因为唯一输入给机器的就是图像或视频信息，机器通过算法将要考虑到的因素已经都考虑了，最后是得到一个置信度也就是 Confidence Score，分数比较高的会被机器认为就是正确答案。虽然分数也是综合了非常多因素，但机器没办法再回去想出另外一个分数来。就像我们第一期里双胞胎的情况，机器最后决定什么分数就是什么分数，没办法再改。人不一样，除了看图像还会联想到一些信息，最终进行综合考量，但这会带来好结果也会有不好的结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：听说因为和王昱珩比赛而加班加点升级了算法，具体是做了哪些升级呢？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;林元庆&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：我们做系统升级不是因为要和王昱珩比赛，是我们原本就计划要做。所做的升级其实是针对这次比赛的内容—有遮挡的人脸识别。在这次比赛中，要识别的人脸可能戴口罩、戴墨镜甚至戴帽子，如何处理这些有遮挡的人脸图片，在人脸识别领域里还是悬而未决的问题。针对遮挡情况，我们也特地设计了一些比较新的算法。比如我们将人脸分为 7 个部分，每个部分的遮挡情况都是根据那个部位在深度学习的输出特征来描述这个部位被遮挡的程度，根据不同部位遮挡程度的不同决策出哪些部位是可以有效提供人脸信息的，进而可以用于人脸识别。简单来讲，就是让模型了解不同部位被遮挡的情况，然后根据情况来使用这个部位的信息。我们训练的是一个端到端的模型，输入照片后系统自动得到不同部位的遮挡信息，最后做综合决策。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：在这一过程中，小度如何用到推理能力？目前具备的推理能力水平如何？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;林元庆&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：小度在别的方面可能会用到更多的推理能力，比如说自动驾驶。但在人脸识别方面，它的推理能力还是比较初级，比如我们会去分析哪一些部位可能被遮挡，这些部位需要怎样根据这些信息作出最后的判断。从不同方面得到的信息进行相互作用也是需要通过数据和模型去学习出来，因此，在模型设计时就会涉及一些比较基本的推理能力，让小度通过数据去学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：要获得理想的识别结果，对人脸角度和像素分辨率都有什么样的要求？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;林元庆&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：其实我们在左右转向 45 度之内都能做到非常高精度的识别，但如果角度太大，比如说半脸就会很难了，精度会下降。从上往下看或从下往上看，也属于比较难的，上下 15 度左右还比较好处理，但如果角度太大，难度就会比较大。当然，我们也有计划再扩展算法。相比像素分辨率，其实更重要的是图片质量，如果图形都糊了，人都很难分辨出五官，（对机器来说）就更难了。但只要有足够的分辨率，放大之后你还能看到五官，比如说眼睛能看到瞳孔，基本上还是能够识别的比较好，质量越高肯定识别越好。当我们做系统（整体设计）的时候，其实可以想办法提高画面捕捉的水平，比如摄像头可以装得低一些，从一体化的角度来考虑怎么才能取得比较高的分辨率。比如说在一些机场，为了能在人路过时捕捉人脸进行识别，他们把摄像头放在一个大屏幕上，人走过的时候常常会看一下屏幕，这样就有可能捕捉到一个人脸稍正的画面。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：节目中第一题和第三题，小度都答对了，但第二题被形容错得很离谱，是什么原因造成的？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;林元庆&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：错的很离谱可能指的是，正确答案是一个相对比较胖一点的人，但是小度给的答案是一个胖瘦正常的。这是因为小度可能看的不单单是脸型，看到更多是比如鼻子的形状、嘴角的形状，对小度来说，它根本没有信息来判断人的脸型是不会变的，举个例子来讲，像我们在第一期跨年龄识别里看到，人的脸型完全是会变化的，小度无法得知它看到的这个照片跟库里的照片相比，只是几天或几个礼拜、几个月之前拍摄到的，它只能从原来学习出来的信息里进行判断。其实我们 IDL 工程师们后来仔细去看了结果，除了脸型（胖瘦）因素之外，其实也挺难确定那个人是不是就是最后的人，通过电视仔细看照片也很不容易，反倒是小度的答案的嘴型更接近真实答案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9iaSgfTFRChrskKuUMbnjjpwJujVajoOdibLMNPwTnrPRyQKLhJDeLEoDJV4pP3jEEkfmhdfSeiaYKA/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：在百度，这项技术目前仍然停留在技术研究阶段还是即将成为一个产品化的系统？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;林元庆&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：之前，人脸识别主要还是用在百度已有产品覆盖到的场景里，包括全网的人脸搜索、图片的人脸搜索，在百度之外做的非常少。但是从 2017 年开始，我们有计划要把百度人脸识别系统在公司之外用起来，包括我们现在跟景区在做的人脸闸机系统，游客进景区以后就可以刷脸进出，这在乌镇已经落地。在安防领域，水哥曾帮山东省公安厅从监控的视频里找到罪犯，但水哥只有一个，而这个系统其实已经可以做到非常好的识别精度，我们也希望它能够在更多的安防领域用起来。我们希望技术能得到广泛的应用，这也是我们今年需要努力的重要方向，争取把我们的技术落地到更多的实际生活中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：能否回顾一下这次小度人机大战的准备过程？比如团队筹备了多长时间？涉及到哪几个部门的配合？中间遇到过什么状况，如何解决的？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;林元庆&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：8 月底，节目组到百度来邀请我们参加，当时他们说希望做跨年龄的人脸识别和声音的识别，还带了一些测试数据，我们在一个会议室里面现场做了识别精度的测试。（当时）在跨年龄人脸识别方面做了 8 组测试，结果是对了 7 组，是节目组当时很震惊，觉得百度的人脸识别技术确实做得很好。事实上，当时我们还没有针对这个产品场景做过优化。这次提前测试之后，节目组在同时接触的国内几家人工智能领域的公司中选择了我们。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关于到底要不要参加，我们考虑了一两个星期，对我们整个团队来说，参加还是有一定风险。一方面，我们对自己的技术很有信心，也想看看百度经过这几年人工智能的积累，跟人类顶级选手比水平如何，即便输掉对技术的人来说也没什么，因为我们做实验也有失败的时候；但另一方面，这些选手很强，现场比拼确实没有十全的把握，我们还是会有压力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;决定参加之后，我们成立了一个二十几个人的课题组。其实这个项目非常复杂，不单单是算法，还包括人脸识别、声音的识别，我们为了节目的趣味性还做了一些技术的展示，比如与主持人、嘉宾的互动，其中用到的是个性化语音合成等等。大家都在一个会议室里面做封闭开发，除了技术开发我们还要跟节目组协调。为了让观众更容易理解，要做很多工作，公司内部涉及到很多跨部门协作，IDL、AI 平台部、语音技术部、系统部、品牌部、众测等。需要百度众测帮我们收集很多数据，需要海量的计算需要 GPU 的调配，包括配合节目播出做的 H5 页面让大家来亲自体验技术...... 总之，一个比分背后有非常多准备工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：在整个三期节目录制过程中，团队的状态是怎样的？接下来对小度的表现有什么预期？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;林元庆&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：重中之重的是算法，也就是系统的精度，我们核心成员一直在加班，经常忙到 3、4 点才回家，有时早上 7、8 点，回去睡一觉就回来再继续。因为最后非常非常紧张，大家承受的压力很大，我们第一期在最强大脑节目录制现场，我站在后台，节目组的人开玩笑说，元庆看着你好紧张，我说是很紧张。小度对错一道题，对于科学家来说跟平常的实验一样，我们做科学研究经常也会给人家做 Demo，一般是面对几十人到几百人做 Demo，压力也会蛮大的，但这次要做的 Demo 是展示我们的技术，面对是几千万上亿人，这个压力可想而知。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们现在赢了两局平了一局，根据节目规则，我们会进入脑王决战，我们收到的通知是脑王决战会在 3、4 月份举行。我们会再重新开始备战，但具体是什么节目内容，我们现在还不知道，唯一知道的是最后一期可能全部是人机大战，并且可能会安排 3 个选手跟小度 PK，这又给我们带来非常大的压力。节目给出的极端场景，比如跨年龄识别，我们之前其实没有做过，我们对人脸识别理解很深、技术也做的很好，但能在多大程度上把这些基础能力用在极端情况中，我们都是没有十全把握的。不过，相比（几个月之前）接下这个项目的时候，通过两个月准备，我们现在再去测这套人脸识别系统，比如给 10 个测试例子，小度已经做到完全比我们要好很多的程度。因此我们对脑王决赛充满信心，也非常期待。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicS08ZFjdibpLIeOjg73NAOyRulPA7upc5nBHVHQV4nEe1VYKJ0oCNRDHIgfRdEjDQg3atmJKUrSEg/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote style="color: rgb(62, 62, 62); font-size: 16px; white-space: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p&gt;&lt;span&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;「AI Talk」&amp;nbsp;是机器之心最新出品的视频访谈栏目，旨在邀请国内外人工智能顶级专家分享对技术和行业的观点，为大家呈现更为直观、丰富的内容。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 22 Jan 2017 19:28:52 +0800</pubDate>
    </item>
    <item>
      <title>观点 | 暮光女主发表人工智能学术论文，引来业内一片嘘声</title>
      <link>http://www.iwgc.cn/link/4447946</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Quora&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀、微胖、朱思颖&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;近日，电影&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722569&amp;amp;idx=3&amp;amp;sn=6ca8e1b70a80f57ad3d356ac48960c7e&amp;amp;chksm=871b1577b06c9c61a3637aa4a4bcba91bf5544e0f020d6b31016f7ce2d45b1c0ac6eb187c41b&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722569&amp;amp;idx=3&amp;amp;sn=6ca8e1b70a80f57ad3d356ac48960c7e&amp;amp;chksm=871b1577b06c9c61a3637aa4a4bcba91bf5544e0f020d6b31016f7ce2d45b1c0ac6eb187c41b&amp;amp;scene=21#wechat_redirect"&gt;《暮光之城》女主角 Kristen Stewart 的名字出现在了一篇 arXiv 论文的作者名单上&lt;/a&gt;，引起了极大的关注，一些读者将其评价为「颜值与智商双高的女神」。但抛开学术论文+电影明星的「自带光环」，这篇论文到底有多好呢？这个值得关注的问题已经出现在了问答网站 Quora 上，并且也吸引到了一些业内人士的观点，机器之心从中筛选了一些值得关注的答案进行了编译，了解更多观点可查看问题原地址：&lt;span&gt;https://www.quora.com/What-do-people-who-work-in-machine-learning-and-AI-think-of-actress-Kristen-Stewarts-research-paper-on-AI&lt;/span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;问题：机器学习和人工智能领域的业内人士怎么看待女演员 Kristen Stewart 的人工智能研究论文？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;回答者一&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：Xavier Amatriain，前机器学习研究人员，现 Quora 的首席工程师&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里涉及两个不同的问题：（1）我们如何评价这篇论文？（2）怎么看待这次「上头条」？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先回答第二个问题，因为我觉得这可能是问题的根本。今天人工智能的热度有一部分属于炒作，我也知道普通出版物（这里指报道这篇新闻的 Quartz——编译者注）会对一篇能将人工智能和好莱坞明星联系起来的论文感兴趣。也就是说，我认为 Quartz 的报道是把双刃剑。必须承认，我也在 Twitter 和 Facebook 上分享了这篇文章。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先，请注意，Quartz 使用了「发布（release）」而不是「发表（publish）」。这个表述很好。后来，他们也解释了在 ArXiv 上发布论文并不意味着通过了同行评议或者被研究社区认可。读者应该记住，尽管 ArXiv 降低了提交的要求，但是，他们并不为论文质量负责。简言之，即使提交一份研究草稿或课程计划都是可以的。现在，在论文被其他刊物或会议接收前，都应该在这个语境中看待这篇研究。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二，正如其他读者指出的，这不是「头条」所说的人工智能研究论文（research paper），而是一篇应用论文（application paper）。这完全是两码事。虽然这并不意味着它是一篇糟糕的论文，但是，需要根据不同的背景加以评价，因为该论文并没有介绍任何新的东西。据此，人工智能研究人员怎么看也就不是真的那么有关系了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我觉得自己多少有点资格发表一下看法。尽管我是做深度学习研究的，但是我发表的论文实际上都是应用方面的，从推荐系统到多媒体系统。实际上，我和一些艺术家合作发表过论文，其中一些论文还发表在了国际会议和期刊上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由此，我现在回答第一个问题：我怎么看这篇论文？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;呃，不幸的是，我对它没多大印象。作为一篇应用人工智能技术的论文，其价值有限。也存在许多问题，这些都不利于它被绝大多数会议接收：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 从这一应用中获得的经验真的很难泛化，这篇论文甚至一开始就没有这个目标。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 研究方法的比较也非常有限。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 参考不够。特别是，作为一篇应用型论文，对现有的人工智能/机器学习领域内的论文参考不够。作者应该参考其他利用人工智能进行艺术创作的研究方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;也就是说，比如，这篇论文可以提交给研讨会做「poster」。考虑其格式和长度，我猜这可能也是该论文的作者的想法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，既然其他回答中已经讨论过 Kristen Stewart 是否是名副其实的合作者这个问题，那么，我也来回答一下：肯定算是名副其实的合作者。还是刚才说过的，这是一篇应用论文（或者说艺术创作应用论文）。艺人的作用与研究人员的作用不相上下，甚至超过后者。实际上，分享一点小秘密，我非常确定在该论文里描述的 Kristen 的贡献比许多在博士论文上署名的知名教授和研究人员还多。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9iaSgfTFRChrskKuUMbnjjpO4v5cEJIibSLDkxurcs5icMHyppXN5Hrno6Cfkc4I1aiaJDVsFgU6rYBA/0?wx_fmt=png"/&gt;&lt;em style="color: rgb(136, 136, 136); text-align: justify;"&gt;&lt;span&gt;这是一篇我与艺术家合作的论文，几年前发表在 IEEE Multimedia 上。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;回答者二：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;Shashwat Verma，新加坡-麻省理工学院研究与技术联盟研究实习生&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;听说过 Prisma 吗？这个 App 将你上传的照片按你所挑选目标图片的风格进行重画。关于这个 App 的实现原理的论文是由 Gatys 等人完成的 https://arxiv.org/pdf/1508.06576v2.pdf&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那些还不知道Prisma做什么的人可以看下面的例子：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9iaSgfTFRChrskKuUMbnjjp63Diaw0uTpkglkT2hA26eppPsqBNQKcIgxMjhqEs3yfjuATOAPJc8IA/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一步：上传一张图片&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二步：挑选一种风格&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第三步：欣赏重画为目标风格的图片&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Prisma 是通过卷积神经网络（CNN）完成上述的图片重画过程。我在上面所提到的论文是运用深度学习来做一些艺术性的创作工作而不是给猫分类这样的任务。这是一篇很好的论文，论文的写作很用心并且你可以运行出论文里所提到的结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Krister Stewart 的论文只是「延伸（extend）」Gatys 等人的工作。首先，她的研究论文不是一个真正意义上的关于人工智能的论文。他们甚至很可能都没有做一篇人工智能论文的意愿。让我们来分析这篇「人工智能」论文中第一个也是唯一一个数学公式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;Experimenting with the style transfer ratio led us to conclude that it needed to be exponent form for meaningful creative exploration. Subjectively, this exponential form gave us a useful measure of unrealness, u , a rough way to map how impressionistic the style transferred image looked: style transfer ratio = 10^u&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以上内容为论文节选，唯一出现的数学公式为：风格转换系数=10^u&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Kristen Stewart（可能是这篇论文最重要的一个作者）的论文的「贡献」根本谈不上是「贡献」（contribution）。评论结束。Gatys 的论文中早有谈及这个公式，甚至有对改变风格转换系数值所依次得到的效果呈现图。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9iaSgfTFRChrskKuUMbnjjpM5Suq0oxcSx5SIibxUFicS66nibU3cCqTdocib3ZWWOtpZpFVZxGe951ag/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9iaSgfTFRChrskKuUMbnjjpGBBTIUoTal5s5xAfqgUWPuHAhb7xShvpqwXczqobpjwIic0S7lPxCjQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里补充给大家 Kristen 论文中的风格转换图（上）以及 Gatys 论文中的风格系数改变效果图（下），大家可以对比来看。（编译者注）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他们在论文中提到几个其他贡献，我相信，对于一篇论文来说，这些也是不够的。文中谈到几个参数（不是超参数）以及如何调这些参数。这完全不能构成一篇人工智能论文。他们只是把自己的工作像写博客那样让所有人知道。我个人没有发现他们论文中任何的价值点。没有一点能对我既有知识的进行扩充。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是，这篇论文或许对那些打算在电影制作中用深度学习技术实现风格转换的人有用，对那些需要调整参数来得到足够好的产品输出图片的人也有用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你真的想知道 Kristen Stewart 论文中那堆东西是怎么实现的或者说 Prisma App 的原理，那么你去读 Gatys 等人的论文吧。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，我认为，Kristen 甚至没有做任何与深度学习相关的技术工作。她很可能只是挂名在论文下面，就如那些没有参与任何论文研究的教授在论文下面挂名一样。Kristen 是一个演员不是一个深度学习工程师。这也是对该论文的作者、研究工程师 Bhautik J Joshi 的批评。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在我的分析里也许有错误的地方，非常欢迎大家挑出我错误的地方。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;加油！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;回答者三：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;Roman Trusov，Facebook 人工智能研究（FAIR）的 2016 年实习生&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这不是一篇研究论文，也不是关于人工智能的。唯一真实的部分就是「Kristen Stewart」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他们所做的：下载一个预训练了的直接可用的架构，然后在他们的图像集上运行了一下。你不需要为此做任何训练。要解决的问题是找到一个足够轻量的解决方案（vgg16 vs vgg19）以及设置一下去噪例程（denoising routines），这纯粹是个技术活儿。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果去掉「Kristen Stewart」，在机器学习领域里，没人会看把这篇文章两遍，仅此一点就可以判断出里面有多少科学成分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除此之外，试着减小 Erdős–Bacon 数字是一个不错的尝试，显然，这是真的。或许也能鼓励更多的女性踏入计算机科学领域。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在，是时候行动起来了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;回答者四：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;Alex Seewald&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Stewart 这次完成的工作更像是研究生的课程期末作业、人工智能爱好者发布的技术博客或本科生论文（thesis），却不像学术出版物。神经风格迁移（Neural style transfer）和与之相关的一切已经完成研究了。他们提到在实践中什么有效和无效的内容，对那些打算使用神经风格转移的人来说，是一些准确的信息（我在运用风格转移时，也有相似体验）。但是，说「在这些条件下，x 奏效但是 y 却不能」，这种深度的研究不能算真正的科学研究。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Kristen stewart 参与论文的事情让人们想知道她是如何参与的。通常仅列举作者名字的做法并不会真的给你这方面的答案。通常也没啥机会怀疑某人是否参与过论文。这一次，我并不相信，但是我想相信。我希望能在 CVPR 会议上遇见 Kristin Stewart。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 22 Jan 2017 19:28:52 +0800</pubDate>
    </item>
    <item>
      <title>学界 | 微软提出PrivTree：利用算法保护位置隐私</title>
      <link>http://www.iwgc.cn/link/4447948</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自微软&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀、蒋思源、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;打车、导航、外卖、AR 红包等各种基于位置的应用已经成为我们日常生活的重要组成部分，但位置的隐私安全也随之成为了我们需要关注的问题之一。近日，微软亚洲研究院高级研究经理 Winnie Cui 在微软研究博客上发文介绍了他们为位置隐私安全所提出的一种新算法 PrivTree。点击文末「阅读原文」可查阅相关论文。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据科学家 Anthony Tockar 在西北大学攻读硕士学位期间曾经尝试了一个研究，成功利用网上公开的数据追踪了纽约市的名人，详情可查阅：https://research.neustar.biz/author/atockar/。通过交叉参考（cross-referencing）名人在纽约市搭乘出租车的公开新闻和照片，Tockar 找到了名人搭上出租车的地点和目的地位置，以及他们为此支付了多少钱。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个案例说明，基于位置的服务（location-based services，即根据 GPS、IP 地址和 WiFi 网络映射获取用户的位置数据并基于其提供服务）可能会是隐私的一个噩梦。但它们也可能具有非常重要的价值，能够为用户提供实时导航、本地天气、基于地理位置的定向搜索结果等等有用的功能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 2011 年微软的一项调查《位置的使用和感知》（参阅：http://thelbma.com/research/3/microsoft-location-usage-and-perceptions/）中，我们发现有 94% 的消费者认为基于位置的服务很有价值。但是，这个调查还发现 52% 的用户对于与地理位置有关的数据隐私问题有所担忧。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;隐私问题现在是研究界的焦点之一。南洋理工大学教授 Xiaokui Xiao（萧小奎）说：「如今的计算机算力和公开可用的数据让我们可以更加简单地根据数据识别出个人。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;近日，Xiaokui Xiao 教授团队与位于北京微软亚洲研究院的 Xing Xie（谢幸）团队一个合作项目发现了有可能有可以缓解这种隐私问题的方法。这个联合团队提出了一种名叫 PrivTree 的数据操作技术，其可以对地理位置数据进行预处理以保护个人的隐私。之后，这些被隐私保护的数据可以被用在任何前瞻性分析（prospective analysis）之中，甚至可以公开发布，而不会有泄漏用户隐私的风险。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;PrivTree 可以通过数学的方式对个人的地理位置信息进行模糊化处理，同时还能在整体上维持该数据集的整体精度。在下面的例子中，数据集中的个人被投射到了一个由他们的地理位置坐标提供的地图上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9iaSgfTFRChrskKuUMbnjjpDb5mls5LicBlVPb2IckSShiacpGbUodexiasNktA2SgpC5RZggark4ib8g/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;其中每一个标记都代表了该地理位置数据库中的一个个体。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;接下来，PrivTree 会经历两个阶段来实现对单个个体的地理位置信息的模糊化处理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;阶段 1：地图分区&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9iaSgfTFRChrskKuUMbnjjpzpy4uLQesaZ6yDhTKSKZNOicG5skE7JbjPpr6mcf9kqSOluRj6wG0pw/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;该地图会基于数据点的密度而被分割成一些子区（sub-regions）。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;阶段 2：地点扰动&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9iaSgfTFRChrskKuUMbnjjpCMgEPy3WwKhFzBbr2QfTH49A5icMzzFYUWdicsLSDIjvWUIKflovfCxg/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;使用统计学分析，个体会按扰动方案（perturbation scheme）被随机移除，在添加或搅乱来保证隐私性的同时保证统计学的准确性。在对每个子区进行位置扰动（location perturbation）后，新的地理位置数据库就可以使用了。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这将产生一组新的数据点，并且它和原数据遵循类似的分布，只不过每个参与者真实的地理位置已经被掩盖了。然后经过隐私保护的数据将作为 PrivTree 的输出。PrivTree 可以扩展支持各种类型的地理位置数据，例如将你日常慢跑的线路上传到健康应用软件。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;研究论文《PrivTree：一种用于层级分解的差分隐私算法（PrivTree: A Differentially Private Algorithm for Hierarchical Decompositions）》已经被 ACM SIGMOD 2016（世界顶级数据管理会议）接收。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Xiao 教授谈到了与微软研究员之间的合作：「微软亚洲研究院在管理大型定位数据上的专业性在此项目成功上扮演着重要角色，比如北京的出租车数据。它帮助了我们开发、测试模型。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Xiao 教授计划进一步将 PrivTree 技术融合到微软的定位技术中，从而提供隐私保护。微软亚洲研究院的高级研究员 Xing Xie 教授也参与到了这一项目中，他说：「数据隐私是云计算时代的重大挑战，特别是包含大量个人隐私内容的用户定位数据。我们希望这一研究能有所贡献，并最终为每个人带来更安全的世界。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;论文：PrivTree: A Differentially Private Algorithm for Hierarchical Decompositions&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9iaSgfTFRChrskKuUMbnjjpJu7doIIZCIbXomJTKS5TV7S8FUIOSurdXCpGgZdlzS5aEDm5upH7IQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：给定 Omega 域上定义的一个元组集合 D，我们研究了在 Omega 上构建直方图（histogram）以逼近 D 中的元组分布的差分隐私算法（differentially private algorithms）。对于该问题现有的解决方案大多数都采用了一种分层分解方法（hierarchical decomposition approach），其递归式地将 Omega 分成子区域并计算每个子区域的有噪声元组数，直到所有的噪声数都低于一个特定的阈值。但是，这种方法需要我们&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;(i) 在 Omega 的分割中的递归深度上施加一个限制 h；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;(ii) 设置每个计数中的噪声，使之与 h 成比例。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;h 的选择是一个非常严重的难题：h 太小会导致直方图粒度太粗糙，h 太大则会导致当在确定一个子区域是否应该被分割时在元组计数中出现太多的噪声。此外，h 不能直接基于 D 而进行调制；否则，h 自身的选择就会暴露隐私信息和违反差分隐私。为了弥补现有方法的不足，我们提出了一种直方图构建算法 PrivTree，该算法采用了分层分解（hierarchical decomposition），但完全消除了对预定义的 h 的需求。PrivTree 的核心是一种全新的机制，其可以&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;(i) 在拉普拉斯分布（Laplace distribution）上利用一种新分析；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;(ii) 让我们可以在决定应该分割哪个子区域时仅使用常量的噪声，而无需担心分割的递归深度（recursion depth）。我们在建模空间数据上演示了 PrivTree 的应用，结果表明其可以被扩展到能处理序列数据（其中子区域中的决策并不是基于元组数，而是一个更复杂的度量）。我们在许多不同的真实数据集上的实验表明 PrivTree 在数据效用方面显著超越了当前最佳水平。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 22 Jan 2017 19:28:52 +0800</pubDate>
    </item>
    <item>
      <title>专题 | 脑芯编： 为什么 GPU 是 AI 的神外挂？</title>
      <link>http://www.iwgc.cn/link/4447949</link>
      <description>&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;〈五〉&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;一遇泰坦误终身&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;或许林燕妮自己也没有想到&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;写了一辈子的文&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;最后能和自己老公的「沧海一声笑」&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;一起流过的岁月的，&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;是那篇&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;《一遇杨过误终生》&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今天的主题，叫做「一遇到泰坦误终身」。你会问，泰坦是什么？Titan X -- NVIDIA Pascal 架构下的终极显卡（Graphics Card）产品。显卡？！这不是一个人工智能硬件的专栏，我又不玩游戏，关显卡什么事？且听小编慢慢道来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9iaSgfTFRChrskKuUMbnjjpmWou2aV8L6KxibAuyjHdMpXmIZcnPBKeTtUVlNVWrv0jEtibeHRfvcGg/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在进入正文以前，我们先来回忆两个概念，其一是加速器（你还记得挂在 ARM core 边上的加速协处理器么？见「脑芯编（三）」），其二是单指令多数据体系结构（SIMD，见「脑心编（四）」）。在人工智能大热之前，这两个方案就已经广泛地出现在我们的系统中，这个系统叫做「显卡」。那是一个显卡还在用来的投影（shadow）和渲染（rendering）的年代。除了高等级游戏玩家，普通人的电脑常有一个抬不起头的配置——「集显」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;显卡主要用于大规模的同一类型计算，比如向量积和一些简单的非线性操作。听起来有没有很熟悉？神经元也是同一类操作。也就是说在神经网络大红之前，显卡已经在类似硬件上默默耕耘了数十年。但是，十年前没有人会想到上帝会掉一个馅饼到 NVIDIA 额头上，让它成为了比肩 intel 的超强处理器帝国。原因有二，其一是显卡是最能体现体系结构中协处理架构和 SIMD 的硬件。除此之外，显卡还有一个法宝，称为——多线程并行（Multi-thread parallelism）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;最远的距离，是你的芯里没有我&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;张小娴说「世间最遥远的距离，不是生与死，天与地，是我在你面前，你却不知道我爱你。」而在数据处理器里，也有一个如此「遥远」的距离——存储数据访问失败。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;故事起源于计算机体系结构中存储的分级结构（memory hierarchy）。一般，一台处理器的数据存储的位置，以离计算单元的位置排序，包括寄存器表（Register File），高速缓存（cache），内存（DDR Memory）和硬盘（SSD/Hard Disk）。非常容易理解地，离计算单元越远，访问延时越长，但是可用作存储的空间越大。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9iaSgfTFRChrskKuUMbnjjpB0Vp6dRr4aXWWb7AZIJsWJLnhcPlJBESt3ickEnGfURjsFvJcya6BYg/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那问题是，什么样的数据，该放在 Cache 里呢？简单的答案，是不断被访问的数据。那万一不断被访问数据不在 Cache 里呢？那处理器就要派出一个信号兵，历经千山万水，走到 disk 来求得一本「真经」再带回处理器开始计算。那这段时间里，处理器单元在干什么呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;等。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;就像那些只能把爱存在心底的痴人。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;解药，只能是爱上另一个人。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;用计算机体系结构的话说，是执行——&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;另一个进程&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们在讲到 VLWI（超长指令集）谈到过说，其实不同类型的执行电路是相互独立的。对于一个包含 load/store 指令和 ALU 计算指令的处理器，完全可以同时执行 load/store 和计算，只要两者间的数据不存在依赖关系。即，处理单元在派出信号兵的时候，仍然也在高效率的计算。那么，我们把这两个没有数据依赖关系的指令称为它们分别属于两个进程（thread）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于这样的操作，处理器在传统体系架构往外还需要支持一个叫「scheduler」的发射器，用于分配当前处理器的不同模块分别处于哪一个进程中。显然地，就每个进程而言，其寄存器是独立的。共享的只是操作实现单元。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;GPU 就是在这一概念下产生。下图是一个典型的 GPU 多核单元。可以看到，他有 32 个处理单元，称为 CUDA Core，每个 CUDA Core 里有一个浮点计算单元和一个整数计算单元。16 为一队分为两组。还有 16 个 Load/Store，和四个特殊函数计算单元（SFU, Special Function Unit）用来计算三角函数之类的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9iaSgfTFRChrskKuUMbnjjpia7KwWASC20uca0ibAHiaHIjZEdGIeUuRXtbR4dW2dUzoqjUCO5Ls4m9g/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这样，这个处理器就可以以 16 为单位，在同一实现执行一条指令，即 SIMD。除此之外，LD/ST 与两组 CUDA Core 可以按照不同的指令同时对于不同的 Thread 进行不同的操作。至于当前情况对哪个 Thread 进行操作，由 Scoreboard（记分牌）和 Warp Scheduler 共同决定。因此，cuda 是不用等 ld/st 操作的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9iaSgfTFRChrskKuUMbnjjpuSrGGhIH0vic6yUskgfbsY7NpI451x3bP30QBnBB1L0ANjJcF719Cibg/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;讲到这里，不得不提一下 Nvidia 的起名，那也是一种境界。比如说线程吧，好好的 thread 的不叫，要叫 warp。如果各位硅工辅修一门「羊毛衫针织技术」课的就会理解这个名字精妙所在，上图是 google image 搜出来的 thread 和 warp。Thread 是单一没有规律的线，而 warp 是针织后多条并线错落有致的线。Warp 可以形象地体现 GPU 中每个线程的并行性和交替活跃的特征。可惜，大部分硅工连 warp 可以作名词都不知道。另外，NV 还把一个上述的并行的单元处理器叫做 streaming multiprocessor。对，简写就是那个五十度灰里羞羞的 SM，看 GPU 的文章时，一定不要对四处飞的 SM 想太多哦。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;时间上，一个可能的 SM 处理的操作如下图所示。通过 Warp Scheduler, 每个对应的 cuda core 将在不同的 thread 间跳跃以达到性能的最优值，同时成功地掩护处理器对存储器里所需数据的访问时间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9iaSgfTFRChrskKuUMbnjjpekFe3sicBO7OvlHQ1JYbCNib0ZkajezVZdNlUAtJGja7nQFSQnxrW2Cw/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;从费米到帕斯卡：泰坦之父们&lt;/span&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;希腊神话里面，泰坦们是天神 Uranus 和地神的 Gaia 的后代，是奥林匹斯众神（宙斯等）的父辈。然而，在 GPU 的世界里，泰坦之父却要贡献给这四个名字：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Fermi / Kepler / Maxwell / Pascal&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9iaSgfTFRChrskKuUMbnjjpabhlwVRU7CzpOKyD13HjM7gibrOjE71uIX8aoWiaxXmy1CbzlmVticjfQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这 4 位鼎鼎大名的先贤（不认识的请自行回去打屁股）又和 GPU 有什么关系呢？这又要归结到 Nvidia 牛逼的起名学了。10 年以前，专用图像处理芯片都叫做「显卡」（Graphics Card）。但 2008 年的时候，多家公司决定给他一个高霸上的名字——「图像处理单元」（Graphic Processing Unit, GPU）。Nvidia 从那时起，给每一代自己的图像处理芯片都冠一个牛逼哄哄的干爹姓。第一任干爹就是大名鼎鼎的核物理学家——Enrico Fermi。其实，fermi 前还有个，叫 tesla 姓，但是现在 tesla 已经被 NV 作为一个产品线名字了。就这样，GPU 以两年一代的速度，不断进取，如今已经发展到 Pascal 代。在今年刚过去的 CES，下一代架构 Volta 的样机已经出现了，集成在 xaiver 平台上。（请参考《矽说--从芯片核弹到未来平台：从 CES 看 Nvidia 的转型野心》）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9iaSgfTFRChrskKuUMbnjjpsa1RTu6K20IwSuicNmVCGyNFXVGmFCVuz8B2HTOY4KdBtQrXKNbAKyA/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Titan X 首次亮相时在 Maxwell 时代，目前能买到的新款已经更新到 Pascal。其实，N 家作为卖游戏显卡的主，出的了很多性能超越 Titan 的游戏卡（比如 GTX 1080，游戏跑分基本秒杀 Titan）。但是为啥 Titan X 一直是 AI 加速、特别是 training 的主要硬件外挂呢？有两个重要要原因。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一是，Titian 在单精度模式上拥有长足的优势。单精度指的是 16 位的浮点计算模式（FP16），而日常显卡是为双精度（32 位浮点）甚至更高的 FP64 模式设计的。Data scientist 的经验表明，深度学习往往仅需要单精度即可得到。大家可以从 (A+B)(C+D) = AC+AD+BC+DC 中可以简单地发现，FP32 所需要的硬件代价大约是 FP16 的 4 倍，可以做 FP16 的 Titian X 自然成了 AI 训练的首选。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二个原因是，Titan 卡上的存储空间（DRAM）是 NV 卡里最高的，达到 12GB。就如本文一开头所述的，离计算单元越近且越大的 Memory 越值钱。这一点在大规模神经网络中尤为有用。多少个矩阵乘就这么避免了被「五马分尸」的命运呢。因此，凭着这 12GB 的显卡内存，Titan 的运行 AI 是对「云深不知处」的主机内存访问又降低了很多。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;既然讲到了 GPU RAM，可能会有筒子们问 GPU 是在 GPU 芯片里的还是芯片外的？。答案是两者都是。从 Pascal 架构开始，GPU 所用的 DRAM 不再是与 GPU 分立的单独存储芯片，而采用 2.5D 封装的 HBM 结构，为了更近、更快、更宽（位宽）的访问存储器。详情请参考《矽说-那些年我们追的摩尔定律（二）》&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9iaSgfTFRChrskKuUMbnjjpkokMukmXq58KwLOMGGVOvGgFNk8K5q12NibRLtUfxmx8zl0g7Pic6Z1Q/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;(说了那么多 N 家，最后拿 A 家的 ppt 镇个楼)&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「一遇泰坦误终身」介绍了在 GPU 的在 SIMD 基础上的另一绝技——多线程，并且在此基础上义务地给 titan X 神卡做了个软文。可是，难道整个 AI 的硬件就要被黄教主统治了么？其他的硬件机遇在哪里？篇幅有限，且听下回分解。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;眼瞅着就要过年了，&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这也应该是年前脑芯的最后一更，&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;小编在这里给大家拜早年了！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 22 Jan 2017 19:28:52 +0800</pubDate>
    </item>
    <item>
      <title>投票 |「2016 年度学术公众号」20 强入围榜单出炉</title>
      <link>http://www.iwgc.cn/link/4447950</link>
      <description>&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/kKoeb9t5fNpXdhibh2jrmJrfga7z8p5mG5fkpAukdYwKKVnFmdHBGd5CVGBYFtF1934dlchUjXov9j8X26aO3vw/640?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;2016年11月，「科研圈」启动「2016年度学术公众号」评选，邀请科研人员、“科研圈”的数十万用户提名自己心中的最佳的垂直领域学术公众号。截止2017年1月17日，总计提名候选公众号235个。&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;“科研圈”综合读者提名、专家推荐、公众号体量、内容质量、更新频率及用户评价等指标，经过多轮筛选，最终出炉入围的20强学术公众号，覆盖七大学科领域。&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;现在，欢迎您给20个入围公众号投票，“科研圈”将根据读者投票结果与专家评审打分，评选出最终的 Top 10学术公众号。&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;点击文末「阅读原文」，为机器之心号投上一票。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;本次入围的20个学术公众号名单如下（根据字母顺序排名）：&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;blockquote style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section&gt;&lt;/section&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;span&gt;「&amp;nbsp;材料&amp;amp;化学类&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;」&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;br/&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/kKoeb9t5fNpXdhibh2jrmJrfga7z8p5mGwkEke0XpYJianh7j4w9AooM9YzJibzXmQhMT3zDLNm2CBtSVow1GgTPA/640?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/kKoeb9t5fNpXdhibh2jrmJrfga7z8p5mGxHWKGQXl4QwNg6nz1UHdAN4tozS6V59jlGQp1XN1RdnDgn9LuDib2eQ/640?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/kKoeb9t5fNpXdhibh2jrmJrfga7z8p5mG0bia5qlrQggmsyP8TPLph6SRmNAicSLiaMjtqAT6NftcvfjzjzjTOc1lg/640?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;「&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;计算机类&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;」&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/kKoeb9t5fNpXdhibh2jrmJrfga7z8p5mGPmF3CMew2KT0pV08CPDku2K0EbKcxZcWoBnSFTKyO6v8IFpGnVKl6g/0?"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/kKoeb9t5fNpXdhibh2jrmJrfga7z8p5mG1xMWXlkk6eicARic8D8VSR2VzGmOnh3kT8uCOvm1EfW7QDBaaNY7k8Xg/640?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/kKoeb9t5fNpXdhibh2jrmJrfga7z8p5mGmib64zLxCAdcOzF5IUibyQibIQfr8N40zKlrr3LSia0xD9Ob9OmgzRzCCQ/640?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;「&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;生物类&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;」&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/kKoeb9t5fNpXdhibh2jrmJrfga7z8p5mG5NRRL6xgUiaXNpLk8vpA4APmur5ia6gfgKb4Ywic2Y410MeHcvKJsnA6w/640?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/kKoeb9t5fNpXdhibh2jrmJrfga7z8p5mGrjczcw7YEfiacYqGU4ScoI4dvC8CBosblUlia6Sk2CR1kxCtHYNka5fg/640?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/kKoeb9t5fNpXdhibh2jrmJrfga7z8p5mGzHN9VW2KBQPCfzibOTkUzVtCia55vET9yK0Drh1GM6yojedD0pXnPJRw/640?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/kKoeb9t5fNpXdhibh2jrmJrfga7z8p5mGXuEPJvSBnnQRnYGVx5XFZortaWVYD9JwPUiakXibyL5LNUVofdHezEbQ/640?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/kKoeb9t5fNpXdhibh2jrmJrfga7z8p5mGV54X31lTbCXbceP2ic2B4icsrIMdThxicHIBWWCn9BNcXdhtNRmMru6jA/640?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;「&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;数学类&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;」&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/kKoeb9t5fNpXdhibh2jrmJrfga7z8p5mGyzibSUVm7cY7UfuX0Oia76N7oGiagbCJmeABcGZichLPNkwTqDW6HibA10g/640?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/kKoeb9t5fNpXdhibh2jrmJrfga7z8p5mGHnhKuIOZxwOrjzT1ibWKRWm8UU5Bz3uvNbqk6dRMicicVctmEdFeREsvg/640?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;「&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;物理类&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;」&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/kKoeb9t5fNpXdhibh2jrmJrfga7z8p5mGXHerydZ2wMiafA0MficGPgzj8eSgmZW9zib9AHbpeVB6RdNQvbpVWNWPw/640?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/kKoeb9t5fNpXdhibh2jrmJrfga7z8p5mGxiac3AiaKuQib2rMRLzmZWOmT3Jm8iaCBnicTa3KbT66EPTuP3Jb7dO6ibIw/640?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;「&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;心理学类&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;」&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/kKoeb9t5fNpXdhibh2jrmJrfga7z8p5mGq2zDHGWG8AArl5sicBg3o6hO95yqqAlvsNj6QSRX1ibUogk8bN2l8uFA/640?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;「&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;医药类&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;」&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/kKoeb9t5fNpXdhibh2jrmJrfga7z8p5mGKzf7WQfmawLnrnZvRN2bJyS99TB1dfFORSiciagvvpo4VwmcLgGMk4sw/640?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/kKoeb9t5fNpXdhibh2jrmJrfga7z8p5mGbYe6AnJkDApLhYrwpCWczT3j9iaSHYiaXcbPUPZTRbMntfialbxALdV8A/640?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/kKoeb9t5fNpXdhibh2jrmJrfga7z8p5mGnSCUL3lsXQg3y5p7ZVJgVHq3CjlatZaEMbgoy4oweAKG8k3LdDZGtA/640?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/kKoeb9t5fNpXdhibh2jrmJrfga7z8p5mGwicXMdEVYiaYWEzK5Zbe05V7Jht6CxRTGvicDBZqCYcdQhuibiaVENJW1SA/640?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;*****&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;「科研圈」综合读者提名情况、专家推荐、公众号体量及更新频率、用户评价等条件，筛选出入围20强，读者对20强进行投票的结果及专家打分，将决定最终的&amp;nbsp;Top 10。&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;“2016年度学术公众号”&amp;nbsp;Top 10榜单&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;五大平台 同步发布：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;《环球科学》杂志&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;《环球科学》官网&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微信平台“环球科学ScientificAmerican”&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微信平台“科研圈”&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;科研圈网站&amp;nbsp;&lt;/span&gt;www.keyanquan.net&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;敬请期待！&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/kKoeb9t5fNpXdhibh2jrmJrfga7z8p5mGbZ8bUictcS5UTicXKrCRg5A3oDtgBNoR0fiblFickleOKCv1WMfAx5aDIg/640?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;现在就点击「阅读原文」&lt;/span&gt;&lt;span&gt;，为机器之心投上一票吧！&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 22 Jan 2017 19:28:52 +0800</pubDate>
    </item>
    <item>
      <title>深度 | 我们真的找对了方法？新研究为欧美脑计划敲响警钟</title>
      <link>http://www.iwgc.cn/link/4435235</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自The Economist&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李泽南&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;UC Berkeley 的最新研究告诉我们，大部分研究者用于分析大脑运行规律的算法也许并不准确。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic17FA5ZBlbiaEavsI2wmR5XOnbmLiaPdkB4NK4qL5bCmUuaH2kxlkr7x18VMOop6WfrIPB4PJPkmxw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;神经科学就像其他很多学科一样，对获取数据有着无穷的欲望。在 2013 年，前总统奥巴马宣布的美国脑计划——和同年的欧盟脑计划一样，都致力于探寻人类大脑中数千个神经细胞的交互形式。科学家们希望在数量庞大的信息中找到一些规律，能让我们距离揭开大脑运行机制的面纱更进一步。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是最近在 PLOS 计算生物学上发表的一篇论文对于量变能否产生质变提出了质疑。Eric Jonas 等人使用了神经科学界常用的方法：将人类大脑与计算机类比。就像大脑一样，计算机通过电信号与复杂的环路来处理信息。我们知道计算机的所有运行机制，而面对大脑却只能假设。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Eric Jonas 来自 UC Berkeley，论文的共同作者 Konrad Kording 则来自西北大学，他们都拥有神经科学和电子工程的复合背景，他们都认为计算机是测试现代神经科学分析工具的最佳方法。他们的思路是：将这些分析技术应用到计算机芯片中去，看看分析结果是否和计算机架构相符。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他们用于测试的硬件是 MOS Technology 6502 处理器，它是一种 8 位 CPU，于 1975 年面世，曾经在 Atari 游戏机、苹果电脑和 Commodore 上出现。以现在的眼光看来，它显得有点落后——只有 3510 个晶体管。6502 的结构非常简单，这让研究者可以构建一个模型，模拟在运行特定程序时 CPU 中所有晶体管的运行状态，与和这些晶体管相连的数万个通路的所有电压。这一模拟程序每秒钟能够产生 1.5G 的数据，这还处在用于探索大脑运行机制的算法的能力范围内。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;大脑向左，芯片向右&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对比受损和健康大脑的不同特性是一个常见的脑科学研究方式。如果特定部位受损的大脑展现出另一种预测行为，研究人员就可以得知这一部分脑区主要负责处理何种任务。以老鼠为例，如果掐断海马体（两个位于大脑底部，细长形状的小结构）就可以有效地影响它们识别物体的能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当应用于芯片时，这种方法呈现了有趣的假阳性。研究人员发现，禁用一个特定的晶体管组就可以完全阻止「Donkey Kong」程序（第一个出现超级马里奥形象的游戏）启动。「这也许是一个错误，」Jonas 说道。「它们不像是组成基础计算功能循环，实现软件加载的一部分，而更像是其他的什么东西。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一种神经科学研究方法，是寻找神经细胞群的活动与特定行为之间的相关性。在芯片上，研究人员的算法发现其中五个晶体管的活动与屏幕上显示图像的亮度强烈相关。然而再一次，这个发现随即被否定了。Jonas 和 Kording 知道这些晶体管的计算结果并不会直接与屏幕显示的内容相关（在 Atari 游戏机中，显示处理的工作由 Television Interface Adaptor 芯片完成）。这些晶体管只包含一些简单的意义——它们被程序的某些部分使用，最终决定屏幕上会出现什么。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对此，研究人员分析了这种芯片的接线图（在生物学家那里，对应的东西应该是连接组），随后把这张图输入了分析算法。算法生成了很多看起来让人印象深刻的数据，暗示着芯片处理任务时，内部存在着一些复杂的结构。然而仔细检查以后，这些推论很少被证明成立。这些性状非常具有误导性，而且经不起推敲——这倒很符合真正神经科学令人沮丧的研究历史。研究人员有一个完整的蠕虫连接组（Caenorhabditis elegans，来自 1986 年），其中只包含 302 个神经细胞。现在，我们知道自己对于如此简单的「脑结构」也无能为力了（相比之下，英特尔 Skylake K Core i7 约有 17 亿个晶体管——而且我们清楚它的内部机制）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「这其中最基本的问题，」Jonas 说道。「在于现代神经科学的研究方式无法探明我们已知的芯片结构，而这对于我们理解真正发生的事情至关重要。计算机芯片由晶体管组成，它们是微小的电子开关。它们被组成逻辑门，从而实现简单的逻辑运算。这些逻辑门又可以组织成为更复杂的结构，如加法器。算术逻辑单元由一系列加法器组成。再往后更为复杂的结构也是这样层层递进的关系。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是，用神经科学的方式分析这种高级结构是非常困难的，分析算法无法探知芯片内部的电流如何计算出超级马里奥的形象。这不是神经科学才会遇到的问题，Jonas 把他们遇到的麻烦与人类基因组计划进行了比较，人类基因组计划是一项规模庞大的计划，已于 2003 年结束。科学家们希望通过这一计划攻克癌症、衰老这样的难题。然而十几年过去了，事实证明我们不能从浩如烟海的数据中获得太多启示，我们面对无数条四个字母编写的密码一筹莫展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人类脑计划也要面临长达十几年的困局吗？或许不会。在这项研究中，算法还是探测到了主时钟信号，它协调 CPU 中不同的部位的运行。同时，一些神经科学家也批评了论文给出的结论，他们认为计算机芯片和大脑的机制并不能完全类比，同样的分析方式并不能直接移植应用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;法国计算机科学与自动化研究所机器学习专家 Gaël Varoquaux 表示：「6502 与当代 CPU 相比，前者和大脑的区别更明显。这种原始的芯片按照顺序处理输入内容。而大脑（和现代 CPU）是多线程同时计算的。」正如他所说的，神经科学在近年来已经走过了很长的一段路。例如在视觉系统的复杂细节上，人们对于大脑如何区分线和面这样的概念已经有了合乎情理的解释。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Jonas 对这些看法表示部分接受。「我并不否认神经科学近年来的成就，」他辩解道，他继续用人类基因组计划作类比。「这项工程产生的数据，以及其后更先进手段收集得来的数据都为人类的基因研究打下了基础，但由基因组计划引起的对于未来的不实际期待则被打破。收集数据是一回事，想搞清楚数据背后的意义，我们还要等很久。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;论文：Could a Neuroscientist Understand a Microprocessor?&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic17FA5ZBlbiaEavsI2wmR5Xmh27sEiajNOyke9phT4uiagibVFOHubR5jaG9sEJhUap8kWMY7hWRJRKg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：&lt;/span&gt;&lt;span&gt;在神经科学领域，我们有一个普遍的观念：研究非常依赖于数据，在大型数据集和高级分析算法的帮助下，我们可以探求大脑运行方式。这种量级的数据集尚不存在，而且即使它们存在，我们也无法得知我们算法生成的分析结果是否有效。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了证明这个观点，我们使用了一个具有代表性的微处理器作为生物模型，并进行了一系列实验以检查目前主流的分析方法是否可以理解 CPU 的信息处理方式。微处理器是人造信息处理系统的组成部分，它们形式复杂，同时结构完全已知——从逻辑流程，到逻辑门，再到晶体管的动态。我们的研究展示了现有神经科学分析方法对于 CPU 的运行数据产生了有趣的见解，但这些分析随后被证明对于解释芯片在信息处理时的层级结构毫无意义。这意味着目前神经科学领域的分析方式可能对于我们理解神经系统毫无帮助——无论我们是否拥有足够数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此外，我们的研究结果表明，科学家们需要使用复杂非线性动态系统在已知内容的基础上开展研究，微处理器对于时间序列和结构发现方法而言就是一个可用的平台。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文：http://www.economist.com/news/science-and-technology/21714978-cautionary-tale-about-promises-modern-brain-science-testing-methods&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Sat, 21 Jan 2017 17:20:27 +0800</pubDate>
    </item>
    <item>
      <title>业界 | FDA批准首个云深度学习临床医疗应用平台Atrerys</title>
      <link>http://www.iwgc.cn/link/4435236</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自福布斯&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;参与：杜夏德、李泽南&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote style="color: rgb(62, 62, 62); font-size: 16px; white-space: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/blockquote&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;初创公司 Arterys 的产品成为了第一个获得 FDA 批准的机器学习应用，它标志着医疗行业和人工智能领域的一大进步。意味着深度学习和云技术可以真正进入医疗工作流程。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Arterys 的医疗成像平台已被美国食品和药物管理局（FDA）批准投入临床医疗使用，它可以帮助医生诊断病人的心脏问题。这个应用中的神经网络模型从 1000 多个病例中自我学习，并可以在每个新案例中不断获取新知识，提高自己的准确性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在此之前，为获得 FDA 的认证，这一系统通过了严格的临床测试，以证明它至少可以与人类医生达到相同的判断水平。Arterys 与人类的最大不同是他可以在约 15 秒钟内对一个病例作出诊断，而要做同样的事，专业人类分析师需要花上 30 分钟到一个小时。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Arterys 是由 Fabien Beckers，John Axerio-Cilies，Albert Hsiao 和 Shreyas Vasanawala 在斯坦福大学发起的，目前已完成 A 轮融资，公司的创始人们对于机器学习的潜力有着共同的期望。他们目前的工作是帮助医生了解病人心脏的状态，通过准确测量每个心室的体积，人工智能系统可以对病人的健康状况作出评估。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「这是一个令人瞩目的成就，」Beckers 说道。「这是此类医疗成像方法第一次通过批准。这意味着深度学习和云技术可以真正进入医疗工作流程，为医生和病人提供重要帮助。我们的工作开启了一扇门，此类应用从此有了先例。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic17FA5ZBlbiaEavsI2wmR5Xgro4931ZCbHuib5wkmAI7dMCZ7SfWRMROBlQQN2cX3Nl0ceah56hS2w/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;深度学习&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;投入 1000 个病例作为训练数据后，Artery Cardio DL 运行了监督学习算法，并基于它在数据中发现的关联得出大约 1000 万条规则。它的目的是在没有人工干预的情况下做到察觉和识别问题。但是 Becker 肯定道，这个目的并不是要代替医生，而是为他们提供工具，帮助他们更高效地工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们正在尝试将它做成定量的和数据驱动的。我们从心脏的应用开始，因为它是最难的器官之一。现在我们知道我们可以做到了，能在其他很多领域用这个 Arterys 了。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「心脏的左心室呈圆形，结构简单，而右心室呈花生状，比较复杂。证明这项技术可以用来分析左右心室的两个图像是一个大成果，因为使用传统方法花的时间太长了。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「这个技术能做到这些证明了它的用处是何其的巨大而深远。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Arterys 是基于云的平台。这一点很重要，因为它能让外科医生在全世界范围内收集数据，Arterys 也将继续学习这些数据。有了时间和足够的数据，终有一天它的精确性不仅能与媲美人类，甚至能超过人类。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然这也会带来特殊的挑战，因为数据是高度敏感和个人化的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;「&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;医疗成像大约有 30 亿美元的市场，它是基于工作站的——除了医疗行业，还有其他行业使用「工作站」这个词吗？」Beckers 问道。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;iframe class="video_iframe" data-vidtype="5" allowfullscreen="" frameborder="0" height="417" width="556" data-src="https://v.qq.com/iframe/preview.html?vid=z0368bajy6e&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0"&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;云安全&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们一直在思考为什么云技术不能像进入金融领域里一样进入医疗领域，最后我们发现问题在于数据隐私——在其他行业里，你可以像谷歌、GE 或任何世界级大公司一样行事，但医院不会允许你随意把个人医疗信息（PHI）放到云端处理。」Beckers 解释道。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;解决这个问题的方案是一种被称为 PHI 服务的系统，它允许医院提供的图像数据在被云端收集时将个人识别信息剥离掉。当系统认可的用户和医生登陆时，他/她可以从 Arterys 的云系统中获取成像数据和分析结果，并从医院的安全服务器中获取 PHI，并将个人识别信息与图像数据重新整合在一起。这样，在整个流程中，Arterys 不会接触到任何个人隐私内容信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种由加密和安全传输协议支持的认证系统可能在克服存储和分析个人数据固有的问题方面发挥越来越大的作用。由此观之，FDA 批准 Arterys 解决方案有了更重要的意义。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;学习系统应用于医疗扫描设备生成的大量数字图像数据的巨大潜力已经被讨论一段时间了。现在 FDA 批准了 Arterys，路障已被清除，这一突破性技术将会带出现更多的应用程序。Artery 自己还在生产下一代的技术应用，这一次的目标是癌症。从 FDA 批准释放出的信号，以及政府支持人工智能和机器学习应用的热度，我认为可以期待的更多。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Sat, 21 Jan 2017 17:20:27 +0800</pubDate>
    </item>
    <item>
      <title>一周论文 | Image Caption任务综述</title>
      <link>http://www.iwgc.cn/link/4435237</link>
      <description>&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;引言&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Image Caption是一个融合计算机视觉、自然语言处理和机器学习的综合问题，它类似于翻译一副图片为一段描述文字。该任务对于人类来说非常容易，但是对于机器却非常具有挑战性，它不仅需要利用模型去理解图片的内容并且还需要用自然语言去表达它们之间的关系。除此之外，模型还需要能够抓住图像的语义信息，并且生成人类可读的句子。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随着机器翻译和大数据的兴起，出现了Image Caption的研究浪潮。当前大多数的Image Caption方法基于encoder-decoder模型。其中encoder一般为卷积神经网络，利用最后全连接层或者卷积层的特征作作为图像的特征，decoder一般为递归神经网络，主要用于图像描述的生成。由于普通RNN存在梯度下降的问题，RNN只能记忆之前有限的时间单元的内容，而LSTM是一种特殊的RNN架构，能够解决梯度消失等问题，并且其具有长期记忆，所以一般在decoder阶段采用LSTM.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;问题描述&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Image Caption问题可以定义为二元组(I,S)的形式， 其中I表示图，S为目标单词序列，其中S={S1,S2,…}，其中St为来自于数据集提取的单词。训练的目标是使最大似然p(S|I)取得最大值，即使生成的语句和目标语句更加匹配，也可以表达为用尽可能准确的用语句去描述图像。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;数据集&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;论文中常用数据集为Flickr8k,Flick30k,MSCOCO,其中各个数据集的图片数量如下表所示。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a title="" rel="gallery0" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgmrz6yCn8okVud4zBBMTYwTibNliaPcMjcaLjzfnESsHrBS203GpEzibu6GBZicRx0w1jpLjSVIy95OoA/640?wx_fmt=jpeg"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;a title="" rel="gallery0" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/a&gt;&lt;a title="" class="" rel="gallery0" style="color: rgb(37, 143, 184); max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgmrz6yCn8okVud4zBBMTYwTAYfULnoC75Dianhxbfjc8XWfE4nSQAnFib0ZWmpeLhOjnChDIqZl0muQ/640?wx_fmt=jpeg"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据集图片和描述示例如图&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中每张图像都至少有5张参考描述。为了使每张图像具有多种互相独立的描述，数据集使用了不同的语法去描述同一张图像。如示例图所示，相同图像的不同描述侧重场景的不同方面或者使用不同的语法构成。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;模型&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本文主要介绍基于神经网络的方法&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;1 NIC[1]&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Show and Tell: A Neural Image Caption Generator&lt;br/&gt;本文提出了一种encoder-decoder框架，其中通过CNN提取图像特征，然后经过LSTM生成目标语言，其目标函数为最大化目标描述的最大似然估计。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;a title="" rel="gallery0" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgmrz6yCn8okVud4zBBMTYwTj1fOIHvz9no04ldPfg0QcvmkLP1ibodriba6WhfyBkwswKLBU1jN1H4g/640?wx_fmt=jpeg"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该模型主要包括encoder-decoder两个部分。encoder部分为一个用于提取图像特征的卷积神经网络，可以采用VGG16，VGG19, GoogleNet等模型, decoder为经典的LSTM递归神经网络，其中第一步的输入为经过卷积神经网络提取的图像特征，其后时刻输入为每个单词的词向量表达。对于每个单词首先通过one-hot向量进行表示，然后经过词嵌入模型，变成与图像特征相同的维度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;2 MS Captivator[2]&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;From captions to visual concepts and back&lt;br/&gt;本文首先利用多实例学习，去训练视觉检测器来提取一副图像中所包含的单词，然后学习一个统计模型用于生成描述。对于视觉检测器部分，由于数据集对图像并没有准确的边框标注，并且一些形容词、动词也不能通过图像直接表达，所以本文采用Multiple Instance Learning(MIL)的弱监督方法，用于训练检测器。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;a title="" rel="gallery0" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgmrz6yCn8okVud4zBBMTYwTP2eIetibZ86DM3Wa9nmJiaL0x6yc1660vb6p5ITbYgD8j4hcJdnUv1aQ/640?wx_fmt=jpeg"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;3 Hard-Attention Soft-Attention[3]&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Show, atten and tell: Neural image caption generation with visual attention&lt;br/&gt;受最近注意机制在机器翻译中发展的启发，作者提出了在图像的卷积特征中结合空间注意机制的方法，然后将上下文信息输入到encoder-decoder框架中。在encoder阶段，与之前直接通过全连接层提取特征不同，作者使用较低层的卷积层作为图像特征，其中卷积层保留了图像空间信息，然后结合注意机制，能够动态的选择图像的空间特征用于decoder阶段。在decoder阶段，输入增加了图像上下文向量，该向量是当前时刻图像的显著区域的特征表达。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;a title="" rel="gallery0" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgmrz6yCn8okVud4zBBMTYwTa9v6dklNu93NNVnDJf1oicYY0iaeEg6MVX83Oze2o8Z1Cjlg6oYCy9yw/640?wx_fmt=jpeg"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;br/&gt;&lt;/h2&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;4 gLSTM[4]&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Guiding long-short term memory for image caption generation&lt;br/&gt;使用语义信息来指导LSTM在各个时刻生成描述。由于经典的NIC[1]模型，只是在LSTM模型开始时候输入图像，但是LSTM随着时间的增长，会慢慢缺少图像特征的指导，所以本文采取了三种不同的语义信息，用于指导每个时刻单词的生成，其中guidance分别为Retrieval-based guidance (ret-gLSTM), Semantic embedding guidance(emb-gLSTM) ,Image as guidance (img-gLSTM).&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;a title="" rel="gallery0" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgmrz6yCn8okVud4zBBMTYwTmBLBauze3MmCfoElrekjqoLDL2hUTUYlYPbmmDLpJYETg4ppJPQ1wA/640?wx_fmt=jpeg"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;5 sentence-condition[5]&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Image Caption Generation with Text-Conditional Semantic Attention&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;a title="" rel="gallery0" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgmrz6yCn8okVud4zBBMTYwT6U7vicPyoygkrQHDHKnHBW5pOedCloTpM1RBOibUL95ic1gT6bEw3jnaQ/640?wx_fmt=jpeg"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该模型首先利用卷积神经网络提取图像特征，然后结合图像特征和词嵌入的文本特征作为gLSTM的输入。由于之前gLSTM的guidance都采用了时间不变的信息，忽略了不同时刻guidance信息的不同，而作者采用了text-conditional的方法，并且和图像特征相结合，最终能够根据图像的特定部分用于当前单词的生成。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;6 Att-CNN+LSTM [6]&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;What value do explicit high level concepts have in vision to language problems?&lt;br/&gt;如图，作者首先利用VggNet模型在ImageNet数据库进行预训练，然后进行多标签数训练。给一张图片，首先产生多个候选区域，将多个候选区域输入CNN产生多标签预测结果，然后将结果经过max pooling作为图像的高层语义信息，最后输入到LSTM用于描述的生成。该方法相当于保留了图像的高层语义信息，不仅在Image Caption上取得了不错的结果，在VQA问题上，也取得很好的成绩。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;a title="" rel="gallery0" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgmrz6yCn8okVud4zBBMTYwTWNIZdpT0wP6ar72HHzL7CYq57olee7eAzJuZtt1Qq9h6Y1leicZ662Q/640?wx_fmt=jpeg"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;7 MSM[7]&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;BOOSTING IMAGE CAPTIONING WITH ATTRIBUTES&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;a title="" rel="gallery0" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgmrz6yCn8okVud4zBBMTYwT0rBJa8HnLiczlkkUfSL9DbLlFy96XtWYCELOXzvEfpJb7xYDElSwQsA/640?wx_fmt=jpeg"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该文研究了图像属性特征对于描述结果的影响，其中图像属性特征通过多实例学习[2]的方法进行提取。作者采用了五种不同的组合形式进行对比。其中第3种、第5种，在五种中的表现出了比较好的效果。由于提取属性的模型，之前用于描述图像的单词的生成，所以属性特征能够更加抓住图像的重要特征。而该文中的第3种形式，相当于在NIC模型的基础上，在之前加上了属性作为LSTM的初始输入，增强了模型对于图像属性的理解。第5种，在每个时间节点将属性和文本信息进行结合作为输入，使每一步单词的生成都能够利用图像属性的信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;8 When to Look[8]&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Knowing When to Look: Adaptive Attention via A Visual Sentinel for Image Captioning&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;a title="" rel="gallery0" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgmrz6yCn8okVud4zBBMTYwTVe1rXQuRibvXVaT6WjrQ2heCut0EXVASLggDVia6wUzLTBzLHTeoLpvw/640?wx_fmt=jpeg"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该文主要提出了何时利用何种特征的概念。由于有些描述单词可能并不直接和图像相关，而是可以从当前生成的描述中推测出来，所以当前单词的生成可能依赖图像，也可能依赖于语言模型。基于以上思想，作者提出了“视觉哨兵”的概念，能够以自适应的方法决定当前生成单词，是利用图像特征还是文本特征。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;结果&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本文列出的模型的在COCO测试集上的结果如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;a title="" rel="gallery0" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgmrz6yCn8okVud4zBBMTYwTdr20NTX1v6arSvalKvaTEiacTmibYNkmeprHTyEcWbGojVBFR8oqjTEQ/640?wx_fmt=jpeg"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以下为online MSCOCO testing server的结果：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;a title="" rel="gallery0" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgmrz6yCn8okVud4zBBMTYwT9ar0JNb8MOic8sIlXzwIPvialjoeQRTWOamASibgKg9ibjke5ibDW1TLkSQ/640?wx_fmt=jpeg"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;总结&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最近的Image Caption的方法，大多基于encoder-decoder框架，而且随着flickr30,mscoco等大型数据集的出现，为基于深度学习的方法提供了数据的支撑，并且为论文实验结果的比较提供了统一的标准。模型利用之前在机器翻译等任务中流行的Attention方法，来加强对图像有效区域的利用，使在decoder阶段，能够更有效地利用图像特定区域的特征[3]。模型利用图像的语义信息在decoder阶段指导单词序列的生成，避免了之前只在decoder开始阶段利用图像信息，从而导致了图像信息随着时间的增长逐渐丢失的问题[4][5]。模型为了更好的得到图像的高层语义信息，对原有的卷积神经网络进行改进，包括利用多分类和多实例学习的方法，更好的提取图像的高层语义信息，加强encoder阶段图像特征的提取[6][7]。随着增强学习，GAN等模型已经在文本生成等任务中取得了不错的效果，相信也能为Image Caption效果带来提升。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;参考文献&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. Vinyals O, Toshev A, Bengio S, et al. Show and tell: A neural image caption generator[J]. Computer Science, 2015:3156-3164.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2.Fang H, Gupta S, Iandola F, et al. From captions to visual concepts and back[C]// IEEE Conference on Computer Vision and Pattern Recognition. IEEE, 2015:1473-1482.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3.Xu K, Ba J, Kiros R, et al. Show, Attend and Tell: Neural Image Caption Generation with Visual Attention[J]. Computer Science, 2016:2048-2057.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4.Jia X, Gavves E, Fernando B, et al. Guiding Long-Short Term Memory for Image Caption Generation[J]. 2015.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;5.Zhou L, Xu C, Koch P, et al. Image Caption Generation with Text-Conditional Semantic Attention[J]. 2016.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;6.Wu Q, Shen C, Liu L, et al. What Value Do Explicit High Level Concepts Have in Vision to Language Problems?[J]. Computer Science, 2016.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;7.Yao T, Pan Y, Li Y, et al. Boosting Image Captioning with Attributes[J]. 2016.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;8.Lu J, Xiong C, Parikh D, et al. Knowing When to Look: Adaptive Attention via A Visual Sentinel for Image Captioning[J]. 2016.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;朱欣鑫&lt;/strong&gt;，北京邮电大学在读博士，研究方向为视觉语义理解&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;邮箱：&lt;a style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;zhuxinxin@bupt.edu.cn&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;paperweekly最近刚刚成立&lt;span&gt;&lt;strong&gt;多模态&lt;/strong&gt;&lt;/span&gt;组，有对image caption、VQA等多模态任务感兴趣的童鞋可以申请加入！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;关于PaperWeekly&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;PaperWeekly是一个分享知识和交流学问的学术组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;微信公众号：PaperWeekly&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgmrz6yCn8okVud4zBBMTYwTbHfzKZtva0qb5msvRByocicTG7tD5pYIdLeJPL0be4Z4kpeeur5cJ2w/640?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微博账号：PaperWeekly（&lt;/span&gt;&lt;a target="_blank" rel="external" style="max-width: 100%; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important; text-decoration: underline;"&gt;&lt;span&gt;http://weibo.com/u/2678093863&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&amp;nbsp;）&lt;br/&gt;微信交流群：微信+ zhangjun168305（请备注：加群交流或参与写paper note）&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Sat, 21 Jan 2017 17:20:27 +0800</pubDate>
    </item>
    <item>
      <title>招聘 | 加入百度语音，收获在人工智能领域的未来！</title>
      <link>http://www.iwgc.cn/link/4435238</link>
      <description>&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;在上一期的最强大脑比赛结束后，机器之心&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722318&amp;amp;idx=1&amp;amp;sn=586fc816eb9e318735bc1e4906a44604&amp;amp;chksm=871b1470b06c9d66e4e3bfac05691f7d637291505854be05e791660b50ad3ba8697199349d65&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722318&amp;amp;idx=1&amp;amp;sn=586fc816eb9e318735bc1e4906a44604&amp;amp;chksm=871b1470b06c9d66e4e3bfac05691f7d637291505854be05e791660b50ad3ba8697199349d65&amp;amp;scene=21#wechat_redirect"&gt;专访了百度首席科学家吴恩达&lt;/a&gt;了解背后的语音技术。看完之后，有没有加入百度语音团队的想法？如今他们急需人才！&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;iframe class="video_iframe" data-vidtype="1" allowfullscreen="" frameborder="0" height="417" width="556" data-src="https://v.qq.com/iframe/preview.html?vid=e0366l4b003&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0"&gt;&lt;/iframe&gt;&lt;em style="color: rgb(136, 136, 136);"&gt;&lt;span&gt;AI Talk：机器之心专访吴恩达视频&lt;/span&gt;&lt;/em&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;百度语音技术部定位于面向全行业提供语音及声音信号处理等领域的产品研发、产品交互体验设计，通用平台及工具开发、前瞻技术研究及技术支持。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;百度语音技术部是互联网行业中最早自主研发语音技术的团队，拥有业界领先的语音识别、语音合成等技术，百度深度语音识别系统入选 MIT「2016 十大突破技术」，确立了百度语音技术处在业界领先的地位。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;百度语音在美国硅谷同步设有办公场所，国内外拥有一大批行业顶尖的语音及人工智能人才，加入百度语音，收获你在人工智能领域的未来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWic17FA5ZBlbiaEavsI2wmR5XBwWvkrzqbKiaDwnWA79yzYNDIRY9ymwSYiaMsmGHKRDM10laceBVnBHg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;语音识别高级工程师（工作地点：北京）&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;工作职责:&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;负责语音识别技术的研究，&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;负责声学模型、语言模型、解码器三个方向之一的相关工作&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;职责要求:&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;对语音识别的算法细节有深刻的了解&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;深入了解声学建模的过程，以及具体训练算法&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;主导开发过应用级别的语音识别系统&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;具有良好的数学功底&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;具有很强的分析问题和解决问题的能力，对解决具有挑战性问题充满激情&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在 Interspeech，ICASSP 等语音学术会议中有论文发表者优先&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;有强烈的上进心和求知欲，自我管理能力强，有良好的时间意识&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;音频信号处理工程师（工作地点：北京）&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;工作职责：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;负责语音信号处理相关技术研发&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;负责其他音频相关技术研发&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;负责语音识别和合成等任务的前端信号处理技术研发&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;职位要求：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;精通各种信号处理技术（如语音增强，回声消除，麦克风阵列信号处理等）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;扎实的数学基础、数字信号处理理论与实践经验&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;精通 C/C++、matlab 编程，对数据结构和算法设计有较为深刻的理解，熟悉 Linux 平台&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在 Interspeech，ICASSP 等语音学术会议中有论文发表者优先&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;积极主动的学习能力，能够及时跟进新技术&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;优秀的分析问题和解决问题的能力，对工作充满热情，敢于接受挑战&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;良好的沟通能力和团队合作精神&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;声纹识别算法高级工程师（工作地点：北京）&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;工作职责：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;负责说话人/语种识别和检测等相关技术的研发&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;负责说话人/语种识别和检测系统开发和线上优化&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;职位要求：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;熟悉说话人/语种识别技术，了解 NIST/国内关于说话人/语种识别的评测&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;熟悉说话人识别、语种识别算法，如 GMM，HMM，SVM，iVector 等算法&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;精通 C/C++编程，熟悉 Linux 平台以及相关 python,shell 等脚本语言&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;具有实际线上运行说话人/语种识别和检测系统开发经验者优先&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;语音合成工程师（工作地点：北京）&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;工作职责：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;负责语音合成文本语料库的设计开发&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;负责语音合成系统前端文本分析、韵律预测分析和线上问题分析，&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;负责语音合成系统中参数合成系统的研发&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;负责 HTS 语音合成系统引擎和拼接合成系统的研发 C13&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;职位要求：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;精通 C/C++编程，熟悉 Linux 平台，熟悉 python 等脚本开发&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;有扎实的数据结构和算法设计基础，优秀的分析问题和解决问题的能力，对解决具有挑战性问题充满激情&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;具有良好的沟通能力，和良好的团队合作精神&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;有 NLP，机器学习，韵律/句法分析，语音合成声学模型, 拼接合成，声码器（vocoder）和语音引擎等相关经验者优先)&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在国际性程序设计竞赛获奖，数学竞赛获奖者优先&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;语音产品经理（工作地点：北京）&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;工作职责：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;负责语音产品的产品规划、设计、推进等工作&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;可独立完成产品功能的相关调研、设计、数据分析, 高质量完成项目循环和迭代&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;可对用户需求满足&amp;amp;交互方式提出创新型的想法&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;与技术团队紧密配合, 快速、高效推动产品设计、研发&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;职位要求：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;1 年及以上互联网产品经理从业经验&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;具备互联网产品设计经验，熟悉语音&amp;amp;AI 产品和技术，且有浓厚兴趣&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;有优秀的产品设计、数据分析、用户体验评估能力&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;沟通执行能力强，注重用户体验，有强烈的责任心和团队合作精神&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;思维活跃，有创新精神，能承受工作压力&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;兴趣广泛，热爱生活&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;深度学习算法工程师（工作地点：北京）&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;工作职责:&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;利用深度学习算法进行大规模数据的序列模型建模&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;开发 DeepSpeech 训练平台&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;跟进最新的机器学习算法，推进新算法在语音识别领域的应用&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;职责要求:&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;精通 C++编程，熟悉 Linux 平台，在国际性程序设计竞赛获奖者优先&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;对代码的效率优化和数据结构优化有实践经验者优先&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;对语音识别声学模型有研究经验者优先&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;深度学习、自然语言处理、语音识别、图像处理、模式识别相关专业背景，对深度学习的算法有一定的实践&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;优秀的分析问题和解决问题的能力，对解决具有挑战性问题充满激情&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;具有良好的沟通能力，和良好的团队合作精神&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;高性能计算开发工程师（工作地点：北京）&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;工作职责:&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;负责语音识别模型训练的高性能计算方面的加速优化&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;负责识别解码器的声学模型计算模块的计算优化&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;负责并行训练平台（GPU 集群）的操作和维护&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;构建各种数据规模下，计算最快的大规模机器学习平台&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;负责实现训练程序自动化训练脚本及流程、效率优化&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;职责要求:&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;计算机相关专业硕士以上学位&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;精通 C/C++编程，熟悉 Linux 平台，有良好的编程功底，对数据结构和算法设计有较为深刻的理解&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;熟悉分布式/高性能计算系统，有 mpi、gpu 等开发经验&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;有丰富的大规模机器学算法习开发和应用经验者优先&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;优秀的分析问题和解决问题的能力，对解决具有挑战性问题充满激情&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;具有良好的沟通能力，和良好的团队合作精神&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;具有语音识别相关经验者优先&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;架构研发工程师（工作地点：北京）&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;工作职责：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;从事语音及信号处理相关服务软件架构研发&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;研究海量数据的存储、优化分布式计算架构、提升服务吞吐能力，不断提升系统时效性、扩展性、稳定性、性能&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;研究语音及信号技术适应的服务架构，分析和修改架构与服务策略&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;主要方向：离线数据批处理，在线服务系统设计研发&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;职位要求：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;热爱互联网，对语音及信号处理相关技术有浓厚的兴趣，有语音及信号处理背景更佳&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;计算机及计算机相关专业本科或本科以上学历&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;精通 Linux/Unix 平台上的 C/C++编程，有良好的编程习惯&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;精通网络编程、多线程编程&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;对数据结构和算法设计具有深刻的理解，有 1 年以上系统分析和设计的实践经验&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;具备优秀的逻辑思维能力，对解决挑战性问题充满热情，善于解决问题和分析问题&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;有强烈的上进心和求知欲，善于学习新事物&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;良好的团队合作精神，较强的沟通能力和学习能力&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;简历请投递至&lt;/span&gt;&lt;span&gt;:&amp;nbsp;&lt;/span&gt;&lt;span&gt;wuyujing@baidu.com&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;</description>
      <pubDate>Sat, 21 Jan 2017 17:20:27 +0800</pubDate>
    </item>
    <item>
      <title>深度 | 不要只看论文，缺乏工程实践才是深度学习研究的瓶颈</title>
      <link>http://www.iwgc.cn/link/4419775</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自dennybritz&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：微胖、杜夏德&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote style="color: rgb(62, 62, 62); font-size: 16px; white-space: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/blockquote&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;学术界面临的研究瓶颈不仅来自各种技术，还包括社区文化和研究流程等问题。本文提到当下发表的大部分论文中 90% 的内容都是他人的研究成果，剩下的 10% 不过是研究者测试自己的假设，而且这种形式的论文很少会带来惊喜。就连 Andrej Karpathy 都十分赞同的文中一个观点：读论文不会太在意它的结果，只是为了获得灵感。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9ZOmknUpmm3m7sKze0ibcvqpuzn1gwV3tkde1S4QOOAeE9rIzWkARR02icytydjicApxhrktPVsfoAA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;读研时，我研究的是 NLP 和信息提取，我几乎将所有时间都花在编码研究思路上。这就是有一个不喜欢接触代码导师（这样的导师估计占所有导师的 95%）的研究生所做的事。当我对问题（problems）表示担心时，总会听到这样的话「这只是一个工程问题；继续。」后来我才意识到这句话的真实含义：「我认为，一篇论文提到了这点就通不过同行评议」。这种心态似乎在学术界普遍存在。但作为一个工程师，我不禁注意到缺乏工程实践如何会让我们停滞不前。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我会拿我熟悉的深度学习社区作为一个例子，但这也可能适用于其他社区。作为研究人员的社区，我们都有一个共同的目标：推动该领域发展。推进当前最先进的技术。有很多方法做到这一点，但是，最常见的是发表论文。绝大多数发表的论文都是渐进式的，我没有贬低的意思。我相信，研究当然是渐进的，也就是说，新成果是建立在别人过去所做的基础之上的。而且这就是它应该的样子。说得具体一点，我读过的大多数论文的内容中有 90% 都是现有的东西，包括数据集、预处理技术、评估标准、基线模型架构等等。作者们通常会再添加一些新的东西，展示一下做了哪些超越现有基线的改进。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前来看，这么做也没什么错。问题不在于这个过程本身，而是如何实施。在我看来，这里面有两个突出的问题，都可以用「工程实践（just engineering）」来解决。1、浪费研究时间；2、缺乏精确性和可重复性。逐一展开。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;浪费研究时间（站在他人肩膀上的不易）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;研究者都是经过高度训练的专业人士。很多人都花了几年到几十年的时间才拿到博士学位，成为各自领域的专家。只有那些人花大部分时间做他们擅长的事——通过提出新的技术来进行创新，才有意义。就像你不想让一个训练有素的外科医生每天花几个小时从纸质表格上输入病人的数据一样。但他们每天做的几乎就是这些事情。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在一个理想状态里，一个有想法的研究者能够轻松以已有成果为基础（亦即上文提到的论文 90% 的内容），剩下 10% 的内容用于测试研究者的假设。（我发现，也有例外，如果你正在做的研究真的很新，但是大部分发表的研究都不属于这个例外）。在实践中，几乎没有什么真正新东西。研究者花上几周的时间重复做数据的预处理和后处理，一遍又一遍地部署，调试基线模型。这些工作通常包括追踪相关论文的作者，弄清楚他们用的到底是什么技巧。论文往往不会提到细节（fine print），因为这会让结果看起来没那么令人印象深刻。在这个过程中，研究者会引入数十个混杂变量（confounding variables），这基本上会让比较变得没什么意义。然而后面还有更多没意义的事情。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我意识到，在他人成果基础上做研究的难易性是决定你正在做的是什么研究的主要因素。大多数研究者都是在自己的研究基础上一遍一遍做研究。当然有人可能会说，这是因为他是某个特定子领域的专家，所以，只有继续关注类似的问题才有意义。虽然不是完全没道理，但我认为，这么做没什么意义（尤其是深度学习领域，里面很多子领域之间联系非常紧密，以至于其间的知识迁移可以做的很好）。我相信，主要的原因是从实验的角度看，在自己工作的基础上做研究是最容易的。它能带来更多的论文发表，并让周转时间变得更快。基线已经用熟悉的代码部署好了，评估已经设置好了，相关工作也写好了，等等。而且这么做，竞争更少——其他人没法能接触到你的实验装置也就没法轻易和你竞争。如果这与在他人成果上做研究一样容易，我们可能会在发表的研究中看到更多的多样性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;并非都是坏消息。当然，有几个趋势正朝着正确的方向发展。发表代码越来越普遍。像 OpenAI 的 gym（以及 Universe）那样的软件包确保了至少评估和数据集能够做到效率化（streamlined)。Tensorflow 等深度学习框通过部署低水平基元（primitives）移除了大量潜在混杂变量。有人说，我们还有很多能做的事情没做到。试想一下，如果我们有标准化的框架、标准的数据库、标准的代码库和编码风格、严格的自动评估框架和在完全相同的数据集上运行的实体，研究效率又会如何。从工程角度来看，所有这些都是简单的事情，但是可能会产生巨大的影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我认为，我们低估了这一事实：我们是在和纯软件打交道。听起来似乎显而易见，但是，兹事体大。在诸如医学或心理学领域，设计牢牢加以控制的实验几乎不可能，工作量也相当庞大。而软件领域基本上是自由的。这一领域比我们绝大多数所认为的那样还要独特。但是，我们并没有这么做。我相信，这些变化（以及许多其他变化）还未发生的原因之一在于动机不对称。说实话，几乎所有研究人员更关心论文发表、引证率以及可授予终身教职的聘任制度，而不是真地推进这个领域。他们对有利于自己的现状很满意。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;缺乏精确性（rigor）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二问题与第一个问题密切相关。上文也暗示过了。就是缺乏精确性和可重复性。理想状态是，研究人员可以控制住所有无关变量，采用新的技术，然后展示各种基线的改善情况（在显著边际内）。貌似显而易见？好吧，如果你碰巧读了很多深度学习方面的论文，那么，你会觉得这个理想状态就像直接源自科幻电影。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;实践中，当每个人采用不同框架和流程再度实现技术时，比较会变得没有意义。几乎每个深度学习模型在使用过程中都会存在很多会影响结果的「隐藏变量」，包括加进代码中的不明显的模型超参数，data shuffle seeds，变量初始化器以及其他论文通常不会提及的东西，但是，很明显它们会影响最终测量结果。当你用一个不同的框架重新使用你的 LSTM，预处理数据并写下几千行代码，你创造了多少混杂变量？我猜几百甚至几千个吧。如果你可以证明较之基准模型，有 0.5% 的边际改进，你怎么证明它们之间的因果关系？你咋知道这个结果就是结合某些混杂变量的结果？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我本人根本不相信论文结果。我读论文更多是为了获取灵感——关注论文的想法，而不是结果。这不是个应然问题。如果所有的研究人员都发布代码，会怎么样？会解决问题？实际上，并非如此。将 1 万条代码未入文献的代码放到 Github 上，说「在这里，运行这个指令，复制我的结果。」，这和生产人们愿意阅读、理解、证实和以此为基础进行研究的代码不是一回事。这就像望月新一证明 ABC 猜想，除了他，没人看得懂。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;再一次，「不过是个工程问题（just engineering）」有望解决这个难题。解决方案和问题 1（标准代码、数据组、评估实体等）解决方案差不多，但问题也差不多。实际上，发表具有可读性的代码，可能并不最有利于研究人员。如果人们找到 bug 怎么办？需要收回论文吗？除了为你效劳的单位做公关，没有其他清楚的好处，发表代码是在冒险。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文：http://blog.dennybritz.com/2017/01/17/engineering-is-the-bottleneck-in-deep-learning-research/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 20 Jan 2017 12:01:05 +0800</pubDate>
    </item>
  </channel>
</rss>
