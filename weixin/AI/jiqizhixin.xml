<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>干货 | Nervana技术深度解读：使用Neon的端到端语音识别是如何实现的</title>
      <link>http://www.iwgc.cn/link/3941389</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Nervana&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：杨旋、张瑞宁、chen chen&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;语音是一种固有的即时信号。语音中所承载的信息元素在多个时间尺度上演变。在空气压强的影响下，同一个声源的频率只会发生几百上千赫兹的变化，所以我们可以利用声音去判断一个声源的位置，并把它与周围嘈杂的环境区分开来以获得传递的信息。语音的功率谱中的缓慢变化的部分就是音素（phoneme）的生成序列，其中音素是构成我们所说的词的最小单位。除此之外，其中由单词组成的序列的变化更缓慢，这些词就组成了短语和叙事的结构。然而，这些元素在时间尺度上没有严格的区分界限。相反，各种尺度的元素都混合在了一起，所以时间上下文是十分重要的，其中较为稀少的停顿就可以作为元素之间区分的界限。自动语音识别（ASR）系统就必须弄明白这种噪声多尺度数据流，将其转换为准确的单词序列。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在撰写本文时，当下最流行和成功的语音识别引擎采用了一种混合系统来构建。即同时将深度神经网络（DNN）与隐藏马尔科夫模型（HMMs），上下文相关电话模型（context-dependent phone models），n-gram 语言模型（n-gram language models），和一种维特比搜索算法（Viterbi search algorithms）的复杂变体进行混合使用。这个模型相当的复杂，需要一套精致的训练方法，以及相当多的专业知识来帮助搭建模型。如果说深度学习的成功能教会我们什么东西，那就是我们可以经常用一种通用的神经网络来替代复杂的，多维度的机器学习方法，这些神经网络经过训练以后可以用来优化可微分的代价函数（cost function）。这种方法（我们暂且把这种方法称为「纯正」的 DNN 方法），已经在语音识别上取得了巨大的成功。现在，一旦我们有了相当多的训练数据和足够的计算资源，我们就可以更加轻松地构建一个高水准的大词汇量连续语音识别（Large Vocabulary Continuous Speech Recognition (LVCSR)）系统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本文的目的是为了对如何使用 Neon 来建立一个使用「纯正」DNN 方法的语音识别系统提供一种简单的指导介绍，其中 DNN 遵循了 Graves 和 他协作者所倡导的方法，同时，百度的人工智能研究人员对其进行了进一步的开发，让其成为了一种完整的端到端的 ASR 管道（end-to-end ASR pipeline）。同时，作为对本博文的补充，我们将会开源我们实现的这个端到端的音识别引擎（end-to-end speech recognition engine）的代码。在其最初始形式中，系统使用双向循环神经网络（BiRNN）来训练模型以直接从频谱图产生转录，而不必显示地将音频帧与转录对齐。与之取代的是一种隐式对齐，我们采用了 Graves 的连接体时间分类（CTC）算法（Connectionist Temporal Classification ，CTC）来实现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然「纯正」DNN 方法现在允许使用具有最先进性能的 LVCSR 系统进行训练，但是显式的解码步骤 ： 将模型输出转换为单词的可感知序列，在评估期间仍然是十分关键的。解码的技术是多种多样的，我们通常同时使用加权有限状态传感器（weighted finite state transducers）和神经网络语言模型（neural network language models）。如果想要了解相关的内容，那么需要一篇更加深入的文章来进行介绍，而本文主要限于 ASR 管道的训练部分。如果需要的话，我们为读者提供一些额外的参考知识来以填补空缺，希望能给读者传达构建端到端语音识别引擎的完整视图。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;简单扼要的说，端到端语音识别流水线由三个主要部分组成：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 特征提取阶段，其将原始音频信号（例如，来自 wav 文件）作为输入，并产生特征向量序列，其中有一个给定音频输入帧的特征向量。特征提取级的输出的示例包括原始波形，频谱图和同样流行的梅尔频率倒频谱系数（mel-frequency cepstral coefficients，MFCCs）的切片。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 将特征向量序列作为输入并产生以特征向量输入为条件的字符或音素序列的概率的声学模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 采用两个输入（声学模型的输出以及语言模型）的解码器并且在受到语言模型中编码的语言规则约束的声学模型生成的序列的情况下搜索最可能的转录。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9Iicdl6w0e8yz3Cx1yLlo7iarvHtWXEAL6fxMvYWia79sb7GMiaQaicAWVNHs8ZIoRw9JP0qApwcVeOOQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;处理数据&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当构建端到端语音识别系统时，一套有效的加载数据的机制是十分关键的。我们将充分利用 Neon 1.7 版本中新添加的功能：Aeon，一个能够支持图像，音频和视频数据的高级数据加载工具。使用 Aeon 大大简化了我们的工作，因为它允许我们直接使用原始音频文件训练声学模型，而不必困扰于对数据显示地预处理过程。此外，Aeon 能让我们更加容易的指定我们希望在训练期间使用的光谱特征的类型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;提取数据&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通常，语音数据以一些标准音频格式的原始音频文件和一些包含相应转录的一系列文本文件的形式被分发。在许多情况下，转录文件将包含形如：&amp;lt;音频文件的路径&amp;gt;，&amp;lt;音频文件中的语音的转录&amp;gt;的行的形式。这表示所列出的路径指向包含转录的音频文件。但是，在许多情况下，转录文件中列出的路径不是绝对路径，而是相对于某些假定目录结构的路径。为了处理不同数据打包情况，Aeon 要求用户生成包含绝对路径对的「清单文件」（manifest file），其中一个路径指向音频文件，另一个路径指向相应的转录。我们将为读者介绍 Neon 的演讲示例（包括链接）和 Aeon 文档以获取更多详细信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除了清单文件，Aeon 还要求用户提供数据集中最长的话语的长度以及最长的转录的长度。这些长度可以在生成清单文件时被提取。比如可以使用当下流行的 SoX 程序去提取音频文件的时长。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们通过训练由卷积（Conv）层，双向复现（bi-directional recurrent (BiRNN)）层和完全连接（FC）层（基本上遵循「Deep Speech 2」，如示意图所示）组成的深层神经网络来建立我们的声学模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9Iicdl6w0e8yz3Cx1yLlo7iaotLPFeibgsffF0kcQXXBxicrRQ7SVZ24RRmuA0bvNAbiaRnuZcF5GhNvA/0?wx_fmt=png"/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除了在输出层使用 softmax 激活函数，我们在其它层都采用 ReLU 激活函数。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如图所示，网络采用光谱特征向量作为输入。利用 Aeon dataloader，Neon 可以支持四种类型的输入特性：原始波形，频谱图，mel 频率谱系数（mel-frequency spectral coefficients (MFCSs)）和 mel 频率倒频谱系数（mel-frequency cepstral coefficients (MFCCs)）。MFSCs 和 MFCCs 是从频谱图中导出的，它们基本上将频谱图的每个列转换为相对较小数量的与人耳的感知频率范围更相近的独立系数。在我们的实验中，我们还观察到，在所有其他条件相等的情况下，用 mel 特征训练的模型作为输入执行效果略好于用频谱图训练的模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;光谱输入被传送到了 Conv 层。通常，可以考虑具有采用 1D 或 2D 卷积的多个 Conv 层的架构。我们将利用可以允许网络在输入的「更广泛的上下文」（wider contexts）上操作的 strided convolution 层。Strided convolution 层还减少序列的总长度，这又显著减小了存储器的占用量和由网络执行的计算量。这允许我们训练甚至更深层次的模型，这种情况下我们不用增加太多的计算资源就可以让性能得到较大的改进。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Conv 层的输出被送到 BiRNN 层的栈中。每个 BiRNN 层由串联运行的一对 RNN 组成，输入序列在如图所示的相反方向上呈现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9Iicdl6w0e8yz3Cx1yLlo7iat2TG5oKyjk4MDRUqtymBcWZc8M2mx8bjTiczbLbjicdmPefBtRIWsM1Q/0?wx_fmt=png"/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;来自这对 RNN 的输出将被串接起来如图所示。BiRNN 层特别适合于处理语音信号，因为它们允许网络访问输入序列 [1] 的每个给定点处的将来和过去的上下文。当训练基于 CTC 的声学模型时，我们发现使用「vanilla」RNN 而不是其门控变体（GRU 或 LSTM）是有好处的。这主要是因为后者具有显着的计算开销。如 [2] 所讲，我们还对 BiRNN 层应用批次归一化（batch normalization），以减少整体训练时间，同时对总体字错误率（WER）测量的模型的精度几乎没有影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在每次迭代中，BiRNN 层的输出先传递给一个全连接层，然后转而将信息传递给 softmax 层。在 softmax 层中的每个单元都对应着字母表中描述目标词汇表中的单个字符。例如，如果训练数据来自英语语料库，那么字母表通常将包括 A 到 Z 的所有字符和任何相关的标点符号，也包括用于分离文本中单词的空格字符。基于 CTC 的模型通常还需要包括特殊的「空白」字符的字母表。这些空白字符促使模型可以可靠地预测连续的重复符号以及语音信号中的人为部分，例如，暂停，背景噪声和其他「非语音」情况。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此，对于给定话语的帧序列，该模型要为每帧生成一个在字母表上的概率分布。在数据训练期间，softmax 的输出会被传输到 CTC 代价函数（后文将详细论述），其采用真实的文本来（i）对模型的预测值进行打分，以及（ii）生成用以量化模型预测值的准确性的误差信号。总体目标是训练模型来提升在真实场景下的预测表现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;训练数据&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;根据经验，我们发现使用随机梯度下降法和动量与梯度限制配对法会训练出最优性能的模型。更深层的网络（7 层或更多）在大体上也有同样的效果。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们采用 Sutskever 等人实现的 Nesterov 的加速梯度下降法去训练模型。大多数模型的超参数，例如：网络的深度，给定层中的单元数量，学习速率，退火速率，动量等等，是基于现有的开发数据集根据经验选择出来的。我们使用「Xavier」初始化方法来为我们的模型中的每一层进行初始化，虽然我们还没有系统地调查过是否通过使用其他可取代的初始化方案，来比较实验的结果是否有所优化。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们所有的模型都使用 CTC 损失标准进行训练，对 CTC 计算法内部过程的详细解释超出了本博客的范围。我们将在这里提出一个简要概述，为了获得更深的理解，建议读者去阅读 Graves 的论文。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;CTC 计算法以「折叠」函数的动作为核心，该函数采用一系列字符作为输入，并通过首先去除输入字符串中的所有重复字符，然后删除所有「空白」符号来产生输出序列。&lt;/span&gt;&lt;span&gt;比如说，如果我们使用「_」表示空白符号，然后&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9Iicdl6w0e8yz3Cx1yLlo7iaQodpzEGZAPOFaf4iacr9ibrMIJZpFFibfpiauPoVBKP4EicAoxV2LOIA9VA/0?wx_fmt=png"/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;给定一个长度为 T 的话语和其对应的「ground truth」的转录，CTC 算法会构建「转置」的折叠函数，其定义为所有可能的长度为 T 的，折叠到「ground truth」转录上的字符序列。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;任意序列出现在该「转置」集合中的概率是可以直接从神经网络中的 softmax 输出计算出来的。然后将 CTC 成本定义为序列的概率和的对数函数，它存在于「转置」集合中。该函数对于 softmax 的输出是可区分的，这是反向传播中所要计算的误差梯度。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以一个简单示例来做说明，假设输入话语有三个帧，并且相应的转录本是单词「OX」。同样，使用「_」表示空白符号，折叠为 OX 的三字符序列集包含 _OX，O_X，OOX，OXX 和 OX_。&lt;/span&gt;&lt;span&gt;CTC 算法设置 &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9Iicdl6w0e8yz3Cx1yLlo7iamicRFu2zerDOTjVHYaE5zzSEicr8uMeEIM7o6dHiaFbx1ufCT0icPibxQiaA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P(abc) = p(a,1)p(b,2)p(c,3)，其中 p(u,t) 表示单元「u」, 时间 t（帧）时 softmax 模型的输出值。因此 CTC 算法需要枚举固定长度的所有序列，其折叠到给定的目标序列。当处理非常长的序列时，通过前向 -后向算法，枚举组合可以被有效的执行，这就非常接近采用 HMMs 方法的处理问题的思想。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;评价&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一旦模型训练完成，我们可以通过预测一段系统从未听过的语音来评估它的性能。由于模型生成概率向量序列作为输出，因此我们需要构建一个解码器（decoder）来将模型的输出转换成单词序列（word sequence）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;解码器的工作是搜索模型的输出并生成最有可能的序列作为转录（transcription）。最简单的方法是计算&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9Iicdl6w0e8yz3Cx1yLlo7iaU2B9IicCLEXK69GIbgt6zFzkyh2NUomhcMPa72ctibS7mcVLKx3tzZgg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中 Collapse（...）是上面定义的映射（mapping）。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管用字符序列训练模型，我们的模型仍然能够学习隐式语言模型（implicit language model），并已经能够非常熟练地用语音拼写出词语（见表 1）。通常在字符级别用 Levenshtein 距离计算的字符错误率（CERs）来测量模型的拼写性能。我们已经观察到，模型预测的很多误差是没有在训练集中出现过的单词。因此，可以合理地预计，随着训练集规模的增加，总的 CER 数值将继续改进。这个预期在深度语音 2（Deep Speech 2）的结果中得到证实，它的训练集包括超过 12000 小时的语音数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;table align="center"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); word-break: break-all;" align="center" valign="middle"&gt;&lt;p&gt;&lt;span&gt;Model output without LM constraints&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;没有 LM 约束的模型输出&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); word-break: break-all;" align="center" valign="middle"&gt;&lt;p&gt;&lt;span&gt;「Ground truth」transcription&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;完全实况转录的结果&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;younited presidentiol is a lefe in surance company&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;united presidential is a life insurance company&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;that was sertainly true last week&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;that was certainly true last week&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;we’re now ready to say we’re intechnical default a spokesman said&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;we’re not ready to say we’re in technical default a spokesman said&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;表 1：模型对华尔街日报评估数据集的预测样本。我们故意选择了模型难以判断的例子。如图所示，加入语言模型约束后基本上消除了在没有语言模型的情况下产生的所有「拼写错误」。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然我们的模型显示了非常好的 CER 结果，模型的读出单词拼写（spell out words phonetically）的倾向导致了相对较高的单词错误率。我们可以通过加入从外部词典和语言模型得到的解码器来约束模型，以此改进模型的性能（WER）。根据 [3,4]，我们发现使用加权有限状态传感器（WFST）是一个特别有效的完成这项任务的方法。我们观察到 WER 数值在 WSJ 和 Librispeech 数据集上相对提高了 25％。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;表 2 列出了使用华尔街日报（WSJ）语料库训练的各种端到端语音识别系统。为了测试「苹果」（公司）与「苹果」（水果）的识别结果，我们选择仅用 WSJ 数据集训练和评估的系统的公开数据进行系统间的比较。然而，结果显示在同一数据集上训练和评估的混合 DNN-HMM 系统比使用纯深神经网络架构的系统表现更好 [6]。另一方面，结果显示当训练集的数据量更大时，纯深度神经网络架构能够实现与混合 DNN-HMM 系统相同的性能 [引用 DS2]。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;Reference&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;CER&lt;br/&gt;(no LM)&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;WER&lt;br/&gt;(no LM)&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;WER&lt;br/&gt;(trigram LM)&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;WER&lt;br/&gt;(trigram LM w/ enhancements)&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;Hannun, et al. (2014)&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;10.7&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;35.8&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;14.1&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;N/A&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;Graves-Jaitly (ICML 2014)&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;9.2&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;30.1&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;not reported&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;8.7&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;Hwang-Sung (ICML 2016)&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;10.6&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;38.4&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;8.88&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;8.1&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;Miao et al. (2015) [Eesen]&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;not reported&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;not reported&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;9.1&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;7.3&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;Bahdanau et al. (2016&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;6.4&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;18.6&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;10.8&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;9.3&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(205, 224, 223);" align="center" valign="middle"&gt;&lt;span&gt;Our implementation&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(205, 224, 223);" align="center" valign="middle"&gt;&lt;span&gt;8.64&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(205, 224, 223);" align="center" valign="middle"&gt;&lt;span&gt;32.5&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(205, 224, 223);" align="center" valign="middle"&gt;&lt;span&gt;8.4&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(205, 224, 223);" align="center" valign="middle"&gt;&lt;span&gt;N/A&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;表 2：我们只使用华尔街日报数据集来训练和评估各种端到端的语音识别系统的性能。CER（character error rate）指的是比较由模型得到的字符序列与实际转录的字符序列的字符错误率。LM 指的是语言模型。最后一列指的是使用附加技术（如重新评分、模型聚合等）解码的例子。&lt;/span&gt;&lt;br/&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;未来的工作&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;将 CTC 目标函数嵌入神经网络模型的语音识别模型，让我们初次看到了这种 纯正 DNN 模型的能力。不过，最近，所谓的基于注意机制（attention mechanism）增强的编-解码器（encoder-decoder）的 RNN 模型正在兴起，并作为用一种使用 CTC 标准 [4,5] 训练的 RNN 模型的可行的替代方案。基于注意机制的编-解码器模型与基于 CTC 标准的模型，都是被训练用于将声音输入序列（acoustic input）映射（map）到字符/音位（character/phoneme）序列上。正如上面所讨论的，基于 CTC 标准的模型被训练用于预测语音输入的每个帧对应的字符，并在逐帧的预测与目标序列序列之间搜索可能的匹配。与之相反，基于注意机制的编-解码器模型会在预测输出序列之前首先读取整个输入序列。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该方法概念上的优点是，我们不必假设输出序列中的预测字符是相互独立的。CTC 的算法基于这个假设，而该假设是毫无根据的——因为字符序列出现的顺序是与比之之前较早出现的字符序列是高度条件相关的。最近的研究工作显示，LVCSR 系统的基于注意机制的编-解码器模型相对于基于 CTC 标准的模型在字符出错率上有明显的改善 [4]。在我们这两种方法被整入语言模型之前进行评估，得出的评断是正确的，这也支持了基于注意机制的模型是比基于 CTC 标准的模型更好的声学模型的论断。然而，值得指出的是，当语言模型被用来确定单词错误率时，这种性能上的差异就消失了。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们正致力于建立 ASR 系统的基于注意机制的编-解码器网络的 Neon，竭诚欢迎各类参与。代码可以参见&lt;/span&gt;&lt;span&gt; https://github.com/NervanaSystems/deepspeech.git.&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em style="color: rgb(136, 136, 136);"&gt;&lt;span&gt;原文链接：https://www.nervanasys.com/end-end-speech-recognition-neon/&lt;/span&gt;&lt;/em&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 16 Dec 2016 11:40:09 +0800</pubDate>
    </item>
    <item>
      <title>开源 | 谷歌开源Land Lines：简单一笔为你匹配谷歌地球对应位置</title>
      <link>http://www.iwgc.cn/link/3941390</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自GoogleDevelopersBlog&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;新年将近，如果你不愿意亲自在寒冷的冬天里外出旅行，那么你可以尝试一下谷歌地球（Google Earth）。但地球这么大，你却不知道看哪里？没关系，谷歌近日又推出了一项神奇的新功能：Land Lines。你只需要简简单单画一笔，谷歌就能为你将这一笔和谷歌地球上的地理或建筑线条匹配起来，将你带到你意想不到的地方：东南亚群岛的海岸线、欧洲小镇的街角、南美横贯的河流……&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这一切只需要轻轻一画。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;体验地址：&lt;span&gt;https://lines.chromeexperiments.com&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该项目有两种体验方式。一是画（draw）——能帮你找到与你画的线匹配的卫星图像；二是拉（drag）——可以创建一条互相连接的河流、高速公路和海岸线的线条。下面是一个简单的演示：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_gif/KmXPKA19gW9Iicdl6w0e8yz3Cx1yLlo7iaAezXBn7X5YJ1o26FxiccEomnBvm6o8obxLIsWyBBcsNz7QLbMypwkfw/0?wx_fmt=gif"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这一切都运行在你的手机网页浏览器中，不需要任何服务器。（桌面 Chrome 浏览器也可使用。）据谷歌介绍，这些响应是通过机器学习、数据优化和 vantage-point tree 分析图像和存储该数据所得到的。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌解释说：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;我们组合性地使用了 OpenCV 的基于结构化森林（Structured Forests）机器学习的边检测和 ImageJ 的 Ridge Detection 库。这将最初的超过 5 万张高分辨率图像数据集减少到了能够代表这些线的形状的仅仅几千张图像，如下图所示。这样的处理以往需要花费几天时间，我们只用了几个小时就完成了。&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9Iicdl6w0e8yz3Cx1yLlo7iawDHEz35Zv6D0uTmzZDSnk9cgibbtVY2PPZbJAFbvMyTRs3bqVZzUnqQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;来自线条检测处理（line detection processing）的输出示例。其中主线以红色突出显示，而辅助线则以绿色显示。&lt;/span&gt;&lt;/em&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在绘画实验中，谷歌将结果数据存储到了 vantage-point tree 中。这让该应用可以有效地在所有图像上运行手势匹配（gesture matching），并在毫秒级的时间内给出结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9Iicdl6w0e8yz3Cx1yLlo7iaTWWpWggibvIFAuzvCQzEs2O3gWicHktdWVUYfLsVgb8kc78bUhnkz2OQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;使用 vantage-point tree 的一个早期的手势匹配样本，其中右边是画出的输入，而左边则是最接近的结果。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9Iicdl6w0e8yz3Cx1yLlo7iaqnT6eqGRgJM7aC9mFKiaWLhZthePNwkL82mE5LnoibicWA0OlToTBouqQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;另一个用户手势分析的示例，其中右边是画出的输入，而左边则是最接近的结果。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该项目是与黑客兼艺术家 Zach Lieberman 合作开发的。Land Lines 是一个大型视觉数据连接主题探索实验。开发团队表示他们在他们的开发过程中采用了多种机器学习库。Lieberman 还写了一份有关的学习经历，该项目的代码也已经开源，相关链接如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Lieberman 的经历：&lt;span&gt;https://developers.google.com/web/showcase/2016/land-lines&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Land Lines 开源地址：&lt;span&gt;http://github.com/ofZach/landlines/&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;vantage-point tree 开源地址：&lt;span&gt;https://github.com/fpirsch/vptree.js&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;OpenCV Structured Forests 机器学习：&lt;span&gt;http://docs.opencv.org/3.1.0/d0/da5/tutorial_ximgproc_prediction.html&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;ImageJ 的 Ridge Detection 库：&lt;span&gt;http://imagej.net/Ridge_Detection&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 16 Dec 2016 11:40:09 +0800</pubDate>
    </item>
    <item>
      <title>学界 | IEEE发布人工智能道德准则设计，确保人工智能为人类服务（附草案）</title>
      <link>http://www.iwgc.cn/link/3941391</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自TechCrunch&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：Jane W&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;随着人工智能应用的日益普及，对人工智能所涉及到的法律、社会、伦理和道理问题也正在成为一个越来越值得关注的话题。近日，电气和电子工程师协会（IEEE）发布了世界首个人工智能道德准则设计草案《Ethically Aligned Design》。该草案目前仍在意见征求中，草案 PDF 版本可点击文末「阅读原文」下载。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;专业技术协会 IEEE 认为，有道德标准设计的人工智能系统能够造福全人类并且避免算法偏差，但是技术行业缺乏对道德的归属感和责任感已经成为阻碍它发展的一个因素。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicr33MwRF3MYPqDITzNX5zhRRzang7dNX0FrcFVP0iaHvsg3XBr7mA27O0lKAESia5FNyPNB50Pgs6w/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;近日，IEEE 发布了第一个框架文件版本，希望它能引导行业走向光明，并帮助技术人员建立和睦有益的自治系统，而不是认为道德与他们没有关系。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该文件称为「道德准则设计（Ethically Aligned Design）」，它基于 100 多名在人工智能、法律、伦理、哲学和政策领域工作的学术界、科学界、政府和企业部门的「思想领袖」，包括了一系列详细的建议。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;IEEE 希望它能成为人工智能/自治系统（AS）技术专家的重要参考文件，因为自治技术在未来几年内会进入越来越多的系统。它也邀请了有关各方面对该文件做了反馈——IEEE 全球倡议网站（The IEEE Global Initiative』s website）有标准的提交指南模板。网站声明所有的反馈意见都将公开发布，这些反馈应不晚于 2017 年 3 月 6 日提交。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;网站地址：&lt;span&gt;http://standards.ieee.org/develop/indconn/ec/autonomous_systems.html&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该组织更广泛的希望是能够通过创造共识和促进开发实现道德目标，为 IEEE 标准提出基于道德准则设计概念的倡议。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「通过为技术专家提供同行推动的、实用的建议，以创建符合道德标准的自治和智能的产品、服务和系统，我们可以超越与这些技术相关的恐惧，为人类的现在及将来带来有价值的福利，」IEEE 标准协会（IEEE Standard Association）常务董事 Konstantinos Karachalios 在一份声明中说。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这份 136 页的文件分为一系列章节，从一般原则开始——例如需要确保人工智能尊重人权、运作透明，以及人工智能是否为自动决策负责——然后再转到更具体的领域，例如如何将「人类准则或价值观」融入自治系统，如何解决潜在的偏见，如何达成信任，以及如何从外部评估并实现价值校正。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一部分讨论指导伦理研究和设计的方法论——与其它问题一起（例如工科学位的常规课程不包含伦理学），在这里，技术行业缺乏对道德的所有权和责任感被认为是一个问题。IEEE 还指出实现伦理人工智能的其它问题，例如自治系统缺乏一个独立的审查组织来监督算法操作，以及在创建算法时使用「黑箱组件（black-box component）」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;IEEE 也提到，一个帮助技术行业克服道德盲点的建议是确保那些建立的自治技术覆盖「多学科和多样化的群体」，以便涵盖所有潜在的伦理问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;它还讨论了制定「监督智能和自治技术的制造过程」的标准，以确保受众用户不被自主行为伤害。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在监督产品是否符合道德标准时，要建立「独立的国际协调机构」，并且监督应该时刻存在，无论是在产品发布时还是在其发展并与其它产品交互时。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「当构建可能影响人类安全或健康的系统时，仅仅假定系统的工作方式是不够的。工程师必须确认和评估黑箱软件所涉及的道德风险，并在可能的情况下实施应急策略，」IEEE 写道。「技术专家应该能够通过透明和可追溯的标准来描述他们的算法或系统要做什么。在我们力所能及的范围内，它应该是可预测的，但考虑到人工智能/自治系统的性质，它可能更需要具有追溯性（retrospective）和缓解导向性（mitigation oriented）。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「类似于航空领域的飞行数据记录仪，这种算法的可追溯性能够提供导致特定可疑或危险行为的算法参考。即使这些过程仍然有些不透明，技术人员也可以寻求间接验证结果和检测危害的方法。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;它的最终结论是，因为决策过程的不透明性以及检查或验证这些结果具有困难性，工程师「只有在非常谨慎和伦理关怀」的情形下部署黑箱软件服务或组件。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;文件中另一部分——有关通用人工智能的安全性和有益性——也警告说，随着人工智能系统越来越有能力，人工智能「无法预期或无意识的行为会越来越危险」，而提高安全性到通用级别会使未来的人工智能系统面临困境。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「在开发和部署日益自主和强大的人工智能系统时，研究人员和开发人员将面临越来越复杂的伦理和技术安全问题，」文件指出。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该文件还涉及到对由个人数据支持的人工智能系统固有的不对称性——从这个角度讲，该技术获得的收益不是平均分配的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「人工智能和自治系统（AI/AS）驱动了算法经济，它们可以广泛访问我们的数据，但我们仍然与这个来源于生活发现的收益相脱离，」它提到。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「为了解决这种不对称性，人们有必要定义、访问和管理他们的个人数据，作为他们个人身份信息的管理人。关于收集个人信息的类型，还需要定义新参数加以规范。未来应建立对有限具体数据交换的知情权和同意权机制，而不是长期牺牲信息资产。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;原文链接：https://techcrunch.com/2016/12/13/ieee-puts-out-a-first-draft-guide-for-how-tech-can-achieve-ethical-ai-design/&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 16 Dec 2016 11:40:09 +0800</pubDate>
    </item>
    <item>
      <title>资源 | 谷歌开源机器阅读理解数据集MC-AFP</title>
      <link>http://www.iwgc.cn/link/3941392</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自GitHub&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;MC-AFP 是一个基于公众可用的 Gigaword 数据集（AFP 部分）生成的机器理解数据集。创造这样数据集的技术在论文「Building Large Machine Reading-Comprehension Datasets using Paragraph Vectors」中有所报告。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们生成了一个大约有 2 百万样本的数据集，在上面估算人类的准确率大概为 90%。一种结合了循环神经网络的表征能力与全连接多层网络判别能力的全新神经网络架构在此数据集上取得的最好结果是：83.2% 的准确率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;压缩包中附上的是加密的 MC-AFP 数据集以及密码。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;项目地址：&lt;/span&gt;&lt;span&gt;https://github.com/google/mcafp&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;论文：Building Large Machine Reading-Comprehension Datasets using Paragraph Vectors&lt;/span&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：我们提出的技术对机器阅读理解任务有双重贡献：使用 paragraph-vector 模型创造大型机器理解（MC）数据集的技术；一种全新的、混合的神经网络架构，它结合了循环神经网络的表征能力与全连接多层网络的判别能力。我们使用 MC-数据集生产技术建立了一个大约 2 百万样本的数据集，在上面我们凭借经验判断出了人类水平（大约 91）的准确率，以及各种计算机模型的表现。在我们试验过的所有模型中，我们的混合神经网络架构获得了最高的表现（83.2）的准确率。该架构与人类水平之间的差距为未来模型的提升提供了足够的空间。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;论文地址：&lt;span&gt;https://arxiv.org/pdf/1612.04342v1.pdf&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 16 Dec 2016 11:40:09 +0800</pubDate>
    </item>
    <item>
      <title>学界 | Yann LeCun提交ICLR 2017论文：使用循环实体网络跟踪世界状态</title>
      <link>http://www.iwgc.cn/link/3941393</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自arXiv.org&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：杜夏德&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;论文标题：TRACKING THE WORLD STATE WITH RECURRENT ENTITY NET WORKS&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9Iicdl6w0e8yz3Cx1yLlo7iah9OcsiacMU7QP2ibIE0A0TYZRQIhxsrq9ZHloUKxryT1NkdK7SbkKSNQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：我们介绍了一种新模型：循环实体网络（EntNet/Recurrent Entity Network）。它配备了一个动态长期记忆（dynamic long-term memory），能让它在接受新数据时维持和更新世界最新状态的表征。在语言理解任务中，它不仅能像记忆网络（Memory Network（Sukhbaatar et al., 2015））那样能在被要求回答一个问题或者给出回应时推理，还可以一边阅读文本一边进行推理。就像神经图灵机（Neural Turing Machine）或者可微神经计算机（Differentiable Neural Computer，Graves et al., 2014; 2016）那样，它能维持一个固定大小的记忆并能学习去执行基于位置和内容的读取和写入任务。然而，与那些模型不同的是，它有一个简单的并行架构，该架构包含了几个记忆位置，这些位置能实现同时更新。该 EenNet 在 bAbI 任务中实现了新的最佳表现纪录，同时也是首个能在一万个训练样本场景中解决所有任务的方法。我们还证明了它可以解决一个需要大量事实支持的推理任务，而其它方法无法解决这个问题，同时它也可以泛化到其训练范围之外，也能被实际地用到 Children』s Book Test 等大型数据集中，在这项任务上，它的表现十分具有竞争力，能一次阅读一个故事。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;论文地址： &lt;span&gt;https://arxiv.org/pdf/1612.03969v1.pdf&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 16 Dec 2016 11:40:09 +0800</pubDate>
    </item>
    <item>
      <title>重磅 | 谷歌大脑养成记：从识别猫到突破性机器翻译</title>
      <link>http://www.iwgc.cn/link/3928460</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自NYT&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;em style="color: rgb(136, 136, 136); font-size: 12px;"&gt;谷歌如何使用人工智能来改进谷歌翻译等许多谷歌服务？《纽约时报》杂志今日发布了一篇重磅长篇《The Great A.I. Awakening》全面解读谷歌利用机器学习重塑自身的战略。机器之心编译时进行了适当的删减。&lt;/em&gt;&lt;br/&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;序言：你即你所读&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;十一月一个周五的晚上，东京大学著名人机交互教授 Jun Rekimoto（暦本純一）正在准备演讲，他开始留意到社交媒体上出现了一些奇特的博文。谷歌公司颇受欢迎的机器翻译服务已经突然有了大幅提升。Jun Rekimoto 开始亲自测试这一服务。结果让他惊讶不已。他在一篇博文中写下了一些发现。他比较了两个版本的《伟大的盖茨比》（一个 1957 年 Takashi Nozaki 的版本，一个是 Haruki Murakami 近期的修订版本）中的几个句子，选择了谷歌翻译能够翻译的句子。他后来对我解释道，Haruki Murakami 的翻译非常优美，但显然是 Murakami 风格的。谷歌翻译后的日文尽管有点小小的不自然，但是，读起来感觉更加易懂（transparent）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;接着，博文的第二部分从另一个方向（日文到英文）检查了谷歌翻译。他把自己翻译的海明威《乞力马扎罗的雪》的开头输入进去，让谷歌翻译成英文。结果发现翻译的准确度难以置信。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Rekimoto 将自己的发现放在了 Twitter 上，几个小时后，数以千计的人也贴出了自己的实验结果。一些翻译结果很赞，另一些的翻译结果颇有喜剧效果。每个人都好奇：谷歌翻译是怎么变得如此惊艳的？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌公司的人工智能研究机构谷歌大脑（Google Brain）成立于五年前。成立原则是：通过试错熟悉周围世界的人工「神经网络」或许会发展出类似人类的灵活能力。这个概念不是新东西。不过，其大部分历史，在绝大多数计算机科学家看来，有些狼藉甚至神秘。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管如此，2011 年以来，谷歌大脑已经证实深度学习方法可以解决传统手段无法解决的难题。语音识别之前并不理想，直到谷歌大脑更新了这一技术；机器学习的应用在谷歌移动平台安卓上的表现堪比人类。同样，图像识别也是硕果累累。不到一年前，谷歌大脑首次开始充满热情地更新整个产品线。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;翻译工具声名鹊起的那一年是 2006 年，打那时起，它就成为谷歌最可靠也最受欢迎的资产；月用户量达 5 亿多人，每天需要进行 1400 亿词的翻译。它不仅自成一体，也是谷歌邮件、浏览器以及其他产品的一部分，是该公司数字业务中浑然天成的一部分。Pichai 解释说，不仅仅是难民危机，公司也估计翻译的地理政治重要性：他身后的屏幕上出现了一幅图表，一个陡峭的曲线表明最近阿拉伯语和德语之间的翻译需求翻了五番。谷歌翻译团队一直在稳定地为产品添加新的语言和功能，不过，过去四年的质量提升已经明显放缓。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;直到今天，翻译工具引进了人工智能技术。首轮尝鲜的语言包括英语、西班牙语、法语、葡萄牙语、德语、中文、日语、韩语和土耳其语。接下来还有上百种语言——大概每个月处理八种，直至明年年底。翻译工具的焕然一新仅花了九个月的时间。人工智能系统一夜之间取得的成果相当于旧的技术一辈子成果的总和。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌决定以人工智能为中心的策略也反映出整个业界范围内的机器学习热。过去四年中，特别是谷歌、Facebook、苹果、亚马逊、微软和百度这六家公司已经启动了人工智能人才争夺战，特别是争夺大学里的人才。公司许诺的资源和自由已经让顶尖学术机构的人才越来越少。硅谷谁人不知 Mark Zuckerberg 用电话、视频聊天等糖衣炮弹亲自督导公司最想要的研究生。诱人的七位数年薪并非罕见。参加这一领域最重要的学术会议的人员已经翻了四倍。利害攸关的不仅是渐进创新，还要控制住能够代表未来全新计算平台的东西：无处不在的人工智能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;Part 1:学习的机器&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1. 大脑的诞生&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然 Jeff Dean 的职称是高级研究员（senior fellow），但却是谷歌大脑实际上的负责人。作为医疗人类学家与公共健康流行病学专家的儿子，Dean 在世界多个地方长大——明尼苏达州、夏威夷、波士顿、阿肯色州、日内瓦、乌干达、索马里、亚特兰大。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在高中和大学的时候，他写的软件被世界卫生组组所使用。从 1999 年开始，他就加入了谷歌，从此他几乎插手了谷歌的每一个重大业务中的核心软件系统。谷歌公司文化的一个可爱伪影就是 Jeff Dean Facts，模仿「罗礼士的真相」写下：Jeff Dean 的 PIN 是 pi 的后四位；在贝尔发明电话之后，他看到有一通 Jeff Dean 的未接电话；在系统最大等级是 10 的时候，Jeff Dean 提升到了 11 级（这一个确实是真的）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2011 年的一天，Dean 走进谷歌的休息区碰见了吴恩达。当时吴恩达还是斯坦福大学计算机科学教授，也是谷歌的顾问。吴恩达告诉了 Dean 关于 Project Marvin 的事，这个项目是吴恩达最近帮助建立的实验「神经网络」的一次内部尝试。Dean 自己也在 1990 年在明尼苏达大学上学时做过简单版本的神经网络。如今，研究神经网络的学术人员 5 年来又开始发展，从屈指可数的几个增长到了几十位。吴恩达告诉 Dean 由谷歌神秘部门 X 实验室正在做的 Project Marvin 已经取得了一些惊人成果。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Dean 对此非常感兴趣，愿意在此项目上付出「20%」的工作时间，也就是期望每个谷歌员工在自己核心工作之外的项目上付出的工作时间。不久之后，他建议吴恩达让另一个有神经科学背景的 Greg Corrado 加入进来。在春末，吴恩达最好的毕业生之一 Quoc Le 也加入了进来，成为了第一个实习生。然后，一些谷歌工程师喜欢称 Project Marvin 为谷歌大脑。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因为人工智能一词是 1956 年才被首次提出，一批研究员一直以来在思考创造人工智能的最佳途径，写出很大的、综合的程序，能同时展示逻辑推理与世界上足够知识的规则。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;例如，如果你想要从英语翻译到日语，你要把英语的所有语法规则编程到计算机，然后是牛津英语词典中的所有定义。接下来你还要把日语的语法规则与单词编程，只有所有的语句用源语言输入之后才能让它把语句翻译成目标语言。这种观念通常被称为符号人工智能，因为它对认知的定义是基于符号逻辑的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但这种老旧的方法主要有两个问题。第一个就是这样做非常耗费人工时间。第二个就是这种方法只能处理规则和定义都非常清晰的问题，比如数学问题和国际象棋。对于翻译来说，这种方法完全失效，因为词语不仅只有词典上定义，而且语言的使用中常常有很多特殊用法，尽管有很多语法规则。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;iframe class="video_iframe" data-vidtype="1" style="   z-index:1; " height="375" width="500" frameborder="0" data-src="https://v.qq.com/iframe/preview.html?width=500&amp;amp;height=375&amp;amp;auto=0&amp;amp;vid=e0355310x9a" allowfullscreen=""&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;一份 1961 年的文摘强调人工智能研究的前提：如果你可以编程让计算机模拟高级的认知任务如数学和象棋，那么你终将找到让计算机实现模拟意识的途径。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个系统所能做到的事情是有限的。20 世纪 80 年代，卡内基梅隆大学的一位机器人方面的研究员指出，让计算机去做那些成人能够做到的事情很容易，但是让它们去做那些 1 岁孩童做的事情几乎是不可能的，像是拿着一颗球，或者是辨别车辆等。在 20 世纪 90 年代前，计算机象棋方面取得了一些进展，但我们离强人工智能还很远。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌大脑是首个投资人工智能所能呈现的可能的重大商业机构。Dean、Corrado 和吴恩达用兼职时间工作，协作实验，但他们很快就取得了进展。他们从近期的理论基础以及上世纪 80 年代、90 年代的思路中获取设计灵感，并利用公司无与伦比的数据资源和大量计算基础设施，在大量的银行标记数据（例如，准确录音的语音文档）上构建网络，结果计算机的回应和真实情况实现了很好的匹配。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Dean 相当保留地说，「进化中动物发育出眼睛是一大进步。」当时，我们像往常一样坐在一间带有白板的会议室，他在白板上密密麻麻写上谷歌大脑的时间轴，以及与近期神经网络的历史拐点的关系。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「现在计算机有了眼睛，我们可以围绕现有的能力建造眼睛从而理解不同的难题。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他们建造的这些能力看起来很简单，但影响很大。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicr33MwRF3MYPqDITzNX5zhT1DuUhcFWc3IzJz4JZYsH5qY2ojdHOMmcR4JRouY5wMDZUCliaRZMiaA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图：Geoffrey Hinton&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2. 想像不到的实习生&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Dean 说，在谷歌大脑诞生的一两年左右，该部门在开发一岁儿童智能水平的机器上取得非常好的结果。其语音识别团队将他们的旧系统和神经网络结合了起来，实现了近 20 年来最好的提升。他们的系统的物体识别能力也提升了一个数量级。这并不是因为谷歌在这一年突然想出了什么突破性的方法，而是谷歌开始向其中投入更为显著的资源和人才。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;作为当时一些概念的提出者和优化者，Geoffrey Hinton 在谷歌大脑成立的第二年加入谷歌大脑，和吴恩达共事（吴恩达现在在百度领导着 1300 人的人工智能团队）。当时，Hinton 只想离开其在多伦多大学的岗位 3 个月，所以因为一些合同上的原因他的身份是实习生。在「实习」培训期间，Hinton 还问了「什么是 LDAP（一种用户登录方法）？」这样的问题。那里有很多 25 岁左右的聪明学生一起培训，他们只是对深度学习有所耳闻而已，他们会问：「这个老头子是谁？为什么他在这里实习？」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Hinton 说：「在午餐时间，有人大叫：『Hinton 教授，我上过你的课！你在这里做什么？』自那以后，一切都变好了。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;几个月后，Hinton 带着两个学生在 ImageNet 图像识别竞赛上展现出了真正激动人心的成果。谷歌很快就接触了 Hinton，要给他和他的学生工作邀请。他们接受了。Hinton 说：「我认为他们对我们的知识产权感兴趣，结果发现他们感兴趣的是我们。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Hinton 来自一个老式的英国家庭，希望在天文学或流体动力学领域做出一些小的贡献。他有一位伟大的曾曾外祖父乔治·布尔——计算机基础的布尔逻辑的提出者，还有一位曾曾祖父是著名外科医生，他的父亲是一位有冒险精神的昆虫学家，他的叔叔是洛斯阿拉莫斯国家实验室研究员……他在剑桥和爱丁堡上学，然后在卡内基梅隆任教，最后落脚多伦多大学，并在那里度过了他的半生时间（他的研究工作得到了加拿大政府的大力支持）。我在当地的谷歌办公室拜访了他，他会说一些奇怪的话，比如说：「计算机会比美国人先理解讽刺。」&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自 60 年代末 Hinton 在剑桥的本科阶段以来，他就一直在研究神经网络，被视为这个领域的先驱。但在那个时候，当他谈论机器学习时，人们看他就好像在谈论托勒密球或水蛭。那时候神经网络被当作是未经证实的愚蠢想法。造成这种看法的主要原因是当时一个被炒作过度的项目：Perceptron（感知器）——康奈尔大学心理学家 Frank Rosenblatt 在 50 年代末开发的一个人工神经网络。该研究的资助者美国海军预期其「能走路、说话、看见、书写、复制自己和意识到自己的存在」。结果没让任何人满意。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;美国的人工智能元老 Marvin Minsky 也在他 1954 年普林斯顿的论文里研究过神经网络，但自那以后，他渐渐地就对 Rosenblatt 对神经范式的夸张说法感到厌倦了（他们当时也在竞争美国国防部的资金）。后来，Minsky 和他的 MIT 同事出版了一本书，证明有一些非常基本的问题是感知器无法解决的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Minsky 对感知器的批评只扩展到了一层（layer）的网络，而后来，他却又阐释了和当代的深度学习非常相似的思想。但那个时候 Hinton 已经明白使用很多层的网络可以执行复杂的任务。对于神经网络的最简单的描述是：基于发现数据中模式的能力来进行分类和预测。如果只有一层，你只能发现一个简单模式；有更多的层时，你甚至能发现模式的模式。比如图像识别，现在这项任务依赖于一种被称为「卷积神经网络」的技术（该技术是由 Yann LeCun 在其 1998 年的开创性论文中提出的，他是 Hinton 的博士后）。该网络的第一层学习非常简单的「边（edge）」，意味着一个 off-pixel 之后跟着一个 on-pixel，或相反。后续的每一层都会在前一层中寻找模式。边的某一个模式可能是圆或三角形，而圆或三角形的模式又可能是一张脸……这种技术有点类似于人类视觉系统处理到达眼睛的信息的方式。在每一个感知步骤，不重要的细节会被丢弃。如果边、圆、三角形之类的模式能够组合成一张脸，那么我们的目的就达到了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;iframe class="video_iframe" data-vidtype="1" style="   z-index:1; " height="375" width="500" frameborder="0" data-src="https://v.qq.com/iframe/preview.html?width=500&amp;amp;height=375&amp;amp;auto=0&amp;amp;vid=k0355veznol" allowfullscreen=""&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;多层的深度神经网络的问题在于试错（trial-and-error）的部分会随着深度的增加而越来越复杂。这就像让孩子学习把玩具放进身边的箱子 A，一下子就学会了。如果让他学习带着玩具走过一段很多分支的路然后放进 A 箱，那就可能会在中间走错路。怎么让机器学会这样复杂的指令呢？为了解决这个问题，Hinton 及其同事在 70 年代末和 80 年代的停滞期发明（或者说重新发明）了一个解决方案，然后计算机科学家对神经网络的兴趣有了短暂的恢复。Hinton 说：「人们对此感到兴奋，但我们炒作过度了。」不久之后，计算机科学家又继续将 Hinton 看作是怪人和神秘主义者了。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但这些思想却受到了哲学家和心理学家的欢迎，他们将其称为「联结主义（connectionism）」或「并行分布式处理（parallel distributed processing）」。Hinton 说：「少数几个人的想法就让这个思想继续燃烧，这是一个不错的神话。在人工智能领域这确实是事实，但是在哲学领域，很多人相信这是正确的，他们只是不能实践。」尽管 Hinton 得到了加拿大政府的资助，但他自己也不能做到。「那时候的计算机算力和数据都不够。我们这边的人常常说：『呃，如果我有一台真正大的机器，它就有效果。』这可不是什么很有说服力的论据。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3. 深度学习的深度解释&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人脑中神经元的平均数量的数量级大概是 1000 亿。其中每一个神经元都与其它 10000 个神经元相连，这意味着突触的数量是在 100 万亿到 1000 万亿之间。我们目前仍然远远不能构建那么大规模的网络，但谷歌大脑的投资已经帮助实现了大约小鼠大脑的人工神经网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了理解为什么规模会如此重要，你首先要理解这项技术的细节。有些人认为人工智能可以直接从图书馆或网络上读取理解知识，但事实并非如此。它们的工作是在数据中寻找模式——先是基本模式，然后寻找更复杂的模式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果这个简短的解释不够说明问题，没有技术背景的读者可以阅读下一节关于猫的故事（当然这一节也有猫）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;假设你要在老式的符号式人工智能模型上编程一个猫识别器。那么你需要花大量的时间来帮机器定义什么是「猫」——四条腿软软的毛、尖尖耳朵喵喵叫……所有这些信息组合起来构成了一只猫。然后你向其展示一张图片用于识别。首先，该机器需要分解图片中不同的元素，然后再将这些元素和它记忆中的信息进行比对。如果有四条腿、尖耳朵、有胡须、有尾巴、表情傲慢，那么这就是一只猫。但是这个模型却不能识别苏格兰折耳猫——这种有基因缺陷的猫的耳朵耷拉在头上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在让我们来尝试用神经网络识别猫。我们并不会人工编写猫的定义，它们的定义存在于大量互连的「开关」之中，就像一条带有大量分岔路的道路。在这团开关的一边是输入的图片，在另一边则是对应的输出标签。然后你让网络自己通过调整其中的每一个开关来将一个输入映射到对应的输出。这个训练过程就像是走隧道迷宫一样，目的就是要将输入和合适的输出连接到一起。训练数据越多，隧道的数量和复杂性就越大。一旦训练完成，这团开关之中就有了大量的隧道，可以在其从未见过的数据上做出可靠的预测，这就是所谓的「监督学习」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为什么这样的网络需要如此之多的神经元和数据呢？因为从某种程度上讲，该网络的工作方式就像是一种「机器民主」。可以假想你想要计算机进行 5 种分类，你的网络由数亿个神经元「投票人」组成，他们可以进行 5 个选项的投票：猫、狗、蜘蛛猴、勺子和除颤器。然后你拿出一张图片问：这是猫、狗、蜘蛛猴、勺子和除颤器中的哪一个？投票者开始投票，然后网络统计员根据大多数的意见认为这是狗。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然后你告诉他：「不对，这是猫。再投一次。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然后，统计员回头检查哪些投了猫，哪些选了其它的。选了猫的投票者获得了加权——「一票可当两票用」（至少在选择猫的时候，选择其他分类时权重可能不同）；这样不断调整知道得到正确的答案。所以重要的不是单个神经元的票，而是整个投票的模式。你的投票者越多，你就能获得越多的模式。如果你有数百万个投票者，你就能获得数十亿种模式。每一种模式都可以对应一种结果，这些不同的模式归类成不同的类别。训练的数据越多，网络就越了解一种模式属于哪一个类别，就能在未来遇到没有标注的图片时做出更准确的分类。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;计算机科学领域对这些思想有如此大的抵触的部分原因是其输出只是基于模式的模式（patterns of patterns) 的预测，这不会是完美的，而且这样的机器也不能为你定义到底什么是一只猫。只有当它看到一只猫时，它才能知道那是猫。但这个方法的最主要缺点还是数据量。要让神经网络理解一只猫是在懒洋洋晒太阳还是躲在阴影里注视世界，我们需要给神经网络送入大量大量的数据，需要大量大量的投票者。而这是很难满足的需求。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;值得一提的是，神经网络的概率性本质使其无法胜任某些任务。但有些情况我们又需要它完美，比如自动驾驶汽车的应用。但这不是唯一的缺陷。监督学习是一种基于有标签数据的试错过程。也就是说，机器的学习使用了人类最先设计的分类，这个过程有很大程度上的人类参与。如果你的训练数据存在对女性或少数族裔的偏差，那么最后得到的模型也会是有偏见的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4. 猫识别论文&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在最初的一两年，谷歌大脑设计出了具有 1 岁孩童智力的机器，这些努力让其最终从 X 实验室毕业，进入了公司更宽阔的研究中。（谷歌 X 负责人曾提到谷歌大脑曾支付过 X 的所有花费）。而那时的谷歌大脑团队依然不足 10 人，也不清楚最后会得到什么。但即使如此，他们仍在思考接下来会发生什么。人的思想不需要多少时间就能学会识别球和其它东西，时间或长或短。然后，开始进军语言。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌大脑在这个方向迈出的第一步是一篇关于猫的论文，也让谷歌大脑出名了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这篇论文证明的是带有十亿「突触」连接的神经网络（要比当时公开的任何神经网络都要大数百倍，当然也要比我们大脑小无数数量级）能观察原始的未标记数据，从而为自己挑选出高级的人类概念。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌大脑研究员像网络展示了 YouTube 视频的数百万张静止图片，无论是翻滚的猫，还是面部清楚的猫，神经网络会先剥离出一个稳定的模型，能毫不迟疑地识别出这是猫。机器之前从未被编程过有关猫的先验知识，它直接接触世界、为自己抓取想法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当时大部分的机器学习还受限于标记数据的质量。猫识别论文证明机器也能过处理原始为标记数据，即使这些数据人类之前从未建立先验知识。这不仅是猫识别研究上的重大进展，也是整个人工智能的重大进展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这篇猫论文的第一作者是 Quoc Le。他在越南顺化城边长大，父母都是农民，家中甚至没有电。但艰苦的环境没有埋没 Quoc Le 的数学天赋，他很小就被送到科学院学习。在上世纪 90 年代后期，他还在学校中的时候，他尝试开发了一个聊天机器人。他想看看这到底有多难。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「但事实上，」他对我悄悄说道，「这实在是难。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Quoc Le 从越南的农村一路走来，进入了堪培拉的澳大利亚国立大学。在那里，他进行了人工智能的一些研究。时间主导的方法，例如给机器传递边缘这样的概念，让他感觉有点像是作弊。Quoc Le 当时并不知道，这一领域当时在全世界有几十位学者正在做着同样的研究，很多人都不约而同想到了机器可以从头开始学习。在 2006 年，Quoc Le 在德国大学城 Tübingen 的马克斯·普朗克生物控制论研究所任职。在一个读书小组中，他接触了 Geoffrey Hinton 的两篇论文。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「当时出现了一次很大的争论，」他对我说道。「一次非常大的争论。」我们坐在一个小型会议室里，一个狭窄的有着很高天花板的空间，配备了一个小桌子和两个白板。他看着他在他背后白板上画的曲线，轻声说道，「我从没有见过这样激烈的辩论。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他记得他在读书小组中站起来发言，「这就是未来。」他表示，发表这种言论在当时那种情形下可不是一个很好的选择。他在澳洲国立大学的前导师，在小组里坐在他的旁边，事后发来电子邮件质问：「你为什么要这样做？」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我当时没有办法回答这个问题，」Le 说，「我只是好奇。那是一个成功的范式，但实话说我只是对这个新范式感到好奇。」2006 年时，此类讨论活动还屈指可数。」很快他进入了吴恩达的门下，在斯坦福大学开始了追随 Hinton 理念的旅程。「到 2010 年底，我已经非常确定马上将有变革会发生了。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随后发生了什么？不久以后，Le 成为了 Google Brain 的实习生，在那里，他继续着自己的研究——最终成就了这篇猫的论文。在一个简单的层面上，Le 希望看到计算机是否可以训练自己识别给定图像中最重要的信息。他的神经网络训练了从 YouTube 中获取的大量数据。之后，他命令神经网络丢掉图像中包含的一些信息，但他没有指定抛弃哪些信息。机器开始服从命令，抛弃一些信息，一开始，被抛弃的内容是随机的。随后他说：「好了，现在根据保留的信息尝试重新构建原始图像。」这就像他在让机器「总结」一张图片的内容，然后再从总结描述中还原这张图片。如果图片描述中包含的是不相关的信息——如天空的颜色而不是胡须——机器就不能有效地重建原始图像。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这就像一个原始人，需要在剑齿虎附近隐蔽自己的行踪，这个过程不能发出一点声音。Le 的神经网络不需要原始人那样小心，它可以无限次地试错。每一次它都会在数学上「选择」一个新的最优解试图让信息的处理更加准确。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;神经网络在某种程度上来说是一个黑箱。它识别模式，但识别模式的过程对于人类观察者而言并不总有直观意义。同样的网络既能识别猫，也能识别出某些形式的家具和动物的组合，比如一条长椅和一只山羊重叠在一起。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Le 并不认为自己是一个语言学者，但他认为这项研究和他早期的聊天机器人有一些相同之处。在猫论文之后，他意识到如果你要求神经网络总结一张照片，你应该要求它生成一句完整的话来形容照片的内容。这个问题是 Le 和他在谷歌中的同事 Tomas Mikolov 在之后两年里的主要研究内容。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在那个阶段，谷歌大脑发展迅速。有一段时间，他们在大楼的同一层办公，可以随时和高管们分享自己的想法。他们后来收到了一封电子邮件，信中要求他们禁止团队成员在 Larry Page 和 Sergey Brin 的套房前面的沙发上睡觉，因为这会让来访的客人们感到尴尬。随后，他们被分配在街对面的一个大楼中，在那里，他们在厨房中交流，不会被繁文缛节所拖累。在那段时间，谷歌的竞争对手们纷纷加快了追赶步伐。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Le 一直向我强调他与 Tomas Mikolov 的密切合作，他以一种奇怪的方式重复 Mikolov 的名字，听起来有点可怕，他在说这个词的时候表现出了前所未有的庄严，我终于无法抑制住自己的好奇心，问道：「他是...？」Le 点了点头。「他现在在 Facebook 了。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicr33MwRF3MYPqDITzNX5zh9rRBf1iaRz3lia97aEJ080ozrEme9TIxjy566Nhul0btTFruyTAHnh8g/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Google Brain 团队的图片小组在 2012 年发布著名的「猫论文」，展示了神经网络对于未标记数据的分析能力&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他们花费了很长一段时间构建这个神经网络架构，使其不仅可以进行简单的照片分类，也可以识别各种静态的，但同样复杂的结构，如语言和音乐。其中用到的许多方法在 20 世纪 90 年代已被提出，Le 和他的同事们回到那些长期被忽视的研究成果中去寻找。他们明白，一旦建立起了具有基本语言预测能力的系统，你就可以用它从事其他各种智能的任务——例如自动回复电子邮件或预测一个谈话流程。你会发现它看起来很神奇；在外行眼里，看起来它就像是在思考。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;Part II：语言机器&amp;nbsp;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;5. 语言学的转向&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前谷歌大脑团队不像是一个巨大的企业层次分明的科技公司的一个部门，而更像是一个社团或者一个学术集体，或者说是一个「星际酒店」。这些年来谷歌大脑团队的成员一直是整个谷歌内部比较自由且广受赞誉的员工。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当我 6 月份开始进驻谷歌大脑团队的时候，办公室里还有成排的空工位，但已被贴上便利贴，上面大多写着类似「Jesse，6/27」（新职工及将要入职时间）这样的标注。现在这些空工位都已满。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌大脑团队的发展使得团队的负责人 Dean 开始有点担忧公司对需求的掌控。他想一改谷歌以往「成功毁灭者」的形象，而外界对谷歌的这个印象是由于谷歌在产品开发落地上的能力远不及其在理论研究上的能力。他曾做过简单的估算，并用一个只有 2 页的 PPT 向执行董事汇报了他的估算。「假设未来使用安卓手机的用户每人每天和手机语音对话的时间为三分钟，那么这就是我们所需服务器的总量。」也就是谷歌需要将他们的全球计算能力扩增 1 到 2 倍。「这个数量听起来有些吓人，但是我们必须去做——去建造新的数据处理中心。」他不愿去设想如果不这样做的后果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是还有另外一种解决方案：只需设计芯片，成批量的设计出让所有计算过程更快的芯片并在全球各地的数据中心使用。这些芯片将被称为「张量处理单元（TPU）」，这些芯片区别于普通芯片在执行计算过程时是非精确计算，这也是体现芯片价值之处。如在计算 12.246 乘 54.392 的时候，芯片会给一个 12 乘 54 的近似计算值。在数学层面上，一个神经网络只是一组成百上千或者成千上万的矩阵的有序计算。对这些矩阵的计算过程而言，计算速度比精确计算更重要。「一般情况下，为某一特别任务而设计硬件是一个不明智的做法。因为这样设计出来的硬件只能加速该项任务的计算过程。但是由于神经网络的普适性，你可以在很多其他的任务执行时运用专为神经网络而设计的硬件。」Dean 说。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当芯片的设计过程即将完成的时候，Le 和两个同事终于证明出神经网络可以用来构造语言模型。他的结论是基于「词向量」而得出的。当你看到图像的时候，大脑会从边缘到图形依次概括图像主要内容。语言概括的过程也与此类似，你本质上也是在构建不同维度的距离图。在构建的时候，依据惯用使用规则，构建一个词和其他单独的每一个词的距离。计算机并不是以人认知语言的方式进行语言分析的，而是在构建的距离图里转移、偏转或者倾斜词向量。二维的向量图是没有价值的。比如在地图中你希望 "cat "在 "dog "附近，同时 "cat "也在 "tail""supercilious""meme"附近，因为你需要构建这些词相互之间的关系而且一个词（这里是"cat"）对于其他所有词的关系有强弱之分。如果一个词与其他所有词之间的关系各自成为一个独立的向量维度，那么一个词与其他词之间的关系就能一步构建出来。但是创建一个维度为 16 万的向量不是一件容易的事，所幸的是某种语言的词向量图完全可以用一个只有一千维度的向量图来很好的构建出来。换句话说来说，在这个词向量图的空间里，每个词是由一组 1000 个数值来定位的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是在这样构建的空间里，并不能很好地显示出不同种人的称呼之间的区别。如果把定位「king」的那组数对应的减去定位「queen」的那组数中相同位置的数那么得到的新向量将会同定位「man」的那组数对应减去定位「man」那组数的向量相同。如果让机器学习整个英语词汇所构建的向量空间图以及整个法语词汇所构建的向量空间图，在理论上你是可以训练出这样的一个神经网络，从英语中选取一条语句对应的生成法语中向量值相同的语句。在训练时，你只需要先将大量的英文语句作为网络的数据输入，然后将对应的法语语句作为网络的输出，进行一个监督学习的过程，在机器完成这个监督学习之后神经网络将会习得词语之间的关系，这就跟图像分类器能识别不同像素点之间的关系一样。词语和像素之间的主要区别在于一副图像中的像素点在时间上是没有先后之分的，而词语的使用是有时间先后的。你需要时刻让神经网络"记住"它是以时间先后的顺序来处理语句，即从语句的第一个词至最后一个词的顺序进行。在 2014 年 9 月的某周里，这种处理方法的所有理论工具在三篇论文中被提出来。一篇来自 Le，另外两篇来自加拿大和德国的研究者。他们的研究催发了一些开发式的项目如谷歌大脑的 Magenta 项目，这个项目是对机器如何创作艺术作品和音乐作品的研究。同时也为工具性的研究（如机器翻译）扫清障碍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;6. 伏击&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Le 的论文表明神经翻译是靠谱的，但是他只使用了一个相对较小的公共数据集。（对于谷歌来说很小，要知道谷歌拥有世界上最大的公共数据集。过去十年旧的翻译系统已经积累了比其使用的数据集大上成百上千倍的生产数据。）更重要的是，Le 的模型对于超过 7 个单词的句子就不怎么管用了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Mike Schuster 那时是 Brain 团队的一名研究科学家，接管了这项研究。他明白如果谷歌找不到一种能将理论见解拓展到产品层面的方式，其他人也会找到的。这个项目花了他两年的时间。Schuster 说，「你想要翻译一些东西，你就要有数据、做实验，并且你做了，效果未必如你所愿。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Schuster 是个时刻保持紧张专注，大脑永远灵活的家伙，皮肤黝黑，肩膀不宽，穿着窄口过膝迷彩短裤，脚踩一双闪着荧光的 Nike Flyknits。Schuster 在前西德 blast-furnace 区的杜伊斯堡长大，研究的是电子工程，后来去京都研究早期的神经网络。上世纪 90 年代，他做了一个会议室大小的神经网络机器实验；花费数百万美元，训练了好几周才能做一些你现在一个小时内就能在台式电脑上训练出来的东西。1997 年，他发表了这篇研究的论文，之后的十五年都几乎没有人引用过；今年，这篇文章被引用了 150 次左右。他不乏幽默，但穿着上总是流露出一种严肃的感觉，他的签名带着一种日本人和德国人特有克制感。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个非解决不可的问题很棘手。一方面，Le 的代码是自定义编写的，与谷歌之后新开发的开源机器学习平台 TensorFlow 不兼容。2015 年秋天，Dean 给 Schuster 介绍了另外两名工程师，Yonghui Wu 和 Zhifeng Chen。然后他们花了两个月将 Le 的结果复制到这个新系统上。Le 就在旁边，但是他从头到尾都没有给过他们一点指导。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;就像 Schuster 说的那样，「很多工作都不是在完全清楚的情况下完成的。他们不知道自己为什么要做。」今年二月，谷歌的研究组织——谷歌的一个松散部门，大约有 1000 名员工，做的都是前瞻性和一些未知的研究——将总部外的各个带头人召集到联合广场上的 Westin St. Francis 酒店，奢华程度略低于谷歌自己在东部一英里之外三藩市里的那家店。上午是几轮的「闪电会谈」，快速汇报最新的研究进展，下午是悠闲的跨部门「促进讨论。」这次召集是为了提供一个场合能促进不可预测的、不明朗的、贝尔实验室风格的交流，期望这种交流能给公司带来更多的生产力量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;午餐时间，Corrado 和 Dean 两人在找谷歌翻译的负责人 Macduff Hughes。Hughes 一个人用餐，两名谷歌大脑的成员坐在离他有点距离的两边位置上。就像 Corrado 说的那样，「我们伏击了他。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「O.K.」Corrado 想放松 Hughes 的警惕，让他的呼吸恢复平稳。「我们要和你谈点事。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他们告诉 Hughes 2016 年是个不错的时机，可以用神经网络重整一下谷歌翻译——数百名工程师超过十年编出来的代码。这个旧系统采用的是 30 年来所有机器翻译系统采用的方法：它能将连续的句子片段隔开，在一个大型统计衍生词汇表中检索句子中的单词，然后使用一组后处理规则附上适当的结果，再重新排列起来组合成句子。这个方法叫「基于短语的统计机器翻译」，因为直到该系统获取下一个短语，它才知道这个短语是什么。这就是为什么谷歌翻译的输出有时像一对抖动后的冰箱贴。如果谷歌大脑团队的神经网络能用到翻译中来，就能实现阅读并在一个草稿上呈现完整的句子。它会扑捉整个语境，这和句子表达的意思紧密相关。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;赌注似乎很低：谷歌翻译带来的收入最小，而且这种情况可能会一直持续下去。对于大多数以英语为母语的用户来说，即使是激进地升级一个服务，也不会给他们带来任何用户体验上提升。有个案例可以说明这个问题，人类水平的机器翻译不仅是短期内的必需品，长期来看其发展也很可能会带来颠覆性的变化。在这中间，公司打什么样的战略至关重要。谷歌估计，英语中有 50% 的使用来自 20% 的世界人口。如果谷歌打算进军中国——这里大多数搜索引擎流量的市场份额属于它的竞争对手百度——或印度，得体的机器翻译将是基础系统不可或缺的一部分。2015 年 7 月，百度也发表了一篇关于神经机器翻译的开创性论文。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在更远的将来，机会更多，机器翻译可能是迈向一个使用人类语言的通用计算设备的第一步。这将在真正的人工智能的发展道路上代表一个主要的转折点，或许它本身就是主要的转折点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;硅谷的大多数人都意识到机器学习是一条捷径，所以 Hughes 预料到 Corrado 和 Dean 会来找他谈这个事情。他仍然保持怀疑。这个温和强壮刚刚步入中年的男人，蓬乱的褐色头发，两鬓却已斑白。Hughes 是一个典型直线条的工程师，就是那种上世纪 70 年代出现在波音飞机草稿桌上工匠。他知道，多年来在谷歌其他岗位上或者谷歌之外其他地方的很多人一直试图做神经翻译的研究，不仅是实验室里的还有能投入量产的，但是收效甚微。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Hughes 听了他们的案例，最后小心翼翼地说，这听上去就好像他三年内就能做出来一样。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Dean 却不这么想。「如果我们真的想做，今年内就能做出来。」人们喜欢并崇拜 Dean 的一个原因就是他总能成功地实现自己的想法。另一个原因是，他能轻松地说一件很严肃的事情，「我们能不能把我们的想法加进去。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Hughes 那时肯定神经翻译不会那么快实现，他个人不关心是一个原因。「我们来为 2016 年做准备，」他回去告诉他的团队。「我们不会说 Jeff Dean 没那么快。」一个月后，他们终于可以运行一个并排（side-by-side）实验，将 Schuster 的新系统与 Hughes 的旧系统相比较。Schuster 想用它来试一试英语-法语翻译，但是 Hughes 建议他换个语种试试。「英语-法语太简单了，提升不会太明显。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Schuster 不会坚持这个挑战。评估机器翻译的基准度量是 BLEU 得分，它将机器翻译的结果与许多可靠的人类翻译的平均水平相比较。当时，英语-法语最好的得分是 20s。有一个点的改进就是非常好；两个点的改进就算是十分出色了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;英语 - 法语语对上的神经系统改进比旧系统多达 7 分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Hughes 告诉 Schuster 的团队，在过去四年里，他们自己的系统中从来没有出现过这么大的改进。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了确保这不是侥幸得出的，他们也利用人力对此进行了平行比较。在用户体验得分中，其中例句得分从 0 到 6，平均改善了 0.4——大致相当于旧系统在其整个生命周期的总增益。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicr33MwRF3MYPqDITzNX5zhxhZSG03us3Nk8PI3xZfibtEeJNIxs6kibuFJJtnYJgwy5H6KOdrPpPdw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;谷歌的 Quoc Le（图右），他的工作证明了神经翻译的合理性，Mike Schuster 帮助将这项工作应用于谷歌翻译。图片来源：Brian Finke for The New York Times&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;三月中旬，Hughes 给他的团队成员发了一封邮件，暂停了所有旧系统有关项目。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;7. 将理论变为产品&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在那之前，神经翻译团队只有三个人（Schuster、Wu 和 Chen），但是在 Hughes 的支持下，更多的团队开始了联合。后来他们在谷歌大脑写字楼开会，会议一般有十几人参加。当 Hughes 或 Corrado 在的时候，他们是仅有的以英语为母语的人，工程师们用混杂的语言和数学进行表达，不过他们讲中文、德语和日语等其他语言。在 Google，谁举行会议并不总是完全清楚的，但这次会议是没有疑义的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不过即便如此，他们所需要采取的步骤还是不完全确定的，整个过程都是不明确的。Schuster 将手伸出到胸前 8 英寸说：「这就像在大海里游泳，你只能看到这么远的距离，目标就在某处，或许它就在我们这里」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大多数谷歌的会议室都配有视频聊天显示器，它会在闲置时显示极高分辨率的过饱和公开 Google+照片，包括梦幻森林、北极光或德国国会大厦。Schuster 指向正在显示华盛顿纪念碑水晶般静立的夜景屏幕，「外人会认为我们每个人都有双筒望远镜，可以看到遥远的前方。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;到达现在的理论工作已经让他们精疲力竭了，那么将它转化为可行的产品呢，做学术的科学家可能就会将其归于纯粹的工程学，并认为要实现起来是不难的。首先，他们需要确保有良好的数据进行训练。谷歌数十亿词的「阅读」训练主要是由中等复杂性的完整句子组成，就像海明威的那样。其中一些是公共领域内的：统计机器翻译 Rosetta Stone 就是数百万页的加拿大议会的完整的双语记录建立的。然而它的大部分都从 10 年收集的数据中剔除，包括从热心的受访者得到的众包翻译数据。他们团队的语料库里有大约 9700 万个独特的英语「单词」。但是一旦他们删除了表情符号、拼写错误和冗余，他们的有效词汇量就只剩下了大约 16 万。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然后你不得不重新关注用户实际想要翻译的内容，这通常与是否使用合理的语言无关。谷歌发现许多人不去看复杂句子翻译地是否完整，而是考察那些奇怪的小碎片语言。如果你希望网络能够处理用户查询流，那么就必须确保将其定向到处理小碎片语言。该网络对其训练的数据非常敏感，正如 Hughes 向我提出的一点：「神经翻译系统就像一个小孩，它正在学习一切」他笑着说：「你们都应该谨慎点」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不管怎样，他们需要确保整个翻译过程是快速和可靠的，这样用户才能接受这个产品。在今年 2 月，神经翻译翻译一条 10 个单词长的句子需要 10 秒钟，他们是不可能去推荐一个如此慢的翻译系统。所以翻译小组开始对一小部分用户进行延迟实验，以伪造延迟的形式识别容错。他们发现，如果翻译需要 2 倍到 5 倍的时间不会被注意到，但是到达八倍的减速就会了。他们不需要确保所有语言都是这样，在高流量的语言（如法语或中文）的情况下，他们几乎不会放慢速度。而对于一些更模糊更抽象的事物，他们知道如果用户能获得更好的质量，那么基本不会害怕轻微的延迟。他们只是想防止用户转换到某些竞争对手的服务上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于 Schuster 而言，他承认不是太清楚他们团队能否让这个系统运行地足够快。Schuster 还记得和 Chen 在小厨房里的对话，他当时说：「一定有一些我们不知道的，但能使我们的系统运行地足够快的东西，虽然我不知道是什么」。不过他们都知道他们需要更多的计算机，确切地说是需要更多的图形处理器训练神经网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Hughes 去问 Schuster 他是怎么想的：「我们是不是应该使用一千块图形处理器？」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Schuster 回答：「为什么不用 2 千块？」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;十天后，他们增加了 2000 块图形处理器。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;到 4 月份，原来的三人阵容已经超过 30 人，其中一些人，如 Le，来自谷歌大脑团队，许多人还是来自谷歌翻译。5 月，Hughes 为每种语对配备了一位临时主管，每个人都需要将结果录入到一个大型的共享绩效评估电子表格中。在任何时候都至少有 20 个人正在进行为期一周的独立实验，并处理出现的各种意想不到的问题。有一次有一个模型毫无缘由地把开始所有句子中的数字删除。这个问题花了几个月的时间才得以解决。Schuster 说：「所有人都在着急地大喊大叫。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;到春末，各部分的工作都聚在一起。团队引入了一些诸如 word-piece model、coverage penalty、length normalization 的概念。Schuster 说，「每个部分的结果都能改进几个百分点，总体就会有显著的效果。」一旦模型标准化，它将只是一个单一的多语言模型，而不是目前使用的翻译的 150 种不同模型，这一模型将会随着时间的推移而不断改进。但是，当一个工具通过学习机器来实现普遍化时，实现自动化的过程会需要异于常人的才智和努力。但是很多做出的决定都依赖的是直觉。每层需要使用多少个神经元？1024 还是 512？有多少层？一次运行多少句？需要训练多久？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;Schuster 对我说，「我们做了成百上千次实验，直到我们确定在一周后我们可以停止训练。你总是在问我们什么时候才可以结束？我怎么知道我做了些什么？你永远不知道你做了些什么。机器学习的机制永远都达不到完美的状态。你需要训练，在某一个时间，你需要停下来。这就是整个系统的本质。对于某些人来说，这确实很困难。这就是创造艺术一样，你得拿着你的刷子慢慢让它变得完美。所以我们要去做，有些人会做得越来越好，有些人会越来越糟糕。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;5 月份，谷歌大脑团队了解到，他们唯一能够使系统作为产品快速实现的方法是能够在 TPU 上运行。正如 Chen 所说：「我们甚至不知道代码是否能工作。但是我们知道没有 TPU 肯定是不行的。」他还记得曾经一个接一个地去请求 Dean，让他帮忙保留一些 TPU。Dean 保留了，但是 T.P.U.s 却不能正常工作。Wu 花了两个月的时间坐在硬件团队的人旁边，试图找出原因。他们不只是在调试模型，他们也在调试芯片。神经翻译项目成为整个基础设施投资概念的验证。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;六月一个星期三的晚上，在 Quartz Lake 举办的一个会议以对近来出现在行业权威网上论坛上百度的一篇论文的讨论开始。Schuster 说，「确实百度出了一篇论文，就好像有人在监视着我们一样——相似的架构、相似的结果。」它们的 BLEU 分数是谷歌在二三月份内部测试时达到的分数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌团队知道它们应该早一点发布自己的结果，这样或许就能够打败它们的竞争对手。但 Schuster 说道：「推出要比发布更重要」。最终他们确实首先推出了更好的服务。但是 Hughes 说，「我们不想说这是一个新系统，我们只想确保它能够正确运行。理想的情况是看到大批人在 Twitter 上面说：『你们有看到谷歌翻译现在有多厉害吗？』」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;8. 一次庆祝&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;9 月下旬一个星期一的下午，团队的论文最终发布，论文共有 31 位作者。第二天谷歌大脑和谷歌翻译的成员聚集在为厨房中举行了一个小小的庆祝活动。一定程度上，它们是在庆祝谷歌大脑和谷歌翻译的联合工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌的神经翻译终于开始运作了起来。在聚会举办的时候，公司的中英翻译已经处理了 1800 万条查询指令。几周之后，谷歌正式将神经翻译拓展到了中英互译领域，这是谷歌取得最好业绩的语言对。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Hughes 说道：「上一分钟存在问题，上上一分钟也存在问题，对论文的测量误差或者是一个奇怪的标点符号都可能导致系统缺陷，但所有的问题我们都解决了，或者至少当前是有效解决了。神经翻译目前取得了一些进步，但是这种进步是间断的、垂直的，而不是一条光滑的曲线。相关的翻译并不仅是关于两个团队，而是关于将理论转变为现实，目的是为了交流、合作。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Dean 说：「它们展示了可以同时处理两大主要任务的能力：做研究，并且将结果摆在 5 亿人（我猜测）的面前。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所有人听到都发出了笑声，并不是因为这句话夸大其词，反倒是因为它丝毫没有夸张。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;后记：没有灵魂的机器&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;或许对于人工智能最著名的历史性批判或者是在其立场上做出的断言，便设计到了翻译的问题。伯克利的哲学家 John Searle 中 1980 年提出中文屋（Chinese room）的实验。在这个思想实验当中，他将一个只会说英语的人关在一间只有一个开口的封闭房间中。房外的人不断向房间内递进用中文写成的问题。房间里面的人只有几张桌子和一本用英文写成的手册，指示他该如何处理收到的汉语讯息及如何以汉语相应地回复。房内的人便按照手册的说明，很快他们的回答似乎就变得与与讲中文的人没有什么差别了。那么我们可以说房间里面的人「懂」中文吗？Searle 的答案是否定的。他在之后用计算机来作比喻，他说「给适当编程的电子计算机赋予正确的输入和输出，就会造成一种计算机和人脑一样也具有思维的感觉。」&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于谷歌大脑团队，以及在硅谷从事机器学习工作的几乎每个人来说，这种观点都有些文不对题。这并不是说它们在无视哲学问题，而是说他们对智能的思维有着完全不一样的看法。和 Searle 不一样，他们没有从特殊的心理方面来分析「意识」，Gilbert Ryle 将其称之为「意识的灵魂」。他们只是相信我们称之为「意识」的复杂技能分类，在很多简单机制的协调活动中是随机出现的。因此，逻辑推理就成为了一种补足的方式，就像是我们扔球和接球的能力一样。人工智能并不是要去建立一种思维，它是对于解决问题工具的改进。Corrado 在我第一天进入谷歌的时候就对我说，「人工智能并不是关于机器『知道什么』和『理解什么』，而是关于它可以『做什么』，还有至关重要的一点是——它目前还不能做什么」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而「知道」和「做」这两个概念当中确实存在一些文化和社会含意。Schuster 曾经因为媒体将「谷歌表示人工智能翻译的能力已经与人类无异」（GOOGLE SAYS A.I. TRANSLATION IS INDISTINGUISHABLE FROM HUMANS）放上头条一度在论文中强调这一点，他经常重复论文中的观点——「现在的发展状况比以前要好很多，但还是不及人类。」他希望人们能够清楚地意识到他们所做的工作是在帮助人类，而不是要取代人类。然而机器学习的崛起又为我们提出了难题。如果你相信，根据 Searle 的观点，人类「洞察力」当中存在着一些特殊之处，那你就可以在人类和机器之间划出一条明显的界限。如果你持相反的看法，那么就当然不能。所以为什么那么多人都支持前者似乎就容易理解了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 2015 年 MIT 关于人工智能根源的一次大会上，有人问 Noam Chomsky 他对机器学习的看法是怎么样的。他轻蔑的回答说，整个市场都仅仅是在做数据预测，其实就像是天气预报一样。即使神经翻译能够完美演绎，对于语言的本质也并不能产生什么深远的影响。这种预测能够成为我们完成任务的一种很好的工具，但是不能帮助我们理解事情为什么会这样发生。在医学扫描上，机器已经能够比人类放射专家更准确地检测出肿瘤，但是机器不能告诉你是怎么得病的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那么问题是放射专家能够告诉你吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;医学诊断是受到机器学习威胁最直接最不可预测的一个领域。放射科医生一般都经过广泛培训，并且报酬优渥，我们认为他们的技能是一种专业洞察力——最高级的思想领域。在过去的一年里，研究人员不仅发现神经网络可以比医疗图像更早找到肿瘤，而且机器甚至可以根据病理报告的文本做出诊断。放射科医生做的事情其实更像是一种预测模式而不是逻辑分析。他们并没有告诉你是什么导致了癌症，他们只是告诉你它在那里。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你出于某种目的建立了一个模式匹配装置，它可以在为别人服务时进行调整。一个翻译工程师既可以利用一个网络评价艺术品，也可以用它来驱动一个自主无线电控制的汽车。用于识别猫的网络可以用于训练 CT 扫描。一个用于翻译的神经网络可以很快处理数百万页的法律的文件，所需要的时间和收费最昂贵的资格律师相比也仅仅是一小部分。那些机器可以做的工作也不再仅仅是我们之前所做的一些重复性的工作。我们不只是在谈论 350 万名可能很快面临失业的卡车司机。我们谈论的还有库存管理者、经济学家、财务顾问、房地产代理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在硅谷发生的最重要的事情现在不是分裂。相反，它对体制的建设和权力的巩固，在规模和速度上都达到了人类历史上可能是前所未有的程度。谷歌大脑有实习生，有常驻职员，有培训其他部门的「忍者」。每个地方都有免费自行车头盔和免费的雨伞、水果沙拉、午休的地方、共享的跑步机书桌、按摩椅、高级糕点、婴儿衣服捐赠场所、配备教练的两层攀岩墙、阅读小组和政策会谈以及各种支持网络。这些大规模投资的受益者可以控制分布在四大洲 13 个数据中心的复杂协调服务器，所拥有的数据中心吸引的电力足以照亮大城市。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但即使像谷歌这样庞大的机构也将面临自动化的浪潮，一旦机器可以从人类的语音当中进行学习，即使程序员的舒适工作也受到威胁。Hughes 在回忆过去 10 年翻译代码库历史时候曾说，「不要担心，新的代码库将会继续发展，一切都会变得越来越好。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;原文链接：http://www.nytimes.com/2016/12/14/magazine/the-great-ai-awakening.html?_r=0&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 15 Dec 2016 16:14:18 +0800</pubDate>
    </item>
    <item>
      <title>专访 | 云从科技创始人周曦：刷分的人脸识别没有任何意义</title>
      <link>http://www.iwgc.cn/link/3928461</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：虞喵喵&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一家成立不到两年的图像识别公司，如何在短时间内拿下众多银行客户？&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自 2015 年 4 月成立以来，海通证券、西安银行、中国建行等多家金融机构先后应用了云从的人脸识别系统。今年 9 月，中国农业银行更是率先将云从的技术应用到 37 家分行，成为全国第一家应用人脸识别技术的四大行。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;作为云从科技的创始人，周曦博士师从「计算机视觉之父」Thomas Huang（黄煦涛）教授，并在 2007-2011 年期间 6 次获得智能识别类世界大赛冠军。2011 年受邀回国后，周曦博士进入「中国科学院百人计划」，联合 UIUC（伊利诺伊大学厄巴纳-香槟分校）及新加坡国立大学成立中国科学院重庆研究院智能多媒体技术研究中心。期间带领团队研发出智能图像侦查仪、公安千万级人像检索机、人脸识别智能人员管理系统、大规模动态人群特征检测系统等产品，并作为中国科学院人脸识别唯一代表参与战略先导 A 类专项「新疆安防布控」。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;多年的学科钻研和技术、实践经验积累，使得云从自诞生之初就有着不俗的竞争力。可移动式大规模数据采集阵列、双层异构深度神经网络等复杂名词的背后，是云从「希望帮助更多人」的初心。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9DFP58EX6ymYTnLpicibkXOrxh1XKAbE69802iaAH3kGCpibHVsMuESWSsnzDb7N4o3EXr9ehHPfhoibw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;云从科技创始人周曦&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器之心专访周曦博士，从个人经历、云从科技的技术特色、金融业的技术应用特点、图像识别的发展等多个角度，还原这家图像识别公司的不同面貌。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;从语音转行图像，希望技术真正「有用」&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心&lt;/span&gt;&lt;span&gt;：您为什么选择了图像这个方向？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;周曦&lt;/span&gt;&lt;span&gt;：最早我在中科大做语音。后来去北京，在微软亚洲研究院语音识别组也呆了很长时间。但这期间「做了错误的判断，做了正确的决定」——我觉得语音没前途。按照摩尔定理，语音识别每 18 个月错误率能够减半，但我感觉离实用还是很难。而图像识别的视频和图像是个大得多的领域，可以解决的问题要多得多。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从信息分析来看，语音是一维信号，图像是二维信号，视频是三维信号，从信息上看图像比语音丰富。从任务来看，Audio（声音）本身是有很多任务的，但 Speech（语音）和 Audio 是两回事儿。Speech 是人的声音，背景音等很多声音对我们意义不大。我们想要研究的就是 Speech，这造成了所有做语音这一行，能做的任务就是能把说话的内容识别准。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图像和视频是完全不同的，人脸识别大概对应着语音识别。把图像中的人找到，再识别他是谁、他的情绪、年龄、性别。这只是浩瀚的图像识别和视频识别中的一小部分，对于我们来说有用的不止这一点。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;医学上应用图像处理，可以识别早期癌症等疾病。为什么体检后很多疾病没有检查出来？不是没拍到，是需要非常专业、非常资深的医生才能看出来。如果疾病尤其是癌症早期就看出来，基本能够治愈。通过图像识别和大数据，更好的把有嫌疑的部分都找到后再请专业的人确认，这样不就可以挽救很多人的生命吗？&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;再比如做工业视觉，生产线上的东西是不是有瑕疵，有没有裂缝？表面平不平？也可以通过图像视频看出来。又比如现在很「火」的自动驾驶，可以通过图像识别出所有路面的情况，是不是有标志等等。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于图像来说，识别宇宙万物都很有意义，不止是识别人的脸才有意义。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图像做一点点事都可能帮助到别人。当时我看到一条新闻，国外有人在泳池下装了一个摄像头，能自动识别出游泳者是不是溺水。做图像视频可以有很多的方法帮助别人，就觉得这个还蛮有意思的。所以「做了一个错误的判断，一个正确的决定。」来到美国，开始做图像视频。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;span&gt;机器之心&lt;/span&gt;：在美国您跟从 Thomas Huang（黄煦涛）教授学习，他是怎样一位老师？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;周曦&lt;/span&gt;：他是那种给我们营造环境的大师，给我们很大的平台和 high-level 的指导，比较轻松自由的环境，可以去做自己想做的方向。Thomas Huang 给我们很大的视野和平台。他本身是顶级教授，他指大的方向，给我们看大的视野是什么，我们自己三五成群研究自己感兴趣的东西。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9DFP58EX6ymYTnLpicibkXOricIsy0hTia3vZBECaXQ8J7G3h1VmicQuuKKEmxRWFLryroOl0HkSGBXQg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Thomas S. Huang（黄煦涛）教授在图像处理、模式识别、计算机视觉领域有奠基性贡献&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;span&gt;机器之心&lt;/span&gt;：那您后来为什么创业做了云从？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;周曦&lt;/span&gt;：很多时候都是幸运。我本来做语音、后来做图像，都属于人工智能甚至机器学习这一个分支里，有一定的学科交叉，很多东西都是复用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当时的语音识别走在图像识别前面，已经到了系统化的阶段。我到美国时，图像还没到这个阶段。从语音转到图像，让我们在方法论和做系统这件事上远远领先了所有人。当时图像领域都是「单兵作战」，在一个电脑上跑或者在一个服务器上跑任务。语音领域的人都认为必然需要 cluster 服务器阵列，分布式的提交任务。我到 UIUC 时发现还没有，马上就搞了一个。有 cluster 服务器就相当于正规军，别人是散兵游勇。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;语音有很多做得很好的算法和思想，我也在图像上实践。果不其然效果很好，2006-2010 年之间拿了很多世界冠军。拿了这么多冠军我就想，总要做什么有意义的事儿吧。这个东西要「实用」，不管是检查零件还是挽救溺水的生命，在各种场合下要能帮到大家。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这时就发现，虽然能识别宇宙万物，但图像识别一定要具体到一件事上才能帮助到别人。想来想去，人脸是图像中很重要的东西，把人脸做好可以做很多事。于是我们就先选了人脸识别。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;后来发现，如果没有商务推广能力也是不行。2013 年底、2014 年初，我发现芬兰有一家小公司做刷脸支付，觉得很好玩，就率先在国内做了刷脸支付。2014 年是做出来了，在手机上可以使用了，但其实是没有用的，因为没有人真的用。我只是告诉别人，可以这么玩儿，谁会真的去用呢？哪个金融机构会拿这个真的去做事呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果我们永远只在学术里，还是帮助不了人，做不了什么事儿。一定要自己有个公司、自己有能力去做商务推广，把这个东西往前推动，就有了云从。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;短时间搞定多家客户背后，是多年的实践积累&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;span&gt;机器之心&lt;/span&gt;：云从成立一年半时间，为什么能拿到银行、公安这么多客户？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;周曦：技术积累就不说了，很多年我一直在尝试怎么让技术实用。从学术到好用的系统，有很长的距离。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们在美国拿很多世界冠军，回国就是想让技术能实用。从 2011 年回国做了好多年，我们在中科院做的很多系统已经在新疆等地使用了。产品是成熟的，只是还没在商业推广起来。虽然公司去年成立，但准备工作特别完善。如果不全力以赴、以公司这样严肃的方式运作，是没有办法得到大家的认可的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9DFP58EX6ymYTnLpicibkXOrklJB4tTHiaiaF3g9ibkOVOHXnCJeJv7g5nLdhiagrGiaDjoPBRx8WLl2jicg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;云从科技部分应用案例，可于其官网查看具体内容&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;还有一点是我们做东西很集中，&lt;span&gt;我觉得专注是很重要的。一个是研究的东西很集中，虽然什么都能做，但现在还是做好人脸；第二是行业上要集中，各行各业都能做，我们只做金融和安防。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;span&gt;机器之心&lt;/span&gt;：银行这个行业应用分支有什么具体特点？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;周曦&lt;/span&gt;：银行的要求是，一定是一个严肃、认真的公司。不仅要求稳定，同时希望有非常快的响应速度。银行有严格的「2 小时、4 小时、8 小时原则」，系统宕机 2 小时，行长就要去当地人民银行喝茶；4 小时没解决，就要写报告；8 小时没解决，这就是严重事故，银行的评级一定会下降、甚至是关门，就是这么严重。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对我们这种 IT 供应商来说，能保证程序出现问题两小时之内修复吗？这是非常难的。如果人脸是其中的标准环节，恰好人脸识别的服务器宕机，银行只能关门，民众会怎么想？大家可能觉得银行是要垮了，会出现很大的金融事件，然后出现挤兑。这个就是银行的特点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们的系统还必须从总行部署，压力很大，需要我们非常专业。云从虽然成立时间不长，但很认真，在全国十个城市有销售服务中心，全国每一个省有自己的销售服务人员，要保证各个地方一线有云从的人。真的出现问题，我们要第一时间过得去。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;银行是很看重销售服务体系的，大部分互联网模式的公司可能不太重视这个事情。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;&lt;span&gt;机器之心&lt;/span&gt;：云从的「超大规模移动式数据采集阵列」是怎样的装置？作用是什么？&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;周曦&lt;/span&gt;：这实际上是受我在了解医学过程中的影响。我们这一行，其实没有做医学那么认真。医学上做 CT 切片时，因为光线是流明，从正极白到负极白每一度都要拍摄下来。这些图片形成一个严格的表格，可以反向查表解决问题。不能做错手术、不能误判、医学是很严格的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但我们这行经常说「情况很复杂，只能搞个大概」，光线、角度、遮挡、表情，影响因素很多。医学是值得学习的，所以当时从美国回来就做了结构化数据。采数据容易，结构化数据不容易。就算从互联网上下载 1000 万张人脸，或者在大街上安装摄像头收集行行色色的人脸，这些数据都是非结构化的。一张人脸的照片拿出来，它是什么角度？是什么光线？光源从哪儿来？有没有遮盖？是什么表情？有没有模糊？很难一张一张标回来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以我们花了很大力气，做了这个移动式采集阵列。&lt;span&gt;横向上从负 30 度到正 30 度，纵向上从 0 度到 30 度，每隔 5 度安装一个摄像头。7 层 13 列，一共 91 个摄像头形成了一个阵列，使用的摄像头是当时我们从加拿大进口的高速摄像机元件。&lt;/span&gt;这个阵列结构是可拆卸的。我们自己做了同步单元，保证毫秒级触发同步采集。因为视频量非常大，我们还要保证存储跟得上，整套东西做好是个宏大的工程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9DFP58EX6ymYTnLpicibkXOrmWjbFC6W8psibAsic54Bp0o0U7DhdStrxl6Lib7JWvln3qpvgQXDzXNjw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;采集的空间是有标尺的，人的脸部都是固定的，加上我们自己做了光源阵列，可以获得光线和角度属性。我们还自己设计了剧本规定了表情，遮挡方面有假发、帽子、眼睛等等。获得的每一张照片，属性都是自动获得的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但只是这样，就不需要「移动」了。实验室环境是不够的，从实验室到实用都要去做，所以这个阵列要可拆卸、可移动。银行业务很多在大堂办理，所以我们还要采集大堂情况下的数据；公安有时监控的是通道，我们就在通道采集数据看具体是什么情况。依靠这个结构化数据采集阵列，我们得到了广泛的数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为什么在大数据背景下，我们还要费力气做结构化数据？就像我们常说社会是最好的学校，为什么还要设立小学、中学、大学？在学校学习的是结构化知识体系，让小孩有三观和基础知识，再去接受广泛的数据洗礼，进行大量的学习。如果从最开始就随便学，最后学习的结果就不可控了。所以&lt;span&gt;需要先有结构化数据，再有海量的非结构化数据，才能做出最好的模型&lt;/span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;span&gt;机器之心&lt;/span&gt;：那么云从的另一项技术「双层异构深度神经网络」，是如何做到将看起来不相似、但实际是同一个人的人脸对应起来的？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;周曦&lt;/span&gt;：双层异构是双层、异构两件事。很多时候注册的照片是证件照，比较端正；现场照往往过了好几年，现场的光线、表情、角度等等各种因素都比不过证件照，需要用复杂的网络解开。描述每个东西都是一个分布，同一个人要满足同一个分布，但因为种种因素同一个人的照片之间已经隔得很远。我们不用强行把两张照片圈在一起，而是让他们在两个层上组成分布，用线将它们连接起来。接受注册和测试时的不同，将中间的原因找出来，这个就是双层。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;异构和双层是相辅相成的。大数据有一个特点，只要数据足够多就可以让它自己学习，但实际上影响因素是什么，人是知道的。人们知道原因是光线、遮挡、表情造成了差异，可以完全让它自己去学习，也可以提前告诉它可以省很多力。异构就是结构化不一样，数据是一种结构，知识是另外一种结构。要把知识簇给出，映射到一个一个簇中，让它用更少的代价解决这件事。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;用「三个苹果」举例。教一个孩子认识苹果，大概三个就够了。告诉他「圆圆的」、「上面有果蒂」、摸起来是什么感觉，这就是苹果。下一次再看见苹果，问他「这是什么」，他可能知道也可能不知道。如果不知道，可以告诉他「这就是上次说的苹果」。他会问「颜色为什么不一样」，可以回答「上次是青苹果，这次是红苹果」，孩子就会知道「苹果有不同颜色」。几次之后，他就认识苹果了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深度学习要想「搞定苹果」，需要多少个苹果？通常要 1000 或者 10000 个苹果的训练数据，训练结果达到识别率 90%。也就是说假如有 10000 个苹果，有 1000 个会识别错。我们问电脑，「这 1000 个为什么识别错了？」它不会回答「颜色不一样」，而是说「求了偏导、积分等，结果是 0.4，预置值 0.5 以上才是苹果，所以它不是苹果」。如何纠正电脑？没有办法，只能说是训练数据不够多，再找 10 万张苹果的照片训练。终于，识别率到达了 98%，效果还不错。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在我看来这并不是人工智能，&lt;span&gt;和小孩子沟通的过程才叫人工智能，因为他理解我抽象出来的概念。通过颜色、形状、材质等几个抽象出来的概念，定义了一个新的事物，当他有不同的理解时，也会用同样的概念提出问题，再来纠正他的认知。我们在一个很高的层次做交互，能够举一反三。&lt;/span&gt;一个点一个点的求偏导、求积分，是没办法交流的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除了基本的、初级的像素信息外，要加入上层的 concept（概念信息）和 attribute（属性信息），才能做到在更高的层面交互，快速的举一反三，迭代出问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;&lt;span&gt;机器之心&lt;/span&gt;：图像识别会涉及到大量运算，我们如何提升反应速度？&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;周曦&lt;/span&gt;：这又涉及到工程上的问题。为什么（图像识别）门槛很高？因为它不是搞一个模型就行的问题。人脸识别本身就有几十个模块，从检测、跟踪、分割、关键点、旋正，到质量分析、光线补偿、角度补偿、遮挡补全等等等等，对于任何一个模块又要针对每种场景做不同的适配。比如关键点提取如果应用在手机前端，供应商会要求模型大小在 1M 以下，而整个人脸识别模型在服务器端是有超过 1 亿个参数的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;同时，我们还要求很快，比如视频中有很多人，要求在 1ms 之内识别出多有的关键点。为什么是 1ms？因为还有很多的模块要运行，要满足所有的运行时间加在一起达到「实时」（30ms 之内）。有时候又要求很准，比如美妆应用对关键点的识别偏一个像素，就会让人感到不适。又要小、又要快、又要准，就要有不同的算法和模型应对不同的场景。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;几十个模块、每个模块要有不同的场景、还要应对所有的硬件（不同的手机型号、服务器、嵌入式设备），这就是我们常常说的「无数的精力都放到适配上了」。研究出一种新算法，Android、iOS、Linux 等等所有的模型都要重新更新一遍，这是很累的。所以为什么像我们这样的公司都要有庞大的研发队伍，很多人不理解为什么做一个人脸识别研发团队要超过 200 人，原因就在这里。这还只是核心技术的一小块，还不算在不同的行业做闸机、迎宾等等不同的设备。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;&lt;span&gt;机器之心&lt;/span&gt;：您曾在一次演讲中提到云从能够解决「人从哪里来」的问题，现在我们已经能做到对单人实现历史轨迹提取了吗？&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;周曦&lt;/span&gt;：这个不能光靠我们，首先要将所有的监控视频结构化，先将其中的人脸数据提取保存起来。将来如果想快速得到某一个人的信息，可以从系统快速的发布请求到所有的服务器端，将得到的信息组合起来。轨迹图、甚至这个人做过什么事、和谁说过话，信息链就会整合出来。现在在技术上是可行的，但数据联动等还不能保证。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;刷分的人脸识别，没有任何意义&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：图像识别发展到现在，您认为有哪些标志性事件？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;周曦&lt;/span&gt;：图像识别曾经很火过。到了 20 世纪末、本世纪初，这行变得很惨淡，大家都觉得未来遥遥无期、没有希望。直到 2001 年的 ICCV，Paul Viola 和 Michael Jones 发表了《Robust Real-Time face detection》，在现场引起了轰动。他们用摄像头对准大家，现场所有人的脸都被圈出来了。图像识别第一次有实用的东西出现，这是图像识别命运的扭转。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一件挽救了图像识别命运的事件，是 911。911 后美国政府率先要求全部应用摄像头，海量视频出现后需要加强智能监控，客观上也让经费大幅提升。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深度学习也是一个巨大的标志性事件，深度学习在 2006 年提出，2009 年左右开始在图像中应用。一直到现在，仍是大爆发的阶段。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;硬件先行、大数据也有了，云计算云存储又得到了非常好的发展，需要有算法将他们的能力表达出来。深度学习，就是炊米的「巧妇」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：中国在图像识别研究上，大概是什么样的位置？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;周曦&lt;/span&gt;：就图像识别而言，我们在国际上是领先的，至少没有落后美国。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在中国，尤其是人脸识别，需求是比美国旺盛的。需求推动造成企业敢于投入资金，大家的投入也很大，再加上算法基础相当，中国的数据更多，所以中国是不会落后于美国的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;span&gt;机器之心&lt;/span&gt;：有一种声音认为，现在的图像识别每天都在参赛刷分，离解决人类视觉认知等初衷太远，您怎么看这种观点？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;周曦&lt;/span&gt;：刷分是没意义的。我们的初心是让图像识别真的有帮助，真的能用起来。一定要有人沉得下来做基础研究，也要有人做实用的东西。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们是偏向做有用的东西，把好的技术在银行、公安、机场等各个地方用起来，让民众觉得很好用、很舒服。为了解决这件事就会面临很多科研问题，比如晚上光线不好，就无法进自己的家门了吗？应该 24 小时每天稳定的让每个人使用，这就是实用中出现的科研问题，同样要去解决。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;做原创性研究比如怎样从理论上解决大数据的问题，也很了不起。但刷分是没有意义的，因为解决的是制造出来的、不存在的问题，只是炫技。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心原创文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 15 Dec 2016 16:14:18 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 用游戏测试人工智能，Nature盘点三大开源3D测试环境</title>
      <link>http://www.iwgc.cn/link/3928462</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自 Nature&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;参与：李泽南&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;《我的世界》对于 José Hernández-Orallo 而言并不陌生，他是一名计算机科学家，正在使用这款游戏进行自己的研究。他在瓦伦西亚理工大学的研究团队设计了一种测试机器智能性能的基准，这种方法的设计灵感来源于他看到自己的孩子在 3D 虚拟世界中游戏的情形。在《我的世界》中，玩家通常需要通过互动解决问题，而不是射杀怪物。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicr33MwRF3MYPqDITzNX5zhuJatPeEWJ2E0454NCxChZicrbgjejlKIGMqpia41amCsfdiaDH21RUyVA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;《我的世界》是一款风靡全球的游戏，现在科研人员们正在使用它来测试人工智能&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2014 年，微软购买了《我的世界》的所有权，这家科技巨头的研究机构——微软研究院随后在此之上设计了一个用于科研的新版本，让计算机程序和科学家们可以探索和自定义游戏中的 3D 环境。随后，微软邀请了包括 Hernández-Orallo 在内的一些外部研究人员下载了这个机器友好版本的《我的世界》。从 2015 年 7 月起，微软将其完全开放，现在任何人都可以免费使用它，微软希望以此加快人工智能领域的研究速度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能在各种游戏中的研究最近变得非常火爆，很多公司正像微软一样在游戏中投入研究力量。12 月 3 日，DeepMind 开放了自己的 3D 虚拟世界程序 DeepMind Lab，供所有开发人员下载和自定义使用。这家谷歌下属公司设计的虚拟环境一开始被用于训练自己的人工智能程序。仅仅两天以后，OpenAI 发布了一个「元平台」允许人工智能程序在其中与最初为人类玩家设计的十几款 3D 游戏互动，另外，这个环境还包含了一些网络浏览器与手机 app。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这三个工具让研究人员与软件开发者们可以轻松地开展自己的实验，测试程序在遇到前所未见的问题时如何进行解决，同时可以帮助程序在类似真实场景的环境中进行自我训练。「这样的虚拟环境将会为人工智能的发展奠定基础，」西雅图华盛顿大学的机器学习研究者 Pedro Domingos 说道。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;iframe class="video_iframe" data-vidtype="1" style="   z-index:1; " height="375" width="500" frameborder="0" data-src="https://v.qq.com/iframe/preview.html?width=500&amp;amp;height=375&amp;amp;auto=0&amp;amp;vid=i0355gr1txb" allowfullscreen=""&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;DeepMind Lab，一开始被用于训练谷歌自己的人工智能程序，现在已经向所有开发者开放&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Atari 算法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能是各种视频游戏的老玩家，但在早期，每个用于通关的算法都是特殊定制的。近年来，人们的研究重点开始转向于使用机器学习让程序自我积累经验。在 2015 年上半年，DeepMind 推出的算法在 Atari 游戏中拥有了超越人类玩家的水平，算法通过不断试错来获得游戏高分，设计者并没有告诉程序每个游戏的目标是什么。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Atari 游戏仅仅是 2D 世界而已。像《我的世界》这样的「第一人称」3D 视频游戏可以让玩家置身于一个充满立体感的环境中，相比前者更接近于真实世界，因此吸引了更多研究者的目光。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在《我的世界》中，玩家可以和虚拟世界中的砖块互动，使用它们盖房子，同时也可以探索路线，和游戏世界中的其他内容展开交互。面向开发者的版本被称为 Malmo，允许机器算法像人类玩家一样在游戏中进行探索。Hernández-Orallo 正在使用 Malmo 来探究虚拟环境是否可用于创建机器智能的基准。不同算法可以相互竞争，看看哪一个可以将砖块搭建成某个物体的形状，或者比较它们在同一个迷宫中寻路所需的时间，这种测试的涵盖面相比图灵测试——机器智能最有名的测试方式——要广泛的多。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;让《我的世界》吸引人工智能学者们的另一个原因是，在游戏中玩家们可以打字互相交流。「这可以帮助专家们研究人工智能在现实世界中与人类互动的情况，」微软研究院的科学家 Katja Hofmann 说道，她在英国剑桥领导着开发 Malmo 的团队。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;iframe class="video_iframe" data-vidtype="1" style="   z-index:1; " height="375" width="500" frameborder="0" data-src="https://v.qq.com/iframe/preview.html?width=500&amp;amp;height=375&amp;amp;auto=0&amp;amp;vid=r03550afrzg" allowfullscreen=""&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;目前约有 100 个研究机构正在使用 Malmo 3D 世界，它由微软研究院开发，用于人工智能研究&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;训练机器人&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「虚拟世界的人工智能训练对于机器人的发展大有益处，」Hofmann 说道。「因为虚拟环境的定制成本很低，定制速度和安全性也有保障。虚拟环境也可以让机器人研究者们专注于解决机器人的智能问题——机械的问题有时的确令人分心。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除了 Hernández-Orallo 以外，微软研究院还与不少其他研究机构合作开展了一系列 Malmo 项目。Hofmann 认为真实的用户数量不止于此，也许有 100 家。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Malmo 平台包括 Java 版本的模块，以及帮助智能体在 Minecraft 环境中感知和操作的代码。这两个组件可以在 Windows，Linux 或 Mac OS 上运行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;DeepMind Lab 和 Malmo 类似，也允许研究者创建迷宫，让不同算法学习如何寻路，获得奖励。DeepMind 正在尝试将「更自然的元素」（如起伏的地形和植物）整加入到这个虚拟世界中。目前这个 3D 环境已经开源，DeepMind 希望在其他研究者的帮助下，这个平台能够更加复杂，从而训练更聪明的训练算法。「通过开源，我们可以让所有人参与进来，不断改进这个项目，」DeepMind 的一位发言人说道。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;OpenAI 的元平台，Universe，相比前两个 3D 世界则更进一步。通过为同一个人工智能程序提供多种不同类型的环境，这一平台或许可以解决领域内最棘手的问题：如何创建一个可以解决任何新问题的算法。目前的深度神经网络——通过模仿脑细胞和视觉皮质层的结构创建的计算机系统——可以快速学会在 3D 迷宫中寻路，但同样一个系统却无法将自己学会的方法用于在其他迷宫中导航。「你仅仅改变一下迷宫的颜色，系统就会迷失其中了，」Hernández-Orallo 说道。「这就是目前最先进的技术，令人哭笑不得。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;看来，人工智能的发展还有很长的路要走。目前微软现在正努力让 Malmo 可以在 Universe 中使用。「拥有一个社区平台将使所有人从中受益，」OpenAI 的共同创始人，首席技术官 Greg Brockman 说道。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相关链接：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Microsoft Project Malmo：&lt;span&gt;https://www.microsoft.com/en-us/research/project/project-malmo/&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;DeepMind Lab：&lt;span&gt;https://deepmind.com/blog/open-sourcing-deepmind-lab/&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;OpenAI Universe：&lt;span&gt;https://universe.openai.com/&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文链接：http://www.nature.com/news/tech-giants-open-virtual-worlds-to-bevy-of-ai-programs-1.21151&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 15 Dec 2016 16:14:18 +0800</pubDate>
    </item>
    <item>
      <title>前沿 | 机器学习新进展，从脑波中探知你的兴趣爱好</title>
      <link>http://www.iwgc.cn/link/3928463</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自TechCrunch&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：杜夏德、蒋思源&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;芬兰的研究人员利用机器学习开发出一种技术，可以在你阅读时读取你的脑信号来捕捉你的兴趣点。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;未来涌现的数据越来越多，人们又将如何智能地筛分导航信息呢？所以面对堆积如山的 MBs（数据流量），我们需要更好的方式去过滤分流数字内容。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;芬兰的研究人员一直关注这个问题，并且已经使用脑电图（electroencephalogram，EGG）感知器监控人们阅读 Wiki 文章时的脑信号，并将它与经过训练的机器学习模型结合起来去解析 EEG 数据，同时识别出阅读者感兴趣的概念。这个研究团队使用该技术生成了一列关键词，这些关键词是阅读者读到包含信息的地方时心理上标记下来（mentally flag）的。这些关键词之后可用于预测与这个阅读者相关的其他 Wiki 文章。或者线下帮助过滤一条社交媒体回复，或者为增强现实用户实时标记出一条符合其兴趣的内容。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们已经探索了搜索过程中人类大脑中产生的信号，」研究者 Tuukka Ruotsalo 说。「现在我们想要采集极端（extreme）的信号，我们能尝试直接读取使用者大脑中的兴趣和注意吗？」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该团队来自赫尔辛基信息技术研究所（HIIT），认为这是研究人员首次展示了基于直接从脑信号中提取关联推荐新信息。「现在有很多脑机接口研究，但通常... 主要研究的都是向计算机作出明确的命令，」Ruotsalo 说。「所以那就意味着，你想控制房间里的光线和你在做一个明确的模式时，你正在尝试明确地做一些事情，然后计算机就要试着从大脑中读取这些你要做的事情。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「在我们的研究中，这些是自然进行的。你只要阅读就好，我们不会让你在读到一个兴奋的单词时去拉左右胳膊。你就是在阅读，同时因为文本中有些地方与你相关，我们能让机器学习与文本唤起的事件匹配的大脑信号，并使用这些信号，」他补充道。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你只需要读你的书就好，计算机会挑出你阅读中的兴趣点或者有关联的地方。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「所以在某种意义上，它是纯粹的被动互动。你只要阅读，计算机会挑出你阅读中的兴趣点或者有关联的地方。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然这是一个研究，只有 15 名测试者和一个脑电帽（EEG cap），没人愿意在实验室之外的地方戴上那个帽子，但是它可以让我们窥探到未来的可能性。一旦有了高质量的 EGG 感知器（人人都能戴的可穿戴智能帽子？），让整个过程不再那么麻烦，并且可切实结合机器学习软件，经过训练后能掌握一点读心术时，它就能走出实验室了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「如果你只研究纯粹的信号无视其他事情，那就难了，」Ruotsalo 解释道，他指出该团队没有通过跟踪任何物理上的身体移动比如眼球运动来解释兴趣。他们对关联的理解仅仅是基于他们的机器学习模型解析 EEG 脑波。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「这是一个真正具有挑战性的机器学习任务。你需要训练这个系统来探测它。有很多像移动或眼球运动这样更加容易的东西... 能在信号中真实地看到。这次你真正要做的是把它从噪音中找出来。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Ruotsalo 说他们在数据量适度的数据集上训练模型，只使用了平均 120 词的 6 个文件，每个文件都用来为其对应的测试对象建立模型。实验还包括使用少量的初始化监督学习，使用的是每个维基百科文章的前六个句子。据 Ruotsalo 表明，在未来的研究中他们想看看是否可以在没有任何监督学习下达到同等实验结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然「兴趣」的概念是相当广泛的，它可能是由读者因各种不同原因在心理上标记的一个关键词，他强调人们已经经过有效地训练来以这种方式导航信息，因为他们已经习惯使用通过这种兴趣信号的语言来实现的数字服务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Ruotsalo 接着说：「这就是现在我们在数字世界中所做的。我们点赞或者点击链接和搜索引擎，只要我们点击了，它们就认为这是里面一定有什么。这就使得在没有任何明确的行动下也能获取我们的兴趣，所以你其实是从大脑中读取维基百科的。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;iframe class="video_iframe" data-vidtype="1" style="   z-index:1; " height="375" width="500" frameborder="0" data-src="https://v.qq.com/iframe/preview.html?width=500&amp;amp;height=375&amp;amp;auto=0&amp;amp;vid=j0355z42tsd" allowfullscreen=""&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那么这就意味着当人们在阅读相当大小的文本时从他们的思维中提取出兴趣信号是可能的。如果你考虑如何在一个人沉浸于某个内容时使用定制营销信息来抓取他的兴趣，那么这就有点恐怖了（dystopic）。所以换句话来说，将目标广告真正读取的是你的意图，而不只是你的点击。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Ruotsalo 希望未来将技术应用于其他更好的商业用途。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「例如在有大量的信息需要处理，很多事情需要控制、记忆的工作任务中，这可以作为一种支持 agent 类型的软件，并且标记上『这对用户很重要』，然后能以后提醒用户：『记得查阅这些你发现有趣的事情』，」他建议道。「这样的用户建模能在一个真正的信息密集型任务中自动提取特征是很重要的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「即使是搜索类型的场景，你正在与你的环境进行交互，在投影机上查看数字内容，我们同样可以看到你对它的兴趣，然后它可以自动检测并为你注释或推送个性化内容」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们已经在数字世界中留下了各种痕迹。我们正在研究过去看过的文档，并可能会粘贴一些我们以后想要再查看的数字内容，但是所有这些都可以自动记录。然后，我们表达的各种偏好，不论是评级还是其他什么，都能用于不同的服务建模。他补充说：「看来，现在所有这一切都可以通过从大脑中读取」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这并不是他们团队第一次参与解决搜索和信息超载问题。Ruotsalo 也是构建 SciNet 视觉检测搜索接口的研究人员，后来由这项技术成立了一家商业公司 Etsimo。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「信息检索或推荐是一种过滤问题，所以我们试图过滤信息，来找到到底什么是有趣的或相关的。他补充说：「我认为这是现在最大的问题之一，所有这些新的系统只是推送我们不一定想要的事情。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文链接：https://techcrunch.com/2016/12/14/researchers-use-machine-learning-to-pull-interest-signals-from-readers-brain-waves/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 15 Dec 2016 16:14:18 +0800</pubDate>
    </item>
    <item>
      <title>盘点 | 2016年不可错过的21个深度学习视频、教程和课程</title>
      <link>http://www.iwgc.cn/link/3911931</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自 Analyticsvidhya&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;几年之前，深度学习还是机器学习里面一个不太受人关注的领域。随着神经网络和大数据的出现，很多复杂任务的实现已经成为可能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2009 年时，深度学习还是一个新兴领域，只有少数人认为这是一个值得研究的领域。但很快，这个领域就得到了很大的发展，目前已经被应用到很多的领域当中，例如：语音识别、图像识别、在一个数据集当中寻找模式、照片中的事物分类、字符文本生成、自动驾驶汽车等等。因此，了解深度学习及其概念是非常重要的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了能够让你用一种更简单的方式学习深度学习，Analytics Vidhya 网站发表了一篇文章梳理了一些 2016 年关于深度学习的视频、教材和课程。其中包括深度学习暑期班、峰会和会议等的一些讲座和教材。希望你能够从中受益。（注：这篇文章中的视频都在 YouTube 上，你也许需要专门的工具才能查看。）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;目标读者&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不管是深度学些方面初学者、中等水平的学者还是专家，你都可以找到适合您观看的视频。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这篇文章也会根据读者的学习程度对学习材料进行分别罗列。如果你是一名初学者或者是中等水平的学者，建议你可以从第一部分开始。如果你想掌握完全掌握深度学习，那这篇文章就是你首先要阅读的不二之选。在开始对深度学习的探索之前，你首先要制作一个日程表。我相信在几周后，至少你可以建立你在深度学习中的第一个模型。对于深度学习方面的专家来说，深度学习的高级教程部分有很多精彩的视频可以帮助你加强现有的知识。你也可以看看 5 分钟的初学者视频来巩固基础知识。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于所有深度学习/数据科学方面的爱好者，你们一定会喜欢深度学习的应用和其他部分对例子的介绍。其中包括谷歌 DeepMind 的一些视频，你可以从中学习如何使用深度学习绘画，并且深度学习是如何让自动驾驶汽车成为现实的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外还有一小部分是关于强化学习的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1.深度学习初学者教程&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;深度学习简化版&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;2016 斯坦福湾区深度学习学校 Day 1&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;2016 斯坦福湾区深度学习学校 Day 2&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;深度学习教程&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;使用神经网络的深度学习及 TensorFlow 介绍&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;机器学习神经网络&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;TensorFlow 入门&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;神经网络&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;改变所有事物的神经网络&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;TensorFlow 广度&amp;amp;深度学习——机器学习&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;深度学习简介&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;深度学习揭秘&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2.深度学习高级&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;2016 年蒙特利尔深度学习暑期班&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;深度学习教程——高级&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;深度学习实践-语音识别与其他&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3.深度学习的应用&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;详解谷歌 DeepMind&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;自动驾驶汽车和深度学习 GPU-英伟达&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;九个有趣的深度学习应用&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;深度学习程序绘画&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4.强化学习&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;简介强化学习函数逼近-教程&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;深度强化地形学习&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;深度学习初学者教程&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1.深度学习简化版&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;时长：系列包含27个视频&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;链接：https://www.youtube.com/watch?list=PLjJh1vlSEYgvGod9wWiydumYl8hOXixNu&amp;amp;v=b99UVkWzYTQ&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果复杂的专业术语让你在学习深度学习时感到困难重重，那么这个教程就是给你的福利。这是深度学习及其基本概念的一个简化版教程。在这个教程里你将会了解到神经网络、深度网络、深度信念网络（DBN）和卷积神经网络。H2O.ai 和这个教程将会让你对深度学习有基本的理解。同时你也会了解到不同的模型，以及在不同情况下该选择何种模型和选择这种模型的理由。之后你将会学到深度学习在不同使用情形下的实际操作经验，包括支持构建你自己深度网络的平台、深度学习可以调用的库。这个简化教程里没有任何数学计算或者编程相关的内容，是为初学者了解深度学习基本思想而制作的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2.2016 斯坦福湾区深度学习学校 Day 1&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;时长：10 小时 33 分&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;链接：https://www.youtube.com/watch?v=eyovmAtoUx0&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;正如吴恩达（Andrew Ng）无比精确的描述，深度学习正在改变业界的发展布局，同时大量有意思的深度学习应用正涌现出来。这个视频是 2016 湾区深度学习学校第一天的内容展示。视频覆盖到的内容有： 1）Hugo Larochelle 讲授前馈神经网络介绍（Introduction on Feedforward Neural Network）；2）Andrej Karpathy 讲授用于计算机视觉的深度学习（Deep Learning for Computer Vision）；3）Richard Socher 讲授用于自然语言处理（NLP）的深度学习（Deep Learning for NLP）；4）Sherry Moore 讲授 TensorFlow 教程（TensorFlow Tutorial）；5）Ruslan Salakhutdinov 讲授深度无监督学习基础（Foundations of Deep Unsupervised Learning）；6）吴恩达讲授深度学习应用基本要点（Nuts and Bolts of Applying Deep Learning）。这些深度学习方面的专家都会以一个易于理解的方式讲解深度学习潜在的概念原理，让你对深度学习有基础理解。同时他们也会分享各自讲授主题相关的应用实例。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3.2016 斯坦福湾区深度学习学校 Day 2&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;时长：10 小时 33 分&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;链接：https://www.youtube.com/watch?v=9dXiAecyJrY&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是湾区深度学习学校的第二天讲授内容视频。视频覆盖到的内容有：1）John Schulman 讲授深度强化学习基础（Foundation of Deep Reinforcement Learning）；2）Pascal Lamblin 讲授 Theano 介绍：一个供模型构建和训练使用的极速 Python 库（Introduction to Theano: A Fast Python library for Modelling &amp;amp; Training）；3）Adam Coates 和 Vinay Rao 讲授语音识别和深度学习（Speech Recognition and Deep Learning）；4）Alex Wiltschko 讲授 Torch 和 Autograd 下的机器学习（Machine Learning with Torch &amp;amp; Autograd）；5）Quoc Le 讲授深度学习实现 Seq2Seq（Sequence to Sequence by Deep Learning）；5）Yoshua Bengio 讲授深度学习的基础和挑战（Foundation and Challenges of Deep Learning）。这些深度学习的应用者都是经常被检索到的深度学习应用专家，他们同时也为大型公司服务，如：谷歌大脑、Twitter 等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4. 教程：深度学习&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;时长：2 小时 29 分&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;链接：https://www.youtube.com/watch?v=CLSy5WlaWKc&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这个深度学习的视频教程里，Yoshua Bengio 和 Yann LeCun 讲解了近年来深度学习所取得的重大突破。在这个领域深耕 30 年之后，Yoshua 和 Yann 带来深度学习如何掀起机器学习和人工智能领域变革浪潮的深度解读。在本视频教程里，你将会学到深度学习是如何实现多层计算模型对数据表征的学习。这些方法大幅提升了语音识别、视觉对象识别、目标检测以及基因学等领域的相关研究。这个教程将会覆盖到深度学习基础，并讨论深度学习的不同应用和目前遇到的挑战。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;5. 使用神经网络的深度学习及 TensorFlow 介绍&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;时长：无&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;链接：https://www.youtube.com/watch?v=oYbVFhK_olY&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你一直在想知道神经网络是如何工作的，为什么最近它有这么多的关注。本教程将介绍神经网络，你将了解神经网络如何能够创建具有巨大数据集的强大模型。并理解神经网络的结构以及每个输入层如何组合在一起以生成输出。这只是完整教程中的第一个视频，第二部分是 TensorFlow 基础。如果需要了解怎样建立神经网络模型，请继续学习第三部分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;6. 机器学习神经网络&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;时长：无&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;链接：https://www.youtube.com/watch?v=cbeTc-Urqak&amp;amp;list=PLoRl3Ht4JOcdU872GhiYWf6jwrk_SNhz9&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;研究人工神经网络的主要思想是理解神经元的并行计算方式及其自适应连接。本课程将由多伦多大学教授 Geoffrey Hinton 讲授，你将学习到神经网络和机器学习将如何带来技术革命。本课程包括感知器、反向传播、卷积神经网络、循环神经网络、梯度下降和超参数贝叶斯优化等主题。这是深度学习最好的课程之一，如果你是深度学习爱好者，那就一定不能错过它。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;7.TensorFlow 入门&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;时长：系列，共 7 个视频&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;链接：https://www.youtube.com/watch?v=QfNvhPx5Px8&amp;amp;index=5&amp;amp;list=PL2-dafEMk2A7EEME489DsI468AB0wQsMV&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现如今最流行的机器学习框架之一就是 TensorFlow，虽然它主要用于进行机器学习和深度神经网络研究，但由于其多功能性，TensorFlow 也可用于各种应用。在这个有趣的 TensorFlow 教程中，您将学习在 Python 中用不到 40 行代码进行构建手写数字图像的分类器。您还将学习如何在 TensorFlow 中生成音乐，什么是 Tensorboard，怎样构建一个神经网络还有使用 TensorFlow 相比其他深度学习库的利弊。这个关于 TensorFlow 的简短教程是深度学习新手必须要了解的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;8. 神经网络&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;时长：系列，共 6 个视频&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;链接 https://www.youtube.com/watch?list=PL2-dafEMk2A5BoX3KyKu6ti5_Pytp91sk&amp;amp;v=h3l4qz76JhQ&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工神经网络能够学习，而且它们需要训练。基本上需要 3 步来构建机器学习模型，即构建、训练、测试。一旦模型构建起来，它就可以在模式识别上训练得越来越好。在这些短短 5 分钟视频里，你将学习建立神经网络、自动编码器和循环神经网络，每段视频的代码也可在 YouTube 上的描述中找到。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;9. 改变所有事物的神经网络&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;时长：14 分 16 秒&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;链接：https://www.youtube.com/watch?v=py5byOOHZM8&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;卷积神经网络是深度神经网络和核卷积（kernel convolution）的结合。这个视频解释了卷积神经网络是如何为精确图像分类带来巨大改变的。如果你是深度学习爱好者，但对神经网络了解甚少，不妨看看这个视频。它向你展示了深度学习是如何用来估计房价的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;10.TensorFlow 广度&amp;amp;深度学习——机器学习&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;时长：3 分 24 秒&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;链接：https://www.youtube.com/watch?v=Xmw9SWJ0L50&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;广度和深度学习（wide and deep learning）结合了用于训练广度线性模型和深度神经网络的记忆（memorization）和归纳（generalization）。在这个视频中，你可以了解到在 TensorFlow 当中对这种简单易用的 API 的应用。它们在大规模的回归分析和分类中所涉及到的稀疏输入问题当中非常实用，例如推荐系统、搜索和排名问题。通过这个 视频来探索广度和深度学习的可能性吧。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;11. 深度学习简介&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;时长：11 分钟&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;链接：https://www.youtube.com/watch?v=l42lr8AlrHk&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个视频对深度学习进行了数学解释。它将带你了解机器是如何找到不同变量的分组并做出具体决策的。如果你是一个数学爱好者，你将会学到如何调整模型参数。视频简单地解释了神经网络对不同输入内容的反应。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;12. 深度学习揭秘&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;时长：22 分钟&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;链接：https://www.youtube.com/watch?v=Q9Z20HCPnww&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是一个深度学习的初级教程。其中，你将了解深度学习是如何帮助机器识别特征的。同时，视频用简单的语言解释了神经网络。首先，视频介绍了神经元的工作方式，随后进一步解释神经元之间的交流方式。随后是深度学习在现实世界中的应用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;深度学习-高级&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1.2016 年蒙特利尔深度学习暑期班&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;时长：无&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;链接：https://www.youtube.com/watch?list=PL5bqIc6XopCbb-FvnHmD1neVlQKwGzQyR&amp;amp;v=xK-bzjIQkmM&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;蒙特利尔深度学习暑期班出现了很多来自不同年龄段的专家与从业人员。该教程是要教人们对深度学习与神经网络有基础的理解。里面有 Yoshua Bengio 教授循环神经网络，Surya Ganguli 教授理论神经科学与深度学习理论，Sumit Chopra 教授 reasoning summit 和 attention，Jeff Dean 讲解 TensorFlow 大规模机器学习，Ruslan Salakhutdinov 讲解学习深度生成式模型，Ryan Olson 讲解深度学习的 GPU 编程，还有其他很多的讲演。想要了解更多内容可参考机器之心之前发表的文章：&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718578&amp;amp;idx=1&amp;amp;sn=ff7d748b149e7952c9fa3b53cefd5afc&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718578&amp;amp;idx=1&amp;amp;sn=ff7d748b149e7952c9fa3b53cefd5afc&amp;amp;scene=21#wechat_redirect"&gt;重磅 | Yoshua Bengio 深度学习暑期班学习总结，35 个授课视频全部开放（附观看地址）&lt;/a&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2. 深度学习教程——高级&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;时长：1 小时 36 分钟&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;链接：https://www.youtube.com/watch?v=DlNR1MrK4qE&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在过去几年中，图像分类、分割、物体检测的技术因深度学习有了极大的进展。该教程会带你了解深度学习的进展，主要集中于使用 Theano 和 Lasagne 的计算机视觉与图像处理。此外，演讲者也讨论了一些重要的技巧，比如用更少的训练数据进行审核等。为了理解视频中的概念，需要一定的代数、微积分与机器学习基础。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3. 深度学习实践-语音识别与其他&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;时长：34 分 46 秒&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;链接：https://www.youtube.com/watch?v=LFDU2GX4AqM&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;吴恩达的地位无需再多做介绍了，大家都知道他对深度学习的贡献。他是世界上首先认识到深度学习潜力的几个人之一。在这个与吴恩达的一对一对话中，他分享了在深度学习上研究的经验、深度学习所到来的科技进展。他提到大数据的进展正在颠覆如今的产业。观看此视频可以了解更多关于深度学习与数据科学的未来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;深度学习的应用&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1. 详解谷歌 DeepMind&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;时长：13 分 44 秒&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;链接：https://www.youtube.com/watch?v=TnUYcTuZJpM&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;AlphaGo 击败围棋前世界冠军李世乭是一个历史时刻。每当机器超越人类的时候，就会引发一轮新的社会进步。谷歌 DeepMind 宣称自己将下一代人工智能和目标带到研发这样的系统活动中：聪明到可以自主采取行动。这个视频解释了 DeepMind 的起源，以及它能为人工智能领域带来的什么样的变革。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2. 自动驾驶汽车和深度学习 GPU-英伟达&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;时长：1 小时 7 分&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;链接：https://www.youtube.com/watch?v=KkpxA5rXjmA&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;英伟达 CEO 黄仁勋分享了深度学习与研究如何改变自动驾驶汽车的面貌，如何让其成真的故事。他开局引介了世界上第一个由英伟达设计的、用于自动驾驶汽车的人工智能超级计算机。还解释了深度神经网络和大数据如何被用于解决 GPU 的问题。深度学习和人工智能如何变不可能为可能？这个视频会让你脑洞大开。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3. 九个超酷的深度学习应用&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;时长：4 分 43 秒&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;链接：https://www.youtube.com/watch?v=Bui3DWs02h4&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;想知道深度学习和机器学习在现实生活中有哪些有趣应用？这个视频会给你答案。你会看到一些让你脑洞大开的应用，比如，不同化学结构的毒性检测，大型图像有丝分裂检测，序列生成，计算机程序自己怎么玩游戏等等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4. 深度学习程序学绘画&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;时长：4 分钟&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;链接：https://www.youtube.com/watch?v=UGAzi1QBVEg&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能神经网络受到了人类大脑的启发，旨在研究神经元之间的连接。在这个视频中，我们会看到几个深度学习应用。但是，神经网络的艺术创作是深度学习最神奇的应用形式。在这个视频里，你将学到如何使用深度学习绘画，或使用人工神经网络对世界名画进行再创作。用户要做的就是输入一张照片，再提供一张目标图片供系统学习（其艺术风格）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;强化学习&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1. 简介强化学习函数逼近-教程&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;时长：2 小时 18 分钟&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;链接：https://www.youtube.com/watch?v=ggqnxyjaKe4&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;强化学习是由机器学习研究社区开发出的用来做最佳序列决策的技术。该教程提供了对底层形式问题（马尔科夫决策过程）及其核心解决方法的透彻理解，后者包括动态编程、蒙特卡洛方法和时序差分学习。该视频注重这些方法如何与参数逼近（parametric approximation）结合从而找到因过大而难以解决问题的好的逼近解决方案。演讲者也会带你了解函数逼近、eligibility traces 和 off-policy 学习的最新进展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2. 深度强化地形学习&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;时长：3 分钟&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;链接：https://www.youtube.com/watch?v=wBrwN4dS-DA&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本视频描述了深度学习与强化学习的结合，这种结合被认为有助于解决许多极端困难的任务。谷歌 DeepMind 使用深度学习建立了一个能够玩 Atari 游戏的系统，其表现超过了人类。视频展示了一个有趣的应用就是使用深度强化学习教会处在某些地带中的动物绘制周围环境，避免障碍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;结语&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这就是 2016 年的人工智能视频盘点，我们收集了一系列关于深度学习与强化学习的视频。根据年份、浏览量与关联度挑选出最后名单。目前在网络上有着丰富的内容资源，而我们提供的是其中最引人关注的一部分。相信这个列表中肯定会有适合你的内容。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文链接：https://www.analyticsvidhya.com/blog/2016/12/21-deep-learning-videos-tutorials-courses-on-youtube-from-2016/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 14 Dec 2016 14:01:13 +0800</pubDate>
    </item>
  </channel>
</rss>
