<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>斯坦福大学实现高性能低功耗人工突触，可用于神经网络计算</title>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650723632&amp;idx=1&amp;sn=5e25a2bbd6c27368f3548651d404a266&amp;chksm=871b114eb06c9858cbf3551f5ed692f38ad4b132ce677510f63276e256ff6ea6c902ccc9295d&amp;scene=0#rd</link>
      <description>
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自Stanford&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;作者：TAYLOR KUBOTA&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：微胖、晏奇&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;斯坦福研究人员打造出一种新的有机人工突触，更好地支持计算机再现人类大脑信息处理方式。该研究还能改善脑机（brain&amp;mdash;machine）技术。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管这些年来，计算机技术取得不少进展，但是，在再造大脑低能耗、简洁的信息处理过程这方面，我们仍然步履蹒跚。现在，斯坦福大学和桑迪亚国家实验室的研究人员取得了重要进展，该研究可以帮助计算机模拟某块大脑高效设计，亦即人工突触。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/a7dc11591bf333cc590e0d2b1208c302eb9388fd"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Alberto Salleo，材料科学与工程学副教授，研究生 Scott Keene 在确知用于神经网络计算的人工突触的电化学性能。他们是创造这一新设备团队的成员。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Alberto Salleo 说，它运行起来就像是真的突触，不过，它是一个可以制造出来的电子设备。Alberto Salleo 是斯坦福大学材料科学与工程学副教授，也是这篇论文的资深作者（senior author）。「这是一套全新的设备系列，之前并没有看到过这类架构。许多关键标准测评后，我们发现，这款设备的性能要比其他任何非有机设备要好。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相关研究发表在了 2 月 20 日 的 Nature Materials上，该人工突触模仿了大脑突触从通过其中的信号中进行学习的方式。较之传统计算方式，这种方式要节能得多，传统方法通常分别处理信息然后再将这些信息存储到存储器中。就是在这里，处理过程创造出记忆。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;或许有一天，这款突触能够成为一台更接近大脑计算机的一部分，它特别有利于处理视觉、听觉信号的计算过程。比如，声控接口以及自动驾驶汽车。过去，这一领域已经研究出人工智能算法支持下的高效神经网络，但是，这些模仿者距离大脑仍然比较遥远，因为，它们还依赖传统的能耗计算机硬件。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;建造一个大脑&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人类学习时，电子信号会在大脑神经元之间传递。首次横穿神经元最耗费能量。再往后，连接所需的能力就少了。这也是突触为学习新东西、记住已学内容创造便利条件的方式。人工突触，和所有其他类脑计算版本不同，可以同时完成（学习和记忆）这两项任务，并能显著节省能量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深度学习算法非常强大，不过，仍然依赖处理器来计算、模拟电子状态并将其保存在某个地方，就能耗和时间而言，这可不够高效，Yoeri van de Burgt 说，他之前是 Salleo lab 的博士后研究人员（postdoctoral scholar），也是这篇论文的第一作者。「我们没有模拟一个神经网络，而是试着制造一个神经网络。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这款人工突触是以电池设计为基础的。由两个灵活的薄膜组成，薄膜带有三个终端，这些终端通过盐水电解质连接起来。它的功能就像一个晶体管，其中一个终端控制其与其他两个终端之间的电流。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;就像大脑中的神经通路可以通过学习得到加强，研究人员通过重复放电、充电，为人工突触编程。训练后，他们就能预测（不确定性仅为 1%）需要多少伏电，才能让突触处于某种特定电信号状态（electrical state），而且一旦抵达那种状态，它就可以保持该状态。易言之，不同于普通电脑，关掉电脑前，你会先将工作保存在硬件上，人工突触能回忆起它的编程过程而无需任何其他操作或部件。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;测试人工突触网络&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;桑迪亚国家实验室的研究者目前只制造了一个人工神经突触，但是，他们使用有关突触实验中获得的 15,000 个测量结果来模拟某一列（array）突触在神经网络中的运行方式。他们测试了模拟网络识别手写数字 0 到 9 的能力。三个数据集上的测试结果显示其识别手写数字准确度达 93%~97%。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管这项工作对于人类来说显得相对简单，但是对于传统计算机而言，要解释视觉与听觉信号曾经是非常困难的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们期望计算设备能做的工作越来越多，这就需要模拟大脑工作方式的计算方式，因为用传统计算来完成这些工作，能耗巨大，」A. Alec Talin 说，「我们已经证实这款设备很适合实现这些算法，而且很节能。」A. Alec Talin 是桑迪亚国家实验室的杰出技术研究员，也是这篇论文的资深作者。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该设备极其适合于传统计算机执行起来很费劲的信号识别和分类工作。数字晶体管只能处于两种状态，比如 0 或 1，但是研究人员在一个人工突触上成功编码了 500 种状态，对于神经元类计算模型来说，这很有用。从一种状态切换到另一种状态所使用的能耗约为当前最先进计算系统的 1/10，最先进的计算系统需要这些能耗将数据从处理单元移动到存储器。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而，较之一个生物突触引发放电所需的最低能耗，这款人工突触仍然不够节能，所需能耗是前者的 10000 倍。研究人员希望，一旦他们测试用于更小的设备的人工神经突触，他们可以实现类似生物神经元级别的能耗水平。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;有机材料的潜力&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;设备的每一部分都由便宜的有机材料制成。虽然在自然界中找不到这些材料，但是它们大部分都由氢、碳两种元素构成，而且与大脑化学物质兼容。细胞已经可以在这些物质上生长，并且已经被来打造用于神经递质（neural transmitters）的人工泵。用于训练这类人工突触的电伏也和穿行人类神经元所需的能量相同。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些都使得人工神经突触与生物神经元之间的交流成为可能，可借此改进脑机接口。同时，设备的柔软性与灵活性也使得它可被用于生物环境。但是，进行任何生物学方面应用之前，团队计划先打造一列人工神经突触，用于进一步研究与测试。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文链接：http://news.stanford.edu/2017/02/20/artificial-synapse-neural-networks/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Fri, 24 Feb 2017 12:16:21 +0800</pubDate>
    </item>
    <item>
      <title>业界 | Facebook开源大规模预测工具Prophet：支持Python和R</title>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650723632&amp;idx=2&amp;sn=686c0a40ee081c18dda15ef82dbacd45&amp;chksm=871b114eb06c985815df268fc8bb4bc0e0e3e58bb72ecc98f905ed95ee3389388854f51b6146&amp;scene=0#rd</link>
      <description>
&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自Facebook&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀、黄小天、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;今天，Facebook 宣布开源了一个可以通过 Python 和 R 语言使用的预测工具 Prophet。以下是 Facebook 研究博客对该工具的介绍，后面还附有机器之心对该开源项目 README.md 文件和相关论文摘要的编译介绍。相关论文也可点击文末「阅读原文」查看。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Prophet 项目地址：https://github.com/facebookincubator/prophet&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;预测（forecasting）是一个数据科学问题，也是很多组织机构内许多活动的核心。比如说，像 Facebook 这样的大型组织必须进行能力规划（capacity planning）以有效地分配稀缺资源和目标配置，以便能基于基准对业绩表现进行测量。不管是对于机器还是对于分析师而言，得出高质量的预测都并非易事。我们已经在创建各种各样的业务预测（business forecasts）的实践中观察到了两大主要主题：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;完全自动化的预测技术可能会很脆弱，而且往往非常不灵活，不能整合有用的假设或启发。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;能够产生高质量预测的分析师相当少，因为预测是一种需要大量经验的数据科学领域的专业技能。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这两个主题会导致一个结果：对高质量预测的需求往往超出分析师能够得出的预测速度。这个情况是我们创造 Prophet 的动力：我们想要让专家和非专家都能轻松地做出高质量的预测来满足自身的需求。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于「规模（scale）」的通常考虑涉及到计算和存储，但这些都不是预测的核心问题。我们发现预测大量时间序列（time series）的计算和基础设施问题是相对简单的&amp;mdash;&amp;mdash;通常这些拟合过程可以很容易地并行化，而预测本身也能容易地被存储在 MySQL 这样的关系数据库或 Hive 这样的数据仓库中。据我们观察，「规模」在实践中面临的问题涉及的是由多种预测问题所引入的复杂性（complexity）和在得出预测后如何在大量预测结果中构建信任（trust）。Prophet 已经成为了 Facebook 创建大量可信预测的能力的关键组成部分，这些预测可被用于决策制定甚至用在产品功能中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Prophet 有什么用？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;并非所有的预测问题都可以通过同一种程序（procedure）解决。Prophet 是为我们在 Facebook 所遇到的业务预测任务而优化的，这些任务通常具有以下特点：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;对于历史在至少几个月（最好是一年）的每小时、每天或每周的观察&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;强大的多次的「人类规模级」的季节性：每周的一些天和每年的一些时候&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;事先知道的以不定期的间隔发生的重要节假日（如，超级碗）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;合理数量的缺失的观察或大量异常&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;历史趋势改变，比如因为产品发布或记录变化&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;非线性增长曲线的趋势，其中有的趋势达到了自然极限或饱和&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们发现默认设置的 Prophet 能产生往往和经验丰富的预测师得到的一样准确的预测，而所花费的工作却更少。使用 Prophet，如果该预测不令人满意，你也不用局限于一个完全自动化的程序&amp;mdash;&amp;mdash;即使一个没有接受过任何时间序列方法训练的分析师也能够使用各种各样的可轻松解读的参数来改进或调整预测。我们已经发现：通过在特定案例上将自动化预测和分析师参与的预测（analyst-in-the-loop forecasts）结合到一起，它有可能可适用于非常大范围的业务用例。下图给出了我们发现的可以大规模使用的预测过程：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/a199a014c55f4e0c1e37fe3c11c0b83f97007f14"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于该预测过程的建模阶段，目前仅有有限数量的工具可用。Rob Hyndman 的出色的预测 R 语言的预测软件包（http://robjhyndman.com/software/forecast/）可能是目前最受欢迎的选择，而且谷歌和 Twitter 也都分别发布了带有更加特定的时间序列功能的软件包&amp;mdash;&amp;mdash;CausalImpact（https://google.github.io/CausalImpact/）和 AnomalyDetection（https://github.com/twitter/AnomalyDetection）。就我们所知，在使用 Python 的预测上，还少有开源的软件包可用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们常常在许多设置中使用 Prophet 作为预测（forecast）软件包的替代，因为其有如下两个主要优点：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1.Prophet 让我们可以更加简单直接地创建合理且准确的预测。该预测包包含了许多不同的预测技术（比如 ARIMA、指数平滑等），其中每一个都有它们自己的长处、短处和调整参数。我们发现错误的模型或参数选择往往会导致糟糕的结果，而在这样的选择阵列下，即使是经验丰富的分析师也不太可能能够有效地选择出正确的模型和参数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2.Prophet 预测可以通过对非专家而言很直观的方式进行自定义。有关于季节性的平滑参数让你能调整与历史周期之间的接近程度，以及关于趋势的平滑参数让你能调整跟随历史趋势变化的激进程度。对于增长曲线而言，你可以手动设定「capacity」或增长曲线的上限，这能让你注入关于你预测的增长或下降情况的先验信息。最后，你还可以为模型指定没有规律的节假日，比如超级碗、感恩节和黑色星期五的日期。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Prophet 如何工作&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本质上讲，Prophet 程序是一个可加性回归模型（additive regression model），它包含 4 个主要组件：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;分段线性或者 logistic 增长曲线趋势。通过从数据中选择变化点，Prophet 自动探测趋势变化。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;使用傅立叶级数建模每年的季节分量。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;使用虚变量（dummy variables）的每周的季节分量。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;用户提供的重要节假日列表。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;例如，下面是一个特征预测：使用 wikipediatrend 包（https://cran.r-project.org/web/packages/wikipediatrend/index.html）下载的 Peyton Manning 的维基百科页面的查看数量的日志。由于 Peyton Manning 是一名美式橄榄球运动员，你可以看到他每年季节性的重要程度变化，同时每周的周期性也明显存在。最后你看到特定事件（比如他参加的季后赛）也可能被建模了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/6a07881fdc7dd2e068ab6d53319dcd5cc2e5e7f2"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Prophet 将提供一个组分图，用图形描述它所拟合的模型：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/b638af6ff277eadc284d7c7265f40e898569ba77"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个组分图更加清晰地展示了与浏览 Peyton Manning 的网页（橄榄球常规赛与季后赛）相关的每年的季节性，以及每周的季节性：（星期日和星期一）比赛当天和比赛之后有更多的访问。你也可以注意到趋势组件自他最近退休以来的下行调整。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Prophet 的重要思想是：通过更好地灵活拟合趋势组分，我们可以更精确地建模季节性，并且有更准确的预测结果。对于这个任务我们更喜欢使用非常灵活的回归模型（有一点像曲线拟合）而不是传统的时序模型，因为前者可以使我们建模更灵活，更容易拟合模型，更优雅地处理丢失数据或离群值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过模拟时间序的未来趋势变化，Prophet 默认地会为趋势组分提供不确定的间隔。如果你希望对未来季节性或假期影响的不确定性进行建模，你可以运行数百个 HMC 迭代（花费几分钟），你的预测就将会包括季节性不确定评估。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们使用 Stan（http://mc-stan.org/）调整 Prophet 模型，并在 Stan 的概率编程语言中实现了 Prophet 流程的核心部分。Stan 对参数的 MAP 优化有着极快的速度（&amp;lt;1 秒），让我们可以选择使用 Hamiltonian Monte Carlo 算法评估不确定的参数，也使得我们能够在多种接口语言上重复使用该拟合程序。目前，我们提供了 Python 和 R 语言的 Prophet 实现。它们有着几乎相同的特征，而且通过提供这两种实现，我们希望该预测方法能够在数据科学社区有更广泛的用途。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;如何使用 Prophet&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使用 Prophet 的最简单方法是从 PyPI（Python）或 CRAN（R）里安装这个软件包。你可以阅读我们的快速入门指南，以及阅读综合文档以进行深入的了解。如果你正在寻找一个有趣的时序数据资源，我们建议你尝试一下 wikipediatrend 软件包，它可以从维基百科页面上下载历史页面点击数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以下是机器之心对 Prophet 项目上 README.md 文件的编译介绍：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Prophet 是一个预测时序数据的程序。它基于加法模型（additive model），其中非线性趋势可与按年和按周的季节性、以及节假日进行拟合。借助至少一年的历史数据，它在每日预测数据上表现最好。在数据丢失、趋势变换以及大离群值方面，Prophet 表现也很稳健。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Prophet 是由 Facebook 的 Core Data Science 团队发布的一个开源软件，可从 CRAN 和 PyPI 上下载。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;重要链接&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;主页：https://facebookincubator.github.io/prophet/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;HTML 文档：https://facebookincubator.github.io/prophet/docs/quick_start.html&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;问题跟踪：https://github.com/facebookincubator/prophet/issues&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;源代码库：https://github.com/facebookincubator/prophet&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Prophet R 软件包： https://cran.r-project.org/package=prophet&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Prophet Python 软件包：https://pypi.python.org/pypi/fbprophet/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;在 R 中安装&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Prophet 是一个 CRAN 软件包，因此你可以使用 install.packages：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;# R&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&amp;gt; install.packages('prophet')&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;完成安装，你就可以开始了！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Windows&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 Windows 中，R 需要一个编译器，你可以遵循 rstan 提供的指导：https://github.com/stan-dev/rstan/wiki/Installing-RStan-on-Windows。关键一步是在试图安装软件包之前安装 Rtools：http://cran.r-project.org/bin/windows/Rtools/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;在 Python 中安装&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Prophet 在 PyPI 上，因此你可以用 pip 安装它：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;# bash&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;$ pip install fbprophet&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Prophet 的主要依赖包是 pystan。PyStan 有自己的安装说明：http://pystan.readthedocs.io/en/latest/installation_beginner.html&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;完成安装，你就可以开始了！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Windows&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 Windows 中，PyStan 需要一个编译器，因此你将遵循这个指导：&lt;/span&gt;&lt;span&gt;http://pystan.readthedocs.io/en/latest/windows.html。关键一步是安装一个最新的 C++编译器：http://landinghub.visualstudio.com/visual-cpp-build-tools&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;论文：Forecasting at Scale&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/76891959af79a55c013f189410687dfe99324cdf"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：要在各种时间序列（time series）上产生大量预测，我们面临着各种各样的挑战。我们实现大规模预测（forecasting at scale）的方法是将可配置的模型和全面的分析师参与的（analyst-in-the-loop）性能分析结合到一起。我们提出了一种基于一种可分解模型（decomposable model）的预测方法，这种模型带有可解释的参数，这些参数可被分析师直观地进行调整。我们描述了我们可以用来比较和评估预测程序的表现分析，并且自动标记了需要人工审查和调整的预测。这些能帮助分析师最有效地使用他们的专业知识工具实现了对许多类型业务时间序列的可靠预测。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Fri, 24 Feb 2017 12:16:21 +0800</pubDate>
    </item>
    <item>
      <title>教程 | 你来手绘涂鸦，人工智能生成「猫片」：edges2cats图像转换详解</title>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650723632&amp;idx=3&amp;sn=88f89ee39a145f4bf0c0add7a42fa4ca&amp;chksm=871b114eb06c985809a27507310d1d1394f908c9cd231d3bf0c9180f462d2fedd1a60f505ab6&amp;scene=0#rd</link>
      <description>
&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自Affinelayer&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：黄小天、曹瑞、蒋思源&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;edges2cats 是最近网络中火爆的开源应用，它能以你随手鼠绘的单色线图为基础自动生成一张「真实图片」。其中绘制猫的版本最受欢迎。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/5806c20920aaf720b6b4fc11f7e52f495052a109"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 2 月 19 日推出以后，这个实现很快受到了大家的关注，甚至连 Yann LeCun 这样的重量级人物也在其中开始了自己的「创作」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/c72079f203e7a26dba60e18b66ab5be4ab0ead90"/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/4f5233110fcb0f4132d1725a3568db3ddb3937e5"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这一神奇的应用是如何实现的？让我们看看作者 Christopher Hesse 带来的教程吧。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相关链接：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Edges2cats：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;http://affinelayer.com/pixsrv/index.html&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Github：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://github.com/phillipi/pix2pix&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Isola 等人在 pix2pix 中得到的结果看起来很不错，它是对抗性网络的一种绝佳实现，所以我将 Torch 上的代码移植到了 Tensorflow 中。在 Github 上单文件版（single-file）的实现 pix2pix-tensorflow 已经可供下载：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://github.com/affinelayer/pix2pix-tensorflow&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面是 pix2pix 的一些例子，我将从论文开始一步步解释这到底是什么。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/e49a65d55baaa61dc98889c9ac8f3c54c7a29b5a"/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;「术士的宝石，是魔力无边的宝石，它能点石成金、创造不朽、复生鬼魂、杀死巨魔，它无所不能。」&amp;mdash;&amp;mdash;&lt;span&gt;Wizard People, Dear Readers&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;pix2pix 也许不能复生鬼魂，但是如果你给它一个包含了普通石头和其相对金子形态的数据集，那么 pix2pix 还真能点石成金。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;运行代码&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;code style=" box-sizing: inherit; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; "&gt;&lt;span&gt;&lt;span&gt;# make sure you have Tensorflow 0.12.1 installed first&lt;/span&gt;python -c &lt;span&gt;"import tensorflow; print(tensorflow.__version__)"&lt;/span&gt;&lt;span&gt;# clone the repo&lt;/span&gt;&lt;span&gt;git&lt;/span&gt; clone https://github.com/affinelayer/pix2pix-tensorflow.git&lt;span&gt;cd&lt;/span&gt; pix2pix-tensorflow&lt;span&gt;# download the CMP Facades dataset http://cmp.felk.cvut.cz/~tylecr1/facade/&lt;/span&gt;python tools/download-dataset.py facades&lt;span&gt;# train the model# this may take 1-9 hours depending on GPU, on CPU you will be waiting for a bit&lt;/span&gt;python pix2pix.py \
 &amp;nbsp;--mode train \
 &amp;nbsp;--output_dir facades_train \
 &amp;nbsp;--max_epochs 200 \
 &amp;nbsp;--input_dir facades/train \
 &amp;nbsp;--which_direction BtoA&lt;span&gt;# test the model&lt;/span&gt;python pix2pix.py \
 &amp;nbsp;--mode &lt;span&gt;test&lt;/span&gt; \
 &amp;nbsp;--output_dir facades_test \
 &amp;nbsp;--input_dir facades/val \
 &amp;nbsp;--checkpoint facades_train&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;终端&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在经过一段时间的训练后，你大概会得到类似于以下的输出：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/7c23dced4f6482610d164d4d552b280a3b278151"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;pix2pix 是怎样运作的？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;pix2pix 使用了一种条件生成式对抗网络（Conditional Generative Adversarial Networks）来学习从输入图像到输出图像的映射。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个网络由两个主要部分组成，生成器（generator）和辨别器 (discriminator)。生成器接收了输入图像，经过转变来得到输出图像。辨别器将输入图像与未知图像（不管是数据集中的目标图像，或是辨别器产生的输出图像）进行比较，并尝试猜测该图像是否由生成器生成。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个数据集的例子就是输入图像是黑白图片，但是目标图像是这个图像的彩色版本：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/c0456629d9da0240bf6370bc5b974bf2a7cbdb9e"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这种情况下，生成器就会去尝试学习如何让黑白图像变为彩色：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/08b365d9684ac5248cc465c5eaf6c07c4cdaf827"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;辨别器看到生成器彩色化的尝试，就会去试着学习分辨生成器彩色化的图像和数据集中真正有颜色的目标图像之间的区别。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/a32f19b5aace5ee2d0aed8c13f7d781b5faa0b60"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为什么要这么麻烦呢？这篇论文其中的一个重点就是辨别器为训练生成器提供了一个损失函数，你不需要手动指定。人工设计（Hand-engineered）的转换代码已经由经过训练的神经网络所替代，所以为什么不能把手动设计的损失函数运算也替代了呢？如果这起作用的话，在你还在担忧计算机会取代你的工作时，它们就已经开始接管工作了。让我们来看一看对抗式网络的两个组成部分：生成器和辨别器。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;生成器&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;生成器的工作就是对一张输入图像进行我们想要的转换，以生成目标图像。输入图像应该是黑白图像，输出图像我们想让它成为彩色版本。生成器的结构叫做「编码器&amp;mdash;解码器」（encoder-decoder），在 pix2pix 模型中，编码器&amp;mdash;解码器看起来就如下图所示：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/18e307d8a98b2b050a65b3c11bb09894a9739988"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里的容量给你一种紧挨着张量维度的形状感。样例中的输入是一个带有 3 个颜色通道（红、绿、蓝，全部等于一个黑白图像）的 256x256 图像，并且输出相同。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;生成器获得一些输入，并试图用一系列的编码器（卷积+激活函数）减少它，直到成为一个较小的表征。想法是通过这种方式压缩它我们希望在最后一个编码层之后有一个更高层面的表征。解码层执行相反操作（去卷积+激活函数），并且反转编码层的行动。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/fa96e2d1e6189fc872a1e813a3339389eeed17e9"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了提高论文中图到图传输的表现，作者使用 「U-Net」取代了 encoder-decoder。它们在做同样的事，不同的是有了直接连接编码层和解码层的跳跃连接。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/cebb74a96bf13cbe7f21162245630f8b0c0c58c7"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;跳跃连接给了网络一个忽略编码／解码部分的选择，如果它对其毫无用处。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些图解略有简化。例如，网络的第一层和最后一层之间没有批标准层，中间的个别层有丢失的单元。论文中使用的着色模式对于输入和输出层有着很多不同的通道。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;辨别器&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;辨别器（The Discriminator）的目标就是接收两张图像，一张是输入图像，另一张是未知图像（其可能是辨别的目标或者是生成器输出的图像），辨别器的工作就是识别第二张图像到底是不是从生成器（the generator）输出的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/fc4f9e7316185b218a3351955281c33bff50f74d"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该结构看起来就像是生成器的编码部分一样，只不过稍微复杂一点。输出是 30&amp;times;30 的图像，其中每一个像素值（从 0 到 1）表示未知图像相应部分的置信度。在 pix2pix 的实现中，30&amp;times;30 图像中每一个像素都对应着 70&amp;times;70 块输入图像的置信度（因为输入图像是 256&amp;times;256 的，所以这些图像块有很多重叠）。这种构架就称之为「区块生成对抗网络（PatchGAN）」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;训练&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了训练该网络，我们需要分两步进行：即训练辨别器（discriminator）和训练生成器（generator）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了训练辨别器，首先生成器需要生成一张输出图像。辨别器再根据输入/目标对（input/target pair）和输入/输出对（input/output pair）判定该图像有多大程度看起来是真实的。然后基于输入/输出对（input/output pair）和输入/目标对（input/target pair）的分类误差来调整辨别器的权重。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/1895194fe83b847b593d109ed7071d297006b8a7"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;根据鉴别器的输出和输出与目标图像之间的差异来调节生成器的权重。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/d6e1425ac4ec181e10c57dd9c37fb3c428c6b125"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里有一个技巧：当你在鉴别器的输出结果上训练生成器时，你实际上是在计算鉴别器的梯度，这意味着当鉴别器性能提升时，你是在训练生成器打败鉴别器。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中的原理是这样：当鉴别器变的越来越好时，生成器也是。如果鉴别器擅长这项任务，生成器有能力通过梯度下降学习正确的映射函数，你应该得到一个逼真的生成输出。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;验证&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们从一台装有 Nvidia GTX 750 Ti 显卡（~1.3 TFLOPS）的 Linux 主机上执行代码进行验证。由于计算能力的欠缺，验证并不广泛，并且只有 200 个 epoch 中的 facades 数据集被测验。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;终端&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;code style=" box-sizing: inherit; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; "&gt;&lt;span&gt;&lt;span&gt;git&lt;/span&gt; clone https://github.com/affinelayer/pix2pix-tensorflow.git&lt;span&gt;cd&lt;/span&gt; pix2pix-tensorflow
python tools/download-dataset.py facades&lt;span&gt;sudo&lt;/span&gt; nvidia-docker run \
 &amp;nbsp;--volume &lt;span&gt;$PWD&lt;/span&gt;:/prj \
 &amp;nbsp;--workdir /prj \
 &amp;nbsp;--env PYTHONUNBUFFERED&lt;span&gt;=&lt;/span&gt;x \
 &amp;nbsp;affinelayer/pix2pix-tensorflow \
 &amp;nbsp;python pix2pix.py \
 &amp;nbsp; &amp;nbsp;--mode train \
 &amp;nbsp; &amp;nbsp;--output_dir facades_train \
 &amp;nbsp; &amp;nbsp;--max_epochs 200 \
 &amp;nbsp; &amp;nbsp;--input_dir facades/train \
 &amp;nbsp; &amp;nbsp;--which_direction BtoA&lt;span&gt;sudo&lt;/span&gt; nvidia-docker run \
 &amp;nbsp;--volume &lt;span&gt;$PWD&lt;/span&gt;:/prj \
 &amp;nbsp;--workdir /prj \
 &amp;nbsp;--env PYTHONUNBUFFERED&lt;span&gt;=&lt;/span&gt;x \
 &amp;nbsp;affinelayer/pix2pix-tensorflow \
 &amp;nbsp;python pix2pix.py \
 &amp;nbsp; &amp;nbsp;--mode &lt;span&gt;test&lt;/span&gt; \
 &amp;nbsp; &amp;nbsp;--output_dir facades_test \
 &amp;nbsp; &amp;nbsp;--input_dir facades/val \
 &amp;nbsp; &amp;nbsp;--checkpoint facades_train&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;出于对比，验证集中的第一个图像看起来像这样：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/75175bb1a2c2f6cfbdbf489bd9a20a9b9548048e"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;验证结果集：&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://affinelayer.com/pix2pix/validation.zip&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;实现&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;实现是一个单一文件 pix2pix.py ，尽可能在 TensorFlow 图谱之内。移植过程多是观察现有的 Torch 实现和 Torch 源代码，搞明白什么种类的层和设置被使用，以确保 TensorFlow 版本与原始版本尽可能一致。调试一个有问题的实现很耗时间，因此我细心地尝试这次转化以规避掉大量的调试。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;pix2pix.py：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;https://github.com/affinelayer/pix2pix-tensorflow/blob/master/pix2pix.py&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;实现开始于创建生成器图，接着是鉴别器图，最后是训练系统。在运行时使用 Torchpix2pix 代码打印生成器和鉴别器图。我在 Torch 框架源中寻找不同的图层类型，并发现了当前的设置和操作，以及如何在 Tensorflow 中将其实现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最理想的情况是能把 pix2pix 训练的网络权重导进 Tensorflow 以验证图形构造。但是这令人厌烦，而且我很不擅长 Torch，所以我没有那样做。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本代码中的大多数错误与 Tensorflow 的 build-graph-then-execute 模型相关，如果你习惯于命令式代码，那么 Tensorflow 会让你感到一点惊讶。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;论文：&lt;strong&gt;Image-to-Image Translation with Conditional Adversarial Networks&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/5db86ea99d77ef6930b5d73a750a1f257c66018f"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：&lt;/span&gt;&lt;span&gt;为实现图像到图像转化（image-to-image translation）任务，我们研究了条件对抗网络。这些网络不仅会学习从输入图像到输出图像的映射，而且还学习损失函数来训练映射。这使得我们不必在此类任务中加入通常需要的不同的损失公式。我们的实验证明了这种方法在从有标记的地图中生成照片，利用单色线图生成照片，为黑白图填充色彩等任务中是有效的。我们证明了在此类模型的训练中，人类不再需要手动输入的映射函数以及损失函数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文链接：https://affinelayer.com/pix2pix/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Fri, 24 Feb 2017 12:16:21 +0800</pubDate>
    </item>
    <item>
      <title>专栏 | 顾险峰：看穿机器学习的黑箱（III）</title>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650723632&amp;idx=4&amp;sn=bce69c9144195625be886b91bd054f00&amp;chksm=871b114eb06c9858360ae2af975e272a9c8926dcda8b3b790e120fa97776ac098b61d34710ba&amp;scene=0#rd</link>
      <description>
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;转自老顾谈几何&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;公众号ID：conformalgeometry&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：顾险峰&amp;nbsp;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;这篇文章是顾险峰老师所写的《看穿机器学习的黑箱》的第三篇，&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650723168&amp;amp;idx=3&amp;amp;sn=41fcf2fb0408c7b6a9b82d55d91c2b9c&amp;amp;chksm=871b171eb06c9e082c4083ff32748104a617e5cb1e6bd4d296b4db431358b8a41f40908ea8a5&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650723168&amp;amp;idx=3&amp;amp;sn=41fcf2fb0408c7b6a9b82d55d91c2b9c&amp;amp;chksm=871b171eb06c9e082c4083ff32748104a617e5cb1e6bd4d296b4db431358b8a41f40908ea8a5&amp;amp;scene=21#wechat_redirect" target="_blank"&gt;第一篇&lt;/a&gt;与&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650723249&amp;amp;idx=5&amp;amp;sn=a0b0d42b3a55456ba680b756592aade9&amp;amp;chksm=871b17cfb06c9ed9905f24bbe84366002e01915a3a2991992114c15125249f2f5166d025f695&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650723249&amp;amp;idx=5&amp;amp;sn=a0b0d42b3a55456ba680b756592aade9&amp;amp;chksm=871b17cfb06c9ed9905f24bbe84366002e01915a3a2991992114c15125249f2f5166d025f695&amp;amp;scene=21#wechat_redirect" target="_blank"&gt;第二篇&lt;/a&gt;可点击超链接查看。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;上周，老顾访问了UCLA的师兄朱松纯教授和吴英年教授，向他们学习计算机视觉的统计观点。早在二十多年前，以Mumford先生，朱松纯教授为代表的计算机视觉领域的哈佛学派就大力提倡将统计概率系统性地引进到视觉领域，用统计方法来解释和处理视觉领域的基本问题。目前，这一方法论早已在视觉领域深入人心，实际上也是机器学习的理论基础之一。最优传输理论描述了概率分布的几何，因此有助于我们研究视觉方面的机器学习。下面，我们开始撰写第三次讲稿。&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;概览&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;直观而言，视觉领域机器学习的统计观点如下：我们将所有可能的图像构成的空间设为&lt;img src="http://img03.iwgc.cn/mpimg/334ef486bf2a83bd5bc2b82a63debc67d6234b28"/&gt;，其中n是总的像素个数，每张图像视为全图像空间中的一个点&lt;img src="http://img04.iwgc.cn/mpimg/9ed6e8be86fada6feb22aa01c28823828a5d62e0"/&gt;。每个有意义的视觉&amp;ldquo;概念&amp;rdquo;（例如所有猫的图像）是全空间&lt;img src="http://img05.iwgc.cn/mpimg/9c1c3851f6c56ae19cd4fd7920a1a0b65acb301c"/&gt;的一个可测子集，&lt;img src="http://img05.iwgc.cn/mpimg/746e39b2e5006318db52d1bd82e6c9e318d6485b"/&gt;。固定一个概念&lt;img src="http://img03.iwgc.cn/mpimg/1119b2a4bed0d12afe60942fd0723cf5510dd3ab"/&gt;，每张图片是否表达了这个概念就给出了一个概率分布&lt;img src="http://img03.iwgc.cn/mpimg/ccfd860e808c2e9f761931353d771e4c64be3024"/&gt;。这样，视觉中的问题就被转化为概率统计的问题：如何表示概率分布，如何衡量概率分布间的距离，如何近似一个概率分布，如何生成满足特定概率分布的随机变量，如何根据概率分布进行统计推断，等等。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;近年来，依随Internet技术的发展，人类已经积累了大量的视觉数据，这使得估计各种概率分布成为可能。同时，GPU技术的发展，使得各种统计计算方法的实现成为可能。因此，我们迎来了机器学习的科技大潮。但是，我们依然无法严密解释机器学习算法的有效性。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;老顾倾向于认为，从基础理论角度而言，研究概率分布的一个强有力工具是最优传输理论（optimal mass transportation theory），这个理论着重揭示概率分布这一自然现象的内在规律，因此并不从属于某个学派，也不依赖于具体的算法。相反，这一理论会为算法的发展提供指导，同时真正合理有效的算法（例如机器学习算法），应该可以被传输理论来解释。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;简而言之，传输理论给出了概率分布所构成空间的几何。给定一个黎曼流形，其上所有的概率分布构成一个无穷维的空间：Wasserstein空间，最优传输映射的传输代价给出了Wasserstein空间的一个黎曼度量。Wasserstein空间中的任意两点可以用Wasserstein距离来测量相近程度，自然也可以用测地线来插值概率分布。每个概率分布有熵，沿着测地线熵值的变化规律和黎曼流形的曲率有着本质的关系。这一几何事实在网络领域已经被应用，但在视觉领域，似乎还没有相关工作。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;但在实际计算中，高维的最优传输映射，Wasserstein距离计算复杂。一个自然的想法是降维，将高维空间的概率分布投影到低维子空间，在低维空间上计算边际分布之间的变换。这有些象盲人摸象，每次得到局部信息，如果摸得充分，我们也可以恢复大象的整体信息。&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;回顾&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;在&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650723168&amp;amp;idx=3&amp;amp;sn=41fcf2fb0408c7b6a9b82d55d91c2b9c&amp;amp;chksm=871b171eb06c9e082c4083ff32748104a617e5cb1e6bd4d296b4db431358b8a41f40908ea8a5&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650723168&amp;amp;idx=3&amp;amp;sn=41fcf2fb0408c7b6a9b82d55d91c2b9c&amp;amp;chksm=871b171eb06c9e082c4083ff32748104a617e5cb1e6bd4d296b4db431358b8a41f40908ea8a5&amp;amp;scene=21#wechat_redirect" target="_blank"&gt;第一讲&lt;/a&gt;（看穿机器学习W-GAN的黑箱）中，我们给出了最优传输问题的凸几何解释：给定两个概率分布&lt;img src="http://img04.iwgc.cn/mpimg/8ca611df353e4cf31c990a209457126e593bd4f2"/&gt;，存在唯一的最优传输映射&lt;img src="http://img04.iwgc.cn/mpimg/446342b8670e34d5858d379ad4b094f10a6b8dea"/&gt;，将初始概率分布&lt;img src="http://img03.iwgc.cn/mpimg/7031586284b57d593bceb9d714ab281bd6fa2195"/&gt;变换成目标概率分布&lt;img src="http://img04.iwgc.cn/mpimg/f2fa01a0bd990574a517ef9a0d1561956d369bc9"/&gt;，&lt;img src="http://img04.iwgc.cn/mpimg/6362b39c375266a41ac533764bae0917b71ae563"/&gt;，同时极小化传输代价，&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/fdf1cb2368cbfad33b2de1874589b86c09ef0dc0"/&gt;,&lt;/p&gt;&lt;p&gt;这里&lt;img src="http://img03.iwgc.cn/mpimg/3f6ad912b9d8ee8a1f7258487d70572828b7dffe"/&gt;被称为是两个概率分布&lt;img src="http://img05.iwgc.cn/mpimg/8ca611df353e4cf31c990a209457126e593bd4f2"/&gt;之间的Wasserstein距离。同时，最优传输映射是某个凸函数&lt;img src="http://img04.iwgc.cn/mpimg/2034158271aefbb67356ad6f2d0509f34fb62369"/&gt;的梯度映射，&lt;img src="http://img04.iwgc.cn/mpimg/6cfbf997f986d042cc7048c9dc21439387cdaf85"/&gt;，这个函数满足蒙日-安培方程。我们的理论给出了一种几何变分方法来求解最优传输映射。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;在&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650723249&amp;amp;idx=5&amp;amp;sn=a0b0d42b3a55456ba680b756592aade9&amp;amp;chksm=871b17cfb06c9ed9905f24bbe84366002e01915a3a2991992114c15125249f2f5166d025f695&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650723249&amp;amp;idx=5&amp;amp;sn=a0b0d42b3a55456ba680b756592aade9&amp;amp;chksm=871b17cfb06c9ed9905f24bbe84366002e01915a3a2991992114c15125249f2f5166d025f695&amp;amp;scene=21#wechat_redirect" target="_blank"&gt;第二讲&lt;/a&gt;（看穿机器学习的黑箱（II））中，我们澄清了这样的观点：相比于学习一个映射，学习一个概率分布要容易很多。满足&lt;img src="http://img03.iwgc.cn/mpimg/6362b39c375266a41ac533764bae0917b71ae563"/&gt;的映射构成了一个无穷维的李群。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;但是，在视觉问题中，通常图像全空间的维数非常高，计算难度较高。因此，我们可以放弃理论上的最优性，寻找计算更加简单有效，同时又和最优传输距离等价的算法。下面，我们就讨论这些更为实用的算法及其背后的理论。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;直方图均衡化&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/d2d56486a79542bc441231e1b228ecade300acca"/&gt;&lt;br&gt;&lt;span&gt;图1. 直方图均衡化结果（histogram equalization）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;直方图均衡化是提高灰度图像对比度的常见算法。如图1所示，左侧输入图像的灰度分布在一个狭窄区域，朦胧昏暗；右侧是直方图均衡化的结果，清晰明亮，对比鲜明。我们设输入图像像素的灰度为一随机变量，其取值范围为单位区间&lt;/span&gt;&lt;img src="http://img03.iwgc.cn/mpimg/ec15b0300f1ea8fdcec1fbd7ff1230432c86d044"/&gt;&lt;span&gt;，其概率测度为&lt;/span&gt;&lt;img src="http://img05.iwgc.cn/mpimg/b6f0a0c634feef3c4823d4fc0edcb15e9b475946"/&gt;&lt;span&gt;，直方图均衡化算法的核心就是求灰度空间（单位区间）到自身的一个映射&lt;/span&gt;&lt;img src="http://img03.iwgc.cn/mpimg/e940702c4be1dd332bb90a1866bfaca028d21ce8"/&gt;&lt;span&gt;，这一映射将&lt;/span&gt;&lt;img src="http://img03.iwgc.cn/mpimg/b6f0a0c634feef3c4823d4fc0edcb15e9b475946"/&gt;&lt;span&gt;变换成均匀分布。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;实际上，传统的直方图均衡化就是一维的最优传送映射。假设我们有两个连续的概率分布&lt;img src="http://img03.iwgc.cn/mpimg/8ca611df353e4cf31c990a209457126e593bd4f2"/&gt;，其对应的累积分布函数（CDF）是&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/de348a01ed43fd00d082a52e7b6847df49e23a6d"/&gt;&lt;span&gt;,&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那么直方图均衡化映射就是传输映射：&lt;/span&gt;&lt;img src="http://img05.iwgc.cn/mpimg/e939050a9df93f0acc8306492280654315e3d146"/&gt;&lt;span&gt;。首先，我们可以证明这个映射满足两个条件：&lt;/span&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;li&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/6362b39c375266a41ac533764bae0917b71ae563"/&gt;&lt;span&gt;，&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;单调递增。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;span&gt;另一方面，我们应用最优传输理论：存在一个凸函数，其梯度映射给出最优传输映射。由函数&lt;/span&gt;&lt;img src="http://img05.iwgc.cn/mpimg/e3fdb1561a38907777403c264110e644c20e9d19"/&gt;&lt;span&gt;的凸性，我们得到最优传输映射也满足上面两条性质。更进一步，我们可以证明，在一维情形，满足上面两条的映射是唯一的。这意味着，&lt;span&gt;一维直方图均衡化映射就是最优传输映射&lt;/span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此，一维的最优传输映射非常容易计算。下面，我们应用一维最优传输映射来近似高维最优传输映射。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;迭代分布传输算法&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;有多种最优传输映射的近似算法。我们先讨论&lt;span&gt;迭代分布传输算法&lt;span&gt;（Iterative Distribution Transfer ）：给定单位向量&lt;img src="http://img03.iwgc.cn/mpimg/fa6f69777b2b699e38ec03eb5568b3f1c2dae34a"/&gt;，我们将整个空间投影到一维线性子空间&lt;img src="http://img05.iwgc.cn/mpimg/982e6367dff9320669161b479c18c762a43c0e8a"/&gt;上，投影映射为：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="http://img03.iwgc.cn/mpimg/2b8c43a8fb2b56b306199f8b35c07c796b6b227d"/&gt;，&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;投影诱导的概率分布（边际概率分布）记为&lt;img src="http://img03.iwgc.cn/mpimg/fc672a395be95680b6107e2b77b368533d63ae49"/&gt;。&lt;/span&gt;在算法第k步，假设当前源空间的概率分布为&lt;img src="http://img03.iwgc.cn/mpimg/11146d8a512ed950049a708d4a92bab72ab9c169"/&gt;；我们随机选取欧氏空间&lt;img src="http://img03.iwgc.cn/mpimg/76d35129fabc9645c7e3cd4a2d8271d1553152ab"/&gt;的一个标准正交基&lt;img src="http://img04.iwgc.cn/mpimg/5618be7f68aea3f4e8a7a643c086cf66da30ffe4"/&gt;；为每一个基底向量&lt;img src="http://img04.iwgc.cn/mpimg/0711ec5b8cfc8aa61a76603d7e7a890c81049c50"/&gt;构造一维的最优传输映射&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/66cf6d1b581122078cc575e605e052ab750b845f"/&gt;，&lt;/p&gt;&lt;p&gt;由此构造映射，在标架&lt;img src="http://img05.iwgc.cn/mpimg/54867b137003a90b759b7cdd1d16a3c5b3088f01"/&gt;下&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/5b707522f37f0e45f42366fe17fb6e5049ab26df"/&gt;，&lt;/p&gt;&lt;p&gt;其诱导的概率分布为&amp;nbsp;&lt;img src="http://img05.iwgc.cn/mpimg/8d001a45f2364b80ffc916efbcc3e074c7f2a323"/&gt;。不停地重复这一步骤，对于足够大的n，复合映射：&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/b78d3f03b5476731d68a880b6bea93bee8b72757"/&gt;,&lt;br&gt;&lt;/p&gt;&lt;p&gt;将初始概率分布&lt;img src="http://img03.iwgc.cn/mpimg/7031586284b57d593bceb9d714ab281bd6fa2195"/&gt;映成了目标概率分布&lt;img src="http://img05.iwgc.cn/mpimg/f2fa01a0bd990574a517ef9a0d1561956d369bc9"/&gt;。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/aef25add2f575d6b3775264ba384595c7b45ef4d"/&gt;&lt;/p&gt;&lt;p&gt;图2. 从拉东变换恢复的医学图像。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;这一论断的证明需要用到拉东变换（Radon Transform）：给定&lt;img src="http://img04.iwgc.cn/mpimg/6b096794bd1c6c051f336fdfd30195a1f9668cda"/&gt;中的一个概率分布&lt;img src="http://img03.iwgc.cn/mpimg/d5d8b0894f29c3116d9f267b5b09b6383d109ef7"/&gt;，&lt;img src="http://img03.iwgc.cn/mpimg/d5d8b0894f29c3116d9f267b5b09b6383d109ef7"/&gt;的Radon transform&amp;nbsp;&lt;img src="http://img04.iwgc.cn/mpimg/8b4ccc2f5dd547ef39b8f3de8c2a510b003bbb05"/&gt;是一族一维的概率测度，&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/dfaa19c9d2685de459ee617c23b8d6b243d5a276"/&gt;，&lt;/p&gt;&lt;p&gt;换句话说，给定一个单位向量，它生成一条直线，我们将全空间向这条直线投影，得到边际概率分布。拉东变换的基本定理断言：如果两个概率测度的拉东变换相等，则两个概率测度相等。如图2所示，这一定理是医学图像上CT断层扫描技术的基本原理。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;迭代算法如果最后达到一个平衡状态，则在任意一条过原点的直线上，&lt;img src="http://img03.iwgc.cn/mpimg/54ff51041ea207e924652f4c9e618649dbe565c5"/&gt;的边际概率分布等于&lt;img src="http://img05.iwgc.cn/mpimg/d5d8b0894f29c3116d9f267b5b09b6383d109ef7"/&gt;的边际概率分布，因此由拉东变换原理&lt;img src="http://img04.iwgc.cn/mpimg/54ff51041ea207e924652f4c9e618649dbe565c5"/&gt;收敛于&lt;img src="http://img05.iwgc.cn/mpimg/d5d8b0894f29c3116d9f267b5b09b6383d109ef7"/&gt;，&lt;img src="http://img05.iwgc.cn/mpimg/c48f737594a8d8148f15785d9dee4094d6f39d63"/&gt;。这样，我们将高维的传输映射转换成一维传输映射的复合，降低了计算难度。&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;投影Wasserstein距离梯度下降法&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;另外一种迭代算法想法比较类似。给定两个&lt;img src="http://img03.iwgc.cn/mpimg/6b096794bd1c6c051f336fdfd30195a1f9668cda"/&gt;上定义的概率测度&lt;img src="http://img05.iwgc.cn/mpimg/d5d8b0894f29c3116d9f267b5b09b6383d109ef7"/&gt;和&lt;img src="http://img05.iwgc.cn/mpimg/e7a7b2f1a6598ade5934559d32908b6fc547808c"/&gt;，对于任意一个单位向量&lt;img src="http://img04.iwgc.cn/mpimg/684261aa71ebf97946c6abfba921696361ce99e4"/&gt;，我们考虑投影映射&lt;img src="http://img04.iwgc.cn/mpimg/8e2097948bcbe2d638f77f73e77211af221973aa"/&gt;。投影映射诱导两个直线上的概率分布&lt;img src="http://img04.iwgc.cn/mpimg/fd6ff791c76903a5d33bc118f0923d255a30e56d"/&gt;和&lt;img src="http://img04.iwgc.cn/mpimg/a96e9e9e13899e7c22f9d405d716de0d8d7330b3"/&gt;，它们之间的最优传输映射记为&lt;img src="http://img04.iwgc.cn/mpimg/3334ef49cd010079295e9ce9ec82b8a9fbda5b07"/&gt;。由此，每个点都沿着&lt;img src="http://img04.iwgc.cn/mpimg/c4fd8664b9651991ed2e90b091c6d4e721f469f6"/&gt;平移一个向量：&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/8da24be78ade0060773e212ddeeb7a36cd8aceb8"/&gt;。&lt;/p&gt;&lt;p&gt;我们考察所有的单位向量，然后取平均&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/7342a3600b5a58e960294de05cc93c298d3b451b"/&gt;，&lt;/p&gt;&lt;p&gt;去一个步长参数&lt;img src="http://img03.iwgc.cn/mpimg/99e5cd1618c4c8a9b80d8967af063bfcaf11c8b6"/&gt;，每个点&lt;img src="http://img03.iwgc.cn/mpimg/1b6688e7eaa77ee72ec5eb105364833446781611"/&gt;平移到&lt;img src="http://img04.iwgc.cn/mpimg/ccdc25bf738196f333feea5e03f95e4c91347ac5"/&gt;，相应的概率分布变为&lt;img src="http://img04.iwgc.cn/mpimg/542c757674eee47afe8188a16924040ef7373c08"/&gt;。重复以上步骤，我们可以证明所得的概率分布沿着&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="http://img04.iwgc.cn/mpimg/1c42161fc297a21ffdf6b9cf28afec47587f8ca7"/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;距离收敛。这里&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="http://img04.iwgc.cn/mpimg/1c42161fc297a21ffdf6b9cf28afec47587f8ca7"/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;距离是所谓的&lt;span&gt;投影Wasserstein距离&lt;/span&gt;，其具体定义如下：&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/18547b1be059dc9109252deb83a839eb2f709c41"/&gt;，&lt;/p&gt;&lt;p&gt;这里&lt;img src="http://img04.iwgc.cn/mpimg/c79880e0caee14ae1a0f2b1a416ccae126c1c7ff"/&gt;是Wasserstein距离。投影Wasserstein距离和Wasserstein距离诱导Wasserstein空间同样的拓扑，但是计算起来相对容易很多。&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/8f80c48bb01e8ef0e00a3a4413a9e45d50c5de43"/&gt;&lt;/p&gt;&lt;p&gt;图3. 用于愚弄深度神经网的图像（A. Nguyen, J. Yosinski and J. Clune, Deep Neural Networks are Easily Fooled: High Confidence Predictions for Unrecognizable Images, CVPR2015.）&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;局限性和脆弱性&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;拉东变换将联合概率分布转换成向所有一维子空间投影所得的边际概率分布，从而实现了降维，简化了计算。但是，如果有一些子空间的边际分布缺失，我们无法精确恢复原来的联合分布。在视觉问题中，每个线性子空间被视为一个特征，向子空间投影，等价于特征提取。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;深度神经网在解决视觉分类问题中表现出色，但是也非常容易被愚弄。如图3所示，人类可以轻易看出这些是非自然图像，在现实生活中不具备任何意义。但是深度神经网络非常自信地将它们归结为训练过的类别。如果，我们以欣赏现代抽象艺术的心态来研究这些图像，我们能够领会到深度神经网络分类结果的内在合理性：这些图像的确具有它们所对应类别的内在&amp;ldquo;神韵&amp;rdquo;。从纹理层次而言，它们和对应类别的纹理非常&amp;ldquo;神似&amp;rdquo;；从语义层面而言，这些图像则是无意义的和荒谬的。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;我们可以给出一种解释：那就是投影子空间选得不够，因此即便是在这些子空间上边际概率分布相似，但是联合概率分布依然相差很大。深度神经网所得到的训练集是自然图像，图3这些图像都在自然图像空间之外，但是投影在所选择的子空间后，自然图像和非自然图像无法进行分别。由此，引发了深度神经网络脆弱性。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/5885563f9dac73ee15f0ca70ec39d31afd5c96ff"/&gt;&lt;/p&gt;&lt;p&gt;图4. 视网膜到大脑皮层的映射是保角变换。（A. Fazl, S. Grossberg and E. Mingolla, Visual Search， Eye Movements and Object Recognition)&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;讨论&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;人类的低级视觉在很大程度上依赖于统计特性，因此可以归结为对概率分布的处理和演算。人脑是否真的在计算最优传输映射、计算Wasserstein距离？在历史上，人类经常首先发现某些数学原理，然后又发现这些原理在生物器官上早已应用。例如，人类首先发现了傅里叶分解原理，然后发现人类耳蜗神经结构就是在对声音信号进行傅里叶分解；又如，人类首先发现了保角变换（共形变换），后来发现从视网膜到第一级的视觉中枢就是保角变换，如图4所示。这项工作曾经获得过诺贝尔奖。因此，如果若干年后，人们证实大脑的确在计算概率分布之间的距离，老顾也不会觉得意外。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;因此，我们相信在一些视觉应用中，深度神经网络隐含地构建概率模型，我们可以直接用概率的工具，例如最优传输理论及其各种降维近似，直接取代神经网络，从而使得黑箱透明。&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Fri, 24 Feb 2017 12:16:21 +0800</pubDate>
    </item>
    <item>
      <title>学界 | 剑桥与微软提交ICLR 2017论文提出DeepCoder：组合其它程序代码生成新程序</title>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650723632&amp;idx=5&amp;sn=2654d4e512ff3c23e1bd17b2e9e562d5&amp;chksm=871b114eb06c98581aa12a202b8a97e1ba504854d0fe1632fc19200a271aeaddd0f0b6a7f770&amp;scene=0#rd</link>
      <description>
&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自New Scentist&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;作者：Matt Reynolds&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：曹瑞、蒋思源、李泽南&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器学习系统第一次获得了自我编码的能力，剑桥与微软联合提交ICLR 2017的论文提出DeepCoder，可以组合其它程序代码生成新程序。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「走开吧，人类，我自己能搞定了。」&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是第一次，有机器学习系统获得了自我编码的能力。这个机器学习系统叫做 DeepCoder，是由微软和剑桥大学的研究人员所创造的，这一系统可以解决编程竞赛设置的基本挑战。这种方法让人们编写简单程序容易了许多，甚至可以让不会编写代码的人完成任务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「突然之间，人们的工作效率就提高了很多，」麻省理工学院的 Armando Solar-Lezama 说道。「人造系统此前是无法做到这一点的。」Marc Brockschmidt 是英国剑桥微软研究院 Deepcoder 的开发者之一，它认为这种方法最终可以让那些不懂编码的人只要简单描述一个建立程序的想法，就能够让系统来构建。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;DeepCoder 利用了一种叫做「程序合成」（program synthesis）的技术：它创造新程序的方法就是将从现有软件中提取出来的一行一行的代码组合起来&amp;mdash;&amp;mdash;就像是程序员一样。列出每一个代码片段的输入和输出，DeepCoder 就会知道要总体上完成预期结果需要哪些代码。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;利用这种方法，那些不懂编码的人只要能够简单描述一个建立程序的想法，就能够让系统来构建。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这样放任人工智能的一个优势在于，比人类程序员相比，它能够更全面、更广泛地进行搜索，这样组合源代码的方式可能是人类都没有想到的。此外，DeepCoder 利用机器学习来搜寻源代码数据库，并根据它们对这些源代码可能存在的可用性的判断挑出一些代码片段。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些特性使得该系统比之前的其他系统要快得多。DeepCoder 在一秒钟的时间内就可以建立可用的程序。以前的系统在将可用的代码组合起来之前，要花费好几分钟来追踪不同代码的组合。因为 DeepCoder 知道哪种源代码的组合可用，哪些不可用，在每次解决新问题的时候它都能随之改进。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;构建 IPS 系统需要解决两个问题。首先是搜索问题：我们需要搜索一组可能的程序而找到一致性程序（consistent programs）。我们需要定义数据集（如程序空间）和搜索进程。其次是排序问题：如果有多个程序和输入-输出样本具有一致性，哪一个程序是需要返回的结果？这两个问题都取决于问题构想（problem formulation）的具体细节。因此，构想程序合成方法（program synthesis approach）的第一个要点就是选择特定域语言（Domain Specific Language）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这一技术可以应用到很多不同的地方。2015 年，麻省理工学院的研究人员建立了一个自动修复软件漏洞的程序，可以将程序中错误的代码行用其他程序中可以使用的代码行替代。&lt;/span&gt;&lt;span&gt;Brockschmidt 说，未来的版本将会让建立常规程序变得非常简单，例如它可以从网站上搜寻信息，或者自动将 Facebook 上的照片进行分类，而人类程序员连动动手指都不需要。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Solar-Lezama 表示：「这种科技所蕴含的自动化的潜力或许真的意味着编写代码耗费的经历将大幅减少。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是他不认为这些系统会让程序员失业。我们可以通过程序合成（program synthesis）自动编译一些最繁杂的代码，而程序员可以花更多的时间来做一些更复杂的工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前，DeepCoder 仅仅只能解决五行代码内的编程难&lt;/span&gt;&lt;span&gt;题。但是在优良的编程语言中，少量几行代码可以完成相当复杂的程序。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Solar-Lezama 说：「一次性生成大段代码是非常困难的，甚至是不切实际的，但是那些真正大量的代码都是由许多小块代码所拼接的。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，经过不断的训练，系统会变得更加聪明，如果 DeepCoder 能找出哪些程序块在一起能更好地运行，以及什么时候使用一个代码块替换另一个，那么将大大减轻程序员的工作，这也将会是深度学习系统一个非常好的应用。DeepCoder 是一个会学习的系统，随着构建越来越多的程序块，它将越来越强大。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;论文：DEEPCODER: LEARNING TO WRITE PROGRAMS&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/c20ea8cb883c7a9ac28135ef8bafbd1665c0ec5d"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：&lt;/span&gt;&lt;span&gt;我们开发了一种使用输入-输出样本的深度学习来解决编程竞赛风格（programming competition-style）问题。该方法通过训练神经网络来预测由输入到输出生成的程序属性。我们使用神经网络的预测来增强在编程中进行搜寻的技术，其包括了枚举搜寻（enumerative search）和基于 SMT 的解算器（SMT-based solver）。实证表明，我们的方法可以在强非增强型基线（strong non-augmented baselines）和递归神经网络（Recurrent Neural Network）方法上产生一个数量级的加速，并且我们能够解决和在编程竞赛中比最简单问题更复杂一些的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文链接：https://www.newscientist.com/article/mg23331144-500-ai-learns-to-write-its-own-code-by-stealing-from-other-programs/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Fri, 24 Feb 2017 12:16:21 +0800</pubDate>
    </item>
    <item>
      <title>成本14,000元，如何自己动手搭建深度学习服务器？</title>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650723604&amp;idx=1&amp;sn=70c6bf533b17b2fc842f5926ec9d35c4&amp;chksm=871b116ab06c987c53e92273e3d18398ac17c1744c5b972b497dfcf47cea8fa81fadf2bf18b8&amp;scene=0#rd</link>
      <description>
&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自medium&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：曹瑞、李泽南&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在完成 Jeremy Howard 非常出色的深度学习第一部分课程之后，我查看了一下我的亚马逊网络服务（AWS）账单，发现我每个月运行 GPU 都要花费差不多 200 美元。以这样的代价来完成网络课程看起来代价有点大，而且我已开始着手研究一些课程以外的数据集，并迫切地想得出结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过与大家进行交流，阅读了大量博客文章之后，我最终决定开始配置自己的深度学习服务器。当今科技和硬件的发展是如此的迅猛，我担心我曾阅读过的文章很快就会过时，但我希望自己的以下总结能够为大家带来帮助。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;配置服务器的 6 大步骤：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 选择组件&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 组装&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 安装操作系统&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4. 安装驱动程序&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;5. 安装库&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;6. 设置远程访问&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1. 选择部件&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我阅读了大量博客，最终形成了现在应该选择哪种配置的概念。因为硬件更新换代太快，在下个世代到来时到底该买哪些型号的部件，这一问题还是得留给你们研究。但是一般而言，你需要选购以下部件：主板、CPU、内存（随机存取存储器，RAM）、硬盘驱动器（固态硬盘，SSD）、显卡（GPU）、CPU 风扇、电源和机箱。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/1f92067a900a7b0e6e83faa572db11a7ec9e6788"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P.S. 我强烈建议你在购买之前在 pcpartpicker.com 上创建一个清单。这个网站的特色在于它有一个「兼容性检查」的功能，它会告诉你自己选择的部件是否互相兼容。我的列表在这里。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;部件清单（原文为美国市场价，机器之心将其替换为 2 月 23 日，京东自营/淘宝价）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;CPU&amp;mdash;英特尔 i7 7700k（Kabylake）4.2GHz 四核 2799 元&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;内存&amp;mdash;海盗船 复仇者 LPX 32GB (2 x 16) DDR4&amp;ndash;3200 2499 元&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;固态硬盘&amp;mdash;三星 850 EVO sata3 500G 1299 元&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;GPU&amp;mdash;索泰 GeForce GTX 1080 8GB 4999 元&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;主板&amp;mdash;微星 Z270-A PRO ATX LGA1151 1299 元&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;CPU 风扇&amp;mdash;酷冷至尊 Hyper 212 EVO 82.9 CFM 128 元&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;供电电源&amp;mdash;EVGA SuperNOVA G2 750W ATX 879 元&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机箱&amp;mdash;NZXT S340 (White) ATX Mid Tower Case 369 元&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;总价：14,271 元&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我决定从单块显卡开始自己的装机之路，但我选择的微星 (MSI) 主板有多个 PCIe 通道，这意味着如果有需要，我可以在未来添加更多的 GPU。一般而言，我都会选择那些用户评论数最多的硬件，即使这些评论褒贬不一。但评论意味着部件受欢迎的程度，用户数量越大，就越有可能出现用户自行创建的使用指南和建议。这会为你接下来的两个步骤免去了很大的痛苦。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一些实用的文章：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Build Personal Deep Learning Rig (http://guanghan.info/blog/en/my-works/building-our-personal-deep-learning-rig-gtx-1080-ubuntu-16-04-cuda-8-0rc-cudnn-7-tensorflowmxnetcaffedarknet/)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Optimizing a Starter CUDA Build (https://www.servethehome.com/optimizing-a-starter-cuda-machine-learning-ai-deep-learning-build/)&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Building a Deep Learning Dream Machine (http://graphific.github.io/posts/building-a-deep-learning-dream-machine/)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719346&amp;amp;idx=1&amp;amp;sn=64b5198e70558eb8fdac439cdf8db81b&amp;amp;chksm=871b000cb06c891ac7ba594b4ae9bae68f6f533040fb1f9aef5c70613c77f0cf849807216758&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719346&amp;amp;idx=1&amp;amp;sn=64b5198e70558eb8fdac439cdf8db81b&amp;amp;chksm=871b000cb06c891ac7ba594b4ae9bae68f6f533040fb1f9aef5c70613c77f0cf849807216758&amp;amp;scene=21#wechat_redirect" target="_blank"&gt;&lt;span&gt;Deep Learning Hardware Guide &lt;/span&gt;&lt;/a&gt;&lt;span&gt;(http://timdettmers.com/2015/03/09/deep-learning-hardware-guide/)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2. 组装&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这一部分非常有趣。几乎所有的部件，我都可以在网上找到相关的指导性视频，但是有一些部件我必须要根据相似型号的安装视频才可以。微星主板、酷冷至尊风扇和 NZXT 机箱的指导手册非常不错，但是我还是需要再找一些其他的材料。下面是我找到的一些有用的视频：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;iframe allowfullscreen="" class="video_iframe" data-vidtype="1" frameborder="0" height="417" src="https://v.qq.com/iframe/preview.html?vid=m0377hib5bz&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0" width="556"&gt;&lt;/iframe&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;iframe allowfullscreen="" class="video_iframe" data-vidtype="1" frameborder="0" height="417" src="https://v.qq.com/iframe/preview.html?vid=f0377tz8scp&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0" width="556"&gt;&lt;/iframe&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;iframe allowfullscreen="" class="video_iframe" data-vidtype="1" frameborder="0" height="417" src="https://v.qq.com/iframe/preview.html?vid=f0377e0ok4x&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0" width="556"&gt;&lt;/iframe&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;经验总结&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;买一把好用的螺丝刀&amp;mdash;&amp;mdash;我的螺丝刀非常的差劲，所以很快就让我停滞不前了。买一个杆长一点的螺丝刀，这样你就可以够得到很紧的地方，也是为自己省力。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;不要吝惜自己的力量&amp;mdash;&amp;mdash;免责声明：要是把什么东西弄坏了，不要怪我。但是至少在两种情况下（CPU 和内存），我因为在安装部件时候用劲太小浪费了好多时间。我担心太过用力，所以如果部件不能够轻松放进去，我就放弃了。至于内存，我几乎在亚马逊上购买了一整套新的芯片。这些情况下，解决的办法就是用力压。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;理解你的 BIOS&amp;mdash;&amp;mdash;BIOS 是一个预先安装在主板上的软件，是你的机器启动时加载的第一个软件。它基本上是你配置硬件和安装操作系统的一个控制面板。学会如何在 BIOS 上找到「引导盘」（U 盘或是包含操作系统的固态硬盘），怎样选择使用哪一张显卡都是非常重要的。遗憾的是微星的用户手册在这些问题上表达得不甚清楚，但是这个视频（https://www.youtube.com/watch?v=C6mQqlmL5Sc）会让你更好地进行理解。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;你的显示器没有坏&amp;mdash;&amp;mdash;弄清怎样让显示屏在我的新机器上工作花了我不少时间。我之前曾听说在你第一次启动的时候，你需要将你的 HDMI 线插到主板的某个位置，因为一开始显卡驱动还没有安装。我照做了，但是当我最后启动的时候，显示器上什么都没有。接着我尝试把线插到显卡上，也没有用。最后我尝试将显卡拔出来，把线连上主板并重新启动。终于能看到东西了！这意味着，微星的主板如果不能在 PCIe 通道找到其他的外置显卡，就会默认使用核显。因为在我第一次启动的时候，就安装了显卡，主板就选择使用我的的新新卡。显示器上看不到任何东西是因为我没有安装英伟达的驱动。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，大功告成了！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/1702d7fa9c681b253dc3bf2a99f6b5135c4a55b7"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/5f94f61049f9b317ad4e85e540dcb57060da63be"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3. 安装操作系统&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在显示器可以工作之后，你会看到一个这样的界面。这就是你的 BIOS（注：不同品牌的主板，BIOS 界面略有不同）。我需要更改两处配置，以保证所有的东西都能正常运行：更改启动优先级，替换默认的显卡。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/8e0aa76f64af620ebc193f6636523d2a013f94dd"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;在 MSI 主板上预置的 BIOS&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我计划主要将我的机器用于编程和机器学习，所以我决定要安装 Ubuntu 操作系统。我还希望能够通过我的 Mac 对它进行远程操作，所以我可能不需要 Windows，但是你可以安装双系统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;制作安装 Ubuntu 的 U 盘&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我依照针对 Mac 的说明（https://www.ubuntu.com/download/desktop/create-a-usb-stick-on-macos），下载了一个叫做 UNetBootin (https://unetbootin.github.io/) 的客户端，它可以为你把所有的事情都处理好。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;启动 UBUNTU&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;若是一切正常，我应该能够插入我的 U 盘，重启，回答问题，安装一个完全可运行版本的 Ubuntu，准备好进行下一步。但是，我得到的确实这样的错误信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/bc2dee79ab7c505ed6e6f022514c6b28e68e9ebc"/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;我按了好几次退出键，之后按了删除键，之后 F1、 F10、 F12、 #%^ 、 $\&amp;amp;]&amp;amp;&amp;amp;&amp;amp;#^，但都没有用。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;问题在于微星主板已经选择了默认的「启动优先级」。再次进入 BIOS（在开机之后立刻按 F11），我看到 BIOS 的配置是首先启动硬件驱动（三星固态硬盘），这里面是空的，但是也可能会有一大堆选项。解决办法就是把 USB 选项拉到优先级列表的顶部，然后重启。最后，我看到了这十分友好的 Ubuntu 安装屏幕！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/fa233e513ad9747697b09260cf2bcbd83c603e30"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在安装了 Ubuntu 并且重启之后，我很失望地发现我卡在了 Ubuntu 的加载屏幕上，它就停在了那里，最终超时。这又是怎么了呢？！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;原来问题在于微星主板内置的显卡（我的 GTX 1080 还在我的咖啡桌上）。它与 Ubuntu 的图形用户界面（GUI）不兼容！这真是经典的鸡和蛋的问题。没有 Ubuntu，我不能下载使用显卡所需的驱动，但是没有显卡，我不能安装 Ubuntu！进入 GRUB (https://help.ubuntu.com/community/Grub2)。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/252eaa3f66083bb2467cc7e5b7d60abff89bacad"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Ubuntu 启动菜单。你可以在开机后按压左 Shift 键进入这一菜单。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，我找到了两篇非常好的文章（http://askubuntu.com/questions/162075/my-computer-boots-to-a-black-screen-what-options-do-i-have-to-fix-it，http://askubuntu.com/questions/716957/what-do-the-nomodeset-quiet-and-splash-kernel-parameters-mean）帮我解决了这个问题。解决办法就是在启动命令中添加一个 *nomodeset*参数。这帮我安装了一个普通版本的 Ubuntu GUI，得以让我继续进行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4. 安装驱动程序&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;英伟达的驱动是出了名地难运行，这一个也不例外。在其他用户的引导下，我去英伟达的网站下载了 GeForce 驱动程序，接着利用 Ubuntu GUI 对它进行安装。这个错误给我带来了很大的痛苦。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;无法检测到可兼容的英伟达显卡&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这又是一个鸡和蛋的问题。我没有再重新接上 GTX 1080 是因为没有驱动程序它无法工作。如果我重新接上，MSI 主板就会开始再次使用它，我就又回到了我开始的地方。解决办法是重新进入 BIOS，改变显卡优先级。我更新了设置，将优先级赋予给内置显卡，而不是选择新的显卡。这样我又可以重新接入 GTX 1080，并正常进入 Ubuntu。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;你好像在运行 X 服务器&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我通过使用这里的说明 (http://askubuntu.com/questions/149206/how-to-install-nvidia-run) 解决了这个问题，但是在最初，我都无法通过第一步：「点击 CTRL+ALT+F1，使用你的凭据登录。」我这样做了之后，屏幕又变成了空白，和显示器的连接就断开了。解决方法是启动 Ubuntu，进入文本模式，完成命令行的步骤。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;更好的办法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最终让我感到欣慰的是所有的东西（驱动程序、CUDA、深度学习库等）都可以运行了。但是没过多久，因为一些配置文件我又把事情搞得一团糟。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 Ask Ubuntu 网站上浏览了几个小时之后，我注意到英伟达驱动程序上预先安装了新的 CUDA 8.0 工具箱，让你可以同时安装 CUDA 和驱动程序。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我清除了现有的英伟达库，运行了下面的代码，然后一切都便正常运行了。你可以在这里 (http://docs.nvidia.com/cuda/cuda-quick-start-guide/index.html#ubuntu-x86_64) 看到完整的说明。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;code class="markup--code markup--pre-code" style="font-family: inherit; font-size: 1em;"&gt;&lt;span&gt;wget http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/cuda-repo-ubuntu1604_8.0.44-1_amd64.deb&lt;br&gt;sudo dpkg -i cuda-repo-ubuntu1604_8.0.44-1_amd64.deb&lt;br&gt;sudo apt-get update&lt;br&gt;sudo apt-get install cuda&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然后将下面的代码添加多你的~/.bash_文件中：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;export PATH=/usr/local/cuda-8.0/bin${PATH:+:${PATH}}&lt;br&gt;export LD_LIBRARY_PATH=/usr/local/cuda-8.0/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}&lt;br&gt;export LIBRARY_PATH=/usr/local/cuda-8.0/lib64${LIBRARY_PATH:+:${LIBRARY_PATH}}&lt;/span&gt;&lt;/pre&gt;&lt;p&gt;&lt;br&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;5. 安装深度学习库&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有很多的好文章都对必要的深度学习库和如何安装进行了描述。关键点在于你不能够盲目地跟随这些说明，尤其是关于如何安装的部分。因为这些说明经常更新，你可以在这些库的网站上找到更好的示例。下面是我安装的一些工具：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;CUDA&amp;mdash;利用 GPU 的并行计算平台&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;cuDNN&amp;mdash;加速深度学习的英伟达库&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Anaconda&amp;mdash;Python 数据科学 (numpy, scikit, jupyter..)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;OpenBLAS&amp;mdash;快速的线性代数方法&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Tensorflow&amp;mdash;谷歌的机器学习框架&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Theano&amp;mdash;深度学习框架&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Keras&amp;mdash;另一种框架，可以简化 Tensorflow 或 Theano 的工作&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这之后，我进行了一些测验以保证一切正常运行，并开始运行 Jupyter 笔记本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;6. 设置远程访问&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;再是一个可选步骤。但是如果你希望通过笔记本电脑远程操作，下面是一些方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Teamviewer 是一款屏幕分享软件。如果你安装了这一软件，并在两个机器上运行，你便可以通过你的笔记本电脑控制 Ubuntu 主机，反之亦可。这让工作变得更加方便，但是在进行屏幕分享时做所有的事情都会有一点延迟且不灵活。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/9758d76705547795e4515177a570e9b5c0c3c059"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;SSH 和端口转发&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我想要远程通过 SSH 访问我的新机器，并且和它进行互动，就好像它是我在笔记本上多了个 Tab 键一样。为了做到这一点，我在 Ubuntu 上安装了 OpenSSH。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;sudo apt-get install openssh-server&lt;br&gt;sudo service ssh status&lt;/span&gt;&lt;/pre&gt;&lt;p&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;之后，我将 Comcast 路由器配置到将外部通信量直接转发到我的主机。我根据 Comcast 的说明，出乎意料的是这居然管用！我通过在 www.canyouseeme.org 查看端口 22，确认了这一点。部分过程可能需要你的公共 IP 地址，你可以通过运行下面的代码找到：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;dig +short myip.opendns.com @resolver1.opendns.com&lt;/span&gt;&lt;/pre&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;远程笔记本&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外一个很酷的技巧就是，如果你喜欢 Jupyter，你可以在你的深度学习主机上运行你的笔记本，但是在你笔记本电脑上进行浏览和编辑。这里有关于这一技巧的一些教程 (http://www.justinkiggins.com/blog/zero-configuration-remote-jupyter-server/)，所以我在下面只列出了命令：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;$laptop: ssh -l bfortuner@DEEPLEARNINGIP&lt;br&gt;$server: jupyter notebook --no-browser --port=8888&lt;br&gt;$laptop: ssh -NL 8888:localhost:8888 bfortuner@DEEPLEARNINGIP&lt;/span&gt;&lt;/pre&gt;&lt;p&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在你就可以在笔记本电脑的浏览器上访问 http://localhost:8888，开始编辑你在深度学习机器上的笔记本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;原文地址：https://medium.com/@bfortuner/building-your-own-deep-learning-box-47b918aea1eb#.o5pbw9xao&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Thu, 23 Feb 2017 12:29:28 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 谷歌发布tf.Transform：一个TensorFlow数据预处理库</title>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650723604&amp;idx=2&amp;sn=a8501842827cab6d6c4027216c7993a9&amp;chksm=871b116ab06c987c25400fab5bf76ee7142ee1760b35b2b723f46ee4e5a86b0584d91a07a3cc&amp;scene=0#rd</link>
      <description>
&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自Google Research Blog&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当我们将机器学习应用于真实世界数据集时，我们需要花费大量工作来将数据处理成适合标准机器学习模型（比如神经网络）的格式。这种预处理（preprocessing）有许多不同的形式&amp;mdash;&amp;mdash;从格式之间的转换，到文本的标记化（tokenizing）和提干（stemming）以及形成词汇表，再到执行各种数值运算（例如归一化）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今天，我们宣布发布 tf.Transform，这是一个 TensorFlow 库，可以让用户定义预处理流程（preprocessing pipelines）和使用大规模数据处理框架运行这些流程，同时还能让用户以一种将这些流程作为 TensorFlow graph 一部分的方式运行从而利用这些流程。用户可以通过将模块化的 Python 函数组合到一起来定义一个流程，然后 tf.Transform 会使用 Apache Beam 来执行它。Apache Beam 是一个用于大规模数据的、高效的、分布式的数据处理框架。通过 Apache Beam 计划好的对其它框架的运行支持，Apache Beam 流程还能运行在 Google Cloud Dataflow 上。通过 tf.Transform 导出的 TensorFlow graph 可以让预处理步骤在训练好的模型被用于预测时被复制，比如当使用 TensorFlow Serving 将模型投入应用时。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相关链接：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;tf.Transform：https://github.com/tensorflow/transform&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Apache Beam：https://beam.apache.org/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Google Cloud Dataflow：https://cloud.google.com/dataflow &lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;TensorFlow Serving：https://tensorflow.github.io/serving/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在生产中运行机器学习模型时会常常遇到一个问题：「训练-应用偏差（training-serving skew）」，参阅机器之心文章《&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722526&amp;amp;idx=5&amp;amp;sn=4fd5eddcd49ffdc64f6b96dbe3597d25&amp;amp;chksm=871b14a0b06c9db68a9422f4c7de72acf7c9ef90cc9370de9e1defd36c2a74dcab8a69ef8c83&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722526&amp;amp;idx=5&amp;amp;sn=4fd5eddcd49ffdc64f6b96dbe3597d25&amp;amp;chksm=871b14a0b06c9db68a9422f4c7de72acf7c9ef90cc9370de9e1defd36c2a74dcab8a69ef8c83&amp;amp;scene=21#wechat_redirect" target="_blank"&gt;谷歌机器学习应用的四十三条经验法则&lt;/a&gt;》。「训练-应用偏差」是指当投入产品应用阶段的模型所收到的数据在某些方面不同于该模型在训练过程中所使用的数据时，预测质量出现下降的情况。tf.Transform 通过保证应用阶段的变换和训练阶段所执行的变换完全相同，能够确保在预处理过程中不会出现偏差，这不同于训练阶段和应用阶段的预处理在两个不同的环境中分别实现的情况（比如，分别在 Apache Beam 和 TensorFlow 环境中）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除了方便预处理之外，tf.Transform 允许用户为他们的数据集计算汇总的统计。在每一个机器学习项目中，理解数据都是非常重要的，因为如果对基本数据做出了错误的假设，那么就会产生一些微妙的错误。为了使这种汇总统计的计算简单有效，tf.Transform 允许用户检查他们关于原始数据和预处理后的数据的假设。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/3db4601ebedec7e0b9532f639c4607b933851ace"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;tf.Transform 允许用户定义预处理流程。用户能够在 TensorFlow 训练中具体化要预处理的数据，也能导出一个 tf.Transform graph，其能将转换过程编码为 TensorFlow graph。然后这一转换图（transformation graph）可被整合进用于推断的模型图。&lt;/span&gt;&lt;/em&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们非常高兴能把这个最新版本添加到 TensorFlow 生态系统中，我们希望用户发现它对预处理、理解数据有所帮助。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;致谢&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们感谢以下 tf.Transform 成员为该项目所作出的贡献： Clemens Mewald, Robert Bradshaw, Rajiv Bharadwaja, Elmer Garduno, Afshin Rostamizadeh, Neoklis Polyzotis, Abhi Rao, Joe Toth, Neda Mirian, Dinesh Kulkarni, Robbie Haertel, Cyril Bortolato and Slaven Bilac。也感谢 TensorFlow、TensorFlow Serving 和 Cloud Dataflow 团队的支持。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;原文地址：https://research.googleblog.com/2017/02/preprocessing-for-machine-learning-with.html&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Thu, 23 Feb 2017 12:29:28 +0800</pubDate>
    </item>
    <item>
      <title>前沿 | 脑机接口新突破：实现迄今为止最快的打字速度</title>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650723604&amp;idx=3&amp;sn=7aef52404a8da8d5a4bab7431398a759&amp;chksm=871b116ab06c987c0e57f1e3aaef17d5846bdacb436b26c7c46e2135909f0897a20582b80b5c&amp;scene=0#rd</link>
      <description>
&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自ScientificAmerican&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;strong&gt;作者：Simon Makin&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;编译：侯韵楚 ，微胖&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;一个新型接口系统&amp;mdash;&amp;mdash;使三位瘫痪病人的打字速度比之前快出 4 倍。&lt;em style="color: rgb(136, 136, 136); line-height: 25.6px; text-align: justify; white-space: normal;"&gt;&lt;span&gt;&lt;em style="max-width: 100%; font-size: 16px; line-height: 28px; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;span&gt;读者可点击阅读原文下载此论文。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/db261f606792b38b46f4355e23947e19f245edb8"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;斯坦福大学的 BrainGate 临床试验中，一位被试使用脑机接口，通过她的思想控制计算机光标来打字。来源：Courtesy Stanford University&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;十年前的一个雨天，Dennis Degray 出门扔垃圾时不慎滑倒，从此他的生活轨迹迥然改变。他撞到了下巴，造成了严重的脊髓损伤，以至于脖子以下全部瘫痪。如今研发出了一个系统，意在使瘫痪病人仅用大脑便可以打字；而他便是这个系统调查实验的明星参与者。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了应用脑机接口（Brain-Computer Interface，BCI）使残疾人得到康复，研究人员努力了几十年，但能够被广泛应用的设备却很少，根据具体应用情况，会存在一些障碍。然而，对于打字而言，一个很大的障碍是不是足够快，这样，该技术才有采用价值，而这往往要动手术。eLife 在周二发表了一项研究成果，揭示了该系统的成效：三位被试&amp;mdash;&amp;mdash;Degray，以及两位患肌萎缩侧索硬化症的病人（ALS，或称葛雷克氏症，一种导致进行性瘫痪的神经变性疾病）使用 BCI 后，能以最快速度打字，该技术的具体应用变得切实可行。斯坦福大学的神经外科医生及共同作者 Jamie Henderson 说：「我们已经成功了一半，例如，我可以在手机上打字」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/de0edd50e882e5c2f8025f9c4efc2d9ee852f385"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 1：实验配置 (a) 和在自由书写的问答环节的键入速度 (b)&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;研究人员用三个任务来测评其性能。为了尽可能在最自然的情境中证实该系统性能，研究人员会在「自由打字」任务中，评估一位被试情况，在这一任务中，被试要做的仅仅是使用设备来回答问题。但是，我们通常使用复制打字（copy typing，包括打出固定短语）来评测打字速度，所以，这三位被试都会以这种方式评估。进行「自由打字」的女士快于每分钟六个单词，另一个 ALS 病人打出了约三个单词，而 Degray 打出了约八个单词。2015 年 一期 *Nature Medicine *介绍了可比较的结果，不过，它们都是通过软件实现的，这些软件能够利用英语的统计学数据来预测后续字母。而这项研究中并未应用这类软件。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;复制打字的缺点是：成绩可能会随所用特定短语和键盘布局的变化而变化。为了找到一个不受这些因素影响的度量，第三个任务便与在随机点亮的六乘六网格上选择正方形有关；这样更能接近量化系统输出信息的最大速度，并能轻易转换为数字「比特每秒」的度量。这个团队采用了这一系列任务，但没有使用预测软件，因为该研究的中心目标之一就是制定标准化的度量。斯坦福的博士后研究员及第一作者 Chethan Pandarinath 说：「我们需要建立度量，从而当受试者、方法和研究人员之间存在潜在差异时，同样可以说这种进步显著提高了绩效，因为我们有系统的比较方法，而这是推进该技术的关键。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;两个 ALS 患者分别达到 2.2 和 1.4 比特每秒，是之前记录（相同的参与者在之前的记录）的两倍以上。Degray 达到了 3.7 比特每秒，这比之前的最高速度快四倍。Pandarinath 说：「与之前的 BCI 临床研究相比，这在性能上是巨大的飞跃」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;iframe allowfullscreen="" class="video_iframe" data-vidtype="1" frameborder="0" height="417" src="https://v.qq.com/iframe/preview.html?vid=x03777mt4pc&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0" width="556"&gt;&lt;/iframe&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其他研究者认为这些是最前沿的成果。匹兹堡大学的生物医学工程师 Jennifer Collinger 说：「他是使用 BCI 打字速度最快的一位。这项技术与眼动仪相同，但有些团队的技术对于如被锁定的人来说无效。这些速度也接近 ALS 患者在调查中所提出的 BCI 设备理想值。」他并没有参与到这项研究中。Collinger 说：「你们的技术性能已经足够顶尖，用户也真正想要这类设备」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在受试者的大脑表面植入一或两个小型（六分之一英寸）电极阵列，这些「皮质内」植入物含有 96 个微电极，这些微电极能够穿透 1~1.5 毫米，进入控制手臂运动的运动皮质部分。其中两项手术由 Henderson 执行，他与资深共同作者生物工程师 Krishna Shenoy 共同领导斯坦福的神经假体平移实验室（Stanford&amp;lsquo; s Neural Prosthetics Translational Laboratory）。由电极记录的神经信号通过电缆传输到计算机，在这个计算机中，Shenoy 的实验室开发的算法会解码受试者的想法，并将信号转换为计算机光标的移动。斯坦福大学的团队是一个名为 BrainGate 的多学科联盟的一个分支，这个联盟还包括马萨诸塞州总医院以及布朗大学等等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过电极与大脑相连接的其他方法，包括将电极置于头皮上用于制作脑电图（EEG），以及将电极置于脑表面的头骨之下，制成脑电图（ECoG）。皮质内植入物的优点是：可以从单一细胞挑出具体行为，也可用其他方法捕获数千神经元的平均活动。匹兹堡大学的神经生物学家 Andrew Schwartz 说：「这比从 EEG 或 ECoG 得到的结果要好 10 倍，因为它们所拥有的信息，不足以完成该水平任务。」他同样没有参与到研究中。运动和疤痕会使约前两年植入的信号质量下降，但剩下的信号仍然有效&amp;mdash;&amp;mdash;「比任何其他技术要好得多」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前最大的缺点便是从头部发出，将电线接到电缆上，这很繁琐也有风险。Pandarinath 说：「我们未来的目标便是研发无线设备，虽然现在还未实现，但 5 到 10 年后也许就会成为可能。这是关键的进步&amp;mdash;&amp;mdash;你能用它来送一个人回家，而不必担心譬如感染这类潜在的风险」。这样的设备需要无线电源，已经有几个小组投入研究。Schwartz 说：「基本上大多数技术都是已知的，可以用线圈感应来实现，就像将你的手机置于一边带有线圈的支架上充电。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;团队把这些进展归功于更优的系统工程和解码算法。Pandarinath 说：「在实时控制系统中，快速执行重复计算至关重要」。去年，研究人员发表了一项斯坦福生物工程师 Paul Nuyujukian 领导下的研究。通过训练两只猕猴来执行与类似于本研究所用的网格练习的任务。猴子打字的方式是，通过改变屏幕上字符的颜色来选择字符，生成句子。（尽管他们不会理解这些单词的意思）。当他们添加了一个独立的算法来检测猴子的停止意图时，相应的最快速度每分钟增加了两个单词。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个「离散型点击解码器（discrete click decoder）」也被用于当前的研究。Pandarinath 说：「基本上，我们在这里创建了一个类似于鼠标指明和点击的接口。对于现代智能手机或平板电脑而言，这是一个优质接口；它将开启超越沟通的全新功能领域：上网，播放音乐等正常人认为理所当然的各种方面。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;斯坦福大学的团队已在研究无线技术，并为该项目制定了雄伟的长期目标。Henderson 说：「我们的愿景是使无线接收器能够插入所有计算机，并能通过大脑进行使用。我们的目标之一便是：一年中的每日每夜，每分每秒都能够使用大脑信号来控制标准的计算机接口。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;论文：瘫痪者使用脑皮质内脑机接口的高性能通信（High performance communication by people with paralysis using an intracortical brain-computer interface）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/57b97864b615a153c68315c06dcb49d9698e9ef2"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：脑机接口（BCI）有望通过将神经活动翻译成辅助通信设备的控制信号而帮助患有四肢瘫痪和构音不全的人重新获得交流能力。尽管之前的临床前和临床研究已经给出了有潜力的概念验证（(Serruya et al., 2002; Simeral et al., 2011; Bacher et al., 2015; Nuyujukian et al., 2015; Aflalo et al., 2015; Gilja et al., 2015; Jarosiewicz et al., 2015; Wolpaw et al., 1998; Hwang et al., 2012; Sp&amp;uuml;ler et al., 2012; Leuthardt et al., 2004; Taylor et al., 2002; Schalk et al., 2008; Moran, 2010; Brunner et al., 2011; Wang et al., 2013; Townsend and Platsko, 2016; Vansteensel et al., 2016; Nuyujukian et al., 2016; Carmena et al., 2003; Musallam et al., 2004; Santhanam et al., 2006; Hochberg et al., 2006; Ganguly et al., 2011; O』Doherty et al., 2011; Gilja et al., 2012），但人类临床 BCI 系统的表现还并不够好，还不足以支撑有语音方面的身体限制的人的广泛采用。在这里我们报告了一种用于交流的高性能的皮质内脑机接口（intracortical BCI / iBCI），其已经在三位瘫痪的临床试验参与者的身上进行了测试。该系统利用了之前的临床前和临床研究（Gilja et al., 2015; Kao et al., 2016; Gilja et al., 2012）所发展的解码器设计上的进步。在打字速度（是原来的 1.4&amp;ndash;4.2 倍）和信息流通量（是原来的 2.2&amp;ndash;4.0 倍）上，所有三位参与者的表现都超过了之前的 iBCI（Bacher et al., 2015; Jarosiewicz et al., 2015）。这种高水平的表现表明了 iBCI 作为运动功能受限者的强大辅助交流设备的潜在应用价值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;原文地址：https://www.scientificamerican.com/article/brain-computer-interface-allows-speediest-typing-to-date/&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Thu, 23 Feb 2017 12:29:28 +0800</pubDate>
    </item>
    <item>
      <title>学界 | Yoshua Bengio 等人提出 Char2Wav：实现端到端的语音合成（附资源）</title>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650723604&amp;idx=4&amp;sn=5aeb3df13d7565fb6c889450bb48b80b&amp;chksm=871b116ab06c987c8c0dc36f437008c30ab7df5f8450c2de183f358662e14260995d8cdf10ce&amp;scene=0#rd</link>
      <description>
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自arXiv&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;近日，来自印度理工学院坎普尔分校、INRS-EMT、加拿大高等研究院（CIFAR）的研究者在 arXiv 上发布了一篇 workshop track 论文，介绍他们在端到端语音合成上的研究成果 Char2Wav。据介绍，该模型可以直接根据文本生成高质量的音频。目前，该研究团队已经将相关的研究代码开源并且公布了合成的样本示例。&lt;em style="max-width: 100%; color: rgb(136, 136, 136); font-size: 16px; line-height: 28px; text-align: justify; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;span&gt;读者可点击阅读原文下载此论文。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GitHub 开源地址：http://github.com/sotelo/parrot&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;合成语音样本地址：http://josesotelo.com/speechsynthesis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/f29e2a312f734ae79cd4fee21aaa238420dccbcc"/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;摘要&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们提出一种端到端的用于语音合成的模型 Char2Wav，其有两个组成部分：一个读取器（reader）和一个神经声码器（nerual vocoder）。该读取器是一个带有注意（attention）的编码器-解码器模型。其中编码器是一个以文本或音素作为输入的双向循环神经网络（RNN），而解码器则是一个带有注意的循环神经网络，其会产出声码器声学特征（vocoder acoustic features）。神经声码器是指 SampleRNN 的一种条件式的扩展，其可以根据中间表征（intermediate representations）生成原始的声波样本。与用于语音合成的传统模型不同，Char2Wav 可以学习直接根据文本生成音频。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1 引言&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;语音合成的主要任务包括将文本映射为音频信号。语音合成有两个主要目标：可理解性（intelligibility）和自然感（naturalness）。可理解性是指合成音频的清晰度，特别是听话人能够在多大程度上提取出原信息。自然感则描述了无法被可理解性直接获取的信息，比如听的整体容易程度、全局的风格一致性、地域或语言层面的微妙差异等等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;传统的语音合成方法是将这个任务分成两个阶段来完成的。第一个阶段被称为前端（frontend）是将文本转换为语言特征，这些特征通常包括音素、音节、词、短语和句子层面的特征（Zen, 2006; Zen et al., 2013; van den Oord et al., 2016）。第二个阶段被称为后端（backend），以前端所生成的语言特征为输入来生成对应的声音。WaveNet（van den Oord et al., 2016）就是一种可实现高质量的「神经后端（neural backend）」的方法。要更加详细地了解传统的语音合成模型，我们推荐参阅 Taylor (2009)。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;定义好的语言特征通常需要耗费大量时间，而且不同的语言也各有不同。在本论文中，我们将前端和后端整合到了一起，可以通过端到端的方式学习整个过程。这个流程消除了对专业语言学知识的需求，这就移除了在为新语言创建合成器时所面临的一个主要瓶颈。我们使用了一个强大的模型来从数据中学习这种信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2 相关研究&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;基于注意（attention）的模型之前已经在机器翻译（Cho et al., 2014; Bahdanau et al., 2015）、语音识别（Chorowski et al., 2015; Chan et al., 2016）和计算机视觉（Xu et al. 2015）等领域得到了应用。我们的工作受到了 Alex Graves (Graves, 2013; 2015) 的工作很大的影响。在一个客座讲座中，Graves 展示了一个使用了一种注意机制的语音合成模型，这是他之前在手写生成方面的研究成果的延伸。不幸的是，这个语音方面的延伸没有被发表出来，所以我们不能将我们的方法和他的成果进行直接的比较。但是，他的结果给了我们关键的启发，我们也希望我们的成果能有助于端到端语音合成的进一步发展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3 模型描述&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3.1 读取器&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们采用了 Chorowski et al. (2015) 的符号。一个基于注意的循环序列生成器（ARSG/attention-based recurrent sequence generator）是指一种基于一个输入序列 X 生成一个序列 Y= (y1, . . . , yT ) 的循环神经网络。X 被一个编码器预处理输出一个序列 h = (h1, . . . , hL)。在本研究中，输出 Y 是一个声学特征的序列，而 X 则是文本或要被生成的音素序列。此外，该编码器是一个双向循环网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/a2e4287b948fd6fa4222628bc597e4c6129fefcd"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;图 1：Char2Wav：一种端到端的语音合成模型&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在第 i 步，ARSG 重点关注 h 并生成 yi：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/9b31fd19e3eea42c8b26f59e0a83bcf1e7e12e46"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中 si-1 是该生成器循环神经网络的第 i-1 个状态，而&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/0a3c1c0b88f1585688217c4a55202c39b00126fb"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;是注意权重（attention weight）或对齐（alignment）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这项成果中，我们使用了由 Graves (2013) 开发的基于位置的注意机制（location-based attention mechanism）。我们有&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/dd54b25c3920090050a896ed33f2483011f413d4"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而给定一个调节序列 h 的长度 L，我们有：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/55a31e75716ea891fea06f5850e1bc269ffb4436"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中 &amp;kappa;i、&amp;beta;i 和 &amp;rho;i 分别表示该窗口的位置、宽度和重要程度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3.2 神经声码器&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使用声码器进行语音合成受到特定声码器重建质量的限制。为了获得高质量的输出，我们使用一个学习到的参数神经模块（parametric neural module）替代了该声码器。为了该目标，我们使用 SampleRNN(Mehri et al., 2016）作为增强的函数逼近器（function approximator）。SampleRNN 最近被提出用于在音频信号这样的序列数据中建模极其长期的依存关系。SampleRNN 中的层级结构被设计来捕捉不同时间尺度中序列的动态。这对捕捉远距音频时间步骤（例如，语音信号中的词层面关系）之间的长距关联以及近距音频时间步骤的动态都是有必要的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们使用同一模型的条件式版本学习把来自声码器特征序列映射到相应的音频样本。每个声码器的特征帧（feature frame）被加了进来用作相应状态的最好的额外输入。这使得该模块能使用过去的音频样本和声码器特征帧来生成当前的音频样本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4. 训练细节&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先，我们分别预训练读取器和神经声码器然后使用标准的 WORLD 声码器特征（Morise et al., 2016; Wu et al., 2016）作为读取器的目标和神经声码器的输入。最终，我们端到端的微调整个模型。代码已经在网上公开。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;5 结果&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此次我们并未提供对结果的综合的定量分析。相反，我们提供了来自模型 2 的样本。在图 2 中，我们演示了模型生成的样本以及相应的文本对齐。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/44a74c308b7048dfacf8f772f6545d021da5a08f"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 2：以上样本分别来自以 a) 英语音素、b) 英语文本和 c) 西班牙语文本为条件的模型。a) 和 b) 的模型是在 VCTK 数据集（Yamagishi, 2012）上进行训练的，而 c) 模型是在 DIMEX-100 数据集（Pineda et al., 2010）上训练的&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;致谢与参考文献（略）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Thu, 23 Feb 2017 12:29:28 +0800</pubDate>
    </item>
    <item>
      <title>2016 年度学术公众号 TOP10 重磅发布</title>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650723604&amp;idx=5&amp;sn=f61fb279042bec50aebbca75ddb2ee3b&amp;chksm=871b116ab06c987c58079ed4235e44213f7d62d182f6d9dde932a5091787a2d4ebff793e1888&amp;scene=0#rd</link>
      <description>
&lt;p&gt;&lt;br&gt;&lt;img src="http://img04.iwgc.cn/mpimg/8d83cf30400d526eb422666a4554ae05f73e8b12"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;7大领域专家参与评审&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;235个学术公众号参选&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;31969次网络不记名投票&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;历时88天&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;打造一份科研人不能错过的&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;学术公众号榜单&amp;mdash;&amp;mdash;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;2016年，一批独具特色的学术公众号崭露头角，它们为科研人员提供的研究动态、学术服务和交流平台，受到越来越多科研人员关注，也逐渐成为中国科研生态的一部分。为促进学术传播、传递更多优质科研资源，《环球科学》旗下学术服务平台&amp;ldquo;科研圈&amp;rdquo;发起2016年度学术公众号评选，为研究者甄选垂直领域&amp;ldquo;十大最受关注学术公众号&amp;rdquo;。&lt;br&gt;&lt;br&gt;历时三个月，经过粉丝提名、大规模网络投票、专家团评议环节，十个在专业性、前沿性、传播力、实用性、发展潜力方面有着出色表现的公众号脱颖而出，入选&amp;ldquo;十大最受关注学术公众号&amp;rdquo;。&lt;br&gt;&lt;br&gt;过去一年，它们在跟踪学术前沿、传播科研进展、促进交流的同时，自身也成为中国科研文化的一部分。2017年，我们期待微信平台出现更多优质学术媒体，共同催生科研服务的新生态。&lt;br&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/f1d3a361ce3f3bb1516a0fe91f2a4a99e567aeac"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/60250c86432297028b8326903ea61c3aca392dd9"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/9000f7c3b9ebf1ed3e89529501bdf07e86a38154"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/a4235f04a7e575e630a70f195dce07a4d9548fd4"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/a3f9c566da62a0cdeb77762ec4fb018eabd4a7af"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/d5ebcc4b00ef7718de940c9f3c2d6178c18856b0"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/e6619053b5800d462faa3c8e3531ea46001a92f8"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/32986454fbbb82c712e09630d3207943b60bbcb6"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/6df7b6b87b067661c0d267e0bbcf869701032b62"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/c3ce19c5e31986736702f2bdf9300c160a7bc108"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/8dc02019bf22e449fc7778e08c0ee08674f9f80e"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/4dd1cac5531db3127e67b6f08d9789280ed35b01"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;
</description>
      <pubDate>Thu, 23 Feb 2017 12:29:28 +0800</pubDate>
    </item>
  </channel>
</rss>
