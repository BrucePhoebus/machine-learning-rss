<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>独家 | AAAI-17获奖论文深度解读（上）：从无标签监督学习到人工智能道德框架</title>
      <link>http://www.iwgc.cn/link/4644206</link>
      <description>&lt;div class="article-content"&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;section style="max-width: 100%; white-space: normal; line-height: 28.4444px; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%; border-width: 0px; border-style: initial; border-color: currentcolor; font-family: 微软雅黑; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; max-width: 100%; border-style: solid none; font-family: inherit; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="color: rgb(62, 62, 62); font-size: 1em; margin-top: -1.2em; max-width: 100%; min-height: 1em; border-width: initial; border-style: initial; border-color: currentcolor; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(255, 255, 255); background-color: rgb(117, 117, 118); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;机器之心原创&lt;/span&gt;&lt;/p&gt;&lt;section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px; max-width: 100%; font-family: inherit; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="color: rgb(62, 62, 62); font-size: 16px; margin-top: 5px; margin-bottom: 5px; max-width: 100%; min-height: 1em; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(127, 127, 127); font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;作者：吴沁桐、Olli Huang&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-top: 5px; margin-bottom: 5px; max-width: 100%; min-height: 1em; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color:#7f7f7f"&gt;&lt;span style="font-size: 12px;"&gt;&lt;strong&gt;参与：朱思颖、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style="max-width: 100%; min-height: 1em; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;AAAI 2017 大会刚刚闭幕，会议围绕人工智能的研究与发展进行了多场演讲、讲座、Workshop 等活动，吸引了世界各地的人工智能从业者参加。当然，众所周知的是，华人是本次大会不可忽视的一支力量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;依照惯例，AAAI 在会议期间评选了一些获奖论文，其中包括两篇杰出论文（Outstanding Paper，其中有一篇学生论文）以及经典论文、鼓励创新研究的 Blue Sky Idea Awards 获奖论文等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;在 AAAI 获奖论文公布之后，机器之心邀请多位技术分析师对这些论文进行了深度解读，为我们分析了这些论文的杰出和创新之处，带我们领略了人工智能和机器学习领域的最前沿的研究成果和思想。以下即为对本届 AAAI 上获奖论文的解读。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;span style="font-size: 16px;"&gt;&lt;strong&gt;AAAI-17 杰出论文奖（Outstanding Paper Award）&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px; text-align: justify;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px; text-align: justify;"&gt;论文标题：&lt;strong&gt;使用物理学和领域知识的神经网络的无标签监督（Label-Free Supervision of Neural Networks with Physics and Domain Knowledge）&lt;/strong&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;作者：Russell Stewart and Stefano Ermon&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;关于该奖：AAAI 杰出论文奖获奖论文体现了技术贡献和阐述的最高标准。这个奖通常是将给在计算机科学领域实现了广度和独特性的研究者，这些研究通常构建了不同科系和学科之间的桥梁。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;论文解读&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;本届的杰出论文《Label-Free Supervision of Neural Networks with Physics and Domain Knowledge》的灵感来自于人类的学习过程，其利用了先前的领域知识来将输出空间约束到一个特定的学习结构，而不是简单的从输入到输出的映射。这种做法让该论文不需再使用大量有标签数据来监督神经网络，而是让神经网络学习更见先进的结构。通常来说，当前将不使用标签进行学习方法称为无监督学习（unsupervised learning），比如说自编码器（autoencoder）。无监督学习方法通常是将输入数据聚类（cluster）成不同的分组，这种方法虽然高效，但往往缺乏有意义的解读。与无监督学习相反，通过没有明确标签但有 ground truth 法则的数据进行训练，我们可以得到两点好处：1）花费在标注上的工作量减少，2）通用性提升，因为单一一套约束可以无需重新标注就被应用到多个数据集上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1486700494GzYTlj.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 12px;"&gt;图 1：约束学习的目标是在无需提供标签 y 的情况下恢复变换 f。我们并没有那么做，我们则是寻找一个能够获取 g 所要求的结构的映射 f.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;要将先验知识整合进监督学习中，通常有两种方式：1）通过限制能特定假设类 F 的可能函数，2）通过为 F 中的特定函数增加一个 a-prior preference，其对应的正则化（regulation）为 R(f)，其中 f 属于 F。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;在这篇论文中，作者重点关注了约束函数 g:X*Y 根据先验知识（即物理法则）映射到 R，以在学习过程偏离先验知识时惩罚学习结构——这些先验知识是抽象的高层面思考，而不仅仅是标签。在这个训练场景中，标签 y 仅用于评估，而且其对于发现 f* 属于 F 的最优规则并不是必需的。为了确保收敛以找到正确的 f*，我们也可能需要为监督机器（supervise machine）增加额外的正则化项。这个设计约束函数 g 和正则化项的过程确实是一种监督形式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;该论文提供了三个案例：1）跟踪一个自由落体，2）跟踪一个行人的位置，3）根据因果关系检测目标。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;第一个案例遵循最简单的规则——任何物体受到没有重力之外的其它力时都会下落。因此，当一个物体被扔出去后，其运动轨迹毫无疑问是一条抛物线。通过使用这种物理定律的先验知识，我们可以设计一个约束函数迫使神经网络向其收敛。在训练过程中，该数据集包含了 65 个不同的轨迹，共计 602 张图像。使用 Adam 优化器和 0.0001 的学习率，该 CNN 训练了 4000 次迭代。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;让人惊讶的是，结果很不错。训练好的神经网络得到了 90.1% 的相关性（correlation），相比而言，在标签上训练好的神经网络的相关性为 94.5%。不使用标签，神经网络仍然实现了出色的输出。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1486700494ohGB31.jpg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;第二个案例和前一个类似，但其约束函数需要修改，因为其有收敛问题。在这个场景中，这个常速假设大约仍然还存在。这两个实验都涉及到运动方程，唯一的区别是第二个实验中没有重力项。如果我们没有明确地防范这种平凡的解决方案，这里的问题是该网络总是可以收敛到一个常量 C。所以我们需要设计正则化项以帮助约束函数 g 以随机化其网络，因此，一个平衡辅助函数（counterbalance helper function）是必需的。在训练过程中，该数据集包含了 6 种不同场景的 11 种不同轨迹，共计 507 图像。而在第一个实验中的超参数也得以保留以体现参数的稳健性。最后的结果是与 ground truth 相关 95.4%。此外，这个模型仍然在测试集（在训练集上 99.8%）上实现了 80.5%。论文作者将性能下降归咎于在小训练数据量（11 轨迹）上的过拟合（overfitting），对于一个得到了良好训练的监督式分类器，可能实现接近完美的相关性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1486700494unMI98.jpg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;第三个案例是更一般化，这并不是来自真实世界的现象，而是来自逻辑和基于约束的方法（formalisms）。因此，在第三个实验中，我们从施加在单张图像上的逻辑约束中探索了学习的可能性。该数据集由随机收集的任天堂角色（马里奥、桃子公主、耀西、库巴）组成，其中每个角色都有因旋转和翻转造成的轻微的外观改变。其生成的分布编码了一种基本巧合——即马里奥和桃子公主同时出现的场景（和游戏 Save Peach! 本身一样）。这个神经网络任务是分辨马里奥和桃子公主。我们没有使用直接标签来进行监督，我们通过约束它们的输出到有 y1 到 y2 的逻辑关系来训练网络，其中 y1 表示桃子公主，y2 表示马里奥。在这个设置中，我们总是可以预测 y1 === 1 和 y2 === 1，因为这个规则总是正确的。没有任何惩罚（penalty）和正则化，其输出最终会是决定性的和无意义的（以 ROC 曲线，这个情形对应于：错误检测概率等于 1，同时检测概率也等于 1，这是无意义的）。为了避免这种无价值的解决方案，我们需要更加复杂的正则化项来让网络将重点放到物体的存在而非位置上。在一个有 128 张图像的测试集上，该网络学会了将每张图像映射到一个正确的描述——图像是否包含了桃子公主和马里奥。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1486700495tmLG86.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="text-align: justify; font-size: 12px;"&gt;图 4：不管桃子公主（金黄色）什么时候出现，马里奥（红色）就会在附近出现，但反之并不亦然。耀西（绿色）和库巴（橙色）随机出现。该系统使用了这种高层面的知识进行训练并学习了回答每张图片是否包含桃子公主和马里奥。第一列包含了样本图像，第二和三列给出了桃子公主和马里奥网络分别出现的位置。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;约束学习是一种监督学习的泛化，允许实现更具创造性的监督方法。而这种新方法是通过以下方式学习的：&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px; text-align: justify;"&gt;利用现代神经网络的表征学习能力；&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;当主要约束仅仅是必要条件时，添加充分条件。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;未来的挑战包括将这些结果扩展到更大型的数据集（其中每张图像都有多个目标）上，以及简化为新的和有趣的问题挑选充分项的过程。通过让操作者免于收集标签，我们的小规模实验表明了未来使用弱监督训练神经网络的潜力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;拓展阅读&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: left; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Convexification of learning from constraints.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: left; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;https://arxiv.org/abs/1602.06746&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: left; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;A method for stochastic optimization.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: left; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;https://arxiv.org/abs/1412.6980&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: left; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Building high-level features using large scale unsupervised learning. https://static.googleusercontent.com/media/research.google.com/zh-CN//archive/unsupervised_icml2012.pdf&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;strong&gt;AAAI-17 Blue Sky Idea Award&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;论文标题：&lt;strong&gt;人工智能的道德决策框架（Moral Decision Making Frameworks for Artificial Intelligence）&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;作者：Vincent Conitzer, Walter Sinnott-Armstrong, Jana Schaich Borg, Yuan Deng, Max Kramer&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;AAAI-17 Blue Sky Idea 奖授予了论文《Moral Decision Making Frameworks for Artificial Intelligence》&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1486700495VNc8zy.jpg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;关于该奖：根据 AAAI 的设定，这个奖项是为表彰那些论文中所提出的想法和愿景能够促进研究团体去寻求新的研究方向（如：新问题、新应用领域或新方法）的论文。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;论文解读&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;现在有越来越多的人工智能系统在帮助我们做决策以及减少类似粗心这样的行为所导致的错误。当我们赋予人工智能系统更多自主性时，我们是否应该为这些人工智能系统或许会做出的伦理视角下的反直觉判断而担忧呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;在这篇论文中，Conitzer 等人为如何设计具有道德考虑的人工智能系统提供了一个路线图，虽然还处于研究的婴儿期，他们希望在不久之后就能设计出一个通用框架，这个通用框架将支持人工智能系统在面临道德困境时自主做出合理的道德决策。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;将道德推理引入人工智能系统是非常必要的，因为人工智能系统需要更多的自主性，当设计一个包含道德的人工智能系统时，应该有一个道德理论来清晰定义下面的内容：&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;哪些行为在道德上是正确的以及哪些行为是错误的；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;智能体来表达行为结构以及系统在不同情形下做审判时所需要的语言体系，包括行为中与道德相关的特征以及特征如何交互影响道德审判的规则。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;用以抽象表征道德困境的路线图&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;一个博弈论方案&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;博弈论是讨论对同一博弈条件下多个不同利益智能体的场景建模。并且智能体所采取的行动将会导致它们在不同范围内有更好或者更坏的表现，因此博弈论为抽象表征道德困境（moral dilemmas）提供一个潜在的优质备选。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;扩展式（extensive forms）是标准的表征体系之一，因此直观的想法是用扩展式来叙述道德困境、展示博弈中的智能体、智能体所采取的行动以及博弈的结果。然而，Conitzer 等人同时指出过分简单化的博弈论解决方案并不能完全顾及道德的各方面考虑，因为博弈论中标准的解决方案将各方限定在预指定的效用实现上。因此，他们指出扩展式需要有延伸，从而支持「博弈的分析与评估一个智能体是否应该追逐另一个智能体的福祉结合在一起。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;论文为对博弈论方案中道德人工智能系统的未来工作开展感兴趣的研究者提供两个研究方向：&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;将博弈的概念泛化到有更多博弈方参与的完美/不完美信息博弈中；（注：完美信息（perfect-information）博弈应该能够给博弈（如国际象棋）中所有博弈方提供当前博弈状态的全局观察，这与不完美信息博弈（如德州扑克）并不是这样。）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px; text-align: justify;"&gt;定义能获取其它道德关注点的其它不同的解决方案概念&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;扩展式的一个范例：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;如果我们（第一个博弈者）不采取任何行动，让一个失控的火车继续前进，那么这列火车将马上撞向第二个博弈方；我们是否应该马上采取行动将火车转到另一个轨道上行驶从而避免第二个博弈者受到伤害，但是转到另一个轨道上会让第三个博弈方的生命处于危险之中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1486700495f8xsUS.png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;一个机器学习方案&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;另一个展示道德困境的方式是基于机器学习的。从根本上来说，我们将有一组道德正确的决策作为训练集，这组正确的决策是由人工标注的并交由人工智能系统来归纳。这篇论文里还提到了一些悬而未决的问题：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;（1）什么是正确的表征？&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;（2）那些特征是重要的？&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;（3）怎样精确构建和标注一个好的训练集？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Conitzer 等人宣称道德困境可以由关键道德特征来表征，构建出一个让人工智能系统自动做出道德抉择的通用框架的主要任务是确定能在不同领域内应用的抽象特征，而不是去寻找只适用于个别情形的某些特定特征。给定一个由特征值表征的道德困境的标注训练集，机器学习的技术能够帮助人工智能系统学会区分智能体的行为是道德正确的还是道德错误的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;除了创建一个行为二分类（要么道德正确，要么道德错误），还可以进一步分析用回归（regression）算法所产生的抉择的道德错误程度；以及例如在贝叶斯框架下，一个抉择在道德错误上的似然性大小，或者把这两个方法结合在一起看看。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;道德困境由什么构成？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;考虑图 1（来自 Conitzer 等人的论文）中被称为「信任博弈」的例子。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;假设在最开始的时候，第一个博弈者（下简称 P1）有 100 美金，而第二个博弈者（下简称 P2）没有任何资金。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;如果 P1 决定给出一部分钱，比如说 50 美金，那么这时候 P2 将会收到 3 倍于 P1 给出钱数目的钱，也就是 150 美金。此时，P1 有 50 美金，P2 有 150 美金。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;现在如果 P2 想还 P1 一个人情，将 100 美金还给 P1，那么 P1 将只收到 100 美金。这个时候，P1 有 150 美金，而 P2 拥有 50 美金。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1486700495unMH97.jpg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;直观的博弈论分析将是这样的，每一个博弈方应该尽最大可能使自己的钱数最大化。P1 和 P2 将很可能把钱留在自己那里而不是给对方。甚至即使收到对方给的钱，仍旧不会给回任何钱以作感激。但是显然人在做决定时不总是只考虑自己的利益。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Conitzer 等人指出「信任博弈（the trust game）」是道德推理的一个普遍特征，即人们会考虑所采取的行为的后果以及行为发生的情形，同时还会考虑他们的行为是否表现出公平、不感恩、不忠诚、不可信任或者理所应当。参与者或者智能体会从未来的影响和过去的影响来评价自己的行为。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;显然让所有人都认同哪些道德特征是相关的，或者是解决道德困境的最重要特征。找出每个智能体的道德价值点也许是可行的，抽象表征它们并且在人工智能系统中对其编码。在道德困境中，人工智能系统可能会遵从某个智能体的道德价值（「道德相对主义（moral relativism）的一种」），或者拥有人的道德价值所聚合的社会选择理论，例如，只运用对所有智能体都常见的道德价值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;我们授予了人工智能系统自主权，而这使得人工智能系统在做一些道德上的决策时可能会产生适得其反的效果。所以我们就需要将人工智能系统设计成能制定出更具稳健性和安全决策的系统，并且这个决策绝大多数人都认为是合理的。建立道德体系可能的一个方法就是在必要的时候创建专门的道德规则，但是一般来说，人工智能系统受益于采用跨领域（cross-domain）的方法，在这方面起到关键作用的是预期最大效用，而预期最大效用却又会阻止制定出合理的道德决策。因此，研究者已经在寻求道德人工智能系统的一般道德框架，其中当人工智能系统在学习和理解了道德价值后，道德困境可以用抽象的形式来表示。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;然而，道德人工智能系统仍处于起步阶段，我们还有很长的路才能建立一个通用框架，才能使人工智能系统自动地做出道德决策。Conitzer 等人的论文是引人深思的，该论文提供了表征人工智能系统中道德困境的两个范例，即带有道德决策成分的博弈论方法和使用人工标注案例的机器学习方法，另外这两种方式是潜在的互补范式。可能还存在建立道德人工智能系统的其它范式，但是 Conitzer 和他的同事肯定会给我们带来道德人工智能系统方面上的进步。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;扩展阅读&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Joshua Letchford, Vincent Conitzer, and Kamal Jain. An ethical game-theoretic solution concept for two-player&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;perfect-information games. In Proceedings of the Fourth Workshop on Internet and Network Economics (WINE), pages 696–707, Shanghai, China, 2008.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Michael Anderson and Susan Leigh Anderson. Machine ethics: Creating an ethical intelligent agent.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;AI Magazine, 28(4):15–26, 2007.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Nick Bostrom and Eliezer Yudkowsky. The ethics of artificial intelligence. In W. Ramsey and K. Frankish, editors,&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Cambridge Handbook of Artificial Intelligence. Cambridge University Press, 2014.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Swarat Chaudhuri and Moshe Vardi. Reasoning about machine ethics, 2014. In Principles of Programming Languages (POPL) - Off the Beaten Track (OBT).&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;James H. Moor. The nature, importance, and difficulty of machine ethics. IEEE Intelligent Systems, 21(4):18–21, 2006.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="max-width: 100%; min-height: 1em; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; text-align: justify; line-height: 1.75em; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; line-height: 25.6px; font-family: 微软雅黑; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; font-style: normal; color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; font-style: normal; color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;©本文为机器之心原创，&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; font-style: normal; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; max-width: 100%; min-height: 1em; color: rgb(62, 62, 62); white-space: normal; font-size: 18px; line-height: 1.75em; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(127, 127, 127); line-height: 25.6px; font-family: 微软雅黑; text-align: justify; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; max-width: 100%; min-height: 1em; color: rgb(62, 62, 62); white-space: normal; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(217, 33, 66); font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="max-width: 100%; min-height: 1em; color: rgb(62, 62, 62); white-space: normal; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(217, 33, 66); line-height: 1.6; font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="max-width: 100%; min-height: 1em; color: rgb(62, 62, 62); white-space: normal; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; font-size: 12px; color: rgb(217, 33, 66); line-height: 1.6; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/div&gt;</description>
      <pubDate>Fri, 10 Feb 2017 12:12:30 +0800</pubDate>
    </item>
    <item>
      <title>干货 | 手把手教你搭建$1000以下的超级深度学习机器</title>
      <link>http://www.iwgc.cn/link/4630845</link>
      <description>&lt;div class="article-content"&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;section style="font-size: 16px; white-space: normal; max-width: 100%; color: rgb(62, 62, 62); background-color: rgb(255, 255, 255); line-height: 28.4444px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%; border-width: 0px; border-style: initial; border-color: currentcolor; font-family: 微软雅黑; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; max-width: 100%; border-style: solid none; font-family: inherit; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-top: -1.2em; max-width: 100%; min-height: 1em; font-size: 1em; border-width: initial; border-style: initial; border-color: currentcolor; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; background-color: rgb(117, 117, 118); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;选自Oreilly&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px; max-width: 100%; font-family: inherit; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-top: 5px; margin-bottom: 5px; max-width: 100%; min-height: 1em; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(127, 127, 127); font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;作者：Lukas Biewald&amp;nbsp;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-top: 5px; margin-bottom: 5px; max-width: 100%; min-height: 1em; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(127, 127, 127); font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;参与：赵华龙、微胖&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;br&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 12px;"&gt;是的，你可以在 价值$39 的树莓派上跑 TensorFlow。而且，你可以在 带有 GPU 引擎的 EC2 节点上每小时只花 1 美元跑 TensorFlow。这些可选方案可能比构建你自己的计算机更具实用感。但如果你像我一样，你会渴望构建你自己的高速深度学习机器。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;好吧，一千美元花在一个 DIY 项目上是太多了，但一旦你把机器搞起来，你可以建立数百个深度学习应用程序，从增强的机器人大脑到艺术项目（至少，我是如此为自己辩解的）。至少，这台机器将在除了功耗之外的每个指标上轻松超过 $2,800 的 Macbook Pro，并且因为它容易升级，在接下来的几年里也会保持领先。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;自从 80 年代以来，我还没有组建一台电脑，因为我非常害怕在一些我可能无法构建的东西（而且也可能并不会真正使用）上放几百美元。但我在这里告诉你，这样做肯定没问题！此外，它真的很有趣，你会得到一个伟大的通用计算机，会做常见的推理和学习而且在这方面比你的笔记本电脑快 20 倍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;主板&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;主板有不同的大小。由于我不想使用多 GPU，那种&lt;span style="font-size: 14px; text-align: justify;"&gt;被称为 mini-ITX 的&lt;/span&gt;最便宜和最小标准尺寸主板对这种项目就挺好了。我的最低要求是有一个 PCIe 插槽来插 GPU 和有两个 DDR4 插槽来插 RAM，我花$125 在 Amazon 上买了一个华硕 ASUS Mini ITX DDR4 LGA 1151 B150I PRO GAMING/WIFI/AURA 主板。它配备了一个 WiFi 天线，这实际上在我的地下室里超级有用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;机箱&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;机箱并不重要，但它们相当便宜，而且由于这个 DIY 电脑市场里主要都是玩家，因此机箱有各种有趣的形状和颜色。机箱尺寸应该与主板相匹配，因此机箱名字中也应有 mini-ITX 字样。我在 Amazon 上花$50 买了一个 Thermaltake Core V1 Mini ITX Cube 机箱。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;RAM&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;我不能相信能拿到这么便宜的 RAM！你需要购买 DDR4 RAM 来匹配你的主板（这个最容易在网上找到），价格都是一样的。我花$129 买了两个 8GB of Corsair Vengeance。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;我又额外花了 $5，因为亚马逊评论说，「对于那些只是不能得到足够的 LED 塞满他们系统的人，这些是完美的选择。」如果你在你的地下室组建一台电脑，同时你又不接受你内心的反传统（Burning Man）/青少年审美，你会花费大量时间却很难找到组件。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;CPU&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;我在网上看过 CPU 速度比较测试，我想如果 CPU 速度较慢我也没问题，因为我做的很少的事情是受限于 CPU 的（除了训练神经网络，而这个我会使用 GPU）。但是我不能让自己建造一台装有第三代 CPU 的计算机。我花 $214 用了 Intel I5-6600。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;几乎任何你可以在亚马逊找到的 CPU 都还可以。我没有多花$20 买 I5-6600K，两者几乎差不多就是能超频，因为对于我来说，为了 10% 的增速而牺牲可靠性，简直就是疯了。我也确实承认，开始习惯建造自己机器的想法时，也开始后悔当初这个决定了。所以谁又能知道呢？构建计算机可以改变你的人生观。如果有了超频芯片，可能遗憾会更少吧。另一方面，也许最好还是保护自己不受自己的影响，把选项从脑子里去掉吧。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;硬盘&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;我也不能相信能买到这么便宜的硬盘驱动器。我$ 50 买了一个 1TB SATA 驱动器。固态驱动器能更快，但是也更贵，并且通常，我的深度学习程序没有磁盘 I / O 限制，因为它们通常将批数据加载到 RAM 中，然后对数据处理很长时间。如果你想用计算机进行繁重的文件传输工作或者只是想确保它在所有程序运行上都明显快过你朋友的 Macbook，那么，我建议你买个类似 三星 850 EVO 250GB 2.5-Inch SATA III Internal SSD 的固态驱动器，$ 98 容量 250Gb。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;所有这些驱动器会让你意识到，苹果公司给你的 Macbook Pro 扩容 250G 加收 $ 200 简直就是在敲诈。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;显卡/GPU&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;选哪个显卡是最重要的和最棘手的问题。对于几乎所有的机器学习应用程序，你想要一个 NVIDIA 卡，因为只有 NVIDIA 有你必需的 CUDA 框架和 CuDNN 库，这是包括 TensorFlow 在内的所有机器学习框架所依赖的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;我并非一个 GPU 专家，我发现这里面的术语非常容易让人糊涂，但这对选择一款 GPU 来说是非常基本的知识。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;也许对深度学习来说最需要重要关注的属性是卡上可用的 RAM 大小。如果 TensorFlow 不能将模型和当前批次的训练数据放入 GPU 的 RAM 中，则会将故障转移到 CPU——这会使 GPU 毫无存在的意义。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;另一个需要关键考虑的是显卡的架构。NVIDIA 推出的几个最新的架构依次被称为「Kepler」、「Maxwell」和「Pascal」。架构之间的差异对速度的影响非常大；例如根据 该基准 (https://github.com/jcjohnson/cnn-benchmarks)， Pascal Titan X 是 Maxwell Titan X 速度的两倍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;大多数机器学习的文章使用 TITAN X 卡，它很棒，但成本至少$ 1,000，即使是一个较旧的版本。大多数进行机器学习而没有预算限制的人会使用 NVIDIA GTX 900 系列（Maxwell）或 NVIDIA GTX 1000 系列（Pascal）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;要了解显卡的架构，您可以看看 NVIDIA 令人吃惊的混乱命名规则：9XX 卡使用 Maxwell 架构，而 10XX 卡使用 Pascal 架构。但是由于更高的时钟速度和更多的 RAM，980 显卡仍然可能明显快于 1060 显卡。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;你将不得不基于所能获得的 GPU 的体系结构为 NVIDIA 卡打上不同的标签。但最重要的却是任何 9XX 或 10XX 显卡将会几个数量级地快于你的笔记本电脑。所以不要被选项难倒；如果你没有使用过 GPU，你会发现他们都会远比你现在用的要好。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;我选了标价为 195 美元的 GeForce GTX 1060 3G，它运行模型的速度比我的 MacBook 快 20 倍，但偶尔会因为跑某些应用而耗尽内存，所以我可能应该再加 60 美元买 GeForce GTX 1060 6GB。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;电源&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;我要谈的是标价 85 美元的 650W power supply。这个产品很烦人而且有电源问题的时候很难调试，看来似乎不应该在这上面省钱。另一方面，我从没见过我的机器在峰值负载下超过 250W。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;散热&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;我记得我工作的第一家创业公司把服务器放在他们的壁橱里，风扇的声音非常吵，甚至透过壁橱的门都觉得吵。这样的日子似乎已经过去很久了。尽管如此，650W 的电源得以让你将几乎 10 倍的能量充入你的笔记本电脑，而这种能量必须从某个地方散发出来。也许并不是必需的，但我仍花$ 35 买了一个非常棒的 Cooler Master Hyper 212 EVO 散热器。它使 CPU 保持凉爽，同时运行超静音。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;概况&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;要实际使用这些东西，你还需要一个显示器、鼠标和键盘。这些事情都很容易（我手头就有）。到目前为止，总数是 883 美元，所以距花 1000 美元左右组建一个称心的机器还有留有许多空间。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1486617599ohGB31.png"/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;将计算机组装起来&lt;/span&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;当所有快递包裹开始陆续到货时，我相当兴奋，同时我发现组装计算机只是貌似容易。按各机器部件附带的说明书，我大约花了一个小时组装完。但最后电脑打不开，我不得不更换主板，这让人沮丧，但结果还 OK。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;差不多第二次，我先在一个纸板箱上把所有的东西组合在一起检查了一下，机器运行了。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;基本上，如果你把一切东西都插入到看起来可能适合的地方，一切似乎都能运行良好。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1486617599SKa5xv.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 12px;"&gt;图 1. 放在桌上的半组装电脑，已装上可于测试的最少部件。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1486617599kdCxZX.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 12px;"&gt;图 2. 连上巨大散热器的电脑看起来更强大。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1486617600xpPKca.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 12px;"&gt;图 3. 这里插上硬盘驱动器后的俯视图。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;引导机器&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;安装最新版本的 Ubuntu 能让你的生活更轻松，因为 Ubuntu 支持几乎所有你将安装的深度学习软件。你可将图像存在 U 盘上，并 按这个简单的分步指南进行安装。因为我在 90 年代与 drivers 斗争的日子，linux 桌面安装过程已经改变了很多——现在变得难以想象的流畅。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;新的 Ubuntu 桌面也很棒。自从建立它以来，我经常使用这台机器作为个人电脑。有了大量 RAM，相当快的 CPU 和轻量级操作系统，它已经是迄今为止我家最快的机器了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;安装 CUDA，OpenCV 和 TensorFlow&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&amp;nbsp;为了使用你的全新深度学习机，你首先需要安装 CUDA 和 CudNN;最新版本的 CUDA 是 8.0，最新版本的 CudNN 是 5.1。从高层次看：CUDA 是一个 API 及编译器，它得以使其他程序将 GPU 用于通用应用程序，CudNN 是一个旨在使神经网络在 GPU 上运行得更快的库。你需要从 NVIDIA 网站下载该软件。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px; text-align: justify;"&gt;OpenCV 是大多数应用程序使用的图像处理开源库。现在，最新版本的 OpenCV（3.1）不适用于 EC2 上最新版本的 CUDA（8.0）。你可以通过将 CUDA_GENERATION 标志显式设置为 Kepler，Maxwell 或 Pascal 来使其工作，这取决于你购买的 GPU 的类型。这里是下载 OpenCV 并设置它运行的命令序列：&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1486617600BuTOge.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;最后，近期证明 TensorFlow 是很容易的——只需在该网站查看安装指南。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;要查看是否启用了 GPU 支持，可以运行 TensorFlow 的测试程序，也可以执行命令行：&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/14866176001UjfGF.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px; text-align: justify;"&gt;应该开始训练一个没有错误的模型。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;有趣的部分！&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;现在你已经支付了超过 1000 美元，并花费了无数小时构建和安装软件，是时候来证明你的投资了！GPU 使得运行速度明显加快，因此你需要能发挥速度优势的应用程序。幸运的是，你可以做许多有趣的事。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;对邻居的实时对象识别&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;在你家房子外面安装一个便宜的 USB 相机或带相机的树莓派（Raspberry Pi）。你可以很容易地使用 RPi 相机模块（RPi Camera Module）制作一个 Pi 流视频，我曾在上一篇关于 $ 100 TensorFlow 机器人 (https://www.oreilly.com/learning/how-to-build-a-robot-that-sees-with-100-and-tensorflow) 的文章中谈到。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;YOLO&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px; text-align: justify;"&gt;YOLO 包将对进入的数据进行实时对象识别。我发现，使用 Macbook 进行有边界框的对象识别需要 3-4 秒，但是使用 GPU 我能实时进行对象识别，且准确度相当不错。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;通过 YOLO_tensorflow (https://github.com/gliese581gg/YOLO_tensorflow) 项目使用 YOLO 模型并将其在 TensorFlow 上运行是很容易的。安装 Darknet 也很有趣，这是一个不同的深度学习框架，YOLO 最初即被设计与其一同运作：&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/14866176004WlhJH.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;br&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;一旦安装 Darkne，你能通过下面的方式运行它处理图片：&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1486617601NF40rq.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;br&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;由于 Pi 相机只是将文件放在一个 Web 服务器上，你可以直接链接到该文件，并在流上进行实时对象识别。这是我在我的车库里对外面一个交通拥堵做出的对象识别：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;iframe class="video_iframe" data-vidtype="1" allowfullscreen="" frameborder="0" height="417" width="556" data-src="https://v.qq.com/iframe/preview.html?vid=e0373sorhrf&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0"&gt;&lt;/iframe&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px; text-align: justify;"&gt;给你的树莓派机器人一个增强版大脑&lt;/span&gt;&lt;br&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;我在写前一篇 关于一台 $100 TensorFlow 机器人时发现，机器人可以在一个 30 美元的硬件上做深度学习是令人难以置信的。不幸的是，最令人失望的是机器人得用好几秒来做对象识别，因此，实时决策的工作效果并不好。但是，如果你的机器人用的是你的新 GPU 机器，你可做的就不仅是实时图像识别了，而且计算边界框的速度可达每秒 12-20 帧！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;如果你按照我在 GitHub 说明 (http://github.com/lukas/robot)，你可以构建一个机器人，以一种容易解析和快速的格式流放（stream）从摄像头中看到的一切。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;我的朋友 Shawn Lewis 教给我了这篇文章中提到的每件事，所以我将我的两个树莓派机器人带到我朋友肖恩的办公室。他的梦想，据我所知也是许多机器人学家的梦想，是造一个机器人给他倒啤酒。这里是机器人和地上的瓶子战斗的情况：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;iframe class="video_iframe" data-vidtype="1" allowfullscreen="" frameborder="0" height="417" width="556" data-src="https://v.qq.com/iframe/preview.html?vid=y03734qpus2&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0"&gt;&lt;/iframe&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;如果你看着他的电脑，实际上，机器是在他的 GeForce 980 上实时对输入中的两个机器人图像进行对象识别。他声称他可以在内存耗尽之前一次处理四个视频输入。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;创作艺术&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;使用神经网络可以做到的最有趣的事情之一就是复制 Google 的 Deep Dream 工作，即使没有 GPU，这也是可能的，但会花费无限长的时间。基本上，这涉及修改输入图像以找到在神经元中驱动最高响应的图像，因此它需要大量的计算能力。有很多不同的方法来做到这一点，而且输出通常是令人难以置信的奇怪和酷。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: left; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;现成的一个很好的教程是 Google 发布的 Deep Dream 代码：https://github.com/google/deepdream/blob/master/dream.ipynb。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;你需要安装 Jupyter 笔记本服务器 (http://jupyter.readthedocs.io/en/latest/install.html)（你不管怎么样都需要！）和 Caffe。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;然后仔细阅读 Google 的教程。通过使用你的新机器，这些图像需要几分钟而不是几个小时就可以生成，这将是非常有趣的探索。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1486617601qiHD53.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 12px;"&gt;图 4. 我的邻居 Chris Van Dyke 和 Shruti Gandhi (https://twitter.com/atShruti) 在我的车库里听我解释 Deep Dream 实现的时候。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1486617601OH61tr.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;span style="font-size: 12px; color: rgb(136, 136, 136);"&gt;&lt;em&gt;图 5. 我的朋友 Barney Pell 与他的国际象棋生日蛋糕&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1486617601DvUQig.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;em&gt;&lt;span style="font-size: 12px; color: rgb(136, 136, 136);"&gt;图 6. 这里是我的机器在 Deep Dream 它自己的一幅图片上运行！它看到到处都是狗（可能是因为模型的训练数据 ImageNet 全是狗，因为创作者包含了 120 个单独品种的示例图像）。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;如果你想要更疯一点，这有一个通过 TensorFlow 实现的神经风格（Neural Style）(https://github.com/anishathalye/neural-style)，基于 Deep Dream，可以做更多的惊人的事情，其中一些在这个令人兴奋的博客文章中 (http://genekogan.com/works/style-transfer/) 概述。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;结论&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px; text-align: justify;"&gt;你不需要花费数千美元来获得一个比你的笔记本电脑快得多的深度学习盒子。而且构建计算机并让一切运行它是一个很棒的学习经验，况且你还得到一台可升级的机器。我现在已经换成了一个具有相同架构的 Titan X 显卡，并且一切运行良好不用重新编译。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;总而言之，这是一个胜利：这台机器运行速度与使用 K80 GPU 的 1 美元/小时的 Amazon P2 实例大致相同，具有更多的内存和较旧的架构。我大部分时候用它来训练模型，这也是这种方法真正炫的地方——也许这是一个后续博客的话题了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 14px;"&gt;原文链接：https://www.oreilly.com/learning/build-a-super-fast-deep-learning-machine-for-under-1000&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal; max-width: 100%; min-height: 1em; text-align: justify; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; line-height: 25.6px; font-family: 微软雅黑; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; font-style: normal; color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; font-style: normal; color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;©本文由机器之心编译，&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; font-style: normal; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; white-space: normal; max-width: 100%; min-height: 1em; font-size: 18px; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(127, 127, 127); line-height: 25.6px; font-family: 微软雅黑; text-align: justify; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; white-space: normal; max-width: 100%; min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(217, 33, 66); font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal; max-width: 100%; min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(217, 33, 66); line-height: 1.6; font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal; max-width: 100%; min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; font-size: 12px; color: rgb(217, 33, 66); line-height: 1.6; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/div&gt;</description>
      <pubDate>Thu, 09 Feb 2017 12:40:23 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 百度PaddlePaddle联手Kubernetes，助力开发者高效训练深度学习模型</title>
      <link>http://www.iwgc.cn/link/4630846</link>
      <description>&lt;div class="article-content"&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;section style="font-size: 16px; white-space: normal; max-width: 100%; color: rgb(62, 62, 62); background-color: rgb(255, 255, 255); line-height: 28.4444px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%; border-width: 0px; border-style: initial; border-color: currentcolor; font-family: 微软雅黑; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; max-width: 100%; border-style: solid none; font-family: inherit; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-top: -1.2em; max-width: 100%; min-height: 1em; font-size: 1em; border-width: initial; border-style: initial; border-color: currentcolor; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; background-color: rgb(117, 117, 118); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;选自Kubernetes等&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px; max-width: 100%; font-family: inherit; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-top: 5px; margin-bottom: 5px; max-width: 100%; min-height: 1em; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(127, 127, 127); font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;参与：吴攀、李亚洲、蒋思源&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 12px;"&gt;2016 年 9 月，百度开源了深度学习框架 PaddlePaddle，今天，百度又宣布实现了这一框架和集群管理系统（cluster management system）Kubernetes 的兼容，从而使 PaddlePaddle 成为了迄今为止唯一一个官方支持 Kubernetes 的框架。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;据百度研究官网介绍，这种兼容性将使得开发者可以很方便地在全球所有主要的云服务提供商（包括百度云和企业内部的集群（on-premise clusters））上训练大型的模型。该项目是由百度和 CoreOS 联合开发的；CoreOS 是 Kubernetes 的主要贡献者之一。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;开发者通常会将人工智能程序与网络服务、日志收集器和数据处理器一起联合部署在同一个通用的集群上，以实现高效的数据流程（data pipelines）。为了管理这个过程，开发者就会用到 Kubernetes 这样的工具；Kubernetes 是现在最复杂精细的通用集群管理系统之一。通过使 PaddlePaddle 与 Kubernetes 兼容，开发者现在可以用它们开发高效的深度学习驱动的应用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;「使用 Kubernetes 这样的框架，开发者再也不用担心为了在一个标准云平台上配置和部署深度学习训练系统而编写不必要的代码。」PaddlePaddle 项目技术负责人 Yi Wang 说，「这最终能帮助他们更快地将他们的项目落地。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Kubernetes 可将 PaddlePaddle 中需要 GPU 的工作和需要其它资源（如大型存储或磁盘 I/O 流通）的工作封装到同一套物理计算机上，从而可以充分利用集群硬件。而且当白天存在许多活跃用户时，它还会自动扩展其在线服务，而到了夜间用户较少时它又会释放出一些资源。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;PaddlePaddle 是一个源于百度的易用的深度学习框架，已经在百度的许多产品和技术中得到了应用，其中包括搜索排序和机器翻译。据介绍，该框架非常适合用于训练循环神经网络，从而使其可以高效地被应用在自然语言理解、语音和多媒体等应用中。百度声称，自去年 9 月开源之后，PaddlePaddle 已经成为了现在增长最快的深度学习框架之一。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;关于在 Kubernetes 上运行 PaddlePaddle 的更多细节，可在下面的介绍文章中了解（下文作者为 Baidu Research 的 Yi Wang 和 CoreOS 的 Xiang Li）。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1486617603b4tpQP.jpg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;什么是 PaddlePaddle&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;PaddlePaddle 是一个易于使用、高效、灵活和可扩展的深度学习平台，该平台最初是由百度在 2014 年为其产品应用深度学习而开发的。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;现在已经使用 PaddlePaddle 的创新已经超过了 50 项，并支持包括搜索引擎、在线广告、Q＆A 和系统安全等 15 项百度产品。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;2016 年 9 月，百度开源了 PaddlePaddle，并且很快就吸引了很多来自百度外的参与者。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;为什么要在 Kubernetes 上运行 PaddlePaddle&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;PaddlePaddle 是被工程师们设计成精简且不依赖于计算基础设备的深度学习平台。用户可以在 Hadoop、Spark、Mesos、Kubernetes 和其他平台上运行它。我们对 Kubernetes 有很强烈的兴趣，因为它的适应性、高效性等丰富的特点。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;当我们将 PaddlePaddle 应用于百度的各种产品时，我们注意到 PaddlePaddle 的两种主要用法——研究和产品。用于研究的数据并不会经常性地变动，重点是快速地实验以达到预期的科学度量。而应用于产品的数据会经常性地变动，它通常来自网页服务而产生的日志信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;一个成功的深度学习项目包括了研究和数据处理流程（pipeline）。因为有很多参数需要调整，许多工程师在整个项目的不同部分同时工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;为了确保项目易于管理且能高效利用硬件资源，我们希望能将项目的所有部分运行在同一个基础平台之上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;这样的平台需要提供：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;容错性（fault-tolerance）。它应该将流程（pipeline）的每一个阶段摘取为一个服务，并且这些服务包含了许多过程，这样的冗余能够提供高流通量（high throughput）和鲁棒性。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;自动扩展（auto-scaling）。在白天，通常有许多活跃用户，因此平台就需要能向外扩展其在线服务。而到了晚上，平台就需要释放一些资源进行深度学习试验。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;工作封装和隔离（job packing and isolation）。平台需要能够为 PaddlePaddle 训练器过程（trainer process）分配要求的 GPU、需要大内存的网络后端服务和需要磁盘吞吐量的 CephFS 过程，并且保证相同的节点充分利用其硬件资源。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;我们想要的是一个能在同一个集群上运行深度学习系统、网页服务器（如 Nginx）、日志收集器（如 fluentd）、分布式队列服务（如 Kafka）、日志加入器（log joiner）和使用 Storm、 Spark、Hadoop MapReduce 编写的其他数据处理器的平台。我们希望所有的工作（线上线下、产品和实验）都能在同一个集群上运作，这样我们才能充分利用集群，因为不同的工作需要不同的硬件资源。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;我们选择的是基于容器（container based）的解决方案，因为由虚拟机（VM）引入的总开销与我们的高效、实用这一目标相矛盾。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;基于我们对不同的基于容器（container based）解决方案的研究，Kubernetes 最符合我们的要求。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;在 Kubernetes 上的分布式训练&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;PaddlePaddle 本就支持分布式训练，在 PaddlePaddle 集群中有两个角色：参数服务器（parameter server）和训练器（trainer）。每个参数服务器处理包含全局模型的一部分，每个训练器有该模型的局部复制，并且使用它的局部数据更新该模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;在训练的过程中，训练器将模型更新信息发送到参数服务器，参数服务器负责聚集这些更新，以便于训练器能够能够与全局模型同步它们的本地复制版本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/148661760392rmOM.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;em&gt;&lt;span style="font-size: 12px; color: rgb(136, 136, 136);"&gt;图 1：模型被划分为两个分片（shard），分别由两个参数服务器管理。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;一些其他的方法使用一系列参数服务器在多台主机的 CPU 存储空间中一起存储一个非常大型的模型。但在实际中，我们通常没有这么大的模型，因为由于 GPU 的存储限制，处理特别大的模型是效率低下的。在我们的配置中，多参数服务器大部分是为了快速通信。假设只有一个参数服务器处理与所有的训练器一起工作，参数服务器要聚集来自所有训练器的梯度，这是一个瓶颈。在我们的经验中，经实验验证的有效配置包括同样数量的训练器和参数服务器。我们通常在同样的节点上运行一对训练器和参数服务器。在下面的 Kubernetes 配置中，我们启动了一个运行了 N 个 pod 的工作，其中每个 pod 中都有一个参数服务器和一个训练器。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="  ;; background-color: transparent; color: black; font-size: 10pt; vertical-align: baseline; white-space: pre-wrap; "&gt;yaml&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="  ;; background-color: transparent; color: black; font-size: 10pt; vertical-align: baseline; white-space: pre-wrap; "&gt;apiVersion: batch/v1&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="  ;; background-color: transparent; color: black; font-size: 10pt; vertical-align: baseline; white-space: pre-wrap; "&gt;kind: Job&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="  ;; background-color: transparent; color: black; font-size: 10pt; vertical-align: baseline; white-space: pre-wrap; "&gt;metadata:&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="  ;; background-color: transparent; color: black; font-size: 10pt; vertical-align: baseline; white-space: pre-wrap; "&gt; &amp;nbsp;name: PaddlePaddle-cluster-job&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="  ;; background-color: transparent; color: black; font-size: 10pt; vertical-align: baseline; white-space: pre-wrap; "&gt;spec:&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="  ;; background-color: transparent; color: black; font-size: 10pt; vertical-align: baseline; white-space: pre-wrap; "&gt; &amp;nbsp;parallelism: 3&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="  ;; background-color: transparent; color: black; font-size: 10pt; vertical-align: baseline; white-space: pre-wrap; "&gt; &amp;nbsp;completions: 3&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="  ;; background-color: transparent; color: black; font-size: 10pt; vertical-align: baseline; white-space: pre-wrap; "&gt; &amp;nbsp;template:&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="  ;; background-color: transparent; color: black; font-size: 10pt; vertical-align: baseline; white-space: pre-wrap; "&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;metadata:&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="  ;; background-color: transparent; color: black; font-size: 10pt; vertical-align: baseline; white-space: pre-wrap; "&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;name: PaddlePaddle-cluster-job&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="  ;; background-color: transparent; color: black; font-size: 10pt; vertical-align: baseline; white-space: pre-wrap; "&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;spec:&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="  ;; background-color: transparent; color: black; font-size: 10pt; vertical-align: baseline; white-space: pre-wrap; "&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;volumes:&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="  ;; background-color: transparent; color: black; font-size: 10pt; vertical-align: baseline; white-space: pre-wrap; "&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;- name: jobpath&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="  ;; background-color: transparent; color: black; font-size: 10pt; vertical-align: baseline; white-space: pre-wrap; "&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;hostPath:&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="  ;; background-color: transparent; color: black; font-size: 10pt; vertical-align: baseline; white-space: pre-wrap; "&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;path: /home/admin/efs&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="  ;; background-color: transparent; color: black; font-size: 10pt; vertical-align: baseline; white-space: pre-wrap; "&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;containers:&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="  ;; background-color: transparent; color: black; font-size: 10pt; vertical-align: baseline; white-space: pre-wrap; "&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;- name: trainer&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="  ;; background-color: transparent; color: black; font-size: 10pt; vertical-align: baseline; white-space: pre-wrap; "&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;image: your_repo/paddle:mypaddle&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="  ;; background-color: transparent; color: black; font-size: 10pt; vertical-align: baseline; white-space: pre-wrap; "&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;command: ["bin/bash", &amp;nbsp;"-c", "/root/start.sh"]&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="  ;; background-color: transparent; color: black; font-size: 10pt; vertical-align: baseline; white-space: pre-wrap; "&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;env:&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="  ;; background-color: transparent; color: black; font-size: 10pt; vertical-align: baseline; white-space: pre-wrap; "&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;- name: JOB_NAME&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="  ;; background-color: transparent; color: black; font-size: 10pt; vertical-align: baseline; white-space: pre-wrap; "&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;value: paddle-cluster-job&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="  ;; background-color: transparent; color: black; font-size: 10pt; vertical-align: baseline; white-space: pre-wrap; "&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;- name: JOB_PATH&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="  ;; background-color: transparent; color: black; font-size: 10pt; vertical-align: baseline; white-space: pre-wrap; "&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;value: /home/jobpath&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="  ;; background-color: transparent; color: black; font-size: 10pt; vertical-align: baseline; white-space: pre-wrap; "&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;- name: JOB_NAMESPACE&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="  ;; background-color: transparent; color: black; font-size: 10pt; vertical-align: baseline; white-space: pre-wrap; "&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;value: default&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="  ;; background-color: transparent; color: black; font-size: 10pt; vertical-align: baseline; white-space: pre-wrap; "&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;volumeMounts:&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="  ;; background-color: transparent; color: black; font-size: 10pt; vertical-align: baseline; white-space: pre-wrap; "&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;- name: jobpath&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="  ;; background-color: transparent; color: black; font-size: 10pt; vertical-align: baseline; white-space: pre-wrap; "&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;mountPath: /home/jobpath&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="  ;; background-color: transparent; color: black; font-size: 10pt; vertical-align: baseline; white-space: pre-wrap; "&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;restartPolicy: Never&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;我们能从配置中看到，并行和实现都被设定为 3。所以该工作将同步启动 3 个 PaddlePaddle pod，而且在所有的 3 个 pod 结束后运行的工作才会结束。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1486617604yqPLdb.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 12px;"&gt;图片 2：运行在 2 个节点上的 3 个 pod 的 Job A 和 1 个 pod 的 Job B&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;每个 pod 的入口是 start.sh。它从一个存储服务下载数据，所以训练器可以从 pod 本地的磁盘空间快速读取。下载完成之后，其会运行一个 Python 脚本 start_paddle.py，该脚本会启动一个参数服务器，然后等待所有 pod 的参数服务器都为使用做好准备，之后再启动该 pod 中的训练器过程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;这里的等待是必需的，因为每个训练器都需要与所有的参数服务器进行通信（如图 1）。Kubernetes API 使训练器能够检查 pod 的状态，所以该 Python 脚本可以等待，直到所有的参数服务器的状态都改为「running」，然后它才会触发训练过程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;目前，从数据分片（data shards）到 pods/trainers 的映射是静态的。如果我们要运行 N 个训练器，我们需要将数据分割成 N 个分片，并将每个数据分片静态地分配给训练器。同样我们依赖于 Kubernetes API 来获取工作中的 pods，因此我们可以将 pods / trainers 从 1 到 N 建立索引。第 i 个训练器将读取第 i 个数据分段。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;训练数据通常是在一个分布式文件系统上提供的。我们实际上在我们的企业内集群上使用了 CephFS，在 AWS 上使用了 Amazon Elastic File System。如果你对构建 Kubernetes 集群来运行分布式 PaddlePaddle 训练工作感兴趣，请参考这个教程：https://github.com/PaddlePaddle/Paddle/blob/develop/doc/howto/usage/k8s/k8s_aws_en.md&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;未来&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;我们正在努力让 PaddlePaddle 能够在 Kubernetes 上运行得更加顺畅。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;你可能已经注意到，当前的训练器调度（trainer scheduling）完全依赖于基于静态分区图（static partition map）的 Kubernetes。这种方法开始是很简单，但也可能会导致一些效率问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;首先，缓慢或死亡的训练器会终止整个工作。在初始部署之后就没有什么受控的优先权（preemption）或重新调度（rescheduling）了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;其次，其资源配置是静态的。所以如果 Kubernetes 有比我们预计的更多的资源，那么我们就必须手动修改其资源要求。这是一个非常繁重的工作，与我们的效率和实用的目标不一致。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;为了解决上述问题，我们将添加一个理解 Kubernetes API 的 PaddlePaddle master，其可以动态地添加/移除资源量，并且可以以一种更加动态的方式为训练器处理分片（shard）。该 PaddlePaddle master 使用 etcd 作为从分片到训练器的动态映射的容错存储。因此，即使该 master 崩溃，该映射也不会丢失。Kubernetes 可以重启该 master，然后该工作将会继续运行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;另一个潜在的提升是更好的 PaddlePaddle 工作配置（job configuration）。我们的有相同数量的训练器和参数服务器的经验大多数都收集自在专用集群（special-purpose clusters）上的应用。据我们观察，这种策略在我们客户的仅运行 PaddlePaddle 工作的集群上是高性能的。但是，这种策略可能在能够运行许多种工作的通用集群上并不是最优的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;PaddlePaddle 训练器可以利用多个 GPU 来加速计算。GPU 目前还不是 Kubernetes 中的首选资源。我们还必须半人工地管理 GPU。我们期望能与 Kubernetes 社区一起提升 GPU 支持，以确保 PaddlePaddle 能在 Kubernetes 上实现最佳的表现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;资源&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Kubernetes：http://get.k8s.io/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;本 Kubernetes 项目的 GitHub：https://github.com/kubernetes/kubernetes&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Stack Overflow 问题讨论：http://stackoverflow.com/questions/tagged/kubernetes&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Slack 社区：http://slack.k8s.io/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal; max-width: 100%; min-height: 1em; text-align: justify; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; line-height: 25.6px; font-family: 微软雅黑; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; font-style: normal; color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; font-style: normal; color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;©本文由机器之心编译，&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; font-style: normal; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; white-space: normal; max-width: 100%; min-height: 1em; font-size: 18px; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(127, 127, 127); line-height: 25.6px; font-family: 微软雅黑; text-align: justify; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; white-space: normal; max-width: 100%; min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(217, 33, 66); font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal; max-width: 100%; min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(217, 33, 66); line-height: 1.6; font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal; max-width: 100%; min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; font-size: 12px; color: rgb(217, 33, 66); line-height: 1.6; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/div&gt;</description>
      <pubDate>Thu, 09 Feb 2017 12:40:23 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 英特尔推出用于Apache Spark的深度学习库</title>
      <link>http://www.iwgc.cn/link/4630847</link>
      <description>&lt;div class="article-content"&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 12px;"&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section style="max-width: 100%; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; background-color: rgb(255, 255, 255); line-height: 28.4444px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%; border-width: 0px; border-style: initial; border-color: currentcolor; font-family: 微软雅黑; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; max-width: 100%; border-style: solid none; font-family: inherit; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-top: -1.2em; max-width: 100%; min-height: 1em; font-size: 1em; border-width: initial; border-style: initial; border-color: currentcolor; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; background-color: rgb(117, 117, 118); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;选自Intel&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px; max-width: 100%; font-family: inherit; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-top: 5px; margin-bottom: 5px; max-width: 100%; min-height: 1em; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(127, 127, 127); font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;参与：黄小天、朱思颖&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 12px;"&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 12px;"&gt;英特尔今天宣布推出开源 BigDL，一个用于 Apache Spark 开源集群计算框架的分布式深度学习库。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;深度学习库是英特尔公司在行业中实现最先进的人工智能战略的一部分。在去年 11 月宣布的公司战略，详细介绍了英特尔所做的工作——通过旗下的人工智能学院（Intel® Nervana™）使人工智能训练和工具被更广泛的开发人员所获取。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;BigDL 具有基于 Spark 架构的高效大规模分布式深度学习库，使大数据用户和数据科学家更容易获得深度学习。BigDL 使得 AI 专家能够像在数百个领域的数千个应用程序中工作的数据科学家一样研究数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;BigDL 还可以作为用于数据存储、处理和挖掘、特征工程以及机器和深度学习工作量等的统一数据分析平台（Hadoop / Spark）。它允许开发人员将深度学习应用程序编写为在现有 Spark 或 Hadoop 集群之上运行的标准 Spark 程序，以使深度学习工作量与他们使用的数据更直接地接触。BigDL 已经在 Databricks Spark 平台上运行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;英特尔软件与服务部高级副总裁兼总经理 Doug Fisher 说：「BigDL 是一个开源项目，我们鼓励所有开发人员在 BigDL Github 上与我们联系，采样代码并为项目做出贡献。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;BigDL：&lt;strong style="text-align: center;"&gt;在 Apache Spark 上的分布式深度学习&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;BigDL 是一个为 Apache Spark 而建的分布式深度学习库；通过 BigDL，用户能够以标准的 Spark 程序编写深度学习应用，并能直接在现有的 Spark 或 Hadoop 集群上运行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;丰富的深度学习支持。BigDL 是在 Torch 之后搭建的模型，为深度学习提供全面支持，包括经由 Tensor 的数字计算和高级神经网络；此外，用户还可以通过使用 BigDL 把 Caffe 或 Torch 里预训练的模型加载到 Spark 程序中。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;极其完美的运行表现。为了获取非常好的运行表现，在每个 Spark 任务中 BigDL 使用因特尔 MKL 和多线编程。因此，在单个节点的至强（Xeon，与主流 GPU 比较）处理器上的处理比即用部署的开源框架 Caffe、Torch 以及 TensorFlow 有量级上的提升。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;高效的横向扩展性能。BigDL 能高效的进行横向扩展从而实现大数据的数据分析，通过发布 Apache Spark（快如闪电般的分布式数据处理框架），以及 Spark 上有效实施的同步 SGD 和全局归约交流机制。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;为什么是 BigDL?&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;你也许想用 BigDL 写一些深度学习程序如果：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;你想要在存储数据（例如 HDFS，HBase，Hive 等）的相同大数据（Hadoop / Spark）集群上分析大量数据。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;你想要为你的大数据（Spark）程序和/或工作流程添加深度学习功能（训练或预测）。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;你想要利用现有的 Hadoop / Spark 集群来运行深度学习应用程序，然后可以与其他工作量（例如 ETL、数据仓库、特性工程、经典机器学习、图形分析等）动态共享。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;怎样使用 BigDL？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;想学习如何安装和搭建 BigDL（Linux 和 macOS 上的安装），你可以查阅构建文档（Build Page）。链接：https://github.com/intel-analytics/BigDL/wiki/Build-Page&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;想学习如何运行 BigDL 程序（运行一个局部 Java 程序或者 Spark 程序），你可以查阅开始指导页面（Getting Started Page）。链接：https://github.com/intel-analytics/BigDL/wiki/Getting-Started&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;想在 EC2 上尝试使用 BigDL，你可以查阅在 EC2 上运行的页面（Running on EC2 Pages）。链接：https://github.com/intel-analytics/BigDL/wiki/Running-on-EC2&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;想在几分钟内学到如何通过 BigDL 创建实用的神经网络，你可以查阅教程页面（Tutorial Page）。链接：https://github.com/intel-analytics/BigDL/wiki/Tutorials&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;更多细节内容，可以在说明文档中查阅（Documents Page），说明文档包含教程、范例、编程指南等内容。链接：https://github.com/intel-analytics/BigDL/wiki/Documents&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;支持&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;你可以加入 BigDL 谷歌网上论坛（https://groups.google.com/forum/#!forum/bigdl-user-group）（或订阅邮件列表：bigdl-user-group+subscribe@googlegroups.com）以获得更多关于 BigDL 的问题和讨论。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;你可以在问题页面上发布错误报告和功能请求。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="color: rgb(123, 12, 0); font-size: 14px;"&gt;GitHub 资源：https://github.com/intel-analytics/BigDL&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="max-width: 100%; min-height: 1em; text-align: justify; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; line-height: 25.6px; font-family: 微软雅黑; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; font-style: normal; color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; font-style: normal; color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;©本文由机器之心编译，&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; font-style: normal; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; max-width: 100%; min-height: 1em; font-size: 18px; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(127, 127, 127); line-height: 25.6px; font-family: 微软雅黑; text-align: justify; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; max-width: 100%; min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(217, 33, 66); font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="max-width: 100%; min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(217, 33, 66); line-height: 1.6; font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="max-width: 100%; min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; font-size: 12px; color: rgb(217, 33, 66); line-height: 1.6; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/div&gt;</description>
      <pubDate>Thu, 09 Feb 2017 12:40:23 +0800</pubDate>
    </item>
    <item>
      <title>资讯 | 沈向洋、Yann LeCun 等人当选美国工程院院士</title>
      <link>http://www.iwgc.cn/link/4630848</link>
      <description>&lt;div class="article-content"&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;section style="max-width: 100%; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; background-color: rgb(255, 255, 255); line-height: 28.4444px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%; border-width: 0px; border-style: initial; border-color: currentcolor; font-family: 微软雅黑; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; max-width: 100%; border-style: solid none; font-family: inherit; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-top: -1.2em; max-width: 100%; min-height: 1em; font-size: 1em; border-width: initial; border-style: initial; border-color: currentcolor; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(255, 255, 255); max-width: 100%; background-color: rgb(117, 117, 118); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;机器之心报道&lt;/span&gt;&lt;/p&gt;&lt;section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px; max-width: 100%; font-family: inherit; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-top: 5px; margin-bottom: 5px; max-width: 100%; min-height: 1em; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(127, 127, 127); font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;编辑：李泽南、杜夏德&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;美国国家工程院于 2 月 8 日宣布了 2017 年新晋院士名单，微软全球执行副总沈向洋作为外籍院士名列其中。沈向洋博士现主管微软技术与研发部门，因在计算机视觉与图形学的突出贡献、以及在业界的研发和领导力而当选。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;此外，还要恭喜 Facebook 的研究负责人Yann&amp;nbsp;LeCun，同样当选今年的美国工程院院士。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1486617607LD2YpX.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 12px;"&gt;微软全球执行副总沈向洋&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;本期美国工程院院士共有 84 名院士、22 名外籍院士当选，名单中出现了包括沈向洋、黄永刚、张东晓在内的多名华人学者。目前，美国工程院总院士数为 2281 人，另有 249 名外籍院士。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;美国国家工程院院士以「工程研究、实践、教育，对工程学科做出重大贡献，以及开拓新的技术领域，或在传统领域取得重大进步」为标准评选，是美国工程师的最高荣誉。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;这 106 名新晋院士将于今年 10 月 8 日于华盛顿举行的美国工程院年会上正式当选。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;除了美国工程院院士，沈向洋还于&amp;nbsp;2006 年当选为国际计算机协会（ACM）院士，当时沈当选的理由就是他「对计算机视觉和计算机图形学所作出的贡献」。而在这之前，他还被评为美国电气电子工程协会（IEEE）的院士。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;沈向洋出生于江苏省，本科毕业于东南大学，后获得香港大学电机电子工程系硕士学位；研究生毕业后，沈向阳进入了卡内基梅隆大学计算机学院，师从 Raj Reddy 教授，1996 年获 CMU 计算机学院机器人专业博士学位。值得一提的是，去年 10 月，微软任命沈向阳为公司人工智能和研究团队总负责人。&lt;/span&gt;&lt;/p&gt;&lt;p style="white-space: normal; text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;美国西北大学的黄永刚教授因在可伸展电子器件力学及机械引导三维自组装方面的先驱工作当选。黄永刚教授出生于力学世家，毕业于北京大学，其父是清华大学教授黄克智院士，父子二人均为国际固体力学领域的领袖人物。黄教授也是继锁志刚、高华健之后近年第三位当选美国工程院院士的华人固体力学家。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1486617607VNc8Ay.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="text-align: justify; font-size: 12px;"&gt;黄永刚&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;张东晓教授现任北京大学工学院院长，因在多孔介质流体随机模拟的先驱工作而当选。张东晓教授本科毕业于东北大学，曾在美国南加州大学和奥克拉荷马大学任职，入选「千人计划」，协助陈十一教授创办北京大学工学院。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/148661760880plNL.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 12px;"&gt;张东晓&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;今日当选的华人学者，还有伯克利的 Tsu-Jae King Liu 教授、UCLA 的 Jingsheng Cong 教授，两人均担任校级行政职务。另外，还有伦斯勒理工学院（RPI）的周祖康教授\通用电气副总裁陈向力, 和太平洋西北国家实验室资深研究员 Lai-yung Ruby Leung。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px; color: rgb(136, 136, 136);"&gt;完整名单请点击「&lt;span style="color: rgb(136, 136, 136); font-size: 14px; text-align: justify;"&gt;阅读原文&lt;/span&gt;」查看&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="max-width: 100%; min-height: 1em; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; line-height: 25.6px; font-family: 微软雅黑; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; font-style: normal; color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; font-style: normal; color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;©本文由机器之心编辑，&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; font-style: normal; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; max-width: 100%; min-height: 1em; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); font-size: 18px; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(127, 127, 127); line-height: 25.6px; font-family: 微软雅黑; text-align: justify; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; max-width: 100%; min-height: 1em; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(217, 33, 66); font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="max-width: 100%; min-height: 1em; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(217, 33, 66); line-height: 1.6; font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="max-width: 100%; min-height: 1em; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; font-size: 12px; color: rgb(217, 33, 66); line-height: 1.6; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/div&gt;</description>
      <pubDate>Thu, 09 Feb 2017 12:40:23 +0800</pubDate>
    </item>
    <item>
      <title>学界 | 让卷积神经网络变得商业可行，新论文提出WR-Inception网络</title>
      <link>http://www.iwgc.cn/link/4630849</link>
      <description>&lt;div class="article-content"&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;section style="font-size: 16px; white-space: normal; max-width: 100%; color: rgb(62, 62, 62); background-color: rgb(255, 255, 255); line-height: 28.4444px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%; border-width: 0px; border-style: initial; border-color: currentcolor; font-family: 微软雅黑; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; max-width: 100%; border-style: solid none; font-family: inherit; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-top: -1.2em; max-width: 100%; min-height: 1em; font-size: 1em; border-width: initial; border-style: initial; border-color: currentcolor; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(255, 255, 255); max-width: 100%; background-color: rgb(117, 117, 118); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;选自arXiv&lt;/span&gt;&lt;/p&gt;&lt;section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px; max-width: 100%; font-family: inherit; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-top: 5px; margin-bottom: 5px; max-width: 100%; min-height: 1em; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(127, 127, 127); font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;参与：高静宜&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;卷积神经网络（CNN）对计算成本的要求一直以来都让其在嵌入式或移动平台上的商业应用举步维艰，近日，韩国仁荷大学的研究者提出了一种有望解决这一难题的「WR-Inception」，引起了广泛关注。本文是对其研究论文的摘要介绍，原论文请点击文末「阅读原文」查看。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1486617609ZRgcEC.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;br&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;摘要&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;自卷积神经网络（CNN）模型出现以来，许多计算机视觉领域的任务都可以有效利用 CNN 模型实现特征提取。然而，传统的 CNN 模型计算成本较大并且对内存容量要求较高，这使得一些商业应用变得不切实际和难以承受，如基于嵌入式开发板或移动平台完成路实时路面物体检测。为了克服 CNN 模型的这个短板，这篇论文提出了一种宽残差-Inception（Wide-Residual-Inception 又 WR-Inception）网络，其架构的构建基于一种Residual Inception Unit，这种单元能够在相同的特征映射中捕捉各种尺寸的对象。与类似于 ResNet 的目前位于先进水平的网络相比，它具有更浅更宽的层次。为了验证所提出的这个网络，这篇论文阐述了两个实验：一个是基于 CIFAR-10/100 的分类任务，另一个是在 KITTI 数据集上利用 Single-Shot Multi-box Detector(SSD) 完成路面物体检测任务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;背景&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;时下关于人工智能的研究十分活跃，成果也层出不穷，在这个大环境下，基于深度神经网络（DNN）的人工智能已经被灵活地应用于社会生活的方方面面，而且现在的趋势是这样的技术可能在更多的领域中被需求着。特别是自从卷积神经网络（CNN 或 ConvNet）出现，计算机视觉新技术逐步替代了传统的计算机视觉技术。CNN 模型不仅增强了图片分类器的精确度，而且在物体检测，语义分割，深度估算等领域使用了通用特征提取器。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;然而，CNN 技术需要大量的计算成本和内存，为了训练和有效地利用这个方法，需要使用很高端的硬件系统。另外，对于先进驾驶员辅助系统（ADAS）或自驾车来说，实时处理也需要超级计算机才能完成。因此，研究 CNN 模型的优化是十分必须的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;为了克服这些难题，这项研究提出了 Wide-Residual-Inception 网络，它与最新的深度神经网络具有相似的性能却需要更少的计算量和存储负担。这项研究具有以下三点创新：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;1. 提出了 WR-Inception 网络模型，它需要较少内存和计算量；&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;2. 与目前技术发展水平相应的网络模型相比，它可以在物体检测的特征提取上实现更好的性能；&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;3. 有能力在嵌入式开发板中实时进行基于 DNN 的物体探测。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;Wide-Residual-Inception 网络&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;从下图可以看出，模型的性能是与网络的深度有着正相关的趋势，而网络深度的加深，有可能造成梯度消失问题和过拟合问题导致性能大幅度下降。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1486617609IB0Wnm.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 12px;"&gt;图 1：各网络精度及深度关系的比较&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;残差网络（ResNets）利用「跳过连接」这样的方式来解决梯度消失问题。具体来说就是跳过卷积层来帮助梯度通过旁支度过重层，形成一个近路残差块即残差单位，如图 2（a）。可是深度残差网络还是需要大量的计算成本和容量的。那么，找到网络合适的深度和结构就很迫在眉睫了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1486617610AsRNfd.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 12px;"&gt;图 2：各种残差单元&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;一个网络有三个要素：深度，宽度和过滤器尺寸，宽残差网络（Wide-Residual Network）利用减少残差网络深度，增加网络宽度的方式，保留了残差网络具有近路残差块的特点。在此基础上，在 Inception Module 增加级联运算，如图 2（c），使各分支合成一个独立的张量，可以加强特征映射空间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;我们提出的 Wide-Residual-Inception 网络是将 Residual-Inception 单元应用于宽残差网络中。另外，我们可以调整卷积过滤器的数目从而得到不同版本的 WR-Inception 网络。下图是几种网络结构的宏观图：&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1486617610MF4Zrp.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 12px;"&gt;图 3：三种网络结构的比较&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;从下表可以更清晰地看出 Residual-Inception 各单元内容&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1486617610ibA5wv.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;span style="font-size: 12px; color: rgb(136, 136, 136);"&gt;表 1：各网络结构&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;针对物体检测的迁移学习（Transfer Learning）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;ConvNet 的最重要的优势之一就是它可以提取优良的特征代表，我们利用迁移学习来完成我们的两个实验，其流程图如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1486617610FyXSki.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 12px;"&gt;图 4：迁移学习的流程图&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;总结&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;这篇论文提出了 Wide-Residual-Inception 网络来弥补现存网络模型的不足。通过两个实验数据可以证明，这个网络模型在环境资源有限的条件下，如嵌入式开发板或移动平台上是十分经济且有效的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/148661761070pkMK.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;&lt;em&gt;&lt;span style="color: rgb(136, 136, 136); text-align: justify;"&gt;图 5：各网络模型在 NVIDIA Jetson TX1 嵌入式板上执行任务的参数比较&lt;/span&gt;&lt;br&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1486617611WOd9Bz.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 12px;"&gt;表 2：Test error（%）on CIFAR-10/100 by different networks&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1486617611LE3Yqo.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 12px;"&gt;表 3 Average precision（%）&amp;amp; Average recall（%）on KITTI validation set（mAP=Average Precision()）&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;未来，我们可以寄希望于本文提出的网络模型在计算机视觉领域内有更广发的应用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="white-space: normal; max-width: 100%; min-height: 1em; text-align: justify; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; line-height: 25.6px; font-family: 微软雅黑; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; font-style: normal; color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; font-style: normal; color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;©本文由机器之心编译，&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; font-style: normal; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; white-space: normal; max-width: 100%; min-height: 1em; font-size: 18px; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(127, 127, 127); line-height: 25.6px; font-family: 微软雅黑; text-align: justify; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; white-space: normal; max-width: 100%; min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(217, 33, 66); font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal; max-width: 100%; min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(217, 33, 66); line-height: 1.6; font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="white-space: normal; max-width: 100%; min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; font-size: 12px; color: rgb(217, 33, 66); line-height: 1.6; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/div&gt;</description>
      <pubDate>Thu, 09 Feb 2017 12:40:23 +0800</pubDate>
    </item>
    <item>
      <title>谷歌发布深度学习库TensorFlow Fold，支持动态计算图</title>
      <link>http://www.iwgc.cn/link/4615827</link>
      <description>&lt;div class="article-content"&gt;&lt;section style="white-space: normal; line-height: 28.4444px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="border: 0px currentcolor; font-family: 微软雅黑; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; border-style: solid none; font-family: inherit; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="font-size: 1em; margin-top: -1.2em; min-height: 1em; border: currentcolor; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color:#ffffff"&gt;&lt;span style="background-color: rgb(117, 117, 118);"&gt;选自Google Research&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="background-color: rgb(255, 255, 255); padding: 16px 16px 10px; font-family: inherit; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="color: rgb(62, 62, 62); font-size: 16px; margin-top: 5px; margin-bottom: 5px; min-height: 1em; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(127, 127, 127); font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;作者：Moshe Looks、Marcello Herreshoff、DeLesley Hutchins&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-top: 5px; margin-bottom: 5px; min-height: 1em; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color:#7f7f7f"&gt;&lt;span style="font-size: 12px;"&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="color: rgb(62, 62, 62); font-size: 16px; margin-top: 5px; margin-bottom: 5px; min-height: 1em; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(127, 127, 127); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important; font-size: 12px;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;参与：李亚洲、朱思颖&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style="min-height: 1em; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; text-align: justify; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;br style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;在大部分的机器学习过程中，用于训练 (training) 和推理 (inference) 的数据都需要进行数据的预处理，通过预处理将不同的输入数据（例如图像）规整至相同尺寸并进行批（batch）存储。这一步使高性能的深度学习库，例如 TensorFlow，可以并行的处理批存储中的所有输入，且以相同的计算图（computation graph）进行处理。批处理（Batching）利用现代 GPU 和多核 CPU 的单指令流多数据流（SIMD）性能来加速运算执行。但是，当输入数据的尺寸和结构变化时会产生诸多问题，例如在自然语言理解中的解析树（parse tree）、源代码中的抽象语法树（abstract syntax tree）、网页的文档树（DOM tree）等。在这些情况下，不同的输入数据需要不同的计算图，通常这些计算图不能够批存储在一起，导致处理器、存储器以及缓存利用率低。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;今天我们发布 TensorFlow Fold 来解决这些困难。TensorFlow Fold 使得处理不同数据尺寸和结构的深度学习模型更容易实现。不仅如此，TensorFlow Fold 将批处理的优势赋予这些模型，使得这些模型在 CPU 上的运行速度有超过 10 倍的提升，在 GPU 上的运行有超过 100 倍的提升（相比于其他实现方式）。这一提升来源于动态批存储（dynamic batching）技术，在我们的论文中有详细介绍（Deep Learning with Dynamic Computation Graphs）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1486528552FyXSki.gif"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;以上动图演示了动态批处理运行的递归神经网络。带有同样的颜色的运算聚成一批，这使得 TensorFlow 能够更快的运行它们。Embed 运算将单词转换为向量表征。完全连接（fully connected，FC）运算结合词向量，从而形成段落向量表征。网络的输出是一个完整语句的向量表征。尽管上图只演示了一个语句解析树，但在多种任意形状与大小的解析树上，这个网络同样也能运行并实现批处理运算。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;TensorFlow Fold 库首先会为每个输入建立一个独立的计算图。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;因为单独的输入可能有不同的大小和结构，计算图也可能是这样。动态批处理自动结合这些图，从而获取在输入内以及整个输入进行批处理机会的优势，并且插入额外的指令在批处理操作之间移动数据。（查看技术细节请参考论文）&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;想要了解更多，也可以查看我们的 github 网址：https://github.com/tensorflow/fold。我们希望 TensorFlow Fold 能够帮助研究人员与从业者在 TensorFlow 中部署动态计算的神经网络。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;论文：DEEP LEARNING WITH DYNAMIC COMPUTATION GRAPHS&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1486528553IB0Vnl.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;摘要：在包括自然语言处理（解析树）与化学信息学（分子图）在内的多个领域中，在图结构上进行计算的神经网络是解决问题的天然方式。然而，因为每个输入的计算图有不同的形状与大小，所以网络通常不能直接进行批训练或推断。它们也难以部署到流行的深度学习库中，因为这些库是基于静态数据流图的。我们引入了一种称之为动态批处理（Dynamic Batching) 的技术，它不仅能批处理不同输入图（形状也不类似）之间的运算，也能批处理单个输入图内的不同节点。该技术使得我们能够创造静态图、使用流行的库、模仿任意形状与大小的动态计算图。我们进一步展现了组成区块的高层次库，从而简化了创造动态图模型的过程。使用这一库，我们论证了文献中多种模型的简洁且明智的批处理并行实现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 12px;"&gt;原文链接：https://research.googleblog.com/2017/02/announcing-tensorflow-fold-deep.html&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="min-height: 1em; text-align: justify; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="line-height: 25.6px; font-family: 微软雅黑; font-size: 14px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; color: rgb(127, 127, 127); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="color: rgb(62, 62, 62); line-height: 25.6px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; color: rgb(127, 127, 127); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;©本文由机器之心编译，&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; font-size: 18px; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(127, 127, 127); line-height: 25.6px; font-family: 微软雅黑; text-align: justify; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(217, 33, 66); font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(217, 33, 66); line-height: 1.6; font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-size: 12px; color: rgb(217, 33, 66); line-height: 1.6; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-size: 12px; color: rgb(217, 33, 66); line-height: 1.6; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong style="color: rgb(136, 136, 136); font-family: &amp;#39;Helvetica Neue&amp;#39;; font-size: 14px; white-space: normal;"&gt;点击阅读原文下载论文&lt;/strong&gt;&lt;/p&gt;&lt;/div&gt;</description>
      <pubDate>Wed, 08 Feb 2017 12:09:17 +0800</pubDate>
    </item>
    <item>
      <title>深度 | Facebook官方详解：使用Apache Spark进行大型语言模型训练</title>
      <link>http://www.iwgc.cn/link/4615828</link>
      <description>&lt;div class="article-content"&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;section style="font-size: 16px; white-space: normal; line-height: 28.4444px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="border: 0px currentcolor; font-family: 微软雅黑; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; border-style: solid none; font-family: inherit; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-top: -1.2em; min-height: 1em; font-size: 1em; border: currentcolor; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color:#ffffff"&gt;&lt;span style="background-color: rgb(117, 117, 118);"&gt;选自 Facebook&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="color: rgb(62, 62, 62); background-color: rgb(255, 255, 255); padding: 16px 16px 10px; font-family: inherit; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-top: 5px; margin-bottom: 5px; min-height: 1em; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(127, 127, 127); font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;作者： Tejas Patil、Jing Zheng&amp;nbsp;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-top: 5px; margin-bottom: 5px; min-height: 1em; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(127, 127, 127); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important; font-size: 12px;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;参与：李泽南、高静宜&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style="min-height: 1em; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; text-align: justify; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;br style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/p&gt;&lt;blockquote style="color: rgb(62, 62, 62); font-size: 16px; white-space: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/blockquote&gt;&lt;blockquote&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 12px;"&gt;Apache Spark 是用于大规模数据处理的快速和通用引擎，它运行在 Hadoop，Mesos，可以离线或云端运行，具有高速、可扩展等特点。近年来，在 IBM 等大公司和众多社区贡献者的推动下，Spark 得到了越来越多的应用。今天，Facebook 团队也展示了他们使用 Apache Spark 进行大型语言模型训练的方法。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;如何处理大规模数据是 Facebook 基础设施团队面临的核心问题。随着软件技术的发展，我们面临着越来越高的硬件需求，为了满足需要，我们必须在开源架构上设计并构建新的系统。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;考虑到我们的需求，我们决定使用 Apache Spark，一个快速发展的开源数据处理平台，它可以自由扩展，支持用户自定义应用。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;几个月前，我们分享了一个支持 Spark 声明（SQL）的的例子。在本文中，我们将简要介绍如何使用 Spark 重新设计一个大型、复杂（100 余级）的管道，而这个管道最初是使用 HQL 在 Hive 上编写的。在此之中，我们会介绍如何控制数据分布，避免数据偏移，并实现对特定应用程序的优化，以构建高性能及可靠的数据管道。与原来的 HQL 查询集相比，这种新的基于 Spark 的管道是模块化的，高度可读且易于维护的。除了质量提升之外，我们还观察到它的资源使用和数据登录时间也有减少。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;使用案例：N-gram 语言模型训练&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;自然语言处理是涉及计算机和人类语言之间相互作用的人工智能领域。计算机可以对语言进行建模，此类模型可用于检测和纠正拼写错误。N-gram 语言模型是其中使用最广泛的语言建模方法。N-gram 通常以 N-x 方式呈现，其中前 N-1 个字作为历史，基于 N-1 的历史来预测下一个字。例如，「你能来这里吗（Can you please come here）」包含 5 个单词，是一个 5-gram。它的历史是「你能来吗（Can you please come）」基于这个历史，N-gram 语言模型可以计算出单词「这里。（here.）」的条件概率。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1486528555qiHD53.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;大规模、高阶的 N-gram 语言模型（例如 N = 5）已经被证明在许多应用中非常有效，例如自动语音识别和机器翻译。在 Facebook 中，它被用于为上传到时间线的视频自动生成字幕，探测可能低质量的地址标签（如「家，温暖的家」，「Apt#00，Fake lane，Foo City」）。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;用大数据集训练的语言模型与用较小数据集训练的语言模型相比，前者通常具有更高的准确性。覆盖罕见单词（或 N-gram）充分实例的可能性会随着数据集体量的增大而增加。对于具有较大数据集的训练任务，分布式计算框架（如 MapReduce）通常具有更好的可扩展性，可进行并行化模型训练。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;早期解决方案&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;我们最初开发了一个基于 Hive 的解决方案来生成 N-gram 语言模型。N-gram 计数由最后两个字的历史记录分割，使用基于 C ++的 TRANSFORM 来判断局部语言模型，并将它们保存在 Hive 中。单独的子模型建立在不同的数据源上，每个都由 Hive 查询触发。随后，每个子模型被插值算法计算权重，最后所有子模型被组合输出。以下是管道的概述：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1486528556nfEA10.jpg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&amp;nbsp;基于 Hive 的解决方案在构建语言模型中获得了一定程度的成功：当使用几百万 N-gram 训练时，我们能用它轻松地构建 5-gram 语言模型。然而一旦我们试图增加训练数据集的大小，运行管道的端到端时间就会达到不可接受的程度。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Hive 提供了一个基于 SQL 的引擎，可以轻松地编写查询，这些查询会自动转换为 MapReduce 作业。对于训练语言模型而言，将计算表示为 SQL 查询是不自然的，原因如下：&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;管道代码，包括每个子模型训练的几个 SQL 查询。这些查询大部分是相似的，只有细微的差别。为模型训练而编写新的管道会导致这些 SQL 查询重复。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;当越来越多的子句被添加到查询中时，系统会越来越难以理解查询的意图。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;更改查询的一部分需要重新运行整个管道，以确保不会导致回归。无法测试隔离变化使得开发周期变长。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;作为替代方法，编写 Hadoop 作业在表达计算方面为开发人员提供了更多的自由，但这也需要更多的时间，需要我们具有 Hadoop 的专业知识。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;基于 Spark 的解决方案&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Spark 自带特定领域语言（DSL），使得编写自定义应用程序比 SQL 查询作业更加容易。通过 DSL，你可以控制较低级别的操作（例如，当数据被洗牌时），并且可以访问中间数据。这有助于实现复杂的算法，达到更高的效率和稳定性。它还允许用户能以模块化的方式编写管道，而不是使用一个单一的 SQL 字符串，这提高了管道的可读性，可维护性和可测试性。所有这些优势吸引我们引入了 Spark。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;在 Scala 或 Java 中重现 C ++的逻辑——语言模型训练算法的实现——会是巨量的工作，因此我们决定不更改该部分。和 Hive 一样，Spark 支持运行自定义用户代码，这使得调用相同的 C ++二进制文件变得容易。它允许开发者平滑过渡，因此我们不必同时维护两个版本的 C ++逻辑，而且迁移对用户是透明的。我们使用 Spark 提供的 RDD 接口，没有使用 Spark SQL，因为前者可以控制中间数据的分区并直接管理分片生成。Spark 的 pipe（）运算符用于调用二进制文件。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;在更高层上，管道的设计保持不变。我们继续使用 Hive 表作为应用程序的初始输入和最终输出。中间输出被写入集群节点上的本地硬盘中。整个应用程序大约有 1,000 行的 Scala 代码，并且可以在 Spark 上执行时生成 100 多个阶段（这取决于训练数据源的数量）。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;可扩展性挑战&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;当我们使用更大的训练数据集来测试 Spark 方案时，我们遇到了可扩展性的挑战。在本节中，我们首先介绍数据分布要求（平滑和分割），然后是它带来的挑战和我们的解决方案。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;平滑&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;N-gram 模型是根据训练数据中的 N-gram 出现计数来估算的。由于在训练数据中有可能缺少 N-gram，这种方式可能很难推广到未见的数据中。为了解决这个问题，我们使用了许多平滑方法以减少观察到的 N-gram 计数以提升未见的 N-gram 概率，并使用较低阶模型来让较高阶模型平滑。由于平滑，对于具有历史 h 的 N-gram，需要具有相同历史的所有 N-gram 计数和具有作为 h 的后缀的历史的所有较低级 N-gram 来估算其概率。例如，对于三元组「how are you，」，其中「how are」是历史，「you」是要预测的词，为了估计 P（you|how are），我们需要「how are*」，「are*」和所有 unigram（单字 N-gram）的计数，其中*是表示词汇表中任何单词的通配符。经常会出现 N-gram（例如，「how are*」）导致处理时的数据发生偏移。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;分片&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;通过分布式计算框架，我们可以将 N-gram 计数分割成多片，以便由多个并行机器进行处理。基于 N-gram 历史的最后 k 个单词的分片方式可以保证比 k 更长的 N-gram 在所有片段之间被平衡。这需要在所有分片上共享所有长度为 k 的 N-gram 计数。我们把所有这些短 N-gram 放在一个叫做「0-shard」的特殊分片中。例如，如果 k 是 2，那么从训练数据中提取的所有单字母和双字母会被组合在同一个分片（0- shard）中，并且所有进行模型训练的服务器都可以访问。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;问题：数据扭曲（Data skew）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;在基于 Hive 的管道中，我们使用两个单词的历史分片（two word history sharding) 方式进行模型训练。两词历史分片意味着，共享相同集合的最高有效两词历史（最靠近正被预测的词）的所有 N-gram 计数会被分布到同一节点用于处理。与单字历史相比，两字分片通常具有更平衡的数据分布，除了所有节点必须共享存储在 0-shard 中的平滑算法所需的单字和双字统计。下图说明了具有单字和两字历史的分片分布之间的比较。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1486528556umLH87.jpg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;对于大型数据集而言，两字历史分割会生成巨大的 0-shard。必须向所有节点散布 0-shard 以缩短总计算时间。同时，这种情况还存在潜在的不稳定性，因为很难预测它的内存需求，一旦启动作业，它可能在运行中耗尽内存。虽然我们可以提前分配更多内存，但仍然不能保证 100％的稳定性，而且这会导致集群内存利用率降低，因为并不是所有实例都需要比历史均值更多的内存。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;当我们尝试使用 Spark 后，作业可以在低负载状况下运行。但是对于更大的数据集，我们观察到了以下几个问题：&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;由于执行器长时间没有接收到 heartbeat，驱动程序将执行器标记为「lost」&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;执行器 OOM&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;频繁的执行器 GC&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;随机服务 OOM&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Spark 的 block 存在 2GB 的限制&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;所有这些问题的根本原因可以归结于数据扭曲。我们想要实现分片的均衡分布，但是两词的历史分片和单词历史分片都不能带来均衡。因此，我们提出了一种混合方法：渐进式分片和动态调整分片大小。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;解决方案：渐进式分片（Progressive sharding）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;渐进式分片用迭代的方法来解决数据扭曲（skew）问题。在第一次迭代时，我们首先进行单个字的分片，在这一步的分片中只需要对所有分片（shard）的一元语言模型计数进行分割。一元语言模型计数远少于二元语言模型计数。通常情况下这种处理是可以完成预期作用的，但不包含分片极其大的情况。例如，对应于「how to ...」的分片将会被扭曲。为了解决这个问题，我们核查每个分片的尺寸然后仅处理小于某一阈值的分片。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1486528556a3snPs.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;在第二次迭代时，我们使用二个字的分割，即根据二个字的历史来完成对 N-gram 的分布。在这个阶段，我们只需要向二元语言模型（不包括已在第一次迭代中处理的二元语言模型）共享 N-gram 的计数。这些二元语言模型计数的数目远少于整个的二元语言模型计数数目，因此处理起来也更快。正如上面所说，我们依然核查每个分片的尺寸然后仅处理小于某一阈值的分片。所剩下的分片将会在下一次的迭代中通过三个字历史来处理。在大多数情况下，三次迭代已足以满足非常大数据集的需要。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1486528556mfEz1Z.jpg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;动态调整&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;分片尺&lt;/span&gt;&lt;span style="font-size: 14px;"&gt;寸&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;在第一次迭代里，我们用了一个足够大的预设数，从而使得大部分的生成分片尺寸很小。每一个分片是由单个 Spark 所完成。在这次迭代中 0-shard 的分片是非常小的尺寸，有很多小分片并不会影响处理效率。在后面的迭代中，分片的数目将由 N—gram 的未处理部分所自动产生。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;这些方案能够成功实现归功于 Spark DSL 的灵活性。通过 Hive，开发者们不需要支配这些低级别的运算。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;针对训练模型的通用库&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;根据不同应用环境，怎样使用语言模型呢？每一种应用可能需要不同的数据和配置，因此不同的管道也应运而生。在 Hive 解决方案中，管道的 SQL 部分应用之间是相似的，但在几个地方有不同的单元。相较于重复每一个管道的代码，我们开发了一种可以调用不同管道和不同数据源及配置的普适的 Spark 应用。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;基于 Spark 解决问题时，我们也可以自动地在输入配置的基础上，优化应用程序运行的工作流程中的步骤。比如说，如果用户没有明确指出使用熵修剪算法，那么应用程序将会跳过模型重新评估。如果用户在配置中明确指定了计数截止，那么应用程序将会瓦解许多低计数的 N-grams 并以通配符占位符来减少存储。这些优化组合节省了计算资源，同时可以在更短的时间内产生训练好的模型。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;Spark 管道与 Hive 管道性能的比较&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;我们利用以下性能指标比较 Spark 管道与 Hive 管道：&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;CPU 时间：这是从操作系统的角度衡量 CPU 的使用。比如，如果你在 32 核机上使用所有 CPU 的 50%，以每 10 秒处理一个进程，那么你的 CPU 时间将是 32*0.5*160CPU 秒。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;CPU 保留时间：这是从资源管理框架的角度衡量 CPU 的保留。举个例子，如果我们在 32 核机上保留 10 秒来运行一个任务，那么 CPU 的保存时间是 32*10=320CPU 秒。CPU 时间与 CPU 保留时间的比例反映出我们是如何实现在集群上保留 CPU 资源的。当精确度达到要求时，相较于 CPU 时间，在运行相同的工作负载的条件下，保存时间可以作为一个更好的测量尺度去比较引擎的执行。比如，如果一个运程需要 1CPU 秒去运行但是必须保存 100CPU 秒，那么在完成同样的工作量时，按照这种度量标准，它就比一个需要 10CPU 秒运行且保存 10CPU 秒的运程效率低。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;延迟/屏蔽时间：从结束到结束的工作时间&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;以下图表总结了 Spark 和 Hive 工作的性能比较结果。注意 Spark 的管道不是 Hive 管道 1:1 的转化。它有许多有助于实现更好的可测量性和执行的定制和优化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1486528557hazuWU.jpg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;基于 Spark 的管道可以不费力地多次处理输入数据，甚至输入数据量高于 Hive 的巅峰处理量。例如，我们训练一个较大的语言模型，它可以在几小时内生成一个包含 192 亿 N-grams 的语言模型。能够用更多的数据并更快地运行试验训练的能力可以促使产生更高质量的模型。正如我们在我们自己的试验中观察到的，大规模语言模型通常会在相关的应用中得到更好的结果。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;总结&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Spark 的灵活性可以从以下方面为我们提供帮助：&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;用模块化的方式表达应用逻辑，相较于整体的 SQL 字符串，拥有更强的可读性和可持续性。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;在计算的任何阶段都可以对数据实现自定义处理（例如，分区，重洗）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;高性能的计算机引擎可以节省计算资源和试验时间&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;拥有输入更大规模数据的扩展能力可以训练出高质量的语言模型&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;建立一个通用的应用，可以用于在不同的产品上生成语言模型。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;由于支持运行用户二进制文件（如 Hive's TRANSFORM）和与Hive数据交互的兼容性，我们可以从早期的解决方案实行改进。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Facebook 对加入 Spark 开源社区表示激动，并将共同协作致力于开发出 Spark 的全部潜能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="color: rgb(136, 136, 136); text-decoration: none;"&gt;&lt;em&gt;&lt;span style="color: rgb(136, 136, 136); text-decoration: none; font-size: 12px;"&gt;原文链接：&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;span style="font-size: 12px; color: rgb(136, 136, 136); text-decoration: none;"&gt;&lt;em&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;&lt;a style="font-size: 12px; color: rgb(136, 136, 136); text-decoration: none;"&gt;https://code.facebook.com/posts/678403995666478/using-apache-spark-for-large-scale-language-model-training&lt;/a&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="min-height: 1em; text-align: justify; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="line-height: 25.6px; font-family: 微软雅黑; font-size: 14px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; color: rgb(127, 127, 127); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="color: rgb(62, 62, 62); line-height: 25.6px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; color: rgb(127, 127, 127); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;©本文由机器之心编译，&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; font-size: 18px; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(127, 127, 127); line-height: 25.6px; font-family: 微软雅黑; text-align: justify; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(217, 33, 66); font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(217, 33, 66); line-height: 1.6; font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-size: 12px; color: rgb(217, 33, 66); line-height: 1.6; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/div&gt;</description>
      <pubDate>Wed, 08 Feb 2017 12:09:17 +0800</pubDate>
    </item>
    <item>
      <title>前沿 | MIT AAAI-17研究展示：为规划算法加入人类直觉</title>
      <link>http://www.iwgc.cn/link/4615829</link>
      <description>&lt;div class="article-content"&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;section style="white-space: normal; line-height: 28.4444px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="border: 0px currentcolor; font-family: 微软雅黑; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; border-style: solid none; font-family: inherit; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="font-size: 1em; margin-top: -1.2em; min-height: 1em; border: currentcolor; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(255, 255, 255); background-color: rgb(117, 117, 118);"&gt;选自MIT&lt;/span&gt;&lt;/p&gt;&lt;section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="background-color: rgb(255, 255, 255); padding: 16px 16px 10px; font-family: inherit; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="color: rgb(62, 62, 62); font-size: 16px; margin-top: 5px; margin-bottom: 5px; min-height: 1em; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(127, 127, 127); font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;作者： Larry Hardesty&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-top: 5px; margin-bottom: 5px; min-height: 1em; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(127, 127, 127); font-size: 12px;"&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="color: rgb(62, 62, 62); font-size: 16px; margin-top: 5px; margin-bottom: 5px; min-height: 1em; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(127, 127, 127); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important; font-size: 12px;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;整理：黄小天、蒋思源&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style="min-height: 1em; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; text-align: justify; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;每隔一年，自动规划与调度国际会议（International Conference on Automated Planning and Scheduling）会举行一次比赛，参会者设计的计算机系统试图找到规划问题的最佳解决方案，这些规划问题包含如安排航班或协调自主卫星组任务等。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;然而，除了最简单直接的问题外，即使最好的规划算法仍然不如具有特殊解决问题才能的人类有效，例如麻省理工学院的学生。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;麻省理工学院计算机科学与人工智能实验室的研究人员正通过给予自动化系统人类直觉的能力来提高系统的表现。通过以机器可读的形式编码杰出规划人员的策略，他们能够在一系列具有挑战性的问题上提高竞胜规划算法（competition-winning planning algorithms）10％至 15％的性能。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;研究人员本周在 AAAI（Association for the Advancement of Artificial Intelligence）2017 的会议上展示了他们的研究成果。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;MIT 航空航天学助理教授 Julie Shah 说：「在实验室和其他调查中，我们发现对于规划、调度和优化等任务，通常有一小部分人是真正杰出的人才，而我们是否可以从少数真正杰出人才那里获得洞察力和高层次策略等能力，并让一台机器利用这些杰出能力来解决问题，而不是直接通过普通大众的解决方法？」&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;会议论文（conference paper）的第一作者是 Joseph Kim，它是航天航空方向的研究生，且在 2016 年夏天本科时就在 Shah 的实验室担任研究实习生。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;strong&gt;寻找规划者&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;在自动规划比赛（国际规划竞赛/IPC）中会提供给输入算法不同难易程度的相关问题任务。最简单的问题就只要求满足一些严格的约束条件：如给定一定数量的机场、飞机和在各个机场有确定目的地的乘客，是否可以在所有乘客都到达指定目的地且没有飞机空飞的情况下规划航班路线。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;而更复杂的一类问题，即数值问题会增加一些灵活的数值参数：如你是否能找到一组飞行规划，它在满足原始问题的约束情况下，还能最小化飞机飞行的时间和燃油消耗。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;最后，最为复杂的问题就是时间问题，它在数值问题的基础上添加了时序约束：即如何在最小化飞行时间与燃油消耗的同时，确保飞机可以在不同时间抵达和离开。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;对于每个问题，算法有半个小时生成方案。方案的质量根据「成本函数」测量，例如将飞行总时间与燃油总消耗组合起来的方程式。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Shah、Kim 和 Banks 招募了 36 名麻省理工学院的本科生与研究生，并向他们每个人提出了两种不同比赛的规划问题，一个侧重于飞行线路，一个侧重于卫星定位。如同自动规划者，每个学生只有半个小时解决问题。Shah 说：「在这个世界上，麻省理工的学生基本是解决此类问题的专家，相信他们比绝大多数人做得更好。」&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;编码策略&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;当然，他们做得比自动规划者更好。在学生提交解决方案后，Kim 对他们用来解决问题的一般策略进行了采访。他们的答案大多是包含「飞机应该访问每个城市最多一次」和「对于每个卫星，在三次转向之内找到路线」之类的内容。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;研究人员发现，大多数学生的策略可以使用称为线性时序逻辑（linear temporal logic）的形式语言来描述，并可用于向问题规范添加约束。由于不同的策略可以相互抵消，研究人员分别使用已经赢得他们各自比赛的规划算法来测试每个学生的策略。结果仅轻微变化。关于数值问题，飞行规划和卫星定位问题的平均改进分别为 13％和 16％;对时间问题的改善为 12％和 10％。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Shah 说：「当自动规划员使用人类的高级策略时，它提出的规划看起来更像是由人类制定的。「也许这个采取用户的高层次策略加入到机器算法中的方式，可以让人更容易理解规划的制定。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;在正进行的工作中，Kim 和 Shah 正在使用自然语言处理技术（natural-language-processing techniques）使系统完全自动化，在无需人为干预的情况下，将用户对其高级策略的自由形式描述（free-form descriptions）转换为线性时间逻辑（natural-language-processing techniques）。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 12px;"&gt;原文链接：&lt;/span&gt;&lt;/em&gt;&lt;em&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;http://news.mit.edu/2017/human-intuition-planning-algorithms-0207&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="min-height: 1em; text-align: justify; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="line-height: 25.6px; font-family: 微软雅黑; font-size: 14px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; color: rgb(127, 127, 127); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="color: rgb(62, 62, 62); line-height: 25.6px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; color: rgb(127, 127, 127); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;©本文由机器之心编译，&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; font-size: 18px; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(127, 127, 127); line-height: 25.6px; font-family: 微软雅黑; text-align: justify; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(217, 33, 66); font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(217, 33, 66); line-height: 1.6; font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-size: 12px; color: rgb(217, 33, 66); line-height: 1.6; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-size: 12px; color: rgb(217, 33, 66); line-height: 1.6; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="font-size: 14px; line-height: normal; font-family: &amp;#39;Helvetica Neue&amp;#39;;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;点击阅读原文下载论文&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/div&gt;</description>
      <pubDate>Wed, 08 Feb 2017 12:09:17 +0800</pubDate>
    </item>
    <item>
      <title>学界 | ICLR2017公布论文接收名单，匿名评审惹争议</title>
      <link>http://www.iwgc.cn/link/4615830</link>
      <description>&lt;div class="article-content"&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;section style="color: rgb(62, 62, 62); font-size: 16px; white-space: normal; background-color: rgb(255, 255, 255); line-height: 28.4444px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="border: 0px currentcolor; font-family: 微软雅黑; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; border-style: solid none; font-family: inherit; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-top: -1.2em; min-height: 1em; font-size: 1em; border: currentcolor; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(255, 255, 255); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(117, 117, 118);"&gt;机器之心整理&lt;/span&gt;&lt;/p&gt;&lt;section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px; font-family: inherit; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-top: 5px; margin-bottom: 5px; min-height: 1em; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(127, 127, 127); font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;编辑：微胖&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style="min-height: 1em; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; text-align: justify; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 12px;"&gt;2017 ICLR 将于 4 月 26-27 日在法国东南部港口城市土伦举行。近日，大会接收论文名单公布。在 507 篇提交论文中，有 15 篇论文应邀进行演讲，poster 181 篇，应邀参加研讨会的有 48 篇。其中，FAIR 合著被接收的论文共 14 篇。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px; color: rgb(123, 12, 0);"&gt;全部结果：https://openreview.net/forum?id=BkjLkSqxg&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1486528561ibAvXV.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 12px;"&gt;图片来自 Nando 推特&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;这 15 篇应邀演讲的论文分别是：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Making Neural Programming Architectures Generalize via Recursion&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;PDF:https://openreview.net/forum?id=BkbY4psgg&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Jonathon Cai, Richard Shin, Dawn Song&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;End-to-end Optimized Image Compression&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;PDFhttps://openreview.net/pdf?id=rJxdQ3jeg&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Johannes Ballé, Valero Laparra, Eero P. Simoncelli&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Optimization as a Model for Few-Shot Learning&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;https://openreview.net/pdf?id=rJY0-Kcll&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Sachin Ravi, Hugo Larochelle&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Learning End-to-End Goal-Oriented Dialog&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;https://openreview.net/pdf?id=S1Bb3D5gg&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Antoine Bordes, Y-Lan Boureau, Jason Weston&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Towards Principled Methods for Training Generative Adversarial Networks &lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;https://openreview.net/pdf?id=Hk4_qw5xe&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Martin Arjovsky, Leon Bottou&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Reinforcement Learning with Unsupervised Auxiliary Tasks&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;https://openreview.net/pdf?id=SJ6yPD5xg&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Max Jaderberg, Volodymyr Mnih, Wojciech Marian Czarnecki, Tom Schaul, Joel Z Leibo, David Silver, Koray Kavukcuoglu&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Multi-Agent Cooperation and the Emergence of (Natural) Language&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;https://openreview.net/forum?id=Hk8N3Sclg&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Angeliki Lazaridou, Alexander Peysakhovich, Marco Baroni&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Understanding deep learning requires rethinking generalization&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;https://openreview.net/forum?id=Sy8gdB9xx&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, Oriol Vinyals&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Neural Architecture Search with Reinforcement Learning&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;https://openreview.net/pdf?id=r1Ue8Hcxg&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Barret Zoph, Quoc Le&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Q-Prop: Sample-Efficient Policy Gradient with An Off-Policy Critic&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;https://openreview.net/forum?id=SJ3rcZcxl&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Shixiang Gu, Timothy Lillicrap, Zoubin Ghahramani, Richard E. Turner, Sergey Levine&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Learning to Act by Predicting the Future&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;https://openreview.net/forum?id=rJLS7qKe&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Alexey Dosovitskiy, Vladlen Koltun&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;https://openreview.net/forum?id=H1oyRlYgg&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Nitish Shirish Keskar, Dheevatsa Mudigere, Jorge Nocedal, Mikhail Smelyanskiy, Ping Tak Peter Tang&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Semi-supervised Knowledge Transfer for Deep Learning from Private Training Data&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;https://openreview.net/pdf?id=HkwoSDPgg&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Nicolas Papernot, Martín Abadi, Úlfar Erlingsson, Ian Goodfellow, Kunal Talwar&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Amortised MAP Inference for Image Super-resolution&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;https://openreview.net/forum?id=S1RP6GLle&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Casper Kaae Sønderby, Jose Caballero, Lucas Theis, Wenzhe Shi, Ferenc Huszár&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Learning Graphical State Transitions&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;https://openreview.net/forum?id=HJ0NvFzxl&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Daniel D. Johnson&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;另外，Nando 在推特上公开表示了对以下几篇论文的赞赏和喜爱。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;论文：Third Person Imitation Learning，&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;作者： Bradly C Stadie, Pieter Abbeel, Ilya Sutskever&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1486528562d6vqSQ.jpg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;论文：Modular Multitask Reinforcement Learning with Policy Sketches&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;作者：Jacob Andreas, Dan Klein, Sergey Levine&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/14865285622VkfHF.jpg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;论文：Optimization as a Model for Few-Shot Learning&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;作者：Sachin Ravi, Hugo Larochelle&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/148652856291qmNM.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;论文：Making Neural Programming Architectures Generalize via Recursion（被 Nando 形容为突破）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;作者：Jonathon Cai, Richard Shin, Dawn Song&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1486528562tmLH87.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;不过，有趣的是，2016 年刷爆各路媒体的 LipNet 论文却出人意料地遭拒。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 14px;"&gt;来自牛津大学、Google DeepMind 和加拿大高等研究院（CIFAR）的研究人员发表了一篇具有重要价值的论文，提出了 LipNet——一种可以将可变长度的视频序列映射成文本的模型，其使用了时空卷积、一个 LSTM 循环网络和联结主义的时间分类损失（connectionist temporal classification loss）。它是第一个将深度学习应用于模型的端到端学习的模型，可以将说话者的嘴唇的图像帧序列映射到整个句子上。这个端到端的模型在预测句子前不再需要将视频拆分成词。在 GRID 语料库上，LipNet 实现了 93.4% 的准确度，超过了经验丰富的人类唇读者和之前的 79.6% 的最佳准确度, 将自动唇读技术的前沿水平推进到了前所未有的高度。在不久的将来，这一视频识别应用会非常有用。——机器之心报道（&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720335&amp;amp;idx=1&amp;amp;sn=b030d7f82d10acde0378035c900264df&amp;amp;chksm=871b0c31b06c852746f35e16814808ceb13e91b091732afa48b2bb8c6d6f2f542df26e7f5575&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720335&amp;amp;idx=1&amp;amp;sn=b030d7f82d10acde0378035c900264df&amp;amp;chksm=871b0c31b06c852746f35e16814808ceb13e91b091732afa48b2bb8c6d6f2f542df26e7f5575&amp;amp;scene=21#wechat_redirect"&gt;重磅论文 | 如何通过机器学习解读唇语？DeepMind 要通过 LipNet 帮助机器「看」懂别人说的话&amp;nbsp;&lt;/a&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;）&lt;/p&gt;&lt;/blockquote&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;据悉，Nando de Freitas 和匿名评审产生了激烈冲突，评审认为，论文并无洞见和让人惊艳的结果。但是，Nando 感觉受到了羞辱，指责评审论点根本是废话，也不懂深度学习，评审建议毫无必要。Nando 认为，匿名评论不合理，但是，评审认为这位大牛有以大压小的嫌疑。最终，会议 AC 坚决站在了评审这边，拒了这篇论文，连研讨会都没有收。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;机器之心分析师个人认为：&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 14px;"&gt;&lt;em&gt;我也觉得 LipNet 算法方面创新有限，demo 视频也没有给人惊艳感。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 14px;"&gt;&lt;em&gt;LipNet 也是挂在 zisserman 名下的文章，它的实验结果很优秀，但是 ICLR 好像有一个更关注算法创新和理论推进这种高大上的初衷，所以 , LipNet 这样的文章如果是几年前深度学习还没那么热的时候应该是会被录取的，因为那时候，你只要用深度学习又征服了一个新的 cv 或者其他领域的一个课题或应用，就有可能发到相关的顶级会议，可如今深度学习文章已经满大街了，再拿这种征服一个课题上的几个数据集，或者发布一个大规模数据集的方式来发 ICLR 就略显草率了，也不像 DeepMind 的逼格，纯属个人拙见。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Github 上也有网友表示，在读了许多论文的评审建议后，发现 LipNet 的评审建议最富洞见，也最有趣，当然，也极富争议。这既暴露了某些自负，也暴露了学术大牛和匿名评审之间的冲突，这至少表明，评审程序还是起作用的，没有像媒体一样跟风炒作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="min-height: 1em; text-align: justify; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="line-height: 25.6px; font-family: 微软雅黑; font-size: 14px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; color: rgb(127, 127, 127); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="color: rgb(62, 62, 62); line-height: 25.6px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; color: rgb(127, 127, 127); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;©本文为机器之心原创，&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; font-size: 18px; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(127, 127, 127); line-height: 25.6px; font-family: 微软雅黑; text-align: justify; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(217, 33, 66); font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(217, 33, 66); line-height: 1.6; font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-size: 12px; color: rgb(217, 33, 66); line-height: 1.6; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/div&gt;</description>
      <pubDate>Wed, 08 Feb 2017 12:09:17 +0800</pubDate>
    </item>
  </channel>
</rss>
