<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>首届TensorFlow开发者大会：值得关注的亮点都在这里（附资源）</title>
      <link>http://www.iwgc.cn/link/</link>
      <description>
&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：吴攀、李亚洲、微胖&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当地时间 2 月 15 日，谷歌在加州山景城召开了第一届年度 TensorFlow 开发者大会（TensorFlow Developer Summit 2017），这可算得上是 TensorFlow 开发者、支持者与爱好者的第一次盛会，谷歌也在此次会议上发布了开发者期待已久的 &lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650723249&amp;amp;idx=1&amp;amp;sn=2503c119815d74f25703b252ee45f844&amp;amp;chksm=871b17cfb06c9ed9fc1c43f32750f9f4294c59514c174480ed3542722e621beca10d399505b4&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650723249&amp;amp;idx=1&amp;amp;sn=2503c119815d74f25703b252ee45f844&amp;amp;chksm=871b17cfb06c9ed9fc1c43f32750f9f4294c59514c174480ed3542722e621beca10d399505b4&amp;amp;scene=21#wechat_redirect" target="_blank"&gt;TensorFlow 1.0&lt;/a&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;经过一年多的发展，TensorFlow 得到了越来越多开发者的认可，也成为了 GitHub 上最受欢迎的框架之一。从发布以来，TensorFlow 一直在不断完善和增加新功能，比如分布式 TensorFlow、Windows 系统支持等，直到最近 TensorFlow 1.0 正式版的诞生。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/4290410650e327c5697de7caa3b0aa3c1007e32b"/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;图：TensorFlow 的版本更迭&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但除了这个我们早就已经预计到的重磅消息之外，这个首届 TensorFlow 开发者大会上还有什么值得开发者关注的亮点呢？机器之心在此根据本次大会上的演讲对会上值得关注的内容进行了梳理，并按框架对比、产品和应用、移动端与嵌入式 TensorFlow、资源分别进行了总结，希望能对 TensorFlow 开发者能有所帮助。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;框架对比&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自开源以来，TensorFlow 经过一年多的发展已经成为了 GitHub 上最流行的框架。如同 Jeff Dean 下图中演示那样，短短一年时间，TensorFlow 已经超越 scikit-learn、Caffe 等框架，已在 GitHub 获得了最多的 Star 量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/74344fd4d960cb5b4c579fc7ad937fae8d0c3931"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图注：有大量的人在为 TensorFlow 作出贡献，并用其进行各种有趣的尝试。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此外，Jeff Dean 在 Keynote 中介绍说，TensorFlow 现在已经支持 Python、C++、Java、R、Haskell、Go 在内的多种语言。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;框架之间的对比也成为了机器学习社区所关注的一个话题。之前机器之心编译的一篇文章中，数据科学公司 Silicon Valley Data Science 的数据工程师 Matt Rubashkin（UC Berkeley 博士）对深度学习的 7 种流行框架进行了横向对比，其中包括语言支持、速度、兼容 Keras 在内的 8 项衡量标准，结果如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/d5d2108468ddfa8ad82a37d5c610d1c749a599ff"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在本次开发者大会上，谷歌专门也设置了两场演讲凸显 TensorFlow 的优势：XLA 以及 Keras 与 TensorFlow 的融合。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;速度是高效的机器学习框架的一切。在这次大会中，Chris Leary 与 Todd Wang 讲解了通过 XLA（加速线性代数）方法减少训练和推断时间的方式。他们介绍了 TensorFlow 如何使用 XLA、JIT、AOT 以及其它编译技术来最小化执行时间和最大化计算资源。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/ff59a73920cd6b26cb3e34648a118b760ec50a38"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;兼容 Keras：Keras 是成长最快的深度学习框架之一。在此次大会上，Keras 的主要作者 Francois Chollet 用视频 QA 案例演示了如何在 TensorFlow 中使用 Keras。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/a224f0445867ec9418df65126597f9cc06ef18c2"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;产品与应用&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;经过一年飞速的发展，TensorFlow 也逐渐得到了业界的认可，许多企业、公司都在基于 TensorFlow 开发自己的产品或将 TensorFlow 整合到自己的产品中去。其中包括 Airbnb、Uber、Twitter、英特尔和高通等等，当然也还有去年宣布从 &lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715087&amp;amp;idx=3&amp;amp;sn=a736c842914fc58f4789219a85a66206&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715087&amp;amp;idx=3&amp;amp;sn=a736c842914fc58f4789219a85a66206&amp;amp;scene=21#wechat_redirect" target="_blank"&gt;Torch 转向 TensorFlow 的 DeepMind&lt;/a&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/38d5572e112bc29c46eecdab718a8212e487fb59"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而谷歌自己当然更是在产品开发上给予了 TensorFlow 所有可以提供的支持。据谷歌工程开发主管 Megan Kacholia 介绍，TensorFlow 目前已经在以下十几种产品中得到了应用，其中包括谷歌翻译、Google Play、YouTube 和 Gmail 等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/ad79489326b276d596c608afc5f14dd8c413ae3e"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌也不吝于分享自己在 TensorFlow 产品应用方面的经验。Google Research 的软件工程师 Jonathan Hseu 在一个演讲中介绍了 TensorFlow 生态系统（参考：&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720302&amp;amp;idx=4&amp;amp;sn=5a54ac9d2097f0db11d1da8a65cf2e4c&amp;amp;chksm=871b0c50b06c85466eb0bb5e455e306deca82662d83895f9d6ad2311539a9adf7056dac306ac&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720302&amp;amp;idx=4&amp;amp;sn=5a54ac9d2097f0db11d1da8a65cf2e4c&amp;amp;chksm=871b0c50b06c85466eb0bb5e455e306deca82662d83895f9d6ad2311539a9adf7056dac306ac&amp;amp;scene=21#wechat_redirect" target="_blank"&gt;《资源 | TensorFlow 生态系统：与多种开源框架的融合》&lt;/a&gt;），谈到了 TensorFlow 和产品基础设施的整合方式，并介绍了从数据准备到模型训练到产品应用整个过程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/a34a1601ab76550f3d0e8a3ec395b4f4bc10a5d2"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在数据准备阶段，主要处理过程是：从各个数据源获取数据&amp;rarr;执行预处理&amp;rarr;导出一个 TensorFLow 支持的文件格式。在这个阶段用的比较多的工具是 Apache Spark、Hadoop MapReduce 和 Apache Beam。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在模型训练阶段，可以选择本地训练（自己的本地机器或远程虚拟机）或分布式训练（速度更快，但需要合适的基础设施）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然后就是将训练好的模型导出投入到产品中，Hseu 在这里推荐了 TensorFlow Serving 和 In-Process TensorFlow。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而在这些阶段的语言支持上，Python 的支持当然是最好的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/15a87503d971714377c8e547f20563578af0336d"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;接下来，Google Research 的软件工程师 Noah Fiedel 就做了关于 TensorFlow Serving（serving 是指将训练好的模型应用到生产中的过程）的演讲。Fiedel 介绍说，serving 的目标是实现在线的、低延迟的应用，能将多个模型应用到单一一个流程中，可以随时间加载一个模型的多个版本，可以实时计算成本变化以满足产品需求（通过 CloudML、Docker &amp;amp; K8s 自动扩展），在训练时间通过 mini-batching 提高效率（除非有异步的要求）。而 TensorFlow Serving 就是一个专为生产环境设计的，用于机器学习模型的灵活高性能 serving 平台：https://tensorflow.github.io/serving&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/08680458459bd5f349ad8397d4946a2b715f067b"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;还在演讲后面介绍一种新技术 SavedModel，这是一种用于 TensorFlow 模型的通用的序列化格式（universal serialization format），已经包含在了 TensorFlow 1.0 中，其有两个重要功能：支持多个 MetaGraph（同时共享变量和 asset）和 SignatureDef。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/32192c4b29f74644193a70a4af2cb10ee116ba03"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中 SignatureDef 定义了由 TensorFlow graph 所支持的计算的签名。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/86fb3b71491f3c03792e2513da8e7cb4b152bccf"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此外还有 Multi-headed Inference 和 Sequence Models 技术：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/747f63a779c7b5509867c3e141ecc4303ce4b08b"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/ac4e820e73ba0178511310da3216b8e0299ac67c"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;分布式 TensorFlow 也是一个值得关注的亮点，Google Research 的软件工程师 Derek Murray 带来了一个自底向上的关于分布式 TensorFlow 的介绍，并展示了所有可以用来利用这种力量的工具。我们为什么要使用分布式 TensorFlow 呢？随着技术和方法的不断发展，深度学习系统的规模也变得越来越大，对计算资源的要求也随之增长。为了应对这个问题，我们可以将计算分配给不同的 GPU 集群而并行地进行计算，从而减少计算时间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/c1df8d66a3166b54b0ec2c9b44eae18831f0fef1"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们需要分布式 TensorFlow 的情况是模型非常大的时候，比如谷歌的「&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716578&amp;amp;idx=1&amp;amp;sn=aae84df4e4e218afcd9f2d7cc88c96eb&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716578&amp;amp;idx=1&amp;amp;sn=aae84df4e4e218afcd9f2d7cc88c96eb&amp;amp;scene=21#wechat_redirect" target="_blank"&gt;宽度&amp;amp;深度&lt;/a&gt;」模型 和超大规模模型，现有的单个硬件可能无法将它装进去进行计算。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/d53b02dfa4799951c731ddc30911f763128219fb"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/d78747c6089d71e1572df2df8a6eb60642316e61"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;超大规模有多达 680 亿个参数&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在具体的应用方面，Google Research 的软件工程师 Heng-Tze Cheng 介绍了用 TensorFlow 实现「宽度&amp;amp;深度学习」&amp;mdash;&amp;mdash;将记忆（memorization）和归纳（generalization）结合到一起。参阅《&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716578&amp;amp;idx=1&amp;amp;sn=aae84df4e4e218afcd9f2d7cc88c96eb&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716578&amp;amp;idx=1&amp;amp;sn=aae84df4e4e218afcd9f2d7cc88c96eb&amp;amp;scene=21#wechat_redirect" target="_blank"&gt;深度 | 谷歌新开源「宽度&amp;amp;深度学习」框架：结合记忆和归纳实现更优推荐 &lt;/a&gt;》，该网络已经在 Google Play 上得到了应用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/d74eac2a8e781f6ca45e155b385aa205248e3a66"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;TensorFlow 的高级 API，你需要 10 行代码就能实现一个这种类型的网络模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/25f3edc6836de6a9ffc0a765da7fb92a26b28a3c"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Google Research 的产品经理 Lily Peng 以视网膜成像为例介绍了 TensorFlow 在医疗领域的应用。机器之心之前已经有过介绍了《&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720846&amp;amp;idx=1&amp;amp;sn=2f98ec55be6e608ab7b69bae31a8ed23&amp;amp;chksm=871b0e30b06c872680991cbe6441617c36c9e500486decb1603426f918212f7f31fc7ed19737&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720846&amp;amp;idx=1&amp;amp;sn=2f98ec55be6e608ab7b69bae31a8ed23&amp;amp;chksm=871b0e30b06c872680991cbe6441617c36c9e500486decb1603426f918212f7f31fc7ed19737&amp;amp;scene=21#wechat_redirect" target="_blank"&gt;重磅 | 谷歌研发人工智能眼科医生：用深度学习诊断预防失明&lt;/a&gt;》。在谈到 TensorFlow 所发挥的作用时，Peng 介绍说 TensorFlow 的优点包括：快速的原型构建、支持大规模实验并且可以根据实际的应用所收集到的数据和标签重新训练模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/d535b38df46b5c6dd2ae39f039774c072ee0050c"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此外，不久之前得以上 Nature 封面的癌症方面的研究也应用到了 TensorFlow。斯坦福大学的研究人员训练了一个可以诊断皮肤癌的算法。在论文中，他们展示了使用一个单一的深度卷积神经网络进行皮肤病变分类的过程，该网络仅使用像素和疾病标签作为输入，直接从图像中端到端地训练出来。测试结果显示深度卷积神经网络在这两个任务上的表现都达到了所有测试的专家的水平，证明了该人工智能的皮肤癌鉴定水平达到了媲美皮肤科医生的水平。配备该深度神经网络的移动设备可以让皮肤科医生的诊断拓展到临床之外。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在此次开发者大会上，论文的合作者之一 Brett Kuprel 讲解了如何使用 TensorFlow 进行癌症图像分类，这是受到学界、业界极大关注的应用之一。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;iframe allowfullscreen="" class="video_iframe" data-vidtype="1" frameborder="0" height="417" src="https://v.qq.com/iframe/preview.html?vid=k03756n3r9k&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0" width="556"&gt;&lt;/iframe&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此外，谷歌研究科学家 Doug Eck 介绍了基于 TensorFlow 的音乐和艺术生成项目 Project Magenta。机器之心之前也曾深度介绍过该项目《&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719723&amp;amp;idx=2&amp;amp;sn=03925a0eb5a8b78cc2642781b924032c&amp;amp;chksm=871b0195b06c888336f97ac330524580589bf29b073aa76585319a6ad43744a5697d6a424b0f&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719723&amp;amp;idx=2&amp;amp;sn=03925a0eb5a8b78cc2642781b924032c&amp;amp;chksm=871b0195b06c888336f97ac330524580589bf29b073aa76585319a6ad43744a5697d6a424b0f&amp;amp;scene=21#wechat_redirect" target="_blank"&gt;深度 | 人工智能改变 MIDI 创作：谷歌 Magenta 项目是如何教神经网络编写音乐的？&lt;/a&gt;》。&lt;/span&gt;&lt;span&gt;Eck 在演讲中谈到了选择 TensorFlow 的原因：可以使用能操作一切（MIDI、音频）的 Python，灵活且高速的图像、音频、视频 I/O、有很好用的 TensorBoard 和非常好的开发者社区。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/22c30ceca8ac042d2bb97428838cfaa0b9c25094"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后要提及的是谷歌收购的 DeepMind 团队在去年从 Torch 转向 TensorFlow 之后，也在积极地将其用到各种应用上。在大会的一场演讲中，来自 DeepMind 应用团队的 Daniel Visentin 就提到了 DeepMind 将它们的人工智能技术应用到谷歌的数据中心上，从而寻找帮助谷歌降低能源费用的方法。而这种方法的开发就得益于围绕 TensorFlow 开发的一些更高水平的库。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/6d8a5b9ed334d41fc0c6ae14b51f6b748172e474"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;移动端与嵌入式 TensorFlow&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;服务器端的大规模机器学习应用，Google 当仁不让（当然，Facebook、Twitter、Linkedin、Netflix、Amazon 等也有自己的看家本领）。但是，移动计算市场对机器学习的需求极其强劲，谷歌自然不会放弃这块巨大的蛋糕。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;Pete Warden 带来了主题为「移动端与嵌入式 TensorFlow」的演讲。首先，对 TensorFlow 生态系统做了基本介绍，接着就移动端实现 TensorFlow 以及一些问题解决（当然，也是 TensorFlow 的优点）做了简单讲解。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前，TensorFlow 支持的平台包括安卓、iOS 以及树莓派。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/5037f216a3043d72e501f9f4d4693864f9a3da67"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;TensorFlow 还与许多芯片制造商，比如 英特尔、ARM 、Movidius 等密切合作，确保 TensorFlow 在一大堆不同硬件上运行更快更流畅。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/d108b8260fd4deda47183d5fa98486fae531287f"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;简单介绍 TensorFlow 的生态环境后，Pete Warden 利用介绍了安卓系统、iOS 以及树莓派的 TensorFlow 实现，还给出了应用实例。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/89ab4e4f414d6049604c101736ffcdb0c76ce569"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;安卓应用程序用的是 Java，怎么办？答案在上面。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 TF 实现中，通常会遇到一些问题，比如&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/d1971f269d8e1a29f36710ce6a5d8436e6e6c386"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为此，你可能需要知道 TensorFlow 的打造原理，比如，TensorFlow 的组件巨多，根本不存在一个把这些内容都列出来的单一文件。这时，你需尝试有效操作办法：&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/d550bb5520261db2df9e4bef09deb6ba3ef7c9fe"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;接下来，管理模型大小和速度问题，TensorFlow 有不少办法压缩模型大小。其中，最关键的步骤就是量子化权重。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/e5a0f4fc8f03a70b3729f7612bcf6fd5d9ead005"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后介绍了管理二进制文件大小。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/9a8516c8959206c8b2487df59a3a0a949d961c8a"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;TensorFlow 资源汇集&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Ashish Agarwal 在本次开发者大会上介绍了机器学习工具包，他谈到 TensorFlow 虽然是一个非常强大的框架，然而也一直以来都缺乏可以即时使用的解决方案。常用的机器学习工具包括：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/f4c50818b0ec8c5136cc8858054b37348c542708"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Agarwal &amp;nbsp;介绍了了一个旨在解决这一问题的算法工具包，并表示这个工具包是 TensorFlow 中的高性能、分布式、可扩展的机器学习算法实现，可以直接拿来使用，比如下面这个联合实现 k-均值和 DNN 的案例：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/1f89ff2372bd192429048ed09320dcbb9dedab68"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后机器之心在下面梳理了我们关于 TensorFlow 的报道：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;基本概述和新闻&lt;/strong&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2"&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720407&amp;amp;idx=1&amp;amp;sn=768d7248e0ab5fa469dbae86d11152e1&amp;amp;chksm=871b0ce9b06c85ffefa2e0c8f6fb7ae4cc1c0500cda7bad008fe68ed6b87d7c8765d138e1fd1&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720407&amp;amp;idx=1&amp;amp;sn=768d7248e0ab5fa469dbae86d11152e1&amp;amp;chksm=871b0ce9b06c85ffefa2e0c8f6fb7ae4cc1c0500cda7bad008fe68ed6b87d7c8765d138e1fd1&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;" target="_blank"&gt;&lt;span&gt;TensorFlow开源一周年：这可能是一份最完整的盘点&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=401936398&amp;amp;idx=2&amp;amp;sn=9b34d959e50825b24a90dbef09f2d9fd&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=401936398&amp;amp;idx=2&amp;amp;sn=9b34d959e50825b24a90dbef09f2d9fd&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;" target="_blank"&gt;&lt;span&gt;TensorFlow：最棒的深度学习加速器&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720846&amp;amp;idx=4&amp;amp;sn=a15185b1435b14ec6c9ab15366e4f7de&amp;amp;chksm=871b0e30b06c8726020e17d0bf4ad79791a472e320224782b8f69317e9f4a17391e0c9a9fa3d&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720846&amp;amp;idx=4&amp;amp;sn=a15185b1435b14ec6c9ab15366e4f7de&amp;amp;chksm=871b0e30b06c8726020e17d0bf4ad79791a472e320224782b8f69317e9f4a17391e0c9a9fa3d&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;" target="_blank"&gt;&lt;span&gt;终于来了，TensorFlow 新增官方 Windows 支持&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715969&amp;amp;idx=3&amp;amp;sn=1116cce76c0a18b6462acee8c77c2278&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715969&amp;amp;idx=3&amp;amp;sn=1116cce76c0a18b6462acee8c77c2278&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;" target="_blank"&gt;&lt;span&gt;谷歌开源平台TensorFlow向iOS开放&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715679&amp;amp;idx=1&amp;amp;sn=0722624d88f17a70d9663bc918f9ac82&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715679&amp;amp;idx=1&amp;amp;sn=0722624d88f17a70d9663bc918f9ac82&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;" target="_blank"&gt;&lt;span&gt;想揭开深度学习隐藏层的神秘面纱？试试Tensor Flow的神经网络游乐场&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722208&amp;amp;idx=5&amp;amp;sn=392a6aa77f0f5eeb976636f4fe791cc7&amp;amp;chksm=871b0bdeb06c82c84cb811fa6e059b988f56249d027dbdcb5f28fe45a1167f27c1f1e1cd6de2&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722208&amp;amp;idx=5&amp;amp;sn=392a6aa77f0f5eeb976636f4fe791cc7&amp;amp;chksm=871b0bdeb06c82c84cb811fa6e059b988f56249d027dbdcb5f28fe45a1167f27c1f1e1cd6de2&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;" target="_blank"&gt;&lt;span&gt;TensorFlow版本号升至1.0，正式版即将到来&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650723249&amp;amp;idx=1&amp;amp;sn=2503c119815d74f25703b252ee45f844&amp;amp;chksm=871b17cfb06c9ed9fc1c43f32750f9f4294c59514c174480ed3542722e621beca10d399505b4&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650723249&amp;amp;idx=1&amp;amp;sn=2503c119815d74f25703b252ee45f844&amp;amp;chksm=871b17cfb06c9ed9fc1c43f32750f9f4294c59514c174480ed3542722e621beca10d399505b4&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;" target="_blank"&gt;&lt;span&gt;谷歌召开首届TensorFlow开发者大会，正式发布TensorFlow 1.0&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720302&amp;amp;idx=4&amp;amp;sn=5a54ac9d2097f0db11d1da8a65cf2e4c&amp;amp;chksm=871b0c50b06c85466eb0bb5e455e306deca82662d83895f9d6ad2311539a9adf7056dac306ac&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720302&amp;amp;idx=4&amp;amp;sn=5a54ac9d2097f0db11d1da8a65cf2e4c&amp;amp;chksm=871b0c50b06c85466eb0bb5e455e306deca82662d83895f9d6ad2311539a9adf7056dac306ac&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;" target="_blank"&gt;&lt;span&gt;TensorFlow 生态系统：与多种开源框架的融合&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715438&amp;amp;idx=2&amp;amp;sn=3dafb301ec8103fce7ad88d6039cb3ad&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715438&amp;amp;idx=2&amp;amp;sn=3dafb301ec8103fce7ad88d6039cb3ad&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;" target="_blank"&gt;&lt;span&gt;谷歌TensorFlow的一份全面评估报告：好的坏的及令人讨厌的&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721938&amp;amp;idx=1&amp;amp;sn=a7568453296f8b34f1bbb6287cb994d0&amp;amp;chksm=871b0aecb06c83fad3b111c2f48206b26c85762e2b9834a07dddd7a282b60a5df2f78c104de5&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721938&amp;amp;idx=1&amp;amp;sn=a7568453296f8b34f1bbb6287cb994d0&amp;amp;chksm=871b0aecb06c83fad3b111c2f48206b26c85762e2b9834a07dddd7a282b60a5df2f78c104de5&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;" target="_blank"&gt;&lt;span&gt;对比深度学习十大框架：TensorFlow最流行但并不是最好&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650723269&amp;amp;idx=1&amp;amp;sn=959bfccb95502778aadeb1c906044b0d&amp;amp;chksm=871b17bbb06c9ead069be0bca912814ae8b1c10533f90f64cfd46b70a68c89c3df6492139dfc&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650723269&amp;amp;idx=1&amp;amp;sn=959bfccb95502778aadeb1c906044b0d&amp;amp;chksm=871b17bbb06c9ead069be0bca912814ae8b1c10533f90f64cfd46b70a68c89c3df6492139dfc&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;" target="_blank"&gt;&lt;span&gt;从TensorFlow到Theano：横向对比七大深度学习框架&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719562&amp;amp;idx=3&amp;amp;sn=f62ba6a54a5d6c0a11ee21fa4e103382&amp;amp;chksm=871b0134b06c8822abc72d89c493790d7fb0257c9298456e0f7bf9db75a554fb331f08396770&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719562&amp;amp;idx=3&amp;amp;sn=f62ba6a54a5d6c0a11ee21fa4e103382&amp;amp;chksm=871b0134b06c8822abc72d89c493790d7fb0257c9298456e0f7bf9db75a554fb331f08396770&amp;amp;scene=21#wechat_redirect" target="_blank"&gt;&lt;span&gt;TensorFlow工程设计主任Rajat Monga问答：计算能力是深度学习发展的主要瓶颈&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715087&amp;amp;idx=3&amp;amp;sn=a736c842914fc58f4789219a85a66206&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715087&amp;amp;idx=3&amp;amp;sn=a736c842914fc58f4789219a85a66206&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;" target="_blank"&gt;&lt;span&gt;DeepMind：Torch很好，但我们要去老板家的TensorFlow了&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=400417166&amp;amp;idx=2&amp;amp;sn=c040ad708a421fe61ed0eedf064ec73c&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=400417166&amp;amp;idx=2&amp;amp;sn=c040ad708a421fe61ed0eedf064ec73c&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;" target="_blank"&gt;&lt;span&gt;探秘谷歌人工智能实验室，TensorFlow在这里诞生&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;前沿研究&lt;/strong&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2"&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715794&amp;amp;idx=3&amp;amp;sn=3c328f66f24dee02b6a29a7821c7f6a1&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715794&amp;amp;idx=3&amp;amp;sn=3c328f66f24dee02b6a29a7821c7f6a1&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;" target="_blank"&gt;&lt;span&gt;Google Brain论文：TensorFlow，一个大规模机器学习系统&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719022&amp;amp;idx=1&amp;amp;sn=3eeb1958e695388817dd32b0d228ced9&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719022&amp;amp;idx=1&amp;amp;sn=3eeb1958e695388817dd32b0d228ced9&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;" target="_blank"&gt;&lt;span&gt;DeepMind最新生成模型WaveNet，将机器合成语音水平与人类差距缩小50%（附论文）&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722733&amp;amp;idx=4&amp;amp;sn=6e437dbda2795bfa95cd64f82f6c4d7a&amp;amp;chksm=871b15d3b06c9cc5b68f70b42c35cd5823b58780bce6420cd9f4f365e775be47e4a78d61633e&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722733&amp;amp;idx=4&amp;amp;sn=6e437dbda2795bfa95cd64f82f6c4d7a&amp;amp;chksm=871b15d3b06c9cc5b68f70b42c35cd5823b58780bce6420cd9f4f365e775be47e4a78d61633e&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;" target="_blank"&gt;&lt;span&gt;谷歌翻译整合神经网络：机器翻译实现颠覆性突破（附论文）&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720113&amp;amp;idx=1&amp;amp;sn=b45bd28cef19a06c717717d3622d58de&amp;amp;chksm=871b030fb06c8a199334d745ad1be56b6b7aeb364596743be7215cc7c6a15a23053c8b60639f&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720113&amp;amp;idx=1&amp;amp;sn=b45bd28cef19a06c717717d3622d58de&amp;amp;chksm=871b030fb06c8a199334d745ad1be56b6b7aeb364596743be7215cc7c6a15a23053c8b60639f&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;" target="_blank"&gt;&lt;span&gt;谷歌增强型风格迁移新算法：实现基于单个网络的多种风格实时迁移（附论文）&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;span&gt;&lt;strong&gt;应用实现与开源&lt;/strong&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2"&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719367&amp;amp;idx=2&amp;amp;sn=f55be5c1efdbf75f98ec77d6d94c6b62&amp;amp;chksm=871b00f9b06c89eff2bf15e38deb2d060a5c1f5ffb4e01839b920572f9c5499bf7a0129e25b8&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719367&amp;amp;idx=2&amp;amp;sn=f55be5c1efdbf75f98ec77d6d94c6b62&amp;amp;chksm=871b00f9b06c89eff2bf15e38deb2d060a5c1f5ffb4e01839b920572f9c5499bf7a0129e25b8&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;" target="_blank"&gt;&lt;span&gt;Show and Tell：谷歌在 TensorFlow 上开源图像描述系统&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718578&amp;amp;idx=3&amp;amp;sn=2c4141258b0134642c5f4312a56301de&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718578&amp;amp;idx=3&amp;amp;sn=2c4141258b0134642c5f4312a56301de&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;" target="_blank"&gt;&lt;span&gt;谷歌开源新的 TensorFlow 代码，如何进行文本自动摘要&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718786&amp;amp;idx=4&amp;amp;sn=274bbf2332427a274123f6b9e009487e&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718786&amp;amp;idx=4&amp;amp;sn=274bbf2332427a274123f6b9e009487e&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;" target="_blank"&gt;&lt;span&gt;谷歌开放 TF-Slim：在 TensorFlow 中定义复杂模型的高层库&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716578&amp;amp;idx=1&amp;amp;sn=aae84df4e4e218afcd9f2d7cc88c96eb&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716578&amp;amp;idx=1&amp;amp;sn=aae84df4e4e218afcd9f2d7cc88c96eb&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;" target="_blank"&gt;&lt;span&gt;谷歌新开源「宽度&amp;amp;深度学习」框架：结合记忆和归纳实现更优推荐（附论文）&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718798&amp;amp;idx=2&amp;amp;sn=d18431b7d6e352a1001a938d007dec82&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718798&amp;amp;idx=2&amp;amp;sn=d18431b7d6e352a1001a938d007dec82&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;" target="_blank"&gt;&lt;span&gt;谷歌开放Inception-ResNet-v2：一种新的图像分类卷积神经网络模型&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715438&amp;amp;idx=1&amp;amp;sn=3573abf9634a55c9547409a35ca18b38&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715438&amp;amp;idx=1&amp;amp;sn=3573abf9634a55c9547409a35ca18b38&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;" target="_blank"&gt;&lt;span&gt;谷歌开源最精确自然语言解析器SyntaxNet的深度解读：一次关键进步以及一个重要工具&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650723201&amp;amp;idx=2&amp;amp;sn=81dd9fbd5f00b1d17437c17a2e14f8c9&amp;amp;chksm=871b17ffb06c9ee92edc24c76eb32c05173ce2831c4109fb779293fdec9de146bf5e34fadd6d&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650723201&amp;amp;idx=2&amp;amp;sn=81dd9fbd5f00b1d17437c17a2e14f8c9&amp;amp;chksm=871b17ffb06c9ee92edc24c76eb32c05173ce2831c4109fb779293fdec9de146bf5e34fadd6d&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;" target="_blank"&gt;&lt;span&gt;雅虎BigML团队开源大数据分布式深度学习框架TensorFlowOnSpark&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650723010&amp;amp;idx=1&amp;amp;sn=18ce6c3662b346b8d47f19cac8d797ed&amp;amp;chksm=871b16bcb06c9faaf3a5f7decb67ba6d7f0a16ec7b574f05a518a8d6831175c0a1cbeb966c40&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650723010&amp;amp;idx=1&amp;amp;sn=18ce6c3662b346b8d47f19cac8d797ed&amp;amp;chksm=871b16bcb06c9faaf3a5f7decb67ba6d7f0a16ec7b574f05a518a8d6831175c0a1cbeb966c40&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;" target="_blank"&gt;&lt;span&gt;谷歌发布深度学习库TensorFlow Fold，支持动态计算图&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650723201&amp;amp;idx=3&amp;amp;sn=204b20981a52c8e190624e0c0e445857&amp;amp;chksm=871b17ffb06c9ee9b4fc57ea05762dde2f54229f7510c1f60deb7b6707ec3647066aa192a0a5&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650723201&amp;amp;idx=3&amp;amp;sn=204b20981a52c8e190624e0c0e445857&amp;amp;chksm=871b17ffb06c9ee9b4fc57ea05762dde2f54229f7510c1f60deb7b6707ec3647066aa192a0a5&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;" target="_blank"&gt;&lt;span&gt;Wasserstein GAN 的 TensorFlow 实现&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720302&amp;amp;idx=4&amp;amp;sn=5a54ac9d2097f0db11d1da8a65cf2e4c&amp;amp;chksm=871b0c50b06c85466eb0bb5e455e306deca82662d83895f9d6ad2311539a9adf7056dac306ac&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720302&amp;amp;idx=4&amp;amp;sn=5a54ac9d2097f0db11d1da8a65cf2e4c&amp;amp;chksm=871b0c50b06c85466eb0bb5e455e306deca82662d83895f9d6ad2311539a9adf7056dac306ac&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;" target="_blank"&gt;&lt;span&gt;TensorFlow 生态系统：与多种开源框架的融合&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719713&amp;amp;idx=3&amp;amp;sn=b9a3fbdd5a0bc14a4a3b3a94039b9a85&amp;amp;chksm=871b019fb06c888987a8664b5145091caf888f4bd48581cc053a393800e9f17b29b839804cee&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719713&amp;amp;idx=3&amp;amp;sn=b9a3fbdd5a0bc14a4a3b3a94039b9a85&amp;amp;chksm=871b019fb06c888987a8664b5145091caf888f4bd48581cc053a393800e9f17b29b839804cee&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;" target="_blank"&gt;&lt;span&gt;DeepMind语音生成模型WaveNet的TensorFlow实现&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721559&amp;amp;idx=4&amp;amp;sn=950d87934d39712fab6164d3d2a37be5&amp;amp;chksm=871b0969b06c807f47b6fac20daae25d6d2f57495f6624554550fad7177f56657d208f40690d&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721559&amp;amp;idx=4&amp;amp;sn=950d87934d39712fab6164d3d2a37be5&amp;amp;chksm=871b0969b06c807f47b6fac20daae25d6d2f57495f6624554550fad7177f56657d208f40690d&amp;amp;scene=21#wechat_redirect" target="_blank"&gt;&lt;span&gt;OpenAI 的 PixelCNN++实现：基于 Python3 和 TensorFlow&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720463&amp;amp;idx=2&amp;amp;sn=50d88169778ec31a1e1e2d801325005d&amp;amp;chksm=871b0cb1b06c85a7e0299fc733b67d3107970f1176186a2ac8ca2dd5a23d896b5041e592ab4d&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720463&amp;amp;idx=2&amp;amp;sn=50d88169778ec31a1e1e2d801325005d&amp;amp;chksm=871b0cb1b06c85a7e0299fc733b67d3107970f1176186a2ac8ca2dd5a23d896b5041e592ab4d&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;" target="_blank"&gt;&lt;span&gt;DeepMind提出的可微神经计算机架构的TensorFlow实现&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;教程&lt;/strong&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2"&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717557&amp;amp;idx=1&amp;amp;sn=6c8239ec01c2a3f0def744063d070eec&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717557&amp;amp;idx=1&amp;amp;sn=6c8239ec01c2a3f0def744063d070eec&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;" target="_blank"&gt;&lt;span&gt;谷歌官方指南：如何通过玩TensorFlow Playground来理解神经网络&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722700&amp;amp;idx=1&amp;amp;sn=4e14edc4b11cda185cb0788e197118a5&amp;amp;chksm=871b15f2b06c9ce44805dd3bd33103fe5d03159636dadf685c2f517cfd94f9ca378773cf83cc&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722700&amp;amp;idx=1&amp;amp;sn=4e14edc4b11cda185cb0788e197118a5&amp;amp;chksm=871b15f2b06c9ce44805dd3bd33103fe5d03159636dadf685c2f517cfd94f9ca378773cf83cc&amp;amp;scene=21#wechat_redirect" target="_blank"&gt;&lt;span&gt;没有博士学位，照样玩转TensorFlow深度学习&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718229&amp;amp;idx=1&amp;amp;sn=adaf68f2c193028f1c4de5b8d3217cca&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718229&amp;amp;idx=1&amp;amp;sn=adaf68f2c193028f1c4de5b8d3217cca&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;" target="_blank"&gt;&lt;span&gt;如何在 TensorFlow 中用深度学习修复图像？（附论文）&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719794&amp;amp;idx=2&amp;amp;sn=8e320caa1d32f7a444a17bfa93b318ad&amp;amp;chksm=871b024cb06c8b5a421efa2eedff5b7149d17028d99e95a38857785db06c1eb2b7796d6e7e4f&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719794&amp;amp;idx=2&amp;amp;sn=8e320caa1d32f7a444a17bfa93b318ad&amp;amp;chksm=871b024cb06c8b5a421efa2eedff5b7149d17028d99e95a38857785db06c1eb2b7796d6e7e4f&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;" target="_blank"&gt;&lt;span&gt;资源 | 数十种TensorFlow实现案例汇集：代码+笔记&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719723&amp;amp;idx=4&amp;amp;sn=f86e2f30bcee67a424d4617b72560b8d&amp;amp;chksm=871b0195b06c88832108944311c2494a30483590c8c301b0076e2190734a3271e2929db312ed&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719723&amp;amp;idx=4&amp;amp;sn=f86e2f30bcee67a424d4617b72560b8d&amp;amp;chksm=871b0195b06c88832108944311c2494a30483590c8c301b0076e2190734a3271e2929db312ed&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;" target="_blank"&gt;&lt;span&gt;10种深度学习算法的TensorFlow实现&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718466&amp;amp;idx=1&amp;amp;sn=016f111001e8354d49dd4ce279d283cd&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718466&amp;amp;idx=1&amp;amp;sn=016f111001e8354d49dd4ce279d283cd&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;" target="_blank"&gt;&lt;span&gt;机器学习敲门砖：任何人都能看懂的TensorFlow介绍&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&amp;copy;本文为机器之心原创，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;
</description>
      <pubDate>Sat, 18 Feb 2017 12:44:39 +0800</pubDate>
    </item>
    <item>
      <title>深度 | 深度学习概览之自然语言处理：从基本概念到前沿研究</title>
      <link>http://www.iwgc.cn/link/</link>
      <description>
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自Adit Deshpande blog&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Adit Deshpande&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：赵华龙、王宇欣、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote style="color: rgb(62, 62, 62); font-size: 16px; white-space: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/blockquote&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;本文是 Adit Deshpande 的 Deep Learning Research Review 系列文章的第三篇，总结和解读了深度学习在自然语言处理领域的应用。在这里，机器之心随带推荐一篇之前发过的文章《&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721979&amp;amp;idx=4&amp;amp;sn=783ef5189604021eadb39b3d28a08ce6&amp;amp;chksm=871b0ac5b06c83d378629c45f23805227da892c2e934dce6e6aa5d9d5dc0612174842f6e3017&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721979&amp;amp;idx=4&amp;amp;sn=783ef5189604021eadb39b3d28a08ce6&amp;amp;chksm=871b0ac5b06c83d378629c45f23805227da892c2e934dce6e6aa5d9d5dc0612174842f6e3017&amp;amp;scene=21#wechat_redirect" target="_blank"&gt;总结 | 2016 年最值得读的自然语言处理领域 Paper&lt;/a&gt;》&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;自然语言处理介绍&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;介绍&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自然语言处理（NLP）研究的问题是关于如何构建通过处理和理解语言来执行某些任务的系统。这些任务可包括&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;问答（像 Siri、Alexa、Cortana 所做的那些）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;情感分析（决定是否某句话包含积极或消极的内涵）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;图像到文字的映射（生成一幅输入图像的注释）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;机器翻译（将一段文字翻译成另一种语言）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;语音识别&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;词性标注&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;命名实体识别&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;传统的 NLP 方法涉及很多语言学领域自身的知识。要理解诸如音位和语素这样的术语是非常基本的要求，就好像他们的研究统统都是语言学问题一样。让我们来看看传统 NLP 是如何尝试理解下面的话的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/8c351764b3ae85dbddb35a4098074ff49dfdd33f"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;假设我们的目标是收集关于这个词的一些信息（表征其情感，找到它的定义等）。使用我们语言领域的知识，我们可以把这个词分成 3 部分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/aaf0289b15d35f88ca8ecd51065c5aa196fa8378"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们知道前缀「un」表示反对或相反的想法，我们知道「ed」可以指定单词的时间段（过去时态）。通过识别词干「兴趣」的含义，我们可以很容易地推导出整个词的定义和情感。看起来很简单吧？然而，当考虑英语中所有不同的前缀和后缀时，需要非常熟练的语言学家来理解所有可能的组合和意义。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/e2b8a461d460e842a4d012af3c00ae1802147806"/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;深度学习如何很好地解决这些问题？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从最基础层面来说，深度学习即是表征学习（representation learning）。通过卷积神经网络（CNN），我们可以看到不同的过滤器（filter）组合可以用来将各种物体分类。这里，我们将采用一种相似的方式，通过大数据集来创建对各种词的表征。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;本文概论&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本文将以这样的方式来组织文章的内容结构：我们将首先浏览一下构建 NLP 深度网络的基本构建块，然后来谈一谈最近研究论文所能带来的一些应用。不知道我们为什么使用 RNN 或者为什么 LSTM 很有效？这些疑问都很正常，但希望你在读完下面的这些研究论文之后能更好地了解为什么深度学习技术能够如此显著地促进了 NLP 的发展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;词向量（Word Vectors）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由于深度学习爱用数学进行工作，我们将把每个词表示为一个 d 维向量。让我们使 d = 6。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;[Image: https://quip.com/-/blob/cGAAAAubYyb/u9YfGL3mGnMUFhrXOfGArQ] 现在让我们考虑如何填这些值。我们想要以这样的方式填充值：向量以某种方式表示词及其语境、含义或语义。一种方法是创建共生矩阵（coocurence matrix）。假设我们有以下句子：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/c09211bacfcc8f47f54288bf2d374ab316572951"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从这句话，我们要为每个特定的词都创建一个词向量。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/58169d57fd3296c60b3f8b0ca3a1f79bdbf04a6a"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;共生矩阵是包含了在语料库（或训练集）中每个词出现在所有其他词之后的计数数目的矩阵。让我们看看这个矩阵。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/0a20120d27c8d99cbefd6eaedf7082b8e1d9c9ad"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从该矩阵中提取行可以让我们的词向量简单初始化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/533c3da92ecd19e2b91af76430c17f5a996d51ea"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;请注意，通过这个简单的矩阵，我们可以获得一些非常有用的见解（insight）。例如，请注意「love」和「like」这两个词都包含 1，用于名词（NLP 和狗）后的计数。它们与「I」的交集也是 1，因此表明这些词必须是动词。对于远比一个句子更大的数据集，你可以想象这种相似性将变得更加清楚，因为「like」，「love」和其他同义词将开始具有相似的单词向量，因为它们都在相似的上下文中使用。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在，尽管这是一个了不起的起点，但我们注意到每个词的维数将随着语料库的大小线性增加。如果我们有一个百万词（在 NLP 标准中并不是很多），我们将有一个一百万乘一百万尺寸的矩阵，它将会非常稀疏（大量的 0）。从存储效率上讲这绝对不是最好的。在寻找表示这些词向量的最优方法方面已经有许多进步。其中最著名的是 Word2Vec。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Word2Vec&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;词向量初始化技术背后的基本思想是，我们要在这种词向量中存储尽可能多的信息，同时仍然保持维度在可管理的规模（25 - 1000 维度是理想的）。Word2Vec 基于这样一个理念来运作，即我们想要预测每个单词周围可能的词。让我们以上一句话「I love NLP and I like dogs」为例。我们要看这句话的前 3 个词。3 因此将是我们的窗口大小 m 的值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/bfcf4f0651ac695741a7039d43ba9c84e4ffe7f9"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在，我们的目标是找到中心词，「love」，并预测之前和之后的词。我们如何做到这一点？当然是通过最大化/优化某一函数！正式地表述是，我们的函数将寻求给定当前中心词的上下文词的最大对数概率。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/e1bbd5fc9fe7644964c357e7920aa403f669b8b5"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;让我们对这一点再深入地探究。上面的成本函数（cost function）基本上是说我们要添加'I'和'love'以及'NLP'和'love'的对数概率（其中「love」是两种情况下的中心词）。变量 T 表示训练句子的数量。让我们再仔细研究一下那个对数概率。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/80ec9abc71a42d16aa0f9362a8cfca84a0ed76fe"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Vc 是中心词的词向量。每个词由两个向量表示（Uo 和 Uw），一个用于当该词用作中心词时，一个用于当它用作外部词（outer word）时。向量是用随机梯度下降（SGD）来训练的。这绝对是一个理解起来更让人困惑的方程之一，所以如果你仍然有疑问想了解到底发生了什么，你可以查看以下两个资源：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;How does word2vec work?：https://www.quora.com/How-does-word2vec-work&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Word Embedding Explained and Visualized - word2vec and wevi：https://www.youtube.com/watch?v=D-ekE-Wlcds&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一句总结：Word2Vec 寻求通过最大化给定中心词的上下文词的对数概率并通过 SGD 修改向量来找到不同词的向量表示。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（可选：论文《Distributed Representations of Words and Phrases and their Compositionality》的作者接着详细介绍了如何使用频繁词的负采样（negative sampling）和下采样（subsampling）获得更精确的词向量。）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有人认为，Word2Vec 最有趣的贡献是使得不同词向量之间表现出线性关系。经过训练，词向量似乎能捕获不同的语法和语义概念。这些线性关系是如何能通过简单的对象函数和优化技术来形成的，这一点真是相当难以置信。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/d10ab5b0c1e77300c6d3d3f5dfff9919c8ecc619"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;额外补充：另一种很酷的词向量初始化方法：GloVe（将共生矩阵与 Word2Vec 的思想结合在一起）：http://nlp.stanford.edu/pubs/glove.pdf&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;循环神经网络（RNN）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;好吧，那么现在我们有了我们的词向量，让我们看看它们如何与循环神经网络结合在一起的。RNN 是当今大多数 NLP 任务的必选方法。RNN 的最大优点是它能够有效地使用来自先前时间步骤的数据。这是一小片 RNN 的大致样子。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/ad1045195639c1544edabb0ff9d847cd513c61a6"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt; 因此，在底层，我们有我们的词向量（xt，xt-1，xt + 1）。每个向量在同一时间步骤（ht，ht-1，ht + 1）有一个隐藏状态向量。让我们称之为一个模块（module）。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/9d816409980c11cbfed4e9aa7731111964e342c0"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;RNN 的每个模块中的隐藏状态是在前一时间步骤的词向量和隐藏状态向量二者的函数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/9a595a9723b0962a90d378f5f8ce083fa1ac5638"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你仔细看看上标，你会看到有一个权重矩阵 Whx，我们将它乘以我们的输入，并且在上一个时间步骤中，用一个循环出现的权重矩阵 Whh 乘以隐藏状态向量。请记住，这些循环出现的权重矩阵（recurrent weight matrix）在所有时间步骤上都是相同的。这是 RNN 的关键点。仔细考虑一下这一点，它与传统的（比如 2 层的神经网络）非常不同。在这种情况下，我们通常对于每个层（W1 和 W2）都有不同的 W 矩阵。这里，循环权重矩阵在网络中是相同的。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了得到特定模块的输出（Yhat），将以 h 乘以 WS，这是另一个权重矩阵。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/bfcc34df4c2d810a99ac65737cf9fbc814938509"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;让我们现在退一步并且来理解 RNN 的优点是什么。与传统神经网络的最明显的区别是，RNN 接受输入的序列（在我们的例子中是词）。你可以将其与典型的 CNN 进行对比，在 CNN 中你只需要一个单一的图像作为输入。然而，使用 RNN，输入可以是从一个短句到一篇 5 段文章等各种长度。此外，该序列中的输入的顺序（order）可以极大地影响在训练期间权重矩阵和隐藏状态向量的改变情况。在训练之后，隐藏状态将有望捕获来自过去的信息（以前的时间步骤）。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;门控循环单位（GRU）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在让我们来看门控循环单元（GRU）。这种单元的目的是为计算 RNN 中的隐藏状态向量提供一种更复杂的方法。这种方法得以使我们保留捕获长距依赖（long distance dependencies）的信息。让我们想想看为什么在传统 RNN 设置中长期依赖会成为一个问题。在反向传播期间，误差将流经 RNN，即从最近的时间步骤至最早的时间步骤。如果初始梯度是个小数字（例如&amp;lt;0.25），则通过第 3 或第 4 模块，梯度实际上将会消失（链式规则乘以梯度），因此较早时间步骤的隐藏状态将无法更新。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在传统的 RNN 中，隐藏状态向量通过下面的公式计算得来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/905490eb905a51f7c37a20e7a26e084cf89295fe"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;GRU 提供了一个计算此隐藏状态向量 h(t) 的不同方式。计算分为 3 个分量，一个更新门（update gate），一个重置门（reset gate）以及一个新的记忆容器（memory container）。两个门均是前一时间步骤上输入词向量和隐藏状态的函数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/ceda5176b7faf1a563a5a62b2dd8e487a4f70cc0"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关键区别在于每个门使用不同的权重。这种区别通过不同的上标来表示。更新门使用 Wz 和 Uz，而重置门使用 Wr 和 Ur。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在，通过以下方式计算新的记忆容器：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/6b5abdc6f21b8e3382485ade1d648f7aacc6f949"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;空心点表示Hadamard积&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在，如果你仔细看看公式，你将看到，如果重置门单元接近 0，那么整个项也变为 0，此时可以忽略来自之前时间步骤的 ht-1 的信息。在这种情况下，单元只是新的词向量 xt 的函数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;h(t) 的最终公式写为：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/a8fbdd36ec5141af066a29aed82f51f78508329f"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;ht 是一个由三部分构成的函数：重置门、更新门和记忆容器。通过观察当 zt 接近 1 和接近 0 时会发生什么是理解这点最好的方法。当 zt 接近 1 时，新的隐藏状态向量 ht 主要取决于先前的隐藏状态，且因为（1-zt）变为 0 使得我们会忽略当前的存储容器。当 zt 接近 0 时，新的隐藏状态向量 ht 主要取决于当前的存储容器，此时我们会忽略之前的隐藏状态。观察这三部分最直观的方法可以总结如下。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;更新门， 如果 zt〜1，则 ht 完全忽略当前词向量，且只复制上一个隐藏状态（如果行不通，看看 ht 方程，并且注意当 zt〜1 时 1 - zt 项发生什么）。如果 zt〜0，则 ht 完全忽略上一时间步骤上的隐藏状态，且依赖新的记忆容器。此门让模型控制着之前隐藏状态中应影响当前隐藏状态的信息的多少。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;重置门， 如果 rt〜1，则存储容器阻止来自之前隐藏状态的信息。如果 rt〜0，则存储容器忽略之前的隐藏状态。如果该信息在将来不具有相关性，则此门会令模型删除信息。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;记忆容器：取决于重置门。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;阐明 GRU 有效性的常见示例如下。假设你有以下语段。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/4052a26b8054100d3953017f8490ac16ca62b689"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt; 和相关问题「2 个数字的和是什么？」。由于中间语句对手头问题绝对没有影响，重置门和更新门将允许网络在一定意义上「忘记」中间语句，同时仅学习应修改隐藏状态的特定信息（这种情况下是数字）。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;长短时记忆单元（LSTM）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你对 GRU 感到满意的话，那么 LSTM 并不会让你更加满意。LSTM 也是由一系列的门组成。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/e6ba037ada2ff285f2e632c361c576fe89009fbd"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;肯定有更多的信息需要采集。因为这可以被认为是 GRU 背后的想法的延伸，我不会进行深入地分析。如果你想对每一个门和每一步计算进行深入地演算，请查看 Chris Olah 的一篇非常好的博客文章：http://colah.github.io/posts/2015-08-Understanding-LSTMs/。这是迄今为止，在 LSTM 上最受欢迎的教程，它一定会帮助你理解这些单元工作的这么好的原因和其工作方式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;LSTM 和 GRU 的比较&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;让我们从两者相似之处看起。这两种单元具有能够保持序列中字的长期依赖性的特殊功能。长期依赖性指两个词或者短语可能会在不同的时间段出现的情况，但是它们之间的关系对于解决最终目标仍然至关重要。LSTM 和 GRU 能够通过忽略或者保持序列中的某些信息的门来获取这些依赖性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;两个单元之间的差异在于它们所拥有的门的数量（GRU &amp;ndash; 2, LSTM &amp;ndash; 3）。这影响了输入通过的非线性数，并最终影响整体计算。GRU 也不具有与 LSTM 相同的记忆单元（ct）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;看论文之前&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;只是做一个快速的注释。还有一些其他的深度模型在自然语言处理（NLP）当中很有用。递归神经网络（recursive neural networks）和用于自然语言处理（NLP）的卷积神经网络（CNN）有时会在实践中应用，但不像循环神经网络（Recurrent neural Network）那样流行。循环神经网络（RNN）是在大多数深度学习自然语言处理（NLP）系统中的支柱。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;好的。现在我们对与自然语言处理（NLP）相关的深度学习有了不错的理解，让我们来看一些论文。由于在自然语言处理（NLP）中有许多不同领域的问题（从机器翻译到问题回答），我们可以研究许多论文，但是我发现其中有三篇论文有着独到的见解。2016 年，在自然语言处理（NLP）方面有着巨大的进步，但是让我们从 2015 年的一篇论文看起。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：记忆网络（Memory Networks）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;链接：https://arxiv.org/pdf/1410.3916v11.pdf&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;简介：&lt;/span&gt;&lt;span&gt;第一篇文章，我们将要讨论的是在问答（Queston Answering）子领域的一个非常有影响力的论文。作者是 Jason Weston、Sumit Chopra 和 Antoine Bordes，这篇论文介绍了一类称为记忆网络的模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;记忆网络的直观思想是：为了准确地回答关于一段文本的问题，你需要以某种方式记忆被提供的最初的信息。如果我问你「RNN 代表什么？」，（假设你已经完全阅读了这篇文章），你将会给我一个答案。因为你通过阅读这篇文章的第一部分所得到的信息，将会存储在你记忆中的某个地方。你只需要几秒钟来找到这个信息，并用文字将其表述出来。现在，我不知道大脑是如何作到这一点的，但是为信息保留存储空间的想法仍然存在。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本文中描述的记忆网络是唯一的，因为它是一种能够读写的关联记忆（associative memory）。有趣的是，我们并没有这种类型的卷积神经网络或者 Q 网络（Q-Network）（应用于强化学习）或者传统的神经网络的记忆。这是因为问答任务很大程度上依赖于建模的能力或者保持追踪长期依赖性的能力，比如追踪故事中的角色或事件的时间线。使用卷积神经网络和 Q 网络，「记忆（memory）」是一种内置在网络的权重。因为它可以学习从状态到动作的不同的筛选或者映射。首先，可以使用 RNN 和 LSTM，但是它们通常不能记忆来自过去的输入（这在回答任务中中非常重要）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;网络架构&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;好的，现在让我们来看一看这个网络如何处理它给出的初始文本。就像大多数机器学习算法一样，第一步是将输入转化为特征表示。这需要使用词向量、词性标签等。这真的取决于编程者。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/bc78a8496565c9680612f1a235d8f18ae805cd47"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下一步将采用特征表示 I(x)，并允许更新我们的记忆 m 以反映我们接收到的最新的输入 x。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/91f212fa7f4dbab1df0883d0ab7b7cc7af41061f"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你可以认为记忆 m 是一种由单独的记忆 mi 组成的数组。这些单独的记忆 mi 中的每一个都可以作为整体的记忆 m，特征表示 I(x) 和/或者它本身。该函数 G 可以简单地将整个表示 I(x) 存储在单独的记忆单元 mi 中。基于新的输入，你可以修改函数 G 来更新过去的记忆。第三和第四步包括基于问题读取记忆以获得特征表示 o，然后对其解码以输出最终答案 r。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/9b19c76597c861ff8b03435ce5fc93b336b677be"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;R 函数可以用来将特征表示从记忆转化为问题的即可靠又准确的答案。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在，让我们来看第三步。我们希望这个 O 模块输出一个特征表示，使其最佳地匹配给定问题 X 的一个可能的答案。现在这个问题将要与每个独立的记忆单元进行匹配并且基于记忆单元支持该问题的程度被「评分」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/c18408ac237a8a7741b1dd80988d77e45b85f5ac"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们使用评分函数的 argmax 值来找到支持问题的最佳输出表示（你也可以取多个最高得分单位，不必限于 1）。评分函数是计算不同问题和选取存储单元的不同嵌入之间的矩阵乘积的函数（更多细节请查看论文）。你也可以这样认为，你将两个单词的单词向量相乘以找到他们的相似之处。然后将输出表示 o 馈送入 RNN 或者 LSTM 或者另一个输出可靠答案的评分函数。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该网络以监督的方式训练，其中训练数据包括原始文本、问题、支撑句（supporting sentences）、以及 ground truth 答案。这里是目标函数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/88217f4daf01e73f09c2d060cd4a1746d14705b9"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt; 对于那些感兴趣的人，这是构建这种记忆网络方法的论文。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;End to End Memory Networks：https://arxiv.org/pdf/1503.08895v5.pdf&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Dynamic Memory Networks：https://arxiv.org/pdf/1506.07285v5.pdf&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Dynamic Coattention Networks ：https://arxiv.org/pdf/1611.01604v2.pdf&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：用于情感分析的 LSTM 树（Tree LSTMs for Sentiment Analysis）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;链接：https://arxiv.org/pdf/1503.00075v3.pdf&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;简介：&lt;/span&gt;&lt;span&gt;下一篇文章讨论了情感分析方面的进步，确定短语是否有正面或者负面的含义/意义。更正式地说，情感可以被定义为「对于某个情况或事件的看法或者态度」。当时，LSTM 是情感分析网络中最常用的单元。作者：Kai Sheng Tai、Richard Socher 和 Christopher Manning，本文介绍了以一种非线性的结构将 LSTM 连接在一起的新方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种非线性组合背后的动机在于自然语言中表现出的将序列中的词变成短语的特性。这些取决于词的顺序的短语可以有着与原始的组成词不同的意义。为了表示这种特性，LSTM 单元的网络被布置成树状结构，其中不同单元受其子节点的影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;网络架构&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;LSTM 树和标准树之间的一个区别是，后者的隐藏状态是当前输入和先前时间步长的隐藏状态的一个函数。然而，对于 LSTM 树，其隐藏状态是当前输入和其子单元的隐藏状态的函数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有着新的基于树的结构，一些数学变换，包括具有遗忘门（forget gates）的子单元。对于那些对细节感兴趣的人，请查看论文获取更多信息。然而，我想要关注的是为什么这些模块比线性 LSTM 工作的更好。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/32333cc0eeba611e73a835936f8da060c5e78496"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使用 LSTM 树，单个的单元能够并入其所有子节点的隐藏状态。这非常有趣，因为一个单元可以不同地评价其每个子节点。在训练期间，神经网络可以实现特定词（也许是在情感分析中的「not」或者「very」），这对句子的整体情感非常重要。将节点评价的更高为网络提供了极高的灵活性，并可以提高其性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：神经机器翻译（Neural Machine Translation）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;链接：https://arxiv.org/pdf/1609.08144v2.pdf&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;简介：&lt;/span&gt;&lt;span&gt;我们今天要讨论的最后一篇论文描述了机器翻译任务的另一种方法。作者为谷歌大脑的 Jeff Dean、Greg Corrado、Orial Vinyals 等人，本文介绍了一种机器翻译系统，该系统为谷歌流行的翻译任务的支柱。与之前使用的谷歌生产系统相比，该系统平均减少了 60% 的翻译错误。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;传统的自动翻译方法包括基于短语匹配的变体。这种方法需要大量的语言领域的知识，最终它的设计被证明太脆弱并且缺乏泛化能力。传统方法的一个问题是它将尝试逐个翻译输入的句子。结果，更有效的方法是（神经机器翻译（NMT）使用的方法）一次翻译整个句子，从而允许上下文更加广泛并且使语言重新排列的更加自然。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;网络架构&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本文作者介绍了一个深层 LSTM 网络，可以端对端的训练 8 个编码器和解码器层。我们可以将这个系统分为 3 个部分，编码器 RNN、解码器 RNN 和注意模块。从更高的等级，编码器致力于将输入的句子转变为向量的表示，解码器产生输出表示，然后注意模块告知解码器在解码任务期间要关注什么（这是一种使用句子的整体语境的思想）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/d589db18105d9d2759c37d4c1f61eeb48d6589af"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本论文的其余部分主要集中于大规模部署这样的服务相关的挑战。将详细讨论诸如计算资源量、延迟和大容量部署等主题。机器之心曾经报道过对这项研究的解读，请参阅《&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720582&amp;amp;idx=2&amp;amp;sn=06076c800c912622d8fa42665d7de1fc&amp;amp;chksm=871b0d38b06c842e3f6edaa5d36046b6702d26a0bcfb710c2010e5f0815389bf4f60077441ef&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720582&amp;amp;idx=2&amp;amp;sn=06076c800c912622d8fa42665d7de1fc&amp;amp;chksm=871b0d38b06c842e3f6edaa5d36046b6702d26a0bcfb710c2010e5f0815389bf4f60077441ef&amp;amp;scene=21#wechat_redirect" target="_blank"&gt;深度 | 逐层剖析，谷歌机器翻译突破背后的神经网络架构是怎样的？&lt;/a&gt;》&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;结论&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们总结了关于深度学习帮助自然语言处理任务的方法。在我看来，该领域一些的未来目标关注在改进客户服务聊天机器人、完善机器翻译、并希望使问答系统能够获得对非结构化或者冗长的文本（比如维基百科页面）的更深入的了解。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文链接：https://developers.googleblog.com/2017/02/debug-tensorflow-models-with-tfdbg.html&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;
</description>
      <pubDate>Sat, 18 Feb 2017 12:44:39 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 河南最快超算平台启用，加速智慧城市和人工智能应用</title>
      <link>http://www.iwgc.cn/link/</link>
      <description>
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Yan&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2 月 16 日，河南省最快超级计算机在郑州大学（郑州）超算中心正式投入使用。郑州大学超算中心的设备在软件的调度作用下形成了一个紧耦合的全面系统，借助高性能计算集群强大的计算能力，以深度学习硬件为优化工具，使用大数据分析的方法，对包括政务云学习在内的众多应用进行支撑。郑州大学还计划以该超算系统为平台，建设全国最大的人工智能人才培训基地，打造完整的人工智能综合生态，将成为河南省和郑州市在智慧城市和人工智能等领域加速科技创新的重要基础设施。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/f7ffb43bf39a7211dc2ee23a02f31ce8bfc42bac"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该系统部署了 Caffe-MPI 人工智能计算框架，该框架是浪潮集团在开源 Caffe 的基础上，依托中国并行计算联合实验室的资源，开发了 Caffe-MPI 并行版本，Caffe-MPI（https://github.com/Caffe-MPI/Caffe-MPI.github.io）由浪潮的 HPC 应用开发团队进行开发。Caffe-MPI 是一款分布式集群版本，目前支持 GPU 与 MIC 集群并行计算。如下是使用 KNL 集群运行 Caffe-MPI 框架的一个示例，可以看出计算时间得到大大减少。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/dcd695ecd19b2cd1ece7302b0a7aba3b4bc9d0d2"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前，该系统已经完成一期工程，其峰值计算性能达 800 万亿次每秒。在二期工程中，该超级计算机计划升级到每秒 3000 万亿次，将作为网格节点并入国家高性能计算环境。中国工程院院士、浪潮集团首席科学家王恩东表示，浪潮集团一直积极参与郑州智慧城市建设，此次与郑州大学的合作，是浪潮智慧计算战略的重要落地。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「人工智能实际上是这两年浪潮重点发展的方向。我们的定位是做人工智能应用背后计算力和基础设施的提供者。」浪潮集团高性能计算总经理刘军说：「现在中国绝大多数人工智能应用的背后，有超过 60% 以上的计算力是浪潮的运行，我们有专门的团队会针对人工智能的应用去设计相应的计算设施，帮助他们优化计算框架的软件，提供更好更适合的解决方案。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;浪潮在人工智能领域进行了深度布局。目前，浪潮已经拥有以图搜图、语音识别、企业网络安全深度学习应用和深度学习语音识别加速等应用案例，也包括完善的异构加速产品、ClusterEngine 集成深度学习作业管理调度及集群系统监控、基于高性能系统设计开发 Caffe-MPI 等产品。在刘军看来，人工智能所需要的大数据相当于汽油，像谷歌的 AI、百度用的 PaddlePaddle 等相当于车轮，而浪潮则是把这些整合起来做出高性能的一部车给开发者、应用者使用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在同一天开幕的世界大学生超级计算机竞赛（ASC17）中，郑州大学（郑州）超算将与神威&amp;middot;太湖之光成为承担不同赛题的运算平台。本届大赛由亚洲超算协会、郑州大学、国家超算无锡中心、浪潮合作举办，参赛队伍数量比去年增长 31%，共有来自世界各国 230 支队伍参赛将争夺进入总决赛的 20 强名额。ASC 竞赛发起人、中国工程院院士、浪潮集团首席科学家王恩东表示，随着超级计算、大数据、云计算相互融合，以人工智能为代表的智慧计算将成为未来计算产业里面最重要的组成部分，这将对计算技术带来新的挑战。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一个关键性运算平台神威&amp;middot;太湖之光，是世界上首台峰值计算速度超过十亿亿次的超级计算机，采用中国国产处理器构建。国家超算无锡中心主任、清华大学教授杨广文称，「我们做计算机的核心任务是怎么让这些应用人员把超算融合应用起来，没有超算，大数据、人工智能的开发非常困难，所以我们要降低人工智能使用超算的门槛。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;值得关注的是，此次竞赛增加了无人驾驶的交通预测赛题，希望推动在校大学生了解掌握最新的人工智能算法、大数据应用及先进计算架构的相关知识和能力。交通预测是当前热门的无人驾驶技术中最关键的应用软件之一，可以在考虑时空关系后对交通情况做出合理预测，帮助车辆选择最合适的路线，特别是在城市拥堵情况下的路线选择更有现实的意义。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;据了解，交通预测试题来自百度深度学习研究院，在预赛阶段，将给出某城市前 50 个工作日实际采集的交通状况的训练数据集，各参赛队可以通过百度 PaddlePaddle 深度学习计算框架进行数据训练，最终对第 51 个工作日早高峰期间每 5 分钟的交通状况进行预测，百度将根据交通预测的准确度评判各队的预赛成绩。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&amp;copy;本文为机器之心原创，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;
</description>
      <pubDate>Sat, 18 Feb 2017 12:44:39 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 谷歌发布tfdbg：让TensorFlow机器学习模型调试更简单</title>
      <link>http://www.iwgc.cn/link/</link>
      <description>
&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自Google Blog&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;作者：蔡善清&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;参与：李泽南、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;随着 2 月 16 日谷歌开发者大会上 &lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650723249&amp;amp;idx=1&amp;amp;sn=2503c119815d74f25703b252ee45f844&amp;amp;chksm=871b17cfb06c9ed9fc1c43f32750f9f4294c59514c174480ed3542722e621beca10d399505b4&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650723249&amp;amp;idx=1&amp;amp;sn=2503c119815d74f25703b252ee45f844&amp;amp;chksm=871b17cfb06c9ed9fc1c43f32750f9f4294c59514c174480ed3542722e621beca10d399505b4&amp;amp;scene=21#wechat_redirect" target="_blank"&gt;TensorFlow1.0&lt;/a&gt; 的发布，这一最流行的深度学习框架迈进了新的时代。昨天，谷歌宣布开源 TensorFlow Debugger，一个专用于调试TensorFlow 代码的新工具，希望以此让开发者们能够更轻松地构建机器学习项目。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今天，我们很高兴发布 TensorFlow Debugger：一个让 TensorFlow 中机器学习模型变得容易的工具。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：https://www.tensorflow.org/programmers_guide/debugger&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;TensorFlow 是谷歌开源的机器学习框架，它基于数据流图。构建一个典型的 TensorFlow 机器学习项目需要经历两个步骤：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 使用 Python API 将机器学习模型设置为数据流图。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 使用 Session.run() 对这个流图进行训练或应用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此前，如果在第二阶段出现了错误和 bug（如 TensorFlow runtime），我们很难进行 debug 工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了了解这种情况，请注意标准的 Python debugger，Session.run() 调用是一个单独的语句，不会暴露流图的内部结构（节点及其连接）和状态（输出数组或节点的张量）。一些低级的 debugger，如 gdb 无法理解 TensorFlow 流图的堆栈结构和变量值。所以，一个专用的运行环境调试器（debugger）是目前 TensorFlow 用户所急需的工具。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;tfdbg 的出现完美解决了运行环境调试器的需求。让我们看看它在一个简短的，用于运行简单线性方程梯度下降的代码片段中的表现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;import numpy as np
import tensorflow as tf
import tensorflow.python.debug as tf_debug
xs = np.linspace(-0.5, 0.49, 100)
x = tf.placeholder(tf.float32, shape=[None], name="x")
y = tf.placeholder(tf.float32, shape=[None], name="y")
k = tf.Variable([0.0], name="k")
y_hat = tf.multiply(k, x, name="y_hat")
sse = tf.reduce_sum((y - y_hat) * (y - y_hat), name="sse")
train_op = tf.train.GradientDescentOptimizer(learning_rate=0.02).minimize(sse)

sess = tf.Session()
sess.run(tf.global_variables_initializer())

sess = tf_debug.LocalCLIDebugWrapperSession(sess)
for _ in range(10):
  sess.run(train_op, feed_dict={x: xs, y: 42 * xs})&lt;/pre&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;正如代码高亮处所示，会话对象被包装为 debugging（LocalCLIDebugWrapperSession），因此调用 run() 方式将启动 tfdbg 的命令行界面（CLI）。使用鼠标点击或输入命令，你可以继续进行连续调用，检查流图节点和它们的属性，通过中间张量显示流图中执行所有相关节点的完整历史记录。通过使用 invoke_stepper 命令，你可以在「步进模式」中执行 Session.run() 调用。在该模式下，您可以跳转到所选节点，观察和修改它们的输出，然后继续检查下一步，这类似于程序语言的 debug（就像在 gdb 或 pdb 中）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在开发 TensorFlow 机器学习模型时，我们经常会遇到的问题是由于溢出、被零除、log0 等情况下出现的错误值（无穷大和 NaN）在大型 TensorFlow 流图中，寻找这样的错误是费时费力的。但现在通过 tfdbgCLI，你可以很快地找到罪魁祸首。以下视频展示了如何使用 tfdbg 解决神经网络代码中的无穷大/NaN 问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;iframe allowfullscreen="" class="video_iframe" data-vidtype="1" frameborder="0" height="417" src="https://v.qq.com/iframe/preview.html?vid=y03769m8n8i&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0" width="556"&gt;&lt;/iframe&gt;&lt;br&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相比于其他 debug 选择，比如 Print Ops，tfdbg 需要更少的代码行变化，还能提供对 graph 更全面的覆盖，以及更交互的 debug 体验。tfdbg 能够加速模型开发、debug 工作流程。它还提供了其他的特征，比如对服务器环境中废弃张量（dumped tensors）的离线 debug，还有融合 tf.contrib.learn 的特征。在你开始的时候，可以先浏览这一文档：&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://www.tensorflow.org/programmers_guide/debugger。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;运行 tfdbg 需求的 TensorFlow 最低版本是 0.12.1。报告 bug 时，请在 Github 上 TensorFlow 的问题页面开个问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以下论文详细展示了 tfdbg 的设计。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/16e7926e0b40df71256c00ac2a8cbd06422fbea3"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;论文：TensorFlow Debugger: Debugging Dataflow Graphs for Machine Learning&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：可调试性在机器学习系统的开发中非常重要。包括 TensorFlow 和 Theano 在内的多个普遍使用的机器学习框架都是基于数据流图的（dataflow graph)。虽然数据流图能提供分布式训练这样的便利，但这种范式也使得模型问题的 debugg 相比于传统的程序式模型的 debugg 更难。在此论文中，我们提出了 TensorFlow Debugger（tfdbg) 设计，为 TensorFlow 中的机器学习模型专门设计的 debugger。tfdbg 提供的特征包括检验运行时数据流图和媒介图形元素（张量，trensors），以及模拟在图上的步骤。我们将会讨论该 debugger 在开发和测试使用案例中的应用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;论文地址：https://research.google.com/pubs/pub45789.html&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;
</description>
      <pubDate>Sat, 18 Feb 2017 12:44:39 +0800</pubDate>
    </item>
    <item>
      <title>学界 | DeepMind提出PathNet：或可通过迁移学习实现通用人工智能</title>
      <link>http://www.iwgc.cn/link/</link>
      <description>
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自medium&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Th&amp;eacute;o Szymkowiak&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：黄小天、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通用人工智能（articial general intelligence/AGI）至今看起来仍然是遥不可及的一个技术圣杯，但这没有妨碍研究者向这个方向的努力。近日，一直研究成果不断的 DeepMind 又在 arXiv 上发布了一篇也许向这个方向迈进了一步的新论文，该论文提出了一种 PathNet，宣称能够实现某种巨型神经网络（giant neural network）。麦吉尔大学学生兼该校人工智能协会社长 Th&amp;eacute;o Szymkowiak 在 Medium 上发了一篇短文介绍了这篇论文。机器之心对这篇短文进行了编译，并对原论文进行了摘要介绍，原论文可点击文末「阅读原文」下载。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自从科学家开始构建和训练神经网络以来就一直没能跨过「迁移学习（transfer learning）」的难关。迁移学习是指人工智能学习不同任务并将预学习到的知识应用于全新任务的能力。很显然，具备预先知识的人工智能将在面对新任务时比全新开发的神经网络能表现得更好、训练得更快。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;也许 DeepMind 能用 PathNet 达到这一目标。PathNet 是一个由神经网络组成的网络（network of neural networks），通过随机梯度下降和遗传选择方法做训练。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;PathNet 由模块构成的层组成，其中每个模块都可以是一个任意类型的神经网络&amp;mdash;&amp;mdash;可以是卷积网络、循环网络、前馈网络等等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/5f6b9a1e1800c077dc5b45516d90a76fcf767e20"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 1：一个随机初始化的路径（框图 1 中的紫色线）的集合在学习任务 A Pong 游戏的过程中进化。在训练结束时，最好的路径是固定的（框图 5 中的暗红色线），并且会有一个针对任务 B 的新的路径（框图 5 中的淡蓝色线）集合被生成出来。这个路径集合然后在 Alien 游戏上得到训练，然后在 Alien 游戏上逐渐进化，在训练结束时固定达到最佳路径，如框图 9 中的深蓝色线所示。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这 9 个框图是在不同迭代时的 PathNet。在这个案例中，PathNet 被训练用 Advantage Actor-critic（A3C）玩两个不同的游戏。尽管在一开始 Pong 和 Alien 看上去很不同，但我们确实观察到（看一下得分图）了一个使用 PathNet 的迁移学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;它如何训练&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先，我们需要定义模块。设 L 为层数，N 为每一层的最大模块数（论文表明，N 通常是 3 或 4）。最后一层是密集的，并且不在不同任务之间共享。通过 A3C，最后一层表示价值函数（value function）和策略评估（policy evaluation）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那些模块定义完之后，网络之中生成 P 基因型 (=路径)。由于 A3C 的异步属性，需要多个工作器（worker）评估每一个基因型。在 T 个 episode 之后，一个工作器从其他路径中选一对进行比较，如果这些路径中的一些有更好的适配，那就采用它，并用那个新路径继续训练。如果不，则工作器继续评估其路径的合适程度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;迁移学习&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在学习了一个任务之后，网络会固定最优路径上的所有参数。所有其它参数将被重置，因为照论文上讲，如果不这样做，PathNet 将会在新任务中表现很差。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过使用 A3C，用于新任务的 PathNet 上的反向传播不会修改先前任务中的最优路径。这可以看作是保存先前知识的护卫。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;结果&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/0f60c6549ed750cc7519489d4105e9adecabe9a0"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 7：我们在超参数搜索上的最佳运行的结果。其中的表现是通过测量学习曲线下方的区域（在训练过程中每次 episode 的平均得分）而进行评估的，而不是通过最终得分。然后该迁移分数被定义为一个架构的相对表现，这是与一个带有一个固定最大尺寸路径的独立基线（控制量/control）进行比较得到的，这个基线是仅在目标任务上训练得到的（最上面一行）。当存在加速时，该比率大于 1，减速则该比率小于 1. 我们给出了在我们选择的源-目标（source-target）游戏上得到的迁移分数曲线，并在这个迁移矩阵（transfer matrix）中总结了所有的这种游戏对。接下来的 3 行显示出了 fine-tuning 控制的结果，后 3 行给出了 PathNet 的结果。绿色表示发生了正迁移（positive transfer），蓝色表示负迁移（negative transfer）。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;PathNet 并不在每一对游戏上都能有效（蓝色单元格等于负迁移）。但是重要的是 PathNet 已经对一些游戏对实际有效了，我们已经踏出了迈向更好迁移学习的巨大一步。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;延展思考&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;可以想象在将来，我们会有巨型的人工智能（giant AI），它们被训练完成数以千计的任务并且能够泛化，也就是：通用人工智能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/557ac4246b112b8468df6378c7f56aa39eacdde9"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;论文：PathNet：在超级神经网络中的进化通道梯度下降（PathNet: Evolution Channels Gradient Descent in Super Neural Networks）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果多个用户训练同一个巨型神经网络（giant neural network），同时允许参数复用，并且不会遗忘太多东西，则这对通用人工智能而言将是高效的。PathNet 是在这个方向上迈出的第一步。它是一个将代理嵌入到神经网络中的神经网络算法，其中代理的任务是为新任务发现网络中可以复用的部分。代理是网络之中的路径（称为 views），其决定了通过反向传播算法的前向和后向通过而被使用和更新的参数的子集。在学习过程中，锦标赛选择遗传算法（tournament selection genetic algorithm）被用于选择用于复制和突变的神经网络的路径。路径适配（pathway fitness）即是通过成本函数来度量的自身的表现。我们实现了成功的迁移学习；固定了从任务 A 中学习的路径的参数，并据此再进化出了用于任务 B 的新路径，这样任务 B 要比从头开始或 fine-tuning 学习得更快。任务 B 中进化的路径会复用任务 A 中进化出的最优路径的一些部分。在二元的 MNIST、CIFAR 和 SVHN 监督学习分类任务和一系列的 Atari、Labyrinth 强化学习任务上，我们都实现了正迁移，这表明 PathNet 在训练神经网络上具有通用性应用能力。最后，PathNet 也可以显著提高一个平行异步强化学习算法（A3C）的超参数选择的稳健性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;原文地址：https://medium.com/@thoszymkowiak/deepmind-just-published-a-mind-blowing-paper-pathnet-f72b1ed38d46#.bzxfs9cig&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;br&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;br&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Sat, 18 Feb 2017 12:44:39 +0800</pubDate>
    </item>
    <item>
      <title>从TensorFlow到Theano：横向对比七大深度学习框架</title>
      <link>http://www.iwgc.cn/link/4740970</link>
      <description>&lt;div class="article-content"&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;section style="max-width: 100%; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; line-height: 28.4444px; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%; border: 0px currentcolor; font-family: 微软雅黑; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; max-width: 100%; border-style: solid none; font-family: inherit; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-top: -1.2em; max-width: 100%; min-height: 1em; font-size: 1em; border: currentcolor; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(255, 255, 255); line-height: 22.4px; font-size: 1em; font-family: inherit; text-decoration: inherit; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(117, 117, 118);"&gt;选自SVDS&lt;/span&gt;&lt;/p&gt;&lt;section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px; max-width: 100%; font-family: inherit; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-bottom: 5px; max-width: 100%; min-height: 1em; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(127, 127, 127); font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;作者：Matthew Rubashkin&amp;nbsp;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; max-width: 100%; min-height: 1em; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; font-family: inherit; text-decoration: inherit; color: rgb(127, 127, 127); font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong style="max-width: 100%; font-family: inherit; text-decoration: inherit; color: rgb(127, 127, 127); font-size: 12px; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; max-width: 100%; min-height: 1em; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(127, 127, 127); font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;参与：李泽南&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;br&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;&lt;em&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;在深度学习项目开始前，选择一个合适的框架是非常重要的事情。最近，来自数据科学公司 Silicon Valley Data Science 的数据工程师 Matt Rubashkin（UC Berkeley 博士）为我们带来了深度学习 7 种流行框架的深度横向对比，希望本文能对你带来帮助。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px; line-height: 1.75em;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px; line-height: 1.75em;"&gt;在 SVDS，我们的研发团队一直在研究不同的深度学习技术；从识别图像到语音，我们也在各类框架下实现了不少应用。在这个过程中，我们意识到需要一个简明的方式来获取数据、创建模型、同时评估这些模型的表现。但当我们一次次开始新的深度学习项目时，我们却一直没有找到一个可以参考的标准来告诉自己如何开始。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;现在，为了回馈开源社区，同时帮助后来者，我们决定以我们的经验对目前流行的几种工具&lt;/span&gt;&lt;span style="font-size: 14px;"&gt;（Theano、TensorFlow、Torch、Caffe、MXNet、Neon 和 CNTK）&lt;/span&gt;&lt;span style="font-size: 14px;"&gt;进行一次横向对比。以下图表展示了各类深度学习工具的优劣，希望对大家能有所帮助。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;先放结论&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487305834f8xtUT.jpg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;这组对比参考了多种公开基准评测，以及我们在图像/语音识别应用时对这些技术的 主观印象。此外，你需要注意：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;语言&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;当你开始一个深度学习项目时，你最好使用一个支持你所会语言的框架。比如 Caffe（C++）和 Torch（Lua）只能支持有限的语言（最近，随着 &lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722553&amp;amp;idx=1&amp;amp;sn=ce635e60fa8f1cc16982c5d6a9a6931b&amp;amp;chksm=871b1487b06c9d9180d7f881784e68d4b9785481c38aa86eccc183aed8254b2a452e073a0c9b&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722553&amp;amp;idx=1&amp;amp;sn=ce635e60fa8f1cc16982c5d6a9a6931b&amp;amp;chksm=871b1487b06c9d9180d7f881784e68d4b9785481c38aa86eccc183aed8254b2a452e073a0c9b&amp;amp;scene=21#wechat_redirect"&gt;PyTorch &lt;/a&gt;的出现，情况有所改观）。所以如果你希望选用上述两个框架，我们建议你事先熟悉 C++或 Lua 语言。相比之下，TensorFlow 与 MXNet 具有丰富的多语言支持，即使你对 C++感到陌生也可以使用它们。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487305834d6vqSQ.png"/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487305834nfEA10.png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;教程和资源&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;目前，各类深度学习框架的教程与可利用的资源在质量和数量上有着显著的不同。Theano，TensorFlow，Torch 和 MXNet 有着很详尽的文档教程，很容易被初学者理解和实现。与此相比，虽然微软的 CNTK 和英特尔的 Nervana Neon 也是强大的工具，我们却很少能见到有关它们的新手级资料。此外，在研究过程中，我们发现 GitHub 社区的参与度不仅可以用于准确地评价不同工具的开发水平，而且还是在搜索 StackOverflow 或 repo 的 Git Issues 时能否快速解决问题的参考性指标。当然，作为谷歌提供的框架，TensorFlow 理所当然地在教程，资源，开发者和社区贡献者的数量上遥遥领先。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487305834HzYUlk.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;CNN 建模能力&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;卷积神经网络（CNN）经常被用于图像识别、推荐引擎和自然语言识别等方向的应用。CNN 由一组多层的神经网络组成，在运行时会将输入的数据进行预定义分类的评分。CNN 也可用于回归分析，例如构成自动驾驶汽车中有关转向角的模型。在横评中，我们评价一种框架的 CNN 建模能力考虑到以下几个特性：定义模型的机会空间、预构建层的可用性、以及可用于连接这些层的工具和功能。我们发现，Theano，Caffe 和 MXNet 都有很好的 CNN 建模能力。其中，TensorFlow 因为易于建立的 Inception V3 模型，Torch 因为其丰富的 CNN 资源——包括易于使用的时间卷积集使得这两种框架在 CNN 建模能力上脱颖而出。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;RNN 建模能力&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;递归神经网络（RNN）常用于语音识别，时间序列预测，图像字幕和其他需要处理顺序信息的任务。由于预建的 RNN 模型不如 CNN 数量多，因此，如果你已经有一个 RNN 深度学习项目，优先考虑旧 RNN 模型是在哪种框架里实现的最重要。目前，Caffe 上的 RNN 资源最少，而 Microsoft 的 CNTK 和 Torch 有丰富的 RNN 教程和预构建模型。当然，最流行的 TensorFlow 中也有一些 RNN 资源，TFLearn 和 Keras 中更有很多使用 TensorFlow 的 RNN 示例。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;架构&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;为在特定框架中构建和训练新模型，易于使用和模块化的前端是至关重要的。TensorFlow，Torch 和 MXNet 都有直观而模块化的架构，让开发相对变得简单。相比之下，我们在 Caffe 这样的框架上需要进行大量的工作才能创建一个新层。另外我们发现在开发过程中，因为有 TensorBoard web GUI 等应用的存在，TensorFlow 极易在训练中和训练后进行 debug 和监控。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;速度&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Torch 和 Nervana 具有开源卷积神经网络基准测试的最佳性能：&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: left; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;https://github.com/soumith/convnet-benchmarks/blob/master/README.md&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Tensorflow 的性能在大多数测试中是具有竞争力的，而 Caffe 和 Theano 稍稍落后：&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: left; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;https://github.com/tobigithub/tensorflow-deep-learning/wiki/tf-benchmarks&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;微软声称他们的 CNTK 在一些 RNN 训练任务中有最快的速度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;在另一项对比 Theano、Torch 和 TensorFlow 的 RNN 性能的研究中，Theano 是其中最快的：&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: left; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;https://arxiv.org/abs/1511.06435&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;多 GPU 支持&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;大多数深度学习应用都需要用到巨量的浮点运算（FLOP）。例如，百度的 DeepSpeech 识别模型需要 10s ExaFLOPs 用于训练，这是大于 10e18 的计算量：&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: left; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;https://arxiv.org/abs/1512.02595&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;考虑到目前英伟达 Pascal 架构的 TitanX 等顶级显卡可以每秒执行 11e9 FLOP：&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: left; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;https://www.nvidia.com/en-us/geforce/products/10series/titan-x-pascal/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;因此，假如需要在大型数据集上训练一个新模型——用单 GPU 机器的话——可能会需要一个星期之久。为了减少构建模型所需的时间，我们需要使用多 GPU 并联的方式组建自己的机器。幸运的是，上述大部分架构都可以很好地支持多 GPU 运算。其中，据报道 MXNet 有着最好的多 GPU 优化引擎：&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: left; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;http://www.allthingsdistributed.com/2016/11/mxnet-default-framework-deep-learning-aws.html&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;Keras 兼容性&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Keras 是一个用于快速构建深度学习原型的高级库。我们在实践中发现，它是数据科学家应用深度学习的好帮手。Keras 目前支持两种后端框架：TensorFlow 与 Theano，而且 Keras 再过不久就会成为 TensorFlow 的默认 API：&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: left; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;http://www.fast.ai/2017/01/03/keras/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;尽管如此，Keras 的作者表示，这一高级库在未来仍会作为支持多种框架的前端存在：&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: left; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;https://github.com/fchollet/keras/issues/5050#issuecomment-272945570&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;总结&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;如果你想要开始深度学习，你应该从评估自己的团队技能和业务需求开始。例如，如果一个以 Python 为中心的团队想开发图像识别的应用程序，你应该使用 TensorFlow，因为它有丰富的资源，较好性能和完整的原型工具。如果一个有 Lua 能力的团队希望将 RNN 大规模应用到生产环境中去，他们则会受益于 Torch 的高速和强大的 RNN 建模能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;未来，我们将继续讨论在更大规模的应用中这些框架的表现。这些挑战包括多机并联时的多 GPU 优化，多种开源库的兼容性，如 CMU Sphinx 和 Kaldi 等，尽请期待。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px; text-decoration: none;"&gt;&lt;em&gt;原文链接：&lt;/em&gt;&lt;/span&gt;&lt;a style="color: rgb(136, 136, 136); font-size: 12px; text-decoration: none;"&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;&lt;em&gt;http://www.svds.com/getting-started-deep-learning/&lt;/em&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="min-height: 1em; text-align: justify; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="line-height: 25.6px; font-family: 微软雅黑; font-size: 14px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; color: rgb(127, 127, 127); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="color: rgb(62, 62, 62); line-height: 25.6px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; color: rgb(127, 127, 127); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;©本文为机器之心编译，&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; font-size: 18px; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(127, 127, 127); line-height: 25.6px; font-family: 微软雅黑; text-align: justify; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(217, 33, 66); font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(217, 33, 66); line-height: 1.6; font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-size: 12px; color: rgb(217, 33, 66); line-height: 1.6; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/div&gt;</description>
      <pubDate>Fri, 17 Feb 2017 12:06:43 +0800</pubDate>
    </item>
    <item>
      <title>学界 | OpenAI探讨人工智能安全：用对抗样本攻击机器学习</title>
      <link>http://www.iwgc.cn/link/4740971</link>
      <description>&lt;div class="article-content"&gt;&lt;section style="max-width: 100%; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; line-height: 28.4444px; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%; border: 0px currentcolor; font-family: 微软雅黑; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; max-width: 100%; border-style: solid none; font-family: inherit; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-top: -1.2em; max-width: 100%; min-height: 1em; font-size: 1em; border: currentcolor; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(255, 255, 255); line-height: 22.4px; font-size: 1em; font-family: inherit; text-decoration: inherit; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(117, 117, 118);"&gt;选自&amp;nbsp;OpenAI Blog&lt;/span&gt;&lt;/p&gt;&lt;section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px; max-width: 100%; font-family: inherit; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-bottom: 5px; max-width: 100%; min-height: 1em; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(127, 127, 127); font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;作者：IAN GOODFELLOW, NICOLAS PAPERNOT 等&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; max-width: 100%; min-height: 1em; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; font-family: inherit; text-decoration: inherit; color: rgb(127, 127, 127); font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong style="max-width: 100%; font-family: inherit; text-decoration: inherit; color: rgb(127, 127, 127); font-size: 12px; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; max-width: 100%; min-height: 1em; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(127, 127, 127); font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;参与：微胖、李亚洲、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;对抗样本是扮演攻击角色、试图用来引发模型出错的机器学习模型的输入；如同机器产生的光影幻觉。在这篇博文中，我们将为读者展示对抗样本在各种不同介质中的运作原理，还会讨论为什么系统难以防御它们。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;在 OpenAI , 我们认为，对抗样本问题属于人工智能安全研究（我们正在从事）好的一面，因为它们代表着一个能在短期内加以解决的具体问题，由于解决它们比较难，因此需要进行严肃的科学研究。（尽管为了确保打造出一个安全、广为分布的人工智能系统，我们需要研究许多机器学习安全许多方面的问题。）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;为了搞清楚对抗样本的庐山真面，请考虑一下这篇研究《解释并驯服对抗样本（Explaining and Harnessing Adversarial Examples）》中的例证：开始是一张熊猫图片，接着，攻击方给图片添加了小的扰乱，足以让这只熊猫被认定为一只长臂猿。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487305836meDz1Z.jpg"/&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 12px;"&gt;叠加在典型图片输入上的对抗输入会让分类器产生错觉，误将熊猫识别为长臂猿。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;这一办法十分稳健；近期的一些研究也已经表明，在标准论文上打印出对抗样本，用一部标准像素智能手机拍下来后，这些样本仍然可以捉弄系统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/148730583680plML.jpg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;em&gt;&lt;span style="font-size: 12px; color: rgb(136, 136, 136);"&gt;对抗样本可以在论文上打印出来，用标准像素手机拍下后，仍然可以捉弄分类器，在这个例子中，分类器将「洗衣机」识别为「保险箱」。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;对抗样本具有潜在危险性。比如，攻击者可能会用贴纸或者一幅画做一个对抗式「停止（stop）」交通标志，将攻击对象瞄准自动驾驶汽车，这样，车辆就可能将这一「标志」解释为「放弃」或其他标识，进而引发危险。Practical Black-Box Attacks against Deep Learning Systems using Adversarial Examples 讨论过这个问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;一些新近的研究，比如，伯克利，OpenAI 以及宾大联合发表的论文 Adversarial Attacks on Neural Network Policies, 内华达大学 Vulnerability of Deep Reinforcement Learning to Policy Induction Attacks ，表明强化学习智能体也能被对抗样本操控。研究表明，广为采用的强化学习算法，比如，DQN , TRPO 以及 A3C ，都经不起对抗样本的捉弄。这些对抗样本输入会降低系统性能，即使扰乱微妙地让人类也难以察觉，智能体会在应该往上移动的时候却将球拍向下移动，或者在 Seaquest 中识别敌人的能力受到干扰。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;iframe class="video_iframe" data-vidtype="1" allowfullscreen="" frameborder="0" height="417" width="556" data-src="https://v.qq.com/iframe/preview.html?vid=q0375nj0fyk&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0"&gt;&lt;/iframe&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;如果各位看官想玩坏自己的模型，不放试一下 cleverhans 这个开源库，它是 Ian Goodfellow &amp;nbsp;和 Nicolas Papernot &amp;nbsp;一起研发的，旨在测试面对对抗样本，你的人工智能模型有多脆弱。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;在人工智能安全问题方面，对抗样本提供了一些牵引力&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;当你思考人工智能安全时，经常会考虑这个领域中最难的问题——我们如何能确保成熟的强化学习智能体（比人类要智能得多）能按照最初设计意图行事？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;对抗样本向我们展示了这样一个事实：即使是简单的现代算法，不管是监督学习还是强化学习，都能以出乎人类意料的方式行事。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;力图防卫对抗样本&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;让机器学习模型更加稳健的传统技术，比如权重衰减或者 dropout，通常无法切实防范对抗样本。到目前为止，仅有两个办法可以提供显著的防范措施。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;对抗训练：这是一种蛮力解决方案。我们简单地生成许多对抗样本，明确训练模型不要被这些样本给骗了。cleverhans 库提供了一个开源的对抗训练实现，这个教程里有指南（https://github.com/openai/cleverhans/blob/master/tutorials/mnist_tutorial_tf.md）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;Defensive distillation (https://arxiv.org/abs/1511.04508): 在这一策略中，我们训练模型生成关于输入属于不同类别的概率，而不是硬让系统决定输入到底属于哪一类。这一概率由更早一些的模型提供，该模型是针对同一任务，用比较难的类别标签训练过的。这会让我们得到一种模型——其表面在对手通常会加以利用的方向上是平滑的，这会使得对手很难发现导致错误分类的对抗输入调整。（Distilling the Knowledge in a Neural Network (https://arxiv.org/abs/1503.02531) 最初将这个办法视为一种模型压缩技术，为了节省计算资源，小模型被训练用来模拟大模型。）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;然而，只要个敌方再添加些计算火力，这些专门的算法也会被轻易攻下。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;失败的防御：「梯度掩模（gradient masking）」&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;为了给出一个关于简单防御可能如何失败的案例，让我们思考一下为什么一种叫做「梯度掩模（gradient masking）」的技术没有效果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;「梯度掩模」是一个由 2016 年的论文《使用对抗样本对深度学习系统进行实际的黑盒攻击（Practical Black-Box Attacks against Deep Learning Systems using Adversarial Examples）》引入的术语，其描述了一整类试图通过拒绝攻击者对有用梯度（useful gradient）的访问权限而进行防御的失败方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;大多数对抗样本构建技术都使用了模型的梯度来进行攻击。打个比方，它们查看了一张飞机图片，它们测试在图片空间中哪个方向会使「猫」类别的概率增加，然后它们在那个方向上给予一点推动（换句话说，它们干扰输入）。这样，新的修改过的图像就会被认为是一只猫。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;但如果其中并没有梯度呢——如果图片上一个无穷小的修改不会给模型的输出造成任何改变呢？这似乎就能够提供一定程度的防御，因为攻击者无法获悉向哪个方向「推动」图像。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;我们可以轻松地想象出一些非常简单的避免梯度的方式。比如，大部分图像分类模型都可归于两种模式：一是它们仅输出识别出的最有可能的类别，二是它们输出概率。如果一个模型的输出是「99.9% 的概率是飞机，0.1% 的概率是猫」，那么对输入的一点微小改变也会给输出带来一点微小的改变，而梯度就会告诉我们哪些改变会增加属于「猫」类的概率。如果我们运行的模型的模式是仅仅输出「飞机」而没有概率，那么一点微小的改变就不会对输出产生任何影响，梯度也不会让我们了解任何东西。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;下面让我们进行一个思想实验，看我们的模型在处于「最有可能类别」模式而非「概率模式」类别时，可以如何防御对抗样本。攻击者不再需要寻找将被分类为「猫」的输入，所以我们可能已经有了一些防御。不幸的是，之前被分类为「猫」的图像现在仍然还是被分类为「猫」。如果攻击者可以猜测哪些点是对抗样本，那么这些点仍然可被错误地分类。所以这种方法不能让该模型更稳健；只是让攻击者在寻找模型防御的漏洞时没有那么多的线索罢了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;更不幸的是，事实证明攻击者在猜测防御漏洞时具有非常好的策略。攻击者可以训练一个他们自己的模型——一个有梯度的平滑的模型，并为他们的模型制作对抗样本，然后只需要部署这些对抗样本和我们的非平滑模型进行对抗即可。很多时候，我们的模型也会错误分类这些样本。最后，我们的思想实验表明：隐藏梯度不会给我们带来任何好处。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;执行「梯度掩模」的防御策略通常会导致得到一个在特定方向上和训练点的附近非常平滑的模型，这会使得对手更难以找到指示了好的候选方向的梯度，从而更难以以破坏性的方式干扰该模型的输入。但是，对手可以训练一个「替代（substitute）」模型：一个模仿被保护的模型的副本——这可以通过观察被保护模型分配给对手仔细选择的输入的标签而实现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;这篇黑盒攻击论文介绍了一种用于执行这种模型提取攻击（model extraction attack）的方法。然后对手可以使用这种替代模型的梯度来寻找被被保护模型错误分类的对抗样本。在上图（该图来自论文《关于机器学习中的安全和隐私的科学（Towards the Science of Security and Privacy in Machine Learning）》中关于梯度掩模的讨论）中，我们给出了这种攻击策略在一个一维机器学习问题上的应用。该梯度掩模现象（gradient masking phenomenon）在更高维的问题上会加剧，但这是难以描述的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;我们发现对抗训练和 defensive distillation 都会偶尔执行一定类型的梯度掩模。这两种算法明显都不是为梯度掩模而设计的，但当机器学习算法要进行保护自己的训练而未被给出明确的方法指令时，梯度掩模显然是该机器学习算法能相对轻松地发明的一种防御。如果我们将对抗样本从一个模型迁移到另一个也经过对抗训练或 defensive distillation 训练过的模型，那么这个攻击通常会成功——即使当对第二个模型的直接进攻会失败时。这表明这两种模型做得更多的是展平模型和移除梯度，而不是确保其正确分类更多的点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;为什么防御（defend）对抗样本很难？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;对抗样本难以防御是因为很难构造对抗样本处理过程的理论模型。对抗样本是许多机器学习模型非线性、非凸性优化问题的解决方案，包括神经网络在内。因为我们没有好的理论工具来描述这些复杂的优化问题的解决方案，所以也很难作出理论性争辩说一种防御能够排除一系列的对抗样本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;对抗样本难以防御也因为它们需要机器学习模型为每个可能的输入生成好的输出。大部分时间，机器学习模型做的很好，但只有在小量的可能输入的情况下它们可能会碰头。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;目前为止我们测试的每个策略都失败了是因为它不够自适应（adaptive）：它能够限制一种攻击，但对知道该防御手段的攻击者（attacker）而言，它有其它弱点。设计一种能够防御强大的、会自适应的攻击者的手段，这是一个重要的研究领域。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;结论&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;对抗样本表明能以惊人的方式打破许多现代机器学习算法。机器学习上的这些失败证明即使是简单的算法也能表现出与设计初衷相差甚远的行为。我们鼓励机器学习研究人员参与进来，设计提防对抗样本的方法，从而缩短设计者初衷与算法表现之间的差距。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="color: rgb(136, 136, 136); text-decoration: none;"&gt;&lt;em&gt;&lt;span style="color: rgb(136, 136, 136); text-decoration: none; font-size: 12px;"&gt;原文链接：&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;a style="font-size: 12px; color: rgb(136, 136, 136); text-decoration: none;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;https://openai.com/blog/adversarial-example-research/&lt;/span&gt;&lt;/em&gt;&lt;em&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="min-height: 1em; text-align: justify; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="line-height: 25.6px; font-family: 微软雅黑; font-size: 14px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; color: rgb(127, 127, 127); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="color: rgb(62, 62, 62); line-height: 25.6px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; color: rgb(127, 127, 127); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;©本文为机器之心编译，&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; font-size: 18px; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(127, 127, 127); line-height: 25.6px; font-family: 微软雅黑; text-align: justify; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(217, 33, 66); font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(217, 33, 66); line-height: 1.6; font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-size: 12px; color: rgb(217, 33, 66); line-height: 1.6; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/div&gt;</description>
      <pubDate>Fri, 17 Feb 2017 12:06:43 +0800</pubDate>
    </item>
    <item>
      <title>学界 | 2012-2016 年被引用次数最多的深度学习论文</title>
      <link>http://www.iwgc.cn/link/4740972</link>
      <description>&lt;div class="article-content"&gt;&lt;section style="max-width: 100%; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; line-height: 28.4444px; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%; border: 0px currentcolor; font-family: 微软雅黑; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; max-width: 100%; border-style: solid none; font-family: inherit; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-top: -1.2em; max-width: 100%; min-height: 1em; font-size: 1em; border: currentcolor; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(255, 255, 255); line-height: 22.4px; font-size: 1em; font-family: inherit; text-decoration: inherit; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(117, 117, 118);"&gt;选自Github&lt;/span&gt;&lt;/p&gt;&lt;section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px; max-width: 100%; font-family: inherit; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-bottom: 5px; max-width: 100%; min-height: 1em; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(127, 127, 127); font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;作者：Terry Taewoong Um&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; max-width: 100%; min-height: 1em; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; font-family: inherit; text-decoration: inherit; color: rgb(127, 127, 127); font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong style="max-width: 100%; font-family: inherit; text-decoration: inherit; color: rgb(127, 127, 127); font-size: 12px; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; max-width: 100%; min-height: 1em; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(127, 127, 127); font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;参与：吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;&lt;em&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;近些年来在深度学习热潮的推动下，人工智能领域的研究犹如机器之心的吉祥物土拨鼠在春天里一样不断涌现，到今天，一个人要阅读了解这一领域的所有研究已经不再具有任何实践的可能性。择其善者而读之已经成为了人工智能研究者的一项重要技能，而其中非常值得关注的一项指标就是论文的引用次数，尤其是近期的引用次数。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;滑铁卢大学博士、GitHub 用户 Terry Taewoong Um 就希望能在这方面做出贡献，他在 GitHub 上创建了一个项目，罗列了自 2012 年以来被引用最多的深度学习论文。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px; color: rgb(171, 25, 66);"&gt;项目地址：https://github.com/terryum/awesome-deep-learning-papers&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;这是一个持续更新的项目。机器之心曾在 2016 年 6 月编译发表过这个项目之前的一个版本《&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716071&amp;amp;idx=1&amp;amp;sn=7aa209732425c6a52536fbb9012a09fd&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716071&amp;amp;idx=1&amp;amp;sn=7aa209732425c6a52536fbb9012a09fd&amp;amp;scene=21#wechat_redirect"&gt;学界 | 2010-2016 年被引用次数最多的深度学习论文（附论文下载）&lt;/a&gt;》。近日，这个项目再次进行了更新，下面我们就来看看被引用最多的论文有哪些。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;背景及相关资源&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;在这份榜单前后，也有一些其它很棒的深度学习榜单，比如：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;深度视觉：https://github.com/kjw0612/awesome-deep-vision&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;循环神经网络：https://github.com/kjw0612/awesome-rnn&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;深度学习阅读路线图：https://github.com/songrotek/Deep-Learning-Papers-Reading-Roadmap&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;但要看完这些榜单中提及的内容就已经很困难了，更不要说还有更多不在这些列表中的内容。所以我在这里推出了深度学习论文百强列表，希望能对想要整体了解深度学习研究的人提供帮助。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;评选说明&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;1. 这份深度学习论文百强列表的论文来自 2012-2016 年之间发表的论文。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;2. 如果一篇论文被加入到了这个列表，那么就必然会有一篇论文被移出这个列表（因此，移出论文和加入论文一样都是对这份列表的贡献。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;3. 重要但是却无法被包含进这份列表的论文会收纳到 More than Top 100 列表。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;4.New Papers 和 Old Papers 分别包含了最近 6 个月和 2012 年之前发表的论文。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;评选标准&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;小于 6 个月：New Papers，按讨论加入&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;2016 年：至少 60 次引用&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;2015 年：至少 200 次引用&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;2014 年：至少 400 次引用&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;2013 年：至少 600 次引用&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;2012 年：至少 800 次引用&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;2012 年之前：Old Papers，按讨论加入&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;请注意我们更偏爱开创性的可以应用于多种研究的深度学习论文，而非应用论文。基于这样的原因，一些满足评选标准的论文也被排除了。具体还要依赖该论文的影响、这一领域其它研究的稀缺性等等。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;内容目录&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;理解/泛化/迁移&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;优化/训练技术&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;无监督/生成模型&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;卷积网络模型&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;图像分割/目标检测&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;图像/视频等&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;循环神经网络模型&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;自然语言处理&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;语音/其它领域&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;强化学习&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;2016 年其它论文&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;其它看点&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;新论文（New Papers）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;旧论文（Old Papers）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;HW/SW/数据集：技术报告&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;书籍/调查/概述&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;理解/泛化/迁移&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Distilling the knowledge in a neural network (2015), G. Hinton et al. [pdf]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Deep neural networks are easily fooled: High confidence predictions for unrecognizable images (2015), A. Nguyen et al. [pdf]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;How transferable are features in deep neural networks? (2014), J. Yosinski et al. [pdf]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;CNN features off-the-Shelf: An astounding baseline for recognition (2014), A. Razavian et al. [pdf]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Learning and transferring mid-Level image representations using convolutional neural networks (2014), M. Oquab et al. [pdf]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Visualizing and understanding convolutional networks (2014), M. Zeiler and R. Fergus [pdf]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Decaf: A deep convolutional activation feature for generic visual recognition (2014), J. Donahue et al. [pdf]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;重要研究者：Geoffrey Hinton, Yoshua Bengio, Jason Yosinski&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;优化/训练技术&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Batch normalization: Accelerating deep network training by reducing internal covariate shift (2015), S. Loffe and C. Szegedy [pdf]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Delving deep into rectifiers: Surpassing human-level performance on imagenet classification (2015), K. He et al. [pdf]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Dropout: A simple way to prevent neural networks from overfitting (2014), N. Srivastava et al. [pdf]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Adam: A method for stochastic optimization (2014), D. Kingma and J. Ba [pdf]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Improving neural networks by preventing co-adaptation of feature detectors (2012), G. Hinton et al. [pdf]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Random search for hyper-parameter optimization (2012) J. Bergstra and Y. Bengio [pdf]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;重要研究者：Geoffrey Hinton, Yoshua Bengio, Christian Szegedy, Sergey Ioffe, Kaming He, Diederik P. Kingma&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;无监督/生成模型&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Pixel recurrent neural networks (2016), A. Oord et al. [pdf]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Improved techniques for training GANs (2016), T. Sallmans et al. [pdf]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Unsupervised representation learning with deep convolutional generative adversarial networks (2015), A. Radford et al. [pdf]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;DRAW: A recurrent neural network for image generation (2015), K. Gregor et al. [pdf]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Generative adversarial nets (2014), I. Goodfellow et al. [pdf]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Auto-encoding variational Bayes (2013), D. Kingma and M. Welling [pdf]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Building high-level features using large scale unsupervised learning (2013), Q. Le et al. [pdf]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;重要研究者：Yoshua Bengio, Ian Goodfellow, Alex Graves&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;卷积网络模型&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Rethinking the inception architecture for computer vision (2016), C. Szegedy et al.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Inception-v4, inception-resnet and the impact of residual connections on learning (2016), C. Szegedy et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Identity Mappings in Deep Residual Networks (2016), K. He et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Deep residual learning for image recognition (2016), K. He et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Going deeper with convolutions (2015), C. Szegedy et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Very deep convolutional networks for large-scale image recognition (2014), K. Simonyan and A. Zisserman&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Spatial pyramid pooling in deep convolutional networks for visual recognition (2014), K. He et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Return of the devil in the details: delving deep into convolutional nets (2014), K. Chatfield et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;OverFeat: Integrated recognition, localization and detection using convolutional networks (2013), P. Sermanet et al.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Maxout networks (2013), I. Goodfellow et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Network in network (2013), M. Lin et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;ImageNet classification with deep convolutional neural networks (2012), A. Krizhevsky et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;重要研究者：Christian Szegedy, Kaming He, Shaoqing Ren, Jian Sun, Geoffrey Hinton, Yoshua Bengio, Yann LeCun&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;图像分割/目标检测&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;You only look once: Unified, real-time object detection (2016), J. Redmon et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Region-based convolutional networks for accurate object detection and segmentation (2016), R. Girshick et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Fully convolutional networks for semantic segmentation (2015), J. Long et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks (2015), S. Ren et al.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Fast R-CNN (2015), R. Girshick&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Rich feature hierarchies for accurate object detection and semantic segmentation (2014), R. Girshick et al.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Semantic image segmentation with deep convolutional nets and fully connected CRFs, L. Chen et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Learning hierarchical features for scene labeling (2013), C. Farabet et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;重要研究者：Ross Girshick, Jeff Donahue, Trevor Darrell&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;图像/视频/ETC&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Image Super-Resolution Using Deep Convolutional Networks (2016), C. Dong et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;A neural algorithm of artistic style (2015), L. Gatys et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Deep visual-semantic alignments for generating image descriptions (2015), A. Karpathy and L. Fei-Fei&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Show, attend and tell: Neural image caption generation with visual attention (2015), K. Xu et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Show and tell: A neural image caption generator (2015), O. Vinyals et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Long-term recurrent convolutional networks for visual recognition and description (2015), J. Donahue et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;VQA: Visual question answering (2015), S. Antol et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;DeepFace: Closing the gap to human-level performance in face verification (2014), Y. Taigman et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Large-scale video classification with convolutional neural networks (2014), A. Karpathy et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;DeepPose: Human pose estimation via deep neural networks (2014), A. Toshev and C. Szegedy&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Two-stream convolutional networks for action recognition in videos (2014), K. Simonyan et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;3D convolutional neural networks for human action recognition (2013), S. Ji et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;重要研究者：Oriol Vinyals, Andrej Karpathy&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;循环神经网络模型&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Conditional random fields as recurrent neural networks (2015), S. Zheng and S. Jayasumana.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Memory networks (2014), J. Weston et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Neural turing machines (2014), A. Graves et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Generating sequences with recurrent neural networks (2013), A. Graves. &amp;nbsp;[Key researchers] Alex Graves&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;自然语言处理&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;A character-level decoder without explicit segmentation for neural machine translation (2016), J. Chung et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Exploring the limits of language modeling (2016), R. Jozefowicz et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Teaching machines to read and comprehend (2015), K. Hermann et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Effective approaches to attention-based neural machine translation (2015), M. Luong et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Neural machine translation by jointly learning to align and translate (2014), D. Bahdanau et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Sequence to sequence learning with neural networks (2014), I. Sutskever et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Learning phrase representations using RNN encoder-decoder for statistical machine translation (2014), K. Cho et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;A convolutional neural network for modelling sentences (2014), N. Kalchbrenner et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Convolutional neural networks for sentence classification (2014), Y. Kim&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Glove: Global vectors for word representation (2014), J. Pennington et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Distributed representations of sentences and documents (2014), Q. Le and T. Mikolov&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Distributed representations of words and phrases and their compositionality (2013), T. Mikolov et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Efficient estimation of word representations in vector space (2013), T. Mikolov et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Recursive deep models for semantic compositionality over a sentiment treebank (2013), R. Socher et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;重要研究者：Kyunghyun Cho, Oriol Vinyals, Richard Socher, Tomas Mikolov, Christopher D. Manning, Yoshua Bengio&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;语音/其它领域&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;End-to-end attention-based large vocabulary speech recognition (2016), D. Bahdanau et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Deep speech 2: End-to-end speech recognition in English and Mandarin (2015), D. Amodei et al.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Speech recognition with deep recurrent neural networks (2013), A. Graves&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups (2012), G. Hinton et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Context-dependent pre-trained deep neural networks for large-vocabulary speech recognition (2012) G. Dahl et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Acoustic modeling using deep belief networks (2012), A. Mohamed et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;重要研究者：Alex Graves, Geoffrey Hinton, Dong Yu&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;强化学习&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;End-to-end training of deep visuomotor policies (2016), S. Levine et al.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Learning Hand-Eye Coordination for Robotic Grasping with Deep Learning and Large-Scale Data Collection (2016), S. Levine et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Asynchronous methods for deep reinforcement learning (2016), V. Mnih et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Deep Reinforcement Learning with Double Q-Learning (2016), H. Hasselt et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Mastering the game of Go with deep neural networks and tree search (2016), D. Silver et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Continuous control with deep reinforcement learning (2015), T. Lillicrap et al.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Human-level control through deep reinforcement learning (2015), V. Mnih et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Deep learning for detecting robotic grasps (2015), I. Lenz et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Playing atari with deep reinforcement learning (2013), V. Mnih et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;重要研究者：Sergey Levine, Volodymyr Mnih, David Silver&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;2016 年其它论文&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Layer Normalization (2016), J. Ba et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Learning to learn by gradient descent by gradient descent (2016), M. Andrychowicz et al.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Domain-adversarial training of neural networks (2016), Y. Ganin et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;WaveNet: A Generative Model for Raw Audio (2016), A. Oord et al.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Colorful image colorization (2016), R. Zhang et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Generative visual manipulation on the natural image manifold (2016), J. Zhu et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Texture networks: Feed-forward synthesis of textures and stylized images (2016), D Ulyanov et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;SSD: Single shot multibox detector (2016), W. Liu et al.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and&amp;lt; 1MB model size (2016), F. Iandola et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Eie: Efficient inference engine on compressed deep neural network (2016), S. Han et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Binarized neural networks: Training deep neural networks with weights and activations constrained to+ 1 or-1 (2016), M. Courbariaux et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Dynamic memory networks for visual and textual question answering (2016), C. Xiong et al.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Stacked attention networks for image question answering (2016), Z. Yang et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Hybrid computing using a neural network with dynamic external memory (2016), A. Graves et al.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation (2016), Y. Wu et al.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;新论文（New Papers）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;最近六个月内值得一读的论文：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Batch Renormalization: Towards Reducing Minibatch Dependence in Batch-Normalized Models, S. Ioffe.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;Understanding deep learning requires rethinking generalization, C. Zhang et al&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;旧论文（Old Papers）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;2012 年之前发表的经典论文：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;An analysis of single-layer networks in unsupervised feature learning (2011), A. Coates et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&amp;nbsp;Deep sparse rectifier neural networks (2011), X. Glorot et al&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&amp;nbsp;Natural language processing (almost) from scratch (2011), R. Collobert et al&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&amp;nbsp;Recurrent neural network based language model (2010), T. Mikolov et al&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&amp;nbsp;Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion (2010), P. Vincent et al&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&amp;nbsp;Learning mid-level features for recognition (2010), Y. Boureau&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&amp;nbsp;A practical guide to training restricted boltzmann machines (2010), G. Hinton &amp;nbsp; Understanding the difficulty of training deep feedforward neural networks (2010), X. Glorot and Y. Bengio&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&amp;nbsp;Why does unsupervised pre-training help deep learning (2010), D. Erhan et al&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&amp;nbsp;Recurrent neural network based language model (2010), T. Mikolov et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&amp;nbsp;Learning deep architectures for AI (2009), Y. Bengio.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&amp;nbsp;Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations (2009), H. Lee et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&amp;nbsp;Greedy layer-wise training of deep networks (2007), Y. Bengio et al&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&amp;nbsp;Reducing the dimensionality of data with neural networks, G. Hinton and R. Salakhutdinov&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&amp;nbsp;A fast learning algorithm for deep belief nets (2006), G. Hinton et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&amp;nbsp;Gradient-based learning applied to document recognition (1998), Y. LeCun et al&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&amp;nbsp;Long short-term memory (1997), S. Hochreiter and J. Schmidhuber.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;HW/SW/数据集&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&amp;nbsp;OpenAI gym (2016), G. Brockman et al&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&amp;nbsp;TensorFlow: Large-scale machine learning on heterogeneous distributed systems &amp;nbsp;(2016), M. Abadi et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&amp;nbsp;Theano: A Python framework for fast computation of mathematical expressions, &amp;nbsp; &amp;nbsp; &amp;nbsp;R. Al-Rfou et al.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&amp;nbsp;MatConvNet: Convolutional neural networks for matlab (2015), A. Vedaldi and K. &amp;nbsp;Lenc&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&amp;nbsp;Imagenet large scale visual recognition challenge (2015), O. Russakovsky et al&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&amp;nbsp;Caffe: Convolutional architecture for fast feature embedding (2014), Y. Jia et al&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;书籍/调查/概述&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&amp;nbsp;Deep learning (Book, 2016), Goodfellow et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&amp;nbsp;LSTM: A search space odyssey (2016), K. Greff et al.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&amp;nbsp;Deep learning (2015), Y. LeCun, Y. Bengio and G. Hinton&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&amp;nbsp;Deep learning in neural networks: An overview (2015), J. Schmidhuber &amp;nbsp; &amp;nbsp; &amp;nbsp;Representation learning: A review and new perspectives (2013), Y. Bengio et al.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="min-height: 1em; text-align: justify; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="line-height: 25.6px; font-family: 微软雅黑; font-size: 14px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; color: rgb(127, 127, 127); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="color: rgb(62, 62, 62); line-height: 25.6px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; color: rgb(127, 127, 127); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;©本文为机器之心编译，&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; font-size: 18px; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(127, 127, 127); line-height: 25.6px; font-family: 微软雅黑; text-align: justify; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(217, 33, 66); font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(217, 33, 66); line-height: 1.6; font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-size: 12px; color: rgb(217, 33, 66); line-height: 1.6; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/div&gt;</description>
      <pubDate>Fri, 17 Feb 2017 12:06:43 +0800</pubDate>
    </item>
    <item>
      <title>观点 | 大西洋月刊：从AAAI看人工智能领域的中国崛起</title>
      <link>http://www.iwgc.cn/link/4740973</link>
      <description>&lt;div class="article-content"&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;section style="max-width: 100%; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; line-height: 28.4444px; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%; border: 0px currentcolor; font-family: 微软雅黑; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; max-width: 100%; border-style: solid none; font-family: inherit; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-top: -1.2em; max-width: 100%; min-height: 1em; font-size: 1em; border: currentcolor; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(255, 255, 255); line-height: 22.4px; font-size: 1em; font-family: inherit; text-decoration: inherit; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(117, 117, 118);"&gt;选自Theatlantic&lt;/span&gt;&lt;/p&gt;&lt;section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px; max-width: 100%; font-family: inherit; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-bottom: 5px; max-width: 100%; min-height: 1em; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(127, 127, 127); font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;作者：SARAH ZHANG&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; max-width: 100%; min-height: 1em; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; font-family: inherit; text-decoration: inherit; color: rgb(127, 127, 127); font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong style="max-width: 100%; font-family: inherit; text-decoration: inherit; color: rgb(127, 127, 127); font-size: 12px; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; max-width: 100%; min-height: 1em; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(127, 127, 127); font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;参与：晏奇、黄小天&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;每年冬天，来自全世界的成百上千个人工智能研究人员会相聚一年一度的 AAAI（Association of the Advancement of Artificial Intelligence）大会。去年，当 AAAI 宣布下一届会议将于明年 1 月在美国新奥尔良举办时，议程却遭到了一小部分人的反对。会址没有问题，但日期与中国春节相冲突。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487305840EwVRjh.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;span style="font-size: 12px; color: rgb(136, 136, 136);"&gt;&lt;em&gt;中国的大学与科技巨头正在人工智能研究与应用领域赶超美国&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;span style="font-size: 12px; color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;br&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;以往 AAAI 大会很少会为了节日而改期，但现在情况变了，中国参会人员已经变得重要，没有他们，会议简直就无法开展。最终会议还是不得不改期。现任 AAAI 主席 Subbarao Kambhampati（Rao）说：没人会在圣诞节举办 AAAI 大会。我们很快做出改变，重选了会址并推迟一周开幕。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;最终在上周，2017 AAAI 大会于旧金山圆满落幕。不出所料，中国研究人员在这个由美国主导的历史性会议上表现强劲。大会收录的中国论文的数量几近与美国持平。AAAI 主席 Rao 说：「这相当激动人心，如果倒回到 3、4 年之前，这一切难以想象」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;中国人工智能研究排名的迅速上升引人注目。10 月，白宫发布了一份关于人工智能研究的战略计划，指出在人工智能研究的热门子领域深度学习方面，美国的期刊论文数量不再领先世界。谁在赶超美国？毋庸置疑，中国。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;中国不仅在学术研究方面正在赶超美国。中国的技术公司也在人工智能上押注。百度、滴滴和腾讯都设立自己的人工智能研究实验室。由于拥有海量用户，它们可以轻易获得大数据以训练人工智能检测模型需求。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;和微软、谷歌一样，中国的科技公司也看到了人工智能的巨大潜力。在未来的 10 年，从面部识别到自动驾驶汽车，人工智能将推进整个系列的革命性技术。百度首席科学家、Coursera 和谷歌大脑的联合创始人吴恩达说：「没有产业不会被人工智能改造。」现在他正在硅谷的森尼韦尔主管百度的人工智能研究。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;中国在人工智能方面的成就部分原因来自政府在大学中对科研的总体投资。过去的十年中，中国政府在研究上的投资平均每年都以两位数的速度增长。如今年 3 月份发布的中国「五年计划」中我们可以看到，对于科学与技术研究的资助持续占有首要地位。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;Rao 回忆说，当他首次在国际人工智能会议上看见中国研究者时，他们一般都来自清华大学和北京大学，这两所大学被看作中国的麻省理工和哈佛大学。现在，Rao 可以看见来自中国全国各地研究者发来的论文，而不仅仅是那些最顶尖的学校。机器学习（包括了深度学习）最近一直以来都是热点话题。「在中国，关注应用机器学习的人数正在猛蹭」，Rao 说道。这个上升的趋势在白宫的人工智能战略研究中也被提及。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;中国的科技公司也在参与和投资大学的研究项目。香港科技大学的计算机科学家杨强就在与腾讯公司合作（腾讯为杨强实验室的学生提供了奖学金）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;微信是腾讯公司开发的消息应用，类似于 Facebook、iMessage 和 Venmo 三者功能的合一，学生从这里接触到海量数据。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;杨强说：「要做人工智能，我们必然需要大量的数据和一个测试它的平台才可以。」这也就是为什么与产业界的合作如此重要。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;作为回报，腾讯可以直接接触到学术界实验室最具创造力的研究。当然，这些实验室的一些学生毕业后，也会去腾讯工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;中国人工智能研究的质量也在显著上升，不过，美国美国研究者仍然主导许多最具基础突破性的研究。吴恩达说：「我发现，那些改变网络架构的聪明点子还是来自美国。」中国研究者一直擅长的是利用一个想法（比如机器学习），并就这一想法的不同应用为主题发表论文。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;然而，吴恩达说，随着中国人工智能研究的逐渐成熟，它也会形成自己独特的研究社区。他回忆说，巴塞罗那召开的国际会议结束后，有关会议演讲的中文报道立刻出来，但是，却没找到英文报道。语言造成了某种不对称：中国研究者通常使用英语，这有利于他们接触到所有英文研究。可是另一方面，英语主导的研究社区则不太有可能参与到中文人工智能社区当中去。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;「中国对英语世界发生的事情有着非常深度的关注，但是反之则不然，」吴恩达说道。他指出，在像谷歌和微软这样更有名的大公司之前，百度就率先推出了由人工智能技术支持的机器翻译和语音识别服务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;在推出新功能方面，中国公司会更加迅速。「中国研究的发展速度远超大部分硅谷企业，」吴恩达说道。「当你在中国发现了一个商机，给你敞开的反应时间通常来说非常短——比在美国更短。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;对于这一切，杨强将其归因于中国高度竞争的生态系统。例如微信已经围绕二维码、聊天、支付和朋友发现打造了一系列的功能，这些功能已经在中国公民的日常生活中变得必不可少。然而，美国社交媒体公司仅仅还在希望他们的用户拥有足够的忠诚度。杨强说：「腾讯的产品经理对于用户需求有着很好的判断，他们可以很快将技术投入应用，这个周期非常短。」并且为了保持竞争力，中国公司的首要任务是整合人工智能来改善它们的产品。中国科技公司是否在凭人工智能浪潮闯入国际市场还有待观察，但是在中国，它们已经在开始使用人工智能来争夺中国消费者了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;在学术界，现在 AAAI 已在着手确保中国研究人员的贡献和参与了。每一年的中国春节日期并不同，但多是在 1 月或 2 月，AAAI 通常也在这个时期举办。因此，我们一定要避免再次发生冲突。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 12px;"&gt;原文：&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;a style="font-size: 12px; color: rgb(136, 136, 136);"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;https://www.theatlantic.com/technology/archive/2017/02/china-artificial-intelligence/516615/?utm_source=fe&lt;/span&gt;&lt;/em&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px; text-decoration: none;"&gt;&lt;/span&gt;&lt;em&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;ed&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="min-height: 1em; text-align: justify; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="line-height: 25.6px; font-family: 微软雅黑; font-size: 14px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; color: rgb(127, 127, 127); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="color: rgb(62, 62, 62); line-height: 25.6px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; color: rgb(127, 127, 127); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;©本文为机器之心编译，&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; font-size: 18px; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(127, 127, 127); line-height: 25.6px; font-family: 微软雅黑; text-align: justify; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(217, 33, 66); font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(217, 33, 66); line-height: 1.6; font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-size: 12px; color: rgb(217, 33, 66); line-height: 1.6; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/div&gt;</description>
      <pubDate>Fri, 17 Feb 2017 12:06:43 +0800</pubDate>
    </item>
    <item>
      <title>学界 | 谷歌提交新论文提出认知型地图构建器和规划器：同时应对视觉导航的几何和语义任务</title>
      <link>http://www.iwgc.cn/link/4740974</link>
      <description>&lt;div class="article-content"&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;section style="max-width: 100%; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; line-height: 28.4444px; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%; border: 0px currentcolor; font-family: 微软雅黑; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; max-width: 100%; border-style: solid none; font-family: inherit; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-top: -1.2em; max-width: 100%; min-height: 1em; font-size: 1em; border: currentcolor; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(255, 255, 255); line-height: 22.4px; font-size: 1em; font-family: inherit; text-decoration: inherit; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(117, 117, 118);"&gt;选自Google&lt;/span&gt;&lt;/p&gt;&lt;section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px; max-width: 100%; font-family: inherit; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-bottom: 5px; max-width: 100%; min-height: 1em; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(127, 127, 127); font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;作者：Saurabh Gupta 等&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; max-width: 100%; min-height: 1em; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; font-family: inherit; text-decoration: inherit; color: rgb(127, 127, 127); font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong style="max-width: 100%; font-family: inherit; text-decoration: inherit; color: rgb(127, 127, 127); font-size: 12px; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; max-width: 100%; min-height: 1em; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(127, 127, 127); font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;参与：吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;论文题目：Cognitive Mapping and Planning for Visual Navigation&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;摘要&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;我们介绍了一种用于在全新的环境中导航的神经架构。我们提出的架构可以学习根据第一人称视角构建地图（mapping）和在环境中规划（planning）到达目的地的动作序列。这个认知型地图构建器和规划器（CMP/Cognitive Mapper and Planner）基于两个关键思想：a）一个用于地图构建和规划的统一联合架构，这样使得该地图构建可由规划者的需求来驱动；b）一个可以在关于世界的观察集合不完整时能够进行规划的空间记忆。CMP 能构建一个自上而下的关于世界的可信度地图（belief map）并应用一个可微神经网络规划器来在每一个时间步骤产生下一个动作。这种关于世界的积累的可信度使得该代理（agent）能够跟踪其环境中已经访问过的区域。我们的实验表明该 CMP 的表现超过了反应策略（reactive strategies）和标准的基于记忆的架构，并且可以在全新的环境中获得良好的表现。此外，我们还表明 CMP 也能够实现特定语义的目标，比如「go to a chair」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;问题陈述&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;在全新环境中的视觉导航。我们研究了几何任务（其中任务根据相对于机器人当前位置的偏移来确定）和语义任务（其中任务根据实现一个特定的目标类别来确定）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;方法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;我们的学习过的导航网络由一个地图构建器（mapper）和一个规划器（planner）模块构成。其中地图构建器写入对应于一个环境的自我中心地图的隐记忆（latent memory），而规划器则使用这个记忆来输出导航动作。这个地图并没有受到明确的监督，而是从学习过程中自然地融合得到的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/14873058424WlhJH.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;地图构建器模块可以处理来自机器人的第一人称图像并将其观察整合到隐记忆中，这个隐记忆对应于一个对于环境的顶视角的自我中心地图。这个地图构建的操作并没有收到明确的监督——该地图构建器可以自由地向记忆写入任何对规划器最有用的信息。除了填充障碍物之外，该地图构建器还能在地图中存储置信度值（confidence values），这允许其通过利用已学到的模式做出关于地图中未被观察的部分的概率预测。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487305842b4toQO.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;这种分层规划器利用了地图构建器输出的关于世界的以自我为中心的多尺度可信度（egocentric multi-scale belief），并使用了以卷积表示的值迭代和以通道（channel）方式的最大池化，以输出一个策略。该规划器是可训练和可微分的，并会将梯度反向传播给地图构建器。该规划器可在多种规模的问题上工作（规模 0 是最好的规模），这能实现高效的规划。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487305842ogFB31.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;结果&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;实验是在由 3D 真实扫描构成的静态环境中执行的。我们测算了到目标的平均距离、到目标的 75% 分位的距离和成功率，作为我们提出的方法（CMP）的步骤的函数，此外还测算了一个反应基线（reactive baseline）和一个基于 LSTM 的基线。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1487305842CvUPhl.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;在这个视频中，我们展示了我们提出的算法的一些成功和失败的导航案例。注意视频中所给出的结果，该代理使用了第一人称的深度图像作为输入，而我们为了让可视化更容易而使用了 RGB 图像。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&lt;strong&gt;视频&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;iframe class="video_iframe" data-vidtype="1" allowfullscreen="" frameborder="0" height="417" width="556" data-src="https://v.qq.com/iframe/preview.html?vid=k0375pbhot2&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0"&gt;&lt;/iframe&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 12px;"&gt;原文：&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;https://sites.google.com/view/cognitive-mapping-and-planning/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="min-height: 1em; text-align: justify; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="line-height: 25.6px; font-family: 微软雅黑; font-size: 14px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; color: rgb(127, 127, 127); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="color: rgb(62, 62, 62); line-height: 25.6px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; color: rgb(127, 127, 127); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;©本文为机器之心编译，&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; font-size: 18px; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(127, 127, 127); line-height: 25.6px; font-family: 微软雅黑; text-align: justify; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(217, 33, 66); font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(217, 33, 66); line-height: 1.6; font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-size: 12px; color: rgb(217, 33, 66); line-height: 1.6; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/div&gt;</description>
      <pubDate>Fri, 17 Feb 2017 12:06:43 +0800</pubDate>
    </item>
  </channel>
</rss>
