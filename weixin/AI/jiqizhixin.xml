<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>重磅 | Torch7团队开源PyTorch：Python优先的深度学习框架</title>
      <link>http://www.iwgc.cn/link/4403735</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自PyTorch.org&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀、李泽南、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Torch7 团队开源了 PyTorch。据官网介绍，PyTorch 是一个 Python 优先的深度学习框架，能够在强大的 GPU 加速基础上实现张量和动态神经网络。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;官网：http://pytorch.org&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GitHub：https://github.com/pytorch/pytorch&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;PyTorch 是一个 Python 软件包，其提供了两种高层面的功能：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;使用强大的 GPU 加速的 Tensor 计算（类似 numpy）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;构建于基于 tape 的 autograd 系统的深度神经网络&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如有需要，你也可以复用你最喜欢的 Python 软件包（如 numpy、scipy 和 Cython）来扩展 PyTorch。目前这个版本是早期的 Beta 版，我们很快就会加入更多的功能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWib4ZvicIaeEBwxiciaHXZI5ttRvOgwYCXs6wsBU8EWMXU7qiaKxsA5pzeVn41LagLLHhTSLQ5nF81jEww/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;PyTorch 介绍&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在粒度层面（granular level）上，PyTorch 库包含了以下组件：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWib4ZvicIaeEBwxiciaHXZI5ttRuQeicxicSl1eWvnyQXucymZjnu1l0K8fdfOQ8ZOduLscCEww2OuSx6HQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使用 PyTorch 的原因通常有二：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;作为 numpy 的替代，以便使用强大的 GPU；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;将其作为一个能提供最大的灵活性和速度的深度学习研究平台。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;进一步阐述如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;一个支持 GPU 的 Tensor 库&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你使用 numpy，那么你就使用过 Tensor（即 ndarray）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWib4ZvicIaeEBwxiciaHXZI5ttRC522kNyJlEiaibqY4V9EiakRdSQ5e6MLjgw7WGRBcyf020AARm7DxAGQA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;PyTorch 提供了支持 CPU 和 GPU 的 Tensor，可以极大地加速计算。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们提供了各种各样的用于加速的张量例程（tensor routine），可以满足你的各种科学计算需求，比如 slicing、索引、数学运算、线性代数、reduction。而且它们非常快！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;动态神经网络：基于 tape 的 autograd&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;PyTorch 有一种独特的神经网络构建方法：使用和重放 tape recorder。TensorFlow、Theano、Caffe 和 CNTK 等大部分框架对世界的视角都是静态的，让人们必须先构建一个神经网络，然后一次又一次地使用同样的结构；如果要想改变该网络的行为，就必须完全从头开始。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但使用 PyTorch，通过一种我们称之为「Reverse-mode auto-differentiation（反向模式自动微分）」的技术，你可以零延迟或零成本地任意改变你的网络的行为。我们灵感来自关于这一主题的许多研究论文以及当前和过去的研究成果，比如 autograd、autograd、Chainer 等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;autograd：https://github.com/twitter/torch-autograd&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;autograd：https://github.com/HIPS/autograd&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Chainer：http://chainer.org/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管这项技术并非 PyTorch 独有，但它仍然是到目前为止最快的实现。你能为你的疯狂研究获得最高的速度和最佳的灵活性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_gif/KmXPKA19gWib4ZvicIaeEBwxiciaHXZI5ttRiaUAxR3xkdBWE0DuU1Fly9lKKSy6BiaxSnLyRVLKQVKkOP7HhvMqpLtA/0?wx_fmt=gif"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Python 优先&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;PyTorch 不是简单地在整体 C++框架上绑定 Python。它深入构建在 Python 之上。你可以像使用 numpy / scipy / scikit-learn 那样轻松地使用 PyTorch。你可以用你喜欢的库和包（如 Cython 和 Numba）在 Python 中编写新的神经网络层。我们的目标是尽量让你不用重新发明轮子。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;命令式体验&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;PyTorch 的设计思路是线性、直观且易于使用。当你需要执行一行代码时，它会忠实执行。PyTorch 没有异步的世界观。当你打开调试器，或接收到错误代码和 stack trace 时，你会发现理解这些信息是非常轻松的。Stack-trace 点将会直接指向代码定义的确切位置。我们不希望你在 debug 时会因为错误的指向或异步和不透明的引擎而浪费时间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;快速精益&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;PyTorch 具有轻巧的框架。我们集成了各种加速库，如 Intel MKL、英伟达的 CuDNN 和 NCCL 来优化速度。在其核心，它的 CPU 和 GPU Tensor 与神经网络后端（TH、THC、THNN、THCUNN）被编写成了独立的库，带有 C99 API。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种配置是成熟的，我们已经使用了多年。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此，PyTorch 非常高效——无论你需要运行何种尺寸的神经网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 PyTorch 中，内存的使用效率相比 Torch 或其它方式都更加高效。我们为 GPU 编写了自定义内存分配器，以保证深度学习模型在运行时有最高的内存效率，这意味着在相同硬件的情况下，你可以训练比以前更为复杂的深度学习模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;轻松拓展&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;编写新的神经网络模块，或与 PyTorch 的 Tensor API 相接的设计都是很直接的，不太抽象。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你可以使用 Torch API 或你喜欢的基于 numpy 的库（比如 Scipy）来通过 Python 写新的神经网络层。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你想用 C++ 写网络层，我们提供了基于 cffi（http://cffi.readthedocs.io/en/latest/）的扩展 API，其非常有效且有较少的样板文件。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不需要写任何 wrapper code。这里有一个示例：https://github.com/pytorch/extension-ffi&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;安装&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;二进制&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Anaconda&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;conda install&amp;nbsp;pytorch torchvision -c soumith&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;来自源&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Anaconda 环境的说明。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你想要用 CUDA 支持编译、安装：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;NVIDIA CUDA &amp;nbsp;7.5 或之上的版本&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;NVIDIA CuDNN v5.x&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;安装可选依赖包&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;export CMAKE_PREFIX_PATH=[anaconda root directory]&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;conda install numpy mkl setuptools cmake gcc cffi&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;conda install -c soumith magma-cuda75 # or magma-cuda80 if CUDA 8.0&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;安装 PyTorch&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;export MACOSX_DEPLOYMENT_TARGET=10.9 # if OSX&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;pip install -r requirements.txt&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;python setup.py install&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;开始使用&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从以下三点开始学习使用 PyTorch：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;教程：开始了解并使用 PyTorch 的教程（https://github.com/pytorch/tutorials）。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;案例：跨所有领域的轻松理解 PyTorch 代码（https://github.com/pytorch/examples）。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;API 参考：http://pytorch.org/docs/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;交流&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论坛：讨论实现、研究等（http://discuss.pytorch.org）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GitHub 问题反馈：bug 通知、特征要求、安装问题、RFC、想法等。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Slack：通常聊天、在线讨论、合作等（https://pytorch.slack.com/）。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;邮件订阅没有骚扰信件、单向邮件推送 PyTorch 的重要通知。订阅：http://eepurl.com/cbG0rv。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;发布和贡献&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;PyTorch 的发布周期（主版本）为 90 天。目前的版本是 v0.1.6 Beta，我们期望在发布前尽量减少 bug。如果你发现了错误，欢迎向我们提交：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://github.com/pytorch/pytorch/issues&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们欢迎所有形式的贡献。如果你希望帮助解决 bug，请直接上手，无需多作讨论。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你愿意为 PyTorch 提供新功能、实用函数或核心扩展，请先开一个 issue 与大家讨论一下。请注意：在未经讨论的情况下提交的 PR 可能会导致退回，因为我们可能会采取不同的解决方式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在下一个版本中，我们计划推出三大新功能：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1、分布式 PyTorch&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（这里已经有一个尝试性的实现了：https://github.com/apaszke/pytorch-dist）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2、反反向（Backward of Backward）：在反向传播的过程中进行过程优化。一些过去和最近的研究如 Double Backprop 和 Unrolled GANs 会需要这种特性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3、用于 autograd 的 Lazy Execution Engine：这将允许我们可以通过引入缓存和 JIT 编译器来优化 autograd 代码。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;开发团队&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;PyTorch 是一个社区驱动的项目，由经验丰富的工程师和研究者开发。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前，PyTorch 由 Adam Paszke、Sam Gross 与 Soumith Chintala 牵头开发。其他主要贡献者包括 Sergey Zagoruyko、Adam Lerer、Francisco Massa、Andreas Kopf、James Bradbury、Zeming Lin、田渊栋，Guillaume Lample、Marat Dukhan、Natalia Gimelshein 等人。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Note：本项目与 hughperkins/pytorch 有相同的名字，但无关联。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 19 Jan 2017 11:05:27 +0800</pubDate>
    </item>
    <item>
      <title>独家 | 揭秘美图影像实验室：数据、算法和一件关于美的事</title>
      <link>http://www.iwgc.cn/link/4403736</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：虞喵喵&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「美是无用之用。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;每天清晨，全世界不同时区的女孩儿们依次醒来，洗脸、化妆或是不化妆、吃早饭、上班或是去上学。这些女孩儿中有不少人会用美图推出的不同应用自拍，生成大约 2 亿张照片。这些照片有的去了瑕疵，有的加了滤镜，有的干脆添了妆容。不同的手指按下同一个「发送」键，照片们就出现在不同的社交平台上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你很难说清这些照片有什么用。它们既不像传统的旅行照记录「到此一游」，也不像证件照充满了功利。这些照片更像一种自我暗示和面向广袤世界的宣示——我们存在，我们拥有美。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8mkkOTgrRQux7YyjNTL5mdpCO09ahGPcjwSw63T6N1q4sADlA2kPZh80UiaISlkOLQkpAHPngPHpw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;这是一个属于自拍的时代，没有哪张照片能比这张更能说明我们的处境。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;饺子是美图影像实验室（MTLAB）北京地区负责人。在这个制造「魔镜」的人看来，「美是一种选择」，既不能强迫他人接受，也不能接受他人的强迫。美是无解的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自成立以来，美图影像实验室的研究成果几乎改变了美图软件、硬件中所有功能。一键美颜、实时美妆，或是时下相当流行的美图秀秀手绘功能，都有这个实验室的功劳。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他们一定很爱自拍吧？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;饺子笑了笑，「看到自己的技术用在产品中效果非常好，很有成就感，但可能并不会经常自拍。应用和技术之间，是不同的两回事儿。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如今已有 60 余人的美图影像实验室行事相当低调，在搜索引擎上似乎很难找到相关信息。作为首次采访到美图影像实验室的媒体，希望机器之心能让你对「神秘」的实验室和这份关于美的事业多一分了解。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;民主化的的实验室&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;亚麻、香草金或者冰蓝，只要在屏幕上轻轻一点，所有人都能立即改变自己的发色。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但在实验室的研究员们看来，这项令人惊叹的「染发」功能，纯粹是技术上的分割问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8mkkOTgrRQux7YyjNTL5mdrAeCNiaR9ib3YLR07eaPI8E4JrKYicYLvUUPq2bur0RgEV0EGK33RTE5A/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;左一为原图，可以选择较自然的色彩如亚麻色，也可以选择更夺目的色彩如莓粉色&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「一张照片，头发有的亮有的暗，头发和围巾很像甚至有时候纹理也很像。背景是黑的头发也是黑的，和头发连在一起的眉毛也是黑的，那怎么办呢？我们就需要克服这些问题。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前，负责「克服问题」的美图影像实验室有大约 60 多位研究员，分布在北京、厦门、深圳。位于美图总部的厦门实验室是最老也是最大的团队，主要提供人脸技术、美颜技术、3D 技术和性能优化；北京实验室更偏向计算机视觉，包括视频技术及深度学习；深圳则是与智能硬件相关的影像算法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这样的设置自然有吸引人才的考量。深圳有华强北，硬件创业氛围好、相关人才也多，有利于美图手机的迭代研发；北京是全国最大的人才集散地，又有众多高校学府，很适合招揽人才；厦门自 2010 年时就诞生了实验室雏形，有着深厚的技术积累。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8mkkOTgrRQux7YyjNTL5mdNeDsv34OCMMV8wgbicGYltyibnnIcrOpvKXshP6L280y8Nwn7b7X3byw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;美图实验室厦门团队部分成员合影&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;可如此分散的架构，会不会产生协作上的困扰？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「这不单单是美图的问题，很多公司都是这样。」饺子显出某种技术人员独有的认真，讲述起实验室的「解决方案」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;每周，不同地区的实验室都会通过远程会议系统一同召开会议。除了例会，还有定期的论文分享会、主题分享会。论文分享需要每个人介绍一系列文章，讲清内容、问题、自己的理解和未来应用的可能，然后大家共同探讨；主题分享会则由组员讲述近期正在做的、和他人不同的工作，不仅要讲明内容、逻辑清晰，还要应付观众提问，共同提升批判性思维的能力，「和读博士差不多」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;同时，这些内容提前会写成博客——美图在内部建立了一个技术博客，任何人都可以评论和编辑、添加新内容。各次分享会的内容、研究中发现的成果都发布在博客中，即使新人入职也能马上学习新技能，其他人遇到问题也能在博客上寻找解决方案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「这也是我们实验室民主化的一部分，技术分享同样可以提高实验室的整体效率。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;在前沿研究和真实需求之间的平衡感&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自 2010 年从开发团队中剥离，到 2014 年正式成立，实验室如今已是美图最重要的部门之一。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;比起开发团队，实验室更像研究院，不过与研究院不同的是，研究员们关注的内容既要包括前沿技术，也要顾及实际需求。如果有新人入职，第一件事就是将一个项目从头跟到尾，不仅要清晰流程，还要解决最实际的问题、面对最严格的产品经理和最真实的用户需求。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大头贴是美颜相机中最火的功能之一。这个至今已被使用了 7.9 亿次的功能，是产品经理日本考察时发现的需求。在日本游戏中心相当流行的大头贴机，几乎每个前来游玩的女孩子都想尝试一次。与中国的大头贴机不同，日本的大头贴机不仅自带磨皮美白、放大眼睛的美颜效果，还可以选择不同的美化功能，甚至是拉长双腿。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8mkkOTgrRQux7YyjNTL5md6iblGWv0hr3bscVZ0OEYJk4Fo4j5tia09NeTsp8SibUzPDOutTc9RKByQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;美颜相机中的大头贴功能，有各种卡通模版可以选择&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不过想要在软件中实现这些效果，不少在技术上尚且无法满足。研究员们第一时间告知产品经理能达到的效果，最终折衷成目前已上线的功能。而那些没能被满足的需求，不少已经变成了实验室长期研究的课题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除了对产品和用户更加了解的产品经理，也有不少需求直接来自实验室。钻研技术中碰到哪个点刚好会产生不错的效果、感觉用户可能会喜欢，实验室也会和产品经理讨论是否加入到产品中。前面提到的染发功能，就是其中之一。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个需求需要多长时间才能实现？除了规划的「死线」和工程适配的流程，更具决定性的是「效果」。在采访过程中，饺子反复强调美图对效果的严苛，「如果产品要求很低当然可以做得很快，但这取决于美图价值观，我们要为用户提供最好的效果」。甚至不希望用户注意到他们在背后的努力，「一点，头发就变色了，用户感觉很方便就足够了。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;深度学习与数据&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在内部，美图影像实验室将技术分为 8 类，分别对应基础技术和综合技术。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;作为基础的 MTFaces，包含人脸检测、人脸关键点检测和人脸属性分析，可以了解用户的年龄、性别，为后续的美颜和上妆提供支持；MTSegmentation 是图像分割技术，可以准确找到照片中头发、皮肤、身体的位置；MT3DTech 可以通过一张自拍照重建人脸 3D 模型；MTRestoration 则是画质修复，光线不好、有噪点或者被压缩，都可以一键恢复。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;综合技术是多种技术的融合，比如 MTBeauty 包含图像美化和人像美化；MTStyles 风格化技术则是时下最流行的迁徙技术，能够给图像赋予风格；MTPhotos 可以通过人脸识别和图片标签管理照片；基于人脸检测技术 MTMakeup，通过美图独有人脸网格技术实现实时的视频和图像上妆。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWib4ZvicIaeEBwxiciaHXZI5ttRKUHWFQZMaPTfpyic5uINVVLPkpdYr0YZrhupWR6DcQbCMlNYAKHAPjg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;MTSegmentation 头发部分分割效果图，最右为染色后&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这些被划分的技术背后，深度学习功不可没。运用传统方法进行皮肤分割，准确率往往低于 80%。深度学习则可以让 MTSegmentation 的准确率达到 98.5%，以保证在磨掉小斑点、小细纹的同时，不会将衣服、头发磨平。MTRestoration 也离不开深度学习，机器之心也曾报道过相关的应用案例。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在具体应用上，美图的深度学习有什么特点？在饺子看来，美图影像实验室的优势还是在 to C 的场景和拥有的数据：「有多少层、用了什么样的结构，取决于应用场景。美图软硬件产品为我们提供了很多 to C 的应用场景，这可能是其他平台提供不了的。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除了最为人熟知的美图秀秀，美图的产品线还包括美拍、美颜相机、美妆相机、潮自拍、BeautyPlus 等等。截至 2016 年 10 月 31 日，美图应用的月活跃用户总数约为 4.56 亿，核心影像应用当月产生约 60 亿张照片。据相关调查统计，在中国主流社交网络上传的照片中，有约 53.5% 的照片经过了美图应用的处理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8mkkOTgrRQux7YyjNTL5mdicRDa8pfWatQj3NrYiaWSicvOXgXtlvBJtQ4f3ia52l5icbOK4e8C4BaVibw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;美图公司在 App Store 上线的产品，共 20 款&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;庞大的数据为美图带来无可比拟的优势，「图像、视频都在向深度学习靠，但深度学习拼到底，很多时候是要靠数据。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;都是自拍照，会不会面临数据结构单一化的问题？美图获得的数据目前的确以自拍照为主，「但食物、风景这些都是有相当比例的，我们的产品也不全是在人脸上做的。美拍上还有视频，这些都是我们技术上独一无二的优势。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;用户是最苛刻的「数据集」&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;美拍是美图「产品矩阵」中不可忽视的一部分，目前其视频观看量已超 79 亿，月点赞数为 46 亿次（2016 年 10 月数据）。在美拍中，「激萌表情」是相当流行的功能，用户可以实时为自己加上兔耳朵、猫鼻子、甚至直接把自己的脸变成小猪的样子。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3D 已经成为时下最重要的技术之一。去年 10 月，Angelababy 曾在微博上发布了一张万圣节上妆照，网友纷纷留言「孕妇不要搞这些花样」、「怀孕还化妆」，事实上这张照片是由美图秀秀「万圣节妆容」功能自动生成的。以假乱真的逼真效果和美图强大的 3D 技术脱不开干系——通过一张 2D 自拍照重建人脸 3D 模型。「万圣节妆」其实是一款 3D 妆容，立体贴合造就了真实的「假象」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8mkkOTgrRQux7YyjNTL5mdfoHp8DNAr47oNhIEUs9icwyh95Q2Hg8ZpAXY64D7aXmg6ibuKQ8CDvicw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Angelababy 万圣节妆容微博，被点赞 71 万次&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;很快美拍还将上线实时 3D 功能，除了在直播的同时自然的放大双眼、添加妆容，还可以添加 3D 兔耳朵、耳机或是卡通魔镜。早在 2015 年 1 月，美图就已战略投资专注 AR 核心技术和产品研发的亮风台，并成立了联合实验室。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8mkkOTgrRQux7YyjNTL5mdVoPZDN9TIX0Hiaxj4iaCOJicw1yNiay0ECjTicuC73o1ZBdiabr79t6nbrBQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;美图影像实验室 2D 转 3D 的效果图&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谁来衡量「用户喜欢」的标准？美图内部设有专门的「设计特效」团队，会对技术结果进行反馈。作为专管效果的「产品经理」，他们更了解美的标准和用户的标准是什么。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;可是作为专注影像技术的实验室，为什么很少在数据集测试中看见他们的身影？「首先，美图没有通过 PR 获得资本市场认可的压力；另外，美图习惯于用产品说话，我们公司很多功能非常实用，好用到理所当然。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于美图来说，爱美的用户们是最苛刻的「数据集」，为用户提供更好的体验就是探索技术的动力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但也并非完全不理会，实验室正考虑在测试数据集和论文身上分散些精力。目前实验室已经尝试了 FDDB 人脸检测数据集，美图的 MT-Face-v3 在大部分阶段表现都是最佳之一。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8mkkOTgrRQux7YyjNTL5mdXyiaj8yxtQr0q7vzNJXGdZAlniasic0vay8DGXWzbAJVFN6T2D1kxWslw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;MT-Face-v3 在 FDDB 上的表现&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;接下来，美图会在技术上增加不少投入。在去年美图赴港 IPO 招股书中提到，未来两年预计投入 3.27 亿港元（人民币 2.90 亿元，占所得款项净额的 6.6%）用于扩大研发能力，包括但不限于招聘工程师、数据科学家、分析师及收购技术相关知识产权。目前美图已注册超过 300 项专利，并持有 94 款软件程序的著作权。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;当技术遭遇美&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自文艺复兴时代起，艺术家们就在想方设法为自己留下自画像。1513 年达芬奇用红色粉笔画下自己晚年的样貌，透过画纸向未来的观众投以深邃目光；伦勃朗通过镜子描绘自己的样貌，右手执笔的他自画像几乎都向左倾；1998 年，梵高的最后一幅自画像《Self-Portrait without beard》拍出 7150 万美元的天价，是历史上第四贵的画作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一张用相机拍摄的自拍照诞生于 1839 年，Robert Cornelius 打开摄影机，在镜头前坐了足足一分钟。到了 2014 年，Twitter 上转发量最高的的照片，是艾伦和詹妮弗·劳伦斯、布拉德·皮特等明星的自拍照。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8mkkOTgrRQux7YyjNTL5mdwWvJCW4y5amtRBKiaUs99ck6taDicNDEslv3MGrMQbibk9eXAo1FNOHfw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;这张「著名」自拍照被转发超 300 万次&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随着时间流逝，人类的自拍史不断变化，承载自拍的手段和技术也在不断进化。「美本身是没有错的，大家都喜欢，但标准不一样。我作为男生不太喜欢磨皮，拍出来精精神神就好了，更喜欢用潮自拍加滤镜。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;作为在这一过程中提供技术基础的美图影像实验室，不会强调「磨皮就是美」、「不磨皮就是美」，而是希望通过人工智能把「工具」做得更好，为每个人提供不同的美的体验。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;就连实验室也不自觉的向这一目标靠拢靠拢，「我们的愿景，是让世界变得更美。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;满足自我欣赏也好，追求他人认可也罢，在弄清「人们为什么会自拍」这个亘古难题之前，不妨把它当作一种人类的本能行为。也许自拍的合理性一直都在，只是我们没有足够的技术去实现。移动设备的出现和类似美图应用的崛起，让自拍已经从一件「奇怪」的事变成新「常态」。当然，每个人都有选择是否自拍的自由。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「美是自己选择的。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;注：封面图为美图影像实验室在去年 12 月的 Siggraph Asia 上，向与会人员展示产品效果。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心原创，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 19 Jan 2017 11:05:27 +0800</pubDate>
    </item>
    <item>
      <title>演讲 | 腾讯副总裁姚星：人工智能真实的希望与喧哗的隐忧</title>
      <link>http://www.iwgc.cn/link/4403737</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心编辑&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;编辑：朱思颖&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;在近日举行的腾讯研究院年会上，腾讯副总裁、AI Lab院长姚星发表了《AI 真实的希望与喧哗的隐忧》主题演讲，介绍了腾讯人工智能部门的发展历程，同时也对机器学习和人工智能的未来谈了自己的看法。机器之心参与了本次会议，并对演讲内容进行了整理。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8mkkOTgrRQux7YyjNTL5mdbV3YcjgvFF65tmuPGwZMbQ8DGZZiaOW1iaDUdIzZRfVBiaR9lIHOgiaRBg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;姚星首先回顾腾讯与中国互联网二十年的发展历程，从最初的窄带时代到现在的移动互联网时代，在每一个重要节点腾讯都有一款重量级产品出现。在最近进入到 AI 爆发的阶段，腾讯也顺势成立了自己的 AI Lab。演讲中正式向外公布腾讯 AI Lab 所关注 AI 四个基础研究领域和 4 个专属研究方向。也谈及在趋之若鹜的 AI 浪潮中，大家对人工智能的希望来自于深度学习的算法、模型和数学理论的突破，但同时深度学习自身的能力局限、计算能力的限制以及数学理论的不可解释性为过高的期望降温。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;以下为演讲内容整理：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;各位朋友大家下午好。今天我演讲的题目——AI：真实的希望与喧哗的隐忧。希望表明了大家对 AI 的期待，而隐忧则说明大家期望过高。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;腾讯与中国互联网二十年的发展&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;回顾中国互联网过去二十年的发展，这二十年是信息高速发展的二十年，大致经历了三个发展阶段：上个世纪九十年代、21 世纪初期以及2010 年后。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8vVyKicyjQ1yA6SicZOZvAA16wH6sAibQTtcXONic3JELHG0PmxOxUpMBsxb34tW9aBOkRDW9CeOTPXA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在上世纪九十年代初期，中国第一次连上互联网——「跨越长城，连接世界」。随着第一封 e-mail 的发出，中国正式进入到互联网大家庭中来。但是由于当时网络速度的问题，大部分互联网应用只限于沟通。沟通解决了当时的很多问题，人们不再需要面对面才能进行交流，或者通过传统书信的方式进行沟通。不论天涯海角，只要能连上互联网，人们总是可以接触到信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随着整个网络设备和传输能力的发展，特别是 2000 年以来，网吧的大量涌现、网络连接速度的大幅提升、网络带宽速度的快速提升，人们对互联网的诉求不再仅仅是消息的传递和沟通，更多的是分享。当时兴起了很多基于分享的应用，博客、MSN、 Facebook、QQ 空间等都是基于分享的。人人为我，我为人人——有很多内容或者信息都是通过互联网来分享的，比如跟朋友分享生活的喜悦和苦恼。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随后移动时代的发展，特别是以智能手机为代表的智能终端的发展，也即自 2010 年以来，移动互联网高速发展所带来明显的变革——人们不再受限于特定时间和特定空间的互联网连接。以前大家都是在网吧或者工作的地方才能获取互联网信息，现在大家随时随地通过智能手机就可以与互联网连接。可以看出，中国互联网过往二十年的发展是随着设备的发展、产业的发展、信息产业的发展而演进的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;伴随着互联网过往二十年的发展，腾讯在过去二十年里做了些什么？实际上在每一个阶段，腾讯都有一款重量级的产品出现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8vVyKicyjQ1yA6SicZOZvAA1mHeS1arngwL3KiaKgw4fsHrgqcuwfysFNibeZcVlKOichicD1z0O1JqibJg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在上世纪九十年代，也即中国互联网的早期发展阶段——窄带时代，就如刚才所说，当时的互联网主要是用于沟通，在那个阶段腾讯推出了 QQ。QQ 是目前世界上同时在线人数最多的应用，已经达到两亿人同时在线的体量。而到了宽带时代，在 2000 年初的时候，QQ 空间诞生。QQ 空间目前日上传照片数超过五亿张，这个规模跟世界上最大的社交网络 Facebook 相比，几乎是同一个量级，在总照片数量上跟 Facebook 也几乎是同一个量级（2013 年 Facebook 公开数据显示其日上传照片数大概是在 2.5 亿张左右，总照片数大概 6000 亿张）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然后来到移动互联网时代，为大家所熟知的一个产品就是微信。这款产品不仅是一个简单的应用，WeChat 是一个超级 APP。微信不仅解决了沟通问题，还解决了社交、分享的问题，还支持线下支付、线下打车，甚至医院挂号看病、交水电费等一系列功能都可以在这一个软件上实现。实际上，腾讯的这三款产品在整个世界范围内都是领先的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从整个发展史来看，我们可以看出过往的发展史经历窄带时代、宽带时代，然后到现在的移动互联网时代，它犹如生物进化一般，从原始的单细胞生物到多细胞生物到最后有智能的生物。那么今年来讲「智能」，智能会更加的广义，不仅仅是智能终端，大家讨论更多的智能是 AI。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8vVyKicyjQ1yA6SicZOZvAA1N2I5YME9Je6B2tTO931UjmQrZqBD5eSRfa3fiaVibsTUnCHMSUC8epdA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;腾讯的 AI 布局&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2016 年正好是 AI 发展六十周年，从去年开始 AI 迅速爆发，可以说是家喻户晓。这也是为什么我刚刚在跟很多嘉宾聊的时候说，大家觉得腾讯在 AI 上很低调，没有什么大动作。甚至有很多人问我腾讯到底有没有在做 AI？怎么从来没有向外界宣布任何 AI 相关的布局规划呢？实际上腾讯有自己的 AI 部门，从 2016 年 4 月份开始，腾讯成立了自己的 AI Lab，目前已经有 30 多位的 Research Scientists，绝大多数拥有博士学历及以上且都有海外研究经历。他们中业界的来自于微软、IBM、Facebook 等公司，学术界是从世界最顶级学府引进的人才，包括斯坦福、加州伯克利、康奈尔、麻省理工、哥伦比亚大学等顶级高校。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8vVyKicyjQ1yA6SicZOZvAA18tUSG8OvQL9Icnkho01Cichc8GU36iaFibKUHrOic1icUibBFe7mGbS4YapA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前在腾讯，我们已经组织了一个 30 人左右的 AI Lab，而且规模还在扩张。腾讯的 AI 可能不像其它公司的 AI 为人所了解，比如说谷歌的 AI，很多人都知道 DeepMind 在做围棋，他们用强化学习来实现，而且他们用强化学习来完成很多任务。以及他们提出了很多的神经网络结构（neural network），比如 WaveNet，deepNet，LipNet 等；而百度为大家所熟知的有无人车、度秘等一些产品。但腾讯的 AI 一直没有对外宣传，今天我也跟大家分享腾讯在 AI 上面的一些考虑。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;实际上腾讯的 AI 主要基于四个垂直领域，计算机视觉（Computer Vision）、语音识别（Speech Recognition）、自然语言处理（NLP）和机器学习（Machine Learning），每一个领域都是代表了 AI 的一个基础的研究方向，但是每个领域都可以更多深层次的研究拓展。比如在计算机视觉领域，除了传统的图像处理还会有增强现实（AR）的研究拓展，也会引入空间定位（Simultaneous Localization and Mapping）技术；比如在语音识别领域，我们除了传统的语音识别、语音合成以外，还会引入更多的跟语音相关的拓展研究比如说自动翻译（Translation）。另外在 NLP 里，除了传统的自然语言处理的对人的认知行为的一些研究，我们还会做聊天机器人的一些研究。在 ML 里，从监督类的机器学习到无监督的机器学习，然后到增强学习的机器学习，都会展开相关的研究。这四个领域基本上涵盖了当今整个 AI 基础研究领域的方方面面，也是腾讯 AI Lab 将会关注的四个基础研究领域。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8vVyKicyjQ1yA6SicZOZvAA19eOygZqiciadiayRlRWGBqjDf1e6fDPneibiaqHibTo726vQbOFbZxL4v5LA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然后我们还提出了四个专属的研究方向，这是结合整个腾讯公司的业务来进行的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们提出了内容 AI（Content AI），我们把基于内容类的推荐和搜索类的应用都归属在内容 AI 里。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外还有我们的社交 AI&lt;span&gt;（Social&amp;nbsp;AI）&lt;/span&gt;，腾讯是一个社交应用上很强势的公司，包括刚刚说的 QQ 空间、微信都是社交平台，所以在社交 AI 上面我们会基于社交考虑来研究相关的 AI 技术，比如社交中的对话、聊天机器人、智能助手等，都会纳入这个研究方向中来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外一个方向，我认为是和全世界其他所有的公司都不太一样的一个 AI 方向，即我们的游戏 AI（Game AI）。大家可能会问我，DeepMind 也有做围棋的 AI，但是它只是一个围棋游戏，它不会涉及到太多的游戏。而对于腾讯来讲，在整个腾讯集团里面，游戏是腾讯一块很大的业务。我们会在游戏里面引入更多 AI 能力，实际上这个 AI 游戏的想像空间是非常大的。大家试想一下，会不会有一天 LOL 里 AI 也来参加世界电竞赛，与人类交战。大家知道现在腾讯有一款很受欢迎的手游叫做「王者荣耀」，如果把这里面的能力提升，是不是可玩性、乐趣性就会更多，腾讯对这一块也是很关注的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除此之外我们还会提供很多工具类的 AI，会结合到腾讯的云服务，我们需要研发相关技术从而加强相关能力来实现这些工具的开放。这些工具将包括基于图像的人脸识别的能力、语音识别的能力、在自然语言处理里的舆情处理能力等，还包括我们在深度学习上的开放深度学习平台的能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以说从目前来讲，整个腾讯 AI 研究的基础领域是四个，我们的专属研究方向也是四个。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;深度学习喧嚣之下的隐忧&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;AI 不是一个新的概念，它的发展经历了六十多年，在这六十年里，人工智能的发展之路并不平坦。在去年人工智能又突然爆发了，势头一直延续到了现在。1956 年的达特茅斯会议，AI 这个名词被首次提出。人工智能比较有名的事件是九十年代 IBM 深蓝打败了卡斯帕罗夫，也就是那个时代的 AlphaGo 和李世乭。人们记忆中最清晰的一件事还是去年 AlphaGo 围棋打败围棋世界冠军李世乭，这表明在围棋这个最古老、最复杂的游戏上面，AlphaGo 的智能已经超越了人类。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8vVyKicyjQ1yA6SicZOZvAA1wQEhpGxfe4e2ctyOicJHnegF9WEwrWEicXjyAPicmtPTibk8uBVJxkr3Pw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然整个发展史里面也有很多技术方面的演进，比较有代表性的就是 2006 年，Geoffery Hinton 在深度学习上有了巨大的突破，带领 AI 的所有发展方向极速提升。我认为这次人们期待 AI 最主要的原因是这一次 AI 的底层算法在深度学习上面有了实质性的突破。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这次 AI 的发展是从 2012 年开始的，先在业界落地。可以看到整个深度学习的方法和传统方法完全不一样，不像以前的研究方法，是通过模仿来实现的。这一情形和早期人类想粘上羽毛学习飞翔比较类似，我们都知道真正的飞翔是通过空气动力学去完成的，这也是深度学习的一个思想之一。&lt;/span&gt;&lt;span&gt;之所以现在能有很多应用上的突破，是因为研究员们掌握了内在的学习方法，而不是表面的模仿。所以从这一点来说，我们现在在深度学习的研究方法上是正确的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二个是模型上的提升，刚才我说了，AI 的发展有六十年，机器学习以及深度学习并不是最近才突然出现的。神经网络早在六十年代就有过——当时提出来感知机（perceptron）。机器学习在八九十年代也非常火，当时有一个叫 SVM（支持向量机）的分类器，已经是非常厉害的一种机器学习的算法。那么现在为什么又重新提出来？深度学习同原来的机器学习相比，在模型能力上有非常大的提升。大家都知道我们所有的机器学习的方法，都是从 A 到 B 去寻找一个拟合函数，实现一个最佳的拟合过程。在这个过程中如果选取的特征越多，拟合的效果就会越好。但同时有一个问题，当特征太多的时候，计算能力就会出现问题。在浅层模型中，如果要模拟出一个从 A 到 B 的完美拟合过程，它的数据能达到几亿甚至几十亿的规模，当他达到这种规模的时候它的计算能力就会急剧下降，会通过一个非常复杂的复合函数去描述数据。但是深度学习的方式能够很好的解决这个问题，它通过深度学习神经网络的多层连接，其特征表达是一个指数层倍的关系，如果说用一个全连接（fully connected）描述十亿的特征，可能我们只需要三层一千个节点的连接，就能构建十亿个特征的权重出来。所以从本质来讲，模型上的提升也是深度学习的一个突破。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外，针对反向传播问题（BP），AI 界从 80 年代开始真正使用 BP 算法来训练多层神经网络。在神经网络里，当输入信息由多层网络向前传播之后，将网络的输出结果与实际结果的误差，从输出层向输入层反向传播。在整个 BP 过程，都是需要通过随机梯度下降的方式进行求解，以逐渐逼近最优值。今年来，随着网络结构的不断加深，使用传统的 Sigmoid 激活函数使深层网络的参数优化过程中出现梯度消失的问题。通过一些数学的理论和技巧，可以很好解决这种梯度消失问题，以用于训练非常深层的神经网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8vVyKicyjQ1yA6SicZOZvAA1wCoWmRplIszYyslvfroQJpok9E1NyaGDZh0lF5Yd884r0tz18XKP1g/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;正因为这三方面的优势，使得在这次 AI 的浪潮里，深度学习才会如此之火。而且我坚信这次的 AI 浪潮会持续很久。在 1993 年到 2000 年左右，整个传统的浅层机器学习的研究进展还是很不错的，图中可以看到这段时期错误率有明显的下降，也即识别效果的提升很快。但是从 2000 年到 2010 年这十年，可以看出没有明显的下降变化。可能是在方法上面，在模型上面都没有太大的研究进展。在 2012 年左右有一个明显的转折点，也就是微软研究院第一个在业界把深度学习用于语音识别，取得了极大性的突破，随后又进行了一系列性能上的提升。在过往的五年当中，深度学习的发展是非常快的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;讲了很多深度学习的内容，刚才谈到深度学习的快速发展，它的方法很好，模型也很好，数学算法也在突破，但是现状是什么呢？今天我想谈的话题是大家对 AI 的期待很大，但期待有些过，为什么会这么讲？作为一个从业者，我认为目前 AI 上还是有很多局限的，可能需要提出来，与大家一起探讨。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一个是深度学习本身所具备的能力，即大家所说的将 AI 与人类相比，存在多大的差距。实际上如今所有的深度学习方法，不论这个方法有多么的新，其学习过程都是要从头开始，需要经历数据重新训练的过程。这一点和人的学习能力相比确实有很大的差距，因为人有很多的智能是与生俱来的，如小孩刚出生，他感知这个世界是三维的并不需要多长时间，并且如果你将一个物体放在电视机后面，他会知道电视机后面有这样一个物体，这些能力是与生俱来的，其与生物的进化是相关的。所以灵长类动物和单细胞生物相比是有与生俱来的能力的，人类的小孩不需要再次经历单细胞演进到灵长类动物这一过程。但在目前的深度学习方法下，不论我们提出了多么优秀的模型，其都需要从最开始的数据开始学。这和人类的学习能力相比，是一个巨大的缺陷。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二个是计算能力。不论是多么好的深度学习模型或者神经网络出现，本质上还是通过计算能力去解决大数据的问题，更好的计算能力去做更好的拟合。在这个计算力上面，过往的十年是整个硬件发展的十年，是符合摩尔定律的。但是在以后需要训练更多参数的情况下，我们能否有足够的计算力以达到预期效果还有待商榷。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从 2012 年提出来的 AlexNet 网络模型，这个模型在当时的 ImageNet 挑战赛中获得冠军，到剑桥大学提出的 VGGNet，谷歌提出的 GoogleNet，再到 2015 年 MSR 提出的残差神经网络 ResNet，每一次新模型的提出都伴随着模型层级的增加、神经单元复杂度的加强、训练过程的加长，当然得出来的结果也更好。但是这种通过计算力去解决问题的方式是不是还能像以前一样可持续，有待商榷。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;刚才所说的都是图像方面的研究，谈及人工智能来解决系统认知问题，那么与人的差距就更大了。人类语言是一个序列问题，这个语言序列问题如果通过神经网络去训练的话，仅通过计算力是不可能解决这个问题的。人在对话当中很容易回溯到长时间语句的某个片段关键词里。但在机器学习中却不一定能做到这样，虽然从最早的 RNN 模型中构建了 LSTM（长短期记忆单元）模式，后来又提出了带注意力的模型。但总体上，这种模型的演进和人类相比是远不如人类的。举个自然语言处理（NLP）的例子，有三个人在对话，两个人在聊湖人跟快船的比分是几比几，然后中间有大段话题转到去哪里吃饭，突然插进来第三个人问太阳呢？机器这时候很难理解「太阳」到底是哪个太阳，聊天者知道这是描述太阳队，因为在「去哪吃饭」这个话题前有湖人和快船的话题。但是机器基本上没办法识别，又如「夏天能穿多少穿多少，冬天能穿多少穿多少」，这两句基本一样，但前面的描述突出少，后面的突出多。这种认知行为到目前为止，深度学习上再先进的方法也没办法处理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二个例子是语音识别，我看过一个笑话，语音识别很难处理，「您好，方便面试吗？」我在重复这句话的时候，我都不知道自己在讲方便面——是吗，还是方便——面试吗，这的确是一个非常难的问题。但是人的理念里有很多东西，是可以通过反问，多次获取信息来最终理解。所以说目前人工智能情况，在图像方面，例如人脸识别的精确率有多么高能达到 99% 的识别率，但实际上是在很多的约束条件下才能实现，识别正脸的模型不能识别侧脸，或者是把同一个人的侧脸完全识别成另外一个人。在语音识别里也是如此，目前语音识别是在获取的信息源很干净的情况下才能有很好的效果，比如噪音比较小、没有混响、没有风噪和车噪，在这样的条件下，机器在听语音识别的时候才可能会识别出比较好的效果。但对人来说，这完全不是问题，以及多人的面部识别，语音跟踪，这些对人来说都不是很难。但是对机器而言，即便在我刚刚所说的感知领域——图像识别和语音识别，它跟人基本的能力相比还有很大差距，更别提在认知的任务处理上，比如 NLP 的语意理解。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8vVyKicyjQ1yA6SicZOZvAA1nSIuXgr7hcrK80ibL5BvFFEjBOMabLURPoUqfFqMHbAEVbPHCJWPAzA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于整个人工智能领域来说，我认为人们现在对 AI 的期待过高。我们要回归现实，AI 现在方兴未艾，这个趋势是很好。但未来 AI 发展的方向是什么呢？我觉得 AI 跟人，也即深度学习跟人的能力相比还是有些差距的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;跟人相比第一个是创造力的不足。我们现在所有深度学习的模型都是基于大数据的，这些数据从何而来？目前的数据还是通过传统的方法获取到的，但能不能通过深度学习本身创造出更多的数据？AlphaGo 已经在验证这样的问题，通过增强学习产生了人类从未下过的棋局并以此来训练模型，这是一种创造数据的能力。我觉得未来在这方面发展，在增强学习上，我们要进行更多的发展和突破。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二个是举一反三能力。AlphaGo 下围棋能赢世界冠军，但是它如果改下其他的棋，它的下棋方法就不行了，因为它的算法只是为围棋而设。人的很多能力是可以举一反三的，比如小孩做数学题，当他学会列二元一次方程之后，他会很快掌握二元一次方程的技巧去解决这一类的数学应用。这种能力在机器学习里面也有一个同质的算法——迁移学习。当我们在一个全新的应用场景里，在少量数据的情况下去测试一个在大数据集上表现非常好的模型，如何把原来的模型迁移过来并且能够应用在新场景里，这是一个非常重要的研究方向。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第三是归纳总结的能力。人的总结能力是很强的，比如牛顿第一定律、万有引力定律等，都是总结出来的，还有很多公理也都是归纳总结出来的。但是目前机器学习是没办法进行归纳总结的，机器学习的结果再好也只是一个拟合过程，并没有能力去归纳提炼。未来我们要在模型归纳总结能力上提高，如何从海量的结构化或者非结构化的数据中，通过机器学习来完成知识的总结和提炼神经网络中的知识（distill knowledge）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这三个能力，我认为这是未来 AI 需要进行提升的地方。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外一个维度的缺陷是在数学理论的发展方向上，刚刚讲过的很多机器学习适用的数学原理和方法，实际上是很脆弱的。跟过往浅层学习的数学理论相比，深度学习的数学原理还有很多不可解释。在浅层学习里，有完备的统计学概率论理论提供支撑。比如求解凸函数的极值，有很多完善的数学理论能够证明有最优解的存在。但是在深度机器学习的研究中，虽然前面有提到可以用随机梯度下降的方法去求解局部最优值，但是它只是一个框架。我们在很多方面还在使用启发式的约束，比如初始化参数的设置、激活函数的设置、学习率是多少，这都是基于启发式的，也即依赖于人的经验。未来机器学习的继续发展，在数学理论上面一定要有强大的支撑。此外，在交叉学科的研究上要继续加强，我们知道感知机以及神经网络的提出来源于脑神经学科，未来 AI 发展肯定要引入更多学科，不仅是统计学科、数学学科、计算机学科，还要引入脑神经学科。之前所提到的残差神经网络，这个网络在设计上已经有一点接近脑神经的设计了。因此，未来 AI 能有更完备的发展，是需要将这些学科的研究都综合起来的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;再有一点，就是 AI 研究的开放与平等。我认为对任何公司和任何人，AI 都应该是平等的，这也是我们要做开放 AI 的立足点之一。在现在的 AI 领域里，所有的大公司都在做开源，腾讯当然会开放自己的研究。各大公司在开源上都表现出很积极的一面，比如谷歌开源了自己的机器学习框架 TensorFlow，还有很多机器学习的先行者（DeepMind、OpenAI）在做开源，在开放开发框架和训练数据。腾讯未来也会进行开源很多内容，提供一个让更多人参的平台，共同开发人工智能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8vVyKicyjQ1yA6SicZOZvAA1iabFAI4c65icTNxBkficRVfufoibBFTic6kVDyx7SIa2aiaNKehxKPDZE4dQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于未来 AI 技术的发展，首先是能力的提升，在创造能力、举一反三能力以及归纳总结能力上有长足进步；另一方面是机器学习的完备性，我们要在数学完备、学科完备上进一步进行探索；同时，所有的科技公司，AI 的参与者都要以更加开放的心态去面对人工智能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;未来 AI 大有可为&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;说到这个话题，我又想再次强调 AI 对腾讯来说是非常重要的，对整个中国互联网都很重要。回顾整个互联网浪潮，在互联网时代的初始阶段，中国的互联网公司跟美国最强的互联网公司相比有一定的差距。而当下的 AI 时代，我坚信中国的互联网公司跟世界上一流的公司是处于同一位置的，为什么？第一点原因，我们数据足够多，中国的互联网人数是世界上其他国家的互联网人数的总和。在腾讯的业务里面，微信、QQ、QQ 空间，已经产生了海量数据。在中国的其他互联网公司，比如电商和搜索的公司也会产生大量数据，这些对中国公司来说，是一个非常好的优势。第二个原因是来自应用场景，对于腾讯的业务来说，我们有很多种把 AI 这种听起来似乎遥不可及的技术在微信、游戏、新闻、QQ 里通过 AI 产品去落地，哪怕只是一个小点上的应用。第三点是人才，目前的数据表明从事深度学习的研究人员中相当一部分人都是中国人。虽然国内在机器学习上的专业还比较少、学科也比较少，但是在全球范围内，研究深度学习和机器学习的华人是非常多的。我参加 16 年的 ICML 和 NIPS，ICML 有 3000 多人，NIPS 有 6000 多人，有 30-40% 的参会人员都是华人，40% 的会议 paper 都是华裔写的，在人才结构上，中国有很好的人才基础。正是基于我们数据的优势，场景落地的优势，人才结构的优势，我觉得腾讯以及其他中国互联网公司，未来在 AI 上大有可为。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，腾讯的 AI 使命： Make AI Everywhere——让 AI 无所不在。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编辑，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 19 Jan 2017 11:05:27 +0800</pubDate>
    </item>
    <item>
      <title>资源 | 谷歌发布用于有监督词义消歧的大型语料库</title>
      <link>http://www.iwgc.cn/link/4403738</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Google Research Blog&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：微胖、朱思颖、蒋思源&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;理解特定单词在文本中的各种意思是理解语言的关键。比如，句子「he will receive stock in the reorganized company」中，根据新牛津美语词典（NOAD），我们依据上下文可以知道「stock」是指「公司企业通过发行和认购股份筹措到的资金」。但是，词典中，从「存货（goods in a store）&lt;span&gt;」&lt;/span&gt;到「一种中世纪刑具」，stock 的定义有十多个。计算机算法很难区分这些意思，过去，人们形容这一问题难度「与解决强人工智能核心问题的难度不相上下（AI-complete）」（Navigli, 2009 Mallery 1988 ）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了帮助解决这个难题，我们很高兴发布了基于流行的 MASC 和 SemCor 数据组的词义标注，人工标注了 NOAD 的各种词义。我们也在发布 NOAD 词义到 English Wordnet 的映射，研究社区更常用到这个。这是最大的全词义标注英文语料库发布之一。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;发布地址：https://github.com/dmorr-google/word_sense_disambigation_corpora&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;有监督的词义消歧&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人类能很容易分辨出文本词义之间区别的原因是人类能接触大量常识性知识。这些常识包含世界如何运转及其与语言之间的联系。举一个机器理解困难的例子，「[stock] in a business」（在一单生意里的 stock）意味着意思与金融相关。但是，在「[stock] in a bodega」（酒窖里的 stock）中，更可能是货架上的货物，尽管酒窖（bodega）也是一种生意。获取足够的机器可加利用的知识，然后将这些知识运用到文本词义理解上是一种挑战。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有监督的词义消歧（WSD）也即运用人标记的数据来构建一个机器学习系统，这个机器学习系统能够将词典里的某个意思分配给出现在文本中的这个单词（与实体歧义消除不同，后者关注的是名词，对名词的词义理解大多是正确的）。构建一个比不考虑文本语境，仅将单词最常用的意思分配给单词的监督模型更好的模型，很困难，但是，有了大量训练数据，有监督的模型会表现非常好。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过发布这个数据集，我们希望研究社区能提出更先进的算法，从而机器对自然语言有更好的理解，并能支持应用如：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;方便从文本自动构建数据库，从而可以回答问题和链接文本中的知识。例如，理解「hemi engine」是一种自动化的机械，「locomotive engine」是属于火车的，或者也可以是说「Kanye West is a star」意味着他是一个名人，而「Sirius is a star」意味着它是天文学客体。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;消除查询中的词的歧义，使得「date palm」和「date night」或「web spam」和「spam recipe」等查询可以被解读出各自不同的含义，并且使得根据该查询所返回的文档具有和该查询相同的含义。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;人工标注&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在我们发布的人工标注数据集中，每一个词义标注（sense annotation）由五个人评估。为了确保高质量的语义标注，评估者首先会进行黄金标注（gold annotations）的训练，这个训练事先是由经验丰富的语言学家在单独试验研究中标注。下图显示了标注者在使用我们标注工具时的工作页面。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWib4ZvicIaeEBwxiciaHXZI5ttRfthF2nxbpXEklQYGHqVePJyjxHNZBibh6rDndQzH47ictzkic9b38Bu2g/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;页面左侧列出了所有候选的字典词义（在这个例子中是单词「general」）。字典中的例句也会提供给标注者。在页面右侧，需要被标注单词会在句子中突出显示。除了将单词链接到字典词义之外，评估者还能标记如下三个异常：单词拼写错误、无上述情况（none of the above）和标注者不能决定。评估者同样可以检查词的使用是不是一种隐喻，并可以留下评论。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;用于此发布的数据进行词义标注任务使用 Krippendorff's alpha 测量达到了 0.869 的评估者间可信度值（inter-rater reliability score）。在 Krippendorff's alpha 中，α &amp;gt;= 0.67 就可以考虑是可接受的再现性结果（reproducibility），α &amp;gt;= 0.80 就是很高的可再现性结果。下面列出来了标注数：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWib4ZvicIaeEBwxiciaHXZI5ttR6cKcPqwYpybZZJ5T0cexRT0p06hwVMXnKmic4u2HLczLqJUOm0nOE9Q/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Wordnet 映射&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Wordnet 地址：https://wordnet.princeton.edu/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们也发布了两套 NOAD 到 Wordnet 的映射。小一点的那一套，我们采用上述类似词义标注的方法，人工映射了 2200 个单词，大一点的那一套是算法创造的。这些映射有助于将 Wordnet 的资源应用到这个 NOAD 语料库中，也有助于用这套语料库评估使用 Wordnet 构建的系统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这一语料库上使用基于 LSTM 的语言模型以及半监督学习的全部研究结果，请参阅论文《Semi-supervised Word Sense Disambiguation with Neural Models》。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;致谢&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这一数据库的建立离不开以下人员的帮助：Eric Altendorf、Heng Chen、Jutta Degener、Ryan Doherty、David Huynh、Ji Li、Julian Richardson 和 Binbin Ruan。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 19 Jan 2017 11:05:27 +0800</pubDate>
    </item>
    <item>
      <title>资源 | 轻量级Matlab深度学习框架LightNet的实现（附论文）</title>
      <link>http://www.iwgc.cn/link/4403739</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心编译&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：朱朝阳、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote style="white-space: normal;"&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;项目说明及论文摘要：LightNet 是一个轻量级的、多功能的、纯粹的基于 Matlab 的深度学习框架。其设计的目的是为深度学习研究提供一个易于理解、易于使用和高效的计算平台。LightNet 实现的框架支持主要的深度学习架构，例如多层感知网络（MLP）、卷积神经网络（CNN）和循环神经网络（RNN）。LightNet 支持 CPU 和 GPU 进行计算，而且它们之间的切换也非常容易。计算机视觉、自然语言处理和机器人技术中的不同应用作为实验来演示 LightNet。本项目的相关论文可点击文末「阅读原文」下载。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;项目地址：https://github.com/yechengxi/LightNet&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;如何使用 LightNet&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在具有 Nvidia GPU（至少 3GB GPU 内存）的计算机上安装最新的 Matlab，并运行 RunAll.m Matlab 脚本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这里阅读最新论文：http://arxiv.org/abs/1605.02766（LightNet: A Versatile, Standalone Matlab-based Environment for Deep Learning）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;近期更新&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;RNN（带有 skip links）和 GRU 被添加到 RNN 目录。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;LightNet 现在支持使用预训练的 ImageNet 网络模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8mkkOTgrRQux7YyjNTL5mdTch7zqpn2Knyf8kAmIJzX6kKic0X0EXnh8Z7fUceYxndLNYzvOI4svw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;查看 CNN/Main_CNN_ImageNet_Minimal()&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使用 imagenet-vgg-f 预训练网络的识别示例：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8mkkOTgrRQux7YyjNTL5mdzSMQoqPwYRotdN4Lz61CWzibrxIAMnsmsic8CcByiasbBISkWoTTDKRkQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因为 MatConvNet 团队的不懈努力，可以使用 CUDNN 加速卷积运算。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;LightNet 中主要函数&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;adagrad：Adagrad 算法的实现&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;adam：Adam 算法的实现&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;bnorm：批量规范化层的实现&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;dropout：dropout 层的实现&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;fast_conv_layer：卷积层的实现&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;fast_mlp_layer：线性感知层的实现&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;generate_output_filename：根据当前参数设置生成输出文件名&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;im2col_ln：在池化（pooling）层中使用的定制 im2col 函数&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Main_Template：用于训练 CNN 和 MLP 网络的模板脚本&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;lrn：本地响应规范化层的实现&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;maxpool：最大池化（max-pooling）层的实现&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;net_bp：在 CNN 和 MLP 网络中使用的反向传播过程的实现&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;net_ff：在 CNN 和 MLP 网络中使用的前馈过程的实现&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;pad_data：在 CNN 中使用的填充层&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;relu：线性修正单元函数的实现&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;rmsprop：RMSProp 算法的实现&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;select_learning_rate：Selective-SGD 算法的实现，其在训练的开始或中间自动选择最佳学习速率&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;sgd：具有动量的随机梯度下降算法的实现&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;sigmoid_ln：Sigmoid 层的实现&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;softmax：softmax 层的实现&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;softmaxlogloss：softmax log loss 层的实现&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;SwitchProcessor：CPU 和 GPU 之间切换&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;tanh_ln：tanh 层的实现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;test_net：在测试模式下运行网络以评估当前参数&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;train_net：在训练模式下运行网络以评估和计算损耗和梯度&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;TrainingScript：用于 CNN 和 MLP 网络的训练模板&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;如何加速 LightNet&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;CUDNN 可用于计算卷积。你将需要编译由 MatConvNet 团队提供的 vl_nnconv 函数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 请访问&amp;nbsp;&lt;span&gt;http://www.vlfeat.org/matconvnet/install/&lt;/span&gt;&amp;nbsp;下载。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 将文件夹 MatConvNet_Dir / matlab 复制到 LightNet_Dir / CoreModules / matlab 中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 尝试在 LightNet 目录中编译 MatConvNet（尽管我们只使用一个卷积函数）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4. 在主要测试脚本中设置 opts.use_cudnn = 1。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 19 Jan 2017 11:05:27 +0800</pubDate>
    </item>
    <item>
      <title>重磅论文 | 动态神经网络工具包DyNet：比Theano和TensorFlow更快</title>
      <link>http://www.iwgc.cn/link/4390009</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心编译&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：杨旋、袁泽林、赵华龙、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;近日，来自卡内基梅隆大学、日本奈良先端科学技术大学、Google DeepMind、以色列巴伊兰大学、艾伦人工智能研究所、IBM T.J. Watson 研究中心、澳大利亚墨尔本大学、约翰·霍普金斯大学、谷歌、华盛顿大学、微软和英国爱丁堡大学的研究者共同发表了一篇重磅论文《DyNet: The Dynamic Neural Network Toolkit》，正式介绍了动态神经网络工具包 DyNet；该工具包也已在 GitHub 上开源：http://github.com/clab/dynet。机器之心对这篇论文进行了摘要性的介绍，论文原文可点击文末「阅读原文」下载。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8mkkOTgrRQux7YyjNTL5mdAHHI8EQfCD4wtrK852QfSsIeias3GwazaxzHvGyicv8wjREo98e0DibiaQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：在本论文中，我们将介绍 DyNet——一个基于网络结构的动态声明（dynamic declaration of network structure）的用于实现神经网络模型的工具包。在 Theano、CNTK 和 TensorFlow 等工具包中所用的静态声明策略（static declaration strategy）中，用户需要首先定义计算图（computation graph，即计算过程的符号表示），然后样本会被传递给执行该计算的引擎并计算其导数。而在 DyNet 的动态声明策略中，计算图的构建（construction）基本上是透明的，通过执行用于计算网络输出的程序代码来隐式地构造；对于任意一个输入，用户都可以自由得使用不同的网络结构。因此，动态声明有助于实现更复杂的网络架构；特别的，DyNet 允许用户使用他们喜爱的编程语言（C ++ 或 Python）以一种他们惯用的方式来实现他们的模型。在动态声明中，有一件充满挑战的事情：由于对于每个训练样本都要重新定义符号计算图，所以其构建的开销必须要低。为了实现这一点，DyNet 使用了一个经过优化的 C ++ 后端和轻量级的图表示（graph representation）。实验表明，DyNet 的速度与静态声明工具包相当甚至比其更快，并且明显快于另一个动态声明工具包 Chainer。DyNet 根据 Apache 2.0 许可证进行了开源，可以在这里访问：http://github.com/clab/dynet&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;1. 引言&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深度神经网络现在是机器学习开发者的工具箱中不可或缺的工具，它在图像理解 [39]、语音的识别与合成 [29,65]、游戏 [45,54]、语言建模和分析 [6, 14 ] 等领域中拥有重要的地位。首先，深度学习将应用特定的特征工程（加上理解良好的模型，这是经典的「浅度」学习的范式）替换成了应用特定的模型工程（model engineering，通常结合了输入的不太复杂的特征）。因此，深度学习范式在不断发展新的模型变体。要开发有效的模型不仅仅需要洞察力和进行分析，还需要实现一些新模型并评估其在实际任务上的表现。因此，快速的原型设计、高效轻松的维护和正确的模型代码在深度学习中至关重要。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深度学习模型以两种模式操作：在给定输入的情况下计算预测值（或者是预测上的分布），或者在监督学习训练的时候计算相关模型参数的预测误差「损失」的导数，用于使用梯度下降方法的某些变体来最小化和类似输入之间后续的误差。因为实现模型需要同时实现模型预测的代码和进行梯度计算和学习的代码，所以模型开发是一个非常困难的工程挑战。通过使用简化神经网络计算的工具，可以减少这种挑战的难度。这些工具包括 Theano [7]、TensorFlow [1]、Torch [13]、CNTK [64]、MxNet [10] 和 Chainer [62]，它们提供了神经网络功能原语（例如线性代数运算、非线性变换等）、参数初始化和程序优化以及表达特定任务预测和误差的复合能力——这些预测和误差然后会被自动微分（autodiff）以获取驱动学习算法所需的梯度。最后的自动微分（autodiff）组件可以说是它们最重要的节省劳动的功能，因为如果要改变计算训练输入损失值的函数，那么其导数的计算过程也要做出相应的改变。如果工程师独立地维护这些代码路径，则它们很容易导致它们不能同步。此外，由于对复合表达式的微分的算法相对简单 [63,31]，所以使用 autodiff 算法代替手写代码计算导数是个不错的选择。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;简言之，由于这些工具有效地解决了一些关键的软件工程问题，它们让深度学习取得了成功。不过仍然存在一些问题：因为工程（engineering）是深度学习实践的关键组成部分，什么工程问题是现有工具无法解决的呢？它们能让程序员比较自然地实现自己的想法吗？它们是否便于调试？它们是否方便大型项目的维护？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在本论文中，我们将推荐一个基于几个流行工具包的编程模型——即将网络架构的声明和执行（我们称为静态声明）进行分离，在这其中必然会存在一些严重的软件工程风险，特别是在处理动态结构化网络架构（例如，可变长度的序列和树形结构的递归神经网络）的时候。作为一种替代方案，我们提出了一个替代的编程模型，它可在 autodiff 库中进行统一声明和执行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;作为我们推荐的编程模型的概念证明，我们通过论文《DyNet: The Dynamic Neural Network Toolkit》进行了描述。DyNet 是一个基于统一声明和执行编程模型的工具包，我们称之为动态声明（dynamic declaration）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在单台机器环境（single-machine environment）中的一系列案例研究中，我们表明 DyNet 的执行效率与标准模型架构的静态声明工具包相当。和使用动态架构（例如，其中每个训练实例具有不同的模型架构）的模型相比，DyNet 的实现得到了显著的简化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;2. 静态声明 vs. 动态声明&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在本节中，我们更具体地描述了静态声明（§2.1）和动态声明（§2.2）的两种范式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;3.范式编码&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3.1 编码范式概述&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从用户的角度来看，使用 DyNet 编写程序的目的是创建对应于需要被执行的计算的表达式（Expression）。这首先从基本的表达式开始，基本表达式通常是常量输入值或模型参数（Parameters）。然后，通过进行运算（Operation）从其他表达式进一步构建复合表达式，并且运算链（chain of operations）隐含地为所需的计算定义一个计算图（ComputationGraph）。该计算图表示了符号计算，并且计算的结果是被动的：仅当用户显式地请求它时（在该点触发「前向（forward）」计算）才执行计算。评估标量（即损失值）的表达式也可以用于触发「后向」计算，其以参数为依据来计算计算的梯度。参数和梯度被保存在模型（Model）对象中，训练器（Trainer）用于根据梯度和更新规则来更新参数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们下面将简要地介绍这些每种组件：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Parameter 和 LookupParameter：Parameter 是表示诸如权重矩阵和偏置向量之类的实数向量、矩阵或张量。LookupParameters 是我们想要查找的参数向量集，例如词嵌入（word embeddings）。换句话说，如果我们有一个词汇集 V，我们想要查找其嵌入（embeddings），那么就有一个 LookupParameters 对象定义一个 | V | ×d 矩阵，其作为一个嵌入矩阵与 0，...，| V | -1 到 d 维向量的项形成映射。Parameters 和 LookupParameters 被存储在模型中，并可以跨越训练样本（即跨不同的 ComputationGraph 样本）进行保存。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;模型（Model）：模型是 Parameters 和 LookupParameters 的集合。用户通过从模型中请求 Parameters 来获取它们。然后模型会跟踪这些参数（及其梯度）。模型可以保存到磁盘中也可以通过磁盘加载，也可以被下面要讲到的 Trainer 对象使用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;训练器（Trainer）：训练器实现在线更新规则，比如简单随机梯度下降、AdaGrad [16] 或 Adam [34]。Trainer 有指向 Model 对象的指针，所以同时也有其中的参数，并且还可以根据更新规则的需要保存关于参数的其他信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;表达式（Expression）：在 DyNet 项目中，表达式是主要的可以被操作的数据类型。单个表达式代表了一个计算图中的一个子计算。举个例子，一个表示矩阵或者向量的参数对象可以被加进计算图里，这就产生了一个表达式 W 或者 b。同样，一个 LookupParameters 对象 E 可以通过查找操作来查询一个专门的嵌入向量（它也是被加在计算图里的），这就产生了一个表达式 E[i]。这些表达式可以被组合成更大的表达式，例如 concatenate(E[3], E[4]) 或者 softmax(tanh(W ∗ concatenate(E[3], E[4]) +b))。这里的 softmax、tanh、∗、+、concatenate 都是运算，下面详细介绍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;运算（Operations）：运算不是对象，而是在表达式以及返回表达式上运行的函数，它用来在后台构建计算图。DyNet 为很多基本的算术原语（加、乘、点积、softmax、...）和常用的损失函数、激活函数等等都定义了相应的运算。当情况适宜时，运算可以通过运算符重载来定义，这使得图的构建能尽可能地直观和自然。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;构造器类（Builder Classes）：Builder Classes 定义了创建各种「标准化」的网络组件（比如循环神经网络、树结构网络和大词汇量 softmax）的接口。这些都工作在表达式和运算之上，并且提供了各种易用的库。Builder Classes 为各种标准算法提供了高效便捷的实现。不过，从代码层次的意义上来说，它并不是「核心」DyNet 库的一部分，因为 Builder Classes 是更高层次的，它实现在 DyNet 最核心的自动微分功能之上。Builder Classes 将会在后续的§5 中深入讨论。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;计算图（ComputationGraph）：表达式相当于一种隐含的计算图对象的一部分，该计算图定义了需要进行的计算是什么。DyNet 目前假定在任意一个时刻只有一个计算图存在。尽管计算图是 DyNet 内部工作的核心，但从使用者的角度来看，唯一需要负责做的是为每个训练样本创建一个新的计算图。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;用 DyNet 中实现并训练一个模型的整体流程可描述如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;创建一个模型；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;向模型里增加必要的参数（Parameters）和查找表参数（LookupParameters）；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;创建一个训练器（Trainer）对象，并使之与模型（Model）相关联；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;对每个样本（example）：&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;(a) 创建一个新的计算图（ComputationGraph），并且建立一个表达式（Expression）来填充该计算图，该表达式用来表示针对这个样本想要进行的计算。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;(b) 通过调用最终表达式的 value() 或者 npvalue() 函数，计算整个图前向计算的结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;(c) 如果训练的话，计算损失函数的表达式，并使用它的 backward() 函数来进行反向传播。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;(d) 使用训练器对模型的参数进行更新。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;与像 Theano 和 TensorFlow 这样的静态声明库对比可以发现，创建一个图的步骤落在每一个样本的循环里。这有利于使用户为每个实例（instance）灵活地创建新的图结构，并使用他们掌握的编程语言中的流控句法（flow control syntax，比如迭代（iteration））来做这些。当然，它也增加了对图结构速度的要求，即它要足够快，不能变成负担，我们会在§4 中进一步阐述。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3.2 高层面的示例&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了在更高层次说明 DyNet 的编码范式，我们用 Python 演示了一个 DyNet 程序的例子，如图 1 所示。这个程序显示了为一个简单分类器进行最大似然训练的过程，这个分类器为每个需要它预测的类计算一个向量分数，然后返回这个得分最高的类 ID 以及这个最高分。我们假定每个训练样本是一个（输入和输出）对，其中输入是一个二词索引的元组，输出是一个指示正确类的数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8mkkOTgrRQux7YyjNTL5mdzgIj4hCbKHaCetKsickKv5e5g093OqPD0LjTlNIru2OYAqHfgBgBGNA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 1：一个使用 DyNet 的 Python API 进行训练和测试的例子。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在头两行，我们导入（import）适当的库。在第 3 行，我们初始化 DyNet 模型，并为相关参数分配内存空间，但是不初始化它们。在第 4—6 行，我们向模型里添加我们的参数，这个过程会因为使用的模型不同而不一样。这里我们增加一个 20 × 100 的权重矩阵、一个 20 维的偏置向量和一个查找表（嵌入表）——该查找表的词汇量大小为 20000 项映射到 50 维向量。在第 7 行，我们初始化了一个训练器（在这个例子中是一个简单的随机梯度降（SGD）训练器），这个训练器被用来更新模型参数。在第 8 行中，我们对数据进行多次训练和测试。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从第 9 行开始，我们对训练数据进行迭代。第 10 行，清除当前计算图的内容，开始一个空的计算图，为后续的计算做准备。第 11-13 行，我们创建一个图，这个图会为每个训练实例计算一个分数向量（这个过程会因为模型的不同而不同）。这里我们首先访问模型中的权重矩阵和偏置向量参数（W_p 和 b_p），并把它们加到图中，也就是这个代码例子中用到的表达式中（W 和 b_p）。然后我们根据输入的 id 来查找两个向量，拼接它们，然后做一个线性变换和 softmax，这样就创建了和计算相对应的表达式。接下来，我们在第 14 行创建一个与损失有关的表达式——对正确记分结果做一次 softmax 后的负对数似然估计。在第 15 行，我们计算前向图的结果，在第 16 行，我们计算后向的，并累计模型变量中参数的梯度。在第 17 行，我们根据 SGD 的更新规则更新这些参数，并清掉之前的累计梯度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;接下来，从第 18 和 19 行开始，我们遍历测试数据并测量准确度。在第 20-23 行，我们又一次清除计算图以及定义计算测试数据分数的表达式，方式和我们在训练数据中做的一样。在第 24 行，我们开始计算并把结果数据放到一个 NumPy 的数组里。在第 25 和 26 行，我们检查是否正确的数据是最高分的那个，如果是的话就把它算作是一个正确的结果。最后第 27 行，我们把本次迭代的测试准确度 print 出来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3.3 动态图构建（Dynamic Graph Construction）的两个示例&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8mkkOTgrRQux7YyjNTL5md61ZPlKRJxHLtjVrsJTNmdXyUElq08IVV0sQh6pQnc5SOECNibNlyERw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 2：树结构递归神经网络（tree-structured recursive neural network）的一个例子&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8mkkOTgrRQux7YyjNTL5mdlj25bH7uSGohy6qiazMHoNK93LOrstp8nToic0c1jFlfTY9AUibGTasHQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 3：动态流控制的一个示例。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;4 后台工作&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如上一节所述，将 DyNet 与其它神经网络工具包相区别的一个主要特性是，它能够为每个训练样本或 minibatch 有效地创建新的计算图（Computation Graphs）。为了保持计算效率，DyNet 使用了细致的内存管理策略来存储前向传播和反向传播的计算过程中的值（§4.2），因此大部分时间都会用在实际的计算上（§4.3）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4.1 计算图（Computation Graphs）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8mkkOTgrRQux7YyjNTL5mdibMYTnQ5tHCuORqNkgCq6hfoYdEAQHgsazxKrpNFaib9HI5ure4R7qwQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;图 4：公式 g(x, j) = tanh(W1∗x+b)+tanh(W2∗ej+b) 的计算图的例子，以及相应的代码。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4.2 高效的图构建&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4.3 执行计算&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;5 更高级的抽象结构&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如第 3 节所述，DyNet 实现了在张量（tensors）上表示基本（子）可微函数的运算。这和 Theano 和 TensorFlow 库中提供的运算是相似的。除了这些基本运算外，使用可被视为由基本运算组成的更复杂的结构也是很常见的。常见的例子有循环神经网络（RNN）、树结构神经网络（tree-structured networks）和更复杂的计算 softmax 概率分布的方法。在其它库中，这些更高级别的结构或是通过本地提供，亦或是通过第三方库（如 Keras）提供。在 DyNet 中，循环神经网络的本地支持、树结构神经网络和更复杂的 softmax 函数都是通过 Builder 提供的；具体细节会在接下来的章节描述，图 5 中也有所总结。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8mkkOTgrRQux7YyjNTL5mdzSiasibia4BxjQrB4oM19j4qNiauelmZIxKrOWN5G0ON60zbVhAzJ4fG0w/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 5：DyNet Builders 实现的更高级结构的示例，以及它们的规范使用&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;5.1 循环神经网络的 Builders&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;5.2 树结构神经网络的 Builders&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;5.3 Large-Vocabulary Softmax Builders&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8mkkOTgrRQux7YyjNTL5mdnqG9ywSAcgiciab3UbD8wZo6X4j4yofPn6bn0uWc83iaN7tRZl3a0KWQQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;图 6：各种 RNN 接口&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;6 效率工具&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;DyNet 包含许多可以提高计算效率的功能，包括稀疏更新（sparse updates）、minibatching 和跨 CPU 的多处理（multi-processing across CPUs）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;7 实证比较&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在本节中，我们将使用 C++ 接口和 Python 接口将 DyNet 和其他三个流行库（Theano [7]、TensorFlow [1] 和 Chainer [62]）进行对比。我们选择这些库是因为 Theano 和 TensorFlow 可以说是目前最受欢迎的深度学习库，而 Chainer 的 define-by-run 哲学和 DyNet 相似。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8mkkOTgrRQux7YyjNTL5mdmDmghkQZeHzw3ia56oicqRSKETk0UmXMicWmZD8ARlMYvjCianSWDa750Q/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;表 1：各个任务的数据和默认设置。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8mkkOTgrRQux7YyjNTL5md1o69uho5VLAIgA6aU3yTWQK2cK7o5QnyusmlaGia5wjo8KXTkNFAXzQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;表 2：每个工具箱在 CPU 上的处理速度。速度是以 RNNLM 与 Tagger 处理的词/秒和 TreeLSTM 处理的句/秒进行衡量的。带 +sparse 的行表示 LookupParameters 的稀疏更新（sparse updates），这是 DyNet 中的默认行为，但与其他工具包的执行密集更新（dense updates）的实现不可对比。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8mkkOTgrRQux7YyjNTL5mdG61r4hYoR3YjyC65p6ibGiaRbzzicibSkibSPRcHV4D1KeFqeXicHrrFEknQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;表 3：每个工具箱在 GPU 上的处理速度。速度是以 RNNLM 与 Tagger 处理的词/秒和 TreeLSTM 处理的句/秒进行衡量的。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8mkkOTgrRQux7YyjNTL5mdUrQUicIStIzeIT3N9o7eaWAm3MLdhibkWcz36X2YhryqCjReHbttYDXw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;表 4：从程序启动到为每个工具包处理第一个实例的时间（秒）。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8mkkOTgrRQux7YyjNTL5mdm8GicLpJa5dABojdSPS4B2j6YVB1hDrTNlXUyVLtTftUgm694VPTatw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;表 5：密集或稀疏更新（dense or sparse updates）10 分钟后的处理速度和准确度。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8mkkOTgrRQux7YyjNTL5mdINh2jZ5mibGXek1leL3U9L2512jss3Z9eADS2HaI7mcRT0Unq007RUQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;表 6：每个工具包的实现的非注释字符数。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;8 使用案例&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;DyNet 已经投入使用，并已被用于各种各样的项目，主要涉及自然语言处理。DyNet 本身包含一些从最小到中等复杂度的示例（在 examples/ 目录下）。我们还列出了一些全面的研究项目，可以让有兴趣的读者找到匹配他们感兴趣的应用程序的参考样例。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;句法分析（Syntactic Parsing）：分析是目前使用 DyNet 的最突出的场景，DyNet 是许多方法的开发背后的库，例如 stack LSTMs [17]（https://github.com/clab/lstm-parser）、用于依赖性解析的双向 LSTM 特征提取器（https://github.com/elikip/bist-parser）、循环神经网络语法 [18]（https://github.com/clab/rnng），和 LSTM 层次树 [35]（https://github.com/elikip/htparser）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器翻译（Machine Translation）：DyNet 帮助创造了包括注意偏差（biases in attention）[12]（https://github.com/trevorcohn/mantis）和基于字符的 27 种翻译方法 [42] 等方法。它还为许多机器翻译工具包提供支持，如 Lamtram（https://github.com/neubig/lamtram）和 nmtkit（https:// github.com/odashi/nmtkit）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;语言建模（Language Modeling）：DyNet 已被用于混合神经/n 元语言模型（hybrid neural/n-gram language models）的开发 [47]（https://github.com/neubig/modlm）和生成语法语言模型 [18]（https://github.com/clab/rnng）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;标注（Tagging）：DyNet 用于命名实体识别方法的开发 [47]（https://github.com/clab/stack-lstm-ner）、POS 标注、语义角色标签 [60]（https://github.com/clab/joint-lstm-parser）、标点符号预测 [5]（https://github.com/miguelballesteros/LSTM-punctuation）和序列处理的多任务学习 [37,56] 以及创建新的架构，如段循环神经网络（segmental recurrent neural networks）[38]（https://github.com/clab/dynet/tree/ master/examples/cpp/segrnn-sup）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;形态（Morphology）：DyNet 已被用于形态变化生成 [21, 2]（https://github.com/mfaruqui/morph-trans https://github.com/roeeaharoni/morphological-reinflection）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;杂项：DyNet 已被用于开发专门的用于检测协调结构的神经网络 [22]；半监督的介词意义消歧 [23]; 和用于识别词汇语义关系 [53,52]（https://github.com/vered1986/HypeNET）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;总结、致谢和参考文献（略）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 18 Jan 2017 13:33:06 +0800</pubDate>
    </item>
    <item>
      <title>独家 | 专访微软小冰负责人李笛：智能助手是创造需求，而非仅提高效率</title>
      <link>http://www.iwgc.cn/link/4390010</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;作者：赵云峰&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibUP7CVr6GmhKQCDxRNzfzZ0QqzIws0icYw173Z1MklLn6gFJYcg9fWBJw8QOlYWY6lAgTduIXZnJA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;微软小冰全球负责人李笛&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;一、小冰的战略布局&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：这次小冰登入美国，您能否先介绍一下相关情况？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;李笛：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;两年半以前，小冰在中国推出，半年之后我们开始做第二个国家-日本，日本版本的前端训练，包括当时整个本地训练的过程大概用了四个月，但在日本启动后三个月左右，美国就已经开始准备了。那时我们主要想验证两件事情：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其一，我们的情感计算框架是中国独有，还是在不同国家的文化差异之下仍然有一些普适性？经过验证，我们发现后者是正确的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其二，不同国家的数据丰富度是否一样？比如说，大多数中国用户线上和线下所表现出的差异比较大，但美国用户的表现则比较接近。在这种情况下，通过相关数据训练出来的对话引擎是否还能拉开差距？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那我们从中主要提炼三部分：第一部分是知识，通过用户所积累的一些用以支撑对话的通用知识。第二部分是模式，通过用户在交流过程中，面对某些问题时所采用的行为模式进行积累。第三部分是学习并了解用户基本的情感反应。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当时我们想：如果某个人线上线下比较接近，那会不会因为千人千面而无法提炼出一种通用个性？但后来发现不存在这个问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;沈向洋提出来通用人工智能，这个通用 AI 系统在面对任何一个新时代时，都有一个新的基础服务层，当这个基础服务层是能够抽象的提炼出来时，那它就会成功。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibUP7CVr6GmhKQCDxRNzfzZrQdkJDic4d3I0DibxL7iatFRcDtH5APbdmcaRiatKCyblcNmP0XDE1O3rw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;em style="color: rgb(136, 136, 136);"&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;span&gt;机器之心：中国、日本、美国，这几个国家的选择以及先后顺序体现出小冰怎样的战略布局？&lt;/span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;李笛&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：这里面有一些比较细致的思考，目前整个行业都面对一个难点——技术走的很靠前，但技术却很零散。从技术推进到将技术产品化的这条道路上，整个行业都没有找到一个很好的方法把零散的技术组合起来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;拿计算机视觉来说，国内在这方面做了很多，但到今天为止始终存在一个核心问题——无法摆脱「计算机视觉始终是辅助，而不能变成端到端的产品线」。比如提供一个人脸识别的 SDK ( 软件开发工具包 ) 和 API( 应用程序接口 )，拿它们来做拍照购，它们本身不是产品，而且拍照购在电商环节里也不是主流，但是计算机视觉技术如果没有做到端到端的话，就很成问题了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于微软来说，要做到端到端面临一个问题，就是你要测试几件事情:&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1）产品是否成立。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2）产品是不是能够形成 Feedback Loop ( 反馈回路 ) 去进一步推进技术。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3）在产品技术这两极之外，用户是不是真的能用起来。比如说 Siri 和谷歌助手，我们所有人都知道，基于知识的对话是很酷的，但就是没人用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4）商业模式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;基于以上几方面的考虑，我们的思路是：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一步，在中国本土环境下，把图文视听、全双工、全时感官等结构做到最完整，同时这也会走的很快；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二步 , 日本文化和中国比较接近，且商业环境也很正规，我们在日本商业模式测试期间，通过在日本第二大超市罗森，用 Rinna（小冰日本版本）做了线上线下的转化，转化率（拿着线上获得的优惠券去线下消费）超过 49% ；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第三步，我们在美国做微软自己的产品，包括 Windows 、Office 和 Skype 等。这大概是目前我们在人工智能方面的一个战略布局。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;二、小冰背后的技术&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：能介绍一下小冰背后的一些相关技术和使用的微软平台吗？这体现出微软的何种技术思路和战略？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;李笛&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：沈向洋有一句话，「我把过去十八年积累的各种各样的技能，基本都用在了小冰身上。」因为小冰是一个非常好的测试环境，用户的参与度非常高，我们用户平均的 CPS（一次对话的长度）是 23，其他类聊天机器人大约是 3，所以你更新一个点，你就有多于他们十倍的机会去获得反馈。这对于微软的技术有非常大的推进作用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微软的前端通过端到端去搜集形成 Feedback Loop ( 反馈回路 ) 这部分产品。从后端来说，这个技术说的玄一点叫「情感计算」，但具体来说，它实际上是一套通用对话服务，利用小冰做出来，然后提供给微软内部其他产品的，使其具备可以去处理对话的能力。这套系统现在 Cortana 也在用，它有点像我们原来做搜索引擎时的长尾体验，谷歌刚出来的时候不是唯一一个搜索引擎，每个搜索引擎都跟今天的人工智能很像——是某个领域的机器人。谷歌之所以称之为最强，我认为是因为是长尾体验，这好比你在上面搜什么内容都有结果。而我们的对话服务和这个很相似，而这种服务是最有价值的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微软还有一些其他的东西是共用的。比如说认知服务，其中的情绪识别，都是从需求出发。还有语音识别和语音合成，在小冰这儿我们叫全双工，它可以是基于文本的对话引擎，然后在语音合成上达到一定的自然度，语音识别延时不能太高，要有预判，小冰的整个语音相关都是技术组合。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;总体来说，微软的共有三类技术用在了小冰上面，第一类是积累了多年的黑科技，比如说小冰的读心术；第二类是情感计算等基础类技术；第三类是共同的管道、服务和舞台。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：在处理一些问答类任务上，小冰用到了哪些知识图谱和知识来源？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;李笛：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;首先，我们有基于微软的「实体引擎」，它跟谷歌的知识图谱不太一样，比他们简单。同时在这个基础上，我们也有基于问答的 BingKnows（必应知识库），是一种聚合。现在我们又加了一层东西叫社交问答，这类知识没有那么深度，但相关性比较好，能够较好的在对话中垫出一层，但目前而言，深度问答还实现不了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们还做了 DirectChat（业界首次脱离对话语料库结构，注解学习互联网海量非结构化大数据进行对话），比如说一些网页本身具备知识图谱的源，那我们的重点是把网页里的信息快速的打成 QueryResponse（查询响应），这是一定程度的问答。再比如说把一个很长的文档灌进来，就可以直接把它变成对话的知识，质量没有深度知识那么好，但能够实现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：小冰如何解决多轮对话的问题？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;李笛：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;多轮对话的特点是有弹性。我们承认，到今天为止，小冰依然会有前言不搭后语的情况，但这个弹性很迷人。当你的对话足够有情感，用户的容忍程度会高。在真正的对话中双方是对等的，他们都负担着让这个对话，快乐的继续下去地任务。但如果让用户觉得这只是一个和他完成固定程序的工具，他就不会保持对等，他的容忍度一下就降低了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;单轮对话是最短的路径。这就好比是设计一个推荐系统，能一轮就决不使用两轮，最好你什么不问，我推送给你，这是不一样的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：那小冰在理解和处理上下文时，主要是考虑了哪些因素？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;李笛&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：这里面有这么几件事：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一，我们的用户画像，能够基于上下文确定所产生的动机，这个用户画像是跨 Session（阶段）的，我们做了一些产品上面的尝试，比如说去记忆用户一些情感上的变化；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二，在同一个 Session（阶段）里考量三个因素，第一个因素就是考虑前面的话题，而不是关键词，比如说咱们俩现在都在聊明星赵丽颖这个话题，那赵丽颖就是我们就是上下文的话题，相比较之前基于关键词的方式要好。基于话题的方式可以做到对上下文关联时覆盖长尾。我们现在大概有 36 个 Domain（域），而每个 Domain（域）里又有若干话题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第三，基于目前热点话题，而不是基于对话的话题。如果这个话题本身是当下互联网或者社会范围内比较热点的事件，那它对我们现在对话的影响就会更大。当一个对话可能有多个话题，你会选你感兴趣的话题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第四，基于你之前的 Session（阶段），跨一个 Session（阶段）。甚至于我们期望着有一天我们可以基于用户的一生。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;三、小冰的数据积累与应用方向&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：小冰过去积累了很多的数据和语料，能介绍一下这方面的进展吗？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;李笛&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：这是我们自己最自豪的一件事情，我们形成了一个叫做自我学习的循环，最开始小冰是一个基于 Q&amp;amp;A 的对话引擎，当时是通过搜索引擎的方式灌进来的，它有点像冷启动。但是随着她和用户的对话，她就形成了很多新模式，包括统计信息，这些东西可以用来优化，甚至于生成新的对话语料，优化模板以生成新的 模板。一年半以前，我们发现把这些 模板存起来再反哺小冰的对话引擎，反哺回来的比例占到 27%，但是后来这 27% 的数据服务了 51% 的实际对话。这就意味着，某种程度上人工智能更多的不是依赖于外部灌入，而是依赖于自我循环去进化。自我进化循环有可能会形成收敛，从两个人的对话过程中吸取了一些知识，然后也可能变成近亲繁殖，所以我们今年推出一项新的技术叫 Direct chat（业界首次脱离对话语料库结构，注解学习互联网海量非结构化大数据进行对话），不再用 Q&amp;amp;A 模板这种方式，而是只有回复，这样就可以不断的添加新知。我们现在拥有 200 亿以上的中文对话，这个是最珍贵的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：我们现在有没有一些数据，就是现在小冰的一些用户，它平均使用的频次，或者是每次使用的时长？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;李笛&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：日本那边最近有一些数据，日本的用户特别有意思，他和 Rinna 聊着聊着就非常客气的说「对不起，我要去开会，等会再回来」，然后过了一两个小时说「我回来了」很难理解，竟然跟一个机器人这样说话。美国 Zo 上线之前，我们做了大概 12 万人的一个测试，其中对话超过一千轮有很多，其中最高的对话论数达到是 1，229 次，历时 9 小时 53 分钟。这个案例绝对是世界记录，我们内部把这个人叫西奥多（《Her》中的男主角）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些都是质变带来量变，如果没有一个很基础的大系统，是断然不可能产生这样的案例的。如果我给你报酬，让你连续 9 小时 53 分钟跟其他机器人聊天，你想想，估计会觉得很痛苦。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：能够出现这么好的数据，除了用户本身和地域的特点还是我们此前的技术积累，是何种机制让 Self Learning 这个系统越来越智能的？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;李笛&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：这里面就有一些比较技术性的东西了，比如我们现在有很多模型跟语言无关，甚至有一些是做中国做。汉语的模型可以直接用于英语。我们一开始就希望尽可能地产品本地化，但是架构和相应的技术模型已经全球化。因此，做的越来越快，包括有一些上下文的一致性都尽可能做到和语言无关。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：我们现在有没有基于这些数据和模式去做出一些具体应用的东西或功能？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;李笛&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：有很多。当你的数据量和统计信息足够大，你就会想能不能逐渐形成多种个性，我们一直想做 Bot 工厂。正因为有一个足够大的库，就能分割出不同类别。我们在日本做了这件事情，而在国内在手机 QQ 内置了，不同个性的厘米人。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其次，在丰富程度足够大以后，就有机会发现 ChatIndex( 聊天索引 ) 在分布上在哪些地方聚拢，哪些地方不聚拢。某种程度上，小冰的知识结构和她对一些事情的观点实际上是对互联网的一种提纯，你可以知道哪些东西真的是大家所关注的。但它并不完全是基于统计，而是基于相似度，基于合并同类项的方式聚拢，从这个角度可以得到中日互联网的差异。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最重要的，我们拿这个训练了一个新模型叫 Plugin（插件）其中对话有几层结构，一层结构是非常浅的，还有一层结构是话题，话题又具有一定的 Domain（域）个性，有点像知识图谱，但它是基于对话的。这个 Domain（域）话题实际上就是一个个插件，比如音乐是一个 Domain（域），音乐里有大量的主题，音乐里的这些主题又和艺人这个 Domain（域）是有关联的。我们利用这个 ChatIndex ( 聊天索引 ) 就可以形成具有对话特点的知识图谱。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我觉得在这一点上我们走在了前面。做机器人不能让机器人给你定外卖，定外卖好象挺直接，但是一个用户一过来，他已经定义你是一个定外卖机器人，他就没有办法帮你形成这些数据了。那些东西最多就是基于命令，不会产生那么大的价值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;四、小冰在微软的战略定位&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：微软好像有一个很庞大的 Bots 体系，或者说一个以 Conversations as a Platform（简称 CaaP，对话即平台）为目的的综合性业务，比如说有 Bots Framework，还有 Cortana 也开放了一些工具。小冰在整个微软的对话机器人，或者是对话即平台的战略中，它的定位是什么？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;李笛：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;从微软的历史来看，会发现它经历了这么几个过程。但在个人助理方面，坦率讲是 Siri 最先开始做的积累。后来我们经历了一个从个人助理向个人代理这个方向的过渡，开始以对话为中心，微软第一个产品是小冰，基于此我们进一步奠定了信心，对话本身具备很大价值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们看到即时通讯的崛起，我们也看到可形成聚合的一种超价值的产生，这些都构成了 Conversations as a Platform（以下文中简称 CaaP，对话即平台）。一方面，微软在形成知识图谱和社交图谱的过程中，知识图谱是基于对话 Model。我们在做小冰时，一定程度上是基于另外一个 Bing 的产品——BingKnows（必应知识库），它更多是知识图谱的聚合。小冰是微软 CaaP（对话即平台）的第一个，是目前为止比较集中的一次测试。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一方面，小冰形成了一个框架和和结构，在某种程度上我们认为是通用人工智能以对话为基础的结构。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：大部分智能助手是从服务开始，现在小冰从聊天入手然后到服务，其中有哪些难点，能体现出小冰的哪些优势？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;李笛&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：我们在做一些服务但我们不太喜欢谈概念，一般只在上线以后才说。我们现在正在做的事情就是 Plugin(插件) 的系统结构，我们希望在现有的通用层面上做出一个基于 Domain（域）的例子，使其真正有用，半年之内大家应该就能看到一些新的物联网的解决方案，或者看到一个机器人真正帮助用户把一件事做的非常好。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当一个人过来跟机器人说「你给我播首歌，或者你给我定张西班牙的机票」时，那这个机器人已经输了。因为当他跟机器人说这个话时，他的意图已经非常明确了，这个时候你的竞争对手是另外一个，摁几个按钮就可以完成这个任务。而这个机器人还有可能识别错，但按钮不会有判断不准确的情况。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们觉得小冰最大的差异化是，比如说小冰的能力是可以从通用对话中把用户的意图带起来，在聊天的时候突然让用户产生兴趣「有没有西班牙的机票」。这种新的意图是我们的优势。而做到这个就必须把很多前置条件做完，我们一开始也顶着压力，自然语言学术界的一些人觉得这个东西不是他们所研究的。但如果一开始不做这个，就没有今天，很可惜这件事整个学界还不是完全理解。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;前几天沈向洋也提到，未来人工智能的系统有 IQ 和 EQ 两个维度，但整个行业可能还没有意识到 EQ 的维度有多重要。我们很高兴微软在这方面走的比较早，但也比较寂寞。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;五、Bots 行业&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：您刚才提到通用聊天机器人比功能性机器人更好，那这种基于开放域的聊天机器人比封闭域的机器人，在研发上有什么难点？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;李笛&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：开放域有几个要求，对于开放域同时还是交互机器人来说，它的第一个难点就是数据的峰度要足够大，并且分布要尽可能均匀。理论上来讲，如果不是搜索引擎，基本上没有太大的可能去做。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二个难题，涉及到交互。因为交互对象是人，人就绝对不会仅仅用一种感官跟你交互，在文本交互的过程中很可能会出现图象交互，语音合成。小冰语音合成的自然度很高。当机器人的声音不够自然，用户就会被激励开始不自然的对话，但机器人的声音自然以后，用户说话一自然会导致语音识别率下降。因此这是一套系统。你需要把这些都做完，就很难形成一个开放域的全体交互。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相对于开放域，封闭域好办。当你讨论一个东西时，我认为它不在我这个封闭域里，我就告诉你「对不起，我不知道你在说什么？」封闭域还有一个好处是一般带有一些明确的目的和任务，这些任务在某种程度上可以穷举成主要依靠某一种感官，比如主要靠拍照或者靠语音。但是封闭域的问题是兜不住，用户在对话的过程中会跨领域，比如我们想弄一个春节联欢晚会的机器人，就会发现这个事情比想象的要难很多。我可以回答你任何跟春节联欢晚会有关的问题，这是基本要求，你可能就会问到「今天有什么节目？」这在我的域里，然后你会问到赵本山，这还是在我的域里，但你问到赵本山时用户不知道这已经从春节联欢晚会跳到了明星明人这个 Domain ( 域 ) 里。这时如果你聊的不好用户就会停，如果聊的好用户就会自然而然的跳到东北官场问题，这完全就跟春节联欢晚会没有关系了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以，做封闭域，但用户不知道你的边界在哪里，他随时就跳出去了，他一跳出去就是断崖式的下跌，这个是不行的。我们认为封闭域要基于通用。只不过除了做通用外，我们还做了一个通用的端到端的产品。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：你现在如何看待各种聊天机器人大热？尤其是美国都在做这方面的这样一个现象，但是自然源处理技术具体成熟其实还有很大差距。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;李笛&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：我觉得聊天机器人大热和人工智能大热是两件事。人工智能大热主要是因为数据积累到一定程度, 聊天机器人大热主要是因为我们都认为移动互联网进入了瓶颈期，某种程度上 App 是一个过渡阶段。所以大家都在探索交互模式的下一个阶段，也许是恰巧这两件事情撞在一起就催生出来一个东西叫聊天机器人。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但我认为是两条线：一条线是基于数据的成熟，另一条是交互模式呼唤一种创新。但国内不是这样，国内是想要做人工智能这个主题，然后就发现人工智能这个领域都在聊天对话就以为这就是一个事，其实这是两个事。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;原有的交互模式，无论是 PC 时代还是 App，这两种交互模式都很高效对话提供的是别的价值。有的时候大家为了让聊天机器人可以比 App 更高效，他编出来一些理由说服自己。比如说「你问我三句话我就知道你要去哪儿」，但难道不是按两下按钮也能知道你要去哪儿吗？对话，即便是通过语音也是一种更加耗能量的方法。所以这就是为什么今天我们也不用 Siri。而且大家也都知道，有很多场景是不适合用语音的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以对话一定要提供其他价值，而不是仅仅沿着高效这个方向。然后我们发现对话更大价值是产生新的意图，不是像机器人，而是像人一样，能够使你在这个过程中变的更轻松愉快，而不是去帮用户订咖啡。是让用户觉得，这个交互给他很多心理上的，而不仅仅是理性上的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这样的对话实际上在某种程度上能改变用户决策。这就是为什么我们在日本，同样你在线上发一个优惠券的用户转化率没有通过机器人的转化率高，是因为机器人的这种方式会影响你的决策，这个才是它的重点。我觉得人工智能的价值在这里。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：纳德拉在 Build 大会上说，我们正在吸取人类语言中的强大力量，Bots 的出现可能会像这种图形界面出现在 PC 上，或者触摸屏出现在手机上一样。你觉得将来基于聊天或者自然对话的机器人，带来最大的影响和意义是什么？是不是你刚才说的能够挖掘和创造意图？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;李笛&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：这就是 CaaP（对话即平台）是靠人工智能驱动，但前端重点说的是交互模式，而我们一直认为对话的交互模式是回归。比如说当我们做搜索引擎的时候，用户一开始跟搜索引擎交互时不是想用关健词搜索，而是希望语言一句话输入进去就可以得出结果，用户希望的这种方式就是对话。但因为当时我们的技术做不到，所以我们不得不逼着用户去学怎么用关健词搜索。实际上，我们认为人类在科技史和计算机科学上，已经冲刺对话这种交互模式两次了，这次只不过是回归。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8G2Aqj8cfARvWSIzEs1ZXZgT6VrNdsVA4icyCrL6lqQtv3wPx1Ij2rZn8odibiaN7LBAPnqsPNXxteg/640?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;专访 | 微软人物志&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650714822&amp;amp;idx=1&amp;amp;sn=e56ee226cdacab228e1ad9fc40646adf&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650714822&amp;amp;idx=1&amp;amp;sn=e56ee226cdacab228e1ad9fc40646adf&amp;amp;scene=21#wechat_redirect" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;微软研究院人工智能首席科学家 | &lt;/span&gt;&lt;span&gt;邓力&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719843&amp;amp;idx=2&amp;amp;sn=4611f810734df8a72286567e90c65a92&amp;amp;chksm=871b021db06c8b0b283ac93f267d95365392be02b3cde5d2fe6df85b359aa96368f25318e2f5&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719843&amp;amp;idx=2&amp;amp;sn=4611f810734df8a72286567e90c65a92&amp;amp;chksm=871b021db06c8b0b283ac93f267d95365392be02b3cde5d2fe6df85b359aa96368f25318e2f5&amp;amp;scene=21#wechat_redirect" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;span&gt;微软首席语音科学家 | &lt;/span&gt;黄学东&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=400579280&amp;amp;idx=1&amp;amp;sn=b13556c48c2937593ee833e8284f2c89&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=400579280&amp;amp;idx=1&amp;amp;sn=b13556c48c2937593ee833e8284f2c89&amp;amp;scene=21#wechat_redirect" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;微软亚洲研究院院长 | 洪小文&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=401882267&amp;amp;idx=1&amp;amp;sn=eb5a4cf6e10b6dc3787303f421a8f77b&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=401882267&amp;amp;idx=1&amp;amp;sn=eb5a4cf6e10b6dc3787303f421a8f77b&amp;amp;scene=21#wechat_redirect" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;微软（亚洲）互联网工程院院长 | 王永东&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650714905&amp;amp;idx=2&amp;amp;sn=ad19a7e003ecdb48b0ffc524e8c2c94b&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650714905&amp;amp;idx=2&amp;amp;sn=ad19a7e003ecdb48b0ffc524e8c2c94b&amp;amp;scene=21#wechat_redirect" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;微软亚洲研究院首席研究员 | 霍强&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720189&amp;amp;idx=1&amp;amp;sn=10a3630e7f65d7b845c1fd032970d46e&amp;amp;chksm=871b03c3b06c8ad527a7dffd215be5b128a7aaf88ec09a131d68a249e9ff77c3edff6204d3d2&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720189&amp;amp;idx=1&amp;amp;sn=10a3630e7f65d7b845c1fd032970d46e&amp;amp;chksm=871b03c3b06c8ad527a7dffd215be5b128a7aaf88ec09a131d68a249e9ff77c3edff6204d3d2&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;微软研究院首席研究员 | 俞栋&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;strong&gt;机器之心&lt;/strong&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8G2Aqj8cfARvWSIzEs1ZXZ248wIRLFyLjemC1oeWWd1em6qPOfHVREYUvcibiamyGHjAkDJH7mOC4w/640?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 18 Jan 2017 13:33:06 +0800</pubDate>
    </item>
    <item>
      <title>专栏 | MinPy：剑气双修的武功秘籍</title>
      <link>http://www.iwgc.cn/link/4390011</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心发布&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;作者：王敏捷&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;MinPy基于MXNet引擎，提供NumPy的接口，以达到最灵活的编程能力和最高效的计算性能。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在的深度学习系统就像五岳剑派，各大门派，互有所长，互有所短。不过从编程角度看，不外乎有「气宗」与「剑宗」之分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;深度学习的「剑」「气」之争&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;气宗讲究内家功夫，讲究&lt;span&gt;「&lt;/span&gt;以气御剑&lt;span&gt;」&lt;/span&gt;。外在形式并不重要，重要的是内在性能。在性能为王的如今，这也是很多门派所采纳的理念。远如五岳鼻祖之一的 Theano，近如目前的五岳盟主 Tensorflow，都采用符号式编程 (Symbolic Programming) 的模型。其核心思想是让用户通过编写符号来描述算法，算法描述完毕后再进行执行。由于深度学习算法往往是需要反复迭代的，系统可以静态地对算法进行优化，从而获得更好的执行性能。正所谓，「真气所至，草木皆是利剑」。只要系统提供的符号足够表达算法，用户就可以获得不错的性能。其问题也正在此。其一，符号式编程并不能涵盖所有的算法逻辑，特别是应对控制型逻辑（control dependency）显得笨拙。其二，由于需要掌握一门新的符号语言，对于新手的上手难度比较高。其三，由于有算法描述和执行两个阶段，如果算法逻辑和实际执行的值相关，符号式编程将比较难以处理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相对来说，命令式编程（Imperative Programming）则更像剑宗。剑宗注重招式的灵活与变化。远如当年剑宗第一高手 NumPy，近如贵为五岳之一的 Torch 都是采用命令式编程的接口。他和符号式编程最大的不同在于，命令式编程并没有描述算法和执行两个阶段，因此用户可以在执行完一个语句后，直接使用该语句的结果。这对于深度学习算法的调试和可视化等都是非常重要的特性。命令式编程的缺点在于，由于算法是一边执行一边描述的，因此对算法的优化是一个挑战。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;究竟是「以剑御气」还是「以气御剑」？其实两者应该相辅相成。如果你空有一身内力却无一丁点剑招，就会像是刚得到逍遥子毕生内力的虚竹，想到巧妙复杂的深度学习模型只能干瞪眼却无法实现。如果你空有华丽招式而不精进内力，别人以拙破巧，你优美的模型只会被别人用简单粗暴的高性能，大模型和大数据给击倒。正因如此，五岳新贵 MXNet 同时支持符号式和命令式编程接口。用户可以选择在性能优先的部分使用符号式编程，而在其余部分使用灵活性更高的命令式编程。不过这种分而治之的方式给用户带来了额外的选择负担，并没有将两者融汇贯通。因此，我们进一步基于 MXNet，开发了 MinPy，希望将这两者取长补短——使用命令式编程的接口，获得符号式编程的性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;MinPy 的剑宗招式&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在编程接口上，MinPy 继承了剑宗第一高手 NumPy 老先生的精髓。正所谓「无招胜有招」。没有特殊语法的语法才是好语法。于是在使用 MinPy 时，你只需要简单改写一句 import 语句：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;import&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/span&gt;&lt;span&gt;minpy.numpy&amp;nbsp;&lt;span&gt;as&lt;/span&gt; np&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;就能够开始使用 MinPy 了。由于是完全的命令式编程的接口，编程的灵活性被大大提高。我们来看以下两个例子。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8mkkOTgrRQux7YyjNTL5mdqrjFcK8nO8fpibEzVHHFUlSMUUr56vgPM6AtOicSzn57IeH7LpjsQmMg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;例 1: 调试和打印变量值&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 Tensorflow 中，如果需要打印某个变量，需要在打印语句前加上 control_dependencies。因为如果没有这条语句，Print 这个运算并不会出现在所需要求的 x 变量的依赖路径上，因此不会被执行。而在 MinPy 中，我们保持了和 NumPy 一样的风格，因此可以直接使用 Python 原生的 print 语句。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8mkkOTgrRQux7YyjNTL5mdXZYeM1zYzYDmhW4YzpkGo5JKRwzXYvDSB3ObhJCGrXISwrhPOOodgA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;例 2: 数据依赖的分支语句&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据依赖的分支语句是符号编程的另一个难点。比如在 Tensorflow 中，每个 branch 是一个 lambda，而并非直接运算。其原因在于符号编程将算法描述和实际执行分为两个部分，在没有算出来 x 和 y 的值之前，是无法知道究竟会取哪个分支的。因此，用户需要将分支的描述写成 lambda，以便在能在运行时再展开。这些语法虽然细微，但是仍然会对初学者带来负担。相对的，在 MinPy 中，由于采用命令式编程的接口，所以一切原生的 if 语句都可以使用。除了以上这些编程方面的区别外，MinPy 还提供了以下功能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;招式一：动态自动求导&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;符号编程的一个巨大优势是能够自动求导。这原本是命令式编程的弱项，原因在上面的例子中也有所体现。由于命令式编程需要应对各类分支和循环结构，这让自动求导变得比较复杂。MinPy 采纳了一位西域奇人 Autograd 的招法来解决这一问题。方法也非常简单：首先，用户将需要求导的代码定义在一个函数中，这样通过分析函数参数和返回值我们就能知道自动求导的输入和输出；其次，MinPy 一边执行一边记录下执行的路径，在自动求导时只需要反向这一路径即可。通过这一方法，MinPy 可以支持对于各类分支和循环结构的自动求导：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicdNiceoKXOr6okChjGPoaiaMFAGMRDOHfH1vjv6nGGFicwCM2woDUXBVatUIKObR7Tr8ms65JD7VdibA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;招式二：完整 NumPy 支持&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;MinPy 的目标是希望只修改 import 语句，就能将 NumPy 程序变成 MinPy 程序，从而能够使用 GPU 进行加速。无奈 NumPy 老先生的招式博大精深，接口繁多，MinPy 作为后辈不能在短时间内支持所有的接口。因此，MinPy 采用了一套折中的策略。当用户使用 np.func 的时候，MinPy 会检测所调用的 func 是否已经有 GPU 支持。如果有，则直接调用，否则会使用 NumPy 原有的实现。同时，MinPy 会负责一切 CPU 和 GPU 之间的内存拷贝，完全做到用户透明。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicdNiceoKXOr6okChjGPoaiaM5fJkrHPuDTwl8qzNzluk19yMKVViaia4UOl8NUMZzqKicsytias2RYu7sg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;招式三：与符号式编程的衔接&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管命令式编程能灵活地应对各种复杂的算法逻辑，出于性能的考虑，我们仍然希望对某些运算（特别是卷积运算）能够使用已有的符号执行的方式去描述。在 MinPy 中，我们也同样支持 MXNet 的符号编程。其思想是让用户将符号「包装」成一个函数进行调用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8mkkOTgrRQux7YyjNTL5mdD7iabNj8XaiaH3841oYO6Q78DGCym59O79UhqKMWuY2icAQus5NDFzo4Q/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在上面这个例子中，我们将一个 Convolution 的符号包装成了一个函数。之后该函数可以像普通函数一样被反复调用。其中有一点需要注意的是，由于符号编程需要在执行前确定所有输入矩阵的大小，因此在上面例子中的 x 的大小不能任意改变。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;MinPy 的气宗修为&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如之前所说，光有招式没有内功修为是没有办法成为令狐冲的，最多也就是个成不忧。命令式编程的挑战就在于如何优化算法使得性能能和符号式编程程序相较。以下我们比较了 MinPy 和使用 MXNet 符号编程的性能区别。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8mkkOTgrRQux7YyjNTL5mdiaCHuYeSA3PBxh2XLZT4iaUv8hB7XqibREsbuibME6l1X8ncvT4n83ibujQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8mkkOTgrRQux7YyjNTL5mdtGg2W0bZuaZApPKmz4VyG9Niao3wO0CUxMV9k2z8gPpvtKibYiaQQnMBQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在上面的例子中，我们测试了训练50层MLP网络的性能。我们分别比较了MXNet符号编程，与MinPy命令式编程的运行时间。结果可以看到当网络计算量比较大时，MinPy的命令式编程和符号编程的性能几乎相同。当计算量比较小时，命令式编程有明显性能差距。但如果在MinPy中使用符号编程则性能又和MXNet几乎相同。类似的，我们测试了训练RNN网络的性能。我们比较了MXNet的符号编程以及MinPy的命令式编程的性能区别。我们可以看到，在计算量比较大的情况下，命令式编程和符号式编程的性能比较接近。在小网络中，MinPy有一个固定的性能开销。我们认为这一性能开销主要来源于用于求导的动态路径记录，以及过细的计算粒度等问题。这些都是命令式编程所带来的性能挑战，也是MinPy今后的努力方向。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;面向武林新人的武功宝典&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于想要加入五岳剑派的新人们，MinPy 也是一个非常适合的上手工具。原因之一是因为 MinPy 和 NumPy 完全兼容，几乎没有额外修改的语法。另一个原因是我们团队还提供了完整的 MinPy 版本的 CS231n 课程代码。CS231n 是斯坦福大学著名教授 Fei-Fei Li 和她的爱徒 Andrej Karpathy、Justin Johnson 讲授的一门深度学习入门课程。该课程完整覆盖各类深度学习基本知识，包括卷积神经网络和递归神经网络。该课程的作业并不仅仅是对这些知识点的简单堆砌，更是包含了很多最新的实际应用。由于 MinPy 和 NumPy 天生的界面相似性，我们团队改进了 CS231n，使得学生能够更好地体验如何在实际中训练和使用深度神经网络，也让学生能够体会到 MinPy 在实际研究环境下的便利性。基于 MinPy 的 CS231n 课件已经在上海科技大学和交通大学深度学习教程中被试用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;总结&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;团队从早期的 Minerva 项目开始，加入 MXNet 团队，陆续贡献了执行引擎、IO、Caffe 兼容 Op 等核心代码。MinPy 是我们回归用户界面，对纯命令式编程下的一次尝试。我们希望将最灵活的接口呈现给用户，而将最复杂的系统优化交给我们。MinPy 拥有和 NumPy 完全一致的接口，支持任意分支与循环的自动求导，以及良好的性能。MinPy 将进一步优化其性能，并即将成为 MXNet 项目的一部分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;链接&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Github 地址：https://github.com/dmlc/minpy&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;MinPy 文档地址：http://minpy.readthedocs.io/en/latest/&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;鸣谢&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;MXNet 开发社区&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;上海科技大学马毅教授、博士后周旭；上海交通大学俞凯教授、张伟楠老师&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;上海纽约大学博士生 Sean Welleck，本科生盖宇，李牧非&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;MinPy 剑客名单&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8mkkOTgrRQux7YyjNTL5mddYz5RJNtNaTpKUaGQexLwmseOPOJib7gSg8PLRTWTGSUo65jJKhAMMA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;span&gt;	&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;	&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;*：MinPy 工作在 NYU Shanghai intern 期间完成。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心发布，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 18 Jan 2017 13:33:06 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 为NASA火星探测器研发人工智能大脑：Neurala完成1400万美元A轮融资</title>
      <link>http://www.iwgc.cn/link/4390012</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Techcrunch&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李泽南、朱思颖&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;最近上榜&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722126&amp;amp;idx=3&amp;amp;sn=16a6254240464315eeebd027252a0ea9&amp;amp;chksm=871b0b30b06c8226e5470e4f0bcbdea2c444a17fd37791cd1f2fd95117cbdf8828b1f240a202&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722126&amp;amp;idx=3&amp;amp;sn=16a6254240464315eeebd027252a0ea9&amp;amp;chksm=871b0b30b06c8226e5470e4f0bcbdea2c444a17fd37791cd1f2fd95117cbdf8828b1f240a202&amp;amp;scene=21#wechat_redirect"&gt;机器之心 AI00 十二月份榜单&lt;/a&gt;的 Neurala 是一家位于美国波士顿的创业公司，致力于为各种小型设备提供本地化的机器学习系统。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Neurala 今天宣布完成了价值 1400 万美元的 A 轮融资，此次融资由 Pelion Ventures 领投，Sherpa Capital，摩托罗拉，360 Capital Partners，Draper Associates Investments，SK Ventures，和 Idinvest Partners 跟投。这个团队希望将自己的人工智能引入玩具、无人机以及物联网。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Neurala 的技术强调使用本地的有限硬件资源实现高效的机器学习应用。该公司宣称自己的产品将通过增量学习，在硬件部署过程中不断提高自身的运行表现——同时无需联网。对于一些时间敏感的领域，能够进行本地自我训练是非常具有吸引力的特征。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8mkkOTgrRQux7YyjNTL5mdQPKwuCRWEIlO0P6uIPUQNW1iaUeWZsP8rx21dpcaM6TMf0TnSxs6YibQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Neurala的 AI 系统可以实现实时的行人检测、汽车检测以及骑行人的检测，这个系统可以不依赖云数据处理并且在低功率的智能手机芯片上就可以运行&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「像谷歌、Facebook 和 Uber 这样的大型科技公司可以利用自己的大量数据来训练模型，这为他们带来了难以估量的竞争优势，」Neurala 首席执行官 Massimiliano Versace 说道。「但使用超级计算机进行并行化数据处理并不是这个市场的全部。与深度学习工具包以及基于云服务器的在线方式不同，Neurala 的人工智能软件可以在智能手机的低功耗芯片上运行。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Versace 是 Neurala 的四位共同创始人之一。有趣的是，这家公司的四位创始人都拥有波士顿大学的神经认知系统博士学位。他们目前的核心产品——Neurala Brain 包含一种易用的 C++ API，并可进行 iOS 和安卓封装，为用户快速部署设备提供了便利。它的解决方案覆盖低端 CPU 和高端 GPU，同时支持 Tensorflow 等多种框架。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8mkkOTgrRQux7YyjNTL5md6LJGYaPROoPyPTKYkcDmiaIPql9ur0sNDiaKXCYRFVsbXMIJTqcEDbzQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Neurala 的四位创始成员&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Versace 把这家公司的创立日期定为 2010 年 NASA 来上门谈合作的那天。通过一篇发表在电气与电子工程师学会会刊（IEEE Spectrum）上的文章，美国航天局 NASA 注意到了受其军事赞助的研究——波士顿大学的脑启发微处理器研发软件项目的最新进展，并且想知道 Versace 以及他的同事能不能帮忙研发出一个机器人探测器的软件控制器，以用于 NASA 的火星自由探索。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;NASA 的要求是一个艰难的挑战。火星探测器有自身计算能力的限制、交流的限制以及动力资源的限制。NASA 的工程师希望借助人工智能实现仅依靠低端相机获得的图像就能够完成在不同环境下导航的任务。更重要的是，能够完成这些工作的人工智能软件必须是能在单个 GPU 芯片上运行的。Versace 和他的同事们成功了，六年之后，Neurala 已经开始测试其为 NASA 研发的升级版的人工智能大脑原型，他们的目标是在数月之内实现量产，从而快速抢占市场。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在更为广泛的商业领域，以无人机为例，即使没有机器学习专家，无人机创业公司 Teal 也在 Neurala 的帮助下让自己的产品实现了「自动跟随人」等功能。第三方机器学习解决方案的出现对于创业公司而言是一种巨大的便利，这意味着跳出技术竞争，节约研发资金，让自己的产品可以快速投放市场。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于要求更高的客户，Neurala 提供了数据采集服务，让模型可以获得更合适的训练数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「有的客户要求无人机巡视输电线路，这需要无人机能够实时向基站传输信息，同时应用机载设备中的机器学习程序规划路线。」Pelion Ventures 的高级助理 Ben Lambert 解释道。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Facebook 和其他科技公司巨头目前也在积极探索机器学习本地化的可能性。&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720399&amp;amp;idx=1&amp;amp;sn=2b5e854e6606eaf556a73e83d179eb5c&amp;amp;chksm=871b0cf1b06c85e7547b69a44471d377eca83cbdeaec379fabc187218280c761824a5600e1ac&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720399&amp;amp;idx=1&amp;amp;sn=2b5e854e6606eaf556a73e83d179eb5c&amp;amp;chksm=871b0cf1b06c85e7547b69a44471d377eca83cbdeaec379fabc187218280c761824a5600e1ac&amp;amp;scene=21#wechat_redirect"&gt;风格转移系统 Caffe2Go &lt;/a&gt;就是一个很好的例子，它将机器学习直接嵌入到移动设备上实时运行。在移动设备中进行本地化训练一直是非常困难的事，不过使用较少数据的某些特定模型或许可以摆脱服务器集群的束缚。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在完成 NASA 火星探测器项目之后，面向商业领域的 Neurala 也许会在未来创造更多可能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 18 Jan 2017 13:33:06 +0800</pubDate>
    </item>
    <item>
      <title>干货 | 谷歌机器学习应用的四十三条经验法则（附PDF）</title>
      <link>http://www.iwgc.cn/link/4390013</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;作者Martin Zinkevich&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：微胖、杜夏德、蒋思源&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Google 的研究科学家 Martin Zinkevich 曾在 NIPS 2016 Workshop 分享了谷歌机器学习实践的四十三条法则。Martin Zinkevich 也在自己的博客上分享了这四十三条经验法则。文章《Rules of Machine Learning: Best Practices for ML Engineering》旨在帮助具备机器学习基础知识的朋友从谷歌机器学习最佳实践中获益。文章提供了一种机器学习风格，类似 Google C++ 风格指南以及其他流行的实用编程指南。如果你上过机器学习方面的课程或者构建或研究过机器学习模型，那么，你的背景知识足以让你读懂这篇文章。机器之心编译了四十三条经验法则，法则具体内容请点击阅读原文，下载全文 PDF。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;预备&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;规则 1：不要害怕发布一款没有用到机器学习的产品。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;规则 2：评估指标设计并落实优先处理的事情。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;规则 3：在复杂的启发式问题上使用机器学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器学习第一阶段：你的第一个工作流&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;规则 4：第一个模型要保持简单，设计好基础架构。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;规则 5：确保基础结构的可测试性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;规则 6：复制操作时小心删除数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;规则 7：利用启发式问题设计特征或从外部处理它们。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;监控&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;规则 8：知道要进行系统刷新。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;规则 9：输出模型前发现问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;规则 10：当心未被报告的失败。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;规则 11：特征栏包干到户，为之建立详细的文档。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;你的第一个目标&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;规则 12：不要过度考虑选择哪个目标直接予以优化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;规则 13：为你的第一个目标，选择一个简单的、可观察、可归属的评估指标。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;规则 14：从一个可诠释的模型开始能让调试工作变得简单些。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;规则 15：在一个策略层中分开垃圾过滤和质量排名。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器学习第二阶段：特征工程&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;规则 16：计划发布和迭代。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;规则 17：从直接可以观察、被报告的特征开始。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;规则 18：用能跨语境泛化的内容特征进行探索。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;规则 19：可以的话，请使用特别具体的特征。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;规则 20：结合并修改现有特征，以人类可以理解的方式创造新的特征。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;规则 21：在一个线性模型中可以学到的特征权重数量与你的数据量大致成比例。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;规则 21：清除你不再使用的特征。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;系统的人类分析&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;规则&amp;nbsp;&lt;/span&gt;23: 你并不是典型的端用户（end user）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;规则&amp;nbsp;&lt;/span&gt;24: 测量模型之间的差量。-delta 参数。-&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;规则&amp;nbsp;&lt;/span&gt;25: 选择模型时，实用性能（utilitarian performance）比预测能力更重要。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;规则&amp;nbsp;&lt;/span&gt;26: 在测量到的误差中寻找模式，并创造新特征。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;规则&amp;nbsp;&lt;/span&gt;27: 尝试量化观测到的不可欲的行为（undesirable behavior）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;规则&amp;nbsp;&lt;/span&gt;28: 意识到相同的短期行为（short­term behavior）并不意味着长期行为相同。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;训练表现与实际产品之间的偏差&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;规则&amp;nbsp;&lt;/span&gt;29: 要让你的实际产品表现得和你训练时一样好，最好的方法是在你的产品中保留训练的特征集，并将这些特征放到日志中，并在训练时使用它们。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;规则&amp;nbsp;&lt;/span&gt;30: 重要性加权的样本数据，不要武断放弃。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;规则&amp;nbsp;&lt;/span&gt;31: 注意，如果在训练和服务时点将表格中的数据加起来（join data from a table at training and serving time），表格数据会发生变化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;规则&amp;nbsp;&lt;/span&gt;32: 在你训练的流程和实际产品流程之间，尽可能地重复使用同一代码。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;规则&amp;nbsp;&lt;/span&gt;33: 如果你用 5 号之前的数据生成了一个模型，那么用 6 号之后的数据来测试模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;规则&amp;nbsp;&lt;/span&gt;34: 在使用二元分类器进行过滤时（例如垃圾邮件检测），用短期的牺牲获得清洁数据的优良性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;规则&amp;nbsp;&lt;/span&gt;35: 注意在排序问题中的固有偏差（inherent skew）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;规则 36: 用位置特征避免反馈循环（feedback loops）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;规则 37: 测量训练/实际产品表现之间的偏差（Measure Training/Serving Skew）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器学习第三阶段：放慢速度、优化细化和复杂的模型&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;规则 38：如果出现目标不对齐的问题就不要在新的特征上浪费时间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;规则 39：决定不只是基于一个标准做出。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;规则 40：保证组件简单。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;规则 41： 性能达到高峰时，要寻找新的信息源加以补充，而不是精化现有的信号。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;规则 42：不要期望多样性、个性化或者与你所认为的流行性关联。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;规则 43：在不同的产品中你的伙伴可能倾向于同一个产品。而你的兴趣不是。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 18 Jan 2017 13:33:06 +0800</pubDate>
    </item>
  </channel>
</rss>
