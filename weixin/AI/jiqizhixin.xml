<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>四大深度学习框架+四类GPU+七种神经网络：交叉性能评测</title>
      <link>http://www.iwgc.cn/link/09bd0972c62302ee29710a4120a47ee817b8ec89</link>
      <description>
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自add-for&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Pedro Gusm&amp;atilde;o&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李泽南、黄小天&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;最近，Pedro Gusm&amp;atilde;o 等人对于英伟达的四种 GPU 在四种不同深度学习框架下的性能进行了评测。本次评测共使用了 7 种用于图像识别的深度学习模型&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一个评测对比不同 GPU 在不同神经网络和深度学习框架下的表现。这是一个标准测试，可以在给定 GPU 和架构的情况下帮助我们选择合适的框架。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二个测试则对比每个 GPU 在不同深度学习框架训练时的 mini-batch 效率。根据以往经验，更大的 mini-batch 意味着更高的模型训练效率，尽管有时会出现例外。在本文的最后我们会对整个评测进行简要总结，对涉及到的 GPU 和深度学习架构的表现进行评价。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;GPU、深度学习框架和不同网络之间的对比&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们使用七种不同框架对四种不同 GPU 进行，包括推理（正向）和训练（正向和反向）。这对于构建深度学习机器和选择合适的框架非常有意义。我们发现目前在网络中缺乏对于此类研究的对比。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是首次针对不同 GPU（Tesla K40，Titan-X Maxwell，GTX 1080 和 Titan-X Pascal）与不同网络（AlexNet，Overfeat，Oxford VGG，GoogLeNet，ResNet-50，ResNet-101 和 ResNet-52）在不同深度学习框架下（Torch，Caffe，TensorFlow 和 Neon）的评测。在评测中，除了 Neon，所有框架都使用了英伟达 cuDNN 5.1。我们在每个 minibatch 里使用了 64 个取样，每次进行超过 100 次推理和训练。图表中缺失的数据意味着该次测试遭遇内存不足。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/41beadac36003cbe0167f073c20b3d9470d8cf2d"/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/af81f07feeef1d864a1473e9fa0d6a02c7d5c0aa"/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/56bb976d0f1acda2f85c1367a3335ae050d3703b"/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/bdac43b634b9781d8922c9ff792860191609c6f4"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;用于 TensorFlow 的 Minibatch 效率&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;训练深度学习框架时知道每个 minibatch 中的样本数量将会加快训练。在第二个测评中，我们分析了 minibatch 尺寸与训练效率的对比。由于 TensorFlow 1.0.0 极少出现内存不足的情况，我们只使用它进行这项评测。这次实验中我们重新评估了 100 次运行中的平均正向通过时间和和正向+反向通过时间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/878556279d99657d70960cc04876ba32de001cd9"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/ec2f3d5ec1192f66626d1bdde81db7ec6524d74e"/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/2961215693840d7fd87820c83d578d9aa71c9a2b"/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/95293d553a81d35ba027c940ef98d89d0b6b5449"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;测评分析&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关于第一个测评，我们注意到，Neon 几乎总是能为 Titans 和 GTX 1080 导出最好的结果，而对 K40 的优化最差。这是因为 Neon 针对 Maxwell 和 Pascal 架构做了优化。Tesla K40，作为一个 Kepler GPU，缺少这样低层级的优化。Torch 在所有架构中都可以输出好结果，除了被用在现代 GPU 和更深的模型时。这又一次成了 Neon 发挥作用的时候。最后，我们指出 TensorFlow 是唯一一个可以训练所有网络的框架，并且不会出现内存不足的情况，这是我们继续使用它作为第二个测评的框架的原因。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关于第二个测评，一般来说更大的 minibatch 可以减少每个样本的运行时间继而减少每个 epoch 的训练时间。正如我们在上图看到的，当使用 VGG 网络时，GTX 1080 需要 420.28 毫秒为一个 64 样本的 minibatch 运行正反向通过；相同的配置训练 128 个样本需要 899.86 毫秒，是前者的两倍还要再多出 60 毫秒。此外，我们注意到对于所有大小为 8 的 minibatch 中的网络，Tesla K40 有一个下凹曲率； Titan X Pascal 在使用相同 batch 大小的更浅架构上（例如 AlexNet 和 Overfeat）表现出上凹曲率。下凹曲率表明有效率在下降而上凹曲率则相反。更有趣的是 minibatch 大小的特殊取值也意味着更明显的效率。分析两个 GPU 将有助于解释这为什么会发生。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;附录&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以下是对测评中使用的 GPU 还有架构和框架版本的扼要介绍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;GPU&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1.Tesla K40:&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;K40 具有 2880 个 cuda 内核，745MHz 的基本频率和可达 288GB/s 的内存宽带的 12G GDDR5 RAM。这是一个基于 Kepler 架构的服务器 GPU，具备 3.5Tflops 的计算能力。K40 已经停产，但仍被广泛用于很多数据中心，了解其性能对于我们将来是否要购买新硬件很有帮助。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2.Titan X Maxwell：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Titan X 是具有 5.1Tflops 计算能力、用于 Maxwell 架构的旗舰消费级 GPU。它具有 3072 cuda 内核，1000MHz 的基本频率，传送速率为 336.5GB/s 的 12G GDDR5。考虑到其硬件规格和大多数深度学习应用仅依靠于单精度浮点运算，Titan X Maxwell 目前能用 750 美元左右买到，被认为是基于起始价格为 1000 美元的 GPU 的服务器的最佳替换方案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3.GTX 1080:&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;GTX 1080 是英伟达目前生产的高端游戏 GPU，售价 599 美元。它具备 2560 个 cuda 内核，1607MHz 的基本频率，提供 320GB/s 宽带的 8GB GDDR5X。先进的 Pascal 架构为其带来了 6.1Tflops 的计算能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4.Titan X Pascal：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Titan X Pascal 一直是深度学习方面最畅销的 GPU。它具备 3584 cuda 内核，1417MHz 的基本频率，提供 480GB/s 内存宽带的 12GB GDDR5X。它比 GTX 1080 有更强大的计算能力（约 11Tflops），目前标价 1200 美元。尽管消费者趋之若鹜，英伟达目前在官方网站上直销 Titan X Pascal，每个消费者限购 2 块。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此外，在 3 月 10 日售价 699 美元，计算能力 11.34Tflops 的 GeForce GTX 1080Ti 推出以后，消费者拥有了 Titan X 以外的另一个选择。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;神经网络&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1.AlexNet：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2012 年，Alex Krizhevsky 使用五层卷积、三层完全连接层的 CNN 网络赢得了 ImageNet 竞赛（ILSVRC）。AlexNet 证明了 CNN 在分类问题上的有效性（15.3% 错误率），而此前的图片识别错误率高达 25%。这一网络的出现对于计算机视觉在深度学习上的应用具有里程碑意义。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2.Overfeat：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2013 年，Overfeat 通过降低第一层的步幅改进了 AlexNet 的架构，让图片识别错误率降低至 14.2%。这一方法证明了卷积神经网络使用同步分类、本地化和图片中对象检测的方式可以增加图片识别任务的准确度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3.VGG Network：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2014 年，牛津大学的研究人员通过训练 11 到 19 层的卷积神经网络证明了深度对于图像识别任务的重要性。他们的工作表明，使用 3&amp;times;3 空间内核的两个连续卷积层比使用单个 5&amp;times;5 卷积层具有更高的准确性，同时这一优势也能为非线性层带来帮助。此外，作者证明 19 层 CNN 输出的结果与 16 层网络具有相似的精度，这暴露了当时技术训练深度 CNN 的困难。最后，VGG Net 进一步将 ILSVRC-2014 分类任务中的错误率减少到了 7.3％。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4.GoogLeNet：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该方式由谷歌研究人员于 2014 年推出，它是由 22 层卷积神经网络构成的模型，它被称为 Inception，是由并行和串行的网络进行的级联。网络分类器的误差为 6.67%。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;5.残差网络：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 2015 年，微软研究院的学者提出了一种新的 CNN 架构&amp;mdash;&amp;mdash;残差网络（ResNet）。在残差网络中，残差块的任务是学习连续输出的表示差异。这一方法通过 110 层模型在 ImageNet 竞赛时达到了 3.57% 的误差率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本次评测中使用的深度学习架构版本：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Caffe: commit 746a77e6d55cf16d9b2d4ccd71e49774604e86f6&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Torch7: commit d03a42834bb1b674495b0c42de1716b66cc388f1&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Nervana Neon: 1.8.1&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;TensorFlow: 1.0.0&amp;nbsp;&lt;img src="http://img05.iwgc.cn/mpimg/77d78e8a2516c344f08ec753b05acf128083afcd"/&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;原文地址：http://add-for.com/blog/nvidia-dgx-1-supercomputer-join-our-community-based-deep-learning-benchmark/&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;span&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;
</description>
      <pubDate>Fri, 10 Mar 2017 13:17:32 +0800</pubDate>
    </item>
    <item>
      <title>盘点 | 机器学习入门算法：从线性模型到神经网络</title>
      <link>http://www.iwgc.cn/link/8d9ba22a681e89bccee4dae4d7c5ed93b16b9182</link>
      <description>
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自Dataconomy&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：王宇欣、吴攀、蒋思源&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;近段时间以来，我们频频听到「机器学习（machine learning）」这个词（通常在预测分析（predictive analysis）和人工智能（artificial intelligence）的上下文中）。几十年来，机器学习实际上已经变成了一门独立的领域。由于现代计算能力的进步，我们最近才能够真正大规模地利用机器学习。而实际上机器学习是如何工作的呢？答案很简单：算法（algorithm）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器学习是人工智能（artificial intelligence）的一种，其本质上讲，就是计算机可以在无需编程的情况下自己学习概念（concept）。这些计算机程序一旦接触新的数据，就将会改变它们的「思考」（或者输出）。为了实现机器学习，算法是必需的。算法被写入计算机并在其剖析数据时给与其需要遵循的规则。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器学习算法经常被用于预测分析。在商业中，预测分析可以用于告诉企业未来最有可能发生什么。例如，使用预测分析算法，在线 T 恤零售商可以使用当前的数据来预测下个月他们将会售出多少 T 恤。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;回归或分类&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然机器学习也可以用于其它的用途，但是我们将在本指南中着重于预测。预测是一种基于输入变量来估计输出变量的过程。比如，如果我们输入特定房子的特征，则可以预测售价。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;预测问题分为两大类：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;回归问题（Regression Problems）：我们想要预测的变量是数字（例如，房子的价格）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;分类问题（Classification Problems）：我们想要预测的变量是「是/否」的答案（例如，某一设备是否会经历设备故障）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在我们已经介绍了机器学习在预测方面的应用，我们可以讨论机器学习算法，其分为 3 个组别：线性模型（linear models）、树型模型（tree-based models）、和神经网络（neural networks）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;什么是线性模型算法&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/385c4451c013b76b5053c0db06917c50847269d2"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;线性模型使用简单的公式通过一组数据点来查找「最优拟合」线。通过你已知的变量方程（比如，原料），你可以求出你想要预测的变量（例如，烘烤蛋糕需要多长时间）。为了求出预测量，我们输入已知的变量得到答案。换句话说，为了求出烘烤蛋糕需要多长时间，我们只需要输入原料。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;例如，要烘烤蛋糕，分析过后我们得到这个方程：t = 0.5x + 0.25y，其中 t 烤蛋糕的时间，x 为蛋糕糊的重量，y = 1 表示为巧克力蛋糕而 0 表示为非巧克力蛋糕。所以让我们假设，我们有 1kg 的蛋糕糊并且我们想要一个巧克力蛋糕，我们输入我们的数字来建立这个方程：t = 0.5(1) + (0.25)(1) = 0.75，即 45 分钟。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有不同形式的线性模型算法，我们将要讨论线性回归（linear regression）和逻辑回归（logistic regression）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;线性回归&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;线性回归，也称为「最小二乘回归（least squares regression）」，是线性模型的最标准的形式。对于回归问题（我们设法预测的变量是数字），线性回归是最简单的线性模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;逻辑回归&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;逻辑回归是为分类问题进行简单调整过的线性回归（我们设法预测的变量是「是/否」的答案）。由于其构造，逻辑回归非常适合于分类问题&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;线性回归和逻辑回归的缺点&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;线性回归和逻辑回归都有着相同的缺点。两者都具有「过拟合（overfit）」的趋势，这意味着模型太适应于数据而牺牲了推广到先前未知的数据的能力。因此，这两个模型经常需要进行规范，这意味着它们有一定的惩罚（penalty）以防止过拟合。另一个线性模型的缺点是，因为它们太简单了，所以往往不能预测更复杂的行为。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;什么是树型模型&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/9a3b9a6e181478a9d6e18164500081cb65ad5dbd"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;树型模型有助于探索数据集，并可视化预测的决策规则。当你听到关于树型模型的东西时，你可以将其想成是决策树或分支操作序列。树型模型高度精确、稳定且更易于解释。与线性模型相反，它们可以映射非线性关系以求解问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;决策树（decision tree）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;决策树是一种使用分支方法（branching method）来显示决策的每个可能结果的图。例如，如果你想要订购莴苣、浇头和沙拉酱，决策树可以绘制出所有可能的结果（或者你可能最终得到的沙拉的品种）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了创建或者训练决策树，我们采用我们过去训练模型的数据，并找出哪些属性可以最佳分割目标训练集。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;例如，我们在信用卡欺诈中使用决策树。我们可以发现最佳的欺诈风险预测的属性是消费明细（例如，有信用卡用户有非常大的消费）。这可能是第一次分割（或分支）&amp;mdash;&amp;mdash;那些有着异常高消费的卡和没有的卡。然后我们使用第二个最佳属性（例如，经常使用的信用卡）来创建下一次分割。然后我们可以继续直到我们有足够的属性来满足我们的需要。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;随机森林（random forest）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随机森林是许多决策树的平均，每个决策树都用数据的随机样本训练。森林中的每个独立的树都比一个完整的决策树弱，但是通过将它们结合，我们可以通过多样性获得更高的整体表现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随机森林是当今机器学习中非常流行的算法。它非常容易训练（或构建），且它往往表现良好。它的缺点是，相比于其他算法，其输出预测可能较慢。所以当你需要快如闪电般地预测，你也许不会使用它。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;梯度提升（gradient boosting）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;梯度提升和随机森林类似，都是由「弱」决策树构成的。最大的区别是，在梯度提升中树是被一个接一个相继训练的。每个随后的树主要用被先前树错误识别的数据进行训练。这使得梯度提升更少地集中在容易预测的情况并更多地集中在困难的情况。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;梯度提升训练速度也很快且表现非常好。然而，训练数据的小变化可以在模型中产生彻底的改变，因此它可能不会产生最可解释的结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;什么是神经网络&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/3a3c0d8b0097c026932c62a73c594d5b1b6c2577"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;生物学中的神经网络是互相交换信息的相互连接的神经元。这个想法现在已经适用于机器学习的世界，并被称为人工神经网络（ANN）。深度学习（deep learning）是一个经常出现的词，是指几层连续放置的人工神经网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工神经网络（ANN）包含了许多可以学习类似人脑的认知能力的模型。其它算法不能处理的极其复杂的任务（如图像识别），神经网络就可以办到。然而，就像人类的大脑，它需要很长时间来训练模型，且需要很多的能量（想一想我们为了保持大脑的工作，我们吃了多少东西）。&amp;nbsp;&lt;img src="http://img05.iwgc.cn/mpimg/77d78e8a2516c344f08ec753b05acf128083afcd"/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/fb81ab34f17fc5f0d4f5227053b1cec66cf88db4"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;原文地址：&lt;/em&gt;&lt;/span&gt;&lt;a&gt;&lt;span&gt;&lt;span&gt;http://dataconomy.com/2017/03/beginners-guide-machine-learning&lt;/em&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;span&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;
</description>
      <pubDate>Fri, 10 Mar 2017 13:17:32 +0800</pubDate>
    </item>
    <item>
      <title>学界 | 5.5%语音识别词错率究竟如何炼成？IBM发布相关研究论文</title>
      <link>http://www.iwgc.cn/link/04488eb5334672e516f19e26c99d280b405d15aa</link>
      <description>
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自arXiv&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：晏奇、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;语音识别是人工智能领域所研究的核心问题之一，研究者一直以来都在竞相努力以期能首先达到比肩人类的里程碑。去年十月，微软人工智能与研究部门的一个研究者和工程师团队报告他们的语音识别系统实现了和专业速录员相当甚至更低的词错率（WER）&amp;mdash;&amp;mdash;达到了 5.9%。而前两天，IBM 官方博客却发文宣称人类的水平实际上应该是 5.1%，同时该文章还表示 IBM 的系统的词错率已经超越了之前微软报告的最佳水平，达到了 5.5%，实现了新突破。详见机器之心报道《&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650723971&amp;amp;idx=1&amp;amp;sn=0740aff813f433f2df01f8cfbcf24189&amp;amp;chksm=871b12fdb06c9bebd847f9d17e47033a23804eda4b8379fd2dd45a77b94ee41ea59a7e28a73e&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650723971&amp;amp;idx=1&amp;amp;sn=0740aff813f433f2df01f8cfbcf24189&amp;amp;chksm=871b12fdb06c9bebd847f9d17e47033a23804eda4b8379fd2dd45a77b94ee41ea59a7e28a73e&amp;amp;scene=21#wechat_redirect" target="_blank"&gt;IBM 宣称人类语音识别词错率实际应为 5.1%，自家系统已突破至 5.5%&lt;/a&gt;》。不久之前，我们在 arXiv 找到了 IBM 的相关研究论文，机器之心在此对该论文的摘要和核心突破的部分进行了编译介绍，原论文请点击文末「&lt;span&gt;阅读原文&lt;/span&gt;」查阅。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/87eb7998c4ef9dafe307fc837200d5bec04ed3af"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对人与人之间互相交流的精准识别是语音识别任务中最困难的任务之一。在具有代表性的 Switchboard 对话语料库上，深度学习在过去几年中的进步让语音识别能力获得了巨大提升。短短几年时间，词错率就从 14% 下降到 8%，再下降到 6.6%，直到最近，下降到 5.8%。这一比率已经可以和人类表现媲美了。那么进一步的两个问题来了，人类的表现究竟是什么水平？我们还能将语音识别错误率降低多少呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由微软最近发布的一篇论文显示，我们已经实现了人类级别的表现能力。为了试图验证这个说法，我们执行了一套基于两个对话任务的人类水平测试，我们发现人类表现或许比之前报道的要强得多，这个结果无疑给研究社区提出了一个更加困难的任务目标。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们报告了这个领域中我们团队自己的成果，我们提出了一套声学与语言建模技术，它使我们自己的英文对话电话 LVCSR 系统（English conversational telephone LVCSR system）在 Hub5 2000 评估的 Switchboard 和 CallHome 子集上分别实现了 5.5% 和 10.3% 的水平，这是一个新的表现里程碑&amp;mdash;&amp;mdash;至少在写这篇论文时是这样（当然还是无法媲美我们测量的人类水平！）。在声学这方面，我们使用了三个模型的分数融合（score fusion）：第一个是有多特征输入的长短期记忆网络（Long Short-Term Memory, LSTM），第二个是经过说话者对抗多任务学习（speaker-adversarial multi-task learning）训练后的 LSTM。第三个是具有 25 个卷积层与时间扩张（time-dilated）的卷积的残差网络（ResNet）。在语言建模这方面，我们使用了词和字符 LSTM（word and character LSTM）和卷积的 WaveNet 风格的语言模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/975be2d12b01fd4db9d404acd9f33e481334a5a4"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;图 1：带有说话者对抗 MTL 架构（speaker-adversarial MTL architecture）的 LSTM&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/86c6b16ff04d4abe007fb1b798bffb9d33e73a58"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;图 2：在序列上的残差连接。其中卷积是未填充的并会减少特征图（feature maps）在时间方向上的大小（用红色虚线表示）。为了匹配这种缩减，我们只需要简单地沿着 shortcut connection 上的时间对边（edge）进行裁剪。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;语言建模的提升&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除了我们之前的系统 [5] 所用的 n-gram 和 model-M，在这篇论文中我们还引入了基于 LSTM 和基于卷积的 LM。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们实验了四种 LSTM LM，即：Word-LSTM、Char-LSTM、Word-LSTM-MTL 和 Char-LSTM-MTL。Word-LSTM 有一个词嵌入层、两个 LSTM 层、一个全连接层和一个 softmax 层，如图 3 所示。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/c6aa02304bec503f374aceed695eefdbcd10a754"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;图 3：Word-LSTM&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;上面的 LSTM 层和全连接层（FC）被残差连接 [6] 所包裹。dropout 只在垂直维度而不在时间维度上应用 [25]。Char-LSTM 增加了一个额外的 LSTM 层来从字符序列中估计词嵌入（word-embeddings），如图 4 所示 [26]。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/9cedd52264f43ee0d0d2999e854ab82c57c2b7b0"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;图 4：Char-LSTM&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Word-LSTM 和 Char-LSTM 都使用了在其历史上下一个词的交叉熵损失来作为目标函数，这与传统的 LM 类似。此外，我们在 Word-LSTM 和 Char-LSTM-MTL 中还引入了多任务学习（multi-task learning，MTL）。我们首先使用布朗聚类（Brown clustering）[27] 聚集词汇。当训练 Word-LSTM 和 Char-LSTM-MTL 时，在其历史上的下一个词预测和在其历史上的下一个类别预测的交叉熵的加权和被用作目标函数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;受到这种卷积和非卷积声学模型的互补性的启发，我们用基于卷积的 LM 来实验，它和 WAVENET[28] 中使用的扩展因果卷积（dilated causal convolution）层是同样的形式。生成的模型被称为 WordDCC，它由词嵌入层、带扩展（dilation）的因果卷积层、卷积层，全连接层、softmax 层和残差连接组成。实际的层数和扩展（dilation）/窗口大小是使用 heldout 数据来决定的（图 5 给出了一个简单的配置图示进行说明）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/69fe9b89f5a9faef81bdb6d01b53000d01f6f653"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;图 5：Word-DCC&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这 5 个 LM 应用了常规的训练数据和训练步骤，如下所述：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;我们使用来自 [5] 的同样 85000 个词汇。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;首先，我们用涵盖 5 亿 6 千万个词汇的语料库（该语料库由 LDC 的公开文本数据组成，包括 Switchboard、Fisher、Gigaword 和 Brodcast News and Conversations）来训练 LM。然后从被训练的模型开始，我们进一步用由 2400 万词组成的用于训练声学模型的 1975 小时音频数据的转录来训练 LM。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;我们通过 ADAM[29] 来控制学习率（leaning rate）并且我们引入了一个自稳定（self-stabilization）项来协调各层的学习率 [30]。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;对于所有的模型，我们基于 heldout 数据的复杂度调整超参数（这些 heldout 数据是声学转录的子集）。每个模型的参数的大概数量是 9000 万到 1.3 亿。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们首先使用 n-gram LM 生成了词网格（word lattices），而我们最好的声学模型由 ResNet 和两个 LSTM 组成。然后我们使用 model-M 对该词网络进行了重新评分并从这些被重新评分的网格中生成了 n 最佳列表。最后，我们应用了这四种基于 LSTM 的 LM 和基于卷积的 LM。注意其 LM 概率是被线性地内插（interpolated）进去的，且所有 LM 的插值权重（interpolation weights）都使用了 heldout 数据进行估计。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/55a60aa5f3fc09354fff4b9b2e63db0a25698863"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;表 8：多种 LM 配置下，在 SWB 和 CH 上的词错率&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;表 8 给出了在多种 LM 配置下在 SWB 和 CH 上的词错率。基于 LSTM 的 LM 在强大的 n-gram + model-M 结果之上表现出了显著的提升。Word-DCC 也在 n-gram + model-M 之上有微小的提升。多任务学习的效果尤其在 CH 上得到了证实。在这 5 个基于 LSTM 和基于卷积的 LM 中，word-LSTM-MTL 在 SWB 和 CH 上分别实现了最好的 5.6% 和 10.3% 的词错率。通过在 n-gram + model-M 之上结合这 5 种 LM，我们分别在 SWB 和 CH 上实现了 5.5% 和 10.3% 的词错率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/613829077fde9282c8639647dfb8947b9cdf153c"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;表 9：在所有测试数据集上，对应不同的 LM rescoring 步骤的词错率。最后一行 』.』 removal 是指从参考和系统输出中移除了 . 号之后的词错率&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，在表 9 中我们总结了在所有测试集上的多个语言模型 rescoring 步骤所带来的提升。我们注意到参考的测试集的转录标准不一致，比如关于拼写没有遵循 SWB 和 CH 的点号惯例（如 T V），而是遵循其它测试集的点号惯例（比如 T.V.）。表 9 的最后一行给出了在从参考和系统输出中移除了点号之后的词错率&amp;mdash;&amp;mdash;这是通过为其 GLM 文件加入一个过滤规则实现的：A. =&amp;gt; A ... Z. =&amp;gt; Z&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;更多关于该语言建模方法的详细信息，请参考配套的论文 [31].&amp;nbsp;&lt;img src="http://img03.iwgc.cn/mpimg/77d78e8a2516c344f08ec753b05acf128083afcd"/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;span&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;
</description>
      <pubDate>Fri, 10 Mar 2017 13:17:32 +0800</pubDate>
    </item>
    <item>
      <title>教程 | 谷歌官博详解XLA：可在保留TensorFlow灵活性的同时提升效率</title>
      <link>http://www.iwgc.cn/link/c9c911cd7aeccb9da07042354d22fa85e225a54a</link>
      <description>
&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自Google Blog&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：Jane W、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;近日，谷歌开发者博客发布了一篇文章，介绍了用于 TensorFlow 的编译器 XLA（Accelerated Linear Algebra/加速线性代数）的原理和能力。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;TensorFlow 的设计目标和核心优势之一是其灵活性。TensorFlow 被设计成一个灵活和可扩展的系统，可用于定义任意数据流图（data flow graph）并使用异构计算设备（如 CPU 和 GPU）以分布式方式有效地执行它们。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是灵活性通常与性能不能兼得。虽然 TensorFlow 旨在定义任何种类的数据流图，但是由于 TensorFlow 分别优化每个 运算/指令（op），所以使所有图都高效地执行是有挑战性的。当一个具有高效实现的运算存在，或者每个运算都是相对重量级的操作（heavyweight operation）时，一切都很好；否则，用户仍然可以从低级 op 中组合 op，但是这种组合不能保证以最有效的方式运行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这就是我们开发了 XLA（Accelerated Linear Algebra/加速线性代数）的原因，它是一个用于 TensorFlow 的编译器。XLA 使用 JIT 编译技术来分析用户在运行时（runtime）创建的 TensorFlow 图，专门用于实际运行时的维度和类型，它将多个 op 融合在一起并为它们形成高效的本地机器代码&amp;mdash;&amp;mdash;能用于 CPU、GPU 和自定义加速器（例如谷歌的 TPU）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;融合可组合的 op 以提高性能&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;例如，考虑 tf.nn.softmax（https://www.tensorflow.org/api_docs/python/tf/nn/softmax）运算。它计算的是其参数的 softmax 激活函数如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/1a3c0c996f007395a39be83e360537fd1d21a4e6"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Softmax 可以被用于原始 TensorFlow 的 op 的组合（指数、减法、元素除法等）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;softmax = exp(logits) / reduce_sum(exp(logits), dim)&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由于额外的数据移动和 op 内部临时结果的实体化（materialization），这个过程可能是缓慢的。此外，在像 GPU 这样的协处理器上，这样的分解执行可能导致多个「核启动（kernel launches）」，使其速度更加缓慢。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;XLA 是编译调试器的秘密武器，它能帮助 TensorFlow 自动优化原始 op 的组合。有了 XLA 的增强，通过在运行时的过程中分析图、融合多个 op 并为融合子图（subgraph）生成有效的机器代码，TensorFlow 能在保留其灵活性的同时而不牺牲运行时的性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;例如，如上面所示的 softmax 的分解实现，由 XLA 优化后的速度能与人工优化的复合 op 一样快。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;更一般地，XLA 可以获取 TensorFlow 运算的整个子图，并将它们融合到需要最少数量内核启动（kernel launch）的高效循环中。例如：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/6e66e8dd0a352344030497291c00a18c12f7c742"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该图中的许多操作可以融合到单个元素的循环（single element-wise loop）中。例如，考虑将偏差向量（bias vector）的单个元素添加到来自 matmul 函数结果的单个元素中。该添加的结果是可以与 0 比较的单个元素（用于 ReLU）。比较的结果可以指数化并除以所有输入的指数的和，从而产生 softmax 的输出。我们不需要为 matmul、add 和 ReLU 创建内存中的中间数组。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;nbsp;s[j] = softmax[j](ReLU(bias[j] + matmul_result[j]))&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;融合的实现可以在单个元素的循环中计算最终结果，而不需要分配不必要的内存。在更高级的场景中，这些操作甚至可以融合到矩阵乘法中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;XLA 帮助 TensorFlow 保持其灵活性，同时消除性能问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在内部基准（internal benchmark）测试中，相比于没有 XLA 的 TensorFlow，XLA 显示了在 Nvidia GPU 上高达 50％的加速。如预期那样，最大的加速来自含有长序列元素操作的模型，因为 XLA 可以将长序列元素操作融合进高效的循环中。然而，XLA 仍然被认为是实验性的，一些基准可能会经历减速过程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 TensorFlow 开发者峰会的演讲中，Chris Leary 和 Todd Wang 描述了 TensorFlow 如何利用 XLA、JIT、AOT 和其它编译技术来最小化执行时间并最大限度地利用计算资源。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Youtube 视频链接：&lt;/span&gt;&lt;span&gt;https://www.youtube.com/watch?v=kAOanJczHA0&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;可执行尺寸缩减的极度专业化&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除了改进性能，TensorFlow 模型受益于 XLA 的限制内存环境（如移动设备）的要求，因为 XLA 减少了其提供的可执行尺寸（executable size）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;tfcompile 是利用 XLA 进行提前编译（AOT/ahead-of-time compilation）的工具&amp;mdash;&amp;mdash;将整个图（graph）编译为 XLA，然后形成严格的机器代码以实现图中的 op。加上最小运行时间，该方案提供了相当多的尺寸减小。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/9fbcd37bcc9750f6150ef93a08126ebd579afcc9"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种尺寸减小是通过其静态编译隐含的模型所具有的完全专业化来实现的。当模型运行时，不需要 TensorFlow 运行时的全部性能能和灵活性&amp;mdash;&amp;mdash;只有实现用户感兴趣的实际图的 op 被编译为本地代码。也就是说，由 XLA 的 CPU 后端发出的代码的性能仍然远不是最优的；这部分项目需要更多的工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;对替代性后端和设备的支持&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了在当前的新型计算设备上执行 TensorFlow 图，必须重新实现用于新设备的所有 TensorFlow 的 op（内核）。支持设备可能是非常重要的工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过设计，XLA 通过添加自定义后端（backend）使支持新设备更容易。由于 TensorFlow 可以指向 XLA，因此可以向 XLA 添加新设备后端，从而使其能够运行 TensorFlow 图。XLA 为新设备提供了一个显著更小的实现界面，因为 XLA 操作仅仅是原始的（回想一下 XLA 独自处理复杂 op 的分解）。我们已在下面的页面中记录了向 XLA 添加自定义后端的过程：https://www.tensorflow.org/versions/master/experimental/xla/developing_new_backend。&lt;/span&gt;&lt;span&gt;谷&lt;/span&gt;&lt;span&gt;歌使用此机制利用 XLA 配置 TPU。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;结论与展望&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;XLA 仍处于发展的早期阶段。在一些使用案例中，它显示出非常有希望的结果，很显然，TensorFlow 未来可以从这项技术中得到更多益处。我们决定尽早向 TensorFlow Github（https://github.com/tensorflow/tilerflow/tree/master/tensorflow/compiler）发布 XLA，以征求社群的意见，并为各种计算设备优化 TensorFlow 提供方便的界面，以及重新定位 TensorFlow 的运行时和建立模型以在新型硬件上运行&lt;span&gt;。&amp;nbsp;&lt;img src="http://img03.iwgc.cn/mpimg/77d78e8a2516c344f08ec753b05acf128083afcd"/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;原文地址：https://developers.googleblog.com/2017/03/xla-tensorflow-compiled.html&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;span&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Fri, 10 Mar 2017 13:17:32 +0800</pubDate>
    </item>
    <item>
      <title>学界 | CMU论文：神经机器翻译和Seq2seq模型导论</title>
      <link>http://www.iwgc.cn/link/d90dd5c67da0f06612e3f422b4b44353a2693f2a</link>
      <description>
&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自arXiv&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Graham Neubig&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李泽南、蒋思源&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;本文是一篇有关机器翻译的详细教程，适用于计算机科学本科背景的读者。据 Paper Weekly（ID：paperweekly）介绍，本论文来自 CMU LTI，内容包括了 Seq2Seq 方法的各个基础知识，包括 N-gram Language Model、Log Linear Language Model、NNLM、RNNLM、encoder-decoder、attention，是一本高质量教程，适合初学者学习。读者可以点击&lt;span&gt;「&lt;span&gt;阅读原文&lt;/span&gt;」下载论文。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/237a3ee656e7599dcf4102d6dc75d30ea8f4362b"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;摘要&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本教程介绍了一组强大的技术「神经机器翻译」、「神经 seq2seq 模型」。这些技术已经被应用于处理人类语言相关的很多任务中，也已成为所有顺序数据建模的强大工具。本教程假设读者拥有基础数学和编程知识，但对神经网络和自然语言处理背景没有要求。本文试图解释各种方法背后的思路，然后通过完整的数学解析重现它们，让读者可以深入了解这些技术。此外，本文还有一些实现的建议，读者可以通过练习测试自己对于文中内容的理解程度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;背景&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器翻译是通过计算机翻译人类不同语言的技术。想象一下科幻电影里出现的实时翻译机，它可以实时将一种语言转换为另一种。目前，谷歌翻译等网站在这些方向上已经做得很不错了。机器翻译可以消除语言障碍，具有广泛的应用前景，所以在计算机出现不久以后，这一方向就成为了研究人员关注的焦点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们称输入机器翻译系统的语言为源语言，输出语言为目标语言。这样，机器翻译就可以被描述为一种将源语言中的单词序列转换为目标语言单词序列的任务。机器翻译研究者们的目标是最终实现一个高效的模型，让这种转换在各类语言的应用中能够快速进行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Seq2seq 模型是包括将一个序列映射到另一个序列的所有模型的更广泛类型。它包含机器翻译，同时也包含大量用于处理其他任务的方法。事实上，我们可以把每个计算机程序都看成是输入一个位序列，经过处理输出一个位序列，这意味着所有程序都是表示一些行为的 Seq2seq 模型（尽管在许多情况下，这不是最自然和直观的表达方式）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/74a991af992eff547166cb05c7db86b9a1278fe3"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;一个 Seq2seq 模型任务实例&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器翻译作为 Seq2seq 模型代表具有以下特点：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1、机器翻译是最被认可的 Seq2seq 模型实例，允许我们在其中使用很多直观例子来说明处理此类问题的困难。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2、机器翻译通常是新模型开发阶段接触的主要任务之一，这些模型在发展中经常会首先用于机器翻译，然后才会被应用到其他任务中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3、当然，也有一些机器翻译从其他任务中获得灵感的案例，从其他任务中获得的启发有助于机器翻译技术的发展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;导论结构&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本教程从第二章开始介绍机器翻译所需要的统计学一般数学定义和方法。在随后的章节中，本课程将沿着技术复杂度递增的方向进行阐述，一直到当前该领域最先进的注意模型（attentional models）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第三章到第六章关注于语言模型，这些语言模型是对兴趣（interest）目标序列的概率进行计算。虽然这些模型不能执行翻译或序列转换（transduction），但对于初步了解 Seq2Seq 模型还是很有帮助的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;第三章重点阐述了 n-gram 语言模型，该模型是一种基于单词在数据集中所出现频率计算其概率的简单方法。同时本章节还阐述了如何使用混乱度（perplexity）等度量方法来评估这些模型的性能好坏。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;第四章讲述了对数-线性语言模型（log-linear language models），该模型通过上下文特征计算下一个单词的概率。本章节同时还叙述了如何通过随机梯度下降来学习模型的参数，即通过求解偏导数并一次次迭代更新参数而增加观察数据的似然度。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;第五章介绍了神经网络的基本概念，神经网络要比对数-线性语言模型更容易将多信息块组合在一起，从而进一步提升语言模型的准确度。本章节给出了前馈神经网络语言模型这样一个案例，该模型主要通过基于先前词的神经网络预测下一个单词的概率。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;第六章介绍了循环神经网络，这是一种允许通过在多个时间步上记录信息的机制。而这种特性催生了循环神经网络语言模型，该模型能在语言或序列数据建模时获取长期依存关系（long-term dependencies）。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，第七和八章描述了能够执行机器翻译或其他任务的实际 seq2seq 模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;第七章描述了编码器-解码器模型，使用递归神经网络将目标序列编码为数字向量，另一个网络会解码这些数字，并将数字向量转换成为语句输出。本章同时也解释了基于此模型生成输出序列的搜索算法。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;第八章解释了注意机制，这种方法允许模型在生成翻译时聚焦输入句子的不同部分。这引出了更有效和直观的句子表示方法，并且通常比相对简单的编码器&amp;mdash;&amp;mdash;解码器机制更有效。&amp;nbsp;&lt;img src="http://img05.iwgc.cn/mpimg/77d78e8a2516c344f08ec753b05acf128083afcd"/&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;span&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Fri, 10 Mar 2017 13:17:32 +0800</pubDate>
    </item>
    <item>
      <title>现场直击 | 李飞飞首度亮相谷歌云大会：发布全新API，解读AI民主化</title>
      <link>http://www.iwgc.cn/link/0f2fe0b3278eeade07568707c82813dcbe770df3</link>
      <description>
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;机器之心现场报道&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;记者：CZ&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;当地时间 3 月 8-10 日，Google Cloud NEXT '17 大会在美国旧金山举行，机器之心作为受邀媒体进行了现场报道。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大会首日，谷歌云高级副总裁 Diane Greene、谷歌 CEO Sundar Pichai、Alphabet 执行主席 Eric Schmidt 、谷歌云机器学习与人工智能首席科学家李飞飞分别做了 Keynote 演讲。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720553&amp;amp;idx=1&amp;amp;sn=c88e48aab2d789d744ac1629ffec9a8a&amp;amp;chksm=871b0d57b06c844121d6fdf6fda546996e87c1cc395bef55fde20cb910b2fe1bbcdf8d1ce6c9&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720553&amp;amp;idx=1&amp;amp;sn=c88e48aab2d789d744ac1629ffec9a8a&amp;amp;chksm=871b0d57b06c844121d6fdf6fda546996e87c1cc395bef55fde20cb910b2fe1bbcdf8d1ce6c9&amp;amp;scene=21#wechat_redirect" target="_blank"&gt;&lt;span&gt;去年 11 月份李飞飞加入谷歌引起了业内极大关注&lt;/span&gt;&lt;/a&gt;&lt;span&gt;，此番首次亮相谷歌云大会自然也是大会首日的重头戏。在 Keynote 演讲中，李飞飞代表谷歌发布了多个谷歌云 API 产品，解读了谷歌云的「AI 民主化」战略，并正式宣布了谷歌云对数据科学社区 Kaggle 的收购。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/3e7d75039b422e5f723ae86c62c2767af2158170"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先，李飞飞通过一些具体案例介绍了人工智能的应用进展：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;零售：机器学习算法在帮助谷歌的 AdSense 为消费者提供更合适的建议，但也仍还有进步的空间，比如供应链优化、随时间预测需求改变以及使用无人机或无人车为消费者快递货物等等。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;媒体娱乐：比如 Google Photos 的自动照片标注和 YouTube 的推荐播放列表。虚拟现实和增强现实依赖计算机视觉来进行运动追踪、环境监测和游戏。甚至新闻报道也将可以自动生成。人工智能将能帮助我们创造更加个性化的内容，比如音乐、视频和艺术品。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;金融：机器学习正在信用卡风险检测、反诈骗和洗钱等方面发挥越来越大的作用。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;医疗保健：人工智能正在真正改善着人们的生活，比如布满传感器的智能化医院、增强诊断等。几个月前，谷歌大脑的研究者表明可以使用深度学习来帮助&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720846&amp;amp;idx=1&amp;amp;sn=2f98ec55be6e608ab7b69bae31a8ed23&amp;amp;chksm=871b0e30b06c872680991cbe6441617c36c9e500486decb1603426f918212f7f31fc7ed19737&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720846&amp;amp;idx=1&amp;amp;sn=2f98ec55be6e608ab7b69bae31a8ed23&amp;amp;chksm=871b0e30b06c872680991cbe6441617c36c9e500486decb1603426f918212f7f31fc7ed19737&amp;amp;scene=21#wechat_redirect" target="_blank"&gt;诊断糖尿病性视网膜炎。&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能的应用越发广泛，但并非所有的开发者都有能力去使用相关技术。所以，李飞飞认为人工智能的下一步必须是民主化，一方面降低进入的门槛，另一方面能够让开发者、用户及企业等尽可能多的去使用人工智能。而云计算就是实现人工智能民主化的完美途径，这也是谷歌在云人工智能/机器学习方面大力投入的原因。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;李飞飞表示，人工智能民主化分为四个方面：民主化计算、民主化算法、民主化数据以及民主化人才。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/3ac084e71d53d23e8ddf93dc548fc911c073d52b"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先，计算方面。深度学习需要大量计算资源&amp;mdash;&amp;mdash;常常会有成百上千万参数和数十亿个连接，而这正是云的用武之地。李飞飞介绍道：「去年，我们推出了 Beta 版的 Cloud ML Engine，今天我在这里宣布其已经实现了更广泛的可用性。Cloud ML Engine 是一个能够利用谷歌所有计算资源的平台。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;借助 ML Engine，用户可以使用其熟悉的 TensorFlow 库，把精力放在自身创意和解决方案上，谷歌云则会为用户处理基础架构和模型上的问题&amp;mdash;&amp;mdash;用户将它们上传至谷歌云，ML Engine 能更快速地进行大规模处理，并将其部署在移动设备上。但机器学习对于很多应用者来说依然很复杂。因此，谷歌发布了训练过的 API，它就像一个开关，可以在任意应用上开启智能部分，使其理解语音、图像和自然语言。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌拥有庞大的研究团队，连续多年对人工智能和机器学习进行研究，是获得最佳论文数量最多的机构之一。谷歌能够迅速的将这些研究成果变成应用，并将其分发到客户手中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其次，在民主化算法方面，李飞飞宣布了一项新产品&amp;mdash;&amp;mdash;Vision API。她介绍道，正在稳步研发的 Vision API 具备一些非常重要的新能力。第一，谷歌把该 API 的元数据（metadata）扩展到了识别来自谷歌图像的知识图谱的数百万实体。如今，它们使用着同样的元数据来支撑谷歌的图搜索。第二，增强了光学字符识别（OCR）功能，能够从富含文本的图像中提取出文本，比如法律文件等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;针对视频中的信息，谷歌云也发布了另外一个全新 API&amp;mdash;&amp;mdash;Video Intelligence API，其能够对视频中的物体进行识别，并帮助用户检索。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/edbe141a93f32daaa0437c83ead20fb97c854690"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第三，李飞飞认为数据是民主化的另一部分，像人类一样，人工智能需要大量数据为自我发展提供洞见。因此，数据集是人工智能需要克服的最大障碍中的一个。虽然 ImageNet 取得了巨大成功，但中间也经历了很多困难，也有一些残留问题。因此，她认为我们需要的是更具扩展性、更有效的方式来对数据进行民主化，且能面向更多的数据科学家、机器学习开发者、各领域专家甚至是商业用户。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌云实现数据民主化的一大举措就是收购数据科学社区 Kaggle，后者聚集了超过 85 万数据科学家，并拥有众多开源数据集。李飞飞表示，收购 Kaggle 之后，谷歌云将为这个庞大社区提供最先进的机器学习环境，并提供直接市场化模型的机会。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;事实上，Kaggle 早已与谷歌云有所合作。此前，他们曾共同举办了 YouTube 8M 视频理解挑战赛。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/e7796a4fe1288e1c333f8937d634caa776fae3d7"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第四，人才民主化。对此，谷歌云发布了 Advanced Solution Lab，实现其他公司与谷歌的人才合作，以帮助他们解决复杂的机器学习问题。USAA 就通过这种机制与谷歌进行了合作，并解决了自己的技术难题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后提及一个花絮，大会当天恰逢国际妇女节，李飞飞在演讲中还提到她的博士学生、现任谷歌云人工智能与机器学习研发负责人李佳。李飞飞这样描述李佳：「Another badass woman in Stan, CS and AI」，希望女性能够在更多科学和技术领域创造出更大价值并赢得更大尊重。&lt;/span&gt;&lt;img src="http://img05.iwgc.cn/mpimg/808c02cb5bee80190c195da3c5143699df3aaf4e"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/18862882fe76e2cd883fe1130a8608c4a9df6de2"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&amp;copy;本文为机器之心报道，&lt;strong&gt;&lt;span&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Thu, 09 Mar 2017 07:56:13 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 谷歌云官方正式宣布收购数据科学社区Kaggle</title>
      <link>http://www.iwgc.cn/link/b39b9195f2b2b6c522e151ddb839ff7142c66d2e</link>
      <description>
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;机器之心现场报道&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;记者：CZ&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;当地时间 3 月 8-10 日，Google Cloud NEXT '17 大会在美国旧金山举行，机器之心作为受邀媒体进行了现场报道。&lt;strong&gt;&lt;span&gt;在当天 Keynote 演讲中，&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;谷歌云机器学习与人工智能首席科学家李飞飞正式宣布谷歌云收购数据科学社区 Kaggle 这一消息。随后，Kaggle 官方网站和谷歌云平台博客也正式发布了该消息。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/f401c479ba408f003492689bc29949f6825156e5"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Kaggle 由 Goldbloom 和 Ben Hamner 创建于 2010 年。是一个数据建模和数据分析竞赛平台。企业和研究者可在其上发布数据，统计学者和数据挖掘专家可在其上进行竞赛以产生最好的模型。数据科学社区有这样一个难题，即众多策略可以用于解决几乎所有的预测建模问题，而研究者不可能在一开始就了解什么方法对于特定问题是最为有效的。Kaggle 的目标则是试图通过众包的形式来解决这一难题，进而使数据科学成为一场运动。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在只面临少数竞争者（如 DrivenData、TopCoder 和 HackerRank）时，Kaggle 就已经开始了这项服务，并通过专注特殊壁垒成功建立了领先优势。Kaggle 官方表示，该社区目前在全世界范围内有超过 85 万的数据科学家用户。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其实，Kaggle 和谷歌合作的历史也不是一天两天了。比如本月初的时候，谷歌和 Kaggle 联合主办了一个 10 万美元的围绕 YouTube 视频分类的机器学习比赛。那场比赛也与 Google Cloud Platform 进行了深度的整合。收购 Kaggle 后，谷歌将获得一个最大最活跃的数据科学家社区，并提升其在社区之中的影响力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;李飞飞在接受媒体采访时表示，「人工智能的发展需要数据民主化以及越来越多的数据和模型，这是我们对 Kaggle 高度重视及收购的原因。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于这次收购，Kaggle CEO Anthony Goldbloom 在官方博文中写道：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我很高兴和自豪地宣布 Kaggle 正式加入谷歌云。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;七年前，我们发起了第一个预测欧洲歌曲大赛投票模式的竞赛。当时获胜者是 Jure Zbonar，他们击败了 21 支队伍，赢得了 1 千美金的比赛奖金。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从那时起，Kaggle 社区已经使用机器学习为高中作文评级、诊断心力衰竭，并加强对希格斯波色子的发现。在 Merck 比赛中，Geoff Hinton 和 George Dahl 为我们展示了深度神经网络的神奇力量，Tianqi Chen 使用 Kaggle Kernels 为社区引入了 XGBoost。Kaggle 的个人主页已经成为一张可以得到认可的证书，社区成员找到的雇主从 DeepMind 到沃尔玛不等。去年八月，我们发起了一个开源数据平台：https://www.kaggle.com/datasets，社区成员已经在这个平台上共享了数以百计的高质量数据组。我们已经一起取得了很多的胜利。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Kaggle 团队将继续团结在一起，也会成为谷歌云团队中一个独特品牌。我们也会继续增强我们的竞争力以及开源数据平台数量，也会继续将它们面向所有数据科学家、公司以及技术开放。Kaggle Kernels 也会继续支持一个多样的生态系统，包括谷歌支持下的机器学习库和工具包，也包括谷歌工具包之外的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;加入谷歌能让我们取得更多的成绩。这次收购将世界上最大的数据科学社区与世界上最强大的机器学习云联合起来，也是一个将我们的力量与 ImageNet 创造者李飞飞和李佳联合起来的良机，让人振奋。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;将谷歌云技术提供给我们的社区，我们就有能经常提供强大的基础架构，可扩展训练以及部署服务，也有能力存储和询问大型数据集。&lt;/span&gt;&lt;img src="http://img04.iwgc.cn/mpimg/808c02cb5bee80190c195da3c5143699df3aaf4e"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&amp;copy;本文为机器之心报道，&lt;strong&gt;&lt;span&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Thu, 09 Mar 2017 07:56:13 +0800</pubDate>
    </item>
    <item>
      <title>机器之心专访杜克大学Lawrence Carin教授：十年后，你的工作会被人工智能取代吗？</title>
      <link>http://www.iwgc.cn/link/ffb643e8c3a213e24642e5ad8729ca897393ad59</link>
      <description>
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：亚铁&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/4a7ee03122db4b563f50d0b189c460d8d83abdec"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;杜克大学副教务长 Lawrence Carin 教授&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Lawrence Carin 教授是杜克大学分管科研的副教务长，他于 1985 年、1986 年和 1989 年获得马里兰大学电子工程学本科、研究生和博士学位，并于 1989 年以助理教授身份加入位于纽约的理工大学电子工程系并在 1994 年成为副教授。1995 年他加入杜克大学电子工程系并被提名为 William H. Younger 杰出教授及电子工程系主任。Lawrence Carin 教授的早期研究专注于电磁学和感应，并在过去十年研究应用数据和机器学习。共著有或联合编写超过 300 篇学术论文并涉及人工智能、炸弹探测、视频分析、神经学、癌症、传染病、投票行为及音乐等不同领域。他在炸弹探测领域的研究帮助在北卡研究三角园区创办了一家 Signal Innovations Group 的企业并已雇佣超过 40 名员工。他最近出售了他在这家公司中的股份。Lawrence Carin 教授是美国电子电气工程师协会院士、Tau Beta Pi 和 Eta Kappa Nu 荣誉学会的会员。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2017 年 7 月 25 日至 8 月 3 日，即将迎来第二届杜克清华机器学习暑期课程。值此契机，本课程的独家媒体合作伙伴机器之心对作为该暑期课程组织者之一的 Lawrence Carin 教授进行了专访。专访中 Lawrence Carin 教授介绍了昆山杜克大学博雅通识教育的目标，及人工智能时代人不能为机器替代的能力；他如何用两年时间从初步认识机器学习到成为世界级专家；他作为一个创业者对中国创业者的建议；机器学习暑期课程对学员未来职业的影响；贝叶斯定理、机器学习之于杜克大学的意义；清华、杜克与昆山杜克大学在机器学习领域的合作等等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以下是采访正文。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;机器之心：您似乎是刚涉足深度学习领域。除了媒体的关注度还有技术上的突破外，深度学习对您的吸引力源自何处？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Lawrence Carin&lt;/span&gt;&lt;/strong&gt;：深度学习是一个很新的领域，虽然我可能不是最早接触这个领域的，但也不算太晚。我非常喜欢学习新事物，所以深度学习最吸引我的地方在于：它是一门新技术，并且也非常有前景，同时还因为我并不了解它。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;两年前的夏天，我决定开始研究深度学习。于是我大量地阅读和思考，试着用自己的方式理解和追溯事物。所以无论何种情况下，一旦开始钻研并理解一件事，我就会产生浓厚的兴趣，随之就会开始着手研究。我们专心致志研究深度学习已有两年的时间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;机器之心：这么多年，您的研究涉及的话题很广泛。是什么驱动了这么强烈的好奇心？您又是怎样探究各个领域并对其做出贡献？如何一层层探索各个话题的呢？能否和我们分享一些让您在各个领域都成为专家的「认知小技巧」？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;Lawrence Carin&lt;/strong&gt;：有一个很有名的统计学家，叫布莱克威尔，他几年前去世了。他是一个非常出名的统计学家。他说的一些话非常尖锐也很深刻，他的话大概能回答你的问题，也代表了我的想法。他说他从来没有做过研究，他只是喜欢去了解新事物。无论何时你去探索一些事，你就想弄明白它。有时候你研究了别人从没研究过的事物，那么你就可以出版你的发现。他说他的目标从来都不是写论文或者变得出名，他的目标就简简单单的是去理解发现一些事物。对我来说，这也是我的想法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;正如大概在十年前，压缩传感的概念出现了，很多人对此非常兴奋。我对于此一无所知，所以我决定去了解它。结果压缩传感一跃成为了重要的理论。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关于深度学习，我的态度也是一样的。研究深度学习的出发点从来都不是为了写论文或者其他，只是单纯地想要了解它。而在这个过程中，我们得出了一些原创的结果。不管如何，我就是这么做了，不仅坚持了很长时间，还会继续坚持下去。我很享受做研究。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;机器之心：无论何时您对一个领域产生了兴趣，就会在这个领域取得很多成果。您每年发表的论文数量远超过平均值。这么高效率的秘诀是什么？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;Lawrence Carin&lt;/strong&gt;：我认为在要求别人高效之前，我自己必须先变得高效。我的全职工作是副教务处长，有满满的日程安排。做研究并不是我的工作，只能称之为爱好。我做研究只有两个时间段，一是每天早上工作开始之前，我早上五点钟起床，六点到八、九点之间做研究；再就是在周末。如果你不热爱一件事，你就不能把这件事做好。这就是为什么我说做研究是我的爱好。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;机器之心：就像很多杜克大学人一样，您也信奉贝叶斯定理吗？您认为当一个人思考和研究机器学习的时候会大多数时候用贝叶斯思维吗？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;Lawrence Carin&lt;/strong&gt;：杜克大学非常崇尚贝叶斯定理，其中有一个非常有意思的原因。杜克是一个非常年轻的学校，虽然并不是像昆山杜克大学这么年轻，但仍然还是非常年轻的。杜克始终都在排名前十的大学内，而这些排名前十的学校里，大部分都有很长的历史，有些已经建校超过百年。而仅仅只有八十年历史，仍非常年轻的杜克大学，考虑到凡事不能尽善尽美，所以我们必须要有侧重点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;二三十年前，杜克决定向贝叶斯定理发展。我们不可能所有事都有伟大的成就，那么专注并专长于某一方面就尤为重要。恰好当时，贝叶斯定理还没有成为主流。在那个贝叶斯定理还没有传遍世界各地的情况下，使得将贝叶斯定理做到最好就变成了可能。10 年或 20 年前，贝叶斯观点和优化观点或者称之为频率论者观点之间有着非常严峻的竞争，事实上，这两个观点一直都处于斗争中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而现在，人们意识到，这两个观点各有千秋，他们各自扮演着不同的角色，发挥着不同的价值。两者的竞争也在逐渐消失。在机器学习中，优化观点和贝叶斯观点之间的分歧也并不像曾经那么引人注目，而且也不像在统计学中那么显眼了。在任何情况下，贝叶斯观点在机器学习中都是非常强的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;机器之心：您在机器学习领域展现了极强的数学能力，您也同样很关注理论方面的东西，您对于深度学习的效率方面是怎么看的呢？数学的哪个方面能够解释深度学习？在您心中，哪一个理论能用来解释深度学习呢？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;Lawrence Carin&lt;/strong&gt;：我们没有一个明确的理论支撑。正如我所说，两年前我决定开始了解深度学习时，我的目标不是来写论文而是纯粹的理解。所以我认为，渐渐地，深度学习不会再神秘，这也是我一直在向学生们传达的东西。我在之前发表的公开演讲提到了深度学习，用图片和图形来解释了深度学习，这些都是毫无疑问地想向听众传达为什么深度学习是成立的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;和深度学习最接近的是小波。小波是几年前由杜克大学的 Ingrid Daubechies 教授发现的数学领域内的一个理论。小波是一个多角度的数据表达，深度学习也正是如此，多角度的表达。这两者既有区别又有联系。这很有意思，因为深度学习能很好地解决现实问题。所以然和领域都是一个阶段一个阶段发展起来的。大概在七年前，在深度学习还没有出现之前，在机器学习领域最流行的是理论，你必须有证据，你必须有理论支持。那时对于理论是很强调的。结果就是出现了压缩传感。压缩传感在深度学习出现之前是有很大意义的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;压缩传感流行的时候，我很想去理解压缩传感，所以我们研究了压缩传感。大概在 5-7 年前，做研究必须要有理论支撑。有一次有一些研究深度学习的人来找我，他们没有理论，没有定理，但他们有很好的结果成绩。他们真正的改变了机器学习的范例。现在，研究的重心都在于得到好的结果，在于做一些在现实中有意义的事情。当你研究理论的时候你要估计要猜测，但这些可能在现实世界中并不适用。但无论何时我们解决很大规模也很复杂的实际问题的时候，人们是没有耐心研究定理的。就像「好吧，你去研究你的定理吧，做完了告诉我一下。我要去解决实际的问题了。」所以在这就有了一个心态上的变化，这种变化在我看来是很有益的。我觉得之前太侧重理论了，但之后肯定还会出现侧重理论的时候。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有意思的是，当 Yann LeCun 和其他团队研究深度学习的时候，他们说「深度学习真好啊」，他们当然会说深度学习好因为他们就是研究这个的。但无论什么时候别人，就像我，不是第一代开创深度学习的人来研究深度学习的时候，深度学习是成功的。我们就像是独立的验证程序一样，都说深度学习是成功的。你研究的越多，就能得出越多的例子，当你把深度学习应用到实际问题的时候，你会得到很好的结果。当你一遍一遍看这些结果的时候，你就会意识到，深度学习并不是一种转瞬即逝的潮流，而是会一直存在，成为我们的工具箱里的一种工具，不会消失，它是非常真实的。经过一段时间，我们会有一些理论，但这些理论很可能也不会脱离现实。有一些很有意思的故事如果有时间我会讲给你。但是在理论和实践之间肯定有一些妥协，但现在实践是占了上风的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;机器之心：深度学习在演讲和计算机视觉方面都得到了很好的应用。但如果想把它变成一种更可行的计算机科学，在自然语言处理上必须取得突破。你觉得深度学习的发展能革新自然语言处理吗？或者说如果自然语言处理不能取得进展，深度学习就会失去发展势头吗？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;Lawrence Carin&lt;/strong&gt;：我们在自然语言处理上取得了很显著的进展。虽然最深处的东西可能是也可能不是最重要的东西，但就机器学习而言，很多最新的科技都已经取得了进展，对于自然语言处理也是有革新性的影响，对于这整个领域来说也是有革命性的作用。我对于自然语言处理的未来很乐观，是我最乐观的领域之一。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;机器之心：所以您是说方法论的复杂程度并不是成功的关键？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;Lawrence Carin&lt;/strong&gt;：是的，这些模型都不一定很深刻。它们可以变得很深刻，但不必要。一些基本的概念几年前就出现了，但是慢慢地才有变化，也被证明非常有效。一些深度学习领域的东西可能是，也可能不是最重要的事。但关键的是神经网络，那是一种设置，我们最后也发现这种设置是很关键的。我们最近做的就是把贝叶斯公式和这些科技都结合起来，然后延展到其他许多领域。无论是哪种情况，我都对于我们现在在语言处理上取得的进展感到很乐观。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;机器之心：您创建了一个公司叫 Signal，后来被 BAE Systems 收购了。在一些程度上您是一个很成功的企业家。但现在，人工智能吸引了很多的注意力，很多新兴公司都把发展人工智能科技作为他们未来的目标。对于中国的这些想要利用人工智能科技发明一些新东西，革命性的东西的企业家，您有什么想说的吗？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;Lawrence Carin&lt;/strong&gt;：就像你说的，我确实创建了也出售了一个公司。而我想说，管理一个公司不是一个线形的过程，它也不会按着你期待的方向走下去。在商业领域，最重要的就是关注顾客需求。无论何时你创建了一个公司，你肯定对于你怎么进行下去，你想卖出什么商品有了一些点子。但是进入现实世界时，你所想的很重要的东西，和你交流的人不一定认为他很重要。而你所认为的很微不足道的东西，这些人可能觉得很重要。所以，最重要的就是要接纳别人的意见，要聆听，要灵活。也必须明白，只要你做实验，你就会遇到困难。我们公司就遇到过很多挑战。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一个建议是，要仔细挑选你的商业合作伙伴。你成功时身边的合作伙伴不一定是你当初开创公司时的身边伙伴。那是因为你是和一群人一起工作的，创建一个公司也是很艰难的过程。因为它不会像你所想地一样发展，你得做出改变，也要应对挑战。当你和一群在压力和挑战下的人一起工作时，你会看到他们身上不同的方面。他们的做事风格不一定和你设想的一样。所以我说你要谨慎挑选你的伙伴。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我得到的另一个教训，可能听起来不太愉悦，但是我觉得是真理：当你开创公司时，一定要请一个很好的律师。也要确保他们制定好这个公司的法律架构。开始时你会觉得一切都很好，每个人都像朋友一样。但慢慢地，你就会意识到各种各样的挑战。我可以告诉你，我开始时是很天真的。但幸好我们有一个很好的律师。我们没进入现实社会时，我还没有意识到一个好律师的重要性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;开创并且运营一个公司是很艰难的，一点也不浪漫。当你回头再看时，你创建了一个公司，你又卖掉了它，听起来很不错，听起来很激动人心。回头再看这段经历是很好的，但是在过程中确实很艰难也很有挑战性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;机器之心：很多计算机科学专业的学生想去谷歌 Facebook 这样的大公司工作。您认为这一项目（杜克清华机器学习夏季课程）将如何以及和在何种程度上帮助到这些学生的未来职业或者研究生涯呢？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;Lawrence Carin&lt;/strong&gt;：对于学生来说，这是他们初次接触到机器学习。这一课程将会从不同视角涵盖很多领域：贝叶斯定理视角，最优化视角。经研究人们会根据自己的性格选择自己倾向研究的领域：所以喜欢贝叶斯的是一种人，喜欢最优化的是另一种人。因此这给学生一个机会，让他们认识到自己适合的领域。当然最重要的是我希望他们能够得到鼓舞，毕竟没什么能够取代努力。在这样的课堂上，你不会学到如何成为一个机器学习领域的大师。学习的方式是你自己静静的端坐几个小时，不断阅读、思考，因为这是一个非常复杂的领域。但这给他们机会让他们看看自己到底能走多远。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于学生来说，这是他们初次接触到机器学习。还有就是很多导师都是都是年轻人。我们有来自哥伦比亚大学的年轻教授，还有来自德克萨斯大学奥斯汀分校的年轻教授，这位教授还是个中国人。这样中国的学生就会发现原来我的同龄人也可以在像德克萨斯大学这样的世界顶尖学校任教，这对他们的激励作用不言自明。因此我希望这能激励他们，让他们觉得自己也可以做到。当学生们以后在 Facebook 或者谷歌或其他企业工作又或者成立了自己的公司时，回想起这节课，他们会说这节课鼓舞了他们，而不是在这堂课上我学习了我需要知道的知识，因为要学习的知识永无止境。我对这批学生印象非常深刻，他们认真努力。有些事情我们过去是不知道会发生的，但是他们确实发生了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;机器之心：您认为清华、杜克和昆山杜克大学在机器学习领域会迎来怎样的合作？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;Lawrence Carin&lt;/strong&gt;：杜克清华机器学习暑期课程把「杜克」这个品牌带到了中国。清华大学原本在世界上和中国都是一流的大学。把杜克和清华结合起来影响力何其之大。我们想继续举办这样的活动有以下几个原因：第一，这些活动能提高杜克大学和昆山杜克大学在中国和国际上的知名度。第二，在杜克，这样的活动相当于实验，因为我们是在这建立一所真正的大学，我们也准备开设本科项目。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;机器之心：和昆山杜克大学一直以来追求的博雅教育相比，人们当然也需要学习如何工作、如何编码，但是您觉得还有哪些重要品质需要与学习编码相结合？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Lawrence Carin&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：当人年轻时，人们会认为技术是最重要的。可是当我年纪大些，我才发现精英之所以能成为精英是因为他们的人际交往能力，他们能与其他人进行有效的沟通，与他人相处的很好，有团队精神，可以应付各式各样的人，明白生活并不总是顺心如意，能够在控制自己适应这个社会。我认为这些技能是十分重要。实际上当人类的生活变得越来越自动化，当机器学习占据的位置越来越重要时，机器能够做到的事情就变得不那么重要了，毕竟这些事仅仅靠机器就可以解决。做一个有智慧的人，做一个会交流的人&amp;mdash;&amp;mdash;包括口头和书面交流，做一个善于理解的人。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我的意思是我们现在在中国，我不是一个中国人但我得在中国工作，我需要了解中国的风俗习惯，我需要了解如何在中国与人相处。因此我认为这些技能反而越来越重要了。但与此同时，你也要将这些技能和技术结合起来。如果你能够将他们结合起来，那你身上就有了那些重要品质。我的学生遍布世界各地，我经常和他们聊天。我记得其中有一个在英特尔担任相对而言还是比较高层的职位，他和我说「Larry, 你知道吗，他们将我提拔到了这个位置，我们组的人都是斯坦福和麻省理工毕业的，他们提拔了我。」这些有特殊才能的人经常并没有意识到自己其实很特别，这正是他们的特别之处。他其实有着非常好的人际交往能力，因此他和那些来自麻省理工的人其实一样优秀，他能够用别人想不到的方式和他人交流。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此我觉得，在昆山杜克大学，我们和学生都需要行动起来。这真的很重要。你要知道，如果你在谷歌编码，你不会想听一些压根不懂技术的经理说话。假如他对你指手画脚，你肯定会想：你有什么资格告诉我怎么做，你根本什么都不懂。因此在谷歌人人都要掌握技术。但如果我们将人际交往能力和技术结合起来，你就真的真的变得非常「稀有」了。想想我们在昆山杜克大学要做的，不就是能够培养出一些珍稀人才吗。我们不是一个大规模的学校，我们只是一个「小」学校。因此如果我们能够找到那些独特的人，那些能够将人际交往能力与技术能力结合起来的人，他们将来一定会成为领导者。我的意思是像哈佛和杜克这样的学校能够孕育出领导者的秘诀就在于小规模办学。俄亥俄州立大学这样的大规模学校就很少出现领导者，虽然从它的基数考虑，它应该孕育出不少。我们希望至少一部分杜克的学生是那些真的具有特别之处的人，我们感到很幸运能够在杜克遇到他们。这些特别的人无论如何都是特别的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;机器之心：对于未来的人才，您还有什么建议吗？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;Lawrence Carin：&lt;/strong&gt;最后，我想以一个有趣的小故事结束这个话题：我有一个学生 John Paisley，他是杜克的本科生，他出生在威斯康星州的密尔沃基，他从未了解过中国人，也从未见过中国人，更没接触过中文。但是他在杜克上学，这立马就告诉你他其实很聪明。除了聪明，他也是一个特殊的人。发生了什么呢？当他跟着我上研究生的时候，他开始关注周围的中国人，尽管他以前从没见过。大多数美国人见到中国人是这么个态度：好吧，你是中国人，没什么不好的。但我也没兴趣了解你，你反正要和我说英语，就这样吧。换句话说，你要向美国人靠拢，我会以对待美国人的模式对待你。但我真的不是很想了解你。但 John 不是这么想的。John Paisley 在这边讲学时，他听中国人说中文。他从没接触过。然后他看中国人写字，他会发出这样的感慨：「哇，这真有趣」。因此他开始自学中文，学习怎么写，怎么说。实际上他还考了中国的 GRE，在中国上学。这不仅仅是因为他要去一个中国学校，更因为他想证明自己可以做到。他真的做到了。他在清华任教，最后去了哥伦比亚。像这样的人就是特别的。他技术过关，对这个世界充满好奇，因此想了解中国，他学习了中文，又是一个极佳的沟通者，一个优秀的写作者，一个出色的演讲者。因此 John，是一个领导者。领导者将对世界的理解好奇与高超的技术结合起来。像 John Paisleys 这样的人少之又少。&lt;/span&gt;&lt;img src="http://img04.iwgc.cn/mpimg/808c02cb5bee80190c195da3c5143699df3aaf4e"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;点击「阅读原文」查看「杜克-清华机器学习夏令营暑期课程」详细内容。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&amp;copy;本文为机器之心原创，&lt;strong&gt;&lt;span&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Thu, 09 Mar 2017 07:56:13 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 滴滴美国研究院落户硅谷，揽入全球高端人才</title>
      <link>http://www.iwgc.cn/link/24978ddd11bc73bc9935ba949ed96614fb8c00ff</link>
      <description>
&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;机器之心报道&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：吴欣&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;滴滴出行今日正式宣布在加利福尼亚硅谷成立滴滴美国研究院，以吸引顶尖科研人才，推动交通产业变革。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;美国研究院将配合滴滴大研究网络，持续把研究成果转化为生产力，积极助力国际化战略，用创新科技的力量，为更多城市打造前瞻性的整体交通方案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;滴滴出行创始人、董事长兼 CEO 程维表示：「全球交通和汽车产业正面临深刻变革。滴滴作为规模领先的移动出行平台，已经投资于全球五大共享出行领袖。基于海量的出行数据，我们正在驱动人工智能技术迅速迭代升级，与城市管理者共建智慧交通体系，创造未来出行新生态。作为世界级的科技公司，滴滴的国际化战略不仅着眼于为全球更广泛的社群提供便捷优质的出行服务，也包括构建高水准的跨境科研网络，促进创新资源的协同，引领全球交通领域的技术革新。美国研究院的成立是滴滴这一技术创新体系构建上的里程碑式突破。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;美国研究院由滴滴研究院副院长弓峰敏领导，目前已有许多杰出的数据工程师和研究人员加盟，包括世界顶级安全专家查理&amp;middot;米勒（Charlie Miller）。预计今年滴滴美研团队规模将有大幅提升。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/965465d00c7c2f164fe65677f4d24a65858c93b5"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;查理&amp;middot;米勒被业界誉为「全球最杰出的安全专家」。公开资料显示，Charlie Miller 曾就职于苹果、Twitter、Uber 等公司，作为安全领域顶级专家，Charlie Miller 撰写了三本信息安全有关书籍，且曾四次获得 CanSecWest Pwn2Own 大赛冠军，2015 年还成功对吉普切诺基车型进行了远程控制实验，震动汽车界，由此查理&amp;middot;米勒也被认为是最有可能改变汽车历史的安全工程师。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;span&gt;据查理&amp;middot;米勒介绍，其将在滴滴美国研究院主要负责核心前沿业务，如保障智能驾驶的安全性，保护车辆上的代码不受侵犯，让开发、测试、审核过的代码高效安全地为车主和司机服务等。在谈及为何加入滴滴时，查理&amp;middot;米勒表示，当前智能驾驶领域并未有明确的单一的领先者，这还是一个开放的赛场。「滴滴是全球交通技术的领袖，其技术工程团队成熟、富有经验，且正坚持不懈地推进前沿科技创新，在业内有卓越声誉，作为一个全球科技公司，滴滴完全有能力成为人工智能、智能驾驶等领域的主要参与者」，米勒说。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;滴滴出行 CTO 张博在硅谷出席「滴滴-UDACITY 无人驾驶大挑战」启动式时表示，未来十年，滴滴将利用全世界最丰富的出行数据，在三个层面实现创新突破：改变人与汽车之间拥有和使用的关系，引领新能源汽车和新智能驾驶安全技术的应用，并将大数据能力系统地应用于交通基础设施的优化。滴滴欢迎有志于推动科技变革的杰出人才加入团队，共同解决世界级的交通和环境挑战。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;滴滴-Udacity 无人驾驶大挑战是全球首个智能驾驶车开源项目。比赛选手将以海量的真实数据为基础，创建自动化安全和感知处理栈系统 (ASAPS)，用以提升人类和智能驾驶的普遍安全性，即创建一个冗余、安全、可靠的系统，用于识别路径上的行人、车辆及其他障碍物。ASAPS 技术对人类驾驶员和各类辅助驾驶、智能驾驶系统都具有极大意义。参赛者需要处理 LIDAR、RADAR 及摄像头原始数据等信息，输出障碍物位置、移除噪音和环境错误检测。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;排名前五的团队将受邀前往尖端科技企业云集的硅谷与相关领域的顶级科学家进行决赛答辩与交流；他们的代码将在 Udacity (优达学城) 的无人驾驶车上实地运行比拼。此外，比赛冠军将获得 10 万美元奖金，而参赛优胜者还将有机会加入滴滴，和全球领先的智能驾驶技术团队一起工作。&lt;/span&gt;&lt;img src="http://img03.iwgc.cn/mpimg/808c02cb5bee80190c195da3c5143699df3aaf4e"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&amp;copy;本文为机器之心报道，&lt;strong&gt;&lt;span&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Thu, 09 Mar 2017 07:56:13 +0800</pubDate>
    </item>
    <item>
      <title>IBM宣称人类语音识别词错率实际应为5.1%，自家系统已突破至5.5%</title>
      <link>http://www.iwgc.cn/link/de544355204037954246537ee1a3cdb0b10a657f</link>
      <description>
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自IBM&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：George Saon&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀、黄小天&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;去年十月，微软人工智能与研究部门的一个研究者和工程师团队报告他们的语音识别系统实现了和专业速录员相当甚至更低的词错率（WER）&amp;mdash;&amp;mdash;达到了 5.9%，参考机器之心文章《&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719843&amp;amp;idx=1&amp;amp;sn=0c6387d422cf9765b9b10c178d160680&amp;amp;chksm=871b021db06c8b0b0b0447124c5c07818f53a17ba470305049af1d7d49806c87e07307a93811&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719843&amp;amp;idx=1&amp;amp;sn=0c6387d422cf9765b9b10c178d160680&amp;amp;chksm=871b021db06c8b0b0b0447124c5c07818f53a17ba470305049af1d7d49806c87e07307a93811&amp;amp;scene=21#wechat_redirect" target="_blank"&gt;重磅 | 微软语音识别实现历史性突破：语音转录达到专业速录员水平（附论文）&lt;/a&gt;》。但 IBM 官方博客今日发文宣称人类的水平实际上应该是 5.1%，而同时该文章还表示 IBM 的系统的词错率已经超越了之前微软报告的最佳水平，达到了 5.5%。IBM 宣称这是一个全新的突破，但相关研究论文似乎仍未发布（我们未能找到），机器之心将继续保持关注，期待能在第一时间向读者分享这一成果的技术细节。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以下内容编译自 IBM 博客：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/d0b3bcd6cfe46ba8fc33f9d9d5358113bb3a7859"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;此篇博客日期与标题&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在交谈中，人听到的每 20 个词之中便会漏听 1 至 2 个。5 分钟的对话里，我们有可能漏听 80 个单词。但是，这并不妨碍交谈。试想一下，这种情况换成计算机会怎样？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;去年，IBM 宣布在会话语音识别方面取得重大进展，把语音识别的词错率降至 6.9%。自此之后，词错率一降再降，直至今天的 5.5%。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;词错率的测定来自一个困难的语音识别任务：记录人们之间日常的诸如买车之类的话题交谈。这个被记录的语料库称之为 SWITCHBOARD，20 多年来一直是语音识别系统的检测标准。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;IBM 集中扩展深度学习应用技术终于取得了 5.5% 词错率的突破。我们结合了 LSTM 模型和带有 3 个强声学模型的 WaveNet 语言模型。这 3 个使用的声学模型中，前两个是 6 层双向 LSTM，其中一个具有多特征输入，另一个则通过说话者-对抗多任务学习进行训练。第 3 个模型的独特之处在于可以从正负两个样本中进行学习。因此 IBM 的系统变得越来越聪明，尤其是在相似语音模式重复之处，表现更佳。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;达到像人一样交谈的词错率，长久以来一直是业界的最终目标。其中一些宣称实现了与人持平的 5.9% 的词错率。作为今天成就的一部分，我们重新确定了人的实际词错率为 5.1%，比之前达到的还要低。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们的合作者 Appen 提供了语音和搜索技术服务，帮助我们最终确定了人的真实词错率。实现 5.5% 的词错率是一个大突破，但人类实际词错率的确定表明我们还没有达到最终目标。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;作为研究努力的一部分，我们联合其他业界专家获得了他们的语音数据。蒙特利尔大学 MILA 实验室领导者 Yoshua Bengio 认为，要达到像人一样，我们仍然要付出更多努力：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「尽管近些年来有这些了不起的进展，但要在语音识别和目标识别等人工智能任务中实现人类水平的表现仍然是一项极具挑战性的科学难题。实际上，标准基准并不总是可以体现真实数据的多样化和复杂性。比如说，不同的数据集可能对一个任务的不同方面有更多或更少的敏感度，而且其结果严重依赖于人类表现被评估的方式，比如在语音识别的案例中使用技能娴熟的转录员。」Bengio 说，「IBM 通过将神经网络和深度学习应用于声学和语言模型，一直在语音识别上取得显著进展。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们还意识到要在整个行业领域找到一种标准的测试人类表现的方法比预想的要复杂得多。除了 SWITCHBOARD，这个行业的另一个语料库 CallHome 提供了另一组可供测试的语言数据，这个数据集是根据家庭成员在没有预先固定主题上进行的更加口语化的对话而创建的。比起 SWITCHBOARD，来自 CallHome 数据的对话对机器而言更难以转录，这使得在其上的突破更难以实现。（在这个语料库上我们实现了 10.3% 的词错率&amp;mdash;&amp;mdash;这是另一个行业记录；但同样，通过 Appen 的帮助，在同样情形下的人类的准确度是 6.8%）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此外，在 SWITCHBOARD 测试时，在测试说话者数据中一些同样的人类声音也被包含在了用于训练该声学和语言模型的训练数据集中。因为 CallHome 没有这样的重叠，所以其语音识别模型没有接触到测试说话者的数据。因为这个原因，就没有重演（repetition），这会导致人类表现和机器表现之间出现更大的差距。随着我们继续努力向人类水平进军，我们在能够利用这些重演的深度学习技术上的进展在帮助我们最终攻克这些难题上发挥了前所未有的重要作用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;哥伦比亚大学计算机科学系教授兼主席 Julia Hirschberg 对一直以来语音识别上的复杂挑战评论说：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;要达到和人类一样的识别语音的能力是一个持续性的挑战，因为人类语音，尤其是在自发性的对话（spontaneous conversation）中的人类语音，是非常复杂的。而且我们也很难定义人类的表现，因为人类在理解其他人的语音上的能力会各有不同。当我们将自动识别和人类表现进行比较时，需要考虑两件很重要的事情：在被评估的同样的语音上识别器的表现和人类的表现。因此，IBM 最近在 SWIRCHBOARD 和 CallHome 数据上的成就是非常了不起的。而且 IBM 一直以来都在努力想要更好地理解人类理解这两个得到广泛引用的语料库的能力，这也让我印象深刻。这项科学成就在当前 ASR 技术上的表现是很了不起的，也表明我们仍然有一种让机器比肩人类语音理解的方法。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今天的成就是我们在语音技术上的新里程碑。之前，比如说去年 12 月份，我们为 Watson 语音转文本服务增加了语者分类（diarization）功能，这是在区分对话中的个体方面的一项进步。这些语音进展构建于数十年的研究的基础之上，而且实现人类水平的语音识别是一项复杂的任务。我们将继续努力创造未来有一天能够达到人类所听、所说和所想的复杂度的技术。尽管我们为我们的进展而鼓舞，但我们的工作还依赖于未来的研究&amp;mdash;&amp;mdash;而且更重要的是，要致力于实现可能的最高标准的准确度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;原文地址：https://www.ibm.com/blogs/watson/2017/03/reaching-new-records-in-speech-recognition/&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;span&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Wed, 08 Mar 2017 11:52:40 +0800</pubDate>
    </item>
  </channel>
</rss>
