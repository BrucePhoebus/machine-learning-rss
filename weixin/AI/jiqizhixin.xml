<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>独家 | Yoshua Bengio研究生科研指导演讲：解读人工智能全貌和下一个前沿</title>
      <link>http://www.iwgc.cn/link/4034091</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：Joshua Chou&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;近期，Yoshua Bengio 在加拿大多伦多大学 Distinguished Lecture Series 面向计算机及工程方向的硕博研究生进行了一次题为「从深度学习到人工智能（From Deep Learning to AI）」的学术研究方向指导讲座，机器之心技术分析师 Joshua Chou 亲历了这个讲座，并对其中的关键内容进行了梳理和总结。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1. 引言&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;几经波折之后，人工智能终于要来了；它将给我们的社会带来巨大的变革，甚至可能会引发一场新的产业革命。毫无疑问，机器正变得越来越智能，而在这一次智能革命的中心，由大脑所启发的深度学习正在扮演着极其重要的角色。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicicgLZmjFhKnsYxCMx43wia66azyWSWOzAjcQHicpNb4JyfVaZR3sd4hG3YpiayMfkrcAFkfpdftkB9Q/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我很高兴能够参加 Bengio 教授的演讲，并且希望能够将他传递给学生的观点再分享给更多的人。这篇文章中的一些材料来自其演讲所引用的论文，尽管我没有足够的时间仔细阅读所有这些论文，但我将尽我所能给出这些论文的概述以及它们与这个演讲的关联。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2. 深度学习领域的突破&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicicgLZmjFhKnsYxCMx43wia67IGN1aibJKrULCia2gGPMqiaClp8tibLyHfiaxb7ABxwiaiaX7bmH2frvovBw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先值得一提的是，多亏了加拿大高等研究院（CIFAR）的不懈努力，深度学习领域内的很多突破都诞生在了加拿大这片土地上。过去十年来，CIFAR 一直在给许多教授的团队提供资助，其中包括多伦多大学的 Geoffrey Hinton 教授、纽约大学 Yann LeCun 教授和这一次的演讲者、蒙特利尔大学的 Yoshua Bengio 教授。今天，深度学习科学家已经找到了训练更深度的神经网络的方法。但在此之前，科学家们还尝试过很多不成功的训练方法，而不成功的原因则是那时候人们对训练更深度的神经网络还缺乏了解。事实证明，深度（depth）问题是很重要的，深度学习也由此得名——而它本质上是之前十年在神经网络之上的研究的延续。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深度学习的每一个典型案例都涉及到分段非线性单元（piecewise non-linear unit），这一成果是在多伦多大学和蒙特利尔大学的研究成果之上不断积累得到的。这些成果表明，我们可以使用这种分段非线性变换（piecewise non-linear transformation）来训练比之前远远更深的神经网络。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;过去几年里，这一重要的研究结果为我们带来了语音识别等应用（第一款产业界的语音识别应用出现在 2010-2012 年之间）。到 2012 年的时候，只要你有一台安卓手机，你就有了一个可以为你进行语音识别的神经网络（「okay Google」）！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一个远远更大的领域是计算机视觉，它也在一两年之后实现了应用。同样，来自多伦多大学的研究突破也发挥了重要的作用，这些研究将之前的很多思想都集中了起来，并且还带来了更大的改进。这些改进不仅仅是在算法上，而且也涉及到借助硬件的进步来实现更快的计算处理。比如说，研究者发现最初为图形和视频游戏处理所设计的 GPU 碰巧非常适合用来训练神经网络；几年之后，斯坦福大学教授李飞飞启动了 ImageNet 数据集项目，该数据集带有大量有标注的数据，已经帮助许多研究者和开发者实现了很多深度学习应用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前来说，深度学习主要还是基于监督学习（supervised learning），并且还需要数百万有标注的图像来进行训练。实际上，我们可以看到在过去的四五年里，这些深度神经网络的准确度一直在不断提升（了解更多可参阅论文《ImageNet Classification with Deep Convolutional Neural Networks (Sutskever, Hinton, Krizhevsky)》）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3. 用机器学习实现人工智能的关键要素&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;要让机器学习系统接近人类水平的表现，我们通常需要一些关键的要素。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先，你需要大量乃至巨量的数据。为什么呢？因为智能意味着正确地决策；而为了做出正确的决策，你需要知识。研究者所面临的一个核心问题就是如何好好使用知识。这个世界很复杂，如果要让机器理解世界的水平达到人类同样的程度，那么我们就将需要给机器描述大量的知识。为此，我们需要通过大量的数据来训练机器，从而使其能够以一种类似于人类能力那样微妙的方式来进行理解。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其次，为了利用数据，模型还必须要足够灵活。（许多传统的统计模型仅仅是将数据编译成不同的参数集合，这样的模型是很死板僵硬的。）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第三，为了训练机器，我们还需要大量的算力，这方面我们早就实现了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicicgLZmjFhKnsYxCMx43wia6nSJdMoAOWHtAjCzzFBufPsuibHLgt5b1ZpowmmCm6TySNBSwxKb7INQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第四，关于神经网络还有一个更加微妙的细节：一旦你训练好了一个神经网络，你就可以非常高效地使用它，而且仅需要非常少的计算。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，另一个重要的要素是这个世界中已有的假设，它们可以被看作是我们训练的先验知识，它们非常强大，足以应对「维度灾难（curse of dimensionality）」。维度灾难是这样一种情况：当存在大量的变量时，配置（configuration）的数量也将随之指数级增多；因此我们只能针对大多数配置寻找正确答案，而不是针对所有的配置。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在后面的章节中，我们将重点关注最后一个要素。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4. 学习中的维度&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;主要的假设本质上都是关于组合的世界的假设，它们内建于深度网络之中——这解释了深度网络的表现如此良好的原因。我们认为知识生成来自于我们将碎片组合起来的过程，而我们推导给定的答案也是通过将碎片化的信息构建到一起。比如说，语言就有这样的性质——我们定义语言中的每一个概念都是通过组合已有的概念进行定义的。而在之前的机器学习领域，这还是无法实现的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;更确切来说，在深度网络上，我们有两种实现组合性（compositionality）的方式。其中一种可被看作是一种并行的方法，而另一种则是序列式的方法。人类可以并行地选择不同的概念来进行组合，然后以非并行的方式来描述世界。这就是分布式表征（distributed representation）的理念，这意味着每一个对象都会被许多属性（这在神经网络中被称为特征（feature））描述，而这些属性配置的数量将会随属性数量的增长而指数式地暴增。序列式的方法则必须涉及到这一事实：当我们将在并行步骤中所获得的结果组合起来时，我们每一次都要执行一个运算序列（sequence of operations）（可以将这看作是神经网络中的多层面特征学习）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;5. 非分布式表征（Non-distributed Representations）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这只是 Bengio 教授在深入到分布式表征之前所给出的一个例子。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;许多机器学习算法工作的方式都是获取一个输入空间（input space），然后将其分解成一个决策树（decision tree）（想一想在一些 n 维空间中分隔点的超平面）。对于该决策树中的每一个区域，我们都有一个来自构成那片区域的样本的答案（值得注意的一个重点是：可区分的区域的数量与参数的数量成正比）。很多人在很多时候会认为这是一个解决问题的好办法，但我们还能做到更好吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;6. 对分布式表征的需求&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicicgLZmjFhKnsYxCMx43wia6c2DmV6FR91mZJ1qdZt02x7EBxPOq0Np29FS4icnPqyFNx5dUMjYYURw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从统计学的角度来看，需要了解的一个重要问题是参数的数量（或样本的数量）与可区分的区域（这能给我们提供关于其函数复杂度的见解）之间的关系。在这里，我们需要思考一个重要的问题：我们可以泛化到我们从未见过其中任何数据的区域吗？在这种情况下，答案是否定的。我们需要看到每一个区域的数据，因为每一个区域的参数都是特定的（对于每一个区域而言，都存在一个单独的参数集，其中至少有一个参数能告诉你答案对应于哪一个区域）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicicgLZmjFhKnsYxCMx43wia6pibOa9cLEKicUBr2q6RXW1YAHoAmCbosXDnjZ1ibwyc2IyuvpPe0oiaf4Q/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当我们使用分布式表征时，我们的做法是给每一个输入都匹配一个属性集合。然后我们定义以组合式的方式获得的输入空间的区域。比如说，让该属性参数属于一个二元集。对于每一个属性，我们都可以将其看作是能够将一个空间分隔为两个区域的超平面。其中一个区域对应的属性值为 1，另一个区域对应 0。由此，可以很容易理解当属性（超平面）的数量增长时，可区分的区域数量将随之指数式的增长。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在的问题是我们希望学习的功能能否通过这种方式进行分解？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicicgLZmjFhKnsYxCMx43wia6ibWZVjwAmjZNdPDz9iaWXosCUC0G4IVQkgMDiapQBvgWG23u93RYF72icA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里的窍门在于我们会对这个世界进行假设。幸运的是，这个世界是组合式的，因此也遵循这一假设。比如以图像作为输入为例，你可以思考一下与这张图像相关的属性向量——是关于男性/女性、杯子/不是杯子、孩子/成年人……你可以使用这些属性向量描述很大图像集，而我们无法获得这个数量的用于学习的样本。但是，如果我们将这个空间分隔成可区分的区域，我们就可以分别从这些属性中学习。总的来说，在无需涉及其它特征而导致的指数级配置增长的情况下，每一种特征都可以被学习到。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;7. 深度的先验知识（Depth Prior）可以发挥巨大的作用&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicicgLZmjFhKnsYxCMx43wia6chzL12wenfUuXeT5BvBU4fxjFU55CV6yPEeN9APKUd8gt1JYdXSUmw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你使用了一个足够深的神经网络，那么你确实可以有效地表征一些类型的功能；但是大多数功能使用深度网络也没有优势。如果你希望学习的功能落在这个非常严格的组合式类型范围内，那么你就能通过深度网络获得巨大的好处。有很多论文都说明了，除了分布式表征之外，你也可以有很多的层（layer），当我们计算区域的数量时，我们也可以看到区域的数量会随层的数量指数级地增长。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicicgLZmjFhKnsYxCMx43wia60OpHDZCOhQYkSP9vnJ6ZrAVQbEqYMF3sr66hGvbibAd0DC3DibX38eww/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;8. 并不需要凸性&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在过去，研究者真的会害怕局部极小值（local minima）的麻烦。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicicgLZmjFhKnsYxCMx43wia6DvCtCadyDTAjhfcW7I6wqMIbHhWetdEDtICpdicsicHjicoOzRA5D1nsw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关于这一主题的一篇论文《The Loss Surfacesof Multilayer Networks (by Choromanska et al. 2015)》通过实验表明：随着问题的维度的增长，你的解决方案的损失（loss）的变化会减少。所以基本上来说，在最佳方案和最差方案之间的差距会缩小，而你所有的局部极小值都将最终变得差不多一样。所以非最优解决方案（non-optimal solution）的思想已经差不多一去不复返了，因为人们并没有真正解决这个问题，而只是将其变成了一个非问题（non-issue）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicicgLZmjFhKnsYxCMx43wia6EQ4IiaDicJsZ9ibTh6qk3gUYsM81UZZCBswvR4aWhsPN0yzHmHCa2rHsw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个观点本质上是来自于这样一种直觉上经验：局部极小在低维度条件下是最佳的，但鞍点（saddle point）主导了高维。你可以这样思考：任意一个所有方向都是上升的局部最优（鞍）点随维数指数级变小。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;span&gt;9. 超越模式识别、走向人工智能的深度学习&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicicgLZmjFhKnsYxCMx43wia6jNv0OuuKOtomt0bXgItutXFfvlfepgOqpXRcFHwzibLiaqyK90JImicWw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;神经网络正在从其传统的保留地（目标识别、模式识别等）走向传统上与标准人工智能相关的领域（推理、逻辑等）。在这一运动中，Bengio 领导的研究组曾经发现了一种被称软注意（soft attention）的机制。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;10. 深度学习的注意机制&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicicgLZmjFhKnsYxCMx43wia65oLkcibZRbKe9gRRJXsxKRLl7Ra0gfo1neKwHFPuZ51kzuLwN9Zjicfg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个最好通过一个例子来解释。当我们在从左向右一次翻译一个词地将法语翻译成英语的时候，如果能够注意到每个词在原法语句子中的位置，那么就会给我们的翻译结果提供很大的帮助；因为在一个句子中，一个词可能会给其后面的词带来很大的影响。事实已经证明，这种注意（attention）的概念是很重要的。会出现这种情况的原因是我们使用了反向传播。我这么说是因为我们使用了涉及参数的一些损失函数的梯度，我们需要所有的计算都是可微分的（你可以将其看作是可微分的注意）。因此，除了注意特定的位置，我们还在每一个可能的位置上有一个概率（其对应于权重）。所以当我们根据梯度改变权重时，我们本质上只是将注意转移到了另一个地方（参见论文《Neural Machine Translation by Jointly Learning to Align and Translate（Bahdanau, Cho, Bengio）》了解更多。）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;11. 深度网络的低精度训练&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了让我们的算法对更多的硬件友好，有很多的研究者做了很多的工作。其中首要的努力方向是在训练深度网络时使用更低的精度。这个方向的研究涉及到通过低精度的训练来实现更高准确度的神经网络，这能让我们可以在更大型的数据集上训练更大型的网络。Bengio 引述的一篇论文讨论了训练的那个部分应该被削减以维持高准确度。我发现（一个通用的经验法则）：除了任何我们希望保持高精度累积计算（accumulation computations），其它所有部分（权重、梯度等）差不多都可以被削减掉（参见 Guptaet al, arXiv, Fec. 2015 了解更多细节）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicicgLZmjFhKnsYxCMx43wia6G5xthKMe9yf6coib4D990uUSYhBaCxahO3PvY2qqMWWrichETic73VHlw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于阅读这篇来自 Courbariaux, David, and Bengio 的 NIPS 2015 论文（探索了我们可以如何 quantize 激活（activation）的方法），这里给出一个简单的备注。一旦你运行完了加权和（weighted sum），然后你执行非线性，你就会得到一个实数。我们需要将其 quantize 到几个比特。如果我们可以做到这一点，我们就能获得巨大的增益，因为我们避免了乘法和加法！这篇论文提到这项研究仍然还在进行中，但结果仍然差强人意。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;12. 下一个艰巨挑战：无监督学习&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicicgLZmjFhKnsYxCMx43wia6gNgXFfHJeV2x5icU26iasE2qQwt64hicwwsgTzVEibPFo0yUnnt0nJKUlw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前，深度学习领域内的大部分成功都是在监督学习领域，而这个领域的学习需要多得惊人的有标签样本。但是，只要机器还是仅依赖表面的统计规律进行学习，它们就无法应对样本分布之外的数据。要实现人类水平的学习，机器就必须要能归纳出关于基本因果关系的更加精准的内在模型。这能让该机器预测未在任何数据中见过的未来情形，而这正是推理、智能和科学的关键组成部分。无监督学习应该会成为深度学习领域内的下一个焦点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;13. 结语&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个演讲的关键点也是机器学习基础的关键要素。尤其是通过分布式表征对组合函数（compositional functions）的有效表征，分布式表征已经极大地提升了学习过程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一点是硬件友好的机器学习算法的开发。低精度训练这样的机制让我们可以在更大型的数据集上学习更大型的神经网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，深度学习的下一步是无监督学习。这个领域的潜在价值是能让我们真正用上海量的无标签数据、回答关于被观察到的变量的新问题、迁移学习（领域适应，其中机器可以在无需给定模型和领域的情况下学习）和更加结构化的输出（比如翻译）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicicgLZmjFhKnsYxCMx43wia6yW6t3lFibqjFUMgheTwtuYVZ9Hz976aREKW1Jknveh9hj6hOjg0hPxg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Bengio 的这次演讲谈到了很多有趣的主题，我希望这篇概述分享能够引起你的关注，也希望你能从中有所收获。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心原创，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 23 Dec 2016 11:27:25 +0800</pubDate>
    </item>
    <item>
      <title>盘点 | 2016年年度十大Python库</title>
      <link>http://www.iwgc.cn/link/4034092</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自tryolabs&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李亚洲、吴攀、李泽南&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;圣诞将至，又到了年终盘点时间，Tryo Labs 和去年一样又推出了一份 2016 年十大 Python 库的榜单。对于这份榜单的筛选条件，Tryo Labs 写道：「我们避开了 Django、Flask 等已经成为今天的标准库的已经成功的项目。另外，这个榜单中有的库是 2016 年之前建立的，但它们在今年的受欢迎度出现了暴增或我们认为它们非常好所以可以进入这个榜单。」下面是榜单详情：&lt;/span&gt;&lt;/em&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1. Zappa&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：&lt;span&gt;https://www.zappa.io/&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自 AWS Lambda（以及后续的其它项目）发布以来，人们的关注点就全部转移到了无服务器架构上。这些架构让我们可以将微服务（microservice）部署到云端、部署到一个完全可管理的环境中；在这样的环境中，人们不用关心管任何服务器，而只需要分配无状态的、短暂的计算容器（computing container）即可——一个服务提供商即可完全管理。通过这一范式，事件（比如流量尖峰）可以触发更多这些容器的执行，因此有可能能够处理「无限的」水平扩展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Zappa 是一个用于 Python 的无服务器框架，尽管（至少目前）它仅支持 AWS Lambda 和 AWS API Gateway。它使得开发这样架构的应用变得非常简单，能将你从使用 AWS Console 或 API 的繁琐配置工作中解放出来，而且它还有各种用于简化部署和管理不同环境的命令。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2. Sanic + uvloop&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Sanic:&lt;span&gt; https://github.com/channelcat/sanic&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;uvloop: &lt;span&gt;https://magic.io/blog/uvloop-blazing-fast-python-networking/&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谁说 Python 不能很快？Sanic 不仅有可能是有史以来最好的软件库名字，也可能是有史以来最快的 Python 网页框架，而且似乎也远远超过其它框架。它是一个专为速度而设计的类 Flask 的 Python 3.5+ 网页服务器。另一个库 uvloop 是一个用于 asyncio 的事件循环（event loop，其底层使用了 libuv）的超快速的插件替代。这两个加起来就是一个强大的组合！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;根据 Sanic 的作者的基准测试，uvloop 可以驱动 Sanic 每秒处理超过 3.3 万条请求，这实在太强了！（比 node.js 还快）。你的代码可以受益于这种新的 async/await 语法——它们会看起来很整洁；此外我们也喜欢 Flask 风格的 API。你一定要试试 Sanic，而且如果你也在使用 asyncio，你也可以无需太多修改你的代码就能受益于 uvloop。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3. asyncpg&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：&lt;span&gt;https://github.com/MagicStack/asyncpg&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;跟进 asyncio 框架的最新进展，来自 MagicStack 的人为我们带来了这个高效的异步（目前只支持 CPython 3.5）数据库接口库，其是专门为 PostgreSQL 设计的。它有零相关性，这意味不需要安装 libpq。相对而言，withpsycopg2（最流行的 Python 的 PostgreSQL 适配器）需要以文本格式与数据库服务器交换数据；而 asyncpg 则实现了 PostgreSQL 二进制 I/O 协议，这让其不仅支持通用类型，而且还有其它许多性能上的好处。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其基准是很清楚的：asyncpg 平均至少比 psycopg2（或 aiopg）快 3 倍，也比 node.js 和 Go 实现更快。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4. boto3&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：&lt;span&gt;https://github.com/boto/boto3&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你的基础设施部署在 AWS 上或使用了它们的服务（比如 S3），那么你应该非常乐意看到 boto（用于 AWS API 的 Python 接口）被从头到尾完整重写了。而且你不用一次性就完全迁移你的应用：你可以同时使用 boto3 和 boto(2) ；比如仅在你应用中新的部分使用 boto3。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个新的实现在不同的服务间会一致的多，而且因为其使用了数据驱动的方法来在运行时间（runtime）从 JSON 描述文件中生成类，所以其总是可以实现快速更新。再也不用滞后于新的 Amazon API 功能了，赶紧使用 bot3 吧！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;5.TensorFlow&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：&lt;span&gt;https://www.tensorflow.org/&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大名鼎鼎的 TensorFlow。自从谷歌在 2015 年 11 月发布以来，这个库已经获得了很多改进，它已成为时下最流行的 GitHub Python 库。简而言之，TensorFlow 是一个使用数据流图（data flow graphs）的数值计算库，可以在 GPU 或 CPU 上运行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在过去一年里，我们目睹了 TensorFlow 在机器学习社区中掀起了一股新风潮（特别是在深度学习领域），它不仅出现在研究领域，而且在应用领域也非常常见。如果你正在做深度学习并想在高级别接口中使用它，你可以尝试以它为后端的 Keras 或新推出的 TensorFlow-Slim。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;6.gym+universe&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Gym：&lt;span&gt;https://gym.openai.com/&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Universe：&lt;span&gt;https://universe.openai.com/&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你是人工智能圈内的人，肯定听说过非营利人工智能研究公司 OpenAI。他们的研究人员在今年开源了一些 Python 代码。Gym 是一个用于开发并比较强化学习算法的工具包。它包含一个开源库，这个库收集了一些可被用于测试强化学习算法的测试问题（环境）。它还包含一个站点与 API，能让你对比训练出的算法（代理，agent）的表现。因为它不在乎代理的实现方式，你可以选择使用自己的计算库建立代理：numpy、TensorFlow、Theano 等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他们最近也发布了 Universe，这是一个用于研究通用人工智能在跨游戏、网页和其他应用上的表现的软件平台。Universe 能完美匹配 gym，因此它能让任何真实世界应用调整进 gym 环境中。研究人员希望这一无限的可能性能够加速对智能代理的研究，从而解决通用任务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;7.Bokeh&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：&lt;span&gt;http://bokeh.pydata.org/&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你可能熟知一些提供数据可视化的 Python 库，其中最流行的就是 matplotlib 和 seaborn。然而，Bokeh 被创造用来做交互可视化（interactive visualization），并且面向现代的网页浏览展示。这意味着 Bokeh 能创造出一个可以让你探索来自网页浏览器数据的情节（plot）。比较棒的是它紧密融合了 Juptyer Notebooks，所以你能使用它配合你的专业工具进行研究。它也有一个可选的服务器组件 bokeh-server，其带有许多强大的功能，比如在服务器端对大型数据集进行下采样、流传输数据、变换等。可点击网址 http://bokeh.pydata.org/en/latest/docs/gallery.html 查看案例，看起来很棒。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;8.Blaze&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：&lt;span&gt;https://blaze.readthedocs.io/en/latest/index.html&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有时候，当你对数据集运行分析时，却发现数据集过大，无法一次塞进计算机 RAM 中。如果你无法依赖 numpy 或 Pandas，你通常需要转而使用其他的工具，如 PostgreSQL、MongoDB、Hadoop、Spark 等等。这些工具都有其自身的优缺点，依照任务的特点，总有一种工具是适合你的。但决定转换工具是一项巨大的工程，因为你需要了解这些系统如何工作，以及如何以正确的形式插入数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Blaze 提供了一个统一的接口，让用户无需学习所有数据库技术。Blaze 库的核心是一种计算表达方式。Blaze 本身不会进行任何计算：它只是知道如何指定一个特定的后端，决定谁来执行任务。Blaze 还有其它很多功能（它形成了一个生态系统），它作为一个库被开发出来。例如，Dask 实现了一个可用于 NumPy 数组的插件，可以处理大于内存的内容和利用多核处理器，并且还具有动态任务调度能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;9.Arrow&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：&lt;span&gt;https://github.com/crsmithdev/arrow&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有一个流行的说法，在计算机科学领域只有两个大问题：无效缓存和命名。我认为这句话忽略了另一个大问题：管理数据时间（managing datetimes）。如果你曾经试图在 Python 中管理数据时间，你就会知道标准库里有巨量的模块和类型：datetime、date、 calendar、 tzinfo、 timedelta、 relativedelta、 pytz 等等。更糟糕的是，时区都自然设定为默认值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Arrow 为开发者提供了「人类的时间（datetime for humans）」，提供了一种清晰的方法来创建、操作、格式化和转换日期、时间和时间戳。它可以用于替换 Python 2 和 3 的 datetime 类型，并提供了一个更友好的界面，同时加入新的功能（如 humanize）弥补了原系统的不足。即使你不需要 Arrow 提供的额外功能，使用它也可以大大减少代码中的引用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;10. Hug&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：&lt;span&gt;http://www.hug.rest/&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;公开你的内部 API，这样可以大大简化 Python API 的开发过程。Hug 是一个仅限于 Python3 的库，提供在 Python 中创建 HTTP REST API 的最简单的方式。它不是一个 web 框架（虽然 Hug 提供这样的功能，而且表现很好），它的主要功能是公开正确的标准内部 Python API。这个想法非常简单：一次定义逻辑和结构，并且可以通过多种方式公开你的 API。目前，它支持公开 REST API 或命令行界面。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你可以使用类型注释（type annotations），让 Hug 不仅为你的 API 生成文件，同时提供验证和明确的错误消息，这可以让你的开发工作（和你的 API 用户的工作）变得轻松很多。Hug 构建在 Falcon 的高性能 HTTP 库之上，这意味着你可以使用任何 wsgi 兼容的服务器（例如 gunicorn）将其部署到生产环境中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;原文链接：https://tryolabs.com/blog/2016/12/20/top-10-python-libraries-of-2016/&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 23 Dec 2016 11:27:25 +0800</pubDate>
    </item>
    <item>
      <title>深度 | Nature 2017 年十大展望：继续为量子计算而战</title>
      <link>http://www.iwgc.cn/link/4034094</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Nature&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：微胖、蒋思源、朱思颖&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;希望研究人员们继续为量子计算而战，也敢于面对政治震动带来的后遗症。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicicgLZmjFhKnsYxCMx43wia6vftMB0pJPlU32EXhnSZ3ppVkAv2L3Mzga8icPhuhEaVG1zncHic0ETibg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;海洋对气候的影响&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果美国收回当选总统特朗普做出的气候承诺，中国——这个世界上最大的温室气体排放国将主导减缓气候变迁。2017 年晚些时候，中国将启动排放限额与交易系统以减少温室气体排放。过去三年，全球温室气体排放已趋于稳定，一些科学家希望停滞不前的经济和绿色科技的突起能让 2017 年的温室气体排放有所回落。机器人探测器发回的数据会告诉我们南极洲周围的海洋正在吸收多少二氧化碳。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;政治后遗症&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;去年大选带来的政治震动会在 2017 年显示出其后果。1 月 20 日川普就职后，研究人员就能更清楚地知道这任政府是否会真的搁浅 NASA 气候与地球科学计划（NASA』s climate and Earth-science programmes）或批准用人类胚胎干细胞进行试验。三月，英国开始就脱欧展开正式协商，这也会对科学研究产生巨大影响。4 月初，随着法国、德国相继选举新领导人，科学家将会观察到西方对流行的国家主义的热情是否会继续。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;返回发射方&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;中国的嫦娥五号将会发回首批月球样本。如果任务成功，科学家将会深入研究这些重达两公斤的岩石和土壤，了解月球的形成与演化。然后，9 月份，NASA 20 岁的 Cassini 探测器将会荣归故里。飞船将飞身经过土星内光环，在大气层分解之前将会发回科学家期待已久的大量相关数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;身体内的世界&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;希望会有更多关于人类微生物群方面的研究——收集病毒、细菌和其他体内微生物及其基因——看看它们如何影响人类健康。研究人员正在检测微生物群对大脑发育和癌症的影响。另外，分两阶段的美国人类微生物群项目（US Human Micro-biome Project）关注的是人类微生物群与早产、炎症性肠病发病以及 2 型糖尿病的关系，也会在 2017 年发布一些成果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicicgLZmjFhKnsYxCMx43wia643Iq1RCp7Vefclex1uJ8CCGFG0yEWNGia9WEo24CtCzPayrObYNwticw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;基因竞赛&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2017 年，法院很可能会对加州伯克利大学和位于麻省剑桥的博德研究所（Broad Institute）的 CRISPR-Cas9 专利纠纷作出判决。主张自己发明了基因编辑技术的博德研究所能在专利授权方面收入数十亿美元。NgAgo，一个不分伯仲的基因编辑系统（很难复制）会在后续研究基础上孤注一掷。而且在英国，现在诊所可以申请授权使用一项有争议的辅助生育技术，该技术可以混合三个人的基因，旨在预防儿童患上经由母亲线粒体（细胞产生能量的部分）遗传下来的疾病。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;量子争霸&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;物理学家们希望 2017 年 将会是量子计算机执行即使是最好的普通类型计算机也无法执行的计算的一年。谷歌，D-wave 和一小撮其他机构正在进行量子争霸。但是不仅仅只有他们在追求更卓越的计算性能高度，微软正在进行一个很有野心另类技术——拓扑量子计算，这种技术把材料中类似粒子的物体运动的信息进行编码，而且他们的这项技术将会比竞争对手的方法更具鲁棒性。在 2017 年晚些时候，微软可能会第一次成功实现这样的计算。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;照亮黑暗&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;科学家们将在四月份第一次尝试拍摄一事件视界（event horizon），届时分布在全球的 9 个无线电望远镜一起协作形成一个地球天文台（planet-sized observatory）。事件视界望远镜（Event Horizon Telescope）将会探寻银河系中心的特大质量黑洞。如果四月份的尝试能够成功，所拍摄的图片将可以用于检验广义相对论和获知（照亮）黑洞的活动。与此同时，在 LIGO 和 VIRGO 的研究人员，将会进行第一次高级协同运作，让研究者精确定位特定星系的引力波起源。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;新型材料&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随着今年晚些时候商业化的开始，廉价薄型的太阳能电池即将走出实验室。自 2009 年以来，钙钛矿型太阳能电池的效率急速上升。研究者目前正在努力克服材料上的主要缺点，同时推进生产这种电池的低成本方法。德国汉堡电子同步加速器研究所的一台价值 12 亿欧元欧洲 X 射线自由电子激光器投入使用也使得材料科学领域得到强大支持。该仪器将允许研究人员研究原子细节中的二次化学反应和生物和物理过程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Big blue&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;世界上最大的海洋保护区于今年 12 月正式建立，这让南极洲的罗斯海（Ross Sea）免于商业捕鱼和矿产开发。在南极洲的其他地方，甚至大冰山都能从 Larsen C 冰架上崩解，且自它在 1893 年被发现以来，冰雪的质量已经缩减到了最小。在温暖地区，过去几年对珊瑚白化扩张的研究应该可以解释其为何能在一些区域相对安全的生存下来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicicgLZmjFhKnsYxCMx43wia6fFsklUdbUogibf433NBfn4WvH65Kzo9ia2OiaBEVB5NNdKESUsJwy5yJQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;T 淋巴细胞的反击&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一个同类型、复杂的癌症免疫治疗法 CAR-T 看起来好像已经准备投入市场了。药品公司 Kite Pharma 和 Novartis 正在竞争获得批准应用此治疗方法，该疗法涉及的基因工程需要从患者的免疫系统中提取出 T 淋巴细胞，然后使用这些 T 淋巴细胞进行对抗癌症。尽管在一些公司的研究中出现了导致患者死亡的毒性问题，但该疗法今年还是有望获批作为白血病和淋巴瘤患者最后的治疗手段。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;第九大行星&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;太阳系外的研究可能会帮助确定第九大行星的位置，经过理论计算，它的公转周期大约是 20 万年。直到 2016 年的一项研究发现了一些柯伊伯带（Kuiper-belt）中的星体（这些都是远在冥王星轨道之外的冰冷星体），研究表明了它的存在。NASA 计划在 2017 年 12 月发射一颗人造卫星 Transiting Exoplanet Survey Satellite（TESS），从而展开系外行星搜寻。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;原文链接：http://www.nature.com/news/2017-sneak-peek-what-the-new-year-holds-for-science-1.21231&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;br/&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 23 Dec 2016 11:27:25 +0800</pubDate>
    </item>
    <item>
      <title>学界 | 斯坦福联合Facebook创建CLEVR：用于组合式语言和初级视觉推理的诊断数据集</title>
      <link>http://www.iwgc.cn/link/4034096</link>
      <description>&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自arXiv.org&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;论文：CLEVR：一个用于组合式语言和初级视觉推理的诊断数据集（CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：当开发能够推理和回答关于视觉数据的问题的人工智能系统时，我们需要诊断测试来分析我们的进展和发现缺陷。现有的一些视觉问答基准可以提供帮助，但它们有很强的偏置（bias）——模型可以利用这些偏置从而无需推理就能给出问题的正确答案。它们还混有多个误差源，这会让我们难以定位模型的弱点。我们提出了一个诊断数据集，其可以测试许多视觉推理能力。它包含了最小的偏置，并且有详细的标注描述了每个问题所需的推理的类型。我们使用这个数据集分析了各种现代的视觉推理系统，为它们的能力和局限性提供了全新的见解。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;导言&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能研究的一个长期目标是开发能够推理和回答关于视觉信息的问题的系统。为了研究这个问题，研究者在近段时间已经提出了多个数据集 [4, 10, 21, 26, 32, 46, 49]。这些每一个视觉问答（VQA：Visual Question Answering）数据集都包含了关于图像的自然语言难题。正确回答这些问题既需要识别物体、属性和空间关系等感知能力，也需要计数、执行逻辑推理、做比较或利用世界知识常识等更高级的能力 [31]。研究者为解决这些问题提出了很多方法 [2, 3, 9, 24, 44]，但其中许多都只是在强基线上的一点点改进 [4, 16, 48]。不幸的是，我们理解这些方法的局限性的能力受到了 VQA 任务的固有复杂性的阻碍。这些方法的问题到底是识别失败、推理能力差、缺乏常识知识还是其它什么呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这篇论文中，我们提出了一个用于研究 VQA 系统执行视觉推理的能力的诊断数据集（diagnostic dataset）。我们将这个数据集称为 Compositional Language and Elementary Visual Reasoning（组合式语言和初级视觉推理）诊断数据集，简称 CLEVR。CLEVR 包含 10 万张经过渲染的图像和大约 100 万个自动生成的问题，其中有 85.3 万个问题是互不相同的。其中包含了测试计数、比较、逻辑推理和在记忆中存储信息等视觉推理能力的图像和问题，如图 1 所示。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicicgLZmjFhKnsYxCMx43wia6qxpNNjpX8SsDSdWospiaic4vHQiaMCIX7ibTFPee3obYicASKtZa78gkcmg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;图 1：一个来自 CLEVR 的图像与问题样本。这些问题测试的是视觉推理中的属性识别（棕色文本）、计数（红色）、比较（蓝色）、多注意（绿色）和逻辑运算（紫色）等方面。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们设计 CLEVR 的目标很明确——实现详细的视觉推理分析。我们的图像描绘了简单的 3D 形状；这简化了识别，让我们可以将重点放到推理能力上。我们确保每张图像中的信息都是完整的和独有的，这样使得常识知识等外部信息源无法增加正确回答问题的几率。我们通过在相关问题族内的拒绝采样（rejection sampling）而最小化了问题-条件偏差（question-conditional bias），我们还避免了退化问题（degenerate questions）——即那些看似复杂，实际上却有获得正确答案的简单捷径的问题。最后，我们为图像和问题都使用了结构化的 ground-truth 表征：图像使用 ground-truth 物体位置和属性进行了标注，问题则被表征为可以被执行来回答该问题的功能程序（functional programs）（详见第 3 节）。这些表征能够帮助实现使用传统的 VQA 数据集无法实现的深入分析。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些设计选择也意味着：尽管 CLEVR 中的图像可能看起来很简单，但它的问题却很复杂，需要一系列的推理能力。比如说，归纳未见过的物体和属性的组合可能需要分解表征（factorized representations）；计数或比较这样的任务可能需要短期记忆 [15] 或关注特定的物体 [24, 44]；以多种方式结合多个子任务的问题可能需要组合式系统来回答 [2,3]。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们使用 CLEVR 分析了一套 VQA 模型，并且发现了并不为人所知的缺陷。比如说，我们发现当前表现最佳的 VQA 模型在需要短期记忆（比如比较物体的属性）或组合式推理（比如识别全新的属性组合）的任务上表现并不好。这些观察为进一步的研究指出了全新的方向。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，我们强调的在 CLEVR 上的准确度本身并不是一个最终目标：一个使用 CLEVR 宇宙的明确知识的人工设计的系统可能会表现很好，但却无法泛化到真实世界环境中。因此 CLEVR 应该与其它 VQA 数据集结合使用，以研究通用 VQA 系统的推理能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本 CLEVR 数据集以及用于生成新图像和问题的代码将会公开开放。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicicgLZmjFhKnsYxCMx43wia6icniaVzXgPC6Um6icpiafWSsUXuB9PmiakeFbm4NC7V39upA4RmM922S8Hg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;图 2：一个 CLEVR 宇宙的现场指导。左侧：形状、属性和空间关系；中部：问题样本与它们的相关功能程序；右侧：用于构建问题的基本函数的目录。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicicgLZmjFhKnsYxCMx43wia6bz1icr2aCJKibwt3rKeNZOu8ck4nzhfZ3Ja3ic8pbUWLhkRlG5vvicZt6A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 3：上部：CLEVR 的统计数据；大多数问题是独一无二的，少数来自验证和测试集的问题会出现在训练集中。下左侧：对于不同 VQA 数据集的问题长度比较；CLEVR 的问题通常长得多。下右侧：CLEVR 中的问题类型分布。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicicgLZmjFhKnsYxCMx43wia6YOicsZiakSfzL2Vl5XznqDdNHiahib9lD3yS2Fyea5Se1ZakLGibsib626EA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;图 4：在 CLEVR 数据集上，6 种 VQA 方法按问题类型分类的准确度比较（更高的更好）。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;点击阅读原文查看论文&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 23 Dec 2016 11:27:25 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 自动驾驶新进展：激光雷达实现突破性小型化</title>
      <link>http://www.iwgc.cn/link/4034097</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Economist&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李泽南&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8oIsGS2mErEqmOQE2GPACGFClSPhErlcmPicAUtJW5klUZP2TxByoDCE9niaSBHdTjeo4plqSe2zTg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;刚刚成立&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721418&amp;amp;idx=3&amp;amp;sn=bc21aa884bd56d3cf123d66bfa19a31f&amp;amp;chksm=871b08f4b06c81e2502bfe1c69ea291e7be740d7d4d42948e441cfbbf118f3289f661efb1bfd&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721418&amp;amp;idx=3&amp;amp;sn=bc21aa884bd56d3cf123d66bfa19a31f&amp;amp;chksm=871b08f4b06c81e2502bfe1c69ea291e7be740d7d4d42948e441cfbbf118f3289f661efb1bfd&amp;amp;scene=21#wechat_redirect"&gt;独立公司 Waymo&lt;/a&gt; 的谷歌有着大量竞争者，各家公司的自动驾驶汽车正在道路上不断进行实验。在匹茨堡的一次成功试运行之后，Uber 在 12 月 14 日启动了它在旧金山市的「自动驾驶汽车」项目，这个决定迅速陷入了有关法规的争议——Uber 还没有拿到无人车的许可证。但 Uber 坚持认为这是不必要的，因为目前运营的每一辆车都有备用驾驶员随时准备在危险时接管控制（12 月 22 日，Uber 在旧金山的所有16辆无人车被当地车管局责令停止运营）。通用也刚刚宣布他们正在密歇根州进行自动驾驶汽车试验。对于这些试验型车辆来说，有一件事显得尤为重要：汽车操纵系统需要有可靠的视觉。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前还没有任何一个人造系统可以和人类的双眼与大脑媲美，开发者们必须寻找妥协的方案。这就是为什么工程师们正在使用巨大的支柱与鼓包来承载用于扫描道路情况的传感器。在存在多个传感器的情况下，假如一个传感器没有探测到危险情况（如驶来的汽车或横穿马路的行人），其他传感器可以察觉到它，并发出指令让汽车做出回避动作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前的自动驾驶汽车主要使用三种传感系统——摄像头、超声波探测器和雷达——它们是便宜并且易于部署的。第四种方式：Lidar，采用激光扫描和测距来建立车辆周围环境的详细三维模型。Lidar 图像具有高度准确性，这使得它可以与前三种传感器方式相提并论。然而激光传感器面临体积过大的问题（看看谷歌自动驾驶汽车的车顶，Uber 也是一样），同时，它的机械结构非常复杂，造价堪比承载系统的汽车本体。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前，一些厂商正在开发更小、更便宜的激光雷达系统。其中最有前途的是一种基于硅芯片的小型化设计。它的原型已经交付各大汽车零部件供应商（如 Delphi 何 ZF）开始生产。如果一切顺利，在三年以内激光雷达芯片就会出现在量产车上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8oIsGS2mErEqmOQE2GPACGo6YbHLBupntuSVWVXwI2ERWwmzgc7TcJQ84rMSh041VVqOr6aeAdNg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;摈弃旧方法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;带来新一代微型激光雷达 lidar 的是英飞凌（Infineon），一家德国芯片制造商。这家公司是雷达探测器芯片的最大生产商之一。雷达通过发送无线电脉冲并接受被反射的信号工作，发射和接收到反射之间的时间延迟被用于计算和被探测物体之间的距离。如果对象是移动物体，它的速度也可以被测定（通过多普勒效应）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 15 年前，雷达传感器是一种需要定制的设备，每套售价约 3000 美元。英飞凌开发了一种新的方法，使用半导体行业常见的硅制造工艺，并将雷达的许多功能集成到单个芯片上从而提高性能，这种设计使传感器的价格迅速下降到几百美元。雷达芯片不仅是自动驾驶汽车的重要部分，并且已经越来越多地应用在常规车辆中，用于提供诸如自动紧急制动等安全配置。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Lidar 与传统激光雷达有着相似的发展历程。激光雷达是在 20 世纪 60 年代激光实用化后发明的。它通过使用激光束扫描特定区域，随后接受光反射测定与物体的距离。由于光具有比无线电波更短的波长，很容易被小型物体反射，激光雷达可以探测到被雷达错过的物体。激光雷达正被广泛用于地图测绘，测量大气条件，以及扫描事故和犯罪现场等工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通常，激光雷达使用旋转镜面来引导其激光束，发出的光束在人类不可见的光谱近红外部分。商用激光雷达价格可达 5 万美元左右，而目前最为畅销，但较小、功率较低的版本售价约为 1 万美元。许多激光雷达制造商，如加州的 Velodyne 公司，正在试图开发所谓「固态」激光雷达，这是一种更为小型化的版本，取消了所有运动部件。一些研究人员正在尝试使用激光闪烁代替常亮光束，并利用芯片上的微型传感器阵列捕获反射。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;英飞凌公司有着自己独特的思路，他们使用了不同种类的发射器，并使用了微机电系统（MEMS）。这种特殊的 MEMS 是英飞凌在 2016 年 10 月收购的荷兰公司 Innoluce 开发的。该设备由一个椭圆形的反射镜组成，尺寸为 3mm×4mm，被整合在硅芯片上。反射镜连接了致动器，可以改变激光束的方向。英飞凌表示，这种设计允许激光器使用全功率集中扫描，同时，它使用了闪烁系统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「MEMS lidar 可以每秒收集 5000 个数据点，其扫描范围可远至 250 米，」英飞凌汽车传感及控制部门负责人 Ralf Bornefeld 说道。尽管这套设备仍然有反射镜，但 lidar 拥有和其他硅芯片一样的可靠性。在大规模生产的情况下（例如附加在挡风玻璃上），MEMS lidar 在汽车制造商端的成本可以低于 250 美元。这些小型激光雷达同时也可用于其他应用，如机器人和无人机等领域。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;包括 Bornefeld 在内的很多工程师都认为，未来的自动驾驶汽车将使用多个微型激光雷达，普通雷达，超声波传感器和摄像头组成阵列。「每种传感器系统都有自身的优缺点，」Bornefeld 说道。「高效地整合它们才能为自动驾驶汽车提供安全保障。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;雷达可以精确地测量距离和速度，并在黑暗或浓雾的环境中正常工作——此时摄像头无法获取有效信息，但雷达产生的图像不够精细，难以让计算机系统进行分类。另一方面，有一些材质（如橡胶）会吸收而不是反射雷达波，从而让雷达无法探测，造成安全隐患，此时摄像头的优势就显现出来了。摄像头可以捕获高分辨率图片，以供人工智能软件进行分析，然后应用图像识别技术来识别需要避免的对象。Lidar 具有在黑暗中探测小型物体，并收集高分辨率图像的能力，但可能无法穿透浓雾。在未来的无人驾驶汽车上，超声波探测器仍然将发挥作用，这种价格便宜的探测设备可被用于制造停车传感器。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌，Uber 和大多数汽车制造商都希望尽快应用 lidar，因此他们非常乐于看见这些技术的新进展。但不是每个人都在拥抱激光雷达，伊隆·马斯克和他的特斯拉放弃了这一技术。马斯克认为，在特斯拉汽车上安装的摄像头、雷达和超声波传感器系统的性能正在快速提升，目前还不需要引入其他设备。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;看到更多&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;伊隆·马斯克也许很快就会改变他的想法。在今年 5 月，一位特斯拉车主在使用自动驾驶模式时撞向一辆货柜车最终身亡。虽然目前的自动驾驶设备要求驾驶者必须把双手放在方向盘上，双眼观察路面（现在谷歌 Waymo 和 Uber 自动驾驶汽车上的预备驾驶员也是如此），但在这次事故中，特斯拉汽车的摄像头和雷达都没有发现挡在面前的货柜车——它被漆成白色，和当时的天空几乎融为一体，也许系统把货柜车识别成了其他的什么东西，如横跨头顶的交通标志。在这种情况下，lidar 是否会获取正确的信息？永远没有人会知道。但是，当越来越多的无人驾驶汽车在道路上展开冒险的时候，拥有更多的鼓包和探头总会让乘客们更加安心。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;span&gt;原文链接：&lt;/span&gt;http://www.economist.com/news/science-and-technology/21712103-new-chips-will-cut-cost-laser-scanning-breakthrough-miniaturising&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 23 Dec 2016 11:27:25 +0800</pubDate>
    </item>
    <item>
      <title>第四范式联合创始人陈雨强：机器学习在工业应用中的新思考</title>
      <link>http://www.iwgc.cn/link/4020105</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心整理发布&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;编辑：虞喵喵、蒋思源&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote style="line-height: 25.6px; white-space: normal;"&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;第四范式联合创始人、首席研究科学家陈雨强是世界级深度学习、迁移学习专家，曾在 NIPS、AAAI、ACL、SIGKDD 等顶会上发表论文，并获 APWeb2010 Best Paper Award，KDD Cup 2011 名列前三，其学术工作在 2010 年作被全球著名科技杂志 MIT Technology Review 报道。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;陈雨强也是机器学习工业应用全球领军人物，在百度凤巢任职期间主持了世界首个商用深度学习系统、在今日头条期间主持了全新的信息流推荐与广告系统的设计实现。陈雨强目前担任第四范式首席研究科学家，第四范式在人工智能领域科研技术领先，刚刚揭晓的「第六届吴文俊人工智能科学技术奖」，第四范式荣获一等奖，该奖项代表国内最高科研实力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此前，陈雨强在机器之心精品线下活动中，给业内人士分享了其对于机器学习在工业应用中的新思考。以下为活动现场的速记整理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8VWKQofaVnqvnBPXGupytYXIiccLqGwicWVN1S4uXm3rG8scFOnzzQwHoiaNuqibp9fCgoe3TI3bTURQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我是来自第四范式的陈雨强，负责人工智能算法研究、开发等相关工作。就我此前在工业界的经历，今天跟大家分享的是——「机器学习在工业应用中的新思考」。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;iframe class="video_iframe" data-vidtype="1" allowfullscreen="" frameborder="0" height="417" width="556" data-src="https://v.qq.com/iframe/preview.html?vid=y0358z2p4ds&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0"&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;正在改变的公司和行业&lt;/strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFB3f6b9YPqib1F0dC7nBbwNuARia0ucuahONhGavyVIRQ4ENwFD7OMDjJg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能在工业界越来越火，过去五年火热程度以指数的方式上升。不管是在公司内部，还是在公司之间、行业之间，人工智能正在变成一个炙手可热的名词。从公开资料上可以看到，Google 和 Facebook 在 2012 年时，只有搜索和推荐等几个少数核心项目使用了机器学习。随着时间推移，到 2016 年第二季度，Google 已经有超过 2000 个项目和产品正在使用深度学习。同时也有报道称，Facebook 已经有超过 17 个大团队、超过 25% 的工程师正在使用机器学习。也就是说，在互联网行业巨头里、公司内，机器学习的影响力正在从少数几个产品迅速扩展到更多的场景。另外，我们发现一个很有意思的现象，就是 AI 慢慢扩展到全行业的影响，当前的趋势正在从之前的「互联网+」或者「移动+」，慢慢转向为「AI+」。比如滴滴是「互联网+打车」，美团是「互联网+O2O」，很多公司之前做的是「怎么用互联网改变传统行业」。但是现在，他们纷纷转向「如何用积累下来的数据提供更多的价值」。还有一些公司，从创立初始就是「AI+」，比如今日头条是「AI+新闻」、大疆是「AI+无人机/机器人」。我们可以看到，AI 正在慢慢渗透到并且改变所有的行业。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在跟大家分享之前，介绍一下我的个人经历。AI 大潮的热度从 2010 年初开始呈指数上升，我非常幸运地赶上了这个大潮。我在学校时主要做人工智能和机器学习的相关研究，具体包括迁移学习等，也在 AAAI 、NIPS、SIGKDD 等会议上有论文发表。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBlzSCBvAhfYu0CnSD4pJdTwBGeuNGq30I8g38ic4rF6LsHUtek5RLEJQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;毕业之后我去了百度，所在的部门负责百度的搜索广告系统——凤巢系统。&lt;/span&gt;&lt;strong&gt;这个阶段面对的是解决一个公司的一个问题，&lt;/strong&gt;&lt;span&gt;即「如何提升搜索广告的点击率」这个问题。当时我做的事情比较偏纯技术，即怎么让深度学习应用到大规模的机器学习中。我们有上千亿个特征，怎样设计一个模型应用深度学习。我们当时上线了世界上第一个使用深度学习的商用系统。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从百度离职之后我去了今日头条。在头条时面对的产品线更多了，除了主信息流推荐以外，小频道推荐、视频推荐，包括信息流广告、评论排序等等，有非常非常多的应用方向。&lt;strong&gt;所以在今日头条，我面对的是一个公司内很多很多的业务与问题。&lt;/strong&gt;对当时的头条来说，时效性是非常重要的。除了在技术上设计一个追求极致的时效性以及极致的性能与规模的机器学习系统之外，我还做了一件很重要的事情，是设计了很多机制，让这些人工智能技术能用在头条的各个产品线之中。举个例子，人工智能或者机器学习的算法其实是一个发动机引擎，机制是传动的齿轮，怎样把引擎的动力以最有效的方式传动到各个部件，这是机制所做的事情。所以除了需要关心技术之外，还要关心产品与机制创新。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从今日头条离开后来到第四范式，我们面对的业务、行业会更多。金融、电信、互联网，各种各样的行业，包含营销、获客、风控、推荐、排序等各种各样的问题。&lt;strong&gt;在第四范式我面对的，是各行各业不同场景的不同问题。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;可以看到，我的经历是从解决一个公司的一个问题，到解决一个公司的很多问题，到解决各行各业的各种问题。这些经历给了我很多思考，比方说&lt;strong&gt;如何做一个追求极致的人工智能系统？如何在一个公司内让更多的产品使用人工智能？&lt;/strong&gt;如何让更多的行业使用人工智能？在人工智能在公司内与行业间爆发的现在，这个是我想分享给大家的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;人工智能成功必要的五个必要条件&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBhswysfliaNprpyOyCBGO02ZHosr7PoicRMNmo1iafpxoqba7sE51wb1uA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为什么人工智能在最近的一段时间非常火？为什么人工智能在 20 年前、10 年前没有这么火？为什么 AlphaGo 能在今年打败李世石而不是更早？我们直观的会认为是因为算法创新。但是算法创新只是其中一点，国内外很多专家分析总结出了人工智能成功的五个必要条件，这里跟大家分享一下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一，边界清晰。问题需要定义得非常清晰，比如 AlphaGo 做的是围棋，围棋是在 19×19 的棋盘上，黑白两方轮流下子的问题，有吃有打劫。如果变成一个开放的问题，变成 20×20 的棋盘，变成黑白灰三方下棋，或者把打劫规则变一下，都会导致人工智能的失败。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二，外部反馈。算法要不断的有外部输入，知道我们在什么样的情况、算法做出什么样的行为下，外部给出的反馈是什么，这样才能促进提高，比方说需要 AlphaGo 不断地进行对弈，并且告诉它对弈的输赢。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第三，计算资源。近些年算法虽然有很大的进步，但计算资源也是产生智能的关键。最近业界在分布式计算上的成功，让我们相对于几十年前有了飞跃的基础。举个非常有趣的例子，Google 在描述 AlphaGo 不同版本的时候，为了简洁明了，直接使用计算能力来分类，而不是使用算法来分类。简版的 AlphaGo 被称作「单机训练的 AlphaGo」，复杂、更高智能的 AlphaGo 称为「多机、并行训练的 AlphaGo」，从这里也可以看出，计算资源起着至关重要的作用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第四，顶尖的数据科学家和人工智能科学家。增强学习、深度学习最近重新被提出，需要很多科学家大量的工作，才能让这些算法真正的推行，除了围棋、视觉、语音之外，还有非常多的领域等待被探索。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第五，大数据。AlphaGo 的成功，关键的一点是 KGS 棋社的流行，KGS 上有数十万盘高手对战的棋谱，没有这些数据 AlphaGo 绝对不可能这么短的时间内打败人类。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些要素总结起来只有三点：一方面是技术，计算资源和大数据方面的支持；一方面是业务，边界要清晰，业务有反馈；另一方面是人，包括科学家，包括应用到场景需要和人打交道。所以如果一个 AI 要成功的话总结起来三点，要关注技术、要关注业务、要关注人。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;工业界需要可扩展的机器学习系统&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能的兴起是计算能力、机器学习以及分布式计算发展的结果。在实际的工业界之中，我们需要一个可扩展的机器学习系统（Scalable Machine Learning System），而不仅仅是一个可扩展系统（Scalable System），那什么是可扩展的机器学习系统？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBNXyOvYN8uW6ThYwlCOOs4ZJT7QYYwbCgxf2vYIcFzlFXTRX7JBs3Ag/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一点，数据处理的能力随机器的增加而增加，这是传统的可扩展。第二点，智能水平和体验壁垒要随着业务、数据量的增加而同时增加。这个角度的 Scalable 是很少被提到的，但这个层面上的可扩展性才是人工智能被推崇的核心原因。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;举个例子，过去建立竞争壁垒主要通过业务创新快、行业内跑马圈地，或是通过借助新的渠道（比方说互联网）提升效率。在这样的方式中，由于产品本身相对容易被抄袭，那么资本投入、运营与渠道是关键。但随着数据的增加与 AI 的普及，现在有了一种新的方式，就是用时间与数据创造壁垒。举个简单的例子，如果现在去做一个搜索引擎，即使有百度现成的技术现在也很难做得过百度，因为百度积累了长时间的数据，用同样的算法也很难跑出一个比百度更好的搜索结果。这样如果拥有能用好数据的人工智能，就会获得更好的体验，反过来更好的体验又会带来更多的用户，进一步丰富数据，促进人工智能的提高。可以看出，由人工智能产生的竞争壁垒是不断循环迭代提升、更容易拉开差距的高墙。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;可扩展的机器学习系统需要高 VC 维&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那么，我们怎么能获得一个既拥有高智能水平又能 Scalable 的学习系统呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;60 年代 Vapnik 和 Chervonenkis 提出了 &lt;strong&gt;VC 维理论&lt;/strong&gt;，形式化的描述了机器学习算法对复杂函数拟合的能力。对 VC 维的理解，可以举个简单的例子就类似于人大脑内的神经元，神经元数量越多，这个人可能就越聪明。当然，这个不是绝对的，智商高的人比一定做出来的成就是最高的，这里关键的一点是个人的经历也要多，之后经历过很多事情、并且有思考的能力，才能悟出道理。在机器学习中，VC 维度讲的也是这个道理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBztdHj3lbia8VQ8MsLz7TFib3WUTmL1ia7yPO3x7qHiaUBr0ceBHf4RAW8w/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;教科书上的 VC 维都是上面这样的一张图。因为过去的数据不大，训练损失函数在不断下降，测试损失函数在不断的上升，要避免过拟合，VC 维就不能太高。比如你是个很聪明的孩子，但是在很小的时候不能让你过多的思考瞎琢磨，否则很有可能走火入魔。过去对我们教导是在你经历不多、数据不多时干脆傻一点，就没有那么多精力去思考乱七八糟的事情。这是当时大家觉得比较好的解法，控制 VC 维，让训练数据的 Test Loss、Training Loss 同时下降。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但随着时代的不断发展，数据也是在不断增多的，我们的观点有了新的变化。在数据量比较小的时候，高 VC 维的模型比低 VC 维的模型效果要差，产生了 over-fitting，这只是故事的一部分；有了更多数据以后，我们发现低 VC 维模型效果再也涨不上去了，但高的 VC 维模型还在不断上升。这就是刚才说的智能 Scalable 的概念，在我们有越来越多数据的时候，要关心的是 under-fitting 而不是 over-fitting，要关心的是怎样提高 VC 维让模型更加聪明，悟出大数据中的道理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;总结成一句话，&lt;strong&gt;如果要成功在工业界使用人工智能，VC 维是非常重要的问题。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;工业界怎么提升 VC 维呢？我们知道「机器学习=数据+特征+模型」，如果已经有很多数据，提升 VC 维的方法有两条：一种是从特征提升，一种是从模型提升。我们把特征分为两类：一类特征叫宏观特征，比如描述类特征如年龄、统计类特征如整体的点击率、或整体的统计信息；另一类为微观特征，最典型的是 ID 类的特征，每个人都有特征，每个物品也有特征，人和物品组合也有特征。相应的模型也分为两类，一部分是简单模型如线性模型，另一类是复杂模型如深度学习模型。这里，我们可以引出工业界机器学习四个象限的概念。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;模型 X 特征，工业界机器学习的四个象限&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBa7wZ5YouuibQXHseBpxmT9OLVF0yYNSXQON1k7CB9AYMyre10W8flCA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;工业界具体怎么做的？第一象限是简单模型加上宏观特征，在现在的工业界比较难以走通，很难得到极致化的优化效果。这个象限内，有七八十年代专家系统，还有一些统计模型。大家比较熟悉的 UCI Data 就是支持这个时代研究的典型数据，每个数据集有 1000 个左右的训练数据，分的类数也不多，特征也不多。对于这样的数据统计模型比较盛行，要解决的问题是怎样找出特征之间的关系与各自的统计特性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二象限是简单模型、复杂特征，最成功的典型案例是 Google AdWords。Google 在很多技术上都是开山鼻祖，包括整个计算广告学。Google AdWords 有上千亿的特征，每个人、每个广告、每个 Query 的组合都在其中。这种模型非常成功，给 Google 带来了非常大的收益。Google AdWords 占 Google 70% 以上的收入，Google 的展示广告也是用的这样的技术，占了 Google 大概剩下的 20% 左右的收入。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第三象限是复杂模型、宏观特征典型的应用，比如 Bing ads，2013 年他们提出 BPR（Bayesian Probit Regression）来 Model 每个特征的置信度。雅虎也是第三象限忠实的传道士之一，大家所熟知的 COEC（Click Over Expected Click）这个算法就是雅虎提出的，在上面做了很多模型。其次他们还设计了很多模型解决增强学习问题，比如多臂老虎机等等算法。很多雅虎出去创业的同事最常使用的机器学习技术就是统计特征加 GBDT（Gradient Boosting Decision Tree），通常能获得非常好的效果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第四象限，复杂模型和微观特征，现在还是热门研究的领域，它最难的一点是模型的规模实在太大。比如广告有上千亿的特征，如果做深度学习模型一个隐层有 1000 个特征，可能会有万万亿级别的参数。虽然数据很多，但万万亿的数据还是难以获得的。所以怎么解决这个角度的模型复杂问题、正则化问题，目前研究还是一个热点的研究方向。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;如何沿着模型优化？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBJB08wbOnfT67We15edqOX8ccxcCCeS3oBBBqq57431SbyhwUGCicrXg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;沿着模型优化主要由学术界主导，新的模型主要来自于 ICML、NIPS、ICLR 这样的会议。他们主要的研究是非线性的，总结起来有「三把宝剑」：Kernel、Boosting、Neural Network。Boosting、Neural Network 现在非常流行，Boosting 最成功的是 GBDT，而 Neural Network 也在很多行业产生了颠覆性的变化。大约十年前，Kernel 也是很流行的。借助 Kernel，SVM 有了异常强大的非线性能力，让 SVM 风靡了 10-15 年。优化模型的科学家们为了实验的方便，对工程实现的能力要求并不是特别高，大部分模型是可以单机加载的。要解决的实际问题主要是数据分布式，降低数据分布式带来的通讯 overhead 等问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于工业界中的具体问题，基于思考或观察得到新的假设，加入新的模型、结构，以获得更多的参数，这是工业界优化这一项限的步骤。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBIa67D6RGLLOAkyQKnySREkZjexZ5K16yRgibGzQMfTLBfoiasibdLrF5g/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以时序动态的协同过滤为例，我们这里引用的是 Koren, Yehuda 在 2009 年在 KDD 上发表的论文 Collaborative filtering with temporal dynamics，这是时序动态协同过滤被应用最多的一篇经典论文。在这篇论文里，首先协同过滤的问题有一个低秩假设，作者认为由 User，Item 组成的稀疏矩阵是由两个低秩矩阵相乘得到预估评分。第二，通过观察数据，作者观察到 IMDB 对某些电影的打分是随着时间的加长，分数不断上升（对那些经典的电影）。根据这样线性的关系，设计「现在的时间」减去「首次被打分时间」作为偏置，拟合斜率就是一个好的模型。考虑到更复杂的情况下，打分随时间的变化并不是单纯的线性，作者进一步提出将线分成很多小段，每个小段做分段线性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;总结一下，通过机器学习优化的套路是什么？&lt;strong&gt;首先，观察数据；第二，找到规律；第三，根据规律做模型的假设；第四，对模型假设中的参数用数据进行拟合；第五，把拟合的结果用到线上，看看效果怎么样。&lt;/strong&gt;这是模型这条路在工业界上优化的方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;如何沿特征优化？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBCzmNDW2pNj7bZPWoheUAoaCNYB3bibWaEFOb7oXOJFtNgU4lgwbGSFQ/0?wx_fmt=png"/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;特征优化主要是工业界主导的，成果主要发表在 KDD、ADKDD 或者 WWW 上，这些模型相对简单粗暴。主要是 LR，比较简单，粗暴是说它的特征会特别多。就像刚才提到的，Google 使用了上千亿的特征，百度也使用了上千亿的特征，这些特征都是从最细的角度描述数据。&lt;/span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;沿模型优化这条路的主要特点是什么？模型一定是分布式的，同时工程挑战是非常大的。上千亿的特征是什么概念？即使一个参数用一个 Float 存储，也需要上百 G 到上 T 的内存，是单机很难存储下来的。这还只是模型所占的内容空间，训练起来还有其他中间参数与变量、数据也还要占内存，所以这些算法一定是模型分布式的。针对这些难点，学术界中 KDD 和 WWW 等会议上都在研究如何高效并行，以及如何保证高效并行的时候快速收敛。ASP、BSP 等模型和同步、异步的算法，都是为了保证高效分布式的同时能快速收敛。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;应为线性模型理论较为成熟，工业界对模型本身的优化相对没有那么多，其更主要的工作是针对具体的应用提取特征。为什么会有那么多特征？因为我们对所有观察到的微观变量都进行建模。以搜索广告为例，每个 User ID、每个 Query、 每个广告都有特征。同时为了个性化，User+Query、User+广告 ID、Query+广告 ID，甚至 User+Query+广告 ID 都能产生特征。通过组合，特征会发生爆炸，原来可能上亿的特征会变成上千亿特征。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;初听这样的思路会觉得有点奇怪，把用户历史上搜过关键词或者看过广告 ID 作为特征，如果这个用户从来没有搜索过这个关键词或者没有看过这个广告，那是不是就不能获取特征了呢？这个问题正是 LR+大规模特征这条路最常被攻击的一点，即如何进行模型泛化。在大规模离散特征机器学习系统里，解决泛化的方法是设计加入层次化特征，保证在细粒度特征无法命中的时候，层次化的上位更粗粒度特征可以生效。比方说如果一个用户是一个新用户的话，我们没有 UserID 特征，但是我们有更高层次的性别、地域、手机型号等特征生效，在预估中起作用。回到说之前的例子中，我们设计「Query+UserID」特征，到「Query」与「UserID」特征，再到更高级的性别属性「男/女」、使用的设备「安卓/ iOS」，可以组成一个完成的特征体系，无论缺失什么都可以用更高级的特征帮助预估进行弥补。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBQ81WeFoYnwyH8ZdJssQUPySibIMyJ6skxDckvT6dWe0sOUsy3zDHNTw/0?wx_fmt=png"/&gt;&lt;br/&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以之前提到的时序动态的协同过滤为例，我们看看如果走特征这条路，该怎么解决协同过滤的问题。首先我们不再做低秩假设，我们把所有的二阶项可以展平成组合特征。其次，我们会发现发现不是所有的数据都是呈线性的，特别有时候会产生一些突变，甚至都不能通过分段线性描述。还是在 Collaborative filtering with temporal dynamics 的论文中，由于作者也不知道什么原因造成了突变，他的方法是把不同维度的数据与时间进行组合，对时间维度的非线性进行建模。加入 Item 把时间分成比较细的桶，做分段线性的拟合。同样把 User 按时间进行分桶，保证对突变也能有比较好的拟合。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以，当你不能给出比较好的数据假设时，不知道为什么产生突变时，可以更多的依赖数据，用潜在参数建模可能性，通过数据学到该学的知识。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;宽度还是深度？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大家都会比较好奇，沿着宽度走好还是沿着深度走好？并没有那个模型在所有情况下都更好，换一句话说机器学习没有免费的午餐（No Free-Lunch）：不存在万能模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBlUeacGNXVAhggNvnuepJB3c4Z0WmHkibkZJxs9eBS1Nx5fY6V39WbIA/0?wx_fmt=png"/&gt;&lt;br/&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;No Free-Lunch Theory 是由 Wolpert 和 Macready 在 95 年提出的一个定理。他们证明对于任意算法或优化算法 A 与 B，如果在某一种损失函数上 A 好于 B，则一定存在另一个损失函数保证 B 好于 A。更直观的描述是，总能找出一个损失函数让任何算法都不比随机猜更好。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这告诉了我们什么？所有的机器学习都是一个偏置，这个偏置是代表你对于数据的假设，偏置本身不会有谁比谁更好这样的概念。如果使用更多的模型假设，就需要更少的数据，但如果模型本身越不符合真实分布，风险就越大。当然我们也可以使用更少的模型假设，用数据支持模型，但你需要更多的数据支持，更好的特征刻画，然后表示出分布。总结起来对于我们工业界来说，机器学习并没有免费的午餐，一定要做出对业务合适的选择。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;宽与深的大战&amp;nbsp;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFB89RMqINOh9jjWjDG6xj7QeGwyGFmUFoNpMh9XqNiaHM7a88kX2sBXPA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;追求更高的 VC 维有两条路：一个是走宽的、离散的那条路，即 Google AdWords 的道路；也可以走深的那条路，比如深度学习或者 YAHOO！News 那条路。这就是深与宽的大战，因为宽与深在工业界都有非常成功的应用案例，坚信宽与深的人很长一段时间是并不互相理解的，各自忠实的信徒和粉丝们都会去拥护自己坚信的算法，质疑另一条路走不通。坚信深度学习、复杂模型的人认为，宽的道路模型太简单了，20 年就把所有的理论研究透彻，没有什么更多的创新，这样的技术不可能在复杂问题上得到好的结果。坚信宽的模型的人，攻击深度模型在某些问题上从来没有真正把所有的数据都用好，从来没有发挥出数据全部的价值，没有真正的做到特别细致的个性化。的确深度模型推理做得好，但个性化、记忆方面差很多。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;非常有幸的是，我自己在宽和深两边都在工业界做过实际的探索与研究。吴恩达还没正式加盟来百度之前，曾到百度访问交流，当时我在凤巢，有机会与他探讨机器学习在工业界的一些进展与尝试。在那时我们就发现在工业界中，&lt;strong&gt;宽与深有很强融合趋势。&lt;/strong&gt;Google 作为宽度模型的发起者，正在在广告上尝试使用深度模型，而我在百度也在已经做了同样的事，不谋而合，Google 和百度这些宽模型的拥护者正在向深的方向走。同时吴恩达分享他在 Facebook 交流的时候，发现 Facebook 走的是复杂模型宏观特征，虽然效果不错，但也非常急切的想要尝试怎样使用更宽的模型，对广告与推荐进行建模。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;宽与深的模型并没有谁比谁好，这就是免费午餐定理：不同业务使用不同的模型，不同的模型有不同的特点。我们对比一下宽度模型与深度模型：宽度模型有比较准确的记忆能力，深度模型有比较强的推理能力；宽度模型可以说出你的历史，在什么情况下点过什么广告，深度模型会推理出下次你可能喜欢哪一类东西。宽度模型是依靠层次化特征进行泛化的，有很强的解释性，虽说特征很多，但是每一个预估、为什么有这样的预估、原因是什么，可以非常好的解释出来；深度模型是非常难以解释的，你很难知道为什么给出这样的预估。宽度模型对平台、对工程要求非常高，需要训练数据非常多、特征非常多；深度模型对训练数据、对整个模型要求相对较低一点，但现在也是越来越高的。还有一个非常关键的区别点，如果你是 CEO、CTO，你想建一个机器学习的系统与团队，这两条路有非常大的区别。宽度模型可以比较方便与统一的加入业务知识，所以优化宽度模型的人是懂机器学习并且偏业务的人员，把专业的知识加入建模，其中特征工程本身的创新是提升的关键；如果走深度模型，模型的创新是关键，提升模型更关键来自于做 Machine Learning 的人，他们从业务获得知识并且得到一些假设，然后把假设加入模型之中进行尝试。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBWHkuJrBGtPyPNWtRUc6ldS6nr4u2OOJkabKD8I8hyOKw33tuvcj6xw/0?wx_fmt=png"/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;宽度和深度的大战，就我看来各自都有各自的缺点，我们要各取所长做宽与深的结合。宽与深的结合已经逐渐成为一个研究热点，Google 在今年 4 月份发表的一篇论文，介绍他们的最新工作「Deep &amp;amp; Wide Model」。模型分为 Deep 与 Wide 两部分，好处是它既能对比较细的特征有记忆，同时也有推理的能力。我们认为将来的方向都应该朝这路走。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除此之外，近期还有不少工作在探索这个方向，张伟楠 2016 年 ECIR 发表论文论述如何通过底层输入加上因子分解机让一个稀疏矩阵的深度学习可解，随后在 ICDM 上发表论文进一步加入 Inner Product 和 Outer Product 希望更好的刻画特征之间的关系。&lt;strong&gt;第四范式最近也有一些新进展，今年 7 月我们发布了 DSN 算法，算法底层是上千亿大小的宽度网络，上层是一个全连接的网络。&lt;/strong&gt;难点在于如何解决它的可计算性以及如何解决模型的分布式，如何保持模型的稀疏与避免过拟合。总的来说这方面还是非常前沿的、非常热门的研究领域。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;如何上线：从监督学习到强化学习&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不管是宽也好、深也好、又宽又深也好，有这么多厉害模型，是不是欢欢喜喜搞好模型、做好特征，线下评估 AUC 涨了，我们就赶快上线？不要高兴太早，线下做好的模型实际上是一个监督学习模型，并不能保证它线上效果好。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBF0xowBBRiccMibicVa6WgY3hSM11NfoRk9sbsR4c1ETJN9vfIicAyf5B1w/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;以搜索广告为例，上图中最左边表示的是原系统对广告进行排序产生的结果，线上系统展示 6 条广告，还有一些是没有被展示的广告。展示的广告中有被点击的广告（黄色）和没被点击的广告（蓝色）。我们使用展示过的广告研发下一代机器学习模型，如上图中间所示，优化之后发现被点击的广告线下预估得点击率更高，位置向上提升，没有被点击的广告位置向下变化。但是真正的应用到线上的时候（上如最右边所示），面对的侯选广告不止是它展示出来的广告，而是所有的广告。可能之前根本就没被原系统排上来的广告被排到了非常高的位置，这些广告可能很多根本就不会被点击。这样以来，展示过的广告虽然保持了原来的顺序，但是中间插入了很多不会被点击、原来没被排上的广告，占用广告展示位，使得系统 AUC 很差。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里说一下我当年在百度搜索广告上线深度学习的的故事。那时百度凤巢还是在使用大规模离散 LR 系统，上千亿的个性化的特征让广告效果有长足的进步，刚获得百度最高奖。而这个时候，我是在这个 LR 系统的基础上，尝试使用深度学习的技术进一步提升效果。怎么让一个上千亿特征的宽度系统变身深度系统在但是还是一个没被研究过非常困难的问题，我们花了大半年的时间历经千辛万苦在线下获得了非常显著的指标提升，欢天喜地的想要上线，但刚一上线，我们就发现，线下模型训练的越好，线上获得的效果反而越差。这使我们当时非常沮丧，找了很久原因，定位到发现不是模型不对，也不是深度、宽度的问题，而是监督学习的问题——线上系统并不是问题封闭的监督学习系统，而是开放的不断变化的系统。这就好比你去学打《星际争霸》，不能通过顶级玩家的录像来学，因为学到套路并不一定能打败初级玩家，而必须以赛代练，自己上手，才可以把学到的知识真的用起来，面对变化的现实世界。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;回过来看，如何上线其实是从监督学习到强化学习的问题。强化学习一般是闭环系统，系统里会不断的有外部反馈，这个反馈又是由系统产生的输出带来的结果。那如何更好的用系统输出产生的结果进行强化学习？强化学习面临的空间是一个未知空间，在 PPT 的广告的例子中，可以看到的空间是原系统产生出来的空间（只有黄、蓝色广告），但是线上面对的空间其实是黄、蓝加上绿这些广告构成的空间。怎么更好的探索黄、蓝、绿的空间，是强化学习要解决的问题。有很多工作在尝试解决这方面的问题，包括多臂老虎机、UCB 等等很多算法，最近这些强化学习技术也被用到了搜索广告与推荐系统。&lt;strong&gt;总结起来，一定不要开心的太早，线上系统越强数据越有偏，学习越有偏的数据取得的效果，越不能代表上线的效果。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;拆解复杂目标到单一目标，逐个优化&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有这么多好的技术，怎么更好的服务业务？机器学习做的是单目标优化问题，并没有能做多目标优化的机器学习算法。虽然有研究在做尝试，但在工业界还处于研究的初步阶段。在真正出现多目标机器学习算法之前，我们要更多的解决单目标优化的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBV6WWxWubbajNiaxDnctOsBRVGZ97W4yibtZbtGT6A7ISNSRrbW0C0jjg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;比方说新闻推荐就是一个多目标复杂的问题，想要优化的指标极多——我们想优化留存、想优化时长、想优化点击率、想优化转发、想减少低俗、想优化时效性、想加速新用户冷启动等等，只优化某一个目标并不能让我们一劳永逸。那这里回想到以前有一个做推荐的朋友就因此特别的苦恼，因为每天面对这么多的要考虑的因素，每天都在自己跟自己左右互搏，非常的分裂。他在优化点击率时就很担心，是不是变低俗了？优化低俗的时候是不是降低了用户的参与？优化参与时又想阅读时长是不是会受到影响？但是，&lt;strong&gt;如果一心想一次优化所有的目标，那么没有一个目标最终能被优化。机器学习解决问题的套路是通过把目标分解，逐个进行优化。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;举搜索广告的例子，搜索广告的收入可以拆解成：流量 * 有广告展示的流量比例 (asr) * 平均页面广告展示条数 (asn) * 点击率 (ctr) * 广告平均计费价格 (acp)。拆解成这么多目标后，优化点击率时就不用考虑其他的因素，点击率用模型优化，价格、条数用竞价机制优化，流量通过产品与渠道优化。把目标拆开后可以非常舒服的优化每一项，每一项都优化得非常极致，整个系统就能做到极致了。再举一个停留时长的例子。如果我们想优化阅读的整体停留时长，并不是去按照直观优化每个页面的停留时常，而是将停留时长分解成点击率 * 点击后页面停留时长，然后分开进行优化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果进行了合理的拆解，我们实际上可以有更多基础模型，利用这些基础模型，我们可以定义出针对业务目标的机制，比如说指数加权乘法或者逐级阈值门限机制等。利用设计好的机制，我们可以调整各个目标之间的关系，做出取舍，还可以定量的观察与获得指标间的兑换比例，比方说在模型不进行变化的前提下，多少点击率的降低能兑换出多少总时长的增加。应为每个指标都是独立的，我们只需要用 ABTest 就可以根据公司目标调整这些机制参数了。这样的方法相对于根据目标调整数据更能解释清楚，调整数据是我把目标的拆解直接加到数据中，认为什么目标重要就把那个目标对应的数据加倍、权重加倍。但困难在于加倍数据后模型需要重新训练，也很难说清楚处于连续变化状态中的目标，各个分指标是怎么互换的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;关注人&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后分享一下我们在工业界应用中，关注人的一些经验。关注人其实是一件我之前很少想的事情。如果你专注做机器学习，你可能认为与你交流的人、用你的技术的人或多或少懂得机器学习。但如果我们的目标是让所有人都能用上人工智能、让工业界更多的产业用上人工智能，你面对的人关于机器学习的水平参差不齐，就是一个非常现实的问题。在这样的情况下，关注人在其中就是至关重要的事。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBpFPicuDsqMAbyk2Y0OOzdBmDZoJXqzEmGz1uiaQv72TqQsbEauo8AbtQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;开头提到的机器学习成功必要条件的五点中，专家数量是机器学习成功的必要因素。困难之一是在更广阔的工业界，专家教授并没有那么多，企业内部需要优化的业务数量也远远大于专家数量。第二是非专业 AI 人员在无法理解（至少宏观上、直观上理解）模型原理之前，他们是不相信模型能够更好的优化他的业务的。比如你要把司机替换成自动驾驶，会发现人有非常非常多的顾虑，因为人不知道为什么机器会做出左右、前后、刹车的判断，也不知道背后的机器学习会在什么时候失效、什么时候能应用。这些问题在当前的技术前提下都是很难被直接定义、描述清楚的，那么这就会导致人工智能很难被推广到更大的领域中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBD4dPWdWoHVWibD0tpZdKme4akrfGFIQaDLULBiaDL3seQXZvPAAM0ib3g/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;如果要让更多的人能使用上这样的技术，首先是要解决模型的可解释性。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;对应研究中的下一代技术叫 XAI（Explainable Artificial Intelligence），是一个更易理解的、更可解释的 AI 系统。XAI 是 DARPA 今年的 6 月份提出的项目，被美国认为是攸关国家安全高度的人工智能的技术。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;模型的可解释非常有用，更好的可解释性、可理解性可以把人工智能算法或技术推广到更多公司、以及推广到公司其他部门，否则会碰到很多不同层面的问题。模型的可解释有很多研究方向，做图片分类时通过深度学习给出一个 Output，说图片是猫的概率是 0.93。这会令人疑惑，图片中的确是一只猫，但并不知道为什么机器认为它是一只猫。将来的学习过程可能是，图片放进来不仅会给出一个结果说它是猫，还会给出它是一只猫的原因——两个毛茸茸的耳朵、还有爪子、脚上还有很多毛、还有小肉垫，因此认为它是猫。&lt;strong&gt;这样能更好的理解模型能做什么、不能做什么，这是应用人工智能至关重要的点。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;要解决可解释性的问题，我们可以有多个思路，第一个思路是对于重要的模型，我们针对性的设计解释机制。比方说考虑如何去解释一个大规模特征 LR 模型的问题，虽然 LR 模型天生是个解释性很好的模型，但是特征特别多的情况下，由于它是微观模型，并不容易看到模型整体。就像观察全国 14 亿人每个人的行为，我们可以了解很多事情的发生，但是这还是不够的的，我们需要从微观特征中得到宏观的统计和宏观的分析。这条思路其他重要的工作包括如何可视化以及解释深度学习的内部机制。第二个思路是我们也可以设计出一些全新的模型，这些模型最重要的设计目标就是在高可解释性的同时不丢失预测效果。最后一个思路是做模型的黑箱推理，不管是深度模型、宽度模型或者其他模型，通过黑盒的输入输出来窥探模型内部的运行机制。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除了模型可解释，在实际应用中，模型可控也是非常重要的一点。越重要的领域对模型可控的要求越强，因为不能出错。推荐和广告出错一次没什么问题，如果贷款判断失误或是无人驾驶判断失误，后果可能会关系到国计民生。为什么模型可控是一个难的问题呢？因为刚才说到模型要好 VC 维就一定要高、一定要有足够的自由度，但可控是要限制解空间的自由度，让模型满足很多规则与约束。这就相当于想要造一个超音速的飞行器，但同时要求能用绳子牵着像风筝一样被控制方向。这方面，我们也在进行探索，针对具体的问题，比方说定价，我们可以设计出一些既满足规则、VC 维又足够高的模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后一点，模型的互动性、可干预性、可参与性。机器学习更多的是通过观历史预测未来，如果是历史上没有发生过的事情，还是需要通过专家更好的预测。一方面我们不能把人全部替掉，另一方面人在人工智能时代可以产生更重要的作用。怎样设计一个模型把专家的知识加进来，在数据不够充分的时候更相信专家，有了足够的积累就更相信数据和事实，是非常重要研究的话题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Take-Home Message&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，总结一下这次分享，有这么几个关键信息：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一点，	我们要设计一个开放的可扩展的机器学习系统。它一定需要是高 VC 维的系统，才能保证随着业务增长，效率与效果也不断提升。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二点，	没有免费的午餐，也没有万能的模型。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第三点，	宽度模型和深度模型各有利弊，根据场景、根据团队选择最合适你的。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第四点，	模型从线下走到线上其实是强化学习的过程，你（和你的老板）最好做好半年抗战的准备。这个时间不是指写算法、做工程的时间，而是做强化学习、不断的迭代积累数据，让模型越来越好的时间。这点非常重要，否则新的模型很难用到实际的工作中。无数死于襁褓的模型都是惨遭缺乏强化学习之痛。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第五点，	关注业务，设定更专注的目标解决更宽泛的问题。不要妄想一个机器学习模型能解决所有问题，要解决所有的问题就设计更多的模型，用机制让这些模型共同工作。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第六点，	关注产品和业务人员，因为他们会最终决定 AI 能使用的深度和宽度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今天我的分享就到这里。谢谢大家！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;hr style="line-height: 25.6px; white-space: normal;"&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;问答环节&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;听众：第四范式的 Deep Sparse Networks 适合解决什么问题？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;陈雨强&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：解决既要求数据有很强的离散性或很强的个性化，同时又要求有很强的推理的问题。Deep Sparse Networks 能从更细的角度能把特征进行组合，挖掘出特征之间不同的关系，个性化的推荐、广告、排序，包括要做预估的场景都是 Deep Sparse Networks 适合的。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;听众：第四范式的商业模式是什么，是给这些中小型企业提供人工智能服务，还是给大公司提供服务？大企业可能都有自己的团队，那第四范式是做一个平台性的工具，还是将来也做产品？要一直做送水人，还是跟 BAT 这种传统互联网去结合？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;陈雨强&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：我觉得最关键一点是，BAT 解决的问题和各行各业要解决的 AI 问题并不一样。各行各业都有使用 AI 的需求，我们的商业模式是提供一个 AI 的平台，让客户有 AI 的能力、让客户自己使用人工智能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们最近开放的公有云上，面对的目标客户是有很高的人工智能质量诉求，但是现在并没有能力建立这样的团队的公司，诸如一些互联网公司，他们的发展目标也是关注在业务上的。另外一方面，我们会服务金融、保险、电信等领域的一些巨头，他们其实有非常强烈的使用 AI 的场景和诉求，但在技术上没有完全接轨最新的技术。通过平台的方式，我们让他们的人员用上最新的技术产生更好的价值。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;能做的事情太多，并且 BAT 和其他科技公司没有一家完全覆盖这部分业务。大数据公司很多，真正让大数据产生价值的公司很少，目前看还是相对不饱和的市场。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;听众：我好奇的一点是，广点通是一个机器系统吗？投放的时候通过选择年龄、性别这样的标签可以代替监督学习的部分吗？以及，为了提升投放效果，是应该把它当成黑盒子去反复测试吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;陈雨强&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：首先，广点通是一个非常好的机器学习系统。第二，选择年龄、性别能不能代替监督学习，这是两个不同的概念。年龄、性别、地域是用户画像，选择的标签是可被验证的、与产品最息息相关的。比如针对女性用户的产品虽然男性用户点击率会非常高，可你根本不希望任何男性点进来。所以这部分是点击率模型不能解决的问题，一定要经过 Targeting 解决。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;还有一类是用户画像是并不必需的。比如来定义他喜欢车还是喜欢金融，这是一个很宽泛的概念，每家公司定义都不同。比方说高端客户、低端客户这样的标签，游戏公司的高端客户是每天玩 20 个小时游戏的人，但金融公司的高端客户很可能不是每天玩 20 小时游戏的人，所以通用、含糊的标签一般没有特别大的意义。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第三，如何优化。我觉得 ABtest 是最好的方式，如果平台支持，可以通过出价、通过组合观察如何获得最佳的 ROI，是现有比较有效的方法。如果说怎么结合机器学习，可以把 ROI 与数据做一个结合，这样更清楚哪些标签或者哪些投放的关键词更有可能获得更高的 ROI。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;听众：去年吴恩达写了一篇文章叫「每个企业都需要一个首席智能官」，第四范式不在任何一个企业里，但可能也起到一个智能官的作用。对于怎么把机器学习变成可解释的东西，能和我们分享讲一个具体的故事，或者跟企业打交道面临需要解释的困难吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;陈雨强&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：首席智能官需要做的事情有很多，涉及到如何在公司发挥人工智能的价值、推进人工智能、让人工智能更好的被接受、对趋势的判断、对技术的理解以及平台的搭建，还包括技术的推广。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们在某个比较大的国有股份制银行做好了一个模型，仅用一个月的时间就让某一个具体的业务提升了 60% 的收入，换算成钱一年是十几亿的收入。银行就非常急想上线，但是需要让我们解释我们的模型为什么能工作，为什么比他们之前的算法和模型好。我们模型其实是一个宽模型，有上亿的特征，特征是可以一个一个拿出来看的，但是并不能了解模型为什么起作用。我们设计了一个可解释模型，用树模型这个相对容易解释的方式，你和我们的宽模型，让客户了解我们模型的背后在做什么事情。同时业务人员看了我们的模型，也获得一些启发，帮他们找到了一些新的业务规律。这个模型最终一是被用来做可解释模型，第二是用来做他们审计的模型，应对银行的监管诉求。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;听众：深度模型和宽度模型的选择是应该发生在项目开始之前，还是以结果为导向，这两个模型都会去做，最终实际效果哪个更好我选择哪个模型？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;陈雨强&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：这个问题在于选择建设适合你的机器学习系统。比如说这个系统面对的是不断变化的业务，宽度模型是非常好的能结合业务知识和专家意见的机制。如果是一个技术为主、模型为主的团队，走深度这条路也是可以获得非常大的提升的。说到底不只是技术选型的问题，还是管理、架构的问题。选择什么样的路决定将来怎么搭建团队、怎么获得持续的提升，因为机器学习一定不是一次就能完成的，是不断提升的。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;听众：在模型角度出发，什么情况下即使数据是非常充足的，我们也认为专家的意见更可靠？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;陈雨强&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：如果数据比较充分，专家的意见又比较靠谱，它们两个是高度一致的。专家更大的作用还是在于宏观上，可以非常容易的加入宏观的外部信息。这些信息如果计入模型相对会有滞后性，这是没有办法克服的，专家的及时性会更加好。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;听众：假设数据的情况非常理想，在模型方面您会做哪些努力保证这个模型的可控性是最强的？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;陈雨强&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：模型可控性不是所有的方方面面都被控制住，可控是模型达到的业务目标。举用机器学习解决智能定价的问题为例，对信用卡分期产品进行定价，3 期、6 期、9 期、12 期有不同的手续费，一个合理的假设或者一个正常的要求可控的规则是，期数越高单期手续费应该越低。如果机器学习解决这个问题，不能保证期数越高手续费就一定越低。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以具体方法是什么？先设计一个部分强可控的模型，控制它的单调性、一致性和参数范围；另一部分不需要可控的参数，让它自由的学习，通过这种方式来达到可控。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;听众：过去人工智能研究专家系统，现在深度学习和专家系统是不是能够结合？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;陈雨强&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：这方面研究还是挺活跃的，近期的马尔科夫逻辑网把逻辑和神经网络在一起，还有在贝叶斯方法最近也相对更热了一点。大家也意识到深度学习很难解释，所以通过逻辑、推理、概率这种方式能得到更可解释的模型。我们自己也在思考，怎样能更好的把专家的知识结合进来。过去其实分两块，一块就是说 KR（Knowledge Representation)，一种就是做推理，现在有了深度学习、有了各种学习方向，可能会有更多的发展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心整理发布，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 22 Dec 2016 12:25:11 +0800</pubDate>
    </item>
    <item>
      <title>深度 | 英国人工智能初创公司全景图：DeepMind引来收购热潮</title>
      <link>http://www.iwgc.cn/link/4020106</link>
      <description>&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Medium&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：David Kelnar&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;英国风投公司 MMC（MMC Venture）调研全英人工智能创业公司的发展状况，对公司的具体领域、研究方向和资金状况以及面临的挑战进行了分析，是一篇了解英国人工智能创业公司全景的好文章。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在科技的每次范式转移中，随着公司的进步，创新也随之而来，然后就是重新构想流程。如今，我们处在全球人工智能革命的早期阶段。机器学习算法使得我们能够在大型数据集中找到数据模式，并对人、设备、系统与流程做出更准确的预测。但英国的人工智能公司动态如何？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们绘制了英国处于早期阶段的人工智能软件公司，并与其中的 40 家公司进行了接触。下面是我们观察到的英国人工智能市场的 6 大动态，从变化活动等级到专注领域、再到盈利的趋势与融资了多少轮。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8oIsGS2mErEqmOQE2GPACGm57kvdoxJ0mpeyBF7prXVI77sGbKBV4MSWRmcCtRtB2coV5tCKxGfg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 1 英国处于早期阶段的人工智能公司&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;英国人工智能全景图：226 家公司&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随着时间的发展，我们预期人工智能公司与其他软件提供商之间的差别会模糊直至消失，因为机器学习的部署是为了解决大量的业务流程与领域。然而，如今还是能够分辩出在早期阶段专注于人工智能的软件公司的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们调查了英国的 226 家早期阶段的人工智能公司，并与其中 40 家进行了接触。我们也根据一下情况做出了一份全景图（图 1）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;目标：该公司是否专注于改进某项业务职能（例如，市场或人力资源）或领域（医疗、教育、农业）？或者公司是否在开发跨多个领域应用的人工智能技术？&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;客户类型：公司的客户主要是公司（B2B）还是消费者（B2C）？&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;融资：目前为止，公司获得了多少融资？根据天使轮（低于 50 万美元）到「成长」资金（800 万到 1000 万美元），我们对此进行了归类。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们会定期更新该图。如果漏掉或错误分类了一些公司，我们深感抱歉，我们知道许多早期公司可能在使用大量的人工智能技术，但没展现出来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在分析过市场并接触过 40 家公司之后，我们认为市场中有以下六个显著的动态：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1. 专注于人工智能对业务职能的作用&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;英国许多早期阶段的人工智能公司（5/6 的比例）将机器学习应用到特定的业务职能或领域中（图 2）。反映出该领域的萌芽期，然而有 1/6 的公司注重于开发人工智能技术——能力、平台或一系列算法，在多个领域都能够使用这些技术。这些公司跨越从计算机视觉的开发到自动决策算法的创造。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些人工智能公司的客户是谁？我们调查发现 9/10 的公司主要是 B2B 的，为其他公司开发并销售解决方案（图 3）。只有 1/10 的公司直接销售给消费者（B2C）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8oIsGS2mErEqmOQE2GPACGCcou9CTVdrg8d2r911qSyOCJzTG27ltZ9Wy6br34Qn4tHVicGptOWmg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大多数新的 B2C 人工智能公司面临着数据上的挑战。训练机器学习算法通常需要大量的数据。B2B 公司可以分析它们服务对象的大量的不同数据集，但面向消费者的公司缺乏公开的或允许（例如 Facebook 的数据）的数据，一开始通常没有大量的消费者数据可用来分析。因此，随着用户基础与数据集有所增长之后，它们才能随时间部署机器学习。例如 Gousto 是一家为消费者提供菜谱与食材并送货上门的公司，如今，有着机器学习 PhD、数据分析师和工程师的 Gousto 的团队利用人工智能进行仓储自动化与菜单设计。因为最初 Gousto 就有使用人工智能的洞见，因此随着时间进展（数据的增加），该公司也获得了自己的优势。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这样的情况下，大部分消费者将首先通过世界上最流行的消费者应用体验机器学习——Facebook、谷歌、亚马逊、Netflix 等，它们利用大量的数据集与机器学习团队提供面部识别、搜索、娱乐内容推荐、翻译等功能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2. 人工智能公司不均匀的分布&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过测量在每个领域中活动公司的数量，一份热点图显示了早期活动的重要区域（图 4）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8oIsGS2mErEqmOQE2GPACGlKPNbNELU8eibxb7KBKHat3uOx1iaPWJtQD0dIe1TibvOb6G0cZB9th5w/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 4：英国早期人工智能公司热点图&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;它们的活动主要集中在以下领域：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;市场与广告、信息技术、商业智能与分析功能&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;金融领域&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大量集中于：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;人力资源职能&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;基础设施、医疗与零售领域&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;上面的领域很适合人工智能应用，也解释了为什么主要集中于这些活动。每个领域内创造价值的机会显而易见，也非常的重大。这些领域都有大量的很适合机器学习应用的预测与优化挑战，也为机器学习训练与部署提供大量数据集，也获得了比人类更好的技术表现。其余的领域要么不实际，要么成本太高。而这些领域极其垂直，并且远离谷歌、亚马逊、微软、IBM 这样的人工智能平台提供商的竞争。当然，医疗领域谷歌和 IBM 都插手了，创业公司有所挑战。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由于市场的催化，强大的人工智能公司能够通过以下几点获取竞争优势：让专家深入复杂领域；开发专有算法；通过利用非公共数据集创造围绕数据的网络效应；通过保证充足的资金来建立高质量的机器学习团队并占有市场资源。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在市场与广告领域的活动中，英国 1/5 的人工智能公司针对这一领域。现代市场与广告的基础是人工智能的一个甜蜜点。消费者在网页、APP 上有数十亿次的点击量，提供了大量可用却复杂的数据。此外，市场与广告价值链的几乎每个阶段都为优化与自动化做好了准备，包括内容处理、消费者分割、消费者定位、程序广告优化、消费者潜在购买力发现、消费者情绪分析。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;活动较少的领域&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在很多的领域中，活动与市场机遇之间存在着一定的联系。例如，在制造业领域有很多的初创公司针对这一领域解决大量的需求问题。机器学习能够通过预测和对机器的优化维护提高 20% 的生产力。原材料的成本和再加工也能够通过改进对产品质量数据的分析得以降低。另外，「缓冲（buffering）」（储存原材料和一些未完成的产品以弥补在生产过程中未预见的效率低下）会将可预测的生产力降低 30%。制造业领域中的一系列传感器（包括生产线上的传感器数据、机床参数和环境数据）会显著增加机器学习的可用数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在合规与欺诈（Compliance &amp;amp; Fraud）方面，很少有初创公司会将银行不断膨胀的钱花在这一方面。花旗银行的 3 万人（该银行 12% 的员工）目前都在致力于合规的业务。在 2015 年第 1 季度的电话会议上，花旗强调它通过提高效率节省的 3.4 亿美元有 50％以上是通过额外的监管和合规投资带来的。摩根大通（JP Morgan）同样将合规支出在 2011 年至 2015 年期间增加了 50％，达到了 9 亿美元。而高盛（Goldman Sachs）则强调，过去四年其员工人数增长了 11％，主要是为了满足法规合规管理的需求。我们与银行间的对话特别关注「了解您的客户（KYC）」和反洗钱（AML）计划。除了提出广泛的需求，该部门还提供大量的数据集进行训练模型，用以替代高昂的人力成本。机器学习最明显的能力就是在一些领域相比于人类会提供更好的表现，比如说要让人类去监控数据洪流就是不可能的事。在银行内部努力的情况下，英国的合规公司可能很少，不过要是在对潜在用户的集中关注上或者与美国创业公司的竞争上还是很有机会的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在合规和欺诈（Compliance &amp;amp; Fraud）功能中，很少有创业公司利用银行合规性支出。3 万多人的花旗银行（Citi），占银行从业者的 12%，它正在进行内控合规（compliance）管理。在 1Q15 的电话会议上，花旗强调它通过提高效率节省的 3.4 亿美元有 50％以上是通过额外的监管和合规投资带来的。摩根大通（JP Morgan）同样将合规支出在 2011 年至 2015 年期间增加了 50％，达到了 9 亿美元。而高盛（Goldman Sachs）则强调，过去四年其员工人数增长了 11％，主要是为了满足法规合规管理的需求。我们与银行间的对话特别关注「了解您的客户（KYC）」和反洗钱（AML）计划。除了提出广泛的需求，该部门还提供大量的数据集进行训练模型，用以替代高昂的人力成本。机器学习最明显的能力就是在一些领域相比于人类会提供更好的表现，比如说要让人类去监控数据洪流就是不可能的事。在银行内部努力的情况下，英国的合规公司可能很少，不过要是在对潜在用户的集中关注上或者与美国初创的竞争上还是很有机会的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3. 人工智能公司数量加倍&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;与前几年（2011-2013）相比，近些年来（2014-2016）英国每年建立的人工智能公司数量（见下文图 5）数量出现了翻倍。其中，超过 60% 的人工智能公司都是在过去的 3 年当中建立的。也就是说在这期间，英国几乎每一周都会建立一家人工智能公司。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8oIsGS2mErEqmOQE2GPACGzx9ianeb7O1l7XiaSmmzMggIxqkvz1obhZIN3egxOzKNZz6Qianoiam2Zg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能的创业潮是在人工智能时代这一更大的背景下兴起的，此外还有一些其他具体因素助长了这次创业潮。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通常在人工智能领域，20 年前的播种到今天才得以有所收获。新的算法（尤其是卷积和循环神经网络）现在已经收获了更加高效的成果。可用数据的极大增长让我们有可能调整机器学习算法以得出准确的预测。图形处理器（GPU）的发展将训练神经网络的时间减少了 5-10 倍。过去 5 年中，人工智能的公众认知增长了 6 倍，这也增加了购买者对科技的兴趣。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除此之外，还有一些推动人工智能初创公司建立的因素。随着越来越多的投资者对人工智能领域前景的认可，人工智能公司的风险资本融资在 5 年之内增长了 7 倍。一些人工智能基础设施和服务的提供商（谷歌、亚马逊、微软和 IBM）正在降低部署机器学习解决方案的难度和成本。人工智能软件的开源（尤其是 TensorFlow，机器学习的组件库），让越来越多的人都可以参与其中。随着风险资本融资的不断持续，我们期待高水平的人工智能创业能持续下去。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那这些新兴人工智能公司关注的都是什么呢？在这些公司当中，以专注于人力资源业务和财务领域的人工智能公司占最大比重（如下文图 6）。2/3 的人工智能人力资源和财务公司成立都不到 2 年。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8oIsGS2mErEqmOQE2GPACGh6uWgkghorHuVKZXStde9ZRIjWzlDILKSjIicc5EibbG6LqSN6vq7N1Q/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最近的人力资源活动起源于一场该职能内部的范式转移。人力资源正从一个行政系统转变为一个预测增长和效率的系统。企业的运营者正在思考如何让之前没有得到充分利用的数据集发挥效用，从基于能力的招聘到对员工流动的预测性建模。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;意料之中的是，在商业智能中专注于安全和合规的公司，以及零售和基础设施领域的人工智能公司占比较低。但随着大量成熟的数据集可用于机器学习，这些领域首先就会受到人工智能企业家们的青睐。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4. 相对于全球环境来说还处在初始阶段&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相对于全球范围内一些其他的国家来说，英国的人工智能行业的发展还处在初始阶段，机遇与挑战并存。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前，与美国一半的同类公司相比，英国 有 3/4 的人工智能公司在种子基金和天使融资的支持下已经开始探索初期的发展道路（如下文图 7 所示）。但在图中，我们也可以看到英国只有 10% 的公司处于资本增长的阶段，而美国有大约 20% 的公司处在这一阶段。根据 2015 年的数据显示，英国几乎所有人工智能公司的注资都处于天使、种子阶段或是 A 轮融资阶段，而当时全球范围内的人工智能公司已经有 1/3 进入了下一阶段（如下文图 8 所示）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8oIsGS2mErEqmOQE2GPACGO1uvrddXdjAWzsibg7FrddwutiazgeibdfeUBYtoXWnicguK2xlIaa5Tag/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8oIsGS2mErEqmOQE2GPACGU69tMcz2JLVjy7G0gxfvxa0vZUSEEh2goalzN1wFBHszyZ9ytPmJGA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种状况既包含着机遇，也伴随着风险。对处于初始阶段公司的企业家、员工和投资者来说，一个充满生机的创业环境蕴藏着很多的机遇。同时，一些较发达且资金充足的海外公司会给英国的公司发展带来竞争压力。随着很多人工智能公司被卖给大企业，其中很多是全球资源提供商，这种影响可能会加剧。但是在人工智能研究上，英国依然有着属于自己的资本，全球最顶尖的 25 所大学，英国占了 1/4；随着 Deep Mind、SwiftKey、 Magic Pony 和其他一些英国人工智能公司被收购，人工智能领域的高管和投资者们也逐步融入到这种不断发展的产业生态环境当中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;5. 变现的进程可能会更长&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们遇到的人工智能公司中超过 40％尚未产生收入（图 9）。这可不是我们对「早期阶段（early stage）」公司的臆断，我们所调查的公司中，一般是 2-3 年前建立的，平均大约筹集了 130 万英镑资金，拥有平均 9 个人的团队，每月花销大概 76000 英镑左右。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8oIsGS2mErEqmOQE2GPACGjbLky9iaicnZqlDCYZ7QGqqNmxPBibDXZ1VkxQqUFqqGXfeRpFFqlZn1Q/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大多数人工智能公司（至少是人工智能应用型公司）计划通过被收购获得预收入（pre-revenue）而不是销售软件和服务——这简直就是天方夜谭。我们调查的所有公司都在实施或开发变现计划。为什么这些人工智能公司要比一般的初创花更多的时间去进行变现或规模化？我们得出以下四个原因：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="list-style-type: decimal;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在这个具有挑战性的技术领域内，最低可行性产品（minimum viable product）的门槛可能会很高，它需要更长的开发周期。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;90% 的人工智能公司是 B2B 模式。B2B 典型地具有较长销售周期，它是由许多关注人工智能的公司所推动，如具有蔓生性（sprawling）的和敏感性数据集的金融行业。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;由于数据是单客户数据的集成，并还有数据清理（data cleansing）和用户定制化服务的要求，部署期可能会很长。我们调查的人工智能公司一般有纯粹的软件服务模型，它是由许多具有变现意义的客户进行聚合的，然后定制化而从工程项目中获益（上图 10）。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在初创公司中，可用于实施项目的人员数量有限是很多人工智能公司成长的阻碍。在几家公司的回应中，我们被告知「即使我们有销售人员，我们也无法实施更多的销售活动。」因为他们至少三分之一的团队都在进行开发工作。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由于机器学习人才的高成本，现金消耗率（cash burn rates）的加速增长，更长的变现历程可能对人工智能公司产生巨大的挑战。我们建议人工智能公司需要筹集足够的资本，才能渡这段风险期，以后才能上市或走得更远。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;6. 投资力度会更大且不按常规方式进行&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;全球范围内来看，对人工智能公司的投资往往是比同种程度的平均投资额要多 20% 到 60%（下图 11，2015 年的数据统计）。这也反应了公司在资本供应和融资上的基本面和动力。在产品研发成熟之前，人工智能公司需要更长的研发周期，包括高薪聘请机器学习专家和部署装配整个团队复杂设备，因而人工智能公司对资本的要求也更高。在这些基本的资金需求之外，资本注入因大量投资提供方涌入而虚高不下（许多投资家寻找投资人工智能公司的机会），同时需求是有限的（只有相对少量的 AI 公司需要被投资）。对处于早期发展阶段的 AI 公司的资本投入，在近 5 年内增长了 7 倍，然而可以投资的范围还很有限。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此外，在英国相当数量的少数公司，从种子轮直接跳到远远超过常规下一轮融资的更大额融资阶段（下图 12）。在上一轮融资少于 100 万美金的情况下，3 家英国人工智能公司里就有 1 家在下一轮的融资超过 800 万美金。就如上面所说，这种能力一部分是由人工智能公司的资本需求所驱动的，但是更多原因是由于目前人工智能里比较吸引人的投资机会还是很有限的。与此同时，公司预期市值估价也受公司所收购的初创团队人员数量影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;结论：英国人工智能的拐点&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在过去的 36 个月，英国人工智能领域初期出现了一个转择点。因为人工智能技术已经发展有段时间了而且对其投资增加了很多，人工智能公司的企业家数量增加了一倍。然而，相对于全球的人工智能公司来说，英国的人工智能公司还处于早期发展阶段，这也给投资企业家和从业人员带来前所未有的机会与挑战。四分之三的英国人工智能公司还处于非常早期的发展阶段，而且他们的下一步行动也不尽相同。新创的公司主要关注目前已可以解决的商业应用，而在这些领域中，可获取的数据是充足的且需挑战优化的地方也是明晰的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在，商业模式正在被优化，它将在未来会重新构建。在过去的 24 个月，既有人工智能领域外的模式和发展区域已经在被人工智能企业家追逐。目前人工智能公司想实现盈利将有更长一段路要走，但是有效率的企业家正可以在更早的这个阶段中，利用自己公司可吸引资金的能力来为自己筹得足量的资金。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能所带来的变革还在继续，人工智能公司和其他软件提供企业的界限会越来越模糊。但是今天，我们还是很高兴地突出强调那些将会给社会带来巨大收益的公司。这些公司正在共同勾勒出「第四次工业革命」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文链接：https://medium.com/mmc-writes/artificial-intelligence-in-the-uk-landscape-and-learnings-from-226-startups-70b9551f3e4c#.dpthc5idi&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 22 Dec 2016 12:25:11 +0800</pubDate>
    </item>
    <item>
      <title>演讲 | 微软亚洲研究院刘铁岩：对偶学习推动人工智能的新浪潮</title>
      <link>http://www.iwgc.cn/link/4020107</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心整理&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;演讲：刘铁岩&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;12 月 17 日，中国人工智能学会、中国工程院战略咨询中心主办，今日头条、IEEE《计算科学评论》协办的 2016 机器智能前沿论坛暨 2016 BYTE CUP 国际机器学习竞赛颁奖仪式在中国工程院举办，论坛邀请到今日头条、微软、IBM 等业界科学家以及清华大学、北京大学、Santa Fe 研究所、Georgia Institute of Technology（佐治亚理工）等国内外知名院校学者共同探讨了机器学习的研究现状、前沿创新及应用发展等问题。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微软亚洲研究院首席研究员刘铁岩博士受邀发表演讲。刘博士是微软亚洲研究院首席研究员，IEEE 院士，ACM 杰出会员，CCF 高级会员。他的研究兴趣包括：人工智能、机器学习、信息检索、数据挖掘等。他的先锋性工作促进了机器学习与信息检索之间的融合，被国际学术界公认为「排序学习」领域的代表人物。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWiciae9SNdrqiahnvkgK4Sy47zMjic36769myZZNicb5w0YCsJiayGW42pdzCmydX9ABMBTYxJicCz9GcWsg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;刘铁岩：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;谢谢大家，感谢组委会的邀请，让我有这个机会与大家分享我们的研究工作。我刚才坐在台下聆听了孙茂松老师和 David 的报告，都获益匪浅。首先，老师非常全面的回顾了机器翻译的历史，又有高屋建瓴的讨论，让我们从中学到了很多的东西。其次，很荣幸我的报告排在 David 之后，做优化和机器学习的同事们应该都非常熟悉 David 的 No Free Lunch Theory，尤其在今天全世界都希望用神经网络这「一招鲜」来解决所有问题的时候，更应该仔细琢磨一下这个定理，对大家会有很大的启示。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今天我分享的主题是对偶学习。在对这个主题进行深入讨论之前，我想同大家一起回顾一下最近这段时间人工智能领域的一些飞速发展。我举几个例子，首先是语音识别。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWiciae9SNdrqiahnvkgK4Sy47zSpbzYFwgYwXOvw1g7sRrycuBTKhbx4PSkr7fObs7cBgb5gTDiaEtdBw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;可能很多同学都看到过这则新闻，微软研究院在语音识别方面取得了重大突破，第一次机器学习算法在日常对话场景下取得了和人一样好的语音识别能力，词错误率降低至 5.9%。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二个例子是有关图像识别和物体分割，在这方面微软研究院同样也有世界领先的研究成果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWiciae9SNdrqiahnvkgK4Sy47zNlbaAXU99PZyqGgHXNjCW8TMU23asEyzhlTTAhU9HxgIbynYKzttmQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2015 年，我们研究院发明的 ResNet 算法在 ImageNet 比赛中力拔头筹，超过了人类的识别水平。人眼辨识图像的错误率大概为 5.1%，而 ResNet 的错误率低至 3.5%。今年，在 COCO 物体分割竞赛中，我们研究院同样获得了第一名，和第二名拉开了很大的差距。物体分割比图像分类更难，不但要识别出图片里有什么，还要能够把它的轮廓勾勒出来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第三个例子是机器翻译，最近相关产业界的发展突飞猛进。这一方向微软同样有着世界领先的技术。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWiciae9SNdrqiahnvkgK4Sy47zeniaibM5EATCXpc3fsqO157cSaPw5HMJQrhBPshoWtibkjIZQOKrQcubw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;比如在微软的 Skype Translator 软件里，对话双方可以用不同语言进行交流，系统实现实时语音翻译。如果今天会场上大家使用 Skype Translator 的话，可能就不需要聘请同声传译公司了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第四个例子，最近这段时间人工智能之所以吸引了那么多的眼球，一个重要原因就是它在一些需要极高智商的比赛中取得了关键性胜利。比如 AlphaGo 4:1 战胜了围棋世界冠军李世石。在这场人机大战之后，DeepMind 的科学家没有停止他们的训练，据说今天的 AlphaGo 已经达到了人类专业围棋十三段的水平，十三段对决九段那简直就是秒杀。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWiciae9SNdrqiahnvkgK4Sy47zAtyy3AzeseywnAvF3cWJMCZEcgCnADjqwJcCTso8IM78qzn9nIiaGXA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能的这些成果非常令人振奋，那么这些成果背后又是怎样的技术呢？这就不得不提到深度学习和增强学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWiciae9SNdrqiahnvkgK4Sy47zFRue6OqlRZAIciacnjdt8Vkh4CkGvS340w4esgDz7Hsby1MrXMO0o7Q/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深度学习使用的是非常复杂，层次很深，容量很大的非线性模型，如深层神经网络，这样的模型可以很好的拟合大量的训练数据，从而在很多识别任务中表现突出。增强学习是一种持续学习技术，它不断地和环境进行交互，根据环境的反馈更新模型。这两种技术还可以相互结合，我们称之为深度增强学习。AlphaGo 背后的核心技术就是深度增强学习。那么，到底深度学习和增强学习是不是真的已经非常完美，可以解决我们面临的所有人工智能问题呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其实答案是否定的。仔细分析一下，就会发现这两项技术都存在本质的弱点。首先，目前深度学习的成功离不开大量的有标签训练数据。但是获得海量有标签数据的代价是非常高的，在某些特定的邻域甚至是不可能完成的任务。比如医疗领域的疑难杂症，本身样本就非常少，有钱也无法取得大量的有标签数据。正所谓成也萧何，败也萧何，大数据推动了深度学习的成功，但也成为了深度学习进一步发展的瓶颈。其次，增强学习虽然不需要利用传统意义上的有标签数据，但是它的学习效率并不高，需要跟环境进行大量交互从而获得反馈用以更新模型。然而，有时和环境的频繁交互并不现实。比如，在我们学开车的时候，依赖于频繁地和环境（周围的路况，其他的车辆）进行交互是很危险的，可能还没学会开车就已经发生交通事故了。这就解释了为什么增强学习取得成功的领域很多都是模拟环境，比如说打电子游戏、下围棋等等，它们规则明确，可以无限次重复。但当把增强学习应用到一些实际场景里，需要和实际用户进行交互，还可能带有无法挽回的风险，是不是还能取得同样的效果呢？目前还没有被证实。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWiciae9SNdrqiahnvkgK4Sy47zUg7og2HjuV2vFfMEn5Y8g5aRvV9xXYDyoiaBXVniaUs9hXmEicV9YQo3g/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;了解了深度学习和增强学习的弱点以后，我们不禁要问：有没有一种新的学习范式可以克服他们的弱点？能否可以不依赖于那么多有标签的数据，能否不需要跟真实环境做那么多次交互，就可以学到有效的模型？为了回答这个问题，我们首先来对现有的人工智能任务做一个仔细的分析。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWiciae9SNdrqiahnvkgK4Sy47zBpPS1tiafI20ibENOIwEfFiaQsicAuJtQsRZKyYK8AibunsMhicLjx2PbBzw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过分析，我们发现了一个非常重要的现象：现实中，有意义、有实用价值的人工智能任务，往往是成对出现的。比如在做机器翻译的时候，我们关心从英语翻译到汉语，我们同样也关心从汉语翻译回英语。再比如，在语音领域，我们既关心语音识别的问题，也关心语音合成的问题（TTS）。图像领域，我们既关心图像识别，也关心图像生成。类似这样的对偶任务还有很多，比如在对话引擎、搜索引擎等场景中都有对偶任务。这种现象给了我们什么启示呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一点，由于存在特殊的对偶结构，两个任务可以互相提供反馈信息，而这些反馈信息可以用来训练深度学习模型。也就是说，即便没有人为标注的数据，有了对偶结构，我们也可以做深度学习了。第二，这两个对偶任务，可以互相充当对方的环境，这样我们就不必跟真实的环境做交互，这两个对偶任务之间的交互就可以产生有效的反馈信号了。总而言之，如果我们能充分地利用对偶结构，就有望解决刚才提到的深度学习和增强学习的瓶颈——训练数据从哪里来、和环境的交互怎么持续进行下去。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;基于以上的思考，我们提出了一个新的学习范式，叫做对偶学习。它的思路非常简单。我们假设学习过程中有两个智能体，其中一个智能体从事的是原任务，就是从 X 到 Y 的学习任务；而另外一个智能体从事的是对偶任务，也就是从 Y 到 X 的学习任务。假如我们把 X 用第一个智能体的模型 F 映射成 Y，再利用第二个智能体的模型 G 把它反映射成 X’。通过比较 X 和 X'我们其实就可以获得非常有用的反馈信号。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWiciae9SNdrqiahnvkgK4Sy47zp1y10drdFiaS929mo0icSWUG9P87SreSbetbvKJeypV8GUrpMC9uaKtA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其实这个做法在刚才孙茂松老师的演讲中已经提到过，有人曾经用这种翻过去再翻回来的方式判断机器翻译模型的好坏。如果 X 和 X'的差异很大，就说明这个翻译系统不靠谱，说明模型 F 和 G 至少有一个不好；如果 X 和 X'很接近，就给了我们一个利好的消息，就是这两个模型都不错。除了比较 X 和 X'的差异，其实还有很多其他的反馈信息可以被利用。下面我们以机器翻译为例，做个详细的说明。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWiciae9SNdrqiahnvkgK4Sy47zuSeTIRbRKeN2dicrNwIFUxM9oa6FxPr2YktmcnBxx1amTDcfSps4GIg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;假设我们有一个英文的句子 X，通过翻译模型 F 的作用，得到一个中文句子 Y。那么 Y 作为一个中文句子是不是符合语法，是不是顺畅，X 到 Y 之间的关系是否和英汉词典一致等等，都可以作为反馈信息。同样，当我们用模型 G 把 Y 再变成英文句子 X'以后，也可以去衡量 X'是不是符合语法，是否顺畅、X'与 Y 的关系是否与英汉词典一致，以及 X'和 X 是否相似等等，都可以作为反馈信息。利用这些反馈信息，我们可以使用包括 Policy Gradient 在内的方法，来一轮一轮地更新我们的模型，直到最终得到两个满意的模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;上面的这个过程可以无限循环下去，每次随机地抽选一个单语语句，做对偶学习，更新模型，然后再抽选下一个单语语句，进行对偶学习。那么这个过程会不会收敛呢？其答案是肯定的，以机器翻译为例，我们可以证明，只要机器翻译模型 F 和 G 的解码部分都使用的是随机算法，比如 beam search，这个对偶学习过程就一定是收敛的，也就是说你最终会学到两个稳定的模型 F 和 G。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那么接下来，我们就来看看这样的稳定模型是否有效。我们对比的算法是一个非常经典的神经机器翻译方法，而且用的是他们自己开源的代码。为了训练这个对比算法，我们使用了全部的双语标注数据。而我们自己提出的对偶学习算法并不需要双语标注数据，用单语数据就可以进行学习和迭代了。不过万事开头难，我们还是要给这个学习过程一个初始化。在初始化过程中，我们使用了 10% 的双语语料训练了一个相对比较弱的模型，然后用对偶学习的迭代过程不断提高它。也就是说，在初始化完成之后，我们就不再使用任何双语的标注语料了，而是靠两个对偶任务互相提供反馈信息进行模型训练。好，那我们来看看实验结果如何。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWiciae9SNdrqiahnvkgK4Sy47zeHKzzZ1UCIdV7y2yPYOsXRaTr2pPlc1TibCkjlRKexAibXtcXicpj2agA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这两张图展示了法英和英法翻译的实验结果。以第一张图为例，最左边这根柱子对应的是用 10% 双语语料训练的初始模型；最右边这根柱子对应的是用 100% 双语语料训练的翻译模型。可以看出，初始模型确实比较弱。当我们使用对偶学习的方法，虽然不再利用任何有标注的双语数据，我们仍可以很快的接近甚至超过用百分之百的双语语料训练出来的模型。这个结果非常令人振奋。不仅如此，我们的实验发现，对偶学习更不容易饱和，因为无标签的单语数据非常丰富、非常多样化，因此通过不断调节单语数据源和调整反馈信息，可以持续提高模型的有效性。相反，使用双语语料比较容易饱和，过几遍数据以后，当信息被挖掘得足够充分，想要再提升模型精度就变得非常困难了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如上这种振奋人心的结果是否只局限在机器翻译领域呢？其他领域是否也可以使用类似的方法得到提升呢？答案是肯定的，前面我提到的很多人工智能的任务都具有对偶结构，因此都可以用对偶学习来解决。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWiciae9SNdrqiahnvkgK4Sy47z1AkNEib2FAcpyj5U5XQLz7pFPGXaSmHZqWEBtSbwIMiazSPtaHHh2bjg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这张 PPT 展示了在语音识别和语音合成方面如何定义反馈信号，从而进行对偶学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;strong&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWiciae9SNdrqiahnvkgK4Sy47zZZQ5z2ocBPAsjZvHgHpxzlHAEGhGjxVgSdHq6IeuElpyqhCibHc646Q/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;同样，这张 PPT 展示了在图像识别和图像生成方面如何定义反馈信号，从而进行对偶学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWiciae9SNdrqiahnvkgK4Sy47ztT3mSQCHJ25S0Yic8Fu4AZ7VHeb2R1dLKKlDdxFEVJ5bmVbiafvNSScw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而这张 PPT 则展示了在对话引擎方面如何定义反馈信号，从而进行对偶学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;说到这里，可能很多人会有疑问，虽然我们说对偶学习应用很宽泛，但是我们举的例子都有一个共同特点，就是真实的物理世界里确实存在两个对偶的任务。那么，如果我们要解决的问题并不存在一个天然的对偶任务怎么办？其实这个也没关系，即使没有物理上的对偶性，也可以通过虚拟的对偶性来完成对偶学习。我举两个例子。第一个是在深度神经网络领域常用的 Auto Encoder，仔细分析一下，它其实是对偶学习的一个特例。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWiciae9SNdrqiahnvkgK4Sy47zibcRP2iaoueLAjx5ZNTVnMAJ4WiaxX7C3E0rC87R53DUVyLB3J7icZAhTQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Auto Encoder 原本的任务是要学习从输入层到隐层的一个映射（即编码），为了有效地学习这种映射，我们人为添加了一个虚拟任务：就是从隐层到输入层的逆映射（即解码，请注意图中的输出跟输入是一样的数据），这样就形成了机器学习的闭环。如果用对偶学习的语言描述一下，就是这张图：通过人为增加解码回路，使虚拟的对偶性得以成立，从而实现对偶学习。不过需要指出的是，Auto Encoder 和对偶学习有一些小差别，Auto Encoder 只关心单边任务的模型（也就是编码器），而在标准的对偶学习中，我们同时关心两个模型，想把它们都学好。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWiciae9SNdrqiahnvkgK4Sy47zmCBEToeCZcZD4ic6VDT4VzhXicdAIwr0U2V3NFfZetKTia6Sk2RkXgISQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一个例子是最近这两年特别火的——Generative Adversarial Nets（GAN）。它的目标是学习一个图像生成器，为此通过一个鉴别器不断给生成器提供反馈信息（也就是判别生成器生成的东西是真是假）。这样的博弈过程可以获得一个非常有效的图像生成器，用它可以自动制造训练样本来进行深度学习。很显然，GAN 也可以用对偶学习的语言进行描述，并且它也只是对偶学习的一个特例：它只关心单边生成器的有效性，而标准的对偶学习会同时关心生成器和鉴别器的有效性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;到此为止，无论是天然的对偶学习，还是虚拟的对偶学习，都是用来解决无监督学习问题的。那么，如果实际中我们的训练数据已经非常多了，对偶学习的思想还有用吗？我们的答案是：有用，而且非常有用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;让我们来看一下监督学习的例子。我们有一个样本 X，原任务是要预测它的标签 Y。为此，我们可以使用已有的很多监督学习技术加以实现。但如果我们再给它人为增加一条对偶回路会怎样呢？假设存在一个对偶任务，是从标签 Y 到 X 的预测。那么原任务和对偶任务其实存在着非常内在的联系。利用全概率公式和贝叶斯公式我们可以很容易知道，这两个任务背后的条件概率是互相约束的，利用这一点可以构造一个非常强的正则项来提高模型的学习效率。我们在机器翻译上的实验表明，加入这个对偶正则项，翻译模型的 BLEU score 有大幅度的提升。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWiciae9SNdrqiahnvkgK4Sy47z1IibNOdgLER8OhZ8PIiaTN3FgpD5ad74BePFHSkLBQFOh1ZjrOibZpntA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;同样的道理，对偶学习的思想甚至可以提高 inference 的性能。假设我们的模型已经训练好了，原任务是要用它来做预测。传统的做法是，给定一个样本 X，基于已有模型，寻找能够使其条件概率 P(Y|X) 最大化的 Y 作为 inference 的结果。如果我们运用对偶学习的思想，就会发现问题还可以反过来看。从对偶任务的模型出发，利用贝叶斯公式，同样也可以导出条件概率 P(Y|X) 来。按理说这两个条件概率应该是一致的，但是因为原任务和对偶任务是独立进行的，实际中它们可能并不完全一致，那么如果综合考虑这两个条件概率，我们的置信度会得到提升。相应地，inference 的结果也会得到明显的提升。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWiciae9SNdrqiahnvkgK4Sy47z83dpSXaLXHwN0DgjM1un3odjo4dY1oFu41SkOTWkO7dbhZB2fasp5A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;到此为止我们介绍了对偶学习在无监督学习上的应用、在没有天然对偶结构时如何使用虚拟回路实现对偶学习、以及如何把对偶学习的思想延展到有监督学习和 inference 之中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWiciae9SNdrqiahnvkgK4Sy47zex44sr1FU4hMTGQL5p56icpM30sTICNxiaOZohAlH1y72RJYBYw67CNw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;事实上，对偶学习是一个新的学习范式，而不单是一个技巧。它和我们熟知的很多学习范式，如无监督学习、半监督学习、co-training、多任务学习、迁移学习都有联系，又有显著不同。它提供了一个看待这个世界的不同视角，对很多难题提供了新的解题思路。我们非常有信心对偶学习在更多的领域将会取得成功。我们组的同事们正在这个方向上积极探索，也希望在座的各位能够加入我们，一起去推动对偶学习的发展，掀起人工智能的新浪潮，谢谢大家！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心整理，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 22 Dec 2016 12:25:11 +0800</pubDate>
    </item>
    <item>
      <title>特写 | 谷歌研究主管Peter Norvig：创造智能不需要复制人类</title>
      <link>http://www.iwgc.cn/link/4020108</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Forbes&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Gil Press&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：Rick、微胖、杜夏德&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2016 年，人工智能被报道了很多次，不只是因为谷歌人工智能程序战胜世界顶级围棋手李世乭。机器战胜人类引发巨大反响，有的人兴奋，有些人满是焦虑，所有人都设想——人工智能的目标是达到「人类智力水平」，或像一些人所预测的「超级智能（superintelligence）」。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我并不那么在乎我们正在建造的东西是不是真的智能，」谷歌研究部主任 Peter Norvig 说。「我们知道如何建造真正的智能——我和我妻子已经尝试过两次，尽管她的贡献更多。我们不需要复制人类。这就是为什么我专注于利用工具来帮助我们，而不是复制我们已经知道的做事方式。我们想要人类与机器合作，做一些他/它们无法单独完成的事情。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Norvig 进一步对神经科学与人工智能研究做了有用的区分。他说：「理解大脑令人着迷，但是我认为把它和人工智能的目标（即解决问题）区别开来，很重要。」每个领域都可以相互学习，但是，「如果你将二者混为一谈，就好像同时瞄准两座山峰——最终，你往往会落在山峰之间的低谷中」。要避免这种情况，明智的做法是明确目标，小心使用具有误导性的标签：「如果有比神经网络更好的表达，情况会更好些；如果 Google Brain 团队换一个名称也许我们会更好。Google Brain 团队提供解决问题的编程工具——它不是理解大脑的工具，也并不一定要与大脑的工作原理相关。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为解决具体问题而开发工具以及教别人如何操作——是 Norvig 过去三十年职业生涯的标志，那是他在加州大学伯克利分校完成其博士论文之后，论文研究的是利用计算机提高文本理解能力。1995，他（与 Stuart Russell）合著了《人工智能：一种现代方法（Artificial Intelligence: A Modern Approach）》一书，该书成为这一领域的主要教科书（现在是第三版）； 2011 年，他（与 Sebastian Thrun）联合教授网络课程《人工智能导论（Introduction to Artificial Intelligence）》，有来自 209 个国家的 160,000 名学生参加。由于这些及其他成就，Norvig 在 2001 年（「由于他对教育资料、自然语言处理技术、基于网络的技术以及科研管理和领导力方面的重大贡献」）成为国际人工智能协会（Association for the Advancement of Artificial Intelligence/AAAI）会士，2006 年（「由于他对人工智能和信息检索方面的贡献」）成为美国计算机协会（Association for Computing Machinery/ACM）会士。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Norvig 从很早时候起就一心关注着真正的人类智能。六年级时，他就写信向当地报纸抱怨科学报告中的数学盲化与敷衍话语。高中时，有位老师建议他成为一名科学记者，然而 BASIC 编程的学习经历以及一堂语言课程使他想到了用计算机来处理自然语言，这是一条迥然不同的职业道路。Norvig 说，这个兴趣可能也源自他的父亲——一位数学教授以及他的母亲——一位英语文学教授的综合影响。在布朗大学主修应用数学期间，他偶然发现了一门从认知科学角度教授的心理学课程，引领他朝人工智能领域又迈进了一步。因此，在麻省理工学院的一个衍生机构工作了两年并「接触到研究生的大学生活方式」之后，他觉得获得博士学位会很有趣，于是就读于加州大学伯克利分校的计算机科学系。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那时正是消减人工智能研究投资的时期（所谓的「人工智能寒冬」），但 Norvig 认为「这是最有趣的领域——你正在解决最困难的问题。当时希望研究生能深钻某一领域，但你并不期望最终会得到一个能改变世界的产品，所以，人工智能寒冬的说法并没有对我产生太多干扰。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;结果，那段时间却是人工智能研究的重大转折期。「当我还在读研究生时，」Norvig 说，「这一研究领域发生了转变，在此之前，一个专家系统要雇佣很多研究生来手写逻辑规则，积累足够的量以获取好的结果。但是，你永远都做不到——因为编写这些规则太难了。所以，我们转向一种概率的方法，你处理的是不确定性，目标是得到最好的答案，而不是试着复制专家思维。这个方法在医疗诊断和语音识别以及其他领域获得了成功，事情进展得很顺利。」另一个相关的重大变化「是使用数据，而不是自己来思考所有规则」，通过统计分析发现数据中的规则。在一篇影响深远的论文中，Norvig 及其谷歌同事要求一些领域（比如机器翻译和语音识别）的其他研究员避开理论建构，而去「拥抱复杂性，充分利用我们最好的盟友： 不合理的数据有效性。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在过去的十五年里，Norvig 一直在谷歌工作，该公司参与解放了——并成功挖掘了——Web 时代的大数据浪潮。在这之前，他经历了各种不同的研究环境，先后任职于加州大学伯克利分校、Sun Microsystems、两家初创公司以及美国宇航局（NASA）艾姆斯研究中心。他为什么离开学术界？「作为一个大学老师，很难得到资源去做更大的项目，」Norvig 说。「所有都是一点一点地，一段时间带一个研究生，你所需要的计算资源、找到一个会为你提供数据的合作伙伴，所有这一切对一个大学老师来说都是困难的。而在工业体系中，你可以得到所有你需要的资源。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Norvig 将研究环境从企业转向了政府，成为一名 NASA 艾姆斯研究中心的计算科学部门主管，为机器人航天器开发自驱动软件，比如 Mars Rover。至于业界的研发，对实际世界结果的需求会引导着基础研究方向。「但是在一些组织和政府方面，」Norvig 说，「并没有太多不同。如果你那个环节行不通，那么你就失去了整个任务和数亿美元。一切都必须可行，所以进程有点慢。」这种拉长进度的做法也适用于组织工作的其他方面。鉴于 NASA 所正在试图实现的事情，测试通常是作为一次模拟来进行。Norvig 将其与谷歌相比较，谷歌面对的一直是现实世界，来自真实用户的反馈是即时的，而万一失败了，该问题第二天就可以得到解决。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌在研究工作方面的这种即时性状态不仅是时间上的，也是空间上的，就好像不同职业的人坐在一起办公。不同于传统的产品团队，Norvig 说，「那里的研究人员创建了一个原型然后画在墙上，接着工程师们会重新做一遍来实现它，」谷歌创造了一个非常独特的产品开发环境，其中「研发」与「开发」成员在同一个团队中是平等的。「我们觉得我们将一直发展下去，因此我们希望大家能够从头到尾地参与进来，这样他们可以继续作出改进，」Norvig 说。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个「混合研究模型（hybrid research model）」中的一个重要激励因素在于开发出那些研究人员愿意使用的生产环境工具。这种态度逐渐扩展成开发一个内部使用的世界级 IT 基础设施，为研究人员提供最好的工具和机会来实现自己的想法。Norvig 说，早期有一些抵触自主开发，想直接从 IT 厂商那里购买硬件和软件，但是，「自己打造一些东西通常是正确的决定——我们相较之前的做法更进了一步，那么，我们就可以进行快速迭代，而不是为了一个小改动就去找一个供应商，这种做法会拖慢所有的进程。」激励研究人员的另一个因素是允许他们发表论文，并对学术合作的其他渠道给予支持，这为他们提供机会去扩展自己研究在该领域中的影响，并有机会脱离渐进式研究，致力于「范式转变（paradigmatic changes）」或谷歌的「登月计划（moonshots）」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是，最吸引计算机科学家的恐怕是数据，这些数据掌握在谷歌手中。在谷歌，他们可以分析带有现实世界约束条件的大量数据，做一些之前项目或研究规模无法比拟的实验。这种大规模的、实验性的、迭代的重点研究被注入了丰富的数据，正如 Norvig 所指出的，三十亿的互联网群体和一部「口袋里的超级计算机」帮助了谷歌————及其他公司的研究人员/开发者——发明出实用而成功的、以数据为中心的人工智能应用程序，其中大多数应用最近都使用了深度学习和及其他经过改进的新机器学习方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;过去几个月中，我在很多场合听到 Norvig 谈及这些年来将机器学习应用到全球所有信息——在 O'Reilly AI Conference 上，在 波士顿举行的 ACM 会议上，一次 ACM 的网络研讨会以及在一次电话访谈中——过程中所学到的东西。他对比了机器学习和传统的软件开发，突出了前者的优势以及所独有的难题。Norvig 说，机器学习更省事，你要做的就是输入大量数据给计算机，而不是让程序员喝咖啡、吃披萨。输出也要快得多。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是，也有很多挑战。Norvig 说，「机器学习能让你跑得更快，但是，较之于跑得慢，跑快也会有问题，系统崩溃也更加惊人。」机器学习比传统软件更难，因为调试起来更有难度——并没有传统软件那样现成、验证过的调试工具和程序，也很难隔离一个 bug；如果做了任何改变，最后可能会改变一切；另外，如何以及何时动用人力协助，训练使用者不要过分依赖机器，也是不好决定，而且还需要考虑新数据或你正用来训练机器的数据的变化；机器学习中的数据使用引发了许多深层次的问题，比如隐私、安全以及公平。Norvig 的底线可援用丘吉尔关于民主的格言：在所有人类尝试过的制度中，民主是最不坏的选择。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在与各种听众的接触中，Norvig 谈到了很多重要问题，这或许有助于加快问题的解决。最终，随着各行业和政府组织越来越多地使用机器学习，在理解和管理上，机器学习会变得像传统软件。不过，计算机所能做的会持续、快速地发生变化，因此，针对当前问题之一的每个解决方案，可能会出现一些新的小问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今天，我们正在经历人类与计算机互动方式的根本变革，毫无疑问，这会带来新的问题，也会带来新的机遇。我们正在从与应用程序互动占主导地位的今天，转变到与虚拟助手互动（有时是通过语音进行互动）的时代，「就像那些发明了鼠标和菜单时代的互动方式的先行者们，今天，当我们与一个系统对话时，我们不得不发明新的互动方式。现在，你电脑和手机上的所有一切都放在应用程序中，想要做什么的时候，你首先需要决定点击那个应用程序。但是，当你有了虚拟助手后，能够整合在一起的服务就能合并起来。」如何整合这些服务并让用户满意可能是后应用程序时代的一个巨大挑战，此时，新的人机互动类型以及技术会是投资、研发、失败和胜利的一个焦点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这场人工智能的复兴中，同很多人一样，Norvig 把一些新发现的亮点和成功归功于增长的计算机能力和大量数据的可用。但是，他认为还有两个基本的转变也很重要，一个是计算机研究和编程的供给方，另一个是需求方，也就是我们希望计算机能做什么事情。Norvig 引用了 MIT Hal Abelson 的观点，Abelson 观察到计算机科学已经从数学科学转变为自然科学，从计算出一个正确答案转变为观测，从传统的计算机软件转变为机器学习。类似的，需求已经从期望计算机把诸如加数字这样的问题做的更好转变为一些我们真正在意的事情，这些事情不像加加减减那么清晰明确，Norvig 说：「读一些有趣的东西，获取适当的推荐，分享图片并知道图片中有什么，这就是人工智能要做的事情。当我们想要优化或者给出最佳推荐时是没有一个确定答案的，都是不确定的。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了给这些转变带来的新应用和计算机使用方式打开机遇，Norvig 对打造机器学习和人工智能产生了兴趣，「这是所有程序员的必备技能而不是某个专业领域。」他担心没有足够的人工智能人才，并在过去的一年中一直专注于开发方便易用的工具。「如果你是一个优秀的程序员，你就应该有能力去自学人工智能方面的知识自己研究机器学习，不一定需要一个博士学位。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今天的很多计算机程序员和博士候选人 没有在等着人工智能的普及化，都在忙着重复训练并总是将工作重心放到谈论最多最令人兴奋的计算机科学专业。「五年前，一个记者问我『人工智能是怎么走向失败的？』」Norvig 回忆到。「今天，他们会说『人工智能怎么占领世界，杀死所有人类或者霸占我们的所有工作。』」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;看到各种人工智能任务的表现每年以 30% 速度增长，Norvig 很高兴，但他也清楚这些进展也带来一些偏离真正目标的炒作。「我没有看出这个世界会出现奇点。我们的观点是这个世界是复杂的，变得更加聪明并不能解决很多世界问题。」而且：「比获取类人性能更重要的是有些有用的东西不一定要像人，智能明确它要做什么不能做什么就可以了。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;提供有用的东西。解决具体的难题。不要被机器终将变得和人类一样这种莫名的期望带偏了路。了解训练机器时需要做哪些提升来在不确定的情况下做决定，传播使用知识。注重增强人类智力并开发出人机团队合作的艺术。这就是「人工智能」的全部，Peter Norvig 如是说。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;原文链接：http://www.forbes.com/sites/gilpress/2016/12/21/artificial-intelligence-pioneers-peter-norvig-google/#3a2e34d27991&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 22 Dec 2016 12:25:11 +0800</pubDate>
    </item>
    <item>
      <title>学界 | 强化学习可能会出错，OpenAI解读错误奖励函数问题和应对方法</title>
      <link>http://www.iwgc.cn/link/4020109</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自OpenAI&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：ARIO AMODEI、JACK CLARK&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;强化学习算法可能会出问题，而且有时候出问题的方式惊人又反直觉。在这篇文章中，我们探索了一种失败的模式——即当你错误指定了你的奖励函数（reward function）时会出现的情况。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;OpenAI 最近开始使用 Universe 来进行新的强化学习实验了——Universe 是我们用于测试和训练人工智能代理的软件。正如近期的实践中出现的情况一样，有时候这些实验会揭示出强化学习的一些问题。在下面的例子中，我们给出了当错误指定了奖励函数时会发生的情况——即错误指定的奖励函数（mis-specified reward function）通过优先获取奖励信号而非其它的成功度量来破坏其环境。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;要设计出安全的人工智能系统，需要我们设计出不会试图这样做的算法，并且我们需要学会如何指定和塑造目标从而使这些目标不会被我们的人工智能代理错误解读。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;CoastRunners 是我们一直用于训练的一款游戏。这个游戏目标是（就像大多数人类理解的一样）尽快结束船只比赛并且领先其他玩家。CoastRunners 不会在路线上直接奖励玩家的进度，玩家需要到达路线上的指定目标点才能获得更高分数的奖励。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们假设玩家获得的分数反映了完成该比赛的非正式目标，所以我们在这个游戏中包含了一个内部基准，用来测量强化学习系统在比赛游戏上的表现。但是，事实证明这种目标的排布方式让强化学习代理无需完全跑完赛道也能获得高分。这就导致了一些我们训练强化学习代理玩这个游戏时所没有预料到的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;iframe class="video_iframe" data-vidtype="1" allowfullscreen="" frameborder="0" height="417" width="556" data-src="https://v.qq.com/iframe/preview.html?vid=y0358pfkoz8&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0"&gt;&lt;/iframe&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该强化学习代理找到了一个孤立的环礁湖，它在那里可以不停地转圈，一次又一次地经过三个目标，它计算好了时间，这样就能在目标点重新生成的时候总是击中目标而获得分数。尽管会重复地着火、撞到其它船，但我们的代理还是成功通过这一策略得到了比以正常的方式完成比赛所可能得到的最高分还高的分数。我们的代理得到的分数平均超过人类玩家 20%。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管在视频游戏这一场景中这是无害的而且可能还很有意思，但这种情况表明了强化学习代理所具备的一个更为一般化的问题：它很难或不能确切地理解我们想要它做的事，因此我们常常最后会使用不完美但易于测量的代表。通常这么做的表现还算不错，但有时候这也会带来意料之外甚至危险的动作（action）。总的来说，它违反了基本的工程原理——即系统应该是可靠的和可预测的。我们也在我们研究论文《Concrete AI safety problems》中更详细地探索了这一问题。（参见机器之心的文章《研究人工智能安全不再抽象：谷歌、OpenAI 合著论文，提出更加实用的五大研究课题》。）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们可以怎样避免这样的问题呢？除了小心设计奖励函数之外，OpenAI 也正在探索其它有助于减少错误指定奖励的情况的研究方向：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;从演示中学习让我们可以避免直接指定奖励，而是学习模仿人类完成比赛的方式。在这个案例中，因为绝大多数人类都会努力完成赛道比赛，我们的强化学习算法就会学会这么做。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;除了人类演示，我们也可以整合人类的反馈——评估每一轮的质量或者以一种交互式的方式与代理共享控制。很少的一点评估反馈就有可能能阻止这个代理不停地转圈。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在许多相似的游戏上可以使用迁移学习（transfer learning）进行训练，并为这个游戏推理出一个「常识（common sense）」奖励函数。这样的一个奖励函数可能会根据「通常一个游戏都有一个目标」这样的常识而选择优先结束比赛，而不是把重点放在这个游戏的奖励函数的特别性质上。这似乎与人类玩这个游戏的方式更相似。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些方法可能都有自己的缺点。比如说，迁移学习需要基于许多相似环境的奖励函数来推导新环境的奖励函数。这种推导本身可能就是有缺陷的——比如说，如果一个代理在一些赛车游戏上进行了训练并且在这些游戏中脱离道路得到惩罚很小，那么它就可能错误地总结认为：脱离道路是一种有更高赌注的新方法，没什么大不了的。更微妙的是，如果这个奖励推导的过程涉及到神经网络，那么该网络中的对抗样本（adversarial examples）就可能会导致奖励函数有「不自然的」高奖励区域但却不对应于任何合理的真实世界目标。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些问题的解决是很复杂的。我们希望 Universe 能让我们可以快速地发现和解决新的失败模式，并帮助我们最终开发出我们可以对其行为真正有信心的系统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;原文链接：https://openai.com/blog/faulty-reward-functions/&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 22 Dec 2016 12:25:11 +0800</pubDate>
    </item>
  </channel>
</rss>
