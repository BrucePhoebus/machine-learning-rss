<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>资源 | TensorFlow版本号升至1.0，正式版即将到来</title>
      <link>http://www.iwgc.cn/link/4292352</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自github&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote style="color: rgb(62, 62, 62); font-size: 16px; white-space: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/blockquote&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;2015 年 11 月份，谷歌宣布开源了深度学习框架 TensorFlow，一年之后，TensorFlow 就已经成长为了 GitHub 上最受欢迎的深度学习框架（参见机器之心文章《&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720407&amp;amp;idx=1&amp;amp;sn=768d7248e0ab5fa469dbae86d11152e1&amp;amp;chksm=871b0ce9b06c85ffefa2e0c8f6fb7ae4cc1c0500cda7bad008fe68ed6b87d7c8765d138e1fd1&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720407&amp;amp;idx=1&amp;amp;sn=768d7248e0ab5fa469dbae86d11152e1&amp;amp;chksm=871b0ce9b06c85ffefa2e0c8f6fb7ae4cc1c0500cda7bad008fe68ed6b87d7c8765d138e1fd1&amp;amp;scene=21#wechat_redirect"&gt;深度 | TensorFlow 开源一周年：这可能是一份最完整的盘点》&lt;/a&gt;），尽管那时候 TensorFlow 的版本号还是 v0.11。现在，TensorFlow 的一岁生日之后两个月，TensorFlow 社区终于决定将 TensorFlow 的版本号升至 1.x，并也已于昨日发布了 TensorFlow 1.0.0-alpha，其新增了实验性的 Java API，并且提升了对 Android 的支持。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;发布地址&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;官网：https://www.tensorflow.org/versions/r1.0/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GitHub：https://github.com/tensorflow/tensorflow/releases&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;主要特性和提升&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;TensorFlow Debugger (tfdbg)：命令行接口和 API&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;增加新的 python 3 docker 镜像&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;使 pip 包兼容 pypi。现在可以通过 pip install tensorflow 命令来安装 TensorFlow 了&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Android：人员检测+跟踪演示，是通过使用了深度神经网络的可扩展目标检测实现的&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Android：预构建的 libs 现在每晚（nightly）构建&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;新的（实验性的）Jave API：https://github.com/tensorflow/tensorflow/tree/master/tensorflow/java&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;API 的重要更改&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;TensorFlow/models 被移到了一个单独的 GitHub repository.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;除法和取模运算符（/, //, %）现已匹配 Python（flooring）语义。这也适用于 tf.div 和 tf.mod。为了获取强制的基于整数截断的行为，你可以使用 tf.truncatediv 和 tf.truncatemod.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;tf.divide 现在是推荐的除法函数。tf.div 还将保留，但其语义将不会响应 Python 3 或 from future 机制.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;tf.reverse 现在是将轴的索引反转。例如，tf.reverse(a, [True, False, True]) 现在必须写成 tf.reverse(a, [0, 2])。tf.reverse_v2() 暂时保留，直到 1.0 final 版.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;tf.mul、tf.sub 和 tf.neg 被弃用，现在使用的是 tf.multiply、tf.subtract 和 tf.negative.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;tf.pack 和 tf.unpack 被启用，现在使用的是 tf.stack 和 tf.unstack.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;TensorArray.pack 和 TensorArray.unpack 将被启用，取而代之的是 TensorArray.stack 和 TensorArray.unstack.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;以下 Python 函数有参数修改，以在引用特定维度时使用 axis. 我们目前基于兼容性的考量而保留了原来的关键词参数，但我们将在 1.0 final 版中移除它们。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: circle;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;tf.argmax: dimension 变成 axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;tf.argmin: dimension 变成 axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;tf.count_nonzero: reduction_indices 变成 axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;tf.expand_dims: dim 变成 axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;tf.reduce_all: reduction_indices 变成 axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;tf.reduce_any: reduction_indices 变成 axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;tf.reduce_join: reduction_indices 变成 axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;tf.reduce_logsumexp: reduction_indices 变成 axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;tf.reduce_max: reduction_indices 变成 axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;tf.reduce_mean: reduction_indices 变成 axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;tf.reduce_min: reduction_indices 变成 axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;tf.reduce_prod: reduction_indices 变成 axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;tf.reduce_sum: reduction_indices 变成 axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;tf.reverse_sequence: batch_dim 变成 batch_axis, seq_dim 变成 seq_axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;tf.sparse_concat: concat_dim 变成 axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;tf.sparse_reduce_sum: reduction_axes 变成 axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;tf.sparse_reduce_sum_sparse: reduction_axes 变成 axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;tf.sparse_split: split_dim 变成 axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;tf.listdiff 已被重命名为 tf.setdiff1d 以匹配 NumPy 命名.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;tf.inv 已被重命名为 tf.reciprocal（分量互逆）以避免和矩阵求逆的 np.inv 混淆&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;tf.round 现在使用了四舍六入五留双规则语义，以匹配 NumPy.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;tf.split 现在以相反的顺序取参数，并使用了不同的关键词。特别地，我们现在将 NumPy 顺序匹配成了 tf.split(value, num_or_size_splits, axis).&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;tf.sparse_split 现在以相反的顺序取参数，并使用了不同的关键词。特别地，我们现在将 NumPy 顺序匹配成了 tf.sparse_split(sp_input, num_split, axis). 注意：现在我们暂时让 tf.sparse_split 需要关键词参数.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;启用 tf.concat 运算符，现在请暂时切换成 tf.concat_v2 . 在 Beta 版中，我们将更新 tf.concat 以匹配 tf.concat_v2 的参数顺序.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;tf.image.decode_jpeg 默认使用更快的 DCT 方法. 速度的提升牺牲了一点保真度。你可以通过特定属性 dct_method='INTEGER_ACCURATE'来恢复原来的行为.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;tf.complex_abs 已被从 Python 接口移除. 应该使用 tf.abs，它支持复数张量.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;模板.var_scope 属性重命名为 .variable_scope&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;SyncReplicasOptimizer 被移除，SyncReplicasOptimizerV2 重命名为 SyncReplicasOptimizer.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;tf.zeros_initializer() 和 tf.ones_initializer() 现在返回一个 callable，其必须用 initializer 参数调用，在你的代码中用 tf.zeros_initializer() 替代 tf.zeros_initializer.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;SparseTensor.shape 重命名为 SparseTensor.dense_shape. SparseTensorValue.shape 也一样.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;移除了原来的 tf summary 运算符，比如 tf.scalar_summary 和 tf.histogram_summary. 取而代之的是 tf.summary.scalar 和 tf.summary.histogram .&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;移除 tf.train.SummaryWriter 和 tf.train.SummaryWriterCache.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;从公共 API 中移除 RegisterShape . 现在使用 C++ 形状函数注册.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;从 Python API 弃用 _ref dtypes .&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;漏洞修复和其它更改&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;新指令： parallel_stack.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;为 RecordReader/RecordWriter 引入常见的 tf io 压缩选项常量.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;添加 sparse_column_with_vocabulary_file，其能指定一个将字符串特征转换为 ID 的特征列（feature column），其中的映射是通过一个词汇表文件定义的.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;添加 index_to_string_table，其返回一个将索引映射到字符串的查找表.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;添加 string_to_index_table，其返回一个将字符串匹配到索引的查找表.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;添加一个 ParallelForWithWorkerId 函数.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;支持从 contrib/session_bundle 中的 v2 中的检查点恢复会话.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;添加了一个用于任意角度的 tf.contrib.image.rotate 函数.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;添加了 tf.contrib.framework.filter_variables，这是一个用于基于正则表达式过滤变量列表的方便函数.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;make_template() 加入了一个可选的 custom_getter_ param.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;添加了关于现有目录如何被 recursive_create_dir 处理的注释.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;添加了用于 QR 因式分解的指令.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Python API 中的除法和取模现在使用 flooring (Python) 语义.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Android：在 contrib/android/cmake 下，用于 TensorFlow Inference 库的 cmake/gradle build&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Android：远远更加稳健的会话初始化代码.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Android：当 debug 模式激活时，TF stats 直接出现在演示和日志中.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Android：新的更好的 README.md 文档.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;致谢我们的贡献者&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个版本包含了来自谷歌很多人的贡献，此外还有以下贡献者：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodcFhyvB9uT3y2lmKnQMWVbYEqhup3T2KSyGSxN0w7K4NuGaECYbl4vGA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们也非常感激所有提交了问题或帮助解决它们的所有人——提出和回答问题也是激发讨论的一部分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;下载源代码&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;zip ：https://github.com/tensorflow/tensorflow/archive/v1.0.0-alpha.zip&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;tar.gz：https://github.com/tensorflow/tensorflow/archive/v1.0.0-alpha.tar.gz&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 11 Jan 2017 13:40:32 +0800</pubDate>
    </item>
    <item>
      <title>深度 | 自然语言处理领域深度学习研究总结：从基本概念到前沿成果</title>
      <link>http://www.iwgc.cn/link/4292347</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自adeshpande3&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote style="color: rgb(62, 62, 62); font-size: 16px; white-space: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/blockquote&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;每隔几周，加利福尼亚大学洛杉矶分校（UCLA）的 Adit Deshpande 就会在其博客上发表一篇深度解读的深度学习研究回顾博客。今天这篇是 Adit 的这一系列的第三篇博客，将主要介绍深度学习在自然语言处理当中的应用。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;自然语言处理简介&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自然语言处理（NLP）是创造能够处理或是「理解」语言以完成特定的任务的系统。这些任务可能包括：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;问答系统（也就是Siri、 Alexa和小娜所做的事情）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;情感分析（判断一句话隐含的积极或消极意义）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;图片题注（为输入的图像生成一个标题）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;机器翻译（将一段文本翻译成另一种语言）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;语音识别&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;词性标注&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;命名实体识别&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;传统的自然语言处理方法涉及到了很多语言学本身的知识。理解诸如音素（phonemes）和语素（morphemes）等术语都是非常必须的，为了学习这些专业知识，还要学习完整的语言学课程。接下来让我们看一些传统的自然语言处理是如何理解下面这一单词的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodcw7c2XFRMfcoMre0rn9PRcS64WX0Y2M32JdWLamnrxicCCibUt10BpDLg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;假设我们的目标是要收集关于这一单词的一些信息（描述它的情感、寻找它的定义等）。&lt;/span&gt;&lt;span&gt;利用我们在语言上的专业知识，我们把这个单词分为三部分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodchL8vGuGopjlrVibIq6wfdYBgXEvc4UonWdP8kmnjlg1aJJyIDibDnLJA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们知道这个单词的前缀「un」表示的是一种相对立的或是相反的概念，「ed」能够限定这个单词的时态（过去时）。通过对这个单词主干部分「interest」的理解，我们能够很容易地推断出整个单词的意思和情感。看起来是不是非常地简单？但是，当你要考虑到英语中所有不同的前缀和后缀的时候，可能就需要一位非常有技巧的语言学家才能理解所有可能的组合和意义。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodczSicfFZcOI878pT4ian7fPStBtCiakJzIsjGTyvAEY6tSmDHM6kDe9mwQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;如何将深度学习应用其中&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深度学习，从其最基本的层面来说，是表征学习（representation learning）的一种方法。利用卷积神经网络，我们可以看到用来对事物进行分类的不同过滤器的组成。在这里，我们将要采取一种类似的方法，利用大数据集为词汇创造表征。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;本文概述&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这篇文章中，首先我们将了解为自然语言处理建立深度网络的基本构建模块，之后将对最近研究论文的一些应用进行讨论。大多数人都不明确了解为什么我们要使用循环神经网络（RNN）或者是长短期记忆（LSTM）为什么会有用，但是我希望在我们讨论完研究论文之后，你可以对为什么深度学习会为自然语言处理提供这么大的帮助有更好的理解。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;词向量&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因为深度学习和数学密不可分，我们将要把每一个单词都表征为一个d维向量。我们将d设定为6。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodcVIjxUbGUJ5zu3ibTnibJjGnSGWxEJZH3ZfX9Sl5aBSMCvSgaRkf2DKhg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在让我们想一想该如何填写值。我们希望填写值的方式可以让向量表征词，以及词的语境、意思或语义。一种方法就是建立一个共生矩阵（coocurence matrix）。以下面这一句话为例。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodcVWdHbfvJD5IdwXqvp43iagHIsxysj8GCcJgBAbGIUN9Hth8foOG1dvg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这一句话中，我们想要给每一个词都建立一个词向量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodclRP8K1sM9vbeYicvQq79W8t5P0fJlKXSGSWsQQ8JdiaceU10gM8iaapbg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;共生矩阵中包含了在语料库（或是训练集）中每一个词出现在其他词语旁边的次数。让我们看看下面这个矩阵。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodcF3jtnozXaCeZB6jnZmX3xJwdmruCGaMiaoGRs7TKOoxn5OPJ0bJBKWw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;将这个矩阵的行提取出来能够让我们对词向量有一个简单的初始化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodcTYsmKicSiadyicgB8FtJj6PcRYL31XWv8tib3GScGmX5R0HTFiaw741cZdg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;注意，通过这个简单的矩阵，我们将能收获非常有用的见解。例如，注意「love」和「like」，这两个词与名词（NLP 和dogs）相连的次数都是1。和「I」相连的次数也是1，所以这表明这两个单词一定是动词。如果说我们拥有更大的数据集，而不是简单的一句话，你可以想象，这种相似性就会变得越来越明显，就像是「love」和「like」一样，其它的一些同义词也会开始拥有相似的词向量，因为它们一般都会在相似的语境下使用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在，虽然我们的起点很好，但是我们也注意到每一个词的维度都会随着语料库的扩大直线上升。如果我们有100万个词（在自然语言处理的标准中不算多），我们就会有100万乘以100万大小的矩阵，而且这一矩阵会非常的稀疏（有很多的0）。从存储效率来看这一定不是最好的。在寻找表征这些词向量的最优方法中也存在着很多的先进技术。其中最著名的就是Word2Vec。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Word2Vec&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;词向量初始化技术的基本思路就是要在词向量中储存尽可能多的信息，同时也要将维度控制在一个可以管理的范围之内（25 – 1000维是理想的）。Word2Vec让我们可以预测每一个单词周围的单词。还是以我们之前提到的句子「I love NLP and I like dogs.」为例。我们首先来看一看这句话的前三个单词，因此我们就要把我们的窗口大小m设置为3.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodcAUXxdlUBH2XgIehoY52nviaAfL6ZxEQ2rFgGicqqhlia57lZuXzZ9B14A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在，我们的目标是提取中心词「love」，然后预测可能在这个词之前或之后出现的词。我们应该怎么做呢？通过将一个函数最大化/最优化！一般来说，我们的函数都会将现有中心词的上下文单词的对数概率最大化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodcTORicKntvexQDU1fhuj16SguqMud76cylt1IlqqzoFT7k3yRCO74aiaA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;让我们再做一些更深入的了解。上文中的成本函数基本上是在说我们要增加「I」和「love」以及「NLP」和「love」的对数概率（love在两种情形当中都是中心词）。变量T代表的是训练句子的数量。让我们再来了解一下对数概率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodcyIibtnrX8XoePniaTjhtI8aehypvpSnVIcyVdORdeXibk40lBQ08B2rBQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Vc是中心词的词向量。每一个单词都有两次向量表征（Uo 和 Uw），其中一个是当单词作为中心词时，另一个是当单词用作外部词语时。这些向量都经过随机梯度下降法的训练。这一定是令人困惑的方程式之一，也是我们需要理解的，所以如果你还是难以想象正在发生的事情，你可以查看更多的资源加以了解。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一言以蔽之：在给定一个中心词的情况下，Word2Vec 通过最大化上下文单词的对数概率并通过随机梯度下降（SGD）来修改向量，试图找到不同词的向量表征。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;注：论文《Distributed Representations of Words and Phrases and their Compositionality》谈到了更多细节：常见词的负采样和子采样能如何被用于获取更精确的词向量。）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Word2Vec 的最有趣的贡献在于展现出不同词向量之间的线性关系。训练后，词向量似乎捕捉到了不同语法和语义概念。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodc2u7tHictUWd5m9M6exI2fv3l8VRMIO3SBT0iciaO5t6jnc7JJdCF5Z0uA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;难以置信的是，这些线性关联可以如何通过一个简单的目标函数和优化技巧得以形成。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;福利&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：另一个很酷的词向量初始化方式：GloVe（将共生矩阵与Word2Vec结合起来）:http://nlp.stanford.edu/pubs/glove.pdf&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;循环神经网络（RNN）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在我们已经拥有词向量了，然后看看它们是如何拟合循环神经网络的。循环神经网络现在已是大多数自然语言处理（NLP）的必需品。循环神经网络最大的优点是它能有效地使用先前时间步骤的数据。这就是一小块循环神经网络大概的样子。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodcrZhHdfo9upzE5eBbHFKNQBChsMJJlGSx6WrvE0vuPuR6ibdxyJFCMfg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在底部我们有词向量（xt，xt-1，xt+1）。每一个向量在同一时间步骤（ht， ht-1，ht+1）有一个隐藏状态向量（hidden state vector）。我们称这些为一个模块。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodcwq4uNCt4iaySHvibhhpibiauVlhwGaibagg4ricDW3tUgpsOfROPLNsPEU0A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;循环神经网络每个模块中的隐藏状态是前一时间步骤（previous time step）的隐藏状态向量和词向量的函数：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodcIAj75AAHG3Tic3kp7TWIZiaajgHLf99KWPicoa76SzdAThVdh95jc5PLw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;span&gt;如果仔细看看上标，你会发现有一个权重矩阵Whx，我们会将Whx矩阵与输入相乘，并且会有一个循环权重的矩阵（recurrent weight matrix）Whh乘以在前一时间步骤的隐藏状态向量。切记这些循环权重矩阵在所有时间步骤都是相同的，这也是循环神经网络的关键点。仔细想想，这和传统两层神经网络有很大的不同。传统情况下，我们每一层（W1和W2）通常会有不同的权重矩阵W，而这里的循环权重矩阵在整个网络中都是相同的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;要得到特定模块的输出（Yhat），就需要将h乘以WS，这是另外一个权重矩阵。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodcJHUmFGZH85vP0ecD54U22XibTDTiaZ6t2YRibGKyePS79AH9lmDicuiaVcQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在我们退一步，了解循环神经网络的优点在哪。与传统神经网络最大的不同就是循环神经网络可以接收输入序列（我们例子中的词）。你可以将其与典型的卷积神经网络对比，其只能是将单一图片作为输入。然而使用循环神经网络，输入可以小到短句，大到有 5 个段落的文章。此外，该输入的序列顺序能极大地影响到权重矩阵和隐藏向量在训练中如何改变。隐藏状态在训练后期望能从过去（前面的时间步骤）获取信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;门控循环单元（GRU）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在让我们看一个门控循环单元（gated recurrent unit/GRU）。这个单元的目标是提供一种更复杂的方法来计算我们在循环神经网络中的隐藏状态向量（hidden state vectors ）。这种方法将允许我们储存信息并捕获长距依赖性（long distance dependencies）。让我们想象下为什么长期依赖性（long term dependencies）在传统的循环神经网络构架中存在问题。在反向传播中，误差将流经循环神经网络，从最近的时间步骤到最早的时间步骤。如果初始梯度是较小的数字（如小于0.25），那么在通过第三或第四模块时，梯度实际上会消失（链式规则与梯度一起乘积），因此较早时间步骤的隐藏状态将不会更新 。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在传统循环神经网络中，隐藏状态向量是通过该公式计算的：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodcmexQ6WjHpquam5xgV0iaNrkt7sbCOiceK5VyIRQ8hutYLAHe36ja5H2g/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;GRU提供了一个不同的方式计算隐藏状态向量h(t)，该计算分为三个分量，一个更新门（update gate）、一个重置门（reset gate）和一个新的记忆存储器（memory container）。两个门都是输入词向量和在前时间步骤的隐藏状态函数：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodcluMBuLlTbfibHpmuOvcgRJV3DSDT1cz7dywlAibCeUM8ksWL70uvkASA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关键区别是每个门使用不同的权重，这由不同上标来表示。 更新门（update gate）使用Wz和Uz，而重置门（reset gate）使用Wr和Ur。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在，新的记忆存储器（memory container）就是通过以下方式来计算的：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodcAicaBsf4KhhaI6olpxDAa8kBGHAib0liaMV0ibUnndgHU5L6WzIibsnicoSA/0?wx_fmt=png"/&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;（空心点指的是Hadamard 积）&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在，如果仔细看看公式，你会发现如果重置门的值接近0，那么这整个项也会变成0，因此忽略了在先前时间步ht-1的信息。在这种情况下，计算单元仅仅只是新词向量xt的函数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;h(t)的最终公式如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodcic9YUrm86D8WWDjliccUdmFibRDnVQh4xENk1HZyIvNGFVd1QkrmEaY2A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;ht 是一个有三个部分的函数：重置门、更新门以及记忆存储器。理解这一点的最佳方式就是当 zt 接近1 以及 0 的时候，视觉化所发生的情况。当 zt 靠近1，新的隐藏层向量 ht 几乎取决于之前的隐藏层，而且因为(1-zt) 变成 0，我们忽略了当前记忆存储。当 zt 接近 0 时，新的隐藏层向量几乎取决于当前记忆存储，我们忽略了之前的隐藏层状态。以一种直觉的方式观察这三个组成部分，可以归纳为以下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1.更新门（Update Gate）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如果zt趋向于1，ht就完全忽略现在的词向量，仅仅只是复制前隐藏状态（如果不是太理解，请查看ht方程并注意当zt趋向于1时，1-zt有什么改变）。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如果zt趋向于0，ht就完全忽略前一时间步骤的隐藏状态，仅仅只依赖于新的记忆存储器。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;此门控能让模型控制前一隐藏状态的信息多大程度上影响现在的隐藏状态。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2.重置门（Reset Gate）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如果rt趋向于1，记忆存储器将保持前一隐藏状态的信息。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如果rt趋向于0，记忆存储器将忽略前一隐藏状态的信息。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;此门控能允许模型在丢弃一些对未来不相干的信息。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3.记忆存储器（Memory Container）： 依赖于重置门。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个通常用来说明 GRU 有效的例子如下：假设你遇到下面一段话&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodcaNyfibXciaLmTxhvd2sSNqfRWppgSia72vgAOL2zNm977Rzkf99qnzNYQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以及相关问题 What is the sum of the 2 numbers 。既然中间句子对手边问题绝对没有影响，但是，重置和刷新门会让网络在某种意义上“忘记”中间的句子，并学会只有特定信息（这个例子中的数字）才应修改隐藏状态。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;长短期记忆单元（LSTM）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你对GRU 已经很了解了，那理解LSTM对你一定不会太难 。一个LSTM也是由一连串的门（gate）组成。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodcTL9OPdp4JtIf0GPRO0yWic2ubbsZQrviaC0h0V1lSg6ZkIIdtEib85kGQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然， 这里面涉及到更多的知识。 不过因为LSTM可以理解为GRU的衍生物，我将不会过多的分析，但如果你想更深入的了解每个门， 每个计算，你可以点击查看Chris Olah 写的一篇超棒的博文：http://colah.github.io/posts/2015-08-Understanding-LSTMs/ 。这篇文章是目前关于LSTM最受欢迎的教程，并且一定对你们这些想要知道其背后的工作原理的人提供很大的帮助。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;比较和对比 LSTM 与 GRU&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;让我们先从相似点出发。 两者的单元组件都有一个能够记录长时间的词与句子之间依赖关系的特殊函数。 这种长期依赖性， 指的是在一些情况下， 两个词或者词组可能在不同的时间点出现，但两者间的关系对实现最终目标十分关键。 LSTM 和GRU 能够通过一些门（gate）来忽略或者保留语句中的某种信息，从而捕捉这些依赖性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;两者基本单元的不同处在于， 它们拥有的门（gate）的数量（GRU有两个， LSTM有三个）。这一点将影响到输入能够传递的非线性关系个数， 并且最终影响到总体的计算。 另外，GRU并没有和LSTM的记忆单元（C_t）一样的记忆单元。&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;在阅读论文之前&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这部分只是想快速做个提示：还有其它的深度模型对NLP有用。在实践中有时使用循环神经网络和CNN，但却不像RNN 这么流行，它是大部分深度学习NLP系统的支柱。现在，我们已经对NLP与深度学习的关系有了足够了解，接下来看几篇论文。由于NLP领域有不同的问题（从机器翻译到问答系统），所以圈内有大量可以看的论文，但我在此文章中发现了3篇很有洞见的论文。2016年NLP领域有了极大的发展，但我们先从2015年的一篇论文开始说起。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;记忆网络（Memory Networks）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;论文：https://arxiv.org/pdf/1410.3916v11.pdf&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;介绍&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们首先要讨论的第一篇论文， 在问答系统这一子领域很有影响力。 这篇论文由Jason Weston, Sumit Chopra以及 Antoine Bordes撰写，介绍了一类名为memory networks 记忆网络的模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这一想法来自于当你想要精准地回答一个关于一篇文本的问题， 你必须要记住该文本大致的内容。如果我来问你一个问题“RNN表示什么’”（在你已经完全阅读了这篇博文的前提下） 你就一定能告诉我答案。 这是因为你通过阅读、存储记忆，已经吸收了这些知识。你只需要简单的花几秒钟去定位这条信息， 然后把它用通顺的语言表达出来。 目前， 我并不知道大脑是如何做到的， 但需要地方去存储信息的这一想法一定是存在的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这篇论文描述的记忆网络有些特别，因为它含有一个联想记忆（associative memory ）。这种联想记忆能够读写。 值得注意的是我们在CNN或者Q网络（用于强化学习）或者其它的传统网络中并不能找到这种类型的网络。这有部分是因为问答任务很大程度上依赖于系统能够建模或者追踪长期的依赖关系，比如在一个完整的故事中记录一个人物的进展，或者记录时间轴上的重要事件。在CNN或者Q网络中， 记忆模块被植入在网络的权重体系中，因为网络需要能够学习不同的滤波器或者将状态映射到动作上。 初看， RNN和LSTM可能能用来实现这一记忆功能， 但它们通常不能记住来自过去的输入， 而这对于问答系统是至关重要的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;网络架构&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;好的，让我们看看这个网络是如何处理给定的最初文本的。和几乎所有的机器学习算法一样，首先将输入转变成一个特性表征。这需要用到词向量、词性标注、解析等，这些是由程序员决定的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodcaOF60zLJnoyuiaJuHqwy1Z94dOvznK1uAeRhO0J9TJo8vqbXsvbCOAQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下一步就是提出特征表征I(x)，并允许我们的记忆 m 进行更新，从而反映出我们已经接收到的新输入 x。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodc9d2o0ibFell3zRlbKWnrfPCy8ibo6icziaPDzTOPZIVsxd9jvGuIyx4HwA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你可以将记忆 m 视为由单个的记忆 mi 构成的一个序列。这些单个记忆 mi 的每一个都能成为整个记忆 m &amp;nbsp;的一个函数，特征表征 I(x)，和\或其自身。函数 G 能简单到在单个记忆单元 mi 中仅存储整个表征 I(x)。你能基于新输入修改函数 G ，更新过去的记忆。第三、四部包括根据问题读取记忆，获得一个特征表征 o, &amp;nbsp;然后将其解码输出一个最终答案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodcziaSU9Z2JS9IVeOgyxryxmUKbXFcBD1eJPEibibZZRtu1scQ4uiat6ictWQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;函数 R 可以是个 RNN，被用来将来自记忆的特征表征转化为一个可读的、准确的问题答案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在，进一步看看第三步。我们希望 Ｏ模块能输出一个特征表征，将可能的答案最好匹配给一个给定问题 x。现在，这个问题会与每一单个的记忆单元进行比较，也会根据记忆单元能否好好支持问题来打分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodcmezR5Yicc45GTmcicCicbGdFtQOR3ZKY7EDFxvVKjrjzx9zGz6ZpkiaTfw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们求评分函数的 argmax，找到能最好支持问题的输出表征（你也可以取多个最高得分单元，不必限于1个）。评分函数就是计算不同问题嵌入和选中记忆单元之间的矩阵积。（欲知详情，请阅读论文）。当你乘以两个词向量以求其相似性时，你会想到这个。然后，这一输出表征 o 会被输入一个 RNN 或者 LSTM ，或者输入另一个会输出可读结果的评分函数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;训练方式是监督训练，训练数据包括原始文本、问题、支撑句（ supporting sentences）以及基底真实答案。这里是目标函数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodcmacA4YfiagTHuY9s2hwOHosic9FcdJBluQQrn4cibVhZlmURbGv6OQeXA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;感兴趣的读者，下面这些论文谈到了构建这类记忆网络的方法：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;End to End Memory Networks (https://arxiv.org/pdf/1503.08895v5.pdf) &lt;/span&gt;&lt;span&gt;(仅需监督输出，不支持句子）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Dynamic Memory Networks (https://arxiv.org/pdf/1506.07285v5.pdf)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Dynamic Coattention Networks (https://arxiv.org/pdf/1611.01604v2.pdf)&lt;/span&gt;&lt;span&gt;（2个月前才发布，斯坦福问答数据组中获最高得分&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;情感分析的树LSTMs&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;论文：https://arxiv.org/pdf/1503.00075v3.pdf&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;介绍&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下一篇论文分析了情感分析领域取得的进展，情感分析就是判定某个短语的语气/意义是积极的还是消极的。更正式一点的说法，情感可以被定义为对某一状况或时间的观点或态度。这时，LSTMs就是情感分析网络中最常用到的部件。这篇由Kai Sheng Tai, Richard Socher, and Christopher Manning 合作的论文介绍了一种将LSTMs 链入非线性结构的有趣方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种非线性安排背后的想法在于：自然语言具有这样的特质，亦即单词按某种顺序排列后就变成短语。这些依据单词顺序构成的短语所表达的意思和构成短语的单词的意思是不同的。为了能表征出这一特点，一个LSTM的网络单元就必须被安排进一个树结构，其中 ，不同的单元会受它们的子节点（ children nodes）影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;网络架构&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Tree LSTM 和 标准 LSTM 的一个不同之处在于，后者隐藏状态是一个关于当前输入和之前时间步骤上的隐藏状态的函数。不过，有了这个结构，它的隐藏状态就是关于当前输入及其子单元隐藏状态的函数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodcdpiariaYD4tzWwfBbcp2vRCKlGq1GSxiaPBwyUgiaSVicDciaqk0l3sD07ww/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;新的树结构会带来一些数学上的变化，包括子单元忽略掉门。那些对细节感兴趣的读者，可以研读这篇论文。不过我的焦点是理解这些模型会比线性的LSTM效果更好的原因。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个Tree-LSTM，一个单独的单元就可以吸收所有子节点的隐藏状态。这很有趣，因为一个单元可以分别评估其子节点。训练过程中，网络能意识到一个特定的单词（或许是情感分析中的“not”或者“very”）对句子整体情感分析的极端重要性。能给予那个节点更高一点的估值，这一能力让网络具有了很大的灵活性，也提升了网络表现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;神经机器翻译&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;论文：https://arxiv.org/pdf/1609.08144v2.pdf&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;介绍&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后一篇论文讲述了解决机器翻译任务的方法。作者来自谷歌机器学习那些颇有远见的学者们 ：Jeff Dean、Greg Corrado、Orial Vinyals 等。这篇文章介绍了一种机器翻译系统，也是谷歌翻译服务背后的支柱。较之谷歌之前使用的产品系统，该系统平均降低了60%的翻译误差。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自动翻译的传统解决方案包括基于短语的变量匹配。这一方法需要大量语言领域的知识而且这一设计最终也被证实太脆弱也缺乏泛化能力。传统解决方案的问题之一就是一点一点地翻译输入句子。结果，更有效的解决方法是一次翻译整个句子，这种方法让更广泛的上下文以及更加自然的语词再安排成为可能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;网络架构&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该论文的作者介绍了一个深度 LSTM 网络，能够用 8个解码器和编码器层进行端到端的训练。我们能把该系统分解成3个组件：编码器RNN、解码器RNN、注意模块。从高层级来看，编码器要做的任务是将输入语句转换成向量表征，然后解码器产生输入表征，然后注意模块提示解码器在解码的过程中应该注意什么（这是利用输入语句全部语境的思路所在）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodcaVOqJ9kYiaD4KsFq5ZoepcfH9yEIibxXda3CicCzEwuBMd8whRz9HpgHA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;论文的其他部分主要专注于规模化该服务的挑战上。计算资源量、时延、高容量部署这样的话题都进行了长篇介绍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;结论&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在此博客中，我们总结了深度学习如何帮助了自然语言处理任务。在我的认识中，该领域内的一些未来目标包括：改进消费者服务聊天机器人、完美的机器翻译，并且希望能让问题回答系统掌握对无结构文本或长文本（比如 wikipedia 文本页）更深的理解能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em style="max-width: 100%; color: rgb(136, 136, 136); font-size: 16px; white-space: normal; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;原网址：https://adeshpande3.github.io/adeshpande3.github.io/Deep-Learning-Research-Review-Week-3-Natural-Language-Processing&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em style="max-width: 100%; color: rgb(136, 136, 136); font-size: 16px; white-space: normal; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;em style="max-width: 100%; color: rgb(136, 136, 136); font-size: 16px; white-space: normal; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 11 Jan 2017 13:40:32 +0800</pubDate>
    </item>
    <item>
      <title>深度 | 构建好奇的机器，Maluuba的通用人工智能探索（附论文）</title>
      <link>http://www.iwgc.cn/link/4292348</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Maluuba&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李泽南、朱思颖&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote style="color: rgb(62, 62, 62); font-size: 16px; white-space: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;人类具有对认识和理解的天生欲望。从学习骑自行车到学习在线课程，我们通过与周遭环境互动来获得信息。最近，我们受到人类学习方式的启发，开发了一套任务，让人工智能体学会了如何通过提出问题来寻找有效信息。同时，我们也设计了一个基于深层神经网络的人工智能系统，它可以通过高效的信息搜索完成这些任务。我们相信，这些研究让人类向通用人工智能迈出了重要一步。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;问正确的问题&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;假如你在和朋友聚餐，在饭桌上玩起了「20 个问题」游戏。现在轮到你了，你决定让大家来猜「猫」。他们开始从大范围问题切入：「它/他是活物吗？」，「它/他是一个人吗？」，「它/他是一种动物吗？」，「它是否生活在水下？」。首先猜出正确答案的人会成为胜利者，所以你的朋友们不仅需要找出正确的答案，而且还要尽量少问问题。基于简单的是或不是的回答方式，你的朋友们可以很快地缩小寻找范围，最终猜出正确的答案「猫」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个例子说明了人类寻找信息的过程具有的迭代性质：你正在寻找的信息永远基于你已经获得的信息。同样，为了保持效率，寻找信息的智能体必须在某种意义上理解它已经获得的信息。它必须知道自己已经知道了什么，从而可以知晓如何达成自己真正需要完成的任务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「20 个问题」的例子也表明了交流通常是在受限的条件下进行的：每个答案都是简单的是或否（仅仅传递 1bit 信息），而且问题的数量也是有限的。在现实世界中我们对于信息的搜索往往面临同样的困局——我们通过有限的语言在有限的时间内交流。比如在网上搜索，思考为朋友挑选哪件礼物，你一开始会随便搜搜——以对方的年龄、性别和自己的钱包为导向——随后再在缩小的范围内以兴趣和推荐等条件为依据找到最终目标。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由于这种方式构建了智能行为的基础，人们对人工智能寻找信息的方法已经进行了广泛的研究，认知科学、心理学、神经科学和机器学习的角度都已被涉足。例如，在神经科学中，信息寻找策略通常被解释为对新奇，令人惊讶或不确定的事件的偏见（Ranganath 和 Rainer，2003）。信息寻找是乐趣和创造力等概念的一个关键组成部分（Schmidhuber，2010）和内在动机（Oudeyer 和 Kaplan，2007）。也有一些研究认为注意力机制是人类寻找信息的策略，通过忽略不相关的特征提高了处理问题的效率（Mnih 等人，2014）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;信息搜索的新任务&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;研究人员会使用各种工具和系统用来训练人工智能，从数据集到定制学习环境。人工智能已经在国际象棋、围棋、Atari 游戏中取得了令人瞩目的成就。同样，许多人类热衷的游戏看起来正是为了训练信息搜索而设计的，也许人类能从信息搜索的过程中得到快感。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此，我们设计了一套信息搜索的任务集来训练和评估人工智能的信息搜索能力。在这里我们展示了三种任务（其他的任务详见我们的论文）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;iframe class="video_iframe" data-vidtype="1" allowfullscreen="" frameborder="0" height="418" width="557" data-src="https://v.qq.com/iframe/preview.html?vid=g03641k0wol&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0"&gt;&lt;/iframe&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在任务集中，最有意思的任务就是「刽子手」，「面部识别」和「战船」。这些任务中，每一个都有自己的独特规则和获胜目标。更重要的是，每个任务都需要人工智能可以在已有信息的基础上寻找更多信息。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_gif/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodcraiaxKm3BKaolfPTOa3yzgkseFP0uzZvH0KsZs85Zw3xhSqu4rNRmibA/0?wx_fmt=gif"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;刽子手：西方经典游戏，给出一个单词，人工智能必须在指定轮次内猜出该单词的每一个字母。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_gif/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodc43VYFoicJSUvviaoG40yzqyV00Zj8UOocxL99Y1wZlzkhiboGeZXThDQQ/0?wx_fmt=gif"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;面部识别：人工智能需要在这个游戏中回答诸如：「这个人是否戴着帽子？」「这个人是否有胡子？」这类的问题。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_gif/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodc0tjnY0SFhBRraPmTicia6z4bohZMu9kTWKsg78abfkBgtOLBH6xPWxgg/0?wx_fmt=gif"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;战船：人工智能需要击沉地方战船，它们会随机出现在网格中，事先处于隐藏状态，选择正确的网格意味着敌方被「击中」。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;训练模型来获取信息&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在我们任务中人工智能的行为表现可以理解为对其周围环境进行提问，如「这个短语包涵字母'a'吗？」或者「这部分的像素块看起来像什么？」为了成功获取信息，一个人工智能体必须学会提出有效问题并消化由此获取的信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们开发了一个模型，这一模型被训练用来完成上述任务。在完成某一任务的每一步里，模型都会提出一个其所认为当前情形下最有效的问题，然后从环境中获取相应的回复，并进一步将所获取的回复与其既有的知识（knowledge）整合。这个模型是一个深度神经网络，通过把强化学习的技巧（具体是：广义优势估计——Generalized Advantage Estimation，Schulman 等人，2016）和反向传播结合起来的方式训练得到。详细内容请参阅该研究的论文。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodc6NHXW7jBOVg84eicOfGL4lAKpEUOrEoU0tBefZ4S9RdwIkf330C9XxA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;span&gt;在训练中，人工智能会寻求奖励最大化，这个最大化奖励包涵多个特定任务的外部奖励和一个任务无关的内部奖励。外部奖励促使人工智能体通过尽量多的问题来获取有效回复，内部奖励促使模型提出能获取环境最新信息的问题。具体来说，我们对每个问题的奖励设置是依据这个问题的回复能多大程度增加模型的认知与世界真实状态之间的相似度。因此，人工智能学会了如何高效的对周围环境构建一个与之对应的精确内部图。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;目标：通用人工智能&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;就如在 demo 里展示的那样，我们的方法所训练出的人工智能体能够成功完成较广泛领域内的任务。同样的方法可以用于语言处理问题、图像处理问题以及决策问题。在我们的任务中，所训练出来的人工智能的行为是具备可解释性的，且这些系统具有智能化的信息获取能力，它们的效率经常超过人类的水平。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们希望这些研究能为通用智能的发展奠定基础。我们当下的工作只是朝实现这一宏伟目标所迈出的一小步。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;相关论文：TOWARDS INFORMATION-SEEKING AGENTS&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodcUtMpbHOCagsEia3RbojtP5wAQo4P8v1q6QxHVeFdwTPWiawbDicpHEFuA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：我们开发了一种通用问题集用于训练和测试人工智能体收集有效信息的能力。具体来说，它是一系列任务的集合，完成这些任务需要在给定环境中寻找有效信息。同时，我们将深层架构和强化学习技术整合到一起，构建了用于处理此类问题的人工智能系统。我们通过组合内部和外部奖励机制来塑造人工智能体的行为。我们的研究表明，这些人工智能体可以学会积极、智能化地搜索信息以减少不确定性，并在这个过程中不断利用已有信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 11 Jan 2017 13:40:32 +0800</pubDate>
    </item>
    <item>
      <title>专栏 | 旷视(Face++)孙剑：创业公司里的研究之美</title>
      <link>http://www.iwgc.cn/link/4292350</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心专栏&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：孙剑&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;孙剑博士 2003 年毕业于西安交通大学，随后在 Microsoft Research&amp;nbsp;Asia (MSRA)工作，曾担任 MSRA Principal Research Manager。2016 年 7 月，&lt;span&gt;孙剑博士加入旷视科技(Face++)，出任该公司首席科学家，负责Megvii Research。最近，孙剑本人撰文向大家阐述了自己从科技巨头到创业公司的心路旅程，并简要介绍了自己最近的研究。&lt;/span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2016 年，就我个人来讲，所做出的最重大抉择，就是在已经工作了十三年的微软研究院（以下简称 MSR），和一个成立不过几年的创业公司——Face++旷视科技（以下简称 Face++）之间，选择了后者，并且以首席科学家身份加入。当时我还住在西雅图，当真是「身未动，消息已远」，各种报道从国内外朋友圈向我强势袭来，让我体会到了媒体的力量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;时至今日，我已搬回北京，在 Face++ 上班近半年了，依然时常被问及：「过的怎么样？」，「Face++ 和 MSR 的研究部门一样吗？」，「Face++ 是如何开展研究工作的？……」等等。问题或大或小，但大多诸如此类。值此新年之际，我想把自己这半年来的观察与思考与大家分享一下，权且当作对各位关心的答谢。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;接下来，我将围绕大家关注的一些典型问题，逐一说明：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Face++ 与 MSR 的研发部门有什么异同？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;就我的观察与体验，两家公司研发部门的本质是几乎没有差别的。什么叫一个公司的研发部门本质呢？我认为有三个要素极其关键：使命定位、人员组成和研发方式。坦白来讲，从这三点审视，我在两边看到了惊人的一致性，也就是说：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1）他们都同样有着既基于产品，又探索前沿技术的使命定位；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2）他们都同样聚集着一群追求极致，有 Geek 精神，且高自我驱动的精英；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3）他们都用同样的套路推进研究工作：确定问题--&amp;gt;实现、研究和理解既有方法--&amp;gt;进行持续改进或创新。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这其中，最令人有现场触动感的还是「人」。举个最近让我感动的例子： 下面这张我在 2016 年最后一天发的朋友圈最好的诠释了 Face++ 的核心价值观「追求、极致、简单、可靠」中的前两点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9rD6KzMuKBaJJEmtibaiciaXJ3I32qOlB16tMWaicsUdBvonThTwictiaDSHKJaicfCK4SPKbCkd7vPQAiaw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然，即便两边研究部门的本质相同，也必然会存在着不同之处，毕竟每个公司都有其特定的文化与管理模式。当我身边的战友们从平均年龄三十多岁直降十岁的那一天突然来临时，我一方面感觉自己好像在瞬间迈入中老年的行列中（讲个梗：今天一名同事问我为什么把手机字体调的那么大），另一方面觉得自己充满了干劲，同时还有一份沉甸甸的责任感。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Face++ 的研究部门在研究什么？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在众多场合下问，这个问题是被提及次数最多的。为什么会有这样的疑问呢，我想不外乎两方面的思考，一是想知道公司具体研究哪些领域，长期课题与目标是什么，二是想了解一家创业公司里的研发部门，到底能不能推进真正意义上的研究工作，还是打着研究的旗号做着产品开发。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里还隐含着一个认识上的误区，就是在我们公司被广泛称为 Face++ 之后，越来越多的人误以为 Face++ 嘛，只是在做人脸技术。人脸，目前确实是一个商业前景广阔，玩法花样不断翻新的应用。但是，Face++ 从创立第一天就聚焦在人工智能的三大应用领域之——计算机视觉，是以一系列视觉识别（人脸、人、物体、文字、场景、行为等）问题为中心，研发核心算法，打造能落地的产品。消除了这样一个误区，你会比较好理解，为什么 Face++ 要用「Power Human with AI」作为使命，用「人工智能技术造福大众」，来发愿。毕竟公司的全名是叫旷视（英文叫 Megvii, 取自 Mega Vision )，也就是大的视觉。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;回到问题本身，目前我们主要在集中研究四个视觉理解核心问题（见下图）：图像分类、物体检测、语义分割、和序列学习。研究的技术路线是彻彻底底的深度学习：1）使用深度神经网络；2）尽最大可能使用端到端（end-to-end）学习。Face++ 应该说是这波儿人工智能创业公司当中最早研究并应用深度学习的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9rD6KzMuKBaJJEmtibaiciaXJXfLMmISC8vCGo5p72FUkkmIJXVDM2HzE7Rj4DL0ibXicjI9HXZBicAc0A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;图像分类是最基础的问题&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个问题自身就有广泛的应用（例如人脸识别和场景分类），也是研究其他问题的根基。深度学习的出现使得我们从以往的特征设计走向了网络结构设计，这里包含很多对问题的深刻理解、实践中总结的经验和原理、优化算法的探索、和对下一步技术发展的判断。我们的研发部门里有一个专门的小组负责研究如何训练最好的基础神经网络，并沿着以下三个子问题深入：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1）针对不同计算复杂度下设计最优的神经网络；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2）针对不同计算平台的实际要求，来设计最高效的网络；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3）针对不同问题设计最合适的网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外对神经网络模型的压缩和低比特化表示也是我们研究的重点之一。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;物体识别是解决感知图像中哪里有什么物体的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;典型的应用包括手机上的人脸检测，无人车中的车辆/行人/交通标志的检测，视频分析中的各类物体检测。这个问题是图像理解中研究内容最丰富的核心问题，也是一个非常复杂的感知智能问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们关心的若干子问题是：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1）如何有效地解决遮挡问题。这个问题对人来说好像是很容易的，但其实涉及到了人脑中对不可见部分自动做联想和补充的能力，已经部分属于人类的认知智能能力范畴；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2）如何有效的利用图像或视频的上下文（context）信息或我们的常识（common sense）。上下文和常识对我们避免一些明显错误和小物体检测十分重要。目前的物体对小物体检测的性能非常不理想，和人眼的能力差距还是非常大的。如果我们单独把小物体从图像中裁剪出来，人也很难识别。但是当小物体放回整副图像中，人却做得非常出色。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我个人认为对这个两个子问题的深入研究真的可以对理解认知智能提供有意义指导，甚至是突破。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;语义分割就是对每个像素分类，这是一个更为精细的分类任务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;比如说把识别出来的人体分割成具体部位，把人脸分割成五官，把场景分成蓝天、建筑、道路和物体等。目前在这个问题上统治性的方法是 Berkeley 在 2014 年提出的全卷积网络（FCN）。这个方法使得神经网络具有了有强大的结构化输出能力，进而将深度学习有效地推进到很多中期和初期视觉理解（例如立体匹配和光流计算）问题上。我当年博士论文就是在研究初期视觉中的立体匹配问题，十几年后的方法发生了根本性的变化，当年是想也不敢想的。我们研发部门的一名实习生在最近的 CVPR 投稿中设计了一个简单有效的 FCN 模型，在公开评测集上取得了非常好的效果。（顺便插个广告，Face++ 一直面向全国招收实习生、兼职或全职均可，欢迎来我司对众多有意思、有难度的视觉理解问题进行深入理解和有效解决。）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;序列学习是最有趣的问题，它的形式多样，可以输入一个序列（视频或音频）进行分类，也可以针对一副图像输出一个描述性的文字序列，或输入输出都是序列（例如识别图像中的多行文字）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;解决这三类问题的算法在 Face++ 的产品中都有应用。目前解决这个问题的主流方法是递归神经网络（RNN），也是现在在语音识别和自然语言处理中的大杀器。由于人的智能本质是在实时的「处理」连续不断感知到的信号流，这使得序列学习成为当下的最热的研究方向之一。尤其是最近引入外部记忆读写机制和执行单元的 RNN，让我看到了解决人工智能不少难题的一丝曙光。Face++ 的研究员们也正在这方面积极思考，积极实践。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;我们在旷视如何开展研究？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;推进研究部门的工作，核心是培养人做事的能力，并给予最好的研发环境。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;培养什么人才。人才是研发的生命线。创造一个良好的环境吸引人才，培养人才，留住人才是我们的第一优先级。信息学竞赛 ( NOI/IOI ) 和大学生程序设计竞赛 ( ACM/ICPC ) 的选手们构成了研究部门的第一批战士。我们后续更多的战士来自五湖四海，拥有相当不同的背景：既有以前做视觉的，也有以前做机器学习的，既有研究基本问题的，也有专注特定应用的。一个多样性的环境也使得我们看问题的角度更全面。在这样的基因下，我们大致将人才向两个方向培养：研究科学家，和全栈人工智能工程师。研究科学家主要聚焦在算法上，寻求对问题的本质解，我们的培养目标是成为能独挡一面领域专家；全栈人工智能工程师是我们内部的叫法，目的是培养即能上九天揽月（算法设计和训练），又能下五洋捉鳖（算法的工程化，研究问题和方式系统化）的全能战士，他们既能做 research , 又懂 system，能建系统、造轮子。针对目前 AI 发展的趋势，我们需要大量的全能人才来将 AI「+」到不同的行业上，解决实际问题。这就对人才提出了更高的要求。我们相信即便没有 AI 背景的工程师，在这里工作 1-2 年后就能成为独当一面的人才。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;怎么做事。有了一帮志同道合的小伙伴们，就要围绕这上面介绍的四个视觉理解核心问题开展研究、并将研究成果应用在具体的视觉识别场景中。Face++ 的研发团队扁平化，每个研究小组由 2-4 人组成，聚焦一个课题。课题可以是短期的，例如对已经应用的某个产品线上的算法的改进；课题也可以是长期的，例如持续提升识别的精度和性能。我们的每个研究员都可以在不同的课题之间自由切换，这样能最大程度发挥个人的长处和积极性，同时也让大家有机会短时间了解更多的问题，有更丰富的经历，能更快的成长。套用现在深度学习的精髓，每个人的学习也需要输入大数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;研发环境。做深度学习研究需要一个非常高效的训练引擎/平台和充沛的计算资源。Face++ 内部使用了近两年的「MegBrain」是一个全自主研发的训练引擎，它与目前流行的 TensorFlow（Google 一年前发布）设计相似，同属基于 Computing Graph 的新一代训练引擎。为什么非要自研系统呢？公司研究深度学习开展得非常早，当时还没有很好用的系统，并且 MegBrain 在同时满足灵活性及精简性的基础上，能最大限度提升工作效率。目前在 AI 创业公司中完全使用自研深度学习训练引擎的，可能只有 Face++。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除了核心引擎，我们的体系结构组还搭建了一个强大的深度学习平台 Brain++ 来管理我们庞大的 GPU 集群，来完成从数据标注和管理、模型训练、 GPU 集群中心化管理、到产品化发布的「一条龙」自动化流程，从而使得我们的研发人员将宝贵的精力集中在问题上。这也使得来 Face++ 的实习生非常容易上手，即便对深度学习系统零基础，一套简单的教程读过后 2-3 个星期就可以开始思考问题了。这些系统能够建立得益于我们团队内部的有不少「全栈人工智能工程师」，他们不仅是深度学习方面的专家，更是系统和分布式计算方面的专家。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后针对深度学习很大程度上得益于大规模训练数据，我们还设有专门的团队负责标注工具开发和完成大量数据标注任务。以前读书时开玩笑的一个讲法是「没有不好的算法，只有不好的数据」，Data is King。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心发布，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 11 Jan 2017 13:40:32 +0800</pubDate>
    </item>
    <item>
      <title>观点 | 芯片架构换血！如何评价微软在数据中心使用FPGA？</title>
      <link>http://www.iwgc.cn/link/4292351</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;机器之心授权转载&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;作者：李博杰&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;编者按&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;FPGA，一种全新的古老计算机芯片，正在悄然改变着全球的芯片市场。知乎问题“如何评价微软在数据中心使用FPGA代替传统CPU的做法？”的下面，来自微软亚洲研究院的实习生李博杰的回答在很短的时间内就收获了近2000的点赞数。这篇文章转载自他在知乎上的回答，看看他眼中微软的FPGA布局和FPGA的研究前景吧！&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;问题「用 FPGA 代替 CPU」中，这个「代替」的说法不准确。我们并不是不用 CPU 了，而是&lt;strong&gt;用 FPGA 加速适合它的计算任务，其他任务仍然在 CPU 上完成，让 FPGA 和 CPU 协同工作&lt;/strong&gt;。&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;本回答将涵盖三个问题：&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;1.为什么使用 FPGA，相比 CPU、GPU、ASIC（专用芯片）有什么特点&lt;span&gt;？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;2.微软的 FPGA 部署在哪里？FPGA 之间、FPGA 与 CPU 之间是如何通信的？&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;3.未来 FPGA 在云计算平台中应充当怎样的角色？仅仅是像 GPU 一样的计算加速卡吗？&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;一、为什么使用 FPGA？&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;众所周知，通用处理器（CPU）的摩尔定律已入暮年，而机器学习和 Web 服务的规模却在指数级增长。&lt;strong&gt;人们使用定制硬件来加速常见的计算任务，然而日新月异的行业又要求这些定制的硬件可被重新编程来执行新类型的计算任务&lt;/strong&gt;。FPGA (Field Programmable Gate Array) 正是一种硬件可重构的体系结构，常年来被用作专用芯片（ASIC）的小批量替代品，然而近年来在微软、百度等公司的数据中心大规模部署，以&lt;strong&gt;同时提供强大的计算能力和足够的灵活性&lt;/strong&gt;。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPfr5SQnVztOjxotF9OzaewalUGdONiaoTOcOL7uIicfnY99AfLAh31NPmZCjMuZS6wc2JMy1ajDpng/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;不同体系结构性能和灵活性的比较&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;FPGA 为什么快？「都是同行衬托得好」。&lt;strong&gt;CPU、GPU 都属于冯·诺依曼结构，指令译码执行、共享内存。&lt;/strong&gt;FPGA 之所以比 CPU 甚至 GPU 能效高，本质上是无指令、无需共享内存的体系结构带来的福利。&lt;br/&gt;&lt;br/&gt;冯氏结构中，由于执行单元（如 CPU 核）可能执行任意指令，就需要有指令存储器、译码器、各种指令的运算器、分支跳转处理逻辑。由于指令流的控制逻辑复杂，不可能有太多条独立的指令流，因此 GPU 使用 SIMD（单指令流多数据流）来让多个执行单元以同样的步调处理不同的数据，CPU 也支持 SIMD 指令。而&amp;nbsp;&lt;strong&gt;FPGA 每个逻辑单元的功能在重编程（烧写）时就已经确定，不需要指令。&lt;/strong&gt;&lt;br/&gt;&lt;br/&gt;冯氏结构中使用内存有两种作用。一是保存状态，二是在执行单元间通信。由于内存是共享的，就需要做访问仲裁；为了利用访问局部性，每个执行单元有一个私有的缓存，这就要维持执行部件间缓存的一致性。&lt;strong&gt;对于保存状态的需求，&lt;/strong&gt;&lt;strong&gt;FPGA&lt;/strong&gt;&amp;nbsp;中的寄存器和片上内存（BRAM）是属于各自的控制逻辑的，&lt;strong&gt;无需不必要的仲裁和缓存&lt;/strong&gt;。&lt;strong&gt;对于通信的需求，FPGA&lt;/strong&gt;&amp;nbsp;每个逻辑单元与周围逻辑单元的连接在重编程（烧写）时就已经确定，&lt;strong&gt;并不需要通过共享内存来通信&lt;/strong&gt;。&lt;br/&gt;&lt;br/&gt;说了这么多三千英尺高度的话，FPGA 实际的表现如何呢？我们分别来看计算密集型任务和通信密集型任务。&lt;br/&gt;&lt;br/&gt;&lt;strong&gt;计算密集型任务&lt;/strong&gt;的例子包括矩阵运算、图像处理、机器学习、压缩、非对称加密、必应搜索的排序等。这类任务一般是 CPU 把任务卸载（offload）给 FPGA 去执行。对这类任务，目前我们正在用的 Altera（似乎应该叫 Intel 了，我还是习惯叫 Altera……）Stratix V FPGA 的整数乘法运算性能与 20 核的 CPU 基本相当，浮点乘法运算性能与 8 核的 CPU 基本相当，而比 GPU 低一个数量级。我们即将用上的下一代 FPGA，Stratix 10，将配备更多的乘法器和硬件浮点运算部件，从而理论上可达到与现在的顶级 GPU 计算卡旗鼓相当的计算能力。&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPfr5SQnVztOjxotF9Ozaew95cvKDH1WDusxMcodskIcYcGluWxozzBsRDG1mgXEkE1xbNVyNhLHw/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;FPGA 的整数乘法运算能力（估计）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPfr5SQnVztOjxotF9OzaewDMbQsEsygMKib1u680vc2BrbTp0Z1FPes7qoicM6Vb927BxEkMRko3Pg/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;FPGA 的浮点乘法运算能力（估计）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;在数据中心，FPGA 相比 GPU 的核心优势在于延迟&lt;/strong&gt;。像必应搜索排序这样的任务，要尽可能快地返回搜索结果，就需要尽可能降低每一步的延迟。如果使用 GPU 来加速，要想充分利用 GPU 的计算能力，batch size 就不能太小，延迟将高达毫秒量级。使用 FPGA 来加速的话，只需要微秒级的 PCIe 延迟（我们现在的 FPGA 是作为一块 PCIe 加速卡）。未来 Intel 推出通过 QPI 连接的 Xeon + FPGA 之后，CPU 和 FPGA 之间的延迟更可以降到 100 纳秒以下，跟访问主存没什么区别了。&lt;br/&gt;&lt;br/&gt;FPGA 为什么比 GPU 的延迟低这么多？这本质上是体系结构的区别。&lt;strong&gt;FPGA 同时拥有流水线并行和数据并行，而 GPU 几乎只有数据并行（流水线深度受限）。&lt;/strong&gt;例如处理一个数据包有 10 个步骤，FPGA 可以搭建一个 10 级流水线，流水线的不同级在处理不同的数据包，每个数据包流经 10 级之后处理完成。每处理完成一个数据包，就能马上输出。而 GPU 的数据并行方法是做 10 个计算单元，每个计算单元也在处理不同的数据包，然而所有的计算单元必须按照统一的步调，做相同的事情（SIMD，Single Instruction Multiple Data）。这就要求 10 个数据包必须一起输入、一起输出，输入输出的延迟增加了。当任务是逐个而非成批到达的时候，流水线并行比数据并行可实现更低的延迟。因此&lt;strong&gt;对流式计算的任务，FPGA 比 GPU 天生有延迟方面的优势。&lt;/strong&gt;&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPfr5SQnVztOjxotF9OzaewKposOEn0oicNiaqibVZU6qfiahicShOhp8GrcHBNfngAGKZxtkaVsr4B4fg/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;计算密集型任务，CPU、GPU、FPGA、ASIC 的数量级比较（以 16 位整数乘法为例）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;ASIC 专用芯片在吞吐量、延迟和功耗三方面都无可指摘，但微软并没有采用，我认为出于两个原因：&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1.数据中心的计算任务是灵活多变的，而 ASIC 研发成本高、周期长。好不容易大规模部署了一批某种神经网络的加速卡，结果另一种神经网络更火了，钱就白费了。FPGA 只需要几百毫秒就可以更新逻辑功能。&lt;strong&gt;FPGA 的灵活性可以保护投资，事实上，微软现在的 FPGA 玩法与最初的设想大不相同。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2.数据中心是租给不同的租户使用的，如果有的机器上有神经网络加速卡，有的机器上有必应搜索加速卡，有的机器上有网络虚拟化加速卡，任务的调度和服务器的运维会很麻烦。&lt;/span&gt;&lt;strong&gt;使用 FPGA 可以保持数据中心的同构性。&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;接下来看通信密集型任务。相比计算密集型任务，通信密集型任务对每个输入数据的处理不甚复杂，基本上简单算算就输出了，这时通信往往会成为瓶颈。对称加密、防火墙、网络虚拟化都是通信密集型的例子。&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPfr5SQnVztOjxotF9OzaewaXHKb2Ob6Jwn4k7WX0Cbl7NwkicUYqGxda6AsIKcWfPWIxf5BeUEazw/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;通信密集型任务，CPU、GPU、FPGA、ASIC 的数量级比较（以 64 字节网络数据包处理为例）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;对通信密集型任务，FPGA 相比 CPU、GPU 的优势就更大了&lt;/strong&gt;。从吞吐量上讲，FPGA 上的收发器可以直接接上 40 Gbps 甚至 100 Gbps 的网线，以线速处理任意大小的数据包；而 CPU 需要从网卡把数据包收上来才能处理，&lt;strong&gt;很多网卡是不能线速处理 64 字节的小数据包的&lt;/strong&gt;。尽管可以通过插多块网卡来达到高性能，但 CPU 和主板支持的 PCIe 插槽数量往往有限，而且网卡、交换机本身也价格不菲。&lt;br/&gt;&lt;br/&gt;从延迟上讲，网卡把数据包收到 CPU，CPU 再发给网卡，即使使用 DPDK 这样高性能的数据包处理框架，延迟也有 4~5 微秒。更严重的问题是，&lt;strong&gt;通用 CPU 的延迟不够稳定&lt;/strong&gt;。例如当负载较高时，转发延迟可能升到几十微秒甚至更高（如下图所示）；现代操作系统中的时钟中断和任务调度也增加了延迟的不确定性。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPfr5SQnVztOjxotF9OzaewWqHC3Yz2XY7F2OiarlMiagTlC2pPNe84AlGgt98OrNR5icb0YBG9KjqmA/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;ClickNP（FPGA）与 Dell S6000 交换机（商用交换机芯片）、Click+DPDK（CPU）和 Linux（CPU）的转发延迟比较，error bar 表示 5% 和 95%。来源：[5]&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然 GPU 也可以高性能处理数据包，但 GPU 是没有网口的，意味着需要首先把数据包由网卡收上来，再让 GPU 去做处理。这样吞吐量受到 CPU 和/或网卡的限制。GPU 本身的延迟就更不必说了。&lt;br/&gt;&lt;br/&gt;那么为什么不把这些网络功能做进网卡，或者使用可编程交换机呢？&lt;strong&gt;ASIC 的灵活性仍然是硬伤&lt;/strong&gt;。尽管目前有越来越强大的可编程交换机芯片，比如支持 P4 语言的 Tofino，ASIC 仍然不能做复杂的有状态处理，比如某种自定义的加密算法。&lt;br/&gt;&lt;br/&gt;综上，&lt;strong&gt;在数据中心里 FPGA 的主要优势是稳定又极低的延迟，适用于流式的计算密集型任务和通信密集型任务。&lt;/strong&gt;&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;二、微软部署 FPGA 的实践&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2016 年 9 月，《连线》（&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;Wired&lt;/em&gt;）杂志发表了一篇《微软把未来押注在 FPGA 上》的报道 [3]，讲述了 Catapult 项目的前世今生。紧接着，Catapult 项目的老大 Doug Burger 在 Ignite 2016 大会上与微软 CEO Satya Nadella 一起做了 FPGA 加速机器翻译的演示。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPfr5SQnVztOjxotF9OzaewWNehneTIkz9QViaxTGTrLiaSSsWMwQL3s1ibqIQicM02H2NhVlNCN29r5A/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;Ignite 2016 上的演示：每秒 1 Exa-op (10^18) 的机器翻译运算能力&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里就给大家八一八这个每秒 1 Exa-op 的数字是怎么算出来的。每块生产环境中部署的 Stratix V FPGA 有 1.8 T ops 的计算能力，每台服务器上插一块 FPGA。实际使用时，每 8 台服务器为一组，一台服务器作为 FPGA 的控制节点。控制节点的 CPU 也可以做机器翻译的计算，但是每个 CPU 核只能做 0.1 T ops，相比 FPGA 是聊胜于无。非控制节点上的 FPGA 通过网络从其他 FPGA 收发数据，不需要本地 CPU 处理数据平面。&lt;br/&gt;&lt;br/&gt;截至演示时，微软 Azure 云有 46 万台服务器部署了 FPGA，必应有 1.5 万台，Exchange 服务有 9.5 万台，共计 57 万台。乘起来得到总的计算能力是 103 万 T ops，也就是 1.03 Exa-op，相当于 10 万块顶级 GPU 计算卡。一块 FPGA（加上板上内存和网络接口等）的功耗大约是 30 W，仅增加了整个服务器功耗的十分之一。&lt;br/&gt;&lt;br/&gt;微软部署 FPGA 并不是一帆风顺的。&lt;strong&gt;对于把 FPGA 部署在哪里这个问题，大致经历了三个阶段：&lt;/strong&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="max-width: 100%; color: rgb(62, 62, 62); font-size: 16px; font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); width: 527.778px; line-height: 28.4444px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;专用的 FPGA 集群，里面插满了 FPGA&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;每台机器一块 FPGA，采用专用网络连接&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;每台机器一块 FPGA，放在网卡和交换机之间，共享服务器网络&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPfr5SQnVztOjxotF9OzaewSAhibGfgCicnuMqtjADr5DmPKwEEm2iarXMWI9bj8UnEgHiaR6ics8Zv7hA/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;微软 FPGA 部署方式的三个阶段，来源：[3]&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一个阶段是专用集群，里面插满了 FPGA 加速卡，就像是一个 FPGA 组成的超级计算机。下图是最早的 BFB 实验板，一块 PCIe 卡上放了 6 块 FPGA，每台 1U 服务器上又插了 4 块 PCIe 卡。&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPfr5SQnVztOjxotF9Ozaew4ia4Yia7NnS8RG3YUYvSv2LTkHGx68XJGiaL2tDLgiaSRcq4ERBraoG0ZA/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;最早的 BFB 实验板，上面放了 6 块 FPGA。来源：[1]&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;只要规模足够大，对 FPGA 价格过高的担心将是不必要的。&lt;/strong&gt;&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPfr5SQnVztOjxotF9OzaewrBxLLV4H7QTyvK7QGKU7g6Cr2mAUFbnic4NAhvGepkPYiaE6gqR1Hb1g/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;最早的 BFB 实验板，1U 服务器上插了 4 块 FPGA 卡。来源：[1]&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;像超级计算机一样的部署方式，意味着有专门的一个机柜全是上图这种装了 24 块 FPGA 的服务器（下图左）。这种方式有几个问题：&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="max-width: 100%; color: rgb(62, 62, 62); font-size: 16px; font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); width: 527.778px; line-height: 28.4444px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;不同机器的 FPGA 之间无法通信，FPGA 所能处理问题的规模受限于单台服务器上 FPGA 的数量；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;数据中心里的其他机器要把任务集中发到这个机柜，构成了 in-cast，网络延迟很难做到稳定。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;FPGA 专用机柜构成了单点故障，只要它一坏，谁都别想加速了；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;装 FPGA 的服务器是定制的，冷却、运维都增加了麻烦。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;br/&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPfr5SQnVztOjxotF9OzaewDibXrD8FYK0GMDHtTcxdVlkKgIO9GpdV5h6Z3LlCqQiaQEpwpsn7GX6A/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;部署 FPGA 的三种方式，从中心化到分布式。来源：[1]&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一种不那么激进的方式是，在每个机柜一面部署一台装满 FPGA 的服务器（上图中）。这避免了上述问题 (2)(3)，但 (1)(4) 仍然没有解决。&lt;br/&gt;&lt;br/&gt;第二个阶段，为了&lt;strong&gt;保证数据中心中服务器的同构性&lt;/strong&gt;（这也是不用 ASIC 的一个重要原因），在每台服务器上插一块 FPGA（上图右），FPGA 之间通过专用网络连接。这也是微软在 ISCA'14 上所发表论文采用的部署方式。&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPfr5SQnVztOjxotF9OzaewRAGTUfW0FWJkJn6bibkXttt0Gpn6BLyaPeOzpCDNDIcjhiaC4ZkmzelQ/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;Open Compute Server 在机架中。来源：[1]&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPfr5SQnVztOjxotF9OzaewAq975KwklibBZbZoKYj8M9etWu1QhEUBS3e2u6kkLZoFvAyo0Jdwnzg/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;Open Compute Server 内景。红框是放 FPGA 的位置。来源：[1]&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPfr5SQnVztOjxotF9OzaewqC187f4LIyGlDwy4NMOAxM0TXv7hD9Xw7Sg6NzocEqVQRs95uqk7UQ/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;插入 FPGA 后的 Open Compute Server。来源：[1]&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPfr5SQnVztOjxotF9OzaewOnpM8A2oojXGM1WZ3jEQICNGbjQbuOlt5icCV9mETHnq1Wh1Rz4Z8xw/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;FPGA 与 Open Compute Server 之间的连接与固定。来源：[1]&lt;/span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;FPGA采用Stratix V D5，有172K个ALM，2014个M20K片上内存，1590个 DSP。板上有一个8GB DDR3-1333内存，一个PCIe Gen3 x8接口，两个10 Gbps网络接口。一个机柜之间的FPGA采用专用网络连接，一组10G网口8个一组连成环，另一组10G网口6个一组连成环，不使用交换机。&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPfr5SQnVztOjxotF9OzaewAYyc9trdOFVuDWR7rXdKf5IxTgdpEibn4YXBmV0FfIH4zbIwfxicrkZg/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;机柜中 FPGA 之间的网络连接方式。来源：[1]&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这样一个 1632 台服务器、1632 块 FPGA 的集群，把必应的搜索结果排序整体性能提高到了 2 倍（换言之，节省了一半的服务器）。如下图所示，每 8 块 FPGA 穿成一条链，中间用前面提到的 10 Gbps 专用网线来通信。这 8 块 FPGA 各司其职，有的负责从文档中提取特征（黄色），有的负责计算特征表达式（绿色），有的负责计算文档的得分（红色）。&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPfr5SQnVztOjxotF9OzaewLPK7d5KKC1icD13JXUicTK2E0iaesSEDD8domTAxwZibr7HY693cXicY2Yg/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;FPGA 加速必应的搜索排序过程。来源：[1]&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除了加速搜索结果的排序（RaaS，Ranking as a Service），FPGA 还被用来加速从倒排索引中取出相关文档并译码的过程（SaaS，Selection as a Service）。为了加快文档数据结构的访问，FPGA 把服务器主存里常用的 4K 内存页面缓存在 FPGA 板上的 DDR 上。&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPfr5SQnVztOjxotF9OzaewcYicicWjzDqRwLwZcWOCul2G30SnkF0vWoewaVNKMoaT3icNrhic60LBsA/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;FPGA 不仅降低了必应搜索的延迟，还显著提高了延迟的稳定性。来源：[4]&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPfr5SQnVztOjxotF9OzaewibziarrPD4OA9vzH74UW8oxkYjiamZqap7rGK6Dp30ZQD3kI4AkfibXT0w/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;本地和远程的 FPGA 均可以降低搜索延迟，远程 FPGA 的通信延迟相比搜索延迟可忽略。来源：[4]&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;FPGA 在必应的部署取得了成功，Catapult 项目继续在公司内扩张。微软内部拥有最多服务器的，就是云计算 Azure 部门了。Azure 部门急需解决的问题是网络和存储虚拟化带来的开销。Azure 把虚拟机卖给客户，需要给虚拟机的网络提供防火墙、负载均衡、隧道、NAT 等网络功能。由于云存储的物理存储跟计算节点是分离的，需要把数据从存储节点通过网络搬运过来，还要进行压缩和加密。&lt;br/&gt;&lt;br/&gt;在 1 Gbps 网络和机械硬盘的时代，网络和存储虚拟化的 CPU 开销不值一提。随着网络和存储速度越来越快，网络上了 40 Gbps，一块 SSD 的吞吐量也能到 1 GB/s，CPU 渐渐变得力不从心了。例如 Hyper-V 虚拟交换机只能处理 25 Gbps 左右的流量，不能达到 40 Gbps 线速，当数据包较小时性能更差；AES-256 加密和 SHA-1 签名，每个 CPU 核只能处理 100 MB/s，只是一块 SSD 吞吐量的十分之一。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPfr5SQnVztOjxotF9OzaewX3icpjVGfWN8XIeI3zPHZkYuH57nl3ia23XufxQibtBWlMXtGBZpvYCKg/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;网络隧道协议、防火墙处理 40 Gbps 需要的 CPU 核数。来源：[5]&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;为了加速网络功能和存储虚拟化，微软把 FPGA 部署在网卡和交换机之间。&lt;/strong&gt;如下图所示，每个 FPGA 有一个 4 GB DDR3-1333 DRAM，通过两个 PCIe Gen3 x8 接口连接到一个 CPU socket（物理上是 PCIe Gen3 x16 接口，因为 FPGA 没有 x16 的硬核，逻辑上当成两个 x8 的用）。物理网卡（NIC）就是普通的 40 Gbps 网卡，仅用于宿主机与网络之间的通信。&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPfr5SQnVztOjxotF9OzaewhHR1tRr1TkFMs2T8jlkI1KfwnRntZK1tI94HkB5mlkaHV4ibErTgP9Q/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;Azure 服务器部署 FPGA 的架构。来源：[6]&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;FPGA（SmartNIC）对每个虚拟机虚拟出一块网卡，虚拟机通过 SR-IOV 直接访问这块虚拟网卡。原本在虚拟交换机里面的数据平面功能被移到了 FPGA 里面，虚拟机收发网络数据包均不需要 CPU 参与，也不需要经过物理网卡（NIC）。这样不仅节约了可用于出售的 CPU 资源，还&lt;strong&gt;提高了虚拟机的网络性能（25 Gbps），把同数据中心虚拟机之间的网络延迟降低了 10 倍&lt;/strong&gt;。&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPfr5SQnVztOjxotF9Ozaewcb6FibZt2AAMhB5QtBCl4lvFz10TMQ6XulXGjz2PJhLRrfBWxjiaOxDw/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;网络虚拟化的加速架构。来源：[6]&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这就是微软部署 FPGA 的第三代架构，也是目前「每台服务器一块 FPGA」大规模部署所采用的架构。&lt;strong&gt;FPGA 复用主机网络的初心是加速网络和存储，更深远的影响则是把 FPGA 之间的网络连接扩展到了整个数据中心的规模&lt;/strong&gt;，做成真正 cloud-scale 的「超级计算机」。第二代架构里面，FPGA 之间的网络连接局限于同一个机架以内，FPGA 之间专网互联的方式很难扩大规模，通过 CPU 来转发则开销太高。&lt;br/&gt;&lt;br/&gt;第三代架构中，FPGA 之间通过 LTL (Lightweight Transport Layer) 通信。同一机架内延迟在 3 微秒以内；8 微秒以内可达 1000 块 FPGA；20 微秒可达同一数据中心的所有 FPGA。第二代架构尽管 8 台机器以内的延迟更低，但只能通过网络访问 48 块 FPGA。为了支持大范围的 FPGA 间通信，第三代架构中的 LTL 还支持 PFC 流控协议和 DCQCN 拥塞控制协议。&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPfr5SQnVztOjxotF9Ozaew2pfsh7Pn7wOT2ibeyP9WCiaU8lX62viaCyqqTFadCJSjJ7QOeUS8OYMIg/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;纵轴：LTL 的延迟，横轴：可达的 FPGA 数量。来源：[4]&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPfr5SQnVztOjxotF9OzaewKZT5AeuZ3uB0Hv5jESvO8rCTqDbdiaTFXblmuZIGicnvrvd7KOib0BKrQ/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;FPGA 内的逻辑模块关系，其中每个 Role 是用户逻辑（如 DNN 加速、网络功能加速、加密），外面的部分负责各个 Role 之间的通信及 Role 与外设之间的通信。来源：[4]&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPfr5SQnVztOjxotF9OzaewDQ1iay2HkiaDkN7h1SdcFKyfk6UWXmJAOUbyGtE5JZpZgSUzeXLWgP9w/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;FPGA 构成的数据中心加速平面，介于网络交换层（TOR、L1、L2）和传统服务器软件（CPU 上运行的软件）之间。来源：[4]&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;通过高带宽、低延迟的网络互联的 FPGA 构成了介于网络交换层和传统服务器软件之间的数据中心加速平面。&lt;/strong&gt;除了每台提供云服务的服务器都需要的网络和存储虚拟化加速，FPGA 上的剩余资源还可以用来加速必应搜索、深度神经网络（DNN）等计算任务。&lt;br/&gt;&lt;br/&gt;&lt;strong&gt;对很多类型的应用，随着分布式 FPGA 加速器的规模扩大，其性能提升是超线性的。&lt;/strong&gt;例如 CNN inference，当只用一块 FPGA 的时候，由于片上内存不足以放下整个模型，需要不断访问 DRAM 中的模型权重，性能瓶颈在 DRAM；如果 FPGA 的数量足够多，每块 FPGA 负责模型中的一层或者一层中的若干个特征，使得模型权重完全载入片上内存，就消除了 DRAM 的性能瓶颈，完全发挥出 FPGA 计算单元的性能。当然，拆得过细也会导致通信开销的增加。&lt;strong&gt;把任务拆分到分布式 FPGA 集群的关键在于平衡计算和通信。&lt;/strong&gt;&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPfr5SQnVztOjxotF9OzaewBvdltTEqL0rALbhpia6Yiay9hcvJW7etrYwV2Yty18xDHPIKm7dtukFg/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;从神经网络模型到 HaaS 上的 FPGA。利用模型内的并行性，模型的不同层、不同特征映射到不同 FPGA。来源：[4]&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 MICRO'16 会议上，微软提出了&amp;nbsp;&lt;strong&gt;Hardware as a Service (HaaS)&lt;/strong&gt;&amp;nbsp;的概念，即把硬件作为一种可调度的云服务，使得 FPGA 服务的集中调度、管理和大规模部署成为可能。&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPfr5SQnVztOjxotF9OzaewFj1LMk3FiaUg6obiaJDTe85E0Mibq4uNCria6bRjibibxcLiaOg3fwvjpicerw/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;Hardware as a Service (HaaS)。来源：[4]&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从第一代装满 FPGA 的专用服务器集群，到第二代通过专网连接的 FPGA 加速卡集群，到目前复用数据中心网络的大规模 FPGA 云，三个思想指导我们的路线：&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="max-width: 100%; color: rgb(62, 62, 62); font-size: 16px; font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); width: 527.778px; line-height: 28.4444px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;硬件和软件不是相互取代的关系，而是合作的关系；&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;必须具备灵活性，即用软件定义的能力；&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;必须具备可扩放性（scalability）。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;三、FPGA 在云计算中的角色&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后谈一点我个人对 FPGA 在云计算中角色的思考。作为三年级博士生，我在微软亚洲研究院的研究试图回答两个问题：&lt;br/&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="max-width: 100%; color: rgb(62, 62, 62); font-size: 16px; font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); width: 527.778px; line-height: 28.4444px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;FPGA 在云规模的网络互连系统中应当充当怎样的角色？&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如何高效、可扩放地对 FPGA + CPU 的异构系统进行编程？&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我对 FPGA 业界主要的遗憾是，FPGA 在数据中心的主流用法，从除微软外的互联网巨头，到两大 FPGA 厂商，再到学术界，大多是把 FPGA 当作跟 GPU 一样的计算密集型任务的加速卡。然而 FPGA 真的很适合做 GPU 的事情吗？前面讲过，&lt;strong&gt;FPGA 和 GPU 最大的区别在于体系结构，FPGA 更适合做需要低延迟的流式处理，GPU 更适合做大批量同构数据的处理。&lt;/strong&gt;&lt;br/&gt;&lt;br/&gt;由于很多人打算把 FPGA 当作计算加速卡来用，两大 FPGA 厂商推出的高层次编程模型也是基于 OpenCL，模仿 GPU 基于共享内存的批处理模式。CPU 要交给 FPGA 做一件事，需要先放进 FPGA 板上的 DRAM，然后告诉 FPGA 开始执行，FPGA 把执行结果放回 DRAM，再通知 CPU 去取回。&lt;strong&gt;CPU 和 FPGA 之间本来可以通过 PCIe 高效通信，为什么要到板上的 DRAM 绕一圈？&lt;/strong&gt;也许是工程实现的问题，我们发现通过 OpenCL 写 DRAM、启动 kernel、读 DRAM 一个来回，需要 1.8 毫秒。而通过 PCIe DMA 来通信，却只要 1~2 微秒。&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPfr5SQnVztOjxotF9OzaewQ4ibDebSOt5cgBGx7116GYjHXMZyWXePEGTuKF93lvsh7DPDoRz7d5Q/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;PCIe I/O channel 与 OpenCL 的性能比较。纵坐标为对数坐标。来源：[5]&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;OpenCL 里面多个 kernel 之间的通信就更夸张了，默认的方式也是通过共享内存。本文开篇就讲，FPGA 比 CPU 和 GPU 能效高，体系结构上的根本优势是无指令、无需共享内存。使用共享内存在多个 kernel 之间通信，在顺序通信（FIFO）的情况下是毫无必要的。况且 FPGA 上的 DRAM 一般比 GPU 上的 DRAM 慢很多。&lt;br/&gt;&lt;br/&gt;因此我们提出了 ClickNP 网络编程框架 [5]，&lt;strong&gt;使用管道（channel）而非共享内存来在执行单元（element/kernel）间、执行单元和主机软件间进行通信&lt;/strong&gt;。需要共享内存的应用，也可以在管道的基础上实现，毕竟 CSP（Communicating Sequential Process）和共享内存理论上是等价的嘛。ClickNP 目前还是在 OpenCL 基础上的一个框架，受到 C 语言描述硬件的局限性（当然 HLS 比 Verilog 的开发效率确实高多了）。理想的硬件描述语言，大概不会是 C 语言吧。&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPfr5SQnVztOjxotF9OzaewSGbg6vQ7MUbgiaNY4y6MgEia1ES83Mh5d9PyZ5sGkxvxhpx8o2HDN0oQ/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;ClickNP 使用 channel 在 elements 间通信，来源：[5]&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPfr5SQnVztOjxotF9OzaewW6mf6gIvjZlMWF9SEkVlweX3aLRsicJBibzm1VGic4nSRntXicR0gvb5icg/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;ClickNP 使用 channel 在 FPGA 和 CPU 间通信，来源：[5]&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;低延迟的流式处理，需要最多的地方就是通信。然而&amp;nbsp;&lt;strong&gt;CPU 由于并行性的限制和操作系统的调度，做通信效率不高，延迟也不稳定&lt;/strong&gt;。此外，&lt;strong&gt;通信就必然涉及到调度和仲裁&lt;/strong&gt;，CPU 由于单核性能的局限和核间通信的低效，调度、仲裁性能受限，硬件则很适合做这种重复工作。因此我的博士研究把 FPGA 定义为通信的「大管家」，不管是服务器跟服务器之间的通信，虚拟机跟虚拟机之间的通信，进程跟进程之间的通信，CPU 跟存储设备之间的通信，都可以用 FPGA 来加速。&lt;br/&gt;&lt;br/&gt;成也萧何，败也萧何。缺少指令同时是 FPGA 的优势和软肋。每做一点不同的事情，就要占用一定的 FPGA 逻辑资源。如果要做的事情复杂、重复性不强，就会占用大量的逻辑资源，其中的大部分处于闲置状态。这时就不如用冯·诺依曼结构的处理器。数据中心里的很多任务有很强的局部性和重复性：&lt;strong&gt;一部分是虚拟化平台需要做的网络和存储，这些都属于通信；另一部分是客户计算任务里的，比如机器学习、加密解密&lt;/strong&gt;。我们首先把 FPGA 用于它最擅长的通信，日后也许也会像 AWS 那样把 FPGA 作为计算加速卡租给客户。&lt;br/&gt;&lt;br/&gt;不管通信还是机器学习、加密解密，算法都是很复杂的，如果试图用 FPGA 完全取代 CPU，势必会带来 FPGA 逻辑资源极大的浪费，也会提高 FPGA 程序的开发成本。更实用的做法是&amp;nbsp;&lt;strong&gt;FPGA 和 CPU 协同工作，局部性和重复性强的归 FPGA，复杂的归 CPU。&lt;/strong&gt;&lt;br/&gt;&lt;br/&gt;当我们用 FPGA 加速了必应搜索、深度学习等越来越多的服务；当网络虚拟化、存储虚拟化等基础组件的数据平面被 FPGA 把持；当 FPGA 组成的「数据中心加速平面」成为网络和服务器之间的天堑……似乎有种感觉，FPGA 将掌控全局，CPU 上的计算任务反而变得碎片化，受 FPGA 的驱使。以往我们是 CPU 为主，把重复的计算任务卸载（offload）到 FPGA 上；以后会不会变成 FPGA 为主，把复杂的计算任务卸载到 CPU 上呢？随着 Xeon + FPGA 的问世，古老的 SoC 会不会在数据中心焕发新生？&lt;br/&gt;&lt;br/&gt;「跨越内存墙，走向可编程世界」&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;(&lt;/em&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;Across the memory wall and reach a fully programmable world.&lt;/em&gt;)&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;参考文献：&lt;/p&gt;&lt;p&gt;&lt;br/&gt;[1] Large-Scale Reconfigurable Computing in a Microsoft Datacenterhttps://www.microsoft.com/en-us/research/wp-content/uploads/2014/06/HC26.12.520-Recon-Fabric-Pulnam-Microsoft-Catapult.pdf&lt;/p&gt;&lt;p&gt;&lt;br/&gt;[2] A Reconfigurable Fabric for Accelerating Large-Scale Datacenter Services, ISCA'14https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/Catapult_ISCA_2014.pdf&lt;/p&gt;&lt;p&gt;&lt;br/&gt;[3]&amp;nbsp;Microsoft Has a Whole New Kind of Computer Chip—and It’ll Change Everything&lt;/p&gt;&lt;p&gt;&lt;br/&gt;[4] A Cloud-Scale Acceleration Architecture, MICRO'16&amp;nbsp;https://www.microsoft.com/en-us/research/wp-content/uploads/2016/10/Cloud-Scale-Acceleration-Architecture.pdf&lt;/p&gt;&lt;p&gt;&lt;br/&gt;[5]&amp;nbsp;ClickNP: Highly Flexible and High-performance Network Processing with Reconfigurable Hardware - Microsoft Research&lt;/p&gt;&lt;p&gt;&lt;br/&gt;[6] Daniel Firestone, SmartNIC: Accelerating Azure's Network with. FPGAs on OCS servers.&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;span&gt;作者简介&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/HkPvwCuFwNPfr5SQnVztOjxotF9OzaewoO9InWWNbrSUUNpyRuAQibgWd3wMHpw0ibhYuboHMfOrnKnIrH1mmZxg/640?wx_fmt=jpeg"/&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;我叫李博杰，本科毕业于中国科学技术大学少年班学院，2014年加入中国科学技术大学与微软亚洲研究院的联合培养博士生项目。我的研究方向是数据中心网络和可重构硬件（FPGA）上的编程。&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心转载文章，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系作者获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 11 Jan 2017 13:40:32 +0800</pubDate>
    </item>
    <item>
      <title>深度 | 硬件不给力，如何穷玩深度神经网络？</title>
      <link>http://www.iwgc.cn/link/4275482</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自LinkedIn&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀、蒋思源、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;深度学习的力量为其在真实世界的应用创造出了巨大的机会。但深度学习的训练往往需要巨大的计算能力，有时候我们却没法（或没钱）去使用强大的服务器或 NVIDIA 的 Jetson 那样的嵌入式加速平台。假如你需要使用一块树莓派开发板为你家的小院子开发一个目标跟踪器呢？换句话说，如果你需要在没有加速器的 ARM CPU 上运行一个 CNN，你该怎么做？德国 BuddyGuard GmbH 的机器学习工程师 Dmytro Prylipko 近日在 LinkedIn 上发表了一篇文章，分享了他在弱硬件上运行深度神经网络的经验方法。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9rD6KzMuKBaJJEmtibaiciaXJoBOtyryCRic2ZLRLYicRFIBhmGia2eiaadsmKaBeCibLIywql4Eb1jwjicSA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器学习社区已经在加速神经网络推理上进行了很长一段时间的研究了，也已经出现了大量可能有效的解决方案。在这篇文章中，我将尝试回答一个简单的问题：什么软件库/工具包/框架可以帮助改善我们训练好的模型的推理时间？出于文章篇幅的考虑，这篇文章我不会考虑修改网络架构（尽管这确实是一个好方法，比如 SqeezeNet），而是仅仅探讨那些已经可以在 ARM 设备上投入生产并且提供了 C/C++ 接口（因为我们很少在嵌入式设备上使用 Lua 或 Python）的工具包和软件库。所以在这里我仅仅实验了 Caffe、TensorFlow 和 MXNet。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;我们可以做什么&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;要加速你的计算，我们有两个主要的大方向：1）修改模型；2）加速框架。当然，也可能是将这两者结合起来（而且确实是不错的想法）。前一种方法往往需要使用更低的权重精度（也被称为量化（quantization））和/或权重剪枝（weights pruning）。剪枝背后的思想是深度学习模型中的重要参数化冗余，而低精度方法（为浮点数使用了定点或动态定点表示）则利用了这样一个事实——即推理过程并不需要高精度：因为运算的线性本质和非线性的动态范围压缩（dynamic range compression），量化误差（quantization errors）往往倾向于亚线性地（sub-linearly）传播，而不会引起数值不稳定性（Vanhoucke, V., Senior, A., &amp;amp; Mao, M. (2011). Improving the speed of neural networks on CPUs）。此外，我们甚至可以使用低精度乘法来训练模型。结合 SIMD 指令（比如 SSE3），参数量化可以实现非常有效的计算加速。但是目前我们还很难找到同时使用了这两者的解决方案。比如 Ristretto 可以执行自动量化，但它却并没有利用其来降低计算成本。TensorFlow 也可以执行量化，但其推理时间实际上却增加了 5 到 20 倍，因为其向图（graph）中还引入了辅助量化/去量化节点（auxiliary quantize/dequantize nodes）。所以，如果空间上的考虑很重要，那么实际上我们可以将量化仅仅看作是一种压缩网络权重的方法。至少对于当前的状态而言，我们可以这样考虑。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一方面，我们也有用于框架的加速执行时间（execution time）的方法，而不会影响到模型参数。这些方法基本上都是试图优化矩阵之间的乘法（GEMM）的通用计算技巧，并因此会同时影响卷积层（其计算通常是 im2col + GEMM）和全连接层。除此之外是 NNPACK：一个用于深度学习框架的加速包。这个加速包还曾得到过 Yann LeCun 的推荐！就我所知，NNPACK 使用了 FFT 来将时间域中的卷积运算替换成了频域中的乘法计算。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一个方法是将网络定义和权重翻译成针对目标进行优化过的代码，而不是将它们运行在同样一个框架内。这种方法的典型案例是 TensorRT。还有 CaffePresso 可以将 Caffe prototxt 翻译成针对各种不同后端的更低级的规格。但是，TensorRT 的运行需要 CUDA，而且只能在 NVIDIA GPU 上使用，而 CaffePresso 也需要某种硬件加速器（DSP、FPGA 或 NoC），所以这两种都不适合用于我的测试硬件——树莓派。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相关链接：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;Ristretto：&lt;/span&gt;&lt;span&gt;http://lepsucd.com/?page_id=621&lt;/span&gt;&lt;br/&gt;&lt;span&gt;NNPACK：&lt;/span&gt;&lt;span&gt;http://github.com/Maratyszcza/NNPACK&lt;/span&gt;&lt;br/&gt;&lt;span&gt;TensorRT：&lt;/span&gt;&lt;span&gt;http://developer.nvidia.com/tensorrt&lt;/span&gt; &lt;br/&gt;&lt;span&gt;CaffePresso：http://github.com/gplhegde/caffepresso&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;调测配置&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当谨慎地评估现存的解决办法后，我发现下列方法能够加速当前流行的可用模型的推理：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如果你的构架使用了 OpenBLAS，你可以尝试其为深度学习进行过优化的分支：http://github.com/xianyi/OpenBLAS/tree/optimized_for_deeplearning&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;NNPACK 能和其他一些框架（包括 Torch、Caffe 和 MXNet）联合使用：http://github.com/Maratyszcza/NNPACK&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;当在树莓派上使用 TensorFlow 时，你可以使用 NEON 指令集提供一些 optimization flags：http://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/makefile#raspberry-pi&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过这些，我能列出以下调测配置：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="list-style-type: decimal;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;带有 OpenBLAS 主分支（master branch）的 Caffe 作为后端（caffe-openblas）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;带有 OpenBLAS 的深度学习优化分支（caffe-openblas-dl）的 Caffe&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;使用 OPTFLAGS="-Os" (tf-vanilla) 编译的 TensorFlow&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;使用 OPTFLAGS="-Os -mfpu=neon-vfpv4 -funsafe-math-optimizations -ftree-vectorize" (tf-neon-vfpv4) 编译的 TensorFlow&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;带有用于线性代数计算的 OpenBLAS (mxnet-openblas) 的 Vanilla MXNet&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;带有 OpenBLAS 的深度学习优化分支 (mxnet-openblas-dl) 的 MXNet&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你可能会疑惑：配置中怎么没有 NNPACK？这确实有点复杂，由 ajtulloch 制作的 Caffe 分支提供了使用 NNPACK 的最直接的方法。然而自从它被集成进去以后，NNPACK API 就已经改变了，并且目前我们不能编译它）。Caffe2 对 NNPACK 有原生支持，但我不会考虑 Caffe2，因为它处于实验性阶段并且几乎对 Caffe 进行了重构，相关的文档也不多。另外一个选项就是使用 Maratyszcza/caffe-nnpack，虽然它比较老旧且没有什么维护。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外一个问题就是 NNPACK 自身。它并不提供在 Linux/ARM 上的交叉编译（cross-compilation）配置，只有在 Android/ARM 上的交叉编译（cross-compilation）配置。我的实验性构建在与 MXNet 结合的目标平台上无法工作。我只能在台式电脑上运行它，但是我并没有看到使用 OpenBLAS 会有更优秀的表现。由于我的目标是评估已经可用的解决方法，所以我只能以后再做 NNPACK 的实验了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相关链接：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;ajtulloch 制作的 Caffe 分支：http://github.com/ajtulloch/caffe/tree/nnpack-pr&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;NNPACK API 编译问题：https://github.com/Maratyszcza/NNPACK/issues/1#issuecomment-266416638&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Maratyszcza/caffe-nnpack：http://github.com/Maratyszcza/caffe-nnpack&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;NNPACK Linux/ARM 问题：https://github.com/Maratyszcza/NNPACK/issues/35&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;硬件&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所有的这些评估都是在四核 1.3 GHz CPU 和 1 GB RAM 的树莓派 3 上执行。操作系统是 32 位的 Raspbian，所以 CPU 不是 ARMv8 架构，而是 ARMv7 架构。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;model name : ARMv7 Processor rev 4 (v7l)&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;BogoMIPS : 38.40&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;Features : half thumb fastmult vfp edsp neon vfpv3 tls vfpv4 idiva idivt vfpd32 lpae evtstrm crc32&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;CPU implementer : 0x41&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;CPU architecture: 7&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;CPU variant : 0x0&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;CPU part : 0xd03&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;CPU revision : 4&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;测试草案&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了评估上述每个配置的性能，我们会使用相同的神经网络。也就是一个有 3 个卷积层和两个全连接层且在顶部有 softmax 的微型卷积神经网络：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;conv1: 16@7x7&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;relu1pool1: MAX POOL 2x2conv2: 48@6x6&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;relu2pool2: MAX POOL 3x3conv3: 96@5x5&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;relu3fc1: 128 unitsfc2: 848 units&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;softmax&amp;nbsp;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该卷积神经网络有 1039744 个参数。虽然非常小，但它足够处理许多计算机视觉任务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该网络使用 Caffe 进行训练人脸识别任务，并将其转换为 TensorFlow 和 MXNet 格式从而使用这些框架进行评估。为了评估前向通过时间（forward pass time），从 1 到 256 的批大小都进行了测试，因为批大小对性能有很大的影响。而对于每个批大小，网络执行了 100 次前向通过，并为每一张图像计算了平均时间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;评估结果和讨论&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在下面的表格中，列出了平均前向通过的时间。其中，A 是 caffe-openblas, B 是 caffe-openblas-dl, C 代表 tf-vanilla, D 是 tf-neon-vfpv4, E 是 mxnet-openblas, F 是 mxnet-openblas-dl。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9rD6KzMuKBaJJEmtibaiciaXJiaKjIwDvQj1yN1BnRcmdwicxLXUUPfpMEOYtsDfAgrK14mJ9BVECX70A/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9rD6KzMuKBaJJEmtibaiciaXJBBHQok5IzrfyKibxemypuic0JUA4ibtGfrDBTySAKU1t4EnEVQrPmLwAA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在对数尺度（logarithmic scale）尺度上我们来看一下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9rD6KzMuKBaJJEmtibaiciaXJyr66Y3zoqMYlTwy4Z4zmT4Ylw0tc889CE6cTTFjibTqHmCdXCKPDxTA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些结果让我大吃一惊。首先，我没有预料到在 CPU 上运行 MXNet 有如此差的表现。但这看起来已经是一个众所周知的问题。此外，因为存储限制，它无法运行 256 张图片的 batch。第二个惊奇是优化过的 TensorFlow 竟有如此好的表现。它甚至比 Caffe 的表现还好（在超过 2 的批大小上）；光是从原始框架上看是很难预料这个结果的。但小心：不保证你能在任意 ARM 设备上使用这些 flags。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;众所周知，Caffe 的速度非常快。如果你要一张接一张地处理图片，使用优化过的 OpenBLAS 的 Caffe 将会是你最好的选择。想要有 10ms 的改进，你所要做的就只是简单的输入：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;cd OpenBLAS&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;git checkout optimized_for_deeplearning&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了将我的小研究转变成正式的东西，我仍需要做大量的工作：评估更多的模型，集成 NNPACK，以及研究更多的框架与 BLAS 后端的结合。但我希望它能帮助你了解目前最流行的解决方案的推理速度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原网址：https://www.linkedin.com/pulse/how-run-deep-neural-networks-weak-hardware-dmytro-prylipko&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 10 Jan 2017 12:09:13 +0800</pubDate>
    </item>
    <item>
      <title>学界 | MIT将生物学机制引入神经网络，新模型或揭开抑制神经元功能</title>
      <link>http://www.iwgc.cn/link/4275483</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;选自Eurekalert&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;参与：微胖、朱思颖&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;构建了一个新的计算模型，可能有助于我们理解防止其他神经元放电的抑制神经元在计算上所扮演的角色。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;MIT CSAIL（计算机科学和人工智能实验室）研究员们开发出一个新的大脑神经回路计算模型，这一模型将有助于理解抑制神经元（阻止其他神经元放电）的生物学功能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这一模型描述了一个由一列输入神经元和等量输出神经元构成的神经回路，执行神经科学家所谓的「赢家通吃」策略（winner-take-all。重要研究发现，神经系统以这样一种简单的竞争机制保证了使用频率较高、输入较强的环路联接被保留下来并加以强化，而使用频率低、输入较弱的联接被去除，从而使系统资源得到最优化的分配，神经环路的联接更加精确。这种基于竞争的分子机制，对理解正常脑发育十分重要，对研究自闭症（又称孤独症）、精神分裂症等发育性神经系统疾病有重要的借鉴作用。——译者注），其中，来自多个输入神经元的信号仅引发一个输出神经元的信号。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;运用理论计算机科学工具，研究员们证明：在他们的模型条件下，一种特定抑制神经元的配置是能够提供激发「赢家通吃」操作的最有效手段。这一模型能对大脑中抑制神经元的行为做出实证性预测，从而为计算分析援助神经科学研究的方式提供一个范本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;研究员们将在这周的理论计算机科学创新（Innovations in Theoretical Comptuer Science）大会上展示他们的研究成果。MIT 软件科学和工程系的 NEC 教授 Nancy Lynch 是这篇论文的第一作者。加入这项研究的还有她研究团队里的一位博后 Merav Parter，以及 MIT 电子工程与计算机科学系的研究生 Cameron Musco。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;多年以来，Lynch 的团队在自组织网络（ad hoc networks）的交流和资源分配上开展研究，自组织网络是一种组织成员不断离开和再次加入的网络。直到最近，团队开始使用网络分析工具来研究生物学现象。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「计算机网络的行为（或者其他设备如手机）与生物系统之间有密切的对应关系，」Lynch 谈到。「我们尝试去寻找这样一些问题，这些问题能够从这样的分布式计算视角中受益，并关注我们可以证明出数学性质的算法。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;人工神经学&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;近年以来，人工神经网络——计算机模型几乎都是基于大脑结构而构建的。此后，从语音转录到面部识别软件，人工智能系统里一些最快速的改进都得益于人工神经网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个人工神经网络包含一系列结点（nodes），这些节点就如一个个神经元，单个结点的信息处理能力有限，但结点之间的相互联系非常稠密。数据会首先输入到第一层结点中，如果一个有阈值判定条件的给定结点接收到数据之后，比如说这个数据值超过某一特定值，那么这个结点就被激发了也即把信号沿着它所有的输出连接传给下一层结点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所有的这些输出连接每一个都是有关联权重值的，这些权重值可以增强或者减弱传递信号。下一层的每一个结点将会接收到第一层多个结点输出的带有权重的信号；每个结点将会把所有的输入信号累加起来，同理，如果所有信号的累加总值超过某一阈值，这个结点就被激发了，且这个节点的所有输出信号传递到下一层，如此进行下去。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在人工智能应用中，我们使用样本数据「训练」神经网络，不断调整权重和放电阈值，直到最终层的输出能持续表征出一些计算问题的解决方案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;生物合理性&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Lynch, Parter 和 Musco 对这款设计做了一些修改，让它更具生物合理性。第一处修改是增加了抑制「神经元」。一个标准的神经网络中，连接的权重值常常是正的，或者可能为正或负。但是，大脑中的一些神经元显然完全起抑制作用，防止其他神经元放电。MIT 研究人员将这些神经元建模为仅有负权重的连接节点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;许多人工智能应用也是「前馈」网络，信号的传递方向是单一的，从接收输入数据的第一层单向传递到输出计算结果的最后一层。但是，大脑连接要复杂的多。Lynch 等人设计的回路包括&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;反馈：信号经由输出神经元被传递给抑制神经元，它的输出再接着被传递回给输出神经元。输出神经元的信号也反馈给自身，实验证实，这对赢者通吃的策略来说非常重要。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，研究人员的网络是概率性的。在一个典型的人工神经网络中，如果节点输入值超过阈值，节点就会放电。但是，大脑中，增大信号通过输入神经元的力量只会增加一个输出神经元放电的几率。研究人员模型中的节点也是这种情况。这一修改对赢者通吃的策略来说，再次起到了关键作用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在该研究模型中，输入输出神经元的数量是固定的，执行赢者通吃计算也是完全是一堆辅助神经元的任务。Parter 解释说：「我们正在试着观察解决给定问题所花时间和辅助神经元数量之间的平衡。我们将神经元视为一种资源；不想太浪费。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;抑制的好处&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Parter 和她的同事也表明，在他们的模型语境下，赢者通吃的策略要奏效，仅有一个抑制神经元肯定是不够的。但是两个抑制神经元就足够了。技巧在于一个抑制神经元——研究人员称之为收敛神经元——会发出强烈的抑制信号，如果不止一个输出神经元放电的话。另一个抑制神经元——稳定神经元——会发出弱得多的信号，只要任一输出神经元正在放电。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;收敛神经元驱使回路挑选出一个单独的输出神经元，在这一点上停止放电；而稳定神经元防止第二个输出神经元被激活，一旦收敛神经元被关闭的话。源自输出神经元的自反馈回路提升了该效果。一个输出神经元被关闭的时间越长，就有可能继续维持关闭状态；开着的时间越长，就越有可能继续打开着。一但一个单独的输出神经元被选中，其自发聩回路就能确保克服稳定神经元的抑制。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不过，没有随机，回路就不会收敛到一个单独的输出神经元：抑制神经元权重的任一一种设置都会平等影响到所有输出神经元。Parter 解释说，你需要使用随机来打破这种对称性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;研究人员可以确定保证一个特定收敛速度最少需要多少个辅助神经元，以及给定特定数量的辅助神经元，其最快收敛速度是多少。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;增加更多的收敛神经元会增加收敛速度，不过速度会有上限。比如，100 个输入神经元，两到三个收敛神经元就够了；增加一个也不会提升效率。只要一个稳定神经元就已经最优了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不过，或许更有启发性的是，研究人员表明，包括兴奋神经元——刺激而不是抑制其他神经元放电的神经元——以及辅助神经元中的抑制神经元无法证明回路的效率。类似，任何一种没有察觉收敛神经元和稳定神经元差异的抑制神经元的安排都要比可以察觉到这一区别的安排更低效。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那么，假设进化趋于找到解决工程问题的有效解决方案，模型既告诉我们问题的答案就在大脑中，也提出了一个适于经验研究的撩人问题：真实的抑制神经元展示出类似收敛神经元和稳定神经元之间的区别了吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;参考文献：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;PAPER: Computational tradeoffs in biological neural networks: Self-stabilizing winner-take-all networks https://arxiv.org/pdf/1610.02084v1.pdf&lt;/span&gt;&lt;br/&gt;&lt;span&gt;ARCHIVE: Exploring networks efficiently http://news.mit.edu/2016/ant-colony-behavior-better-algorithms-network-communication-0713&lt;/span&gt;&lt;br/&gt;&lt;span&gt;ARCHIVE: New frontier in error-correcting codes http://news.mit.edu/2014/interactive-error-correcting-code-1002&lt;/span&gt;&lt;br/&gt;&lt;span&gt;ARCHIVE: New approach to vertex connectivity could maximize networks' bandwidthhttp://news.mit.edu/2013/new-approach-to-vertex-connectivity-could-maximize-networks-bandwidth-1224&lt;/span&gt;&lt;br/&gt;&lt;span&gt;ARCHIVE: Reliable communication, unreliable networks http://news.mit.edu/2013/reliable-communication-unreliable-networks-0806&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 10 Jan 2017 12:09:13 +0800</pubDate>
    </item>
    <item>
      <title>业界 | IBM连续24年专利数量领跑，人工智能成为其战略重点</title>
      <link>http://www.iwgc.cn/link/4275484</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;机器之心报道&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：李泽南&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;IBM 以 8088 个专利的绝对优势在专利数量上继续领先，在它身后，英特尔和亚马逊正在加速追赶。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在刚刚过去的 2016 年，IBM 继续站稳专利数量第一的位置。随着这家公司正在将战略逐渐转向人工智能领域领，它在相关方向的专利数量也在急剧增长。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本周一，IFI Claims 公布了去年全球公司专利数量排行榜。根据美国专利商标局（US Patent and Trademark Office，USPTO）的数据，2016 年中 IBM 共获得了 8088 项专利，其中超过 2700 项为人工智能和认知计算的相关专利，超过其专利总数的三成。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能技术显然已经成为 IBM 发展战略的重点。对此，IBM 首席创新官 Bernie Meyerson 表示：「这些人工智能新技术是解决当今社会面临的最大挑战的关键——从开发更有效的癌症治疗方式，到促进更快捷安全的金融服务，再到降低中国、印度等发展中国家空气污染的水平。它们代表着创造信息技术未来所需的核心竞争力。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这份统计中，三星电子排在 IBM 之后，新增了 5518 个专利，随后是佳能（3665）、高通（2897）和谷歌（2835），前五名的位置在过去一年里没有发生变化。在 2016 年中，美国专利商标局共授予了 304,126 个专利，相比 2015 年增加了 10%。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9rD6KzMuKBaJJEmtibaiciaXJkXFyO3ZHM2zBluMwYSYd7JxjIX49GasziaG2kpyMpGjpdUZdYyINNng/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;专利数量是用来衡量一个机构在科研、开发、创新和商业应用影响力的标准之一。一方面，专利数量多意味着这家公司拥有大量的员工和知识产权律师，所以专利数量并不能用来衡量初创公司的实力；另一方面，很多专利在申请成功后并不会进入实用阶段，有一些公司也会通过专利勒索让其他大公司支付巨额专利使用费。尽管如此，专利数量仍然是比较公司科研投入的重要指标。值得注意的是，IBM 在专利数量上已经是连续 24 年排名第一了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9rD6KzMuKBaJJEmtibaiciaXJ2XAs7j5Dict1G4ylNEiau1lgMKT8xyBuTalYJ6JpesicgRgVwyqdNr8eg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;IBM 在 2016 年获得的专利数量比 2015 年多 10%，有一些公司的专利增长速度比它更快，第六位英特尔的专利数量增长了 36%，达到 2784；而第 14 位亚马逊增长了 46%，数量达到了 1662，这使得它在名次上攀升了 12 位。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;苹果公司保持了第 11 位的名次，专利数量增长 8%，达到 2102 个。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在本次统计中我们可以看到，一些日本科技公司正在逐步缩减对于创新的投资，排名第三的佳能少了 11% 的新专利；排名第 11 的索尼的新专利数量只有 2181；东芝的新专利数量则减少了 26%。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在排名前 50 的榜单上，华为以 1202 个专利排名第 25，京东方则排名 40——相比 2015 年爬升了超过一百名，成为了进步最快的公司。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;排名前 50 的公司归属于 11 个国家和地区。美国占据其中专利数量的 41％，其后是日本的 28％，韩国的 15％，台湾地区的 4％，德国的 2.6％，中国为 2.5％。来自亚洲的公司现在已经占据了 Top50 榜单的过半席位，共有 26 家企业。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9rD6KzMuKBaJJEmtibaiciaXJmc51S1DEARTfBxGpCWOp661jdM5TT6lCbHpdyVU8PqCBphVic6lZzsw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;附录：美国专利商标局 2016 年专利数量前 50&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="35"&gt;&lt;span&gt;排名&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="184"&gt;&lt;span&gt;公司&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="60"&gt;&lt;span&gt;2016 数量&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="37"&gt;&lt;span&gt;2015 数量&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);"&gt;&lt;span&gt;变化&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="91"&gt;&lt;span&gt;2015排名&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="9"&gt;&lt;span&gt;1&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(225, 225, 225);" width="184"&gt;&lt;span&gt;IBM集团&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="60"&gt;&lt;span&gt;8,088&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="37"&gt;&lt;span&gt;7,355&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(212, 237, 241);"&gt;&lt;span&gt;9.97%&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="35"&gt;&lt;span&gt;1&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="9"&gt;&lt;span&gt;2&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="184"&gt;&lt;span&gt;三星电子&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="60"&gt;&lt;span&gt;5,518&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="37"&gt;&lt;span&gt;5,072&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(212, 237, 241);"&gt;&lt;span&gt;8.79%&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="35"&gt;&lt;span&gt;2&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="9"&gt;&lt;span&gt;3&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="184"&gt;&lt;span&gt;佳能&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="60"&gt;&lt;span&gt;3,665&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="37"&gt;&lt;span&gt;4,134&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(212, 237, 241);"&gt;&lt;span&gt;-11.34%&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="35"&gt;&lt;span&gt;3&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="9"&gt;&lt;span&gt;4&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="184"&gt;&lt;span&gt;高通&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="60"&gt;&lt;span&gt;2,897&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="37"&gt;&lt;span&gt;2,900&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(212, 237, 241);"&gt;&lt;span&gt;-0.10%&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="35"&gt;&lt;span&gt;4&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="9"&gt;&lt;span&gt;5&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(225, 225, 225);" width="184"&gt;&lt;span&gt;谷歌&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="60"&gt;&lt;span&gt;2,835&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="37"&gt;&lt;span&gt;2,835&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(212, 237, 241);"&gt;&lt;span&gt;0%&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="35"&gt;&lt;span&gt;5&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="9"&gt;&lt;span&gt;6&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="184"&gt;&lt;span&gt;英特尔集团&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="60"&gt;&lt;span&gt;2,784&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="37"&gt;&lt;span&gt;2,048&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(176, 220, 230);"&gt;&lt;span&gt;35.94%&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="35"&gt;&lt;span&gt;9&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="9"&gt;&lt;span&gt;7&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="184"&gt;&lt;span&gt;LG电子&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="60"&gt;&lt;span&gt;2,428&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="37"&gt;&lt;span&gt;2,242&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(212, 237, 241);"&gt;&lt;span&gt;8.30%&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="35"&gt;&lt;span&gt;8&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="9"&gt;&lt;span&gt;8&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(225, 225, 225);" width="184"&gt;&lt;span&gt;微软&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="60"&gt;&lt;span&gt;2,398&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="37"&gt;&lt;span&gt;1,956&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(212, 237, 241);"&gt;&lt;span&gt;22.60%&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="35"&gt;&lt;span&gt;10&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="9"&gt;&lt;span&gt;9&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(200, 230, 201);" width="184"&gt;&lt;span&gt;台积电&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="60"&gt;&lt;span&gt;2,288&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="37"&gt;&lt;span&gt;1,774&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(212, 237, 241);"&gt;&lt;span&gt;28.97%&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="35"&gt;&lt;span&gt;13&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="9"&gt;&lt;span&gt;10&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="184"&gt;&lt;span&gt;索尼&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="60"&gt;&lt;span&gt;2,181&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="37"&gt;&lt;span&gt;2,455&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(212, 237, 241);"&gt;&lt;span&gt;-11.16%&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="35"&gt;&lt;span&gt;7&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="9"&gt;&lt;span&gt;11&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(225, 225, 225);" width="184"&gt;&lt;span&gt;苹果&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="60"&gt;&lt;span&gt;2,102&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="37"&gt;&lt;span&gt;1,938&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(212, 237, 241);"&gt;&lt;span&gt;8.46%&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="35"&gt;&lt;span&gt;11&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="9"&gt;&lt;span&gt;12&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="184"&gt;&lt;span&gt;三星显示器公司&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="60"&gt;&lt;span&gt;2,023&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="37"&gt;&lt;span&gt;1,838&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(212, 237, 241);"&gt;&lt;span&gt;10.07%&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="35"&gt;&lt;span&gt;12&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="9"&gt;&lt;span&gt;13&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="184"&gt;&lt;span&gt;东芝集团&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="60"&gt;&lt;span&gt;1,954&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="37"&gt;&lt;span&gt;2,627&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(212, 237, 241);"&gt;&lt;span&gt;-25.62%&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="35"&gt;&lt;span&gt;6&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="9"&gt;&lt;span&gt;14&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(225, 225, 225);" width="184"&gt;&lt;span&gt;亚马逊&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="60"&gt;&lt;span&gt;1,662&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="37"&gt;&lt;span&gt;1,136&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(176, 220, 230);"&gt;&lt;span&gt;46.30%&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="35"&gt;&lt;span&gt;26&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="9"&gt;&lt;span&gt;15&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="184"&gt;&lt;span&gt;日本精工-爱普生集团&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="60"&gt;&lt;span&gt;1,647&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="37"&gt;&lt;span&gt;1,620&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(212, 237, 241);"&gt;&lt;span&gt;1.67%&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="35"&gt;&lt;span&gt;16&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="9"&gt;&lt;span&gt;16&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="184"&gt;&lt;span&gt;GE&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="60"&gt;&lt;span&gt;1,646&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="37"&gt;&lt;span&gt;1,757&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(212, 237, 241);"&gt;&lt;span&gt;-6.32%&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="35"&gt;&lt;span&gt;14&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="9"&gt;&lt;span&gt;17&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="184"&gt;&lt;span&gt;富士通&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="60"&gt;&lt;span&gt;1,568&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="37"&gt;&lt;span&gt;1,467&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(212, 237, 241);"&gt;&lt;span&gt;6.88%&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="35"&gt;&lt;span&gt;19&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="9"&gt;&lt;span&gt;18&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="184"&gt;&lt;span&gt;爱立信&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="60"&gt;&lt;span&gt;1,552&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="37"&gt;&lt;span&gt;1,407&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(212, 237, 241);"&gt;&lt;span&gt;10.31%&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="35"&gt;&lt;span&gt;20&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="9"&gt;&lt;span&gt;19&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="184"&gt;&lt;span&gt;福特&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="60"&gt;&lt;span&gt;1,524&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="37"&gt;&lt;span&gt;1,185&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(212, 237, 241);"&gt;&lt;span&gt;28.61%&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="35"&gt;&lt;span&gt;24&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="9"&gt;&lt;span&gt;20&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="184"&gt;&lt;span&gt;丰田&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="60"&gt;&lt;span&gt;1,417&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="37"&gt;&lt;span&gt;1,581&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(212, 237, 241);"&gt;&lt;span&gt;-10.37%&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="35"&gt;&lt;span&gt;17&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="9"&gt;&lt;span&gt;21&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="184"&gt;&lt;span&gt;日本理光&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="60"&gt;&lt;span&gt;1,412&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="37"&gt;&lt;span&gt;1,627&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(212, 237, 241);"&gt;&lt;span&gt;-13.21%&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="35"&gt;&lt;span&gt;15&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="9"&gt;&lt;span&gt;22&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="184"&gt;&lt;span&gt;GlobalFoundries Inc&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="60"&gt;&lt;span&gt;1,407&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="37"&gt;&lt;span&gt;609&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(141, 204, 219);"&gt;&lt;span&gt;131.03%&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="35"&gt;&lt;span&gt;60&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="9"&gt;&lt;span&gt;23&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="184"&gt;&lt;span&gt;松下&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="60"&gt;&lt;span&gt;1,400&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="37"&gt;&lt;span&gt;1,474&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(212, 237, 241);"&gt;&lt;span&gt;-5.02%&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="35"&gt;&lt;span&gt;18&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="9"&gt;&lt;span&gt;24&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="184"&gt;&lt;span&gt;博世&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="60"&gt;&lt;span&gt;1,207&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="37"&gt;&lt;span&gt;1,142&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(212, 237, 241);"&gt;&lt;span&gt;5.69%&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="35"&gt;&lt;span&gt;25&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="9"&gt;&lt;span&gt;25&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 205, 210);" width="184"&gt;&lt;span&gt;华为&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="60"&gt;&lt;span&gt;1,202&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="37"&gt;&lt;span&gt;800&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(176, 220, 230);"&gt;&lt;span&gt;50.25%&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="35"&gt;&lt;span&gt;44&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="9"&gt;&lt;span&gt;26&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="184"&gt;&lt;span&gt;SK 海力士&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="60"&gt;&lt;span&gt;1,125&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="37"&gt;&lt;span&gt;891&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(212, 237, 241);"&gt;&lt;span&gt;26.26%&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="35"&gt;&lt;span&gt;39&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="9"&gt;&lt;span&gt;27&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="184"&gt;&lt;span&gt;通用汽车&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="60"&gt;&lt;span&gt;1,123&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="37"&gt;&lt;span&gt;1,315&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(212, 237, 241);"&gt;&lt;span&gt;-14.60%&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="35"&gt;&lt;span&gt;21&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="9"&gt;&lt;span&gt;28&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="184"&gt;&lt;span&gt;飞利浦&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="60"&gt;&lt;span&gt;1,069&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="37"&gt;&lt;span&gt;923&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(212, 237, 241);"&gt;&lt;span&gt;15.82%&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="35"&gt;&lt;span&gt;37&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="9"&gt;&lt;span&gt;29&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="184"&gt;&lt;span&gt;半导体能源研究所（日本）&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="60"&gt;&lt;span&gt;1,054&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="37"&gt;&lt;span&gt;1,129&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(212, 237, 241);"&gt;&lt;span&gt;-6.64%&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="35"&gt;&lt;span&gt;27&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="9"&gt;&lt;span&gt;30&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="184"&gt;&lt;span&gt;波音&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="60"&gt;&lt;span&gt;1,053&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="37"&gt;&lt;span&gt;976&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(212, 237, 241);"&gt;&lt;span&gt;7.89%&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="35"&gt;&lt;span&gt;34&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="9"&gt;&lt;span&gt;31&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="184"&gt;&lt;span&gt;现代汽车&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="60"&gt;&lt;span&gt;1,035&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="37"&gt;&lt;span&gt;744&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(176, 220, 230);"&gt;&lt;span&gt;39.11%&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="35"&gt;&lt;span&gt;50&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="9"&gt;&lt;span&gt;32&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="184"&gt;&lt;span&gt;三菱电机&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="60"&gt;&lt;span&gt;1,016&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="37"&gt;&lt;span&gt;896&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(212, 237, 241);"&gt;&lt;span&gt;13.39%&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="35"&gt;&lt;span&gt;38&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="9"&gt;&lt;span&gt;33&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="184"&gt;&lt;span&gt;西门子&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="60"&gt;&lt;span&gt;984&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="37"&gt;&lt;span&gt;1,011&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(212, 237, 241);"&gt;&lt;span&gt;-2.67%&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="35"&gt;&lt;span&gt;32&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="9"&gt;&lt;span&gt;34&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="184"&gt;&lt;span&gt;美国思科&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="60"&gt;&lt;span&gt;978&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="37"&gt;&lt;span&gt;960&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(212, 237, 241);"&gt;&lt;span&gt;1.88%&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="35"&gt;&lt;span&gt;36&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="9"&gt;&lt;span&gt;35&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="184"&gt;&lt;span&gt;兄弟工业（日本）&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="60"&gt;&lt;span&gt;926&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="37"&gt;&lt;span&gt;1,187&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(212, 237, 241);"&gt;&lt;span&gt;-21.99%&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="35"&gt;&lt;span&gt;23&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="9"&gt;&lt;span&gt;36&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="184"&gt;&lt;span&gt;本田汽车&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="60"&gt;&lt;span&gt;922&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="37"&gt;&lt;span&gt;1,031&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(212, 237, 241);"&gt;&lt;span&gt;-10.57%&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="35"&gt;&lt;span&gt;31&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="9"&gt;&lt;span&gt;37&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="184"&gt;&lt;span&gt;AT&amp;amp;T&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="60"&gt;&lt;span&gt;921&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="37"&gt;&lt;span&gt;885&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(212, 237, 241);"&gt;&lt;span&gt;4.07%&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="35"&gt;&lt;span&gt;40&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="9"&gt;&lt;span&gt;38&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="184"&gt;&lt;span&gt;NEC&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="60"&gt;&lt;span&gt;890&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="37"&gt;&lt;span&gt;792&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(212, 237, 241);"&gt;&lt;span&gt;12.37%&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="35"&gt;&lt;span&gt;45&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="9"&gt;&lt;span&gt;39&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="184"&gt;&lt;span&gt;德州仪器&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="60"&gt;&lt;span&gt;887&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="37"&gt;&lt;span&gt;808&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(212, 237, 241);"&gt;&lt;span&gt;9.78%&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="35"&gt;&lt;span&gt;43&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="9"&gt;&lt;span&gt;40&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 205, 210);" width="184"&gt;&lt;span&gt;京东方&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="60"&gt;&lt;span&gt;870&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="37"&gt;&lt;span&gt;285&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(67, 159, 199);"&gt;&lt;span&gt;205.26%&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="35"&gt;&lt;span&gt;122&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="9"&gt;&lt;span&gt;41&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="184"&gt;&lt;span&gt;美光科技&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="60"&gt;&lt;span&gt;863&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="37"&gt;&lt;span&gt;961&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(212, 237, 241);"&gt;&lt;span&gt;-10.20%&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="35"&gt;&lt;span&gt;35&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="9"&gt;&lt;span&gt;42&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="184"&gt;&lt;span&gt;夏普集团&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="60"&gt;&lt;span&gt;829&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="37"&gt;&lt;span&gt;997&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(212, 237, 241);"&gt;&lt;span&gt;-16.85%&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="35"&gt;&lt;span&gt;33&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="9"&gt;&lt;span&gt;43&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="184"&gt;&lt;span&gt;博通&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="60"&gt;&lt;span&gt;823&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="37"&gt;&lt;span&gt;1,085&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(212, 237, 241);"&gt;&lt;span&gt;-24.15%&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="35"&gt;&lt;span&gt;28&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="9"&gt;&lt;span&gt;44&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(200, 230, 201);" width="184"&gt;&lt;span&gt;鸿海/富士康&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="60"&gt;&lt;span&gt;803&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="37"&gt;&lt;span&gt;1,083&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(212, 237, 241);"&gt;&lt;span&gt;-25.85%&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="35"&gt;&lt;span&gt;29&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="9"&gt;&lt;span&gt;45&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="184"&gt;&lt;span&gt;黑莓&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="60"&gt;&lt;span&gt;771&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="37"&gt;&lt;span&gt;1,071&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(212, 237, 241);"&gt;&lt;span&gt;-28.01%&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="35"&gt;&lt;span&gt;30&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="9"&gt;&lt;span&gt;46&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="184"&gt;&lt;span&gt;日本电装&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="60"&gt;&lt;span&gt;756&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="37"&gt;&lt;span&gt;778&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(212, 237, 241);"&gt;&lt;span&gt;-2.83%&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="35"&gt;&lt;span&gt;46&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="9"&gt;&lt;span&gt;47&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="184"&gt;&lt;span&gt;京瓷&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="60"&gt;&lt;span&gt;742&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="37"&gt;&lt;span&gt;692&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(212, 237, 241);"&gt;&lt;span&gt;7.23%&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="35"&gt;&lt;span&gt;52&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="9"&gt;&lt;span&gt;48&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="184"&gt;&lt;span&gt;富士胶片&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="60"&gt;&lt;span&gt;699&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="37"&gt;&lt;span&gt;747&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(212, 237, 241);"&gt;&lt;span&gt;-6.43%&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="35"&gt;&lt;span&gt;47&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="9"&gt;&lt;span&gt;49&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="184"&gt;&lt;span&gt;诺基亚&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="60"&gt;&lt;span&gt;695&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="37"&gt;&lt;span&gt;400&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(176, 220, 230);"&gt;&lt;span&gt;73.75%&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="35"&gt;&lt;span&gt;88&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="9"&gt;&lt;span&gt;50&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="184"&gt;&lt;span&gt;Honeywell&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="60"&gt;&lt;span&gt;672&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="37"&gt;&lt;span&gt;746&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(212, 237, 241);"&gt;&lt;span&gt;-9.92%&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" width="35"&gt;&lt;span&gt;48&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;注：绿色为中国台湾的公司、红色为中国大陆公司&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心报道，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 10 Jan 2017 12:09:13 +0800</pubDate>
    </item>
    <item>
      <title>学界 | 新论文提出玩扑克人工智能DeepStack：已达职业玩家水平</title>
      <link>http://www.iwgc.cn/link/4275485</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自arxiv.org&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;当地时间 1 月 11 日，在宾夕法尼亚州匹兹堡的 Rivers 赌场，&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722085&amp;amp;idx=5&amp;amp;sn=6628c3a29d6cccfe1f56e2a6f39678ca&amp;amp;chksm=871b0b5bb06c824d587b32c60e9f76e34faf8b8f7811ad2f1738da44b1cdf5068967a555b13e&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722085&amp;amp;idx=5&amp;amp;sn=6628c3a29d6cccfe1f56e2a6f39678ca&amp;amp;chksm=871b0b5bb06c824d587b32c60e9f76e34faf8b8f7811ad2f1738da44b1cdf5068967a555b13e&amp;amp;scene=21#wechat_redirect"&gt;由卡耐基梅隆大学（CMU）开发的名为 Libratus 的人工智能系统将与人类顶级职业德州扑克玩家进行 20 万美元的比赛&lt;/a&gt;。然而 CMU 并不是唯一一个在研究如何让人工智能学习玩扑克牌的地方，近日，加拿大阿尔伯塔大学、捷克布拉格查理大学和捷克理工大学的研究者联合发表了一篇论文，表示其人工智能已经在无限制扑克（No-Limit Poker）游戏上达到了专家级的水平。点击阅读原文可下载该论文。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;摘要&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;近些年来，人工智能领域出现了很多突破，其中游戏往往被用作重要的里程碑。过去实现那些成功的游戏的一个常见的特征是它们都涉及到玩家之间的信息对称，即所有的玩家都获取了相同的信息。然而和游戏相比，这种完美信息（perfect information）的性质在真实世界问题中却少见得多。扑克是一个典型的不完美信息（imperfect information）游戏，而且其一直以来都是人工智能领域内的一个难题。在这篇论文中，我们介绍了 DeepStack，这是一种用于扑克这样的不完美信息环境的新算法。它结合了回归推理来处理信息不对称性，还结合了分解（decomposition）来将计算集中到相关的决策上，以及一种形式的关于任意牌的直觉——该直觉可以使用深度学习进行自我玩牌而自动学习到。在一项涉及到数十位参与者和 44000 手扑克的研究中，DeepStack 成为了世界上第一个在一对一无限制德州扑克（heads-up no-limit Texas hold'em）上击败了职业扑克玩家的计算机程序。此外，我们还表明：和已经被人亲睐了十多年的抽象范式（abstraction paradigm）相比，这种方法能够极大地减少最糟糕情况的 exploitability 值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;DeepStack&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;DeepStack 是一种可用于一个很大类别的序列不完美信息博弈（sequential imperfect information games）的通用算法。为了明晰这个算法，我们将会在 HUNL 游戏中描述其运算。一个扑克游戏的状态可以被分成玩家的私有信息（两张牌面朝下的手牌）和公共状态（包括牌面朝上的牌和玩家采取的下注动作序列）。游戏中的公开状态的可能序列构成一个公开树（public tree），其中每一个公开状态都有一个相关的公开子树（public subtree）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9rD6KzMuKBaJJEmtibaiciaXJlD3YKFjUxnJQj5Rnn8BPvgXFACSUoz8icib6pawcK81K4SC1sTqyXQKg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 1：HUNL 中公开树的一部分。红色和天蓝色的边表示玩家动作。绿色边表示公开的公共牌。带有筹码的叶节点表示游戏结束，其中，如果一个玩家根据之前的动作和玩家手牌的联合分布而弃牌或做出决定，那么收益就可能是固定的。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9rD6KzMuKBaJJEmtibaiciaXJpLdGA2E72HFWAfpviaS8yrsXHic5hjzPWMmOhltEPq68iaQPAnleQbKZw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 2：DeepStack 架构概览（见 a）。对于每一个公开状态，DeepStack 都要重新计算它需要的动作，这会用到一个深度有限的向前预测——其中子树值（subtree value）会通过一个训练好的深度神经网络 Neural net（见 b）来计算，该深度神经网络 Neural net 是比赛前通过随机生成的扑克情境（见 c）来训练的。图 2 是由专业图形设计师设计，和图 3 的风格类似。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9rD6KzMuKBaJJEmtibaiciaXJ4S0XzibNQB8LI0XsC1yibcEKdPum4nbrZhuBxTiagjCNRJj9syMSmODTg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 3:深度反事实价值网络（Deep counterfactual value networks）。该网络的输入包括底池大小、公共牌、手牌范围（player ranges），这些首先会被处理成 bucket ranges。来自这 7 层全连接隐藏层的输出还要经过后处理（post-processed），从而保证该值（values）满足零和约束（zero-sum constraint），然后这些值又会回过来被映射为 hand counterfactual values。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 10 Jan 2017 12:09:13 +0800</pubDate>
    </item>
    <item>
      <title>新的一年，机器之心开启全球招聘模式</title>
      <link>http://www.iwgc.cn/link/4275486</link>
      <description>&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器之心是国内领先的前沿科技媒体和产业服务平台，关注人工智能、机器人和神经认知科学，坚持为从业者提供高质量内容和多项产业服务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在媒体业务方面，机器之心最早在微信公众号平台开始运营，目前已经覆盖了微信、今日头条、百家号、网易、腾讯内容开放平台等多个大型内容平台，并运营着自己的官方网站。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在媒体之外，机器之心还将依托联想之星Comet Labs的全球资源平台为人工智能领域的参与者提供各项产业服务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为生产更多的高质量内容，提供更好的产业服务，我们需要更多的小伙伴加入进来！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;国内&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;线下活动产品经理（2 名）&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;工作职责：&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="list-style-type: decimal;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;负责公司活动运营产品的整体规划，功能设计和推进执行；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;结合活动参与者数据进行调研分析，提取用户需求，进行活动产品创新；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;配合其他部门，策划微信端、H5、视频等不同形式的线上活动并执行；&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;负责各类产品活动推动和协调沟通，推进达成共同目标；&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;定期监控分析活动数据，对产品、流程、活动效果的进行持续改进。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;岗位要求：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="list-style-type: decimal;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;本科及以上学历，至少 2 年互联网公司活动策划经验；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;创新能力强，敢于突破，脑洞大，能迅速结合现有资源，产生新的策略并推动实施；&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;有线上营销、活动类策划经验或移动端活动产品成功案例者加分。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;出色的执行和沟通能力。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;工作地点：北京&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;分析师（1-2 名）&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;工作职责：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="list-style-type: decimal;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;跟踪人工智能和前沿科技领域技术，挖掘具有价值的信息点；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;常规独立撰写人工智能及相关领域应用分析，产业解读、行业分析等内容；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;协助其他部门完成非常规重要选题和项目的执行。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;岗位要求&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="list-style-type: decimal;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;出色的英文听力、阅读和写作能力；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;有独立的选题和操作能力；有迅速学习和掌握某个新行业的方法与能力。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;对人工智能技术、应用及产业有较全面的理解。对人工智能和前沿科技充满兴趣和热情，拥有迅速掌握某个特定行业或领域的学习能力；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;计算机科学或其他人工智能相关领域理工科专业毕业或在读者优先；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;极强的自主性、执行力和责任感，可以保证长期稳定地进行工作。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;工作地点：北京&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;记者（2 名）&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;工作职责：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="list-style-type: decimal;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;负责人工智能和前沿技术领域的常规内容生产，撰写人物故事和产业报道；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;挖掘国内外人工智能领域的优秀创业公司并进行报道；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;对国内外人工智能领域的创业者、公司高管、行业专家、科研专家进行深度专访；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;针对公司及产品发布会的内容迅速撰写稿件。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;岗位要求：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="list-style-type: decimal;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;优秀的写作能力，能够驾驭特写、人物故事、常规报道和资讯等各类内容形式；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;有独立的选题策划和操作能力；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;对前沿科技充满兴趣和热情，拥有迅速掌握某个特定行业或领域的学习能力；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;对内容有品味，文字功底深厚，执行力强；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;1-2 年科技媒体从业经历，能够适应新媒体和创业公司的工作节奏，有良好的职业精神和团队意识。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;工作地点：北京&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;全职编译（1-2 名）&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;工作职责：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="list-style-type: decimal;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;编译、校对英文文章；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;撰写技术、产品、公司和行业相关文章，撰写分析报告。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;岗位要求：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="list-style-type: decimal;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;卓越的英语翻译能力；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;英语或计算机相关专业毕业者优先；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;对前沿技术有一定了解和热情。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;工作地点：北京&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;新媒体运营（1 名）&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;工作职责：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="list-style-type: decimal;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;负责公司内容产品线上微信、微博、知乎、今日头条网站等渠道的运营；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;负责上述渠道推广效果分析和经验总结，建立有效运营手段；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;配合线下活动运营进行策划执行工作；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;配合内容团队进行选题策划和对外推广；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;负责用户、专家和行业微信群的运维管理。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;岗位要求：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="list-style-type: decimal;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;1-2 年新媒体运营相关经验，具备一定的文字功底，有线下活动组织和策划经验者优先；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;熟悉微信后台操作，有多渠道沟通经验者优先；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;善于沟通交流，有一定抗压和创新能力，强责任心和高执行力。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;工作地点：北京&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;编辑（2 名）&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;工作职责：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="list-style-type: decimal;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;负责人工智能和前沿技术领域的常规内容生产和新闻整合；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;独立策划相关选题并迅速成稿；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;对既定材料进行编辑并成稿。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;岗位要求：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="list-style-type: decimal;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;优秀的写作能力，能够驾驭多种写作风格；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;对前沿科技充满兴趣和热情，拥有迅速掌握某个特定行业或领域的学习能力；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;对内容有品味，文字功底深厚，执行力强；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;对热点有一定的敏感度，能快速处理整合和梳理类的稿件；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;工作地点：北京&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;商务总监（1 名）&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;工作职责：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="list-style-type: decimal;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;负责公司特定行业客户的商务合作推动与对接，维护与建设积极的客户关系；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;参与制定公司的商务目标、原则、计划和战略，建立完善公司的商务体系及相关制度；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;负责重大业务商务谈判的策略制定和执行以及合同的签订；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;负责拓展新的业务渠道，拓展特定行业的典型大客户，并跟踪协调执行。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;岗位要求：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="list-style-type: decimal;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;3 年以上工作经验；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;良好的沟通、协调和商务谈判能力；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;具有较强的业务开拓能力、市场洞察力和行业分析能力；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;有较强责任感和抗压能力。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;工作地点：北京&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有意者请将简历发送至：hr@jiqizhixin.com，或添加微信 JuveAlex，zhaoyunfeng1984&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;海外&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;兼职分析师（技术方向）&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;工作职责：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="list-style-type: decimal;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;跟踪人工智能和前沿科技领域技术，挖掘具有价值的信息点&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;常规独立撰写人工智能及相关领域技术解读、技术分析，技术应用解读等知识产品&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;协助其他部门完成非常规重要选题和项目的执行&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;岗位要求：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="list-style-type: decimal;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;出色的英文听力、阅读和写作能力&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;有独立的选题和操作能力&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;对人工智能技术、应用及产业有较全面的理解。对人工智能和前沿科技充满兴趣和热情，拥有迅速掌握某个特定行业或领域的学习能力&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;计算机科学/工程、数据科学、神经科学、量子物理或其他人工智能相关领域理工科专业背景&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;极强的自主性、执行力和责任感，可以保证长期稳定地进行工作&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;工作类型&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：兼职&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;工作地点&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：美国、加拿大、英国、瑞士、德国、新加坡、香港、台湾、日本、以色列、澳洲、南非&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;兼职分析师（产业方向）&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;工作职责：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="list-style-type: decimal;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;跟踪人工智能和前沿科技领域技术，挖掘具有价值的信息点&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;常规独立撰写人工智能及相关领域应用分析，产业解读、行业分析等知识产品&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;协助其他部门完成非常规重要选题和项目的执行&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;岗位要求：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="list-style-type: decimal;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;出色的英文听力、阅读和写作能力&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;有独立的选题和操作能力&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;对人工智能技术、应用及产业有较全面的理解。对人工智能和前沿科技充满兴趣和热情，拥有迅速掌握某个特定行业或领域的学习能力&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;计算机科学或其他人工智能相关领域理工科专业毕业或在读&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;极强的自主性、执行力和责任感，可以保证长期稳定地进行工作&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;工作类型&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：兼职&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;工作地点&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：美国、加拿大、英国、瑞士、德国、新加坡、香港、台湾、日本、以色列、澳洲、南非&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;请将简历发送至 chain.zhang@jiqizhixin.com，或添加微信 chainzhang 注明：技术分析师（海外）&lt;/span&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 10 Jan 2017 12:09:13 +0800</pubDate>
    </item>
  </channel>
</rss>
