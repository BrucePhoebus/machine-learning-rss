<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>盘点 | 2016年不可错过的21个深度学习视频、教程和课程</title>
      <link>http://www.iwgc.cn/link/3911931</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自 Analyticsvidhya&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;几年之前，深度学习还是机器学习里面一个不太受人关注的领域。随着神经网络和大数据的出现，很多复杂任务的实现已经成为可能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2009 年时，深度学习还是一个新兴领域，只有少数人认为这是一个值得研究的领域。但很快，这个领域就得到了很大的发展，目前已经被应用到很多的领域当中，例如：语音识别、图像识别、在一个数据集当中寻找模式、照片中的事物分类、字符文本生成、自动驾驶汽车等等。因此，了解深度学习及其概念是非常重要的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了能够让你用一种更简单的方式学习深度学习，Analytics Vidhya 网站发表了一篇文章梳理了一些 2016 年关于深度学习的视频、教材和课程。其中包括深度学习暑期班、峰会和会议等的一些讲座和教材。希望你能够从中受益。（注：这篇文章中的视频都在 YouTube 上，你也许需要专门的工具才能查看。）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;目标读者&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不管是深度学些方面初学者、中等水平的学者还是专家，你都可以找到适合您观看的视频。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这篇文章也会根据读者的学习程度对学习材料进行分别罗列。如果你是一名初学者或者是中等水平的学者，建议你可以从第一部分开始。如果你想掌握完全掌握深度学习，那这篇文章就是你首先要阅读的不二之选。在开始对深度学习的探索之前，你首先要制作一个日程表。我相信在几周后，至少你可以建立你在深度学习中的第一个模型。对于深度学习方面的专家来说，深度学习的高级教程部分有很多精彩的视频可以帮助你加强现有的知识。你也可以看看 5 分钟的初学者视频来巩固基础知识。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于所有深度学习/数据科学方面的爱好者，你们一定会喜欢深度学习的应用和其他部分对例子的介绍。其中包括谷歌 DeepMind 的一些视频，你可以从中学习如何使用深度学习绘画，并且深度学习是如何让自动驾驶汽车成为现实的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外还有一小部分是关于强化学习的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1.深度学习初学者教程&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;深度学习简化版&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;2016 斯坦福湾区深度学习学校 Day 1&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;2016 斯坦福湾区深度学习学校 Day 2&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;深度学习教程&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;使用神经网络的深度学习及 TensorFlow 介绍&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;机器学习神经网络&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;TensorFlow 入门&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;神经网络&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;改变所有事物的神经网络&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;TensorFlow 广度&amp;amp;深度学习——机器学习&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;深度学习简介&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;深度学习揭秘&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2.深度学习高级&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;2016 年蒙特利尔深度学习暑期班&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;深度学习教程——高级&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;深度学习实践-语音识别与其他&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3.深度学习的应用&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;详解谷歌 DeepMind&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;自动驾驶汽车和深度学习 GPU-英伟达&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;九个有趣的深度学习应用&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;深度学习程序绘画&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4.强化学习&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;简介强化学习函数逼近-教程&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;深度强化地形学习&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;深度学习初学者教程&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1.深度学习简化版&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;时长：系列包含27个视频&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;链接：https://www.youtube.com/watch?list=PLjJh1vlSEYgvGod9wWiydumYl8hOXixNu&amp;amp;v=b99UVkWzYTQ&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果复杂的专业术语让你在学习深度学习时感到困难重重，那么这个教程就是给你的福利。这是深度学习及其基本概念的一个简化版教程。在这个教程里你将会了解到神经网络、深度网络、深度信念网络（DBN）和卷积神经网络。H2O.ai 和这个教程将会让你对深度学习有基本的理解。同时你也会了解到不同的模型，以及在不同情况下该选择何种模型和选择这种模型的理由。之后你将会学到深度学习在不同使用情形下的实际操作经验，包括支持构建你自己深度网络的平台、深度学习可以调用的库。这个简化教程里没有任何数学计算或者编程相关的内容，是为初学者了解深度学习基本思想而制作的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2.2016 斯坦福湾区深度学习学校 Day 1&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;时长：10 小时 33 分&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;链接：https://www.youtube.com/watch?v=eyovmAtoUx0&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;正如吴恩达（Andrew Ng）无比精确的描述，深度学习正在改变业界的发展布局，同时大量有意思的深度学习应用正涌现出来。这个视频是 2016 湾区深度学习学校第一天的内容展示。视频覆盖到的内容有： 1）Hugo Larochelle 讲授前馈神经网络介绍（Introduction on Feedforward Neural Network）；2）Andrej Karpathy 讲授用于计算机视觉的深度学习（Deep Learning for Computer Vision）；3）Richard Socher 讲授用于自然语言处理（NLP）的深度学习（Deep Learning for NLP）；4）Sherry Moore 讲授 TensorFlow 教程（TensorFlow Tutorial）；5）Ruslan Salakhutdinov 讲授深度无监督学习基础（Foundations of Deep Unsupervised Learning）；6）吴恩达讲授深度学习应用基本要点（Nuts and Bolts of Applying Deep Learning）。这些深度学习方面的专家都会以一个易于理解的方式讲解深度学习潜在的概念原理，让你对深度学习有基础理解。同时他们也会分享各自讲授主题相关的应用实例。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3.2016 斯坦福湾区深度学习学校 Day 2&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;时长：10 小时 33 分&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;链接：https://www.youtube.com/watch?v=9dXiAecyJrY&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是湾区深度学习学校的第二天讲授内容视频。视频覆盖到的内容有：1）John Schulman 讲授深度强化学习基础（Foundation of Deep Reinforcement Learning）；2）Pascal Lamblin 讲授 Theano 介绍：一个供模型构建和训练使用的极速 Python 库（Introduction to Theano: A Fast Python library for Modelling &amp;amp; Training）；3）Adam Coates 和 Vinay Rao 讲授语音识别和深度学习（Speech Recognition and Deep Learning）；4）Alex Wiltschko 讲授 Torch 和 Autograd 下的机器学习（Machine Learning with Torch &amp;amp; Autograd）；5）Quoc Le 讲授深度学习实现 Seq2Seq（Sequence to Sequence by Deep Learning）；5）Yoshua Bengio 讲授深度学习的基础和挑战（Foundation and Challenges of Deep Learning）。这些深度学习的应用者都是经常被检索到的深度学习应用专家，他们同时也为大型公司服务，如：谷歌大脑、Twitter 等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4. 教程：深度学习&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;时长：2 小时 29 分&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;链接：https://www.youtube.com/watch?v=CLSy5WlaWKc&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这个深度学习的视频教程里，Yoshua Bengio 和 Yann LeCun 讲解了近年来深度学习所取得的重大突破。在这个领域深耕 30 年之后，Yoshua 和 Yann 带来深度学习如何掀起机器学习和人工智能领域变革浪潮的深度解读。在本视频教程里，你将会学到深度学习是如何实现多层计算模型对数据表征的学习。这些方法大幅提升了语音识别、视觉对象识别、目标检测以及基因学等领域的相关研究。这个教程将会覆盖到深度学习基础，并讨论深度学习的不同应用和目前遇到的挑战。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;5. 使用神经网络的深度学习及 TensorFlow 介绍&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;时长：无&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;链接：https://www.youtube.com/watch?v=oYbVFhK_olY&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你一直在想知道神经网络是如何工作的，为什么最近它有这么多的关注。本教程将介绍神经网络，你将了解神经网络如何能够创建具有巨大数据集的强大模型。并理解神经网络的结构以及每个输入层如何组合在一起以生成输出。这只是完整教程中的第一个视频，第二部分是 TensorFlow 基础。如果需要了解怎样建立神经网络模型，请继续学习第三部分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;6. 机器学习神经网络&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;时长：无&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;链接：https://www.youtube.com/watch?v=cbeTc-Urqak&amp;amp;list=PLoRl3Ht4JOcdU872GhiYWf6jwrk_SNhz9&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;研究人工神经网络的主要思想是理解神经元的并行计算方式及其自适应连接。本课程将由多伦多大学教授 Geoffrey Hinton 讲授，你将学习到神经网络和机器学习将如何带来技术革命。本课程包括感知器、反向传播、卷积神经网络、循环神经网络、梯度下降和超参数贝叶斯优化等主题。这是深度学习最好的课程之一，如果你是深度学习爱好者，那就一定不能错过它。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;7.TensorFlow 入门&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;时长：系列，共 7 个视频&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;链接：https://www.youtube.com/watch?v=QfNvhPx5Px8&amp;amp;index=5&amp;amp;list=PL2-dafEMk2A7EEME489DsI468AB0wQsMV&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现如今最流行的机器学习框架之一就是 TensorFlow，虽然它主要用于进行机器学习和深度神经网络研究，但由于其多功能性，TensorFlow 也可用于各种应用。在这个有趣的 TensorFlow 教程中，您将学习在 Python 中用不到 40 行代码进行构建手写数字图像的分类器。您还将学习如何在 TensorFlow 中生成音乐，什么是 Tensorboard，怎样构建一个神经网络还有使用 TensorFlow 相比其他深度学习库的利弊。这个关于 TensorFlow 的简短教程是深度学习新手必须要了解的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;8. 神经网络&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;时长：系列，共 6 个视频&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;链接 https://www.youtube.com/watch?list=PL2-dafEMk2A5BoX3KyKu6ti5_Pytp91sk&amp;amp;v=h3l4qz76JhQ&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工神经网络能够学习，而且它们需要训练。基本上需要 3 步来构建机器学习模型，即构建、训练、测试。一旦模型构建起来，它就可以在模式识别上训练得越来越好。在这些短短 5 分钟视频里，你将学习建立神经网络、自动编码器和循环神经网络，每段视频的代码也可在 YouTube 上的描述中找到。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;9. 改变所有事物的神经网络&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;时长：14 分 16 秒&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;链接：https://www.youtube.com/watch?v=py5byOOHZM8&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;卷积神经网络是深度神经网络和核卷积（kernel convolution）的结合。这个视频解释了卷积神经网络是如何为精确图像分类带来巨大改变的。如果你是深度学习爱好者，但对神经网络了解甚少，不妨看看这个视频。它向你展示了深度学习是如何用来估计房价的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;10.TensorFlow 广度&amp;amp;深度学习——机器学习&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;时长：3 分 24 秒&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;链接：https://www.youtube.com/watch?v=Xmw9SWJ0L50&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;广度和深度学习（wide and deep learning）结合了用于训练广度线性模型和深度神经网络的记忆（memorization）和归纳（generalization）。在这个视频中，你可以了解到在 TensorFlow 当中对这种简单易用的 API 的应用。它们在大规模的回归分析和分类中所涉及到的稀疏输入问题当中非常实用，例如推荐系统、搜索和排名问题。通过这个 视频来探索广度和深度学习的可能性吧。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;11. 深度学习简介&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;时长：11 分钟&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;链接：https://www.youtube.com/watch?v=l42lr8AlrHk&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个视频对深度学习进行了数学解释。它将带你了解机器是如何找到不同变量的分组并做出具体决策的。如果你是一个数学爱好者，你将会学到如何调整模型参数。视频简单地解释了神经网络对不同输入内容的反应。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;12. 深度学习揭秘&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;时长：22 分钟&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;链接：https://www.youtube.com/watch?v=Q9Z20HCPnww&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是一个深度学习的初级教程。其中，你将了解深度学习是如何帮助机器识别特征的。同时，视频用简单的语言解释了神经网络。首先，视频介绍了神经元的工作方式，随后进一步解释神经元之间的交流方式。随后是深度学习在现实世界中的应用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;深度学习-高级&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1.2016 年蒙特利尔深度学习暑期班&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;时长：无&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;链接：https://www.youtube.com/watch?list=PL5bqIc6XopCbb-FvnHmD1neVlQKwGzQyR&amp;amp;v=xK-bzjIQkmM&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;蒙特利尔深度学习暑期班出现了很多来自不同年龄段的专家与从业人员。该教程是要教人们对深度学习与神经网络有基础的理解。里面有 Yoshua Bengio 教授循环神经网络，Surya Ganguli 教授理论神经科学与深度学习理论，Sumit Chopra 教授 reasoning summit 和 attention，Jeff Dean 讲解 TensorFlow 大规模机器学习，Ruslan Salakhutdinov 讲解学习深度生成式模型，Ryan Olson 讲解深度学习的 GPU 编程，还有其他很多的讲演。想要了解更多内容可参考机器之心之前发表的文章：&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718578&amp;amp;idx=1&amp;amp;sn=ff7d748b149e7952c9fa3b53cefd5afc&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718578&amp;amp;idx=1&amp;amp;sn=ff7d748b149e7952c9fa3b53cefd5afc&amp;amp;scene=21#wechat_redirect"&gt;重磅 | Yoshua Bengio 深度学习暑期班学习总结，35 个授课视频全部开放（附观看地址）&lt;/a&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2. 深度学习教程——高级&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;时长：1 小时 36 分钟&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;链接：https://www.youtube.com/watch?v=DlNR1MrK4qE&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在过去几年中，图像分类、分割、物体检测的技术因深度学习有了极大的进展。该教程会带你了解深度学习的进展，主要集中于使用 Theano 和 Lasagne 的计算机视觉与图像处理。此外，演讲者也讨论了一些重要的技巧，比如用更少的训练数据进行审核等。为了理解视频中的概念，需要一定的代数、微积分与机器学习基础。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3. 深度学习实践-语音识别与其他&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;时长：34 分 46 秒&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;链接：https://www.youtube.com/watch?v=LFDU2GX4AqM&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;吴恩达的地位无需再多做介绍了，大家都知道他对深度学习的贡献。他是世界上首先认识到深度学习潜力的几个人之一。在这个与吴恩达的一对一对话中，他分享了在深度学习上研究的经验、深度学习所到来的科技进展。他提到大数据的进展正在颠覆如今的产业。观看此视频可以了解更多关于深度学习与数据科学的未来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;深度学习的应用&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1. 详解谷歌 DeepMind&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;时长：13 分 44 秒&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;链接：https://www.youtube.com/watch?v=TnUYcTuZJpM&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;AlphaGo 击败围棋前世界冠军李世乭是一个历史时刻。每当机器超越人类的时候，就会引发一轮新的社会进步。谷歌 DeepMind 宣称自己将下一代人工智能和目标带到研发这样的系统活动中：聪明到可以自主采取行动。这个视频解释了 DeepMind 的起源，以及它能为人工智能领域带来的什么样的变革。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2. 自动驾驶汽车和深度学习 GPU-英伟达&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;时长：1 小时 7 分&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;链接：https://www.youtube.com/watch?v=KkpxA5rXjmA&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;英伟达 CEO 黄仁勋分享了深度学习与研究如何改变自动驾驶汽车的面貌，如何让其成真的故事。他开局引介了世界上第一个由英伟达设计的、用于自动驾驶汽车的人工智能超级计算机。还解释了深度神经网络和大数据如何被用于解决 GPU 的问题。深度学习和人工智能如何变不可能为可能？这个视频会让你脑洞大开。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3. 九个超酷的深度学习应用&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;时长：4 分 43 秒&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;链接：https://www.youtube.com/watch?v=Bui3DWs02h4&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;想知道深度学习和机器学习在现实生活中有哪些有趣应用？这个视频会给你答案。你会看到一些让你脑洞大开的应用，比如，不同化学结构的毒性检测，大型图像有丝分裂检测，序列生成，计算机程序自己怎么玩游戏等等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4. 深度学习程序学绘画&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;时长：4 分钟&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;链接：https://www.youtube.com/watch?v=UGAzi1QBVEg&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能神经网络受到了人类大脑的启发，旨在研究神经元之间的连接。在这个视频中，我们会看到几个深度学习应用。但是，神经网络的艺术创作是深度学习最神奇的应用形式。在这个视频里，你将学到如何使用深度学习绘画，或使用人工神经网络对世界名画进行再创作。用户要做的就是输入一张照片，再提供一张目标图片供系统学习（其艺术风格）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;强化学习&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1. 简介强化学习函数逼近-教程&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;时长：2 小时 18 分钟&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;链接：https://www.youtube.com/watch?v=ggqnxyjaKe4&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;强化学习是由机器学习研究社区开发出的用来做最佳序列决策的技术。该教程提供了对底层形式问题（马尔科夫决策过程）及其核心解决方法的透彻理解，后者包括动态编程、蒙特卡洛方法和时序差分学习。该视频注重这些方法如何与参数逼近（parametric approximation）结合从而找到因过大而难以解决问题的好的逼近解决方案。演讲者也会带你了解函数逼近、eligibility traces 和 off-policy 学习的最新进展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2. 深度强化地形学习&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;时长：3 分钟&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;链接：https://www.youtube.com/watch?v=wBrwN4dS-DA&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本视频描述了深度学习与强化学习的结合，这种结合被认为有助于解决许多极端困难的任务。谷歌 DeepMind 使用深度学习建立了一个能够玩 Atari 游戏的系统，其表现超过了人类。视频展示了一个有趣的应用就是使用深度强化学习教会处在某些地带中的动物绘制周围环境，避免障碍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;结语&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这就是 2016 年的人工智能视频盘点，我们收集了一系列关于深度学习与强化学习的视频。根据年份、浏览量与关联度挑选出最后名单。目前在网络上有着丰富的内容资源，而我们提供的是其中最引人关注的一部分。相信这个列表中肯定会有适合你的内容。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文链接：https://www.analyticsvidhya.com/blog/2016/12/21-deep-learning-videos-tutorials-courses-on-youtube-from-2016/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 14 Dec 2016 14:01:13 +0800</pubDate>
    </item>
    <item>
      <title>资源 | 斯坦福大学NLP组开放神经机器翻译代码库（附论文）</title>
      <link>http://www.iwgc.cn/link/3911932</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自斯坦福&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀、杜夏德&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;近日，斯坦福大学自然语言处理组（Stanford NLP）发布了一篇文章，总结了该研究组在神经机器翻译（NMT）上的研究信息。在这篇文章中，他们还放出了在多种翻译任务上（比如英德翻译和英语-捷克语翻译）实现了当前最佳结果的代码库（codebase）。除此之外，「为了鼓励再现和增加透明」，他们还放出了他们用于训练模型的处理过的数据以及可以通过他们的代码库使用的预训练好的模型。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;发布地址：http://nlp.stanford.edu/projects/nmt/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9DFP58EX6ymYTnLpicibkXOrOBVuMwuHto1wKEUWPRfLbPzw2YA0iaqnZeC4GmD5qyQ2Y8zu24U416w/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;参与成员：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Christopher D. Manning（斯坦福大学计算机科学和语言学教授）&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Minh-Thang Luong（斯坦福博士，Google Brain 研究科学家）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Abigail See（斯坦福大学计算机科学在读博士）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Hieu Pham&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;代码库&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;对于混合 NMT（hybrid NMT），请使用这个代码库并且引用：&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;代码库：https://github.com/lmthang/nmt.hybrid&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;论文：使用混合词-字符模型实现开放词汇神经机器翻译（Achieving Open Vocabulary Neural Machine Translation with Hybrid Word-Character Models）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：几乎之前所有的神经机器翻译（NMT）使用的词汇都受限，随后可能用一个方法来修补未知的单词。本论文展示了一个全新的能实现开放词汇神经机器翻译（open vocabulary NMT）的词-字符解决方法。我们建立了一个混合的系统，能够实现大部分的词级（word level）翻译，并可查阅罕见词的字母组成。我们字符级的循环神经网络能计算源词的表征，并能在需要时恢复未知的目标词。这种混合的方法还有一个双重优点是，与基于字符的网络相比，它更快且更容易训练；同时，它不像基于词的模型那样会产生未知的词。在 WMT' 15 英语-捷克语的翻译任务上，这种混合方法还实现了一个额外的+ 2.1 BLEU 分的提升——超过已经能处理未知单词的模型 11.4 BLEU 分。我们的最佳系统在这个任务上达到了新的最佳表现：20.7 BLEU 分。我们证明了我们的字符模型不仅能成功地学习生成形式很好的捷克语词（这是一种词汇复杂高度屈折的语言），还能为英语源词建立了正确的表征。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;对于通用的基于注意的 NMT（general attention-based NMT），请引用以下论文：&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;代码库：https://github.com/lmthang/nmt.hybrid&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;论文：实现基于注意的神经机器翻译的有效方法（Effective Approaches to Attention-based Neural Machine Translation）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：最近一种在翻译过程中通过选择性地集中关注部分源句子的注意机制被用于提升神经机器翻译（NMT）结果。然而，探索用于基于注意的神经机器翻译（NMT）的有用架构的研究还不多。本论文探讨了两种简单有效的注意机制类别：一种能顾及到所有源词的全局方法，以及一种只能一次查看源词的一个子集的局部方法。我们证明了在英语-德语/德语-英语 WMT 翻译任务上，这两种方法都是有效的。使用局部注意方法，相比于已经结合了 dropout 等技术的非注意系统，我们的系统增长了 5.0 BLEU 点。我们的组合模型使用了不同的注意架构，在 WNT'15 英语-德语的翻译任务中，实现了目前最好的结果：25.9 BLEU 点；比现有的基于 NMT 和 一个 n-gram reranker 的最佳系统提升了 1.0 BLEU 点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;对于剪枝 NMT（pruning NMT），请引用以下论文（如果你对代码有兴趣，请联系我们）：&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;论文：通过剪枝的神经机器翻译的压缩（Compression of Neural Machine Translation Models via Pruning）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：和其它许多深度学习领域一样，神经机器翻译（NMT）常会遭遇过度参数化（over-parameterization）的问题，这会导致需要大量的存储空间。这篇论文检查了三种简单的基于幅度的（magnitude-based）用来压缩 NMT 模型的剪枝方案，即 class-blind、class-uniform 和 class-distribution；它们的不同之处在于剪枝的阈值为 NMT 架构中不同的权重类所计算的方式。我们表明权重剪枝（weight pruning）可作为一种用于当前最佳 NMT 压缩技术。我们表明一个带有超过 2 亿个参数的 NMT 模型可以在仅有非常少量的性能损失的情况下被剪去 40%——这个结果是在 WMT'14 英语-德语翻译任务上得到的。这揭示了 NMT 架构中的冗余的分布。我们的主要结果是：通过再训练（retraining），我们可以使用 80% 剪枝的模型来恢复甚至超越原有的表现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;预处理的数据&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;WMT'15 英语-捷克语数据（大）&lt;/span&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;训练集（包含 1580 万个句子对）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;英语训练集（train.en）：http://nlp.stanford.edu/projects/nmt/data/wmt15.en-cs/train.en&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;捷克语训练集（train.cs）：http://nlp.stanford.edu/projects/nmt/data/wmt15.en-cs/train.cs&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;测试集：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;newstest2013.en：http://nlp.stanford.edu/projects/nmt/data/wmt15.en-cs/newstest2013.en&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;newstest2013.cs：http://nlp.stanford.edu/projects/nmt/data/wmt15.en-cs/newstest2013.cs&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;newstest2014.en：http://nlp.stanford.edu/projects/nmt/data/wmt15.en-cs/newstest2014.en&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;newstest2014.cs：http://nlp.stanford.edu/projects/nmt/data/wmt15.en-cs/newstest2014.cs&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;newstest2015.en：http://nlp.stanford.edu/projects/nmt/data/wmt15.en-cs/newstest2015.en&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;newstest2015.cs：http://nlp.stanford.edu/projects/nmt/data/wmt15.en-cs/newstest2015.cs&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;词汇库（最常见的词）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;vocab.1K.en：http://nlp.stanford.edu/projects/nmt/data/wmt15.en-cs/vocab.1K.en&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;vocab.1K.cs：http://nlp.stanford.edu/projects/nmt/data/wmt15.en-cs/vocab.1K.cs&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;vocab.10K.en：http://nlp.stanford.edu/projects/nmt/data/wmt15.en-cs/vocab.10K.en&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;vocab.10K.cs：http://nlp.stanford.edu/projects/nmt/data/wmt15.en-cs/vocab.10K.cs&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;vocab.20K.en：http://nlp.stanford.edu/projects/nmt/data/wmt15.en-cs/vocab.20K.en&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;vocab.20K.cs：http://nlp.stanford.edu/projects/nmt/data/wmt15.en-cs/vocab.20K.cs&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;vocab.50K.en：http://nlp.stanford.edu/projects/nmt/data/wmt15.en-cs/vocab.50K.en&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;vocab.50K.cs：http://nlp.stanford.edu/projects/nmt/data/wmt15.en-cs/vocab.50K.cs&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;词典（从对齐的数据中提取出来的，dict.en-cs）：http://nlp.stanford.edu/projects/nmt/data/wmt15.en-cs/dict.en-cs&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;字符库：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;vocab.char.200.en (http://nlp.stanford.edu/projects/nmt/data/wmt15.en-cs/vocab.char.200.en)&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;vocab.char.200.cs (http://nlp.stanford.edu/projects/nmt/data/wmt15.en-cs/vocab.char.200.cs)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;注：我们的论文《Achieving Open Vocabulary Neural Machine Translation with Hybrid Word-Character Models》中使用了这个数据集。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;WMT'14 英语-德语数据（中）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;训练集（包含 450 万个句子对）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;英语训练集（train.en）：http://nlp.stanford.edu/projects/nmt/data/wmt14.en-de/train.en&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;德语训练集：（train.de）：http://nlp.stanford.edu/projects/nmt/data/wmt14.en-de/train.de&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;测试集：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;newstest2012.en：http://nlp.stanford.edu/projects/nmt/data/wmt14.en-de/newstest2012.en&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;newstest2012.de：http://nlp.stanford.edu/projects/nmt/data/wmt14.en-de/newstest2012.de&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;newstest2013.en：http://nlp.stanford.edu/projects/nmt/data/wmt14.en-de/newstest2013.en&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;newstest2013.de：http://nlp.stanford.edu/projects/nmt/data/wmt14.en-de/newstest2013.de&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;newstest2014.en：http://nlp.stanford.edu/projects/nmt/data/wmt14.en-de/newstest2014.en&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;newstest2014.de：http://nlp.stanford.edu/projects/nmt/data/wmt14.en-de/newstest2014.de&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;newstest2015.en：http://nlp.stanford.edu/projects/nmt/data/wmt14.en-de/newstest2015.en&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;newstest2015.de：http://nlp.stanford.edu/projects/nmt/data/wmt14.en-de/newstest2015.de&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;词汇库（最常见的 5 万个词）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;vocab.50K.en (http://nlp.stanford.edu/projects/nmt/data/wmt14.en-de/vocab.50K.en)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;vocab.50K.de (http://nlp.stanford.edu/projects/nmt/data/wmt14.en-de/vocab.50K.de)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;词典（从对齐的数据中提取出来的，dict.en-de）：http://nlp.stanford.edu/projects/nmt/data/wmt14.en-de/dict.en-de&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;注：我们的论文《Effective Approaches to Attention-based Neural Machine Translation》中使用了这个数据集。另外，因为历史上的原因，我们对合成词（compound words）做了拆分。比如，rich-text format --&amp;gt; rich ##AT##-##AT## text format.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;IWSLT'15 英语-越南语数据（小）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;训练集（包含 13.3 万个句子对）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;英语训练集（train.en）：http://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/train.en&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;越南语训练集（train.vi）：http://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/train.vi&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;测试集：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;tst2012.en：http://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/tst2012.en&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;tst2012.vi：http://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/tst2012.vi&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;tst2013.en：http://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/tst2013.en &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;tst2013.vi：http://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/tst2013.vi&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;词汇库（最常见的 5 万个词）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;vocab.en：http://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/vocab.en&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;vocab.vi：http://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/vocab.vi&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;词典（从对齐的数据中提取出来的，dict.en-vi）：http://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/dict.en-vi&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;注：我们的论文《Stanford Neural Machine Translation Systems for Spoken Language Domains》中使用了这个数据集&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;预训练的模型&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们放出了预训练好的模型，可以直接通过我们的 Matlab 代码使用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;注：要使用这些模型，必须要一个 GPU。如果想要这些模型在 CPU 上可用，请考虑使用这个脚本：https://github.com/stanfordnlp/nmt/blob/master/code/misc/model2cpu.m&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;WMT'15 英语-捷克语混合模型（hybrid models）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;我们训练了 4 个具有同样架构的模型（全局注意、双线性形式、dropout、两层字符级模型）:&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;1. Model 1：http://nlp.stanford.edu/projects/nmt/models/wmt15.en-cs/model1.mat&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;2. Model 2 ：http://nlp.stanford.edu/projects/nmt/models/wmt15.en-cs/model2.mat&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;3. Model 3：http://nlp.stanford.edu/projects/nmt/models/wmt15.en-cs/model3.mat&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;4. Model 4：http://nlp.stanford.edu/projects/nmt/models/wmt15.en-cs/model4.mat&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;WMT'14 英语到德语基于注意的模型（attention-based models）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;1. 全局注意、点积：http://nlp.stanford.edu/projects/nmt/models/wmt14.en-de/globalAttn-dotProduct.mat&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;2. 全局注意、点积、dropout：http://nlp.stanford.edu/projects/nmt/models/wmt14.en-de/globalAttn-dotProduct-dropout.mat&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;3. 全局注意、双线性形式、dropout：http://nlp.stanford.edu/projects/nmt/models/wmt14.en-de/globalAttn-bilinear-dropout.mat&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;4. 局部注意（单调）、双线性形式：http://nlp.stanford.edu/projects/nmt/models/wmt14.en-de/localAttnMono-bilinear.mat&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;5. 局部注意（单调）、双线性形式、dropout：http://nlp.stanford.edu/projects/nmt/models/wmt14.en-de/localAttnMono-bilinear-dropout.mat&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;6. 局部注意（预测）、点积、dropout：http://nlp.stanford.edu/projects/nmt/models/wmt14.en-de/localAttnPred-dotProduct-dropout.mat&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;7. 局部注意（预测）、双线性形式：http://nlp.stanford.edu/projects/nmt/models/wmt14.en-de/localAttnPred-bilinear.mat&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;8. 局部注意（预测）、双线性形式、dropout：http://nlp.stanford.edu/projects/nmt/models/wmt14.en-de/localAttnPred-bilinear-dropout.mat&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;IWSLT'15 英语-越南语基于注意的模型（attention-based models）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;1. 全局注意、双线性形式、dropout：http://nlp.stanford.edu/projects/nmt/models/iwslt15.en-vi/globalAttn-bilinear-dropout.mat&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;2. 全局注意、concatenate ：http://nlp.stanford.edu/projects/nmt/models/iwslt15.en-vi/globalAttn-concat.mat&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;3. 局部注意（预测）、点积、dropout：http://nlp.stanford.edu/projects/nmt/models/iwslt15.en-vi/localAttnMono-dotProduct-dropout.mat&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;4. 局部注意（单调）、双线性形式、dropout：http://nlp.stanford.edu/projects/nmt/models/iwslt15.en-vi/localAttnMono-bilinear-dropout.mat&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;5. 局部注意（单调）、双线性形式：http://nlp.stanford.edu/projects/nmt/models/iwslt15.en-vi/localAttnMono-bilinear.mat&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;6. 局部注意（单调）、concatenate、dropout ：http://nlp.stanford.edu/projects/nmt/models/iwslt15.en-vi/localAttnMono-concat-dropout.mat&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;7. 局部注意（预测）、点积、dropout：http://nlp.stanford.edu/projects/nmt/models/iwslt15.en-vi/localAttnPred-dotProduct-dropout.mat&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;8. 局部注意（预测）、双线性形式：http://nlp.stanford.edu/projects/nmt/models/iwslt15.en-vi/localAttnPred-bilinear.mat&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;9. 局部注意（预测）、concatenate、dropout：http://nlp.stanford.edu/projects/nmt/models/iwslt15.en-vi/localAttnPred-concat-dropout.mat&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;联系信息&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有任何评论或疑问，可联系第一作者：lmthang@stanford.edu&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 14 Dec 2016 14:01:13 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 谷歌无人车项目成为独立公司Waymo，新车或2017年商用</title>
      <link>http://www.iwgc.cn/link/3911933</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自TechCrunch&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李泽南、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;谷歌母公司 Alphabet 本周二宣布，旗下的无人驾驶汽车项目正式从 X 中独立出来，成为一家新公司 Waymo，这个名字源于它的使命：「出行新方式（a new way forward in mobility）」。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们现在是 Alphabet 旗下的独立公司了，」Waymo 首任 CEO John Krafcik 在旧金山举行的新闻发布会上说道。他在发布会上同时透露，Waymo 团队去年已经在奥斯汀的公共道路上实现了第一次全无人驾驶，谷歌的无人驾驶汽车不同于其他公司的传统设计，它没有方向盘，没有控制踏板，已经可以在「真实交通情况」的城市街道上正常运行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;iframe class="video_iframe" data-vidtype="1" style="   z-index:1; " height="375" width="500" frameborder="0" data-src="https://v.qq.com/iframe/preview.html?width=500&amp;amp;height=375&amp;amp;auto=0&amp;amp;vid=d03555jcdn4" allowfullscreen=""&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2015 年 10 月 20 日是有史以来第一次，全无人驾驶汽车开上了公共道路，Waymo 首席工程师 Nathaniel Fairfield 的一位盲人朋友 Steve Mahan 成了无人驾驶汽车首次独立出行的乘客。Mahan 曾经乘坐谷歌原型车参与过多次实验，但在此之前每一次出行都有警察开道。这一次，无人驾驶汽车完全不受保护，并且在行驶过程中进行了四向停车，通过人行道并穿越了奥斯丁的一些狭窄的街道。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在新闻发布会上，Mahan 把乘坐无人驾驶汽车比作宇航员飞行，自己是「1 号驾驶员」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最近，谷歌无人驾驶汽车战略发生了变化，前现代北美负责人 Krafcik 被邀请成为新成立的 Waymo CEO。这一步暗示谷歌的无人驾驶汽车已经从实验室走向了实用阶段，公司正在为其商业化，积极布局。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9DFP58EX6ymYTnLpicibkXOricTwykvY2aMSVLibIP735KicjsZyiaUJ6j8lEblWrWEkibWiazdB0f2gpOMg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们一直在强调，谷歌无人车已经在公共道路上行驶了 200 万英里，」Krafcik 在发布会上说道。「现在我们的实验车正在进行最后一百万英里的测试，而且我还没有提到我们在模拟器上的里程数。我们的车辆已经载着谷歌员工和一些客人在山景城、奥斯丁和菲尼克斯进行了超过一万次旅行。」&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌在过去一年不断扩大自己的无人驾驶汽车项目，雇用了更多的工程师，同时将其设在美国的测试中心从两个增加至四个。自 2009 年以来，谷歌的自动驾驶原型车在道路上累积行驶了相当于 300 年的驾驶时间，而在过去一年时间里，谷歌自动驾驶汽车的模拟行驶里程也已超过 10 亿英里。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Google X 的自动驾驶汽车项目组（现在的 Waymo），已经在驾驶和测试上花费了大量时间，也取得了很多成绩。尽管如此，Waymo 的自动驾驶技术主管 Dmitri Dolgov 仍然表示，目前还有很多工作需要完成，包括构建更详细的地图，让汽车行驶更加平稳，让自动导航系统能够适应极端恶劣天气，如大雨和雪天等等。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;至于 Waymo 的未来发展，Krafcik 表示，目前公司看到了很多潜在机会。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9DFP58EX6ymYTnLpicibkXOrBMjDia5ibeUP5Fic3leSImt1FhDI09AB5yf7BVoALHeUSpB3P2go8Ko8A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;新公司 Waymo 的 logo&lt;/span&gt;&lt;/em&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们可以想象，未来，在拼车、交通运输、货运、物流甚至个人用车、公共交通和解决最后一英里问题方面，自动驾驶技术都将占据重要地位，」Krafcik 说道。「在所有这些领域，自动驾驶汽车都具有很大潜力。」Krafcik 同时强调，新公司将专注于技术，不一定会自己制造汽车。这种策略符合分析师们之前的报告——谷歌会倾向于和汽车厂商合作制造新产品，而不是自己建厂。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们是一家自动驾驶汽车科技公司，」Krafcik 强调。「我们非常清楚自己不是汽车厂商，尽管这说起来有点拗口，但这就是我们的理念：我们要做的不是更好的汽车，而是更好地驾驶方式。」&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9DFP58EX6ymYTnLpicibkXOrqHafNAEWUCs2hD4z7UIl0I7WsONiaq0Medjc3ulzmVqjrhVcPicicwAkQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Krafcik 表示，Waymo 目前正处在「构建阶段」，正在将下一代自动驾驶系统装进克莱斯勒 Pacifica 中。在今年早些时候，谷歌曾经宣布与菲亚特-克莱斯勒合作，在 100 辆车上试验自动驾驶装置，这是谷歌第一次宣布与汽车厂商进行合作。目前，这一计划中的车辆正在进行道路测试。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌在自动驾驶上的潜在竞争对手 Uber 也正在进行自己的计划，后者正在积极寻求与汽车制造厂商合作，目前 Uber 的自动驾驶系统已经在福特与沃尔沃等品牌的汽车上进行了测试。而一些汽车厂商，如大众和通用，也正在发展自己的自动驾驶技术。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;据彭博社昨日的报道，Alphabet 的最新自动驾驶公司将与克莱斯勒合作部署拼车服务，或许在 2017 年底，我们就将看到半自动驾驶的克莱斯勒 Pacifica 上路载客。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;就像之前提到的，谷歌先前曾宣布基于菲亚特-克莱斯勒 Pacifica 平台制造 100 台原型自动驾驶汽车，但这次新计划的规模将更广，对汽车要求更高。菲亚特也计划在即将到来的拉斯维加斯 CES 展上公布一款全电驱动的 Pacifica 汽车，这会成为与谷歌合作的要素，因为电动汽车更符合未来自动驾驶按需服务的实际需求。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;作为 Alphabet 旗下的又一个独立公司，Waymo 肯定不能再忽视商业上的进展与表现了，这家公司下一步的动向将非常值得关注。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文链接：https://techcrunch.com/2016/12/13/googles-self-driving-car-unit-spins-out-as-waymo/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 14 Dec 2016 14:01:13 +0800</pubDate>
    </item>
    <item>
      <title>前沿 | 纽约大学发现新的言语工作记忆结构，可用于人工智能研究</title>
      <link>http://www.iwgc.cn/link/3911934</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自NYU&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：杜夏德、李泽南、曹瑞&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;纽约大学的一项新研究发现，在言语工作记忆中，我们用来存储和处理信息的神经结构比我们之前所理解的要复杂的多，这种结构的发现会影响到人工智能系统的建立。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人类用于言语工作记忆（vWM）中储存和处理信息的神经结构要比以前我们所理解的更加复杂，纽约大学的研究者们刚刚在Nature Neuroscience上发表了他们的新研究，这一发现对人工智能系统例如语音翻译工具的构建有着重要的意义。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这项研究认为，在言语记忆工作中的信息处理过程包含了大脑中两个不同的网络，而不是以往认为的一个，这个发现可能会对打造语音翻译工具这样的人工智能系统产生影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;「&lt;/span&gt;我们的研究结果显示，当人类在思维中处理使用语音和语言信息时，至少有两个大脑网络是活跃的，&lt;span&gt;」&lt;/span&gt;纽约大学神经科学副教授Bijan Pesaran说，他是这篇论文的作者之一。&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;过去的研究强调了单一的「中央执行机构」 如何监督存储在记忆工作的操作（manipulation）信息。据Pesaran的观察，这是一个非常重要的假设，因为目前的复制人类语音的人工智能系统通常都假设言语工作记忆中的计算都由一个单独的中心网络负责。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;「&lt;/span&gt;人工智能需要尽量模仿人类， &lt;span&gt;」&lt;/span&gt;Pesaran说。&lt;span&gt;「&lt;/span&gt;通过更好的理解人脑的运行机制，我们可以提出更多提升人工智能系统的方法。我们的研究暗示了我们需要构建带有多个工作记忆网络的人工智能系统。&lt;span&gt;」&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本文的第一作者是Greg Cogan，他曾经是纽约大学的一名博士后，现在来到了杜克大学；其他共同作者包括纽约大学Langone医学中心综合性癫痫中心主任Orrin Devinsky教授，纽约大学Langone神经外科系副教授Dan Friedman，和纽约大学神经系统助理教授Lucia Melloni。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该研究旨在对这种思考、规划和创造性推理至关重要的工作记忆形式进行研究，并涉及了记忆中的语言形式转换，以及形成语言所需的信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;研究人员分析了耐药性颠病人类患者的治疗过程，对病人们的大脑活动进行了监测。具体来说，他们探究了这些病人在倾听和说话时大脑中的深层神经活动，尝试解答为什么病人的反应会出现一定时间的延迟。科学家们在实验中要求研究对象使用研究人员提供的规则，将他们听到的语音用自己的话复述出来。例如，有时患者会被告知要原文复述他们听到的内容，而在其他时间，研究人员指示患者听到声音后用不同的方式复述内容。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;研究人员将每一位患者大脑当中的神经活动进行了解码，患者采用了研究人员提供的规则，将他们听到的东西转化为所需要说的话。结果表明抑制工作记忆当中的操纵信息涉及到了两个大脑网络的运作。一个网络解码了指导患者表达的原则，也就是规则网络（the rule network）。令人惊讶的是，规则网络没有解码出怎样将听到的内容转化为表达内容的细节。使用这个规则将声音转化为言语的过程仅需要一秒钟，这就是转化网络（transformation network）。这个网络当中的活动能够跟踪输入（听到的内容）是如何渐渐转化为输出（所说的话）的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;研究者同时表示，将你听到的一种语言进行翻译，再用另外一种语言表达出来，其中涉及到了一些类似的抽象原则。具有言语工作记忆（vWM）障碍的人学习一门新语言很困难。现代的智能机器在学习语言当中也存在着一些问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Pesaran说：「创造更加智能系统的唯一途径就是对人类大脑和思维的运作进行更加全面的了解。」「人类工作记忆障碍的诊断和治疗涉及到心理学鉴定。以此类推，机器心理学可能也会在将来的某一天对机器智能障碍的诊断和治疗有帮助。这项研究对这种独特的人类智能、言语工作记忆形式进行了研究，提出了让人工智能进一步发展的新方向。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;论文：Manipulating stored phonological input during verbal working memory&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：&lt;/span&gt;&lt;span&gt;言语工作记忆（vWM）包含了音系感知输入中的存储和操纵信息。对 vWM 目前最具影响力的理论认为，全部处理任务由一个中央执行机构执行，信息存储则由两个互相联系的系统执行：语音输出是由可获取基于声音信息的音位输入缓冲器和和发音排练系统来控制的。然而，目前仍没有理论解释语言在大脑中的神经活动是如何被编码处理的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在本研究中，我们在受试者处理语音时的脑神经活动中成功读取了 vWM 内容。正如我们所猜测的，我们找到了包含语音感觉和发音运动表示的存储系统。然而，意料之外的是，我们发现这一处理过程不是由单一的中央处理机构进行，而是由两个任务不同的系统协作完成的。因此，我们认为，中央执行机构是由多个用于处理语音输入和形成语音输出的 vWM 子系统组成的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 14 Dec 2016 14:01:13 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 微软开放小娜：推出两款开发工具提供软硬件支持</title>
      <link>http://www.iwgc.cn/link/3911935</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自微软&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：曹瑞、蒋思源&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;目前正处于人工智能科技革命的开端。所有人工智能的力量都通过个人数字助手的界面成为我们每个人的延伸。要实现这样的前景，需要有一整个社区来对其进行投资，并且能够分享其所带来的益处。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今天，微软让我们看到了 Cortana 的下一步新发展。这家科技巨头今天宣布推出全新的 Cortana Skills Kit 和 Cortana Devices SDK。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9DFP58EX6ymYTnLpicibkXOrCfvY192D3qibqDFmjendLN9F6LfeuQsOpz4eJg25IjaJ5PsX0LicEETw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Cortana Skills Kit 是为了让开发者能够接触到 1.45 亿 Cortana 用户，帮助用户跨平台地发现、参与和完成事务，这些平台包括：Windows、Android、iOS、Xbox 和 Cortana 驱动的新型设备。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Cortana Devices SDK 能够让原始设备制造商（OEM）和原始设计制造商（ODM）创造出新一代的智能个人设备：不管是没有屏幕还是在大屏幕上、不管家里还是在外面使用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前开发者和制造商已经可以注册了：https://developer.microsoft.com/zh-cn/windows/projects/campaigns/cortana-skills-kit，微软表示结束 private preview 之后就会推送更新。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Cortana Skills Kit 预览&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Cortana Skills Kit 能够让开发者利用微软 bot 开发框架（Microsoft Bot Framework）帮助开发 bot 并将其发布出来作为 Cortana 的一项新技能，还能让开发者整合网页服务作为新技能以及将他们已有的 Alexa 技能的代码用于创建 Coratna 技能。它可以在用户询问时将用户与所需的技能连接起来，并能在适当的背景下主动向用户提供服务。另外，Cortana Skills Kit 还能够帮助开发者通过 Cortana 了解用户偏好，并基于用户给予的权限为他们带来个性化的用户体验。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在今天旧金山的发布会上，微软向大家展示了一些早期的开发伙伴是如何利用 Cortana Skills Kit 的。微软表示该工具包将在 2017 年 2 月向更多人开放。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Knowmail 将人工智能应用于电子邮件过载问题，其使用 Bot Framework 构建了一个 bot，并已发布到了 Cortana。他们的智能解决方案可用于 Outlook 和 Office 365，它会学习你使用电子邮件的习惯，以便在你有空的时候提供需要优先处理的电子邮件。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一家登录 Cortana 平台的金融服务公司是 Capital One，微软展示了它是如何通过 Cortana 的免手持自然语言交谈，使用在声音技术上的已有投入来使客户有效地管理他们的资金。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;全球最大的在线旅游公司 Expedia 利用 Microsoft Bot Framework 研发了一款 Skype 平台的 bot，这个 bot 作为一种新的 Cortana 技能，能够帮助用户预订酒店。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;家政服务平台 TalkLocal 公司的 Cortana 技能可以让人们使用自然语言找到当地的服务提供商。比如说，你对 Cortana 说:「小娜，我家的天花板漏水了，情况紧急。」这时候 TalkLocal 公司就会帮助你找一位合适的水暖工。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;设备制造商的 Cortana 设备 SDK&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们相信个人助手需要在你日常生活中提供帮助，不论你是在家、在工作还是其它任何地方都能有效地给予帮助。我们称之为 Cortana 是和你「无约束（unbound）」地绑定的，而不是与任何一个平台或设备绑定的。这就是 Cortana 支持 Windows 10、Android、iOS、Xbox 和多种移动平台的原因。我们上周发布的 Windows 10 Creators Update 的 IoT Core 版将嵌入 Cortana，这将为物联网设备提供有力的支持。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;实现这个目标的下一步正是 Cortana Devices SDK，这将 Cortana 提供给了所有 OEM 和 ODM，让他们可以在所有平台上构建更智能的设备。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该 SDK 也将带领 Cortana 继续完成在任何地方任何时间提高个人生产力的承诺，它将提供与 Skype、电子邮件、日历和列表集成的实时的、双向的语音通信功能，这一切都将使得生活无处不简单。当然 Cortana 也会加载一些专业化技能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们正在与一系列行业和硬件开发商进行合作，包括一些激动人心的互联汽车项目。该 SDK 是为多样化而设计的，支持通过开源协议和软件库跨 Windows IoT、Linux 和 Android 等许多平台。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Cortana Devices SDK 目前正在进行 private preview，它将在 2017 年向更多人开放。如果你是 OEM 或 ODM 并有兴趣在你的设备中嵌入 Cortana，可以填写这个表格获得 Cortana Devices SDK 的最新消息和（可能的）早期预览版使用权限：http://cortanadevicesdksignup.azurewebsites.net&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文链接：https://blogs.windows.com/buildingapps/2016/12/13/cortana-skills-kit-cortana-devices-sdk-announcement/#GIHy5kf5QIzIxc9q.97&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 14 Dec 2016 14:01:13 +0800</pubDate>
    </item>
    <item>
      <title>深度｜NIPS 2016最全盘点：主题详解、前沿论文及下载资源（附会场趣闻）</title>
      <link>http://www.iwgc.cn/link/3896801</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心编辑&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;参与：微胖、杜夏德、吴攀、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;当地时间 12 月 5 日到 10 日，机器学习和计算神经科学的国际顶级会议第 30 届神经信息处理系统大会（NIPS 2016）在西班牙巴塞罗那举行。在这次会议上，人工智能和机器学习领域的研究者为我们呈现了这一领域的研究前沿，其中包括：学习去学习（learning-to -learn）、生成对抗网络（GAN）、用于三维导航的强化学习、RNN 等等；与此同时，一些资深研究者也带来了一些极具看点和启发价值的演讲和教程，其中包括：《&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721081&amp;amp;idx=1&amp;amp;sn=d557968703d4af879b5cf6461069dacd&amp;amp;chksm=871b0f47b06c865185865fcd5ef92af7726e84ae9e689b7ced9986a08c9fe3113df296a8469a&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721081&amp;amp;idx=1&amp;amp;sn=d557968703d4af879b5cf6461069dacd&amp;amp;chksm=871b0f47b06c865185865fcd5ef92af7726e84ae9e689b7ced9986a08c9fe3113df296a8469a&amp;amp;scene=21#wechat_redirect"&gt;吴恩达 NIPS 2016 演讲现场直击:如何使用深度学习开发人工智能应用?&lt;/a&gt;》、《&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721284&amp;amp;idx=1&amp;amp;sn=427e7f45c8253ab22a3960978409f5d1&amp;amp;chksm=871b087ab06c816c424ad03810be3e1b3aa9d6e99a5f325047796f110d178a07736f667d1a10&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721284&amp;amp;idx=1&amp;amp;sn=427e7f45c8253ab22a3960978409f5d1&amp;amp;chksm=871b087ab06c816c424ad03810be3e1b3aa9d6e99a5f325047796f110d178a07736f667d1a10&amp;amp;scene=21#wechat_redirect"&gt;GAN 之父 NIPS 2016 演讲现场直击：全方位解读生成对抗网络的原理及未来&lt;/a&gt;》和《&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721325&amp;amp;idx=4&amp;amp;sn=d570f04d737d09c1b1cebd962755af3f&amp;amp;chksm=871b0853b06c8145985f8c2c5ac7445118f18ce35532c0389b0e5ec24a7a1c4b841fe81280de&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721325&amp;amp;idx=4&amp;amp;sn=d570f04d737d09c1b1cebd962755af3f&amp;amp;chksm=871b0853b06c8145985f8c2c5ac7445118f18ce35532c0389b0e5ec24a7a1c4b841fe81280de&amp;amp;scene=21#wechat_redirect"&gt;Bengio 和 LeCun 在 NIPS 2016 上的演讲&lt;/a&gt;》等等。现在，NIPS 2016 已经顺利闭幕，与会的各路研究者开始在网上分享他们的参会经历和体验，以及总结相关的研究进展。机器之心在此对网络上多篇 NIPS 相关的总结文章进行了综合梳理。&lt;/span&gt;&lt;/em&gt;&lt;br/&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;NIPS 2016 主题概览&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;首先，开放性&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。两年前，亚马逊开始公开他们的研究，现在他们是这场大会的主要参与者。今年，根据 NIPS 与会者的一系列推文，苹果人工智能研究主管、卡内基梅隆大学教授 Russ Salakhutdinov 在会议上表示，「苹果的人工智能研究团队将公开发表他们的研究成果并更多地参与到广阔的学术圈中去。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;其次，模拟&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。Yann LeCun 在开幕 Keynote 演讲中提到，「模拟是减轻强化学习的高样本复杂性的好策略。」同时，从科学方法论上看，对于反事实的场景，模拟的环境是数据集的模拟，因此它们可以使用共同的指标，允许重复性实验和创新民主化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;模拟器不是什么新东西，过去人们对它也曾有过热情和悲观的浪潮，也有很多陷阱，基本上可以归结为过度训练模拟器（包括微观上得到一个不好的模型和宏观上将科学注意力集中在不相关的问题上。）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有两点需要注意。第一个是 Jason Williams 建议的，相对的性能结论可以接受，但是，绝对的性能结论值得怀疑。第二点是 Antoine Bordes 主张使用一个可实现的模拟问题的集合（也就是对于多种问题，哪一种完美的性能是可能实现的，哪一种能表现出明显不同的能力，目前还不知道什么方法可以解决所有问题。）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;毫无疑问，模拟器正在激增。比如 GVGAI，CommAI-env，Project Malmo 以及会议期间公布的 OpenAI Universe 以及 DeepMind Lab。除了理模拟器外，以下几个主题今年也讨论的也比较多。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;生成对抗网络。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;今年，来自其他会议（比如 ICLR）的 GAN 研究热席卷了本次大会。这与模拟有关，尽管更多的是面向减轻样本复杂性而非科学方法论主题。人们正在弄清楚 GAN 能实现如此好的优化能力的奇怪原因，这些原因应该能在近期内帮助深度学习获得一些有趣的改进（不止于许多漂亮照片）。对于 NLU 任务来说，这有点不幸，因为目前从 GAN 生成文本的成熟性并不如声音、图像的生成.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;可解释模型&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。在产业领域，有关能够自己进行解释的模型的想法很流行，不过，我还是第一次看到可解释性得到 NIPS 的很大关注。即将到来的欧盟管制显然加剧了人们对这个主题的兴趣。不过还有其他原因：比如，如果表征更加可以解释的话，那么，表征学习近期取得的进展就能让科学查询更加容易。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;NIPS 2016 研究主题详解&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这部分的要点总结来自 Insight Data Science 程序开发主任兼研究科学家 Ross Fadely 的系列文章。机器之心进行了适当的删减和整理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;第一天亮点：生成对抗网络&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大会第一天主要是参会研究者们带来的一系列研究主题上的最近进展 tutorial。其中这三个是比较引人关注的：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先是来自哥伦比亚大学的统计与计算机科学教授 David Blei 深入介绍了变分推理（Variational Inference）研究的最近的多项进展。最有影响的还是重新参数化（reparameterization）的技巧，该技巧可以通过随机变量实现反向传播，同时也推动了变自编码器上最新进展。吴恩达带来的则是偏向应用的指导，他介绍了自己在业界打造学习系统的最佳实践经历。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一个演讲是法国国家信息与自动化研究所的 Francis Bach 带来的（非）凸优化上的最新进展，其中如 SAGA（https://arxiv.org/abs/1407.0202）这样的算法轻松打败了 BFGS（Broyden–Fletcher–Goldfarb–Shanno algorithm）。一旦有了通用的库，这种算法可以在数据科学和应用机器学习领域发挥巨大的作用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;明星级的 Tutorial 当属 Ian Goodfellow 的 GAN（生成对抗网络）。Yann LeCun 大会开幕主题演讲上将 GAN 评价为「近 20 年来（该领域）最令人兴奋的思想。」Goodfellow 清晰地描绘了 GAN 的概念及其目前的进展，还有一些小技巧和提示以及当前的研究前沿。他提到的更多的是使用 GAN 训练的最新进展。最后，Goodfellow 以 Plug &amp;amp; Play Generative Networks（即插即用生成网络）的最新进展惊艳全场，该技术首次产生了逼真的计算机生成图像（如下图）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8qAJibEDtyiaJvlXTAh04GAcynBPehCpTaibw1JsrISo4SKfjK9NpDsgRnZe9G4Yf4HY6zwHLUCYqjA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;从 Plug &amp;amp; Play Generative Networks（Nguyen et al. 2016）上面的图像分别是赤足鹬鸟、蚂蚁和修道院，看上去比最近的其他几张生成图都要真实&amp;nbsp;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一天还有一个大亮点：共 170 多个展位的海报展示。Yoshua Bengio、 Diederik Kingma 和 David Blei 也站在人群中给大家讲解他们的展示。这些展示的质量也非常高，以下是其中的亮点：&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Exponential Family Embeddings：一种多类型数据的全新强大的嵌入（embedding）技术，带来了用户使用嵌入技术评估数据的可能性。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Unsupervised Learning for Physical Interaction through Video Prediction：利用机器人的推动动作的数据来规划可能的未来。传统的代理（agent）学习算法严重依赖于监督，而这种类型的方法或许是机器人和类似领域未来的新方法。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Improving Variational Inference with Inverse Autoregressive Flow ：结合了变分推断的最新进展和自动回归网络（autoregressive network）的一些想法，得出更好的编码模型。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;第二天亮点：平台之战和强化学习&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721081&amp;amp;idx=2&amp;amp;sn=fb1b2ba31d256c08e3c93e813deabc73&amp;amp;chksm=871b0f47b06c86510e447bd4c366d1d5c78bbffe3b92903eff2e8f5a6b2df67f5c440dc822e9&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721081&amp;amp;idx=2&amp;amp;sn=fb1b2ba31d256c08e3c93e813deabc73&amp;amp;chksm=871b0f47b06c86510e447bd4c366d1d5c78bbffe3b92903eff2e8f5a6b2df67f5c440dc822e9&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;DeepMind 宣布开源其强化学习平台 DeepMind Lab&lt;/span&gt;&lt;/a&gt;&lt;span&gt;，旨在提供一种打造丰富模拟环境的手段方法，用于人工智能研究。最受欢迎的通用平台，恐怕要数 OpenAI 的 Gym。几个礼拜前 OpenAI 也公布了 Universe 平台, 旨在提供比 Gym 更灵活、具有扩展性的平台。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8qAJibEDtyiaJvlXTAh04GAcAR5UIyqebz8CNruqV5OWer9qXBnFjUN52ugjHKJicxatoPCJ0tQHalg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在会议的第二天，我们仍然可以看到强化学习和深度学习正在继续进步，这些机器学习技术也已经在更加广泛的应用中得到了使用，这里给出几篇比较亮眼的论文：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;最佳论文&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721198&amp;amp;idx=1&amp;amp;sn=accdd701751ab9678285f3cdf073304f&amp;amp;chksm=871b0fd0b06c86c6fa49bbae856898920e26c4456bc02be42a947d23fe2b593110e911bf54da&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721198&amp;amp;idx=1&amp;amp;sn=accdd701751ab9678285f3cdf073304f&amp;amp;chksm=871b0fd0b06c86c6fa49bbae856898920e26c4456bc02be42a947d23fe2b593110e911bf54da&amp;amp;scene=21#wechat_redirect"&gt; Value Iteration Network&lt;/a&gt; 令人印象深刻：该论文的主要创新在于其模型包含了一个可微分的「规划模块（planning module），这让网络可以做出规划并更好地泛化到其它从未见过的领域。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;两篇推进 RNN 的研究： Sequential Neural Models with Stochastic Layers 以及 Phased LSTMs。前者将 状态空间模型（State Space Model）的想法和 RNN 结合起来，充分利用了两个领域的最好的东西。后者将「time gate」添加到了 LSTM 中，这显著改善了针对长序列数据的优化和表现。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;一个来自亚马逊的团队的论文讨论了针对大型库存的贝叶斯间断需求预测（论文：Bayesian Intermittent Demand Forecasting for Large Inventories）。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;K-means 是许多数据科学应用的核心算法。不过，找到好的聚类中心（cluster centers）常常要依赖良好的初始化。Olivier Bachem 在论文《Fast and Provably Good Seedings for k-Means》中表明，他们可以获得良好的 centroid seeds，速度比当前最佳的算法（k-Means++）快几个数量级。更妙的是，他们还有代码，「pip install kmc2」= g2g。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外，第二天的 poster session 展示了 170 多篇论文，这里选出了 3 篇比较有意思的：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Attend, Infer, Repeat: Fast Scene Understanding with Generative Models 提出了一种极具启发性的理解图像中场景的方法。使用贝叶斯和变分推理（Bayesian and Variational Inference），该论文的作者构建了一个可以无需任何监督就能理解图像中的数字、地址和物体类型的模型。这引起了较大的关注，因为他们的模型可以在训练样本之外的分布上进行推理/推导。当然，该模型确实需要一些特别的需求，但它们也提供了新的有趣的研究探索路径。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;DeepMath—Deep Sequence Models for Premise Selection 提出的深度学习方法可以持续不断突破新的领域。一个来自 Google Research 的研究团队（包括 François Chollet and Geoffrey Irving）展示了世界上第一个使用深度学习进行自动理论证明（automated theorem proving）的案例。这项成果有助于加速系统的正确性证明，并可替代对该领域的专家所设计的特征的需求（其与自然语言有类似但也不同的结构）。它们可以自动选择与推理过程中的当前状态相关的操作运算，这个过程可以被扩展到其它领域，是一个非常激动人心的研究方向。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;我们喜欢稳步前进。词嵌入帮助改变了许多自然语言处理任务，去年《Word Movers Distance》提供一种使用它们的嵌入在不同文档进行摘要的方法。对监督任务（比如，文本分类）而言，这可以更进一步。《Supervised Word Mover’s Distance》提出了可以执行仿射变换（affine transformation）和重新调整权重（re-weightings）的方法来提供分类，实现了有效的当前最佳的表现。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;第三天亮点：机器人、汽车&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第三天出现的一个主题是将深度学习融入应用中，特别是机器人和汽车。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个出色的研究来自 Pulkit Agrawal 和他的团队论文 Learning to Poke by Poking: Experiential Learning of Intuitive Physics。他们使用了几百个小时数据（让机器人通过戳的动作来移动物体获得的）搭建了一个系统，机器人可以四处移动物体即使它从未见过这些物体。系统使用了 CNNs 来观察世界，有两个理解相关物理世界的模型。前向模型（forward model），用来预测一个动作/戳的结果，以及一个能够获取当前状况并将之映射到行动中的逆模型（inverse model）。通过一系列令人信服的视频，很明显，机器人已经学会如何相当普遍地四处移动物体。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8qAJibEDtyiaJvlXTAh04GAcJZ2RcSv2icEHtzcJqzSGZsaWBUzs6nhvGx4rDGF2rXicXfm3nrTFLUfg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外，来自奔驰的机器学习工程师 Michael Beaumier 的同事展示了他们最新的目标识别系统。他们一直在研发一种可以识路面小型物体的系统，而这份成功就是该研究的关键创新之处。将场景分割（在 ImageNet 上训练 CNN）和一些来自立体图像的几何信息结合起来，他们搭建了一个贝叶斯模型来识别 100 米之处大小为 5 厘米的物体。这项有助于让自动驾驶汽车更加可能和安全。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;第四天到第六天亮点：似然推理、Dessert 类比（Dessert analogies）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;过去两年，NIPS 有关注将机器学习和概率推论用于粒子物理学的研讨会，今年继续了这一主题。Kyle Cranmer 做了主旨演讲，讨论了许多机器学习进步改善粒子实验分析的领域，包括前馈神经网络、卷积网络以及生成对抗神经网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8qAJibEDtyiaJvlXTAh04GAcVwYMR5KZMBtKo6fT5A0iaU9QGiaJum4giaHnne5JbnpcVWXDHeAUA92Yw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;CERN 实验中描述的 ATLAS 实验的图解模型。每一个阶段都包括显著知识、分析和/或推理来让实验获得成功。Kyle Cranmer 在这份主旨演讲中讨论了如何处理模型的各种不同部分。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;演讲重点关注这样一个问题：当你想要推理模型参数时，但是不能评估似然函数时，你该做什么。当你有了针对数据的生成模型时，你可以用似然推理方法（比如《Approximate Bayesian Computation》），你可以评估一个模型的似然性，而无需一个明确的似然函数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些技巧和想法是许多无监督和生成模型的技术，目前也是一个极为活跃的研究领域。在其主旨演讲和接下来的讨论中，Cranmer 显然正在萌生这样一种想法：这些似然技巧不再是近似的。我们很兴奋，因为这些想法已经对自编码和对抗模型产生了巨大影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;与前三天一样，最后三天的日程安排大致相同，但依然是满满的干货。下面是大会第 4-6 天的演讲和研讨会精彩总结：&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;来自康奈尔大学计算机系的副教授 Killan Weinberger 探讨了深度极深的卷积网络。其团队论文 Deep Networks with Stochastic Depth 展示了训练过程中的所以抽样深度，是比微软团队 ResNet 大赛获奖研究的更好版本。在讨论中，他展示了他们能在 CIFAR-10 上训练一个 1202 层深的网络，并且获得了比 ResNet 更好的模型。最后他提到了 Densely Connected Convolutional Networks，该网络可实现一层与其下面所有层直接连接，达到了 目前的最佳表现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有一个趋势是张量方法及其应用中的最新进展。周六的张量学习 workshop 上，讨论了卷积网络的深度效率：网络设计中和分析中分层张量分解的使用。这个讨论证明了一个卷积网络和分级张量分解之间的一个等价，让我们对网络配置的空间、深度网络的表现力以及增加层数带来的益处有了更多的理论上的理解。此外还有一个成果是将当前很多技术形式化，并明确了未来的研究方向&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一个趋势，大会上出现了一些对话更加直接，探讨实际建议的 workshop。比如 Soumith Chintala 讨论了《How to train a GAN》和 John Schulman 的《The Nuts and Bolts of Deep Reinforcement Learning Research》展示了分享研究细节对于加速研究过程的重要性。这些东西无法呈现在最终的论文中，所以这样的分享非常好。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们仍然还有一些疑问：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;2016 年，记忆网络取得了巨大进步，却为什么没有变得更加流行？&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;会议上女性研究者的数量从原来的 13% 增长到了 15%，NIPS 和其它会议的多样性该怎样才能达到合理的水平？&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;几乎所有的强化学习研究都围着游戏转。什么时候能走出玩游戏？&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;人工智能技术的日益商业化会如何影响研究？开放的趋势会持续下去吗？&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;其它值得关注的论文&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里所总结的一些值得关注的论文是来自微软云与信息服务实验室首席研究软件开发工程师 Paul Mineiro的个人意见，在介绍这些论文之前，他也建议多看一些其他人所总结的推荐论文。他写道：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;看单个人的总结就够了吗？我可不这么想。对于这次会议上都有那些好论文，我觉得我们需要众包让大家一起推荐。我只是一个人，只有两只脚和两只眼睛；加上所有的论文都会首先出现在 arXiv 上，就算我读过我可能也没注意到那是投递给这个会议的。这让这个推荐列表有些怪异，但聊胜于无。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你觉得有什么论文也值得推荐却没有出现在这个列表中，请及时与我们分享！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;通过对抗训练生成文本（Generating Text via Adversarial Training）、用于带有 Gumbel-softmax 分布的离散元素的序列的 GAN（GANS for Sequences of Discrete Elements with the Gumbel-softmax Distribution）、对话模型的对抗式评估（Adversarial Evaluation of Dialogue Models）。短评：我对模拟和评估对话系统的技术很感兴趣。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;构建像人一样学习和思考的机器（Building Machines That Learn and Think Like People）。短评：这个主题演讲非常好，所以我想要深入了解一下论文。这个演讲探索了人类利用大量先验知识的方式，以及我们可以如何将其整合进我们的系统中；其中一些特定的观察结果为我们带来了一些可以执行的研究方向。（这似乎和对话有关，因为这个研究可能能够解释类似「the blorf flazzed the peezul」这样的无意义陈述的伪可理解性（pseudo-intelligibility）。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;跨许多个数量级学习价值（Learning values across many orders of magnitude）。短评：粗略看这可能是关于优化（optimization）的，但在反事实的背景（counterfactual setups）中，这个问题是很普遍的。我可是很喜欢把规模不变性用作一个有用的先验知识（scale invariance as a useful prior）。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;用于神经结构预测的回报增强最大似然（Reward Augmented Maximum Likelihood for Neural Structured Prediction）短评：这可以被看作是另一种使用世界的模型来转移强化学习的样本复杂性的方法。（比如：如果编辑距离（edit distance）只是该回报的初始模型呢？&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;安全高效的离策略强化学习（Safe and Efficient Off-Policy Reinforcement Learning）。短评：这是一个重要的设置。这种特别的调整让人联想到了之前这一领域提出的估计器（estimator，参阅论文《Learning from Logged Implicit Exploration Data》）；但尽管如此，这还是很有意思。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面这篇论文不是来自 NIPS 2016，但 Mineiro 表示：「我在一次喝咖啡的休息时间发现了它，真的非常赞！」：理解深度学习需要重新思考泛化（Understanding deep learning requires rethinking generalization）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;短评：当像素被重新排列或甚至完全随机时，卷积神经网络也可以理解标准的图像训练集。当然，在这种情况下泛化能力很差，但是这表明：和「局部像素统计组合（local pixel statistics composition）」架构相比，它们并没有人们认为的那样灵活。所以为什么它们的效果那么好呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;NIPS 2016 趣闻&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;LeCun 的蛋糕&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Yann LeCun 以题为《预测学习（Predictive Learning）》的演讲开启了主会议。这是一个高水平的演讲，他认为我们都应该真正多思考一下无监督学习。为了明确他的意思，他又拿出了自己蛋糕的比喻。他展示了一张蛋糕图片，把监督学习和强化学习分别比作是蛋糕的糖霜和樱桃，而无监督学习则就是蛋糕本身。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8qAJibEDtyiaJvlXTAh04GAcWO68JRjibEybbPN42JOblHtAmlH5Su8xIxChoAuO60ic15IXCVITxLIg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这个演讲之后，LeCun 的蛋糕火了！并且开始出现在这一周的其它 NIPS 幻灯片中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;LeCun 的主要观点是：许多我们通常关心的问题都回避了人工智能最需要的重要部分（即蛋糕本身）——（LeCun 认为）无监督学习。在支持这一观点的论据中，最常见的是「大多数数据都没有标签」（所以为了使用这些数据，我们需要无监督学习）和「人类基本上就是靠无监督学习的」。所以如果我们想要实现人工智能的进一步发展，我们真的需要长期努力地思考所谓的「无监督」的意义。LeCun 提出了一个看待无监督学习的新角度，他称之为「预测学习（predictive learning）」。对此他的描述是：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;从任何可用的信息中预测过去、现在和未来的规律的任何部分。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这听起来似乎有点定义不明。不过他还给出了几个预测学习的案例，比如说根据图像的一半预测另一半、以及 GAN 上面的所有工作。不过无监督学习要比监督学习难得多，LeCun 的蛋糕能够火出成效吸引更多人加入吗？让我们拭目以待。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Jürgen Schmidhuber 起波澜&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;LSTM 发明人、深度学习元老 Jürgen Schmidhuber 一直是一个颇有争议的人（参阅《&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720788&amp;amp;idx=2&amp;amp;sn=f71291991911e6949e0302da05ea00c4&amp;amp;chksm=871b0e6ab06c877c7abeb6763763ef870d4419c53fb23830fa611be7432e2a3539943b7aad5f&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720788&amp;amp;idx=2&amp;amp;sn=f71291991911e6949e0302da05ea00c4&amp;amp;chksm=871b0e6ab06c877c7abeb6763763ef870d4419c53fb23830fa611be7432e2a3539943b7aad5f&amp;amp;scene=21#wechat_redirect"&gt;深度 | LSTM 之父 Jürgen Schmidhuber 为何名声不显？&lt;/a&gt;》），在这次会议上，他又做出了一些有争议的事。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 Ian Goodfellow 的演讲《Generative Adversarial Networks》进行的过程中，Schmidhuber 走向麦克风打断了他。很显然，有些人对这样的行为感到不爽，MetaMind 资深研究科学家 Stephen Merity 就发了一条推文批评这样的行为：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8qAJibEDtyiaJvlXTAh04GAcMDMSZDmjkVk279fc0A41cdDHboRhByL5038tlFIxD71pMqUssj4JEg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;内容：Schmidhuber 打断了 GAN tutorial，这是在盗窃听众和学习者的时间。我不管你是谁，都不能做这种事。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;NIPS 2016 资源&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在主会议网站上，我们可以看到大量的视频资源，这里就不再一一列出了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：https://nips.cc/Conferences/2016/Schedule&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面列出的一些是在网站上没有列出的或无法获取的幻灯片，主要是在 Twitter 上发现的：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;Peter Abbeel, “Tutorial: Deep Reinforcement Learning through Policy Optimization” - http://people.eecs.berkeley.edu/~pabbeel/nips-tutorial-policy-optimization-Schulman-Abbeel.pdf&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Yoshua Bengio, “Towards a Biologically Plausible Model of Deep Learning” - http://www.iro.umontreal.ca/~bengioy/talks/Brains+Bits-NIPS2016Workshop.pptx.pdf&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Mathieu Blondel, “Higher-order Factorization Machines” - http://www.mblondel.org/talks/mblondel-stair-2016-09.pdf&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Kyle Cramer (keynote), “Machine Learning &amp;amp; Likelihood Free Inference in Particle Physics” - https://figshare.com/articles/NIPS_2016_Keynote_Machine_Learning_Likelihood_Free_Inference_in_Particle_Physics/4291565&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Xavier Giro, “Hierarchical Object Detection with Deep Reinforcement Learning” - http://www.slideshare.net/xavigiro/hierarchical-object-detection-with-deep-reinforcement-learning&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Ian Goodfellow, “Adversarial Approaches to Bayesian Learning and Bayesian Approaches to Adversarial Robustness” - http://www.iangoodfellow.com/slides/2016-12-10-bayes.pdf&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Ian Goodfellow, “Tutorial: Introduction to Generative Adversarial Networks” - http://www.iangoodfellow.com/slides/2016-12-9-gans.pdf&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Neil Lawrence, “Personalized Health: Challenges in Data Science” - http://inverseprobability.com/talks/lawrence-ml4hc16b/personalized-health-challenges-in-data-science.html&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Yann LeCun, “Energy-Based GANs &amp;amp; other Adversarial things” - https://drive.google.com/file/d/0BxKBnD5y2M8NbzBUbXRwUDBZOVU/view&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Yann LeCun (keynote), “Predictive Learning” - https://drive.google.com/file/d/0BxKBnD5y2M8NREZod0tVdW5FLTQ/view&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Valerio Maggio, “Deep Learning for Rain and Lightning Nowcasting” - https://speakerdeck.com/valeriomaggio/deep-learning-for-rain-and-lightning-nowcasting-at-nips2016&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Sara Magliacane, “Joint causal inference on observational and experimental data” - http://www.slideshare.net/SaraMagliacane/talk-joint-causal-inference-on-observational-and-experimental-data-nips-2016-what-if-workshop-poster&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Andrew Ng, “Nuts and Bolts of Building Applications using Deep Learning” - https://www.dropbox.com/s/dyjdq1prjbs8pmc/NIPS2016%20-%20Pages%202-6%20(1).pdf&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;John Schulman, “The Nuts and Bolts of Deep RL Research” - http://rll.berkeley.edu/deeprlcourse/docs/nuts-and-bolts.pdf&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Dustin Tran, “Tutorial: Variational Inference: Foundations and Modern Methods” - http://www.cs.columbia.edu/~blei/talks/2016_NIPS_VI_tutorial.pdf&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Jenn Wortman Vaughan, “Crowdsourcing: Beyond Label Generation” - http://www.jennwv.com/projects/crowdtutorial/crowdslides.pdf&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Reza Zedah, “FusionNet: 3D Object Classification Using Multiple Data Representations” - http://matroid.com/papers/fusionnet_slides.pdf&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，下面整理了机器之心发过的 NIPS 2016 相关文章：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721081&amp;amp;idx=1&amp;amp;sn=d557968703d4af879b5cf6461069dacd&amp;amp;chksm=871b0f47b06c865185865fcd5ef92af7726e84ae9e689b7ced9986a08c9fe3113df296a8469a&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721081&amp;amp;idx=1&amp;amp;sn=d557968703d4af879b5cf6461069dacd&amp;amp;chksm=871b0f47b06c865185865fcd5ef92af7726e84ae9e689b7ced9986a08c9fe3113df296a8469a&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;独家 | 吴恩达 NIPS 2016 演讲现场直击：如何使用深度学习开发人工智能应用？&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721198&amp;amp;idx=1&amp;amp;sn=accdd701751ab9678285f3cdf073304f&amp;amp;chksm=871b0fd0b06c86c6fa49bbae856898920e26c4456bc02be42a947d23fe2b593110e911bf54da&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721198&amp;amp;idx=1&amp;amp;sn=accdd701751ab9678285f3cdf073304f&amp;amp;chksm=871b0fd0b06c86c6fa49bbae856898920e26c4456bc02be42a947d23fe2b593110e911bf54da&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;独家 | 机器之心对话 NIPS 2016 最佳论文作者：如何打造新型强化学习观？&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721284&amp;amp;idx=1&amp;amp;sn=427e7f45c8253ab22a3960978409f5d1&amp;amp;chksm=871b087ab06c816c424ad03810be3e1b3aa9d6e99a5f325047796f110d178a07736f667d1a10&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721284&amp;amp;idx=1&amp;amp;sn=427e7f45c8253ab22a3960978409f5d1&amp;amp;chksm=871b087ab06c816c424ad03810be3e1b3aa9d6e99a5f325047796f110d178a07736f667d1a10&amp;amp;scene=21#wechat_redirect"&gt;独家 | GAN 之父 NIPS 2016 演讲现场直击：全方位解读生成对抗网络的原理及未来&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721325&amp;amp;idx=4&amp;amp;sn=d570f04d737d09c1b1cebd962755af3f&amp;amp;chksm=871b0853b06c8145985f8c2c5ac7445118f18ce35532c0389b0e5ec24a7a1c4b841fe81280de&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721325&amp;amp;idx=4&amp;amp;sn=d570f04d737d09c1b1cebd962755af3f&amp;amp;chksm=871b0853b06c8145985f8c2c5ac7445118f18ce35532c0389b0e5ec24a7a1c4b841fe81280de&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;资源 | Bengio 和 LeCun 在 NIPS 2016 上的演讲&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718527&amp;amp;idx=2&amp;amp;sn=8d054db2eca7a0b25190a6cc050fc1d7&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718527&amp;amp;idx=2&amp;amp;sn=8d054db2eca7a0b25190a6cc050fc1d7&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;学界 | NIPS 2016 公布 571 篇接收论文&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721033&amp;amp;idx=2&amp;amp;sn=d0d143e72cf4a637a617be356008b323&amp;amp;chksm=871b0f77b06c86615ed6a59ede1bee6cbff68b6ec08fb9b300e347d9c34b931aabdc3d0fee4e&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721033&amp;amp;idx=2&amp;amp;sn=d0d143e72cf4a637a617be356008b323&amp;amp;chksm=871b0f77b06c86615ed6a59ede1bee6cbff68b6ec08fb9b300e347d9c34b931aabdc3d0fee4e&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;学界 | NIPS 2016 论文 SpotlightVideo 精选，三分钟了解一项最新研究进展&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721081&amp;amp;idx=3&amp;amp;sn=111d844d50c98582695d04fa2b252c89&amp;amp;chksm=871b0f47b06c86514ac934c44fe4df92f5d4209f209b94b4c89d1f138492dbaf7e47479803a3&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721081&amp;amp;idx=3&amp;amp;sn=111d844d50c98582695d04fa2b252c89&amp;amp;chksm=871b0f47b06c86514ac934c44fe4df92f5d4209f209b94b4c89d1f138492dbaf7e47479803a3&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;学界 | NIPS 2016 现场：谷歌发布 28 篇机器学习论文&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720969&amp;amp;idx=2&amp;amp;sn=d1fae404486906125e01b5def7e26d94&amp;amp;chksm=871b0eb7b06c87a1d3e7d0b29e8c8f9e4c86f4949d04b0485df1b45823555a6c88a25ccf4dc4&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720969&amp;amp;idx=2&amp;amp;sn=d1fae404486906125e01b5def7e26d94&amp;amp;chksm=871b0eb7b06c87a1d3e7d0b29e8c8f9e4c86f4949d04b0485df1b45823555a6c88a25ccf4dc4&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;学界 | DeepMind NIPS 2016 论文盘点（Part1）：强化学习正大步向前&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721102&amp;amp;idx=2&amp;amp;sn=cbc44a149457d31ed9a8bbe825f09378&amp;amp;chksm=871b0f30b06c8626bb94cbd7a08fd4a5c8bec747082f49280fbd27e9c87c965de983a279796c&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721102&amp;amp;idx=2&amp;amp;sn=cbc44a149457d31ed9a8bbe825f09378&amp;amp;chksm=871b0f30b06c8626bb94cbd7a08fd4a5c8bec747082f49280fbd27e9c87c965de983a279796c&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;学界 | DeepMind NIPS 2016 论文盘点（Part2）：无监督学习的新进展&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721081&amp;amp;idx=4&amp;amp;sn=af93b221818ff9f564b372de5fc1958f&amp;amp;chksm=871b0f47b06c8651744e4b2819322f4026b248f4474f619c7248f604dafe8490405d70d3d1f3&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721081&amp;amp;idx=4&amp;amp;sn=af93b221818ff9f564b372de5fc1958f&amp;amp;chksm=871b0f47b06c8651744e4b2819322f4026b248f4474f619c7248f604dafe8490405d70d3d1f3&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;业界 | NIPS 2016 现场：LeCun 联同英伟达，推深度学习教学工具包&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721198&amp;amp;idx=4&amp;amp;sn=b2f6412538b2458116cd40f53bcdc23b&amp;amp;chksm=871b0fd0b06c86c6866c3e682aa9a15187154a67ae4b7df3d319cc2233fb5761c53da45abed1&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721198&amp;amp;idx=4&amp;amp;sn=b2f6412538b2458116cd40f53bcdc23b&amp;amp;chksm=871b0fd0b06c86c6866c3e682aa9a15187154a67ae4b7df3d319cc2233fb5761c53da45abed1&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;业界 | 波士顿动力最新机器人亮相 NIPS 2016，但还未用到机器学习&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;参考资料&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;http://beamandrew.github.io/deeplearning/2016/12/12/nips-2016.html&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;http://www.machinedlearnings.com/2016/12/nips-2016-reflections.html&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;https://medium.com/search?q=nips%202016&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心整理文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 13 Dec 2016 15:48:27 +0800</pubDate>
    </item>
    <item>
      <title>重磅 | AMD推出首个基于VEGA GPU架构的机器学习芯片，打响与英伟达的硬件战争</title>
      <link>http://www.iwgc.cn/link/3896802</link>
      <description>&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自VB&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：朱思颖、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;AMD 最新发布Radeon Instinct系列芯片以正式进军机器学习，把矛头指向英伟达。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8qAJibEDtyiaJvlXTAh04GAcgLFZc8K0icmB5LOsZqrwGdTCzicxfticia0rNp5VibzJ5ricf8Jt6iazDq5qw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;总部在加州桑尼维尔的这家半导体公司正跟随其竞争对手的步伐，以显卡作为公司进军机器学习与人工智能的排头兵。AMD 的显卡也是硬件和开源软件的结合体，这款新推出的人工智能芯片是基于 AMD 在今年早些时候推出的北极星图像处理结构而设计的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「AMD 必须尽快部署自己的显卡产品开发战略，既有的产品已经远远落后于人工智能的发展需求，」Tirias 研究机构的分析师 Kevin Krewell 评论。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8qAJibEDtyiaJvlXTAh04GAc0VlnzoOQQnOnftKJR93A5l3aBEkhjagkImjeUDmUeRYaxC3k7zD5lA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;上图：Raja Koduri AMD 镭龙技术组的负责人，图片来自：Dean Takahashi&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这款芯片的研发旨在大幅提升计算机在处理深度神经网络相关工作上的表现，能够更高效且更轻松执行相关工作。新的 Radeon Instinct 加速芯片将给从事深度学习训练和推论的研究机构更强劲的 GPU 来开展深度学习相关研究。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们把显卡作为公司今后 5 到 10 年的发展战略，」AMD 的 CEO Lisa Su 在接受 VentureBeat 的采访时说道。「我们当时所制定的发展战略的第一步是『普通消费水平的显卡是很重要的，它构建了我们的核心用户基础。』这也是我们年初发布北极星的缘由。但是我们的战略不止于此，我们的计划永远是把目光投向整个显卡生态链，这一点是不容置疑的。下一个阶段我们的重点是确保我们硬件有足够的市场竞争力以及相应软件平台的构建。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Raja Koduri AMD 镭龙技术组的高级副总在一次采访时说，「我们在显卡领域还大有作为。我们之前的发展战略还没有仔细考虑其中可施展拳脚的地方。以当前显卡市场的市场需求量来看，我们现在拥有的机会更多，巨额的利润依旧存在。仅在显卡研发上，我们还有很大的发展空间。不得不说，芯片的计算能力的确让人兴奋。而且我们终于有了搭载我们自己硬件的软件堆栈，并且我们的软件堆栈也是很诱人的。这对我们来说是件好事。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除了新的硬件，AMD 也宣布了 MIOpen，这是一个免费的开源 GPU 加速库，用来完成高性能机器智能部署。AMD 也在自己的 ROCm 软件上优化了深度学习框架，来建立下一次机器智能负载变革的基础。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Moor Insights &amp;amp; Strategy 的分析师 Patrick Moorhead 说，「Instinct 系列是 AMD 的良好开端，在开始与英伟达争夺市场前还有很多的工作要完成，也需要更多的检验。让我喜欢的是，他们不只推出了显卡，还发布了平台与软件堆栈。很多消费者想要的是解决方案，而非一堆零件，AMD 如今意识到了这一点。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;廉价的高容量存储、丰富的传感器驱动数据、用户生成内容的指数级增加都在使得全球数据的艾字节（exabytes）增加。近期在机器智能算法上的进展配合高性能 GPU 使得数据处理与理解有了巨大发展，几乎能实时产生洞见。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Radeon Instinct 只是机器智能开放软件生态系统的一个蓝图，帮助加速推断洞见与算法训练。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8qAJibEDtyiaJvlXTAh04GAcbp8ldCbSOrVmOE8HX7MgrIsugQvEHZWu9h2R58O9XfzQf3ric1KYR0Q/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;特别说明一点，此次的Radeon Instinct并不是严格意义上的的显卡，只是加速芯片。这些加速芯片实际上没有任何显示输出的功能，换句话说， Radeon Instinct 是AMD回击英伟达Tesla的利器，纯粹是用来加速计算的加速器。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Radeon Instinct 加速器被设计用来解决一系列机器智能应用。该系列芯片包括基于 Polaris GPU 的 Radeon Instinct MI6 加速器。被动冷却推理加速器能够以 150 瓦完成 5.7 teraflops 的计算，GPU 内存为 16 GB。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Radeon Instinct MI8 加速器配有高性能、节能型的 Fiji Nano GPU，可成为小型化的高性能计算和推断的加速器，巅峰性能可达到 8.2 teraflops 而电耗少于 175 瓦，还有 4 GB 的高带宽内容。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Radeon Instinct MI25 加速器将使用 AMD 的下一代高性能 Vega GPU 架构，被设计用来完成深度学习训练，优化时间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8qAJibEDtyiaJvlXTAh04GAcDxxlO1ibVV6IHzcL63jqlBuianjsfNghh1hQootA0P28rpHZv8DAE68w/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;免费、开源的 MIOpen GPU 加速库将预期在 2017 年第一季度亮相，为标准流程提供 GPU 精调部署，比如卷积、池化、激活函数、正则化和张量形式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8qAJibEDtyiaJvlXTAh04GAcuGURMA6XjNgicpIfZkRib6LMbM99FOmqPd5HH5NlLia1ibz9dYiaLOAjZibA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;ROCm 深度学习框架为 Caffe、Torch 和 TensorFlow 进行过优化，能让编程员专注于神经网络的训练，而非 ROCm 融合其他框架时出现的低级性能调整。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;ROCm 打算成为机器智能问题集下一进化的基础，带有针对特定领域的编译器完成线性代数和张量，以及一个开放的编译器和语言运行时。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Radeon Instinct 产品预期在 2017 年上半年开始出货。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文链接：http://venturebeat.com/2016/12/12/amd-introduces-radeon-instinct-chips-for-machine-intelligence/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，机器之心系今日头条签约作者，本文首发于头条号，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 13 Dec 2016 15:48:27 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 微软宣布投资人工智能孵化器Element AI，机器之心独家对话创始成员</title>
      <link>http://www.iwgc.cn/link/3896803</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：蒋思源、李泽南、ChainnZ&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;在机器学习领军人物 Yoshua Bengio 的&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720113&amp;amp;idx=3&amp;amp;sn=7048bf4b7c718d148615d95ef14a10d7&amp;amp;chksm=871b030fb06c8a19b3bd83051cdc482576cbb7e697015aa6edf51232b8554680cb6ee9d39517&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720113&amp;amp;idx=3&amp;amp;sn=7048bf4b7c718d148615d95ef14a10d7&amp;amp;chksm=871b030fb06c8a19b3bd83051cdc482576cbb7e697015aa6edf51232b8554680cb6ee9d39517&amp;amp;scene=21#wechat_redirect"&gt; Element AI &lt;/a&gt;成立仅仅一个多月后，微软旗下的风投公司 Microsoft Ventures 今天宣布了向 Element AI 投资的新动向。&lt;/span&gt;&lt;/em&gt;&lt;br/&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8qAJibEDtyiaJvlXTAh04GAcaUoQp9iaDT88YuxxmrPjrug3j9hic7IhVBIGnffhTic6dkfT5dG3oprnA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Element AI 是一家总部设于蒙特利尔的人工智能创业孵化器，成立于今年 10 月底，旨在通过硅谷式的产业服务帮助创业者将人工智能领域的各种技术从实验室转化为商业应用。除 Yoshua Bengio 之外，Element 的其他联合创始人包括首席执行官 Jean-François Gagne，Nicolas Chapados 和 Jean-Sébastien Cournoyer 等人。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;近日，机器之心造访了 Element AI 并对其中一位创始人 Jean-Sébastien Cournoyer 进行了专访。JS 这样描述 Element AI 的建立理念：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;我不认为现在有 AI 泡沫。当我刚开始做投资的时候，我们经历了很多次所谓的互联网泡沫；现在一切都是互联网的，每个小餐馆都需要用到互联网。AI 也是这样的，我相信。也许不是所有公司都是人工智能优先（AI First）的公司，但是所有公司都需要用到 AI 来加强和建立自己的核心竞争力。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;大概 2 年前，我的风投 Real Venture 一直在寻找互联网之后下一个颠覆性的技术，毋庸置疑它一定是 AI。于是我们接着对 AI 领域进行了研究，发现大量 AI 研究是开源的。开源带来了一系列开发问题；此外对于 AI 创业公司来说还有数据问题等等。要做好 AI 并不是简单地说用 Tensor Flow 进行分析数据，而是需要真的对底层研究有所了解。这需要雇佣大量的非常昂贵的研究人员，但这并不是一般的 AI 公司可以付得起的。于是我们决定建一个可以帮助其他 AI 公司成功的公司，帮助他们进行研究。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;当时这只是一个想法，于是我拉来了我之前的合作伙伴 Jean-François Gagné，我们的好朋友 Yoshua Bengio 教授从一开始就参与其中。在这中间我们也在商业模式上进行了一些摸索和改良。几个月之后我们正式推出了 Element AI。Element AI 将同时进行基础研究和应用研究。在基础研究方面开源是非常有利于行业成长的。而在解决其他公司的应用研究方面的需求的同时，Element AI 也会将一些通用的问题的经验集合起来，发展出专门的 Spin-Off 公司，并继续优化解决方案，为需要这个领域 AI 技术的公司进行服务。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;JS 认为，Open AI 虽然自称是开源研究，也确实开源了很多基础研究，但在最有价值的应用成果上还是主要服务于其出资方。而 Element AI 的模式则可以真正地服务整个行业。Element AI 的这种模式相对 Open AI，更有前景和可持续性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Microsoft Ventures 成立于今年一月，曾致力于向云服务初创公司提供投资。这家风投公司与 Element AI 的合作表明它正在改变其投资策略，开始进入人工智能领域，但目前还无法得知微软会向人工智能投入资金的数量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「Element AI 参与投资的初创企业将帮助人们和机器共同协作，增加人们获得教育的机会，教授新技能，创造就业机会，增强现有员工的能力，发展新的医疗技术，而且人工智能远不止于此，」Microsoft Ventures 总经理 Nagraj Kashyap 说道。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微软此次对 Element AI 进行的投资并不是这家科技巨头今天宣布的唯一人工智能项目，微软同时宣布参与了对 Tact（CRM 旗下的一家人工智能企业）的 1500 万美元 B 轮融资。此外，微软今天也公开了自己对一些其他科技公司的投资，如对 Dynamic Signal 2500 万美元的 D 轮融资。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能正在越来越多地应用于科技领域，在大量应用背后都能找到它的身影，这类新技术正在让人们的生活变得更加方便。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;毫无疑问，微软已在人工智能领域押上了自己的筹码：它已重组了自己的研发机构，现在更将目光转向于在这个领域的其他独立企业，并试图对其投资。人工智能是目前科技巨头相互竞争的主战场，谷歌、Facebook、苹果等公司正在争相研发自己的新一代产品，微软正迎头赶上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;根据 CB Insights 的数据，超过 250 家人工智能创业公司在 2016 年上半年获得了共计 17 亿美元的融资。而在 2012 年，这个数字仍为 176 家公司和 12 亿美元。目前，人工智能风险投资的主要参与者是英特尔、谷歌和三星。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了进一步推动自身理念，在宣布一系列投资之后，Nagraj Kashyap 解释了微软「人工智能民主化」的想法，并宣称公司的投资将「专注于具有包容性的发展，并致力于为社会造福。」当然，作为 CRM 旗下的 SaaS 解决方案，Tact 已经将人工智能应用于商业领域，微软的投资正在为自己创造利润。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Element AI 作为一家专注于人工智能公司的孵化器，目前正备受人们的关注。这家公司的所在之处——蒙特利尔，正是人工智能的热土，有两所专注于人工智能的高校（蒙特利尔大学和 McGill 大学）和全球最为活跃的创业者与研究者。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然 Element AI 刚刚成立，目前仍未开展投资，不过它在蒙特利尔有一个雄心勃勃的计划，公司的发起者们希望这一投资机构能够连接更多的研究人员与初创公司去创造更多价值，并填补学界与产业之间的鸿沟。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Kashyap 说道：「人工智能对增强人类能力和改善社会环境有很大的潜力，而微软正致力于在保证一些指导性原则下使人工智能民主化，并期望对人类社会产生积极的影响。Element AI 正在传递着我们的哲学。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在投资之外，微软正将人工智能技术不断加入 Azure 及其 Cortana 语音助手等服务中，同时也在不断开拓新的领域，如癌症治疗的研究。今年 9 月，微软在沈向阳的带领下，通过结合了几个现有的业务，创建了一个 5000 人的人工智能团队。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微软此次的投资不仅仅是金融方面的支持，更包含务实的业务支持。微软通过 Azure 和其他现有工具提供软件，云存储等服务。这就确保了未来 Element AI 旗下的初创企业无论建立了些什么体系，都会在一定程度上受到微软影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Element AI 的 CEO Jean-François Gagné，在一份公开声明中说道：「此时此刻，我很难抑制住我对这一团队的自豪感，看看我们在两个月内完成的一切。在明年一月份，Element AI 将形成一个至少 30 人的优秀团队。我们将不断扩张。今天微软的帮助将进一步推动我们的增长，因为这种关系，Element AI 的研究中心与微软研究中心将直接联系，这将为我们和我们的合作伙伴提供充足的支持，帮助我们为下一代优秀的人工智能公司提供服务。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器之心近期对 Element AI 的创始人之一 Jean-Sébastien 进行了独家专访，更多内容请关注我们的后续报道。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心原创文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 13 Dec 2016 15:48:27 +0800</pubDate>
    </item>
    <item>
      <title>观点丨深度神经网络中深度究竟带来了什么？</title>
      <link>http://www.iwgc.cn/link/3896804</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;转自微软研究院AI头条&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：赵黎明&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWib0hSn5ceEO5ias3cGXuGGVRSau7KJcd9U5r0BR5lGJZB8wk0CuT6sl6CiaqCxUPib7qCbibHl7ejdcSw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;深度神经网络中深度究竟带来了什么？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;作者：赵黎明&amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;导师：&lt;/span&gt;&lt;span&gt;微软亚洲研究院主管研究员 王井东&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;缘起&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能近几年实现了爆炸式发展，深度学习可以说是其主要的推动力。笔者对于能来微软实习并从事深度学习方面的研究感到十分荣幸，因为微软研究院在该领域一直处于领先的地位，其优秀的人才配备和强大的计算资源都非常适合做这方面的研究。&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在计算机视觉领域，大部分的问题都已经开始使用深度神经网络进行解决，也确实取得了广泛的成功。在很多视觉任务中，如图像识别、语义分割、目标检测与跟踪、图像检索等，作为提取特征的CNN网络模型往往起到了关键的作用。我们经常见到最新的方法将基础网络换一下，性能就会得到很大的提升。因此，研究并设计一个更好的网络模型变得至关重要。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/HkPvwCuFwNNgOich8V7GNAxIibgaxEhVdo7Y3Aq9NiaGEoib9KOyZYvv6nW1NsYBhcoWgc4A7e8LiaCAWtk88gNmKjg/640?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;基础网络模型的结构样例&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;最新研究进展&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;经典的神经网络模型主要在“宽度”与“深度”方面进行不同程度的扩增。借助于大规模数据的训练，AlexNet、VGG-16、VGG-19等经典网络通过宽度或深度增加的参数可以有效地提升其模型的表达能力。但当网络变得越来越深，其训练难度也随之相应增加，反而会导致性能的下降。最近的ResNet和Highway Networks等方法通过引入Skip跳跃结构来试图解决极深网络在优化上带来的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/HkPvwCuFwNNgOich8V7GNAxIibgaxEhVdouDHxLZud3kLDLZ148XV1SpNPkEKBvpumTibTKiaYJSIvWApwxfLE15zQ/640?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;span&gt;ResNet和Highway Networks结构的简单示意图&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最新的一些研究尝试从其他角度来解释Highway、ResNet和GoogLeNet等网络结构表现优异的原因。其中我在微软实习的导师王井东研究员、实习生魏祯和张婷以及曾文君研究员提出Deep Fusion (Jingdong&lt;/span&gt;&lt;span&gt;&amp;nbsp;Wang, Zhen Wei, Ting Zhang, Wenjun Zeng: Deeply-Fused Nets. CoRR abs/1605.07716 (2016))&lt;/span&gt;&lt;span&gt;深度融合的概念，认为不同分支的网络在中间层进行融合（加和或拼接等方式）能够(1)产生很多潜在的共享参数的基础网络，(2)同时优化信息的流动，(3)从而帮助深层网络的训练过程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/HkPvwCuFwNNgOich8V7GNAxIibgaxEhVdoztiaXQF5aE56uW0zGfpa8z0FfXkoGZVFDKic5aJ5l7j98ztuQHvOlE6Q/640?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Deep Fusion深度融合最简单形式的概念示意图&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们可以发现很多有代表性的网络结构基本都可以按照深度融合的概念进行理解。除去LeNet、AlexNet、VGGNet等单分支网络，近两年提出的ResNet、Highway Networks、GoogLeNet系列等网络均可以看作是不同程度上的深度融合网络。在这个概念下，我们发现今年新的Inception-v4、FractalNet、DenseNet、ResNeXt以及我们新提出的Merge-and-Run等网络结构在融合方式上进行了更多的设计和探索，使得中间的融合次数和分支数目更多，从而得到更多的基础网络和更优的信息流动，最终取得更好的性能表现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/HkPvwCuFwNNgOich8V7GNAxIibgaxEhVdoLcRLzuoeJgH79ktag4C9Oyow2qyehwHvmfkQculz4yLdDQMTjjJrxA/640?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;span&gt;近期一些深度神经网络模型的基本结构示意图&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;康奈尔大学的Serge Belongie团队也有类似的观察与发现，他们解释ResNet其实是众多相对较浅的潜在网络的一个集成。在模型的测试阶段发现将网络中的一些模块去掉，剩下的网络模型依然具有不错的表现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/HkPvwCuFwNNgOich8V7GNAxIibgaxEhVdopHhWt9cANQYcr3GC2jiczfuPYZRft2mjia6pD9jFXVLzCvOurCpvm0Tw/640?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;span&gt;将ResNet中的某些模块移除的实验示意图&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最近提出的一些新的深度神经网络方法也从侧面印证了这方面的研究，如ResNet with Stochastic Depth、FractalNet和Swapout等使用Drop-path的方法与上述移除Residual模块的研究有着异曲同工之妙。ResNet of ResNet、ResNeXt、Multi-Residual Networks和DenseNet等增加分支或路径数目的方法均得到了性能上的提升，从某种程度上验证了增加基础网络数目对整体网络模型的影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;我们的工作&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们沿着deep fusion的思路更进一步地研究了类似ResNet、Highway、Inception等结构的深度融合网络，探索了“深度”在神经网络当中究竟带来了什么。基于研究观察与分析，我们又提出了一个新的网络模型，在不同数据集上均取得了不错的表现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;Liming Zhao,&amp;nbsp;Jingdong Wang,&amp;nbsp;Xi Li,&amp;nbsp;Zhuowen Tu, and&amp;nbsp;Wenjun Zeng. "On the Connection of Deep Fusion to Ensembling." arXiv preprint&amp;nbsp;arXiv:1611.07718&amp;nbsp;(2016).&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;一、深度融合网络剖析&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先我们从网络结构和实验分析上展示这种多分支融合的网络跟多个潜在网络集成的关系。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/HkPvwCuFwNNgOich8V7GNAxIibgaxEhVdo3ibn2hRkn27NSwic0bbcyLY49X7ylkmBsLKuNsF3yQTDSzrt7iajzYuMA/640?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;span&gt;多分支融合的网络与集成网络的结构类似&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过上图可以发现多分支融合的网络形式可以近似很多潜在网络的集成过程，区别是没有中间的信息交互，只是他们共享对应层的网络参数。通过10组不同深度的网络结构实验发现，这样一个共享参数的集成网络与带信息交互的深度融合网络性能表现很相似。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/HkPvwCuFwNNgOich8V7GNAxIibgaxEhVdophseXOyoFTv7ZvgicwdX4DbqqZv9icEkrNmaLPrlEcEmBq70fIMdibfGg/640?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;span&gt;深度融合网络与集成网络的表现类似&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;二、深度带来更多组成网络&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下一步就可以利用集成学习中的一些思路来指导我们对该类型的深度融合网络进行剖析。首先是研究其潜在的基础网络数目，很明显上面图中融合3次的网络能够组合8个基础网络，即2^3个。那么我们可以发现增加融合次数可以提升基础网络的组合数目。那么像ResNet、Highway、Inception等形式的网络，增加“深度”带来的一个影响就是增加了其潜在基础网络的组合数目(Ensemble Size)。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/HkPvwCuFwNNgOich8V7GNAxIibgaxEhVdo479DWzInW37Fa2RBq9ej8pR2hyjrPqat52stjiacrg5rdBWo9oGlXibg/640?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;span&gt;不同融合次数会得到不同数目的组合网络(路径)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们也通过实验在不同深度的网络结构上验证了：增加组合数目能像传统Ensemble理论中增加Ensemble Size一样提升整体性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/HkPvwCuFwNNgOich8V7GNAxIibgaxEhVdobsKQZib3MBP3P9nQXch2jtELuzG2CgGDfRr7CfrE71Cy1QUIMUX1bUg/640?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;span&gt;较多的组合网络数目能够取得更好的结果&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们也通过实验在不同深度的网络结构上验证了增加组合网络数目能够提升整体性能，这也与传统Ensemble理论中增加Ensemble Size能提升性能的结论相吻合。我们可以看到ResNet在增加深度的同时，极大地增加了组合数目，这也是其性能优异的原因之一。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;三、深度影响整体性能&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们继续研究每一个基础组合网络，并且探索在深度融合的过程中其相互之间会产生怎样的影响。对比每个网络单独分开训练得到的模型，我们发现，深度融合网络里较深的组合网络性能得到了提升，但较浅的组合网络性能反而下降了。我们猜想在训练过程中，由于浅层的网络容易收敛，它们能够帮助深层的网络进行优化。但深度融合网络的各个潜在的组成网络是共享参数的，极深的网络可能会影响较浅网络的求解空间与难度，从而产生相互影响性能往中间靠拢的现象。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/HkPvwCuFwNNgOich8V7GNAxIibgaxEhVdorP9YIPNTCtW7nCmzVAHEoSIibSvzktBk72gibhpMxqfOibxP0rEMd3RJg/640?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;span&gt;每一个单独的组成网络行为分析&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;既然我们认为最终的表现是一种集成的近似，那么我们是否可以着手寻找更优的组合网络以达到整体性能的提升？通过上述组合网络之间相互影响的启发，我们认为极深的网络会产生“拖后腿”的效果，反而较深但又不是特别深的“中间”网络会对结果影响比较大。上图的实验结果也验证了我们的这个想法：（a）显示了每个组成网络由于共享参数导致的性能变化；（b）显示了每个组成网络对整体网络（ensemble）的相对贡献程度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们依然需要浅层网络来帮助训练较深网络，而且实际设计神经网络的时候很难做到只保留中间深度的网络结构。那么一个折中的方案是把这里面最深的组成网络去掉，这样看看对结果会产生什么影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/HkPvwCuFwNNgOich8V7GNAxIibgaxEhVdoOw0TovCvrskdFUlsY120BlKwbsjOARSGjGoerVH2SZjGhV7DoeJTcA/640?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;span&gt;去除最深的组成网络（重新训练或只是测试时候去除）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;上图三个方法的实验结果表明，去除极深的组成网络不会对整体性能产生太大影响，有时候反而会提高最终结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/HkPvwCuFwNNgOich8V7GNAxIibgaxEhVdowl8TWeJQOY05Kmbr3xTa1eWCibN2UDOA8ZaN3LhiaYLEia6qibOMmFZu6A/640?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;span&gt;去除极深的组成网络不会影响太大，大部分情况下反而会提升性能&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;四，提出新的方法&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;基于上述观察，我们认为一个好的网络结构应该包含如下两个特性：足够多的潜在网络数目，以及足够好的组成网络。最简单的策略是去掉“拖后腿”的极深网络，将其变成“中间”深的组成网络。下面是我们提出的方法：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/HkPvwCuFwNNgOich8V7GNAxIibgaxEhVdoFyibIALfuoRHXGv3TpmjTL2QuP69LzXWbRHQibFnTO0Qxwmy6Ab3BkibA/640?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;span&gt;基于ResNet的形式，我们提出新的网络结构(b)和(c)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;基于ResNet的形式，我们提出的Inception-Like结构与Merge-and-Run结构都去除了极深的那一条线路，但是Inception-Like的组合数目比相同参数下的ResNet要少，因此我们认为Merge-and-Run形式比较符合我们的分析与观察。最终的实验结果也确实验证了这一想法，而且跟上面的实验观察相吻合：Inception-Like没有极深网络的影响，更加容易训练或收敛，比ResNet会稍好一点，与上述的Ensemble-7与Ensemble-8的实验结果相似。Merge-and-Run结构比Inception-Like的潜在网络数目多，最终结果也是比Inception-Like的表现要好。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/HkPvwCuFwNNgOich8V7GNAxIibgaxEhVdoy24ibQdCuwtXjHsyZPCLN0pkXKZYAuxBZ6EXbJoKUwsDRrenIzN7uCA/640?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;span&gt;ResNet, Inception-Like和Merge-and-Run在不同数据集上的对比&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在ImageNet结果上也验证了我们前面的论述 (我们的方法用DFN-MR表示)：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/HkPvwCuFwNNgOich8V7GNAxIibgaxEhVdoeXXNtsr57yic5zNFcJv0WgXHNEEbyqCUHGhkWib1DlKArV0dqx4eGjxw/640?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;span&gt;我们提出的DFN-MR与ResNet在ImageNet数据集上的对比&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;五、总结&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前一个研究热点是在深度神经网络中引入一个新的维度：潜在的组成网络数目(Ensemble Size)。可以发现像ResNet、Highway、Inception等网络增加“深度”的同时，实际增加了这个网络数目。此外，我们的工作发现极深网络除了能增加潜在网络数目外，对整体性能的贡献并不是最大的。反而会影响其它的组成网络，导致最终的结果受到影响。我们按照“不减少组成网络数目”和“避免极深组成网络”这两个原则，设计出新的网络结构，发现在不同数据集上总是表现优异。后续工作可以围绕当前分析的内容，最优化提出的设计指标与原则，得到更容易训练性能更好的网络模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;后记：&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;个人感觉深度学习方法有时候对工程技术要求较高，往往方法不work的原因不是idea的问题，而是实现层面上对于细节的处理有差异，这也对我们学生在科研道路的前进造成了很大的困难。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了方便大家在该领域的研究，我们将提出的模型和该论文实验中用到代码完全开源，目前维护在GitHub上，项目地址为： https://github.com/zlmzju/fusenet；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;希望我们的工作能给大家在Deep Learning的研究上带来一些新的思考和帮助，期待更多更深入的探索和研究工作。&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;span&gt;作者简介&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/HkPvwCuFwNNgOich8V7GNAxIibgaxEhVdojWbaGBu0PatbLjWtDmJQ9BJicpyc6mHGvGzIQaoAbsaEhMSCQCPiaS5g/640?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&amp;nbsp;&lt;span&gt;赵黎明&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微软亚洲研究院网络多媒体(IM)组的一名实习生，现在就读于浙江大学的计算机科学与技术学院。在微软实习的半年多，跟随王井东研究员从事了深度神经网络的研究及其在计算机视觉领域的应用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心经授权转载文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系原公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;</description>
      <pubDate>Tue, 13 Dec 2016 15:48:27 +0800</pubDate>
    </item>
    <item>
      <title>活动 | 首届「机器智能前沿论坛」强势来袭，众多机器学习大咖邀你共话AI未来！</title>
      <link>http://www.iwgc.cn/link/3896805</link>
      <description>&lt;p&gt;&lt;strong&gt;&lt;span&gt;2016&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;年是人工智能诞生60周年。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;在这一年里，人工智能领域也出现了很多重大进展，相关的技术也加速从实验室迁移到业界。在这一年里，机器首次战胜了最顶尖的人类围棋棋手，学界的顶尖教授也纷纷创办自己的企业或加入人工智能巨头。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWib0hSn5ceEO5ias3cGXuGGVRCXaLcnElpLdibWxfQfCicjGQiczicDbib6CWY9TMgBoviboSPUmECichmwwicQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了纪念AI 60年，中国人工智能学会和中国工程院战略咨询中心将在&lt;span&gt;12&lt;/span&gt;&lt;span&gt;月17日&lt;/span&gt;联合主办——&lt;/span&gt;&lt;strong&gt;&lt;span&gt;首届机器智能前沿论坛（MIFS 2016）&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。论坛聚集了来自中外顶尖的&lt;strong&gt;数据挖掘、机器学习和自然语言处理&lt;/strong&gt;方面的专家学者，届时他们会分享自己的研究和人工智能领域的趋势，并着重讨论自然语言处理在媒体创作和分析方面的应用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;活动信息&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;▼&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;时间：12月17日（周六）08:30—17:30&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地点：中国工程院&amp;nbsp;北京市西城区冰窖口胡同2号&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;官网：&lt;/span&gt;&lt;span&gt;http://mifs.caai.cn/con/&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;报名入口（点击阅读原文）：http://www.huodongxing.com/event/9362387342400&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;活动详情&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8qAJibEDtyiaJvlXTAh04GAcFvKKeEb7L5ZMhfTgde1fiaYoMnAlh1vnf3VXJiaBujVc1WruNKfy9ibqQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8qAJibEDtyiaJvlXTAh04GAchVkEMmoNJHfE0hYGnzj24ta9HI9cyW7nZtLWyia57aPjQ2KPFTWsfjA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8qAJibEDtyiaJvlXTAh04GAcvsgicyYENpZvia5h5WiaqibdaVJCuWQCFD7ibsU2R3msgQUy8kYzt7gjichw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8qAJibEDtyiaJvlXTAh04GAckMz4xUDn853UUjvvKXgIYxnpXaia5UOtUCsiciaynC3l0ZXlD1EhDd0wQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;活动亮点&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;▼&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;看点一：大牌嘉宾，众星云集&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本次活动邀请到香港科技大学的&lt;strong&gt;杨强&lt;/strong&gt;、微软亚洲研究院的&lt;strong&gt;刘铁岩&lt;/strong&gt;，以及Santa Fe Institute的&lt;strong&gt;David Wolpert&lt;/strong&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;3位 IEEE Fellow。DavidWolpert曾于1996年提出了“没有免费的午餐”定理，现在已经广泛应用于机器学习领域。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;看点二：重点突出，大势与专业兼顾&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本次活动将讨论机器学习的一般问题和趋势，同时着重探讨自然语言处理技术在媒体方面的应用。清华大学教授、中国中文信息学会的副理事长&lt;strong&gt;孙茂松&lt;/strong&gt;教授将担任论坛上半场主持人，他将在论坛上介绍自然语言处理的最新进展。今日头条的实验室科学家&lt;strong&gt;李磊&lt;/strong&gt;将介绍今日头条如何用技术让机器读懂文章。此外，北京大学的张志华、清华大学的&lt;strong&gt;朱军&lt;/strong&gt;和佐治亚理工的&lt;strong&gt;宋乐&lt;/strong&gt;等人也将在论坛上介绍他们的前沿研究。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;看点三：2016 ByteCup国际机器学习大赛颁奖礼&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2016&lt;/span&gt;&lt;span&gt;年的ByteCup国际机器学习大赛的颁奖典礼也在MIFS 2016期间举办。届时，&lt;strong&gt;从1000支赛队伍中脱颖而出的3支队伍将介绍他们在比赛中使用的方法。&lt;/strong&gt;IEEE亚太区高级总监&lt;strong&gt;华宁&lt;/strong&gt;和今日头条技术副总裁&lt;strong&gt;杨震原&lt;/strong&gt;将为获奖选手颁奖。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;看点四：丰厚的参会福利&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了让更多初入行业的学生和青年研究者参与此次学术盛会，论坛提供了低廉的注册费用和有吸引力的参会福利。专业会员的全票价和IEEE/CAAI会员价分别为￥488和￥369，而学生全票和IEEE/CAAI会员票仅有￥288和￥169。票价还包括会议的茶歇和工作午餐，以及一个&lt;strong&gt;免费的CCF一年会员名额（价值￥200）&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;福利时间&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;作为本次活动的战略支持，&lt;/span&gt;&lt;strong&gt;&lt;span&gt;机器之心&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;为一直关注支持我们的朋友准备了丰厚的福利！通过机器之心报名者，均可享受颇具吸引力的&lt;/span&gt;&lt;span&gt;门票折扣！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;原￥488的专业票，机器之心价格只需￥240！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;原￥288的学生票，机器之心价格只需￥120！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;票价还包括：会议的茶歇和工作午餐，以及&lt;strong&gt;价值￥200的CCF全年会员名额&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;福利获取方式&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&amp;gt;&amp;gt;&lt;/span&gt;&lt;span&gt;关注“机器之心”微信公众号，回复“&lt;/span&gt;&lt;strong&gt;&lt;span&gt;福利&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;”即可获得&lt;/span&gt;&lt;span&gt;优惠密码&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 13 Dec 2016 15:48:27 +0800</pubDate>
    </item>
  </channel>
</rss>
