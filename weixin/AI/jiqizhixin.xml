<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>重磅 | 德扑人机大战收官，Libratus 击败世界顶尖扑克选手</title>
      <link>http://www.iwgc.cn/link/4530409</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;机器之心报道&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：微胖、杜夏德、朱思颖&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;当地时间 1 月 30 日，在宾夕法尼亚州匹兹堡的 Rivers 赌场，卡耐基梅隆大学（CMU）开发的　Libratus 人工智能系统击败&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;em style="color: rgb(136, 136, 136);"&gt;&lt;span&gt;人类顶级职业玩家。据官网介绍，此次比赛共持续 20 天，由 4 名人类职业玩家 Jason Les、Dong Kim、Daniel McAulay 和 Jimmy Chou 对战人工智能程序 Libratus，&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722637&amp;amp;idx=5&amp;amp;sn=11387e204c3e3f0f07d9aff784fd8946&amp;amp;chksm=871b1533b06c9c259f50cf9077596ff60a034e6ff26b63509aaf90345d7d95354f5fa7317711&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722637&amp;amp;idx=5&amp;amp;sn=11387e204c3e3f0f07d9aff784fd8946&amp;amp;chksm=871b1533b06c9c259f50cf9077596ff60a034e6ff26b63509aaf90345d7d95354f5fa7317711&amp;amp;scene=21#wechat_redirect"&gt;在为期 20 天的赛程里面对玩 12 万手，争夺 20 万美元的奖金&amp;nbsp;。&lt;/a&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你打算开始在网上玩扑克，可要三思了。在无限德扑比赛中（一对一、无限制投注的规则），人工智能击败世界最强的人类德州扑克玩家，这是人工智能历史上又一里程碑时刻。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;比赛过程中，人类选手整体上从未领先过。进入比赛最后一天时&lt;/span&gt;&lt;span&gt;，Libratus&amp;nbsp;赢得156&amp;nbsp;&lt;/span&gt;&lt;span&gt;万筹码。人类选手要挽回劣&lt;/span&gt;&lt;span&gt;势，只有不到 5,000 手的机会。Jason Les 说，最后的感觉就是，自己所能做的就是输。这太打击士气了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8NbZiajJf2Jw76YKNqaia1FtqvLibr8Rx64TMFZrpV3MptKDZrtPnXdCvsTE03AOyxFYzoZtiag1ibQtA/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;与 Libratus对抗中的德扑专业选手 Jason Les&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1979 年，人类首次在西洋双陆棋游戏（backgammon）中败给机器。1997 年，Gary Kasparov 输给 IBM 的深蓝。当时他评论说，可以感觉到对手是种新的智能形式。人类输给机器的其他游戏包括：西洋棋、黑白棋、拼字游戏（Scrabble），甚至是 Jeopardy! 和经典的 Pong。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最近，人工智能打败顶尖围棋高手。2016 年 3 月，李世石 4：1 惜败 AlphaGo。&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722021&amp;amp;idx=1&amp;amp;sn=ee24983b1fce5183bf33845efd367a3b&amp;amp;chksm=871b0a9bb06c838dd8e94363d0be6ec5ad28e46501b51ac951d998f03b83df8ea8c8ce37803a&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722021&amp;amp;idx=1&amp;amp;sn=ee24983b1fce5183bf33845efd367a3b&amp;amp;chksm=871b0a9bb06c838dd8e94363d0be6ec5ad28e46501b51ac951d998f03b83df8ea8c8ce37803a&amp;amp;scene=21#wechat_redirect"&gt;2016 年圣诞节期间，匿名再度出山的 AlphaGO 陆续击败中国顶尖围棋高手，赢得毫无悬念。&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;Libratus 是一个玩无限德州扑克的人工智能程序，由卡耐基梅隆大学的 Tuomas Sandholm 教授与 Noam Brown 博士所开发。Libratus 的策略并非基于专业玩家的经验，所以它的玩牌方式可能有明显的不同。基于在匹兹堡超级计算机中心大约 1500 万核心小时（core hours）的计算，它使用算法分析德扑规则，建立自己的策略。在此次的比赛中，Libratus 将继续提升自己的策略。据介绍，创造 Libratus 使用的算法并非为扑克专门设计的。在面临不完全或误导信息时，该人工智能进行推论的能力有着广泛的潜在应用，包括业务谈判、医疗、网络安全、竞拍等等。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;为什么是扑克？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;围棋被视为棋盘游戏的珠峰，其复杂程度远甚过其他游戏。不过，论挑战性，仍然稍逊扑克。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在真实世界中，扑克是一种有关不确定性的游戏。玩家并不知道其他对手手里的牌。也不清楚以后会有什么牌。在类似围棋或国际象棋的游戏中，所有玩家都可以看到棋盘。每个玩家的信息都是完整的。这使得围棋和国际象棋要比扑克容易玩得多。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「在完整信息博弈中，计算机可以在决策树中进行分析，」CMU 教授 Tuomas Sandholm 解释道，他与自己的博士生 Noam Brown 共同开发了 Libratus 系统。在国际象棋和围棋中，人工智能可以通过预测所有未来步骤的胜率来思考自己的下一步。「然而在不完整信息博弈中，事情就变得复杂起来了，你不知道对面手握什么底牌，」Sandholm 解释道。「这意味着你不能在决策树的架构下选择下一步了。而且，你也不知道发牌员在 flop、turn 和 river 上发出的下一张牌是什么。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8NbZiajJf2Jw76YKNqaia1FtN4kNp9OnBH0PQK6ekpEasBmVZghWQFRNXwLGcUiaX8UujSLAOBlOfBw/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;比赛中的 Daniel McAulay&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不完整信息博弈早已被证明是难以攻克的计算机难题。对此，CMU 的人工智能研究者们专注于信息集（Tuomas Sandholm，2010），通过同时思考未知和已知变量各种可能状态的方式来进行预测。这需要强大的计算能力。「德州扑克有 10 的 160 次方个信息集，还有 10 的 165 次方个游戏树节点，」Sandholm 说道。这意味着牌局的可能性大于宇宙中所有原子的数量（目前可观测宇宙约有 10 的 75 次方个原子）。「而且即使宇宙中的每个原子是一个宇宙，所有原子的数量也无法与牌局的可能性数量相比。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外，扑克也需要懂点其他玩家的心理学。他们有没有在唬牌？需不需要盖牌？你要不要也唬牌？最后，还需要下注。啥时候下注？赌啥？这些都为编写击败人类选手的扑克程序增加了难度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;iframe class="video_iframe" data-vidtype="1" allowfullscreen="" frameborder="0" style="   z-index:1; " height="417" width="556" data-src="https://v.qq.com/iframe/preview.html?vid=d0371vlbmsc&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0"&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了降低结果的纯粹运气成分，比赛是复重扑克（Duplicate hands)，在两张桌上（位于不同房间）使用完全相同的两副牌。这意味着即使有一个玩家手气特别壮，在重复赛制中，这也会镜像到其他玩家身上。这也解释了为什么会鏖战这么多场。从统计置信度上来说，最终&lt;span&gt;Libratus&lt;/span&gt;击败了人类选手。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;怎么赢取比赛&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8NbZiajJf2Jw76YKNqaia1Ft3uqZDqU7vrbu8cJzuqPrWvQymvFKojTX2NBicoe4yUjGibia0kCYhIEqw/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然 Libratus 赢得过程的细节仍然是个秘密。但是我们能在卡耐基梅陇大学之前的研究基础上，凭经验猜出个八九不离十。最有趣的或许是这次的胜利依靠更多的是 Good Old Fashioned AI（GOFAI）而不是当前时髦的深度学习过程。就像象棋比赛中的深蓝一样，Liberatus 用了很多蛮力计算来发挥到最佳水平。我们知道它动用了匹兹堡的超级计算中心来完成每一场比赛。&lt;br/&gt;&lt;br/&gt;每个夜晚，&lt;span&gt;Libratus&amp;nbsp;&lt;/span&gt;都会使用这台超级计算机优化它的策略。这么做是为了防止大家觉得这样对人类选手不公平，职业选手在每场比赛后晚上也聚在一起为第二天的比赛商讨表现和计划。&lt;br/&gt;&lt;br/&gt;&lt;span&gt;Libratus&amp;nbsp;&lt;/span&gt;还利用了博弈论。与 AlphaGo 不同，Libratus 系统不通过分析大量可能的下一步完成任务，这个 CMU 构建的新系统通过平衡风险与收益来决定自己的下一步——在纳什均衡定义中的完美游戏状态。John Nash，电影《美丽心灵》的原型，在 20 世纪 50 年代创立出这一伟大理论，它随后成为博弈论的基石，并让 Nash 在 1994 年获得了诺贝尔经济学奖。&lt;br/&gt;&lt;br/&gt;「在存在两名玩家的零和游戏中，如果有一人不遵从纳什均衡的策略，那么两名玩家获得的收益都将受损，但我们的系统不会这样，」Sandholm 解释说。「在此类游戏中，以纳什均衡的方式思考是最安全的。遵从规律的玩家将合理地获得受益，同时在任何地方都不会被对手利用。」&lt;br/&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;Libratus 的打法让对手无论如何都想不出更好的招来对付它。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;接下来会发生什么？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这只是个开始。Libratus 玩的仅仅是双人版单挑无限额德州扑克。玩家增多会大大增加游戏的复杂性。因此，在计算机还需要几年时间才能够对抗四个或更多玩家。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但这是另一个人工智能如何在狭窄领域接管人类工作的例子： 阅读乳腺 X 线摄片，抄写中文，在战斗中击败人类飞行员... 几乎每周都会出现被人工智能接管的新领域。毫无疑问，许多人都想知道终极结果是什么。计算机会最终接管人类所有的工作吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个被广泛报道的牛津大学 2013 年的研究，研究中估计在接下来 20 年内美国 47% 的工作受到来自自动化取代的风险。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;牛津大学的研究是有一些局限的。出人意料的是，研究的内容之一是计算机可以自动完成对将处于风险之中的工作的预测。这项研究运用机器学习和一个手工标注出 70 个工作类型的小训练集来预测出 700 多个职业中哪些将处于风险之中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是可以给这项研究提供帮助的地方。呼吁在群体的智慧下，看看是否可以做出更好的预测。请用几分钟的时间来完成我们的调查表。在调查表的最后，你可以指定一个慈善机构来接收我们的捐赠作为对你所花时间和精力的认可。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;即使在我们调查表的结果出来之前，显而易见的是一些类如出租车司机、卡车司机、放射线技师以及现在的德州扑克专业选手都处于威胁之中。当然，技术会创造出一些其他的新工作。但是，是否能创造或者摧毁大量工作仍然是一个有意思的开放命题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;要保持领先于机器人，人类将需要在自己的专长如创造力和情感智能上动脑筋。我们同时也应该考虑如何通过机器人增强人类的能力而不是取代人类。人和机器的协作表现将比机器或者人类各自单独的表现更好。当今最优秀的国际象棋「选手」是人同计算机合力组成的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 31 Jan 2017 11:27:32 +0800</pubDate>
    </item>
    <item>
      <title>教程 | 从头开始：如何用 Python 实现带随机梯度下降的线性回归</title>
      <link>http://www.iwgc.cn/link/4530410</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自machinelearningmastery&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Jason Brownlee&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：linjing、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;许多机器学习算法的核心是优化。优化算法用于在机器学习中为给定训练集找出合理的模型参数设置。机器学习最常见的优化算法是随机梯度下降（SGD：stochastic gradient descent）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本教程将指导大家用 Python 实现随机梯度下降对线性回归算法的优化。通过本教程的学习，你将了解到：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如何用随机梯度下降估计线性回归系数&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如何对多元线性回归做预测&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如何用带随机梯度下降的线性回归算法对新数据做预测&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;说明&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本文将对线性回归、随即梯度下降方法以及本教程所使用的葡萄酒品质数据集做一个集中阐释。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;多元线性回归&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;线性回归是一种用于预测真实值的方法。让人困惑的是，这些需要预测真实值的问题被称为回归问题（regression problems）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;线性回归是一种用直线对输入输出值进行建模的方法。在超过二维的空间里，这条直线被想象成一个平面或者超平面（hyperplane）。预测即是通过对输入值的组合对输出值进行预判。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;y = b0 + b1 * x1 + b2 * x2 + ...&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;系数 (b) 用于对每个输入属性 (x) 进行加权，而学习算法的目的正是寻找一组能导出好的预测值 (y) 的系数。这些系数可以使用随机梯度下降的方法找到。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;随机梯度下降&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;梯度下降（Gradient Descent）是遵循成本函数的梯度来最小化一个函数的过程。这个过程涉及到对成本形式以及其衍生形式的认知，使得我们可以从已知的给定点朝既定方向移动。比如向下朝最小值移动。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在机器学习中，我们可以利用随机梯度下降的方法来最小化训练模型中的误差，即每次迭代时完成一次评估和更新。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种优化算法的工作原理是模型每看到一个训练实例，就对其作出预测，并重复迭代该过程到一定的次数。这个流程可以用于找出能导致训练数据最小误差的模型的系数。用机器学习的术语来讲，就是每次迭代过程都用如下等式更新系数（b）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;b = b - learning_rate * error * x&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中 b 是系数或者被优化的权重，learing_rate 需手动设定（如 0.01），error 是取决于权重的训练数据模型的预测误差，x 是输入值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;葡萄酒品质数据集&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;开发了具有梯度下降的线性回归算法之后，我们可以将其运用到一个关于葡萄酒品质的数据集当中。这个数据集囊括了 4898 种白葡萄酒的测量标准，包括酸度和 ph 值。目的是用这些客观标准来预测葡萄酒的品质，分为 0 到 10 级。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下表给出了 5 个数据样本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;7,0.27,0.36,20.7,0.045,45,170,1.001,3,0.45,8.8,6&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;6.3,0.3,0.34,1.6,0.049,14,132,0.994,3.3,0.49,9.5,6&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;8.1,0.28,0.4,6.9,0.05,30,97,0.9951,3.26,0.44,10.1,6&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;7.2,0.23,0.32,8.5,0.058,47,186,0.9956,3.19,0.4,9.9,6&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;7.2,0.23,0.32,8.5,0.058,47,186,0.9956,3.19,0.4,9.9,6&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所有数据需归一化为 0-1 之间的值。每种属性标准单位不同，因而有不同的缩放尺度。通过预测该归一化数据集的平均值（零规则算法），达到了 0.148 的基准方均根差（RMSE）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该数据集详情请参阅 UCI Machine Learning Repository：http://archive.ics.uci.edu/ml/datasets/Wine+Quality&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下载该数据集并将其保存到当前工作目录，文件名为 winequality-white.csv。（注意：文件开头的头信息需去除，用作分隔符的 『；』 需改为符合 CSV 格式的 『，』。）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;教程&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本教程分为三个部分：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 预测&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 估计系数&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 葡萄酒品质预测&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这将能让你了解在你自己的预测建模问题上实现和应用带有随机梯度下降的线性回归的基础。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1. 预测&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先建立一个用于预测的函数。这将用于对随机梯度下降的候选系数的评估，且模型确定之后也需要这个函数。我们会在测试集或者新的数据上用该函数来进行预测。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;函数 predict() 如下所示，用于预测给定了一组系数的行的输出值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一个系数始终为截距，也称为偏差或 b0，因其相对独立且不与特定的输入值相关。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8NbZiajJf2Jw76YKNqaia1FtS8mAt2ZWic73QxXvy630XSxF3IuPp799tvoBOoz8JUHTj83KIjtQeFw/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们可以用一个小的数据集对这个函数进行测试。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;x, y&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1, 1&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2, 3&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4, 3&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3, 2&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;5, 5&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下图是一小部分数据：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8NbZiajJf2Jw76YKNqaia1Ft4XLKzDWCf97AbNQcpPuKqWU4nFnXMqIZ3sYpdP6O48aPB4TfsLmKKA/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;线性回归的部分转换数据&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们也可用之前准备好的系数为这个数据集做预测。predict() 函数测试如下。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8NbZiajJf2Jw76YKNqaia1Ft5ryKBia4vTvTO3FYeB6icIglA4e0aOVicy1aKeYuZuCkMiaKXIyzYvjibEg/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;单个输入值 (x) 和两个系数（b0 和 b1）。用于建模该问题的预测方程为：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;y = b0 + b1 * x&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;或者，手动选择特定系数：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;y = 0.4 + 0.8 * x&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;运行此函数，我们将得到一个相当接近预测值的输出值（y）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Expected=1.000, Predicted=1.200&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Expected=3.000, Predicted=2.000&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Expected=3.000, Predicted=3.600&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Expected=2.000, Predicted=2.800&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Expected=5.000, Predicted=4.400&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在我们可以用随机梯度下降来优化我们的系数值了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2. 估计系数&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们可以使用随机梯度下降来为我们的训练数据估计系数值。随机阶梯下降需要两个设定参数：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;学习率（Learning Rate）：用于限制每次更新时被修正的系数的数量。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Epochs：更新系数的同时运行训练集的次数。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这两个值和数据集都是函数的参数。我们的这个函数将执行三个遍历循环：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 单次 epoch 循环&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 单次 epoch 中训练集中的每行循环&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 单次 epoch 中每个系数循环并为每一行更新它&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;可以看到，每次 epoch，我们都会更新数据集里每行的系数。系数的更新是基于模型生成的误差。该误差被算作候选系数的预测值和预期输出值之间的差。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;error = prediction - expected&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有一个系数用于加权每一个输入属性，这些属性将以连续的方式进行更新，比如&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;b1(t+1) = b1(t) - learning_rate * error(t) * x1(t)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;列表开始的特殊系数，也被称为截距（intercept）或偏差（bias），也以类似的方式更新，但因其不与特定输入值相关，所以无输入值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;b0(t+1) = b0(t) - learning_rate * error(t)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在我们把所有东西组合在一起。coefficients_sgd() 函数正是用随机梯度下降来计算一个训练集的系数值，下面即是该函数：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8NbZiajJf2Jw76YKNqaia1FtDulVfZTppy4QB1mQTORCiaabv9afmibq2cvwskTQLOuSfVZWx9QMnZSQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此外，我们追踪每个 epoch 的方差（正值）总和从而在循环之后得到一个好的结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8NbZiajJf2Jw76YKNqaia1Ftd93eiaKWjJCDHWEKbHP6U2kM909QeuFcC8N2vYg1C0SQeJ83o6jKufQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们用 0.001 的学习速率训练该模型 50 次，即把整个训练数据集的系数曝光 50 次。运行一个 epoch 系统就将该次循环中的和方差（sum squared error）和以及最终系数集合 print 一次：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;gt;epoch=45, lrate=0.001, error=2.650&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;gt;epoch=46, lrate=0.001, error=2.627&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;gt;epoch=47, lrate=0.001, error=2.607&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;gt;epoch=48, lrate=0.001, error=2.589&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;gt;epoch=49, lrate=0.001, error=2.573&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;[0.22998234937311363, 0.8017220304137576]&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;可以看到误差是如何在历次 epoch 中持续降低的。或许我们可以增加训练次数（epoch）或者每个 epoch 中的系数总量（调高学习速率）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尝试一下看你能得到什么结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在，我们将这个算法用到实际的数据当中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3. 葡萄酒品质预测&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们将使用随机阶梯下降的方法为葡萄酒品质数据集训练一个线性回归模型。本示例假定一个名为 winequality—white.csv 的 csv 文件副本已经存在于当前工作目录。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先加载该数据集，将字符串转换成数字，并将输出列从字符串转换成数值 0 和 1. 这个过程是通过辅助函数 load_csv()、str_column_to_float() 以及 dataset_minmax() 和 normalize_dataset() 来分别实现的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们将通过 K 次交叉验证来预估得到的学习模型在未知数据上的表现。这就意味着我们将创建并评估 K 个模型并预估这 K 个模型的平均误差。辅助函数 cross_validation_split()、rmse_metric() 和 evaluate_algorithm() 用于求导根均方差以及评估每一个生成的模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们用之前创建的函数 predict()、coefficients_sgd() 以及 linear_regression_sgd() 来训练模型。完整代码如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;# Linear Regression With Stochastic Gradient Descent for Wine Quality&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;from random import seed&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;from random import randrange&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;from csv import reader&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;from math import sqrt&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;# Load a CSV file&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;def load_csv(filename):&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;dataset = list()&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;with open(filename, 'r') as file:&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;csv_reader = reader(file)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;for row in csv_reader:&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;if not row:&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;continue&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;dataset.append(row)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;return dataset&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;# Convert string column to float&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;def str_column_to_float(dataset, column):&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;for row in dataset:&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;row[column] = float(row[column].strip())&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;# Find the min and max values for each column&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;def dataset_minmax(dataset):&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;minmax = list()&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;for i in range(len(dataset[0])):&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;col_values = [row[i] for row in dataset]&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;value_min = min(col_values)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;value_max = max(col_values)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;minmax.append([value_min, value_max])&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;return minmax&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;# Rescale dataset columns to the range 0-1&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;def normalize_dataset(dataset, minmax):&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;for row in dataset:&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;for i in range(len(row)):&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;row[i] = (row[i] - minmax[i][0]) / (minmax[i][1] - minmax[i][0])&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;# Split a dataset into k folds&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;def cross_validation_split(dataset, n_folds):&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;dataset_split = list()&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;dataset_copy = list(dataset)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;fold_size = len(dataset) / n_folds&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;for i in range(n_folds):&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;fold = list()&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;while len(fold) &amp;lt; fold_size:&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;index = randrange(len(dataset_copy))&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;fold.append(dataset_copy.pop(index))&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;dataset_split.append(fold)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;return dataset_split&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;# Calculate root mean squared error&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;def rmse_metric(actual, predicted):&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;sum_error = 0.0&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;for i in range(len(actual)):&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;prediction_error = predicted[i] - actual[i]&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;sum_error += (prediction_error ** 2)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;mean_error = sum_error / float(len(actual))&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;return sqrt(mean_error)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;# Evaluate an algorithm using a cross validation split&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;def evaluate_algorithm(dataset, algorithm, n_folds, *args):&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;folds = cross_validation_split(dataset, n_folds)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;scores = list()&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;for fold in folds:&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;train_set = list(folds)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;train_set.remove(fold)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;train_set = sum(train_set, [])&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;test_set = list()&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;for row in fold:&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;row_copy = list(row)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;test_set.append(row_copy)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;row_copy[-1] = None&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;predicted = algorithm(train_set, test_set, *args)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;actual = [row[-1] for row in fold]&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;rmse = rmse_metric(actual, predicted)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;scores.append(rmse)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;return scores&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;# Make a prediction with coefficients&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;def predict(row, coefficients):&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;yhat = coefficients[0]&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;for i in range(len(row)-1):&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;yhat += coefficients[i + 1] * row[i]&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;return yhat&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;# Estimate linear regression coefficients using stochastic gradient descent&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;def coefficients_sgd(train, l_rate, n_epoch):&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;coef = [0.0 for i in range(len(train[0]))]&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;for epoch in range(n_epoch):&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;for row in train:&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;yhat = predict(row, coef)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;error = yhat - row[-1]&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;coef[0] = coef[0] - l_rate * error&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;for i in range(len(row)-1):&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;coef[i + 1] = coef[i + 1] - l_rate * error * row[i]&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;# print(l_rate, n_epoch, error)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;return coef&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;# Linear Regression Algorithm With Stochastic Gradient Descent&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;def linear_regression_sgd(train, test, l_rate, n_epoch):&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;predictions = list()&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;coef = coefficients_sgd(train, l_rate, n_epoch)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;for row in test:&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;yhat = predict(row, coef)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;predictions.append(yhat)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;return(predictions)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;# Linear Regression on wine quality dataset&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;seed(1)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;# load and prepare data&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;filename = 'winequality-white.csv'&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;dataset = load_csv(filename)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;for i in range(len(dataset[0])):&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;str_column_to_float(dataset, i)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;# normalize&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;minmax = dataset_minmax(dataset)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;normalize_dataset(dataset, minmax)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;# evaluate algorithm&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;n_folds = 5&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;l_rate = 0.01&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;n_epoch = 50&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;scores = evaluate_algorithm(dataset, linear_regression_sgd, n_folds, l_rate, n_epoch)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;print('Scores: %s' % scores)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;print('Mean RMSE: %.3f' % (sum(scores)/float(len(scores))))&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个等于 5 的 k 值被用于交叉验证，给每次迭代 4898/5 = 979.6（低于 1000 都行）条记录来进行评估。对一个小实验选择了 0.01 的学习率和 50 训练 epoch.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你可以尝试你自己的配置，看你能否超过我的分数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;运行这个样本，为 5 次交叉验证的每一次 print 一个分数，然后 print 平均均方根误差（RMSE）。我们可以看到（在归一化的数据集上）该 RMSE 为 0.126。如果我们只是预测平均值的话（使用 Zero Rule Algorithm），那么这个结果就低于基准值 0.148。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Scores: [0.12259834231519767, 0.12733924130891316, 0.12610773846663892, 0.1289950071681572, 0.1272180783291014]&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Mean RMSE: 0.126&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;扩展&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里给出了一些扩展练习，你可以思考并尝试解决它们：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;调整该实例。调整其学习率、epoch 的数量甚至原始数据处理和准备的方法，以期能提高终结果。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;批量进行随机梯度下降。改变随机梯度下降算法使其在每个 epoch 上累积更新，且仅在 epoch 结束时批量更新系数。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;额外的回归问题。应用该技术来解决 UCI 机器学习库中的其它回归问题。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你会探索这些扩展任务吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;回顾总结&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本教程介绍了如何用 Python 实现带有随机梯度下降的多元线性回归算法。其中包括：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如何对多元线性回归问题做预测&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如何优化用于随机梯度下降的系数设置&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如何将该方法用于实际的回归预测模型问题&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 31 Jan 2017 11:27:32 +0800</pubDate>
    </item>
    <item>
      <title>回顾 |深度专访樊麾：AlphaGo可能会发现另外一种围棋的美，是我们想象不到的</title>
      <link>http://www.iwgc.cn/link/4530411</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：赵巍、赵云峰、Rita&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Libratus 在德扑大赛中首次战胜人类顶级选手。这是继人机象棋大战之后人工智能对抗人类的又一次里程碑式的胜利。在此，我们回顾一篇机器之心对樊麾老师的专访。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz/KmXPKA19gWicPUaa5HgIxfuVGU2ichHgmFaOcES55lFOmF4t5wT7PXC94yEI2yNE3iaeKvD1njibagJ4uwSM3OHwSQ/640?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;span&gt;樊麾接受机器之心专访&lt;/span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;对弈AlphaGo&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;●&lt;span&gt;●●&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;“&lt;/em&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;AlphaGo 没有人类棋手般心理的感觉，它就是一个虚无，但它却完全能把握住你的性格，这是不对等的。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：是什么契机让你和 AlphaGo 开始的这场对弈？有没有一些比较有趣的事情？&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;樊麾&lt;/strong&gt;：去年8月份，我去捷克一个小镇参加一年一度的欧洲围棋大会（欧洲冠军杯），15号左右结束比赛回到波尔多开始度假。之后不久的8月底9月初，我就收到英国 DeepMind 的一封邮件，询问我是否有兴趣去 DeepMind 公司参观。当时我对 DeepMind 这家公司还没有什么概念，但我的性格是比较开放的，于是就同意了。在 Skype 交流之后，我知道他们是一家谷歌旗下的做人工智能研究的公司，聊天时他们提到说正在研究一个跟我相关且非常有趣（ exciting，DeepMind 原话）的项目，但当时并没有告诉我此行目的，甚至没有提及具体的东西，自然也没有提到 AlphaGo。我和他们签署了保密协议，之后就发生了后来的事情（和 AlphaGo 比赛）。由于保密协议，有些细节我肯定无法透露，但我猜测他们之所以找我是和欧洲比赛成绩有关——我是欧洲最近三年的冠军。他们找测试对象的话，需要找一个职业棋手，其次需要有一个头衔，最后离他们又不是很远。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;我跟 AlphaGo 的比赛是在2015年10月份，我当场知道结果，见识了它有多厉害，但全世界都还不知道，我也不能对任何人讲。这期间，有两件事情很有意思。一是，当时我回国观看了一场围棋计算机比赛，觉得这套系统的水平根本无法和 AlphaGo 相提并论，但我不能说；另一件事是去年11月份，有位业余七段的韩国老师，在欧洲也算比较顶尖的棋手，他说他前段时间跟那个 Crazystone 下棋，他在让3子的情况下轻松获胜，说虽然人工智能进步很快，但距离人类还挺远，等等。我当时也只能憋着。也不仅仅是他，当时大家都比较保守，认为围棋程序击败人类还需要再等10年，但没想到现在就实现了。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：最初你是去参观，后来才得知他们的人工智能系统要与你对战。你当时会有顾虑么？有没有想过，万一我输了怎么办？有没有因此想去拒绝这场对决？&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;樊麾&lt;/strong&gt;：谁也没法保证长胜不败，我肯定有想过输的问题。但我之所以接受他们的邀请，首先是觉得自己输的可能性不是很大；其次，如果真的输了又会怎么样？结果对我来说没有决定性的意义，我也不是那么害怕输的人，只要下棋就都会有输赢，不管和谁下都是如此。但我尽全力去下，如果能赢当然更好，但输了也正常。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;小时候我父亲给我讲过很多类似的东西，比如李昌镐的相关报道。李昌镐也担心会输棋，但他的想法很简单——自己安心下好每步棋就行了。所以这盘棋我最后是赢还是输并不重要。其实这么多年，我在欧洲比赛也是一直抱着这种心态，所以没关系。反倒是 DeepMind 当时很谨慎，他们跟我提出比赛时很担心我会拒绝，因为这对于他们来说只是一个研究课题，而我是职业棋手，万一输了会把我的整个名誉压上去。我那时候就跟他们说，你们也不用担心，对于棋手来说，胜负都很正常。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：但这毕竟不是一般的围棋赛，你在下这五盘棋的过程中心态是怎么样的？是有一种很强的压力？还是说比较放松，是以一种平常的心态去对待这次人机大战？&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;樊麾&lt;/strong&gt;：作为一个职业棋手，只要是有胜负关系的比赛，我是绝对不会想输的，一定尽自己所能去赢下这盘棋。现在网上有很多观点，比如说我在比赛中放水等等。我不想对此进行评价，但有一点值得说明，我在下第一盘棋时确实有轻敌的成分在里面，我想到对手是人工智能，而且需要下五盘，所以我想第一盘棋我下得简单一些，之后再寻找别的东西，如果第一盘赢得很轻松，那我就知道该如何去压制住他，如果进展的不顺利，我随时可以变回来。而且我觉得在下围棋时大局观很重要，形势判断是最难的，那么，我下一个比较简明的棋，它是很不容易判断出来的，这是我当时的想法。但它的很多招法让我非常惊讶，至少没有那些很奇怪的电脑招，它在形势判断等各方面都表现得很出色。直到我出完错之后，我就没有机会了，在出错之前，我一直认为我是会赢的，但是一出错我就知道自己要输了，它后面对官子的把控也让我很惊讶。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;第一盘的错误就是有个「手筋」，我当时漏掉了，导致我目数亏损很多，但还不至于决定输赢。那个「勺子」按道理来说是不难察觉到的，但当时我觉得形势比较顺，认为自己要赢，就没注意。但当那这个「勺子」出来之后，我就知道自己可能要输了，这局往下我就没有什么机会了。这是第一盘棋，我没怎么在意，DeepMind 那边倒是格外关注。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;第一盘结束之后我当时的心情非常不好，为什么呢？道理很简单——电脑第一次分先打败职业棋手，这是个历史时刻，这是以前从来没有过的事情，但我是真真正正的输了。不是说这个问题有多严重，而是说我就是感觉下不过它，当我出现第一个错误就来不及了。之后也出现了一些心态问题，第二盘开始，我改变策略，设计了一些复杂的变化和它进行博弈。第一个定式是大雪崩，这是围棋最复杂的变化之一，当时我占到便宜了，但问题在于下到中盘时，我又打了一个「勺子」，并且又被它抓住了。它抓我的错抓得特别准，只要一抓住我就跑不掉，而且只要我一犯错，棋局就进入它的轨道了，我就再也翻不了身了。后面每盘棋基本都是按照同样的步骤走下去的，但它没犯什么错。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz/KmXPKA19gWicPUaa5HgIxfuVGU2ichHgmF0r3szf21KctAyoRyXTqvsaLaWpc0RZ4njryXT9ITeLVKd8B3S534Qw/0?"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;樊麾与 AlphaGo 对战棋局&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：当你感觉良好的那个阶段，基于对你全盘的估计，如果当时不犯错误的话，那一盘的争夺对它来说会不会非常艰难？&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;樊麾&lt;/strong&gt;：非常艰难。但最大的问题在于人都会犯错，而机器犯错几率比人少得多。所以到后来，这是一种负担，对我来说，我的形势不管好还是不好，我都担心自己犯错，但它没有这概念，这也导致了我的心态逐渐开始失衡。在我优势时，我不认为自己能把握住优势；在我劣势时，我又认为自己一定会输，这个棋就影响到我的发挥了。为什么大家看到我当时棋下的不是很好？因为对于一个下过很多比赛的职业棋手来说，比赛过程中的发挥跟你的水平往往不成正比，因为你会有心态的问题。比如说当年击败众多高手的李昌镐，他被称为「石佛」，就是因为他心态特别好，面无表情，你感觉不到他的任何波动。但我想说的是，谁能比电脑更「石佛」啊，当「石佛」对上电脑他就不叫石佛了，对面那个才是真正的面无表情，你跟它下到后来就很难受。没有人类棋手般心理的感觉，它就是一个虚无，但它却完全能把握住你的性格，这是不对等的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：比赛中有没有出现这样一种情况？实际上你犯了一个小错，并且不是特别容易发现，但它没有找到。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;樊麾&lt;/strong&gt;：有。但是这种情况，但我认为不是它没有发现，而是它不想抓我，即便它不抓我，它也赢。在第三盘棋中，有一块棋我是死棋，它很简单就能吃我，但却没有吃，让我活了。如果当时它吃我会有一点点风险，棋局会变的更加复杂，但它不吃我，它就会很轻松的赢下这盘棋，最终它选择了一种更稳妥的策略，选择了轻松获胜。后来有围棋节目对我们的比赛进行复盘，一位专业棋手也是认为当时电脑知道怎么杀我，而它没有杀。因为在实战中，它放我活之后没几个棋我就认输了。它如果不放我活，那我可能还会继续战斗下去，棋局就会出现一些复杂变化。就像柯洁所说，他也看不出来是你还是电脑。谁也看不出来。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：它的错在你看来严重吗？五盘棋下来它犯的哪些错误你觉得比较重要？一共出现了几次？&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;樊麾&lt;/strong&gt;：我签的保密协议涉及这些内容，无法回答。但可以请其他专业棋手去分析这个问题。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;冠军棋手眼中的围棋人工智能&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;●&lt;span&gt;●&lt;/span&gt;●&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;“&lt;/em&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;AlphaGo 可能开辟出另外一种围棋的美，是我们想象不到的。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：你之前和电脑程序下过棋吗？&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;樊麾&lt;/strong&gt;：差不多10年前，有一个法国团队开发了一个叫 mogo 的围棋程序，当时用的是蒙特卡洛方法，就不是很强。我们当时下九乘九的，一台电脑连着里昂的一个中心服务器，刚开始时候机器正常运转，到攻杀时就突然就转的特别快，我说这原来它还是有「脑子」的，因为我觉得这真的跟大脑在转一样。这是我第一次跟它下，下了3-4盘到我输了1盘。这是因为棋盘是九乘九，我对此没有概念，一开始下的不太熟悉，下两盘我就知道怎么下了，它就下不过我了，这就是人对新规则的适应能力。比如说我们把棋盘改成20乘20，一开始电脑可能会比较强，但在下个几盘之后可能人就厉害了，但是再下个成千万盘之后肯定又是电脑会赢。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：有一位挪威的国际象棋天才少年 Magnus Carlsen 说，国际象棋程序的走法，你能明显的感觉就是电脑的招数，但你在跟 AlphaGo 的对弈过程中是不是没有感觉出那种特别计算机的招数？&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;樊麾&lt;/strong&gt;：我在下棋时因为知道它是计算机，所以我会有代入感，所以我总觉得这步棋是计算机的招。但当后来我再去回顾时，那些（计算机的招）很少，可能有几招是错的，我之前认为只要是下得不好的棋，或者坏棋，那就是计算机的招。但其实这是不对的，后来再看这个棋，它只不过是走了错棋，它当然会犯错。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：这位国际象棋神童认为电脑的下棋风格一点都不优美。抛开它的强大不谈，你会认为它的下棋方式是优美的么？&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;樊麾&lt;/strong&gt;：讨论下棋方式是否优美，首先要回答围棋本质是什么。我在国外教围棋很多年，现在不光是搞比赛，还包括一些围棋讲座等围棋文化的传播，包括东方思维模式的传播等。那么围棋本身是什么？这是一个很深奥的哲学问题。围棋在中国来说是体育，是竞技，也是哲学，但我认为围棋本身就是一种游戏。任何一个东西，不管是一个竞技体育，还是人或者一个物种，它最深层的一个原则就是要生存。而围棋的生存力量非常强大，经过几千年，它依然能够顽强的生存在这个世界上，人们依然喜欢它，爱它。在电子产品、电脑游戏高度发达的今天，围棋依然有这么大的活力，就是因为它生存能力非常强。那什么叫生存能力呢？就是它能够适应所有或者说很广泛的对这种美的认识，所以说什么叫美？这个是一个比较虚幻的东西，当年黄龙士与古谱，他们认为这个叫美；围棋在日本被认为是一种功夫棋，这是一种平和的美和道的美；那现在围棋是一种竞技的美，它的美是在随时变化的，所以我很难评论说 AlphaGo 所下的美还是不美，因为它对我来说是一个全新的东西，它可能开辟出另外一种围棋的美，是我们想象不到的。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;我和很多朋友聊天时说，在 AlphaGo 出现的这一天，整个围棋界都会发生翻天覆地的变化，可能是坏的变化，也有可能是好的变化，这对不同人来说是不一样的，就看你怎么接受它了，它是个全新的事物。而围棋本身是没有变的，在法国和别人讨论时，我认为围棋不是人发明的，是人发现的。围棋规则其实很简单，一点也不神秘，第一点，下交叉点，中国象棋也是，但欧洲的棋类是下在格子里；第二点，4个子吃1个，这是规则，除此之后就没规则了，其他都不是规则，全都是必成现实，包括谁的空多谁赢。当然我是一个棋手，我有一种保护围棋的概念，我觉得围棋是一种发现，而并不是一种发明。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：除了围棋之外，比如说科学和数学，数学家会认为数学一些优美的定理实际上是我们发现，不是我们发明的。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;樊麾&lt;/strong&gt;：我也是这么理解，我觉得应该是发现，因为你没法发明这个东西，这个东西在宇宙中已经存在了，只不过你发现它而已。你可能将某些工具搭配在一起让它发挥出某种功能，这可能是一种发明，但是围棋中你没法发明，对它了解太少了，它只能是一种发现。通过这个 AlphaGo ，能够帮助人类更好的理解围棋到底是什么。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：你提到计算机没有情感，是真正的「石佛」，那比如说我们人类棋手都有各自的棋风和特点，你在跟 AlphaGo 下棋时，有没有感觉到它其实也有所谓的自己的棋风？&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;樊麾&lt;/strong&gt;：下到后来我总觉得它是有「感情」的，心里忍不住想骂他，它用同样的方式蹂躏我五盘，自己真的很不爽。但它具体靠什么棋风，由于保密协议我不能解释太多，我只能说它比较均衡。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：关于情感，你在接受 Nature 采访时说，你觉得主要问题在于人类会犯错误、会累，会因为求胜欲过强而感到压力，但计算机不是这样的，它强大且稳定，像一堵墙一样。但反过来说，人类作为一种情绪动物在某些情况下是否也会是一种优点？在下围棋是否也会起到一些正向的作用？有一位俄罗斯国籍象棋棋手，他有个特点，在棋局的收尾阶段他的情绪会上升到一种近乎狂妄的境界，那个时候他就超级自信，而这种情绪会把对手压得喘不过气来。在围棋中是否也会这样？&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;樊麾&lt;/strong&gt;：当两个个体都存在精神力量时，如果一方比较强大，对方肯定会承受很大压力，一个人超级自信，另外一个人并不自信，即便超级自信的人下的是不好的棋，那不自信的人也是扛不住的，这是有直接关系的。两方都在进行一场精神力量交战。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：计算机学习围棋时会用很多的棋局来进行训练，不同的棋风都能完美地融合在一起，取百家之长。但人类在这种信息整合和配合协调时可能不如机器，多个人配合下棋的效果可能会大打折扣，围棋中有这种现象吗？&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;樊麾&lt;/strong&gt;：围棋比赛中有一种叫联棋，二对二、三对三，或者男女混双，这种搭配在围棋文化传播上效果非常好，观赏性很强，而不稳定性也很强。二对二和三对三下的水平跟一对一是不能成正比的，差很多。因为每个人有自己的风格和想法，很难配合。另外一个原因是我们对围棋的了解太少了。当年日本棋圣藤泽秀行老师接受采访时说：我对围棋的理解就5%。5%是什么概念？是人类经过几千年的沉淀下来5%。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：你在接受 Nature 采访时提到「棋如人生，围棋是生活的写照，如果棋下得不好，可能是生活出了问题。」对于 AlphaGo 来说，你认为它是拥有什么样的「人生」，它是一个什么样的「人」？&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;樊麾&lt;/strong&gt;：这个问题挺有意思。这还是关于心态的问题，这个世界有一种人，你跟他说话他不理你，你打他骂他都不理，他无视你的存在。我在采访时把它形容为一堵墙，这个墙的概念是什么呢？就是它不动，你对它施展任何压力它都会反弹给你，你对它施加的所有力量，你对它所有的辱骂也好，对它所有的微笑也好，最后全反馈到你自己身上，这是我对 AlphaGo 的感觉。我重复用「墙」这个字，你可以说它完全没有感觉，也可以说感觉无限大，这是一个很奇怪的东西。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz/KmXPKA19gWicPUaa5HgIxfuVGU2ichHgmF4Uf5fe5P9ic3ViafTibAOuh4LeLUYfjxWEJRso3E4vTM9qcibz8zrtkHMA/0?"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;AlphaGo的策略网络和值网络&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：如果有一天 AlphaGo 开放了，全世界的围棋爱好者都可以和它下棋，你到时候会不会也想继续和它下几盘？&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;樊麾&lt;/strong&gt;：当然想，不只是我想，不管是业余的，还是专业的，大家都想。有的人是说 AlphaGo 不行，有的人说想学两招。那时的 AlphaGo 就像是日本漫画《棋魂》里的主人公「佐为」。在漫画中，他是一个被封印在古老棋盘里的棋圣，直到有一天漫画的主人公小光无意间在旧仓库发现了这个带有血渍的棋盘。当他擦去棋盘上的血渍时，就解开了佐为的封印将他释放了出来。他是平安年间教过秀策下棋的棋士，后来变成鬼魂附着在棋盘上也是因为他对于围棋的热爱。小光本来不喜欢下围棋，但是只有他能看到佐为，佐为便慢慢得教他，后来小光终于成为了一名职业棋手。这个动漫在法国也非常火，法国的少儿电视台也会播放。我觉得这里面有一点特别好，就是小光后来变成职业棋手了。他对于围棋的理解，这里面竞技的感觉、棋手的执着、一下子都被激发出来了，这也是现代年轻人缺失的东西。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz/KmXPKA19gWicPUaa5HgIxfuVGU2ichHgmFyWFDJzic9VHz9o7iap7s9FLowgicugTtddsNqVx1ngp2RTzqgZQtqqXIQ/0?"/&gt;&lt;br/&gt;&lt;span&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;日本漫画《棋魂》主人公佐为&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;我觉得这个比喻很贴切，有一天 AlphaGo 就会成为所有人的「佐为」，你家里其实就有个「佐为」，当你想下棋的时候他可以帮你，告诉你该怎么下。「佐为」永远站在小光的背后，穿着平安年间棋士的和服，带着高高的礼帽手持折扇，他的世界里只有围棋。我觉得这很有意思。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：如果来围棋人工智能的运算能力和算法已经先进到可以打败九段，从某种意义上来说它可以超越人类一大截，那时你跟它下的结果总是会输，那你还愿意跟它下吗？&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;樊麾&lt;/strong&gt;：也许那时候下的方式就不一样了，我跟它下的目的就不是为了输赢了，而是一种学习或者寻找，因为围棋实在太难了。其他棋类可能有些固定的东西，但围棋可以说没有什么是固定的，连第一步下哪儿都不确定是好是坏，所有定式都会变化，今年是定式明年就不是，围棋变化太多。所以，电脑可以给我们一种新的思维模式，当我们认为好，它认为不好的时候，那是不是中间有什么原因我们没有找到？它是一种工具，可以给我们借鉴。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：那假定以后有一种技术，像科幻小说中的那样，通过人体植入芯片将人类和机器连接在一起，能让你在看到一盘棋后马上就「想」出一个赢率很高的方法，那你是想把这个芯片植入呢？还是依旧自己来下？&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;樊麾&lt;/strong&gt;：这方面我还是比较保守的。我看过很多类似的科幻小说和这方面的研究，好像挪威有个项目就是在做这个。我不太喜欢这个概念，人的身体是自然创造的，我对此不够了解，不敢进行过多评论，但我觉得这比较危险，也破坏了人类最自然的部分。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：现在出现了很强的围棋人工智能，那对于你来说，如果可以选的话，是想作为棋手下出这个年代最好的一场棋局？还是想去开发出一款能够下赢人类棋手的人工智能？&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;樊麾&lt;/strong&gt;：因为我是下围棋的，我不会搞计算机，所以可能还是下棋比较实在。棋手有一个基本素质，叫掌控能力，就是我们喜欢做我们能掌控的东西，不做在我们掌握范围之外的事情。比如下棋时，我知道在哪个局面下我更容易掌控，我就会选择在这个局面去下棋；哪个局面下我不擅长掌控，我会尽量避开它，这个是我们的一个职业习惯。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：&lt;span&gt;你和 AlphaGo 比赛结束后，国际围棋联合秘书长 Hajin Lee 说，我觉得围棋还有许多价值有待开发，也并不觉得人工智能能下过人类这件事在任何意义上让围棋「贬值」了。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;樊麾&lt;/strong&gt;：我同意她的说法。我听过很多说法，人工智能的发展对我们是有帮助的，不会让围棋贬值。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;棋如人生&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;●●&lt;/span&gt;●&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;“&lt;/em&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;span&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;围棋它太过简单，所以它太过复杂，它是一个终极的概念。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：你觉得下围棋哪种能力比较重要？比如说逻辑思维能力？&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;樊麾&lt;/strong&gt;&lt;span&gt;：围棋棋手的逻辑能力必须得强。此外，基于我对围棋的理解，还有特别重要的一点就是需要去换位思考，去想别人在想什么，这是最重要的。如果你不去想别人在想什么，光想自己想些什么，那是没法下围棋的。我一定要先想到别人的最佳手法，才能想到自己的最佳手法。围棋这个换位思考在某种意义上会锻炼我们。我现在不崇尚培养高顶尖棋手了，我喜欢搞普及。那么我总在想，我不是想需要什么菜下围棋，而是想下围棋能给我们带来什么东西，因为我觉得学习围棋其实是一个自我学习的过程，围棋像一面镜子，它会把你的所有缺点都照出来，通过它能改正自己，这个是最好的。我觉得下围棋不需要任何特殊才能，谁都可以下，我的感觉是30秒就能下围棋了，它是个游戏，你从游戏实践中学习到更多东西，而不仅仅是靠书本。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：许多围棋选手在回顾一生的各个阶段时，往往会觉得年轻时候的水平可能是最高的，那是不是因为年轻时他的大脑运算是最高效的。而 AlphaGo 作为一种程序运算效率也特别高，那它的这种强大是不是可以和人类棋手进行一种类比，人类在有着高水准表现时也是靠着我们的「硬件运算能力」，所以有些人对计算机依靠纯计算能力的批评，是不是也在批评我们自己？&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;樊麾&lt;/strong&gt;：我是认为人在年轻时并不仅仅依靠运算，为什么？要明白一个道理，为什么年轻时最强？除了运算能力之外，还因为那时你的脑子是心无旁骛的，比如你「硬件」的能力是100%，在你年轻时可能调动起来80%的，随着年龄的增长你会接触到社会上很多很多事情，拿1%去干这个，1%去干那个。这可能是无意识的，你认为我在认真下棋，但实际上你不可能认真下，因为你意识已经跑出去了，去考虑家庭、社交等问题。你会担心名誉和金钱，这些东西会把你的80%变成60%，变成40%、30%，并不是你不想用，而你是用不了，你的 CPU 已经被占用了，里边有太多程序了，就是这个概念，这跟人的生理有关系，跟整个社会有关系。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：许多专业棋手会谈论下棋的「直觉」，或者一种灵光一现的感觉，包括连 DeepMind 也在谈论这个话题。那这种灵感或者直觉的培养，你觉得是一个线性的经验和知识的积累过程？还是有点像禅宗里的那种顿悟？你是经过一个怎样的路径进入到这种状态的？&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;樊麾&lt;/strong&gt;：这个牵扯的就比较广泛，我想有些东西是天分，围棋肯定要靠天分。另外一个就是跟自己的生活有一定关系，你经历过多少东西，你对生活的认识和理解都能原原本本的反映到你的围棋上面。当然，这不代表你经历的多棋就会更厉害。有时候经历的少反而效果会更好，因为更单纯、更直接。而对于围棋也不一定都是追求有多厉害，每个人的理解不同，有的人是追求一种对围棋的理解和快乐。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;那种灵光一现的感觉我想无非就是一种自我满足感和成就感，一种可持续的精神上的高潮。那要达到这个点的可能就需要一种积累的过程。禅宗里讲，你看过很多树、很多花，扫很多地、做很多饭、挑很多水，你走的多了看的多了突然间就顿悟了，我很喜欢这些故事，里面讲到很多种顿悟都是一个积累。没有人突然间顿悟到什么，它是一点一点积累。在围棋中也是这样，很多我的学生经历一年学习也感觉不到长棋，我说你不要着急，就相当于一个瓶子的水一样，水积在瓶子里面，它顶这个瓶塞，你感觉这瓶水不出去为什么？因为它还堵在里面，这时不要着急，当水越积越多到一定压力就会把瓶塞顶出去，这时的进步就是种喷涌而出的感觉，是个进步的概念。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：围棋、国际象棋，甚至数学研究，这些往往被我们认为是人类顶级的智力活动。从事这些活动的人在我们眼里是一种天才，或者特别高智商的人。但我们观察这类智力活动的发展过程，我们看到的一个模式就是需要在很年轻的时候去培养这个能力。比如说成年之后去学围棋，可能就只能当做兴趣了，已经无法取得重要成就了。这是和小孩的大脑可塑性强有关系吗？或者是你刚才提到的小孩的一种「纯洁的心态」？&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;樊麾&lt;/strong&gt;：我是搞教育的，可以解释一下这个问题。不管是从各方面，学语言还是学围棋，都是小孩学的比成人快，为什么？道理很简单，我给儿童教一个东西，不管是什么东西，他会去用，当发现不行会去纠正。那么成人会怎么样？成人说好，我会去用。但有的时候他不会用，他会告诉你，我是想用来着，但这个地方有个这样的问题，我觉得可能不行，所以我才没有用。这个就像禅宗的一个概念，人就像一块海绵，随着年龄增长海绵的水会越来越满，所以当别人给你建议时，你是排斥的，即便他真觉得你是对的，但到时候还是不用。这是一种生理上的排斥，而不是思想上的。而儿童是一个更干净的海绵，往里滴多少水它全部可以吸收，所以他们接受东西是最快的。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;strong&gt;器之心&lt;/strong&gt;：按照你这个思考，如果一个人在精神上修炼到这种境界，可以在四五十岁时依然保持一种孩童般的心灵状态，那他是不是也可以保持年轻时的围棋水准，或者在艺术和数学方面的水准？&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;樊麾&lt;/strong&gt;：有很多人做到过这点，在围棋界有几个人我特别崇拜，比如当年的曹熏铉、赵治勋，他们在那个年龄依然能拿出那么多成绩，这在现在已经是不可能的事情了，因为社会发展太快，你再单纯、再保持专一，也很难达到那个时代的感觉。我想到40岁还保持纯净，这个真的做不到，因为你会被社会上很多新的东西把你渲染进去，这是人类必然经历的东西，就像我们发明电脑，我们需要工具，等等。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;strong&gt;之心&lt;/strong&gt;：你在讨论一些问题时，经常超越围棋本身去思考透过围棋所传递的那种价值观和道。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;樊麾&lt;/strong&gt;：其实我在欧洲这么多年，也是希望将围棋这种文化传递出去，而不仅仅是那些技艺，因为技术这东西总会有更新，就像 AlphaGo 这种，这是时间问题，而围棋所传承的其实是另一个文化，这是中国人发明的东方的思维模式。围棋追求的是一种「和」的精神，它不像国际象棋，最终的目的不是去擒王。围棋没有棋王，在一个权力一直存在的社会，围棋却没有权力之分，它所有的子都是均好的。而且围棋绝对是个团队游戏，国际象棋的子会越来越少，利用越少的子在发挥作用，而围棋的子会越来越多，围棋的子并不是我去发挥我现在要下这个棋子的威力，而是我怎么通过下这步棋让之前子的威力提升，这是最重要的概念——团队精神。所以围棋在这方面对于东方思维和西方思维都是有直接关系的。所以它的价值不仅仅是竞技，而是文化，它在各个方面都会发挥价值。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：那你觉得围棋教给你的东西，除了棋本身的优美和快乐，是不是也对你的生活、友情、爱情和亲情等方面带来了益处？&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;樊麾&lt;/strong&gt;：很多。作为职业棋手来说，围棋就是哲学，它真的是包罗万象，因为它太简单。我有一个理论，我认为所有东西越简单它就越厉害，一切所有最顶级的东西都是最简单的。围棋它太过简单，所以它太过复杂，它是一个终极的概念。我现在没有见过任何游戏能比围棋更简单。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：喆理围棋发起人李喆六段说，我们来到一个时代的交点，跳出（AlphaGo）奇迹而言，人工智能的一个重要价值便是帮助人类认识我们自身。你是否也通过这次和围棋人工智能的对战，对你的生活、棋艺或者人生产生了一些更加深入的理解？&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;樊麾&lt;/strong&gt;：我非常认同这个观点。我觉得人的生活中任何经历都会对你之后的生活产生一些影响并引起一些变化，人生中有很多阶段都挺重大的，这次经历重大到什么程度我现在还不知道，因为它正在发生着，所以我也不太了解。对我的棋艺，有一段时间我认为可能对我棋艺有帮助，然后紧接着又过了一段时间，我觉得可能对我的棋艺有害处，现在我又不清楚了。因为我经常给我的学生和朋友们讲，对于围棋，有段时间我会认为什么都懂，突然间豁然开朗，但过了半年，我会觉得自己什么都不懂了。这是个循环，我相信许多顶尖棋手也都有这种情况，只不过他们可能不这么表达。因为我需要讲棋，我先把我那个漆黑的东西讲出来，所以我就思考怎么表达它，我认为到了一定阶段，必然是个循环。这跟这个人的心态也是有关系的，在你自信时你认为你什么都懂，但当时你把这个慢慢沉淀之后，你还是不自信，你会发现其实你什么都不懂。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;当你在一个庞大的世界中发现了一扇门，你会觉得你好像什么都懂了，但当你再打一扇门，你会发现原来还有这么大的天地，这就是围棋里道的概念，它是循环复始的，而且你会很喜欢这个过程，这个过程很舒服，会给你带来一种自我满足、自我求知的感觉。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;●●&lt;/span&gt;&lt;span&gt;●&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©机器之心原创，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 31 Jan 2017 11:27:32 +0800</pubDate>
    </item>
    <item>
      <title>资源 | 如何自学数据科学？这21个课程能帮你入门数据科学过程</title>
      <link>http://www.iwgc.cn/link/4524079</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;作者David Venturi&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀、侯韵楚&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Class Central 的数据顾问（Data Consultant）David Venturi 近日分享了其对于自学数据科学的课程推荐，本文主要推荐了数据科学过程（data science process）的入门课程。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一年前，我从加拿大顶级的计算机科学课程之一退出，并利用在线资源开始创建属于自己的数据科学硕士课程。我意识到，通过 edX 、Coursera 以及 Udacity，我只需用成本的一小部分便可以更迅速、有效地学到我所需要的一切。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这门课程差不多要完成了。我修读过许多数据科学相关的课程，并了解更多的课程。我知道其中有什么选择，也清楚成为数据分析师或数据科学家所需要的技能。我在几个月之前开始着手创建一个能够为数据科学的每个主题推荐最佳课程的评审驱动指南。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关于系列的第一个指南，我为初学级的数据科学家推荐了编码类指南，然后是概率与统计类的指南：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;编码类：https://medium.freecodecamp.com/if-you-want-to-learn-data-science-start-with-one-of-these-programming-classes-fb694ffe780c#.42hhzxopw&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;概率与统计类：https://medium.freecodecamp.com/if-you-want-to-learn-data-science-take-a-few-of-these-statistics-classes-9bbabab098b9#.p7pac546r&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;现在来介绍数据科学&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于数据科学课程所介绍的一些内容若有不确定的地方也不用担心，稍后会做出解释。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了这本指南，我花了 10 多个小时搜集截至 2017 年 1 月提供的数据科学课程的每一个在线介绍，从它们的教学大纲和评论中提取关键信息并编辑评分。为了完成这个任务，我使用了开源的 Class Central 社区和它的具有数千课程评分与评论的数据库作为辅助。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Class Central 的主页：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;www.class-central.com&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自 2011 年以来，Class Central 的创始人 Dhawal Shah 一直比世界上任何人都密切关注在线课程，他亲自帮我列出了这份资源清单。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;我们如何选择课程&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;每门课程必须符合三个标准：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;它所教授的必须是数据科学过程（data science process），稍后会对其做出解释。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;它必须按需或每几个月来提供课程。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;它必须是一个交互式的在线课程，所以这里没有书或只读教程。虽然存在多种可行的学习方法，但本指南只专注于课程。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们认为这个指南涵盖了所有符合上述标准的重要课程。由于 Udemy 中存在数百个课程，所以仅选择了评论最多且评分最高的课程。但我们总会有可能错过一些优秀的课程，所以如果发现我们有所遗漏，请在评论区告知。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;我们如何评估课程&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了计算每个课程的加权平均评分，我们汇集了 Class Central 和其他评论网站的平均评分和评论数。同时我们阅读文本评论，以该反馈作为数字评分的补充。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们基于两个因素做出主观的大纲判断内容：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 数据科学过程的覆盖。课程是否略过了某些科目？它是否覆盖了某些科目过多的细节？请参阅下一部分来了解此过程的具体内容。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 通用数据科学工具的使用。课程是使用普遍的编程语言（如 Python 和/或 R）教授的吗？这些都不是必要的，但在大多数情况下有帮助，所以对这些课程稍作优先考虑。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibkgzQLGMwFy1N0wOZ7kQ0DsAtugX00C5SWLA23ezTmCWKctL2GF9quickpKh0ludiajdiak79hxhxpw/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Python 和 R 是数据科学中使用最普遍的两种编程语言&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;什么是数据科学过程（data science process）？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;什么是数据科学？数据科学家做什么工作？这些是数据科学课程介绍所应回答的基本问题类型。哈佛大学教授 Joe Blitzstein 和 Hanspeter Pfister 的以下信息对典型的数据科学过程进行了概述，这会帮助我们回答这些问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibkgzQLGMwFy1N0wOZ7kQ0DIwD1jCxBvlbXZh1bE1faIPVUpa2fNrmib3YCXIymN1tsSkaZNqE8Ffg/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;来自 Opera Solution 的可视化&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们对于数据科学课程介绍的目标是熟悉数据科学过程，并不想太深入地涵盖过程的具体方面，因此便停留在该标题的「介绍/入门（intro to）」部分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于每一方面，理想课程应该解释过程框架内的关键概念、介绍常用工具并提供一些示例（动手实践更佳）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们只是在寻找课程介绍，因此本指南不包括约翰·霍普金斯大学的 Coursera 数据科学专业（Data Science Specialization）或 Udacity 的数据分析师纳米学位（Data Analyst Nanodegree）等专业。这些课程的汇编并未包含这个系列的目的：为每个科目找到包括数据科学教育在内的最佳个人课程。本系列文章的最后三个指南将详细介绍数据科学过程的每个方面。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;基本编码、统计以及概率所需的经验&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面列出的课程需要基本的编程、统计和概率经验。这个要求可以理解，因为有些前沿科目通常包含几门专项课程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种经验可以从我们所推荐的数据科学职业指南的前两篇文章（编程、统计）中获得。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;我们选择的数据科学最佳入门课程是：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据科学 A-Z™：包含实际数据科学练习（Data Science A-Z™: Real-Life Data Science Exercises Included）（Kirill Eremenko/Udemy）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://www.udemy.com/datascience&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在我们量化评估的 20 个数据科学课程中，Kirill Eremenko 在 Udemy 上的 Data Science A-Z™ 在数据科学过程的广度和深度上都是确定无疑的赢家。在其 3071 个评价中，其获得了 4.5 的加权平均评分，这个课程是目前评分最高且评论数最多的课程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该课程概述了完整的数据科学过程并提供了实际的案例。而且该课程的长度为 21 小时，是一个非常合适的长度。评价者普遍很喜欢该导师的讲解以及课程的内容组织。该课程的价格会随 Udemy 的折扣政策而发生改变，你甚至有可能只需 10 美元就能学习该课程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管它并不检查我们的「常用数据科学工具使用」工具箱，但非 Python/R 工具选择（gretl、Tableau、Excel）在这一背景中得到了有效的应用。Eremenko 解释了选择 gretl 的原因（注：gretl 是一个统计软件包），尽管这个解释也适用于其使用的所有工具：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;使用 gretl，我们可以实现与使用 R 和 Python 一样的建模，但我们却不需要编写代码。这是很重要的。你们一些人可能已经对 R 非常了解了，但另一些人却可能对 R 一无所知。我的目标是让你了解如何构建一个稳健的模型以及给你一个你可以应用你所选择的任何工具的框架。gretl 将能帮助我们避免陷入写代码的麻烦中。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一位著名的评论者指出：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Kirill 是我在网上找到的最好的老师。他使用实际案例并会解释常见的问题，让你能对该课程有更深入的理解。他也提供了很多关于作为一位数据科学家意味着什么的见解，从如何利用不足分的数据一直到如何将你的成果展示给高管。我强烈推荐初学者学生到中等的数据分析师都学习这门课程。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;一个非常棒的以 Python 为中心的入门介绍&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据分析入门（Intro to Data Analysis（Udacity））：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://www.class-central.com/mooc/4937/udacity-intro-to-data-analysis&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Udacity 的 Intro to Data Analysis 是一个相对较新的课程，该课程也是 Udacity 受欢迎的数据分析师纳米学位（Nanodegree）课程中的一部分。它包含了清晰的使用 Python 的数据科学过程，尽管其在建模方面还有所欠缺。该课程估计需要 36 个小时的时间（每周 6 小时，一共 6 周）。尽管在我的经历中它要短一些。这个课程有一个 5 星的评价。它是免费的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该课程的视频制作精良，其导师 Caroline Buckey 的授课清晰明了。课程中大量的编程测验能够帮助强化在视频中学到的概念。学生肯定能够获得新的或提升过得 NumPy 和 Pandas 技能（NumPy 和 Pandas 都是流行的 Python 库）。其最后的项目（其会在纳米学位中得到评估和评价，但并不在这个免费的单独课程中）可以作为一个很好的额外补充。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;一个很不错但没有评价数据的课程&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据科学基础（Data Science Fundamentals (Big Data University)）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://bigdatauniversity.com/learn/data-science/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Data Science Fundamentals 是由 IBM 的 Big Data University 所提供了一个 4 个课程的系列课程。这四门课程分别是：Data Science 101、Data Science Methodology、Data Science Hands-on with Open Source Tools 和 R 101。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;数据科学 101（Data Science 101）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://bigdatauniversity.com/courses/data-science-101/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据科学方法（Data Science Methodology）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://bigdatauniversity.com/courses/data-science-methodology-2/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使用开源工具上手数据科学（Data Science Hands-on with Open Source Tools）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://bigdatauniversity.com/courses/data-science-hands-open-source-tools/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;R 101：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://bigdatauniversity.com/courses/r-101/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个系列课程包含了使用 Python 和 R 的完整数据过程，此外，这里还有上手的实验环境。这些课程有极大的生产价值。根据你是否选修最后的 R 101 课程（这个课程对于本指南的目的而言并不是必需的），这个系列课程的时间长度为 13-18 小时。不幸的是，在主要的网站上没有关于该课程的评价数据可供我们分析，所以我们不能基于评价做出推荐，不过这个课程是免费的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;比赛&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们的第一名选择的是有 3068 个评论给出了加权平均分 4.5 的课程。下面让我们看看其它选择，按降序排序。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你打算通过 R 语言入门数据科学，你还能在下面找到一些以 R 为重点的课程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据科学入门（Introduction to Data Science (Data Hawk Tech/Udemy）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://www.udemy.com/learn-data-science&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该课程覆盖了数据科学的全过程，尽管深度有限。该课程相当简短（仅有三小时内容）。其简要地覆盖了 R 和 Python。它有 62 个评分，获得了 4.4 的加权平均分。价格依 Udemy 的折扣而波动。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;应用数据科学：入门（Applied Data Science: An Introduction（Syracuse University/Open Education by Blackboard））&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://www.class-central.com/mooc/1806/open-education-by-blackboard-applied-data-science-an-introduction&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该课程覆盖了数据科学的全过程，但并不均匀。其重点关注了基础统计学和 R 语言。对于本指南的目的而言，应用太多，对数据科学过程的关注不够。网络课程体验有所脱节。它获得了 6 个评论，得到了 4.33 的加权平均分。免费。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据科学入门（Introduction To Data Science (Nina Zumel &amp;amp; John Mount/Udemy)）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://www.udemy.com/introduction-to-data-science&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本课程仅覆盖了部分过程，但在数据准备和建模方面有很好的深度。6 小时内容的长度也还不错。使用 R 语言。它获得了 101 个评论，得到了 4.3 的加权平均分。价格依 Udemy 的折扣而波动。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使用 Python 的应用数据科学（Applied Data Science with Python (V2 Maestros/Udemy)）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://www.udemy.com/applied-data-science-with-python&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该课程覆盖了数据科学的全过程，并在该过程的每个方面都有很好的深度覆盖。长度不错（8.5 小时内容长度）。使用 Python。它获得了 92 个评论，得到了 4.3 的加权平均分。价格依 Udemy 的折扣而波动。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibkgzQLGMwFy1N0wOZ7kQ0DUfiakNRuJEjF6wOicViaZ7DwQWic9dByVVicw0P735EPkGBN640rbvrb26Q/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;V2 Maestros 有两个 Applied Data Science 课程版本，一个针对 Python，一个针对 R&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Python 版：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://www.udemy.com/applied-data-science-with-python&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;R 版：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://www.udemy.com/applied-data-science-with-r&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;想成为数据科学家（Want to be a Data Scientist?）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://www.udemy.com/want-to-be-a-data-scientist&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该课程覆盖了数据科学的全过程，尽管覆盖深度有限。内容相当短，仅有 3 小时。有限的工具覆盖。它获得了 790 个评论，得到了 4.3 的加权平均分。价格依 Udemy 的折扣而波动。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据到见解：数据分析入门（Data to Insight: an Introduction to Data Analysis (University of Auckland/FutureLearn)）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://www.class-central.com/mooc/2129/futurelearn-data-to-insight-an-introduction-to-data-analysis&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;覆盖的广度不清楚。声称重点是数据探索、发现和可视化。并不按需提供。内容长度为 24 小时——分成 8 周，每周 3 小时。它获得了 2 个评论，得到了 4 的加权平均分。课程免费，也提供付费的认证。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据科学方向（Data Science Orientation (Microsoft/edX)）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://www.class-central.com/mooc/6405/edx-data-science-orientation&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该课程使用 Excel。不过鉴于该课程是由微软提供的，所以也能理解。课程长度为 12-24 小时（6 周，每周 2-4 小时）。它获得了 40 个评论，得到了 3.95 的加权平均分。课程免费，也提供 25 美元的付费认证。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据科学基础（Data Science Essentials (Microsoft/edX)）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://www.class-central.com/mooc/3954/edx-dat203x-data-science-and-machine-learning-essentials&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该课程覆盖了数据科学的全过程，而且在每个方面都有不错的深度。覆盖了 R、Python 和 Azure ML（这是一个微软的机器学习平台）。有很多 1 星评价是因为该课程选择了 Azure ML 且导师教得不怎么好。该课程长度为 18-24 小时（为期 6 周，每周 3-4 小时）。它获得了 67 个评论，得到了 3.81 的加权平均分。课程免费，也提供 49 美元的付费认证。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibkgzQLGMwFy1N0wOZ7kQ0DfmdkBuyzKKcAAsf79eTfhmSC2Z19SubA0pBupsgEUqg0S8fwjEXaIw/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以上两个课程来自微软在 edX 上的数据科学专业课程证书（Professional Program Certificate in Data Science）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://www.edx.org/microsoft-professional-program-certficate-data-science&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使用 R 的应用数据科学（Applied Data Science with R (V2 Maestros/Udemy)）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://www.udemy.com/applied-data-science-with-r&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;前面也提到了该课程的 Python 版本。该课程覆盖了数据科学的全过程，并在该过程的每个方面都有很好的深度覆盖。长度不错（11 小时内容长度）。使用 R。它获得了 212 个评论，得到了 3.8 的加权平均分。价格依 Udemy 的折扣而波动。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据科学入门（Intro to Data Science (Udacity)）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://www.class-central.com/mooc/1480/udacity-intro-to-data-science&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;部分过程覆盖，但在其选择的主题上都有很好的深度。缺少探索方面，尽管 Udacity 在探索数据分析（EDA）方面有一个很好的全覆盖的课程：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://www.class-central.com/mooc/1478/udacity-data-analysis-with-r&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;声称有 48 小时长度（为期 8 周，每周 6 小时），但我感觉要短一些。一些评论认为其缺乏高级内容。感觉组织不太好，使用 Python。它获得了 18 个评论，得到了 3.61 的加权平均分。免费。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibkgzQLGMwFy1N0wOZ7kQ0DW4iat37VB7f4m1evrl9MeO24UDuwNQByRGzm7zE7yiaZRLePQnOHmlibA/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使用 Python 的数据科学入门（Introduction to Data Science in Python (University of Michigan/Coursera)）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://www.coursera.org/learn/python-data-analysis&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;部分过程覆盖。没有建模和可视化，尽管密歇根大学在 Coursera 上教授的 Applied Data Science with Python Specialization：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://www.coursera.org/specializations/data-science-python&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;课程的 #2 和 #3 覆盖了这些方面。但那对于本指南的目标的深度就太深了。使用 Python。时长 4 周。它获得了 15 个评论，得到了 3.6 的加权平均分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据驱动的决策（Data-driven Decision Making (PwC/Coursera)）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://www.coursera.org/learn/decision-making&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;部分覆盖（缺乏建模），重点关注商业应用。介绍了许多工具，包括 R、Python、Excel、SAS 和 Tableau。长度 4 周。它获得了 2 个评论，得到了 3.5 的加权平均分。有免费和付费的选择。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据科学速成课程（A Crash Course in Data Science (Johns Hopkins University/Coursera)）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://www.coursera.org/learn/data-science-course&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个对于全过程的极简概览。对于本指南来说实在太简单了。时长 2 小时，它获得了 19 个评论，得到了 3.4 的加权平均分。有免费和付费的选择。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据科学家工具箱（The Data Scientist』s Toolbox (Johns Hopkins University/Coursera)）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://www.coursera.org/learn/data-scientists-tools&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个对于全过程的极简概览。可看作是约翰·霍普金斯大学 Data Science Specialization 课程：https://www.coursera.org/specializations/jhu-data-science&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;的基础课程。声称有 4-16 小时内容（4 周，每周 1 到 4 小时），但有一位评论者说这个课程可以在 2 小时内学完。它获得了 182 个评论，得到了 3.22 的加权平均分。有免费和付费的选择。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据管理和可视化（Data Management and Visualization (Wesleyan University/Coursera)）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://www.coursera.org/learn/data-visualization&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;部分覆盖（缺乏建模），长度 4 周。有很好的生产价值。使用 Python 和 SAS。它获得了 6 个评论，得到了 2.67 的加权平均分。有免费和付费的选择。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面的课程截至 2017 年 1 月还没有评价。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibkgzQLGMwFy1N0wOZ7kQ0Dv2qgRe9N7nE5XDyc0zbLicdeDia2VWyTeb5KIdxTjARsXynic7Mu07acQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;CS 109 数据科学（CS109 Data Science (Harvard University)）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;http://cs109.github.io/2015/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;全过程覆盖，深度也很棒（对本系列来说也许太过深度了）。一个 12 周全时长的研究生课程。课程方向很难，因为其并不是为在线使用而设计的。这是哈佛大学课程的实际录像。上面的数据科学过程信息图就来自这个课程。使用 Python。免费。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;用于商业的数据分析入门（Introduction to Data Analytics for Business (University of Colorado Boulder/Coursera)）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://www.coursera.org/learn/data-analytics-business&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;部分过程覆盖（缺乏建模和可视化方面），重点关注商业。在这个课程中，数据科学过程被称为「信息-行动价值链（Information-Action Value chain）」。时长 4 周。描述了多种工具，尽管仅深度覆盖了 SQL。有免费和付费的选择。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据科学入门（Introduction to Data Science (Lynda)）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://www.lynda.com/Big-Data-tutorials/Introduction-Data-Science/420305-2.html&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;完全过程覆盖，尽管覆盖深度有限。相当短，仅有 3 小时内容。介绍了 R 和 Python。费用由 Lynda 订阅确定。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文链接：https://medium.freecodecamp.com/i-ranked-all-the-best-data-science-intro-courses-based-on-thousands-of-data-points-db5dc7e3eb8e#.4xypnelbl&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 30 Jan 2017 13:38:10 +0800</pubDate>
    </item>
    <item>
      <title>观点 | 人工智能的开源模式已经过时，我们需要新的开源模式</title>
      <link>http://www.iwgc.cn/link/4524080</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Techcrunch&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：朱思颖、Jane W&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibkgzQLGMwFy1N0wOZ7kQ0DW2icpAtPygV56ibRibwI2kqVCuKOvlL3mYjzib05d1Bibqftu5E2mkG729g/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能是一个大的领域，并且领域范围还在继续扩大。有机器学习相关经验的企业期望在人工智能的技术上占领先机。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;还没有构建出自己机器学习业务专长的企业正急于理解和策划自己的机器学习和人工智能战略。在当下人工智能的浪潮中，困惑、妄想、落后的风险以及谷歌、Facebook、百度和微软这些公司做了大量的开源（如 TensorFlow、BigSur、Torch、SciKit、Caffe、CNTK、DMTK、Deeplearning4j、H2O、Mahout、MLLib、NuPIC、OpenNN 等项目）提供进军人工智能和机器学习的一个显而易见的方式，尤其是对人工智能技术行业之外的企业而言。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;找到开源项目、下载、安装... 这个过程应该是很容易。但并不是如大家所想的那般容易。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前的开源模式（Open Source model）是过时的且不能满足由人工智能驱动或影响的系统所主导的环境下软件之间的共享。在人工智能驱动的系统所主导的环境中，理论上用户可以在一天之内与成千上万的人工智能引擎交互。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;仅靠人工智能和机器学习的先驱们分享他们的代码是远远不够的。工业界和整个世界需要一个新的开源模式，这个新开源模式能够实现人工智能和机器学习所训练的引擎自身同数据、特征以及真实环境下的表现细节一同开源。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;目前的开源模式能力不足并且已过时&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由人工智能和机器学习驱动（作用）的系统与运用开源组件构建的其它软件是不同的。运用开源组件构建的软件仍然具备「确定性」特质，例如软件的设计和编写都是为了保证每次按照相同的方式运行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能或者机器学习系统（尤其是人工智能系统）并不一定具备这样的「确定性」表现。在应用于和学习新情境（新环境或者新用户）时，这些系统能够改变自己的行为表现。本质上说，当人工智能系统应用于真实世界时，人工智能系统的构建者就失去对所构建系统的控制。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然，创建者可以在学习框架中构建制衡的机制，然而，即使是在人工智能系统所设定的限制下，仍然还会有大量不同的解释。与此同时，面对一个由人工智能所包围的世界的更大挑战来自已证实的冲突——这些限制中人的作用因素。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最近的一个对梅塞德斯主席 von Hugo 报道中引用了其所说「梅塞德斯的无人驾驶汽车将会优先保护车上乘客而不是行人」，尽管事后公司表明报告中对 von Hugo 的引用有误，但仍然揭露出一个根本性问题——资本主义将如何作用设置于人工智能中的限制。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibkgzQLGMwFy1N0wOZ7kQ0DqJuOwMT2y5hN8XpPsl8njG4tMK1q92N0Rr6FYvXZsEibRcQj266tL0g/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;资本主义和人工智能的道德伦理&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果一个企业的目的是实现盈利，在产品和服务开始进入市场前所需要的时间是否表明基于人工智能的经验可以作为一个附加值、差异化体验来要求顾客为这项技术额外付费？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这种情况下，原意并且具备差异化体验付费能力的用户将会获得比普通用户更多的好处。因为企业将会尝试和收回在人工智能上的投入成本，这项技术将只限于给能负担这项技术的用户群体使用。这将会导致人工智能系统的限制设置有利于（保护或者提供优先权）那些能够负担得起的用户。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外一个担忧是法律和政策方面的问题——谁将对人工智能或者机器学习驱动的产品故障（次优）行为负责。由用户、服务提供商、数据科学家或者人工智能引擎负责？这个责任（过失）怎么确立？要回答这些问题需要对创建和使用人工智能以及机器学习的一系列过程有清晰的描述和跟踪。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;人工智能到人工智能的交互&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibkgzQLGMwFy1N0wOZ7kQ0DnibLDjXbKrxMBAC7yh5XpxHKjkeibJ23tNxzB8zQK0dnWqwibLH053jCA/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;一张三维渲染图：一个机器人尝试解决木块拼图问题&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能-人工智能冲突&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;考虑到人工智能驱动的产品的不确定特质，那么在之前未查看的交互过程中人工智能驱动的产品将会和能够如何表现，人工智能驱动的产品在 2 个或多个不同用户的交互使用场景下，这个问题更加凸显出来。例如，如果两辆无人驾驶汽车是由两个独立的人工智能引擎（由不同的公司通过不同的训练数据和特征、相互独立的偏差和情景设置所构建）驱动和控制，当驶向一个停车标志或者一个撞车现场时将会发生什么。这些系统如何到达和应对相似场景上的轻微差别和变异，将会产生意想不到的且有潜在危害的副作用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;偏差泄露（Bias Leakage）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能引擎交互的另一个潜在的副作用是其扩大了训练偏差的风险。例如，一辆无人驾驶汽车可以观察到另一辆无人驾驶汽车以牺牲行人为代价来保护车上的乘客，并且观察到这样的选择机制保障另一辆车自身免出事故，那么这辆车将学会在相似情景下采取相似的做法。这样将会导致偏差泄露，即各自独立训练得到的人工智能引擎能够被其他的人工智能引擎所影响（正面或负面影响）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;学习的敏捷性（Learning Agility）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;即使给相似的人工智能引擎提供相同的训练数据，但训练环境和用以训练架构的不同仍会导致训练和学习过程以不同的速率进行，并得出不同的结论来作为输出结果。这些细微偏差经过多次迭代，将导致人工智能引擎的行为表现产生巨大变化，随之而来的是始料不及的后果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「陈腐」的人工智能引擎和「废料堆积场」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在一个由人工智能驱动的产品组成的世界里，如果这些产品被遗弃或者逐渐消亡将会发生什么。植入的人工智能或许会逐渐被冻结，久而久之变成人工智能的废料堆积场。这些被遗弃的人工智能驱动的产品，是处于对其环境和使用情境学习的巅峰时刻直到消亡时刻到来，如果在另一个时间因为任何原因复活，环境和使用情境还会再次导致不可预测或不理想的作用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibkgzQLGMwFy1N0wOZ7kQ0DddhFQEexhqcZOiaIBpJwJjBoSmsPxgeU8ia8hlSO7FQQxgNhicmhBHdBQ/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;新的人工智能开源模式&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们需要一个开源的人工智能新模式，它可以提供一个框架来解决上面列出的一些问题。考虑到人工智能的特质，仅仅将之前的用于构建人工智能和机器学习引擎的技术开源并嵌入到产品中是远远不够的。此外，与科学研究相似，业界也需要将用于大规模生产的人工智能和机器学习引擎反馈回学界，从而为新的改进的系统、引擎和产品提供基础支撑。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;基准、参照和标准&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于所有的基础场景，例如自动驾驶汽车、图像识别、语音文本转换等，尤其是在面对多个服务提供商的情况下，行业需要定义基准和标准，以应对所有其它新的或现有的人工智能引擎和堆栈的评估排名（例如，就像人工智能相当于自动驾驶汽车的美国国家公路交通安全管理局的 5 星级安全评级）。为基础情景定义业界可接受的基准，可以确保服务提供商和消费者能够在选择使用人工智能和机器学习的产品和服务方面做出明智的决策。此外，可以根据现有的基准和标准不断地评估现有的人工智能引擎，以确保这些系统的质量不断提高。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;构建人工智能和机器学习模式的公司应考虑将整个人工智能和机器学习模式开源（不仅仅是贡献构建模式的技术和框架）。例如，即使是已经有 5 年开发历史的谷歌图像识别或微软语音文本转换模式，也可以在其它板块行业或垂直行业中更快地激发人工智能和机器学习的创新和同化，从而引发自我创新的持续循环。构建人工智能和机器学习模式的公司应考虑将整个人工智能和机器学习模式开源（不仅仅是贡献构建模式的技术和框架）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;寻找偏差&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们需要能够寻找偏差的能力，以便人工智能和机器学习引擎中的偏差能够尽快被发现和解决。离开这样的能力，业界将非常难以运用通用人工智能引擎，从而无法令这些引擎在不同场景中一致和确定地运行。寻找偏差和解决问题需要以下人工智能开放源模式的支持：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据的假设和偏差&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能使得产品设计者需要确保他们了解人工智能和机器学习引擎中包含的假设和偏差。与人工智能产品交互的其它产品需要确保他们理解并准备好处理人工智能引擎行为带来的后果。为了确保人工智能和机器学习模式的消费者或集成商做好足够的准备，应该为每个人工智能和机器学习模式共享以下标准：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;收集标准&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据是怎样收集的？数据生成器是什么？数据生成的频率、地点、时间、方式和原因分别是什么？如何收集、存储和传输？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;选择标准&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据是如何被选择而进行训练的？未被选择的数据有什么标准？数据的子集是如何选择和未选择的？定义高质量数据的标准是什么？定义可接受但质量不高的数据的标准又是什么？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;处理标准&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;用于训练的数据需要怎样的处理？数据是如何转换、增强和归纳的？处理的频率如何？什么原因导致需要计划的处理推迟或中止。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;特征假设和偏差&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能和机器学习模式被建模的系统的特征或特点而训练的。这些特征被提取出来用于人工智能和机器学习引擎以预测该系统的行为或将新信号分类为所需的类别以从系统中推荐特定的行为。人工智能模式的消费者和集成商不仅要很好地理解应该选择什么特征来开发人工智能模式，而且还要理解为什么有的考虑了的特征没有被选择。此外，过程的可见性以及被用于确定训练特征的见解也将需要归档和共享。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;去除盲点&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由于模式内置的偏差和假设，人工智能和机器学习引擎可能会在某些情况、环境中受到限制。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;盲点报告和反馈循环&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;用于人工智能和机器学习的开源模式应该具有的又一特征是不仅能够探知特定模式是否具有盲点，同时具有提供用于消除盲点的反馈信息的能力（真实世界的例子）。这与用户的垃圾邮件报告非常相似——用户标记垃圾邮件的例子，过滤器从中学习规则。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;协作去除盲点&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在理想情况下，开源协议需要允许用户共享数据，更有效地消除盲点。就像谷歌自动驾驶汽车和特斯拉一样。谷歌 Waymo 已经积累了 200 万英里的自动驾驶数据，而特斯拉收集了 5000 万英里的高速公路驾驶数据。这些数据包含大量的避免崩溃/驾驶者/乘客/行人安全的信息，如果这两家公司展开合作分享数据的话，它们就可以利用他人的数据改善自身产品的安全。或许，这些数据应该被开源，为行业和用户提供更多安全保障。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;结论&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能和机器学习正在切实地改变我们的生活方式，为人类提供更好、更简单、更安全和愉快的体验。人工智能和机器学习在很多行业以不同形式不断被应用。但是，如果想加速这些应用，仅仅开源用于构建人工智能和机器学习引擎的框架是不够的。我们需要新的开源模式，让各家公司不仅能够贡献和改进人工智能/机器学习框架，而且可以将这些框架应用于新的环境中去，在标准模式的基础上构建新的模式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此外，人工智能模式中的假设和偏差信息（在数据和特征层面）可以让用户不断提出反馈，为改进产品提供依据。如果没有开源这样的模式，科技领域之外的公司将难以真正得到人工智能带来的好处。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 30 Jan 2017 13:38:10 +0800</pubDate>
    </item>
    <item>
      <title>教程 | 从头开始：用Python实现随机森林算法</title>
      <link>http://www.iwgc.cn/link/4524081</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自machine learning mastery&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：Linjing、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;拥有高方差使得决策树（secision tress）在处理特定训练数据集时其结果显得相对脆弱。bagging（bootstrap aggregating 的缩写）算法从训练数据的样本中建立复合模型，可以有效降低决策树的方差，但树与树之间有高度关联（并不是理想的树的状态）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随机森林算法（Random forest algorithm）是对 bagging 算法的扩展。除了仍然根据从训练数据样本建立复合模型之外，随机森林对用做构建树（tree）的数据特征做了一定限制，使得生成的决策树之间没有关联，从而提升算法效果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本教程旨在探讨如何用 Python 实现随机森林算法。通过本文，我们可以了解到：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;bagged decision trees 与随机森林算法的差异；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如何构建含更多方差的装袋决策树；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如何将随机森林算法运用于预测模型相关的问题。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;算法描述&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个章节将对随机森林算法本身以及本教程的算法试验所用的声纳数据集（Sonar dataset）做一个简要介绍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随机森林算法&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;决策树运行的每一步都涉及到对数据集中的最优分裂点（best split point）进行贪婪选择（greedy selection）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个机制使得决策树在没有被剪枝的情况下易产生较高的方差。整合通过提取训练数据库中不同样本（某一问题的不同表现形式）构建的复合树及其生成的预测值能够稳定并降低这样的高方差。这种方法被称作引导聚集算法（bootstrap aggregating），其简称 bagging 正好是装进口袋，袋子的意思，所以被称为「装袋算法」。该算法的局限在于，由于生成每一棵树的贪婪算法是相同的，那么有可能造成每棵树选取的分裂点（split point）相同或者极其相似，最终导致不同树之间的趋同（树与树相关联）。相应地，反过来说，这也使得其会产生相似的预测值，降低原本要求的方差。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们可以采用限制特征的方法来创建不一样的决策树，使贪婪算法能够在建树的同时评估每一个分裂点。这就是随机森林算法（Random Forest algorithm）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;与装袋算法一样，随机森林算法从训练集里撷取复合样本并训练。其不同之处在于，数据在每个分裂点处完全分裂并添加到相应的那棵决策树当中，且可以只考虑用于存储属性的某一固定子集。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于分类问题，也就是本教程中我们将要探讨的问题，其被考虑用于分裂的属性数量被限定为小于输入特征的数量之平方根。代码如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;num_features_for_split = sqrt(total_input_features)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个小更改会让生成的决策树各不相同（没有关联），从而使得到的预测值更加多样化。而多样的预测值组合往往会比一棵单一的决策树或者单一的装袋算法有更优的表现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;声纳数据集（Sonar dataset）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们将在本教程里使用声纳数据集作为输入数据。这是一个描述声纳反射到不同物体表面后返回的不同数值的数据集。60 个输入变量表示声纳从不同角度返回的强度。这是一个二元分类问题（binary classification problem），要求模型能够区分出岩石和金属柱体的不同材质和形状，总共有 208 个观测样本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该数据集非常易于理解——每个变量都互有连续性且都在 0 到 1 的标准范围之间，便于数据处理。作为输出变量，字符串'M'表示金属矿物质，'R'表示岩石。二者需分别转换成整数 1 和 0。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过预测数据集（M 或者金属矿物质）中拥有最多观测值的类，零规则算法（Zero Rule Algorithm）可实现 53% 的精确度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;更多有关该数据集的内容可参见 UCI Machine Learning repository：https://archive.ics.uci.edu/ml/datasets/Connectionist+Bench+(Sonar,+Mines+vs.+Rocks)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;免费下载该数据集，将其命名为 sonar.all-data.csv，并存储到需要被操作的工作目录当中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;教程&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此次教程分为两个步骤。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 分裂次数的计算。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 声纳数据集案例研究&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些步骤能让你了解为你自己的预测建模问题实现和应用随机森林算法的基础&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 分裂次数的计算&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在决策树中，我们通过找到一些特定属性和属性的值来确定分裂点，这类特定属性需表现为其所需的成本是最低的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;分类问题的成本函数（cost function）通常是基尼指数（Gini index），即计算由分裂点产生的数据组的纯度（purity）。对于这样二元分类的分类问题来说，指数为 0 表示绝对纯度，说明类值被完美地分为两组。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从一棵决策树中找到最佳分裂点需要在训练数据集中对每个输入变量的值做成本评估。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在装袋算法和随机森林中，这个过程是在训练集的样本上执行并替换（放回）的。因为随机森林对输入的数据要进行行和列的采样。对于行采样，采用有放回的方式，也就是说同一行也许会在样本中被选取和放入不止一次。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们可以考虑创建一个可以自行输入属性的样本，而不是枚举所有输入属性的值以期找到获取成本最低的分裂点，从而对这个过程进行优化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该输入属性样本可随机选取且没有替换过程，这就意味着在寻找最低成本分裂点的时候每个输入属性只需被选取一次。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如下的代码所示，函数 get_split() 实现了上述过程。它将一定数量的来自待评估数据的输入特征和一个数据集作为参数，该数据集可以是实际训练集里的样本。辅助函数 test_split() 用于通过候选的分裂点来分割数据集，函数 gini_index() 用于评估通过创建的行组（groups of rows）来确定的某一分裂点的成本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以上我们可以看出，特征列表是通过随机选择特征索引生成的。通过枚举该特征列表，我们可将训练集中的特定值评估为符合条件的分裂点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;# Select the best split point for a dataset&lt;br/&gt;def get_split(dataset, n_features):&lt;br/&gt;    class_values = list(set(row[-1] for row in dataset))&lt;br/&gt;    b_index, b_value, b_score, b_groups = 999, 999, 999, None&lt;br/&gt;    features = list()&lt;br/&gt;    while len(features) &amp;lt; n_features:&lt;br/&gt;        index = randrange(len(dataset[0])-1)&lt;br/&gt;        if index not in features:&lt;br/&gt;            features.append(index)&lt;br/&gt;    for index in features:&lt;br/&gt;        for row in dataset:&lt;br/&gt;            groups = test_split(index, row[index], dataset)&lt;br/&gt;            gini = gini_index(groups, class_values)&lt;br/&gt;            if gini &amp;lt; b_score:&lt;br/&gt;                b_index, b_value, b_score, b_groups = index, row[index], gini, groups&lt;br/&gt;    return {'index':b_index, 'value':b_value, 'groups':b_groups}&lt;/pre&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;至此，我们知道该如何改造一棵用于随机森林算法的决策树。我们可将之与装袋算法结合运用到真实的数据集当中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 关于声纳数据集的案例研究&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这个部分，我们将把随机森林算法用于声纳数据集。本示例假定声纳数据集的 csv 格式副本已存在于当前工作目录中，文件名为 sonar.all-data.csv。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先加载该数据集，将字符串转换成数字，并将输出列从字符串转换成数值 0 和 1. 这个过程是通过辅助函数 load_csv()、str_column_to_float() 和 str_column_to_int() 来分别实现的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们将通过 K 折交叉验证（k-fold cross validatio）来预估得到的学习模型在未知数据上的表现。这就意味着我们将创建并评估 K 个模型并预估这 K 个模型的平均误差。评估每一个模型是由分类准确度来体现的。辅助函数 cross_validation_split()、accuracy_metric() 和 evaluate_algorithm() 分别实现了上述功能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;装袋算法将通过分类和回归树算法来满足。辅助函数 test_split() 将数据集分割成不同的组；gini_index() 评估每个分裂点；前文提及的改进过的 get_split() 函数用来获取分裂点；函数 to_terminal()、split() 和 build_tree() 用以创建单个决策树；predict() 用于预测；subsample() 为训练集建立子样本集； bagging_predict() 对决策树列表进行预测。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;新命名的函数 random_forest() 首先从训练集的子样本中创建决策树列表，然后对其进行预测。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;正如我们开篇所说，随机森林与决策树关键的区别在于前者在建树的方法上的小小的改变，这一点在运行函数 get_split() 得到了体现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;完整的代码如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;# Random Forest Algorithm on Sonar Dataset&lt;br/&gt;from random import seed&lt;br/&gt;from random import randrange&lt;br/&gt;from csv import reader&lt;br/&gt;from math import sqrt&lt;br/&gt; &lt;br/&gt;# Load a CSV file&lt;br/&gt;def load_csv(filename):&lt;br/&gt; &amp;nbsp; &amp;nbsp;dataset = list()&lt;br/&gt; &amp;nbsp; &amp;nbsp;with open(filename, 'r') as file:&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;csv_reader = reader(file)&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;for row in csv_reader:&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;if not row:&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;continue&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;dataset.append(row)&lt;br/&gt; &amp;nbsp; &amp;nbsp;return dataset&lt;br/&gt; &lt;br/&gt;# Convert string column to float&lt;br/&gt;def str_column_to_float(dataset, column):&lt;br/&gt; &amp;nbsp; &amp;nbsp;for row in dataset:&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;row[column] = float(row[column].strip())&lt;br/&gt; &lt;br/&gt;# Convert string column to integer&lt;br/&gt;def str_column_to_int(dataset, column):&lt;br/&gt; &amp;nbsp; &amp;nbsp;class_values = [row[column] for row in dataset]&lt;br/&gt; &amp;nbsp; &amp;nbsp;unique = set(class_values)&lt;br/&gt; &amp;nbsp; &amp;nbsp;lookup = dict()&lt;br/&gt; &amp;nbsp; &amp;nbsp;for i, value in enumerate(unique):&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;lookup[value] = i&lt;br/&gt; &amp;nbsp; &amp;nbsp;for row in dataset:&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;row[column] = lookup[row[column]]&lt;br/&gt; &amp;nbsp; &amp;nbsp;return lookup&lt;br/&gt; &lt;br/&gt;# Split a dataset into k folds&lt;br/&gt;def cross_validation_split(dataset, n_folds):&lt;br/&gt; &amp;nbsp; &amp;nbsp;dataset_split = list()&lt;br/&gt; &amp;nbsp; &amp;nbsp;dataset_copy = list(dataset)&lt;br/&gt; &amp;nbsp; &amp;nbsp;fold_size = len(dataset) / n_folds&lt;br/&gt; &amp;nbsp; &amp;nbsp;for i in range(n_folds):&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;fold = list()&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;while len(fold) &amp;lt; fold_size:&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;index = randrange(len(dataset_copy))&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;fold.append(dataset_copy.pop(index))&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;dataset_split.append(fold)&lt;br/&gt; &amp;nbsp; &amp;nbsp;return dataset_split&lt;br/&gt; &lt;br/&gt;# Calculate accuracy percentage&lt;br/&gt;def accuracy_metric(actual, predicted):&lt;br/&gt; &amp;nbsp; &amp;nbsp;correct = 0&lt;br/&gt; &amp;nbsp; &amp;nbsp;for i in range(len(actual)):&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;if actual[i] == predicted[i]:&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;correct += 1&lt;br/&gt; &amp;nbsp; &amp;nbsp;return correct / float(len(actual)) * 100.0&lt;br/&gt; &lt;br/&gt;# Evaluate an algorithm using a cross validation split&lt;br/&gt;def evaluate_algorithm(dataset, algorithm, n_folds, *args):&lt;br/&gt; &amp;nbsp; &amp;nbsp;folds = cross_validation_split(dataset, n_folds)&lt;br/&gt; &amp;nbsp; &amp;nbsp;scores = list()&lt;br/&gt; &amp;nbsp; &amp;nbsp;for fold in folds:&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;train_set = list(folds)&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;train_set.remove(fold)&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;train_set = sum(train_set, [])&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;test_set = list()&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;for row in fold:&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;row_copy = list(row)&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;test_set.append(row_copy)&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;row_copy[-1] = None&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;predicted = algorithm(train_set, test_set, *args)&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;actual = [row[-1] for row in fold]&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;accuracy = accuracy_metric(actual, predicted)&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;scores.append(accuracy)&lt;br/&gt; &amp;nbsp; &amp;nbsp;return scores&lt;br/&gt; &lt;br/&gt;# Split a dataset based on an attribute and an attribute value&lt;br/&gt;def test_split(index, value, dataset):&lt;br/&gt; &amp;nbsp; &amp;nbsp;left, right = list(), list()&lt;br/&gt; &amp;nbsp; &amp;nbsp;for row in dataset:&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;if row[index] &amp;lt; value:&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;left.append(row)&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;else:&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;right.append(row)&lt;br/&gt; &amp;nbsp; &amp;nbsp;return left, right&lt;br/&gt; &lt;br/&gt;# Calculate the Gini index for a split dataset&lt;br/&gt;def gini_index(groups, class_values):&lt;br/&gt; &amp;nbsp; &amp;nbsp;gini = 0.0&lt;br/&gt; &amp;nbsp; &amp;nbsp;for class_value in class_values:&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;for group in groups:&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;size = len(group)&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;if size == 0:&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;continue&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;proportion = [row[-1] for row in group].count(class_value) / float(size)&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;gini += (proportion * (1.0 - proportion))&lt;br/&gt; &amp;nbsp; &amp;nbsp;return gini&lt;br/&gt; &lt;br/&gt;# Select the best split point for a dataset&lt;br/&gt;def get_split(dataset, n_features):&lt;br/&gt; &amp;nbsp; &amp;nbsp;class_values = list(set(row[-1] for row in dataset))&lt;br/&gt; &amp;nbsp; &amp;nbsp;b_index, b_value, b_score, b_groups = 999, 999, 999, None&lt;br/&gt; &amp;nbsp; &amp;nbsp;features = list()&lt;br/&gt; &amp;nbsp; &amp;nbsp;while len(features) &amp;lt; n_features:&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;index = randrange(len(dataset[0])-1)&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;if index not in features:&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;features.append(index)&lt;br/&gt; &amp;nbsp; &amp;nbsp;for index in features:&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;for row in dataset:&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;groups = test_split(index, row[index], dataset)&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;gini = gini_index(groups, class_values)&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;if gini &amp;lt; b_score:&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;b_index, b_value, b_score, b_groups = index, row[index], gini, groups&lt;br/&gt; &amp;nbsp; &amp;nbsp;return {'index':b_index, 'value':b_value, 'groups':b_groups}&lt;br/&gt; &lt;br/&gt;# Create a terminal node value&lt;br/&gt;def to_terminal(group):&lt;br/&gt; &amp;nbsp; &amp;nbsp;outcomes = [row[-1] for row in group]&lt;br/&gt; &amp;nbsp; &amp;nbsp;return max(set(outcomes), key=outcomes.count)&lt;br/&gt; &lt;br/&gt;# Create child splits for a node or make terminal&lt;br/&gt;def split(node, max_depth, min_size, n_features, depth):&lt;br/&gt; &amp;nbsp; &amp;nbsp;left, right = node['groups']&lt;br/&gt; &amp;nbsp; &amp;nbsp;del(node['groups'])&lt;br/&gt; &amp;nbsp; &amp;nbsp;# check for a no split&lt;br/&gt; &amp;nbsp; &amp;nbsp;if not left or not right:&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;node['left'] = node['right'] = to_terminal(left + right)&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;return&lt;br/&gt; &amp;nbsp; &amp;nbsp;# check for max depth&lt;br/&gt; &amp;nbsp; &amp;nbsp;if depth &amp;gt;= max_depth:&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;node['left'], node['right'] = to_terminal(left), to_terminal(right)&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;return&lt;br/&gt; &amp;nbsp; &amp;nbsp;# process left child&lt;br/&gt; &amp;nbsp; &amp;nbsp;if len(left) &amp;lt;= min_size:&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;node['left'] = to_terminal(left)&lt;br/&gt; &amp;nbsp; &amp;nbsp;else:&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;node['left'] = get_split(left, n_features)&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;split(node['left'], max_depth, min_size, n_features, depth+1)&lt;br/&gt; &amp;nbsp; &amp;nbsp;# process right child&lt;br/&gt; &amp;nbsp; &amp;nbsp;if len(right) &amp;lt;= min_size:&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;node['right'] = to_terminal(right)&lt;br/&gt; &amp;nbsp; &amp;nbsp;else:&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;node['right'] = get_split(right, n_features)&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;split(node['right'], max_depth, min_size, n_features, depth+1)&lt;br/&gt; &lt;br/&gt;# Build a decision tree&lt;br/&gt;def build_tree(train, max_depth, min_size, n_features):&lt;br/&gt; &amp;nbsp; &amp;nbsp;root = get_split(dataset, n_features)&lt;br/&gt; &amp;nbsp; &amp;nbsp;split(root, max_depth, min_size, n_features, 1)&lt;br/&gt; &amp;nbsp; &amp;nbsp;return root&lt;br/&gt; &lt;br/&gt;# Make a prediction with a decision tree&lt;br/&gt;def predict(node, row):&lt;br/&gt; &amp;nbsp; &amp;nbsp;if row[node['index']] &amp;lt; node['value']:&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;if isinstance(node['left'], dict):&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;return predict(node['left'], row)&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;else:&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;return node['left']&lt;br/&gt; &amp;nbsp; &amp;nbsp;else:&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;if isinstance(node['right'], dict):&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;return predict(node['right'], row)&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;else:&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;return node['right']&lt;br/&gt; &lt;br/&gt;# Create a random subsample from the dataset with replacement&lt;br/&gt;def subsample(dataset, ratio):&lt;br/&gt; &amp;nbsp; &amp;nbsp;sample = list()&lt;br/&gt; &amp;nbsp; &amp;nbsp;n_sample = round(len(dataset) * ratio)&lt;br/&gt; &amp;nbsp; &amp;nbsp;while len(sample) &amp;lt; n_sample:&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;index = randrange(len(dataset))&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;sample.append(dataset[index])&lt;br/&gt; &amp;nbsp; &amp;nbsp;return sample&lt;br/&gt; &lt;br/&gt;# Make a prediction with a list of bagged trees&lt;br/&gt;def bagging_predict(trees, row):&lt;br/&gt; &amp;nbsp; &amp;nbsp;predictions = [predict(tree, row) for tree in trees]&lt;br/&gt; &amp;nbsp; &amp;nbsp;return max(set(predictions), key=predictions.count)&lt;br/&gt; &lt;br/&gt;# Random Forest Algorithm&lt;br/&gt;def random_forest(train, test, max_depth, min_size, sample_size, n_trees, n_features):&lt;br/&gt; &amp;nbsp; &amp;nbsp;trees = list()&lt;br/&gt; &amp;nbsp; &amp;nbsp;for i in range(n_trees):&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;sample = subsample(train, sample_size)&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;tree = build_tree(sample, max_depth, min_size, n_features)&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;trees.append(tree)&lt;br/&gt; &amp;nbsp; &amp;nbsp;predictions = [bagging_predict(trees, row) for row in test]&lt;br/&gt; &amp;nbsp; &amp;nbsp;return(predictions)&lt;br/&gt; &lt;br/&gt;# Test the random forest algorithm&lt;br/&gt;seed(1)&lt;br/&gt;# load and prepare data&lt;br/&gt;filename = 'sonar.all-data.csv'&lt;br/&gt;dataset = load_csv(filename)&lt;br/&gt;# convert string attributes to integers&lt;br/&gt;for i in range(0, len(dataset[0])-1):&lt;br/&gt; &amp;nbsp; &amp;nbsp;str_column_to_float(dataset, i)&lt;br/&gt;# convert class column to integers&lt;br/&gt;str_column_to_int(dataset, len(dataset[0])-1)&lt;br/&gt;# evaluate algorithm&lt;br/&gt;n_folds = 5&lt;br/&gt;max_depth = 10&lt;br/&gt;min_size = 1&lt;br/&gt;sample_size = 1.0&lt;br/&gt;n_features = int(sqrt(len(dataset[0])-1))&lt;br/&gt;for n_trees in [1, 5, 10]:&lt;br/&gt; &amp;nbsp; &amp;nbsp;scores = evaluate_algorithm(dataset, random_forest, n_folds, max_depth, min_size, sample_size, n_trees, n_features)&lt;br/&gt; &amp;nbsp; &amp;nbsp;print('Trees: %d' % n_trees)&lt;br/&gt; &amp;nbsp; &amp;nbsp;print('Scores: %s' % scores)&lt;br/&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里对第 197 行之后对各项参数的赋值做一个说明。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;将 K 赋值为 5 用于交叉验证，得到每个子样本为 208/5 = 41.6，即超过 40 条声纳返回记录会用于每次迭代时的评估。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;每棵树的最大深度设置为 10，每个节点的最小训练行数为 1. 创建训练集样本的大小与原始数据集相同，这也是随机森林算法的默认预期值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们把在每个分裂点需要考虑的特征数设置为总的特征数目的平方根，即 sqrt(60)=7.74，取整为 7。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;将含有三组不同数量的树同时进行评估，以表明添加更多的树可以使该算法实现的功能更多。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，运行这个示例代码将会 print 出每组树的相应分值以及每种结构的平均分值。如下所示：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Trees: 1&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Scores: [68.29268292682927, 75.60975609756098, 70.73170731707317, 63.41463414634146, 65.85365853658537]&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Mean Accuracy: 68.780%&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Trees: 5&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Scores: [68.29268292682927, 68.29268292682927, 78.04878048780488, 65.85365853658537, 68.29268292682927]&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Mean Accuracy: 69.756%&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Trees: 10&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Scores: [68.29268292682927, 78.04878048780488, 75.60975609756098, 70.73170731707317, 70.73170731707317]&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Mean Accuracy: 72.683%&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;扩展&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本节会列出一些与本次教程相关的扩展内容。大家或许有兴趣一探究竟。&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;算法调校（Algorithm Tuning）。本文所用的配置参数或有未被修正的错误以及有待商榷之处。用更大规模的树，不同的特征数量甚至不同的树的结构都可以改进试验结果。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;更多问题。该方法同样适用于其他的分类问题，甚至是用新的成本计算函数以及新的组合树的预期值的方法使其适用于回归算法。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;回顾总结&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过本次教程的探讨，你知道了随机森林算法是如何实现的，特别是：&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;随机森林与装袋决策树的区别。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如何用决策树生成随机森林算法。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如何将随机森林算法应用于解决实际操作中的预测模型问题。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 30 Jan 2017 13:38:10 +0800</pubDate>
    </item>
    <item>
      <title>深度 | Richard Sutton：人工智能的未来属于搜索和学习</title>
      <link>http://www.iwgc.cn/link/4524082</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;作者：Yuting&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;strong&gt;参与：&lt;strong&gt;吴沁桐、赵华龙&lt;/strong&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Richard Sutton 在多伦多大学数学科学研究中心的机器学习应用进展系列研讨会上探讨了人工智能的未来方向。他认为人工智能的未来属于可扩展的方法、搜索与学习。而在人工智能未来的发展中，可扩展性是及其重要的方向。监督学习和计算能力的可扩展性并不大，真正重要的是在普通的经验知识世界中学习的能力，这个能力需要扩展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;iframe class="video_iframe" data-vidtype="1" allowfullscreen="" frameborder="0" height="418" width="557" data-src="https://v.qq.com/iframe/preview.html?vid=h0369guf74a&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0"&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;摘要&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当人类最终开始理解智能的原理并将这些原理赋予机器的时候，这会是我们这个时代，或者可以说是任何时代，最重要的发现。最近几年，随着深度学习及其相关领域的进步，这一巨大的进步几乎触手可及。它给人类所带来的后果、利益和危险已成为新闻界、各种公共政策会议以及科学会议上的热门话题，这是一种夸张和恐惧，还是隐藏在激动人心之下的真正科学进步？在这次讨论中，我将基于我 38 年的人工智能研究经验，给大家讲一些有用的但毫无疑问又带有偏颇的观点。我所讲的内容包括两个方面：1）将目前的发展视为人工智能最长久趋势的一部分——更廉价的计算，以及由此而来的将会扮演更重要角色的搜索、学习以及所有可扩展的事情，2）基于预测以及强化学习，勾勒出一条可能的人工智能之路。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;介绍&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在不远的将来，人工智能的可扩展性将会是极其重要的。鉴于摩尔定律奠定了我们目前计算能力发展的基础，根据该定律我们的计算资源每两年将翻一番。优秀的算法必须能够随着硬件的发展而扩展。尽管现在研究人员还不需要花费太多的时间关注人工智能的可扩展性，但在不远的将来，这一部分开销将呈现指数级的增长。人工智能的未来应当属于可扩展的搜索与学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;要点总结&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;现在&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最火最有名的人工智能应用有：AlphaGo、自动驾驶汽车、扑克、语音识别与计算机视觉。为什么它会在现在出现？是因为人工智能算法的巨大进步还是因为摩尔定律？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摩尔定律肯定在其中扮演了重要角色。摩尔定律告诉我们，能够放置在一块相同大小的集成电路上的晶体管的数量大约每两年会翻一番。在计算机硬件领域的长时间指数级增长至少为人工智能的发展贡献了一半的力量。硬件是算法发展的一个巨大激励因素。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 是解决还是不解决，所涉及的是人工智能的问题，但根源来源于人类自身。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;a. 人工智能是不安全的且会威胁到人类本身，人工智能将会比人更聪明。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;b. 人工智能的研究人员有时对这些担忧过于轻视。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Richard &lt;span&gt;Sutton&lt;/span&gt;认为&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;a. 2040(40%), never(10%) 一个人类级别的人工智能将会是一项意义深远的科学成就，它可能会在 2030 年实现（25%），也可能在 2040 年实现（40%），也可能永远不会实现（10%）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;b. 人工智能会带来很多改变，我们应为此做好准备。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;c. 对人工智能的恐惧被过于夸大了，且这种恐惧是无建设性的。有些恐惧人工智能的人甚至都不知道他们恐惧具体是什么。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp; i. 如果人工智能比我们聪明，它们将会脱离我们的控制。很有可能人工智能会是我们的继任者而不是奴隶。而坏的继任者源自于它们父辈的错误。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp; ii. 以摩尔定律的速度来看，人工智能的发展速度是缓慢的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp; iii. 最大的风险来源于那些不当使用人工智能之人。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;过去：从长期来看可扩展的方法总是赢家。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 三波神经网络的热潮&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;a.50-60 年代的感知机、Adaline：仅有一层可学习层。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;b.80-90 年代的连接主义（Connectionism）、神经网络：通过反向传递的多层学习（SGD）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;c.2010 年起的深度学习：神经网络类的方法胜利了，因为它们的性能可以随着摩尔定律的发展大幅提高，而计算类（computational）的方法却做不到这一点。最优秀的算法本质上和 80 年代的算法是一样的，不同的是更快的计算机和更大的数据集。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 最好的解决方案来自于最好的算法和强有力的计算机。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;a. 赢得象棋比赛：关键是巨大、高效、启发式的搜索。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;b. 赢得围棋比赛：关键是巨大且基于样本的搜索。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;c. 理解自然语言：关键是一些统计式的机器学习方法和大数据集。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;d. 视觉识别物体：关键是大数据集、更多的参数和更长的训练时间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 搜索和学习是可扩展的方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;a. 一个可随着摩尔定律扩展的方法在某种程度上它的性能大致和给予它的计算量成比例。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;b. 一个不能扩展的方法意味着它所带来的改进不太受可用计算能力的影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;c. 可扩展的能力是关键，但是它往往也与其他一些问题有关。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;符号的 VS. 统计的、纯手工的 VS 可自我学习的、专用领域的 VS 通用的。尽管前者更依靠人类自己的理解，但是从人工智能的发展历史来看，那些统计化的、可自我学习的、通用的方法已经逐渐变得越来越重要。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;未来&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 监督学习的可扩展性有多大？并不太大&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;a. 通过神经网络，学习的进程已经被大幅扩展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;b. 可扩展性是有限度的，因为它需要人们提供训练数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 强化学习的可扩展性有多大？并不太大&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;a. 一个经典的与不受模型限制的强化学习可以通过失败与错误学习出一条规则，不需要数据标注。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;b. 计算是廉价的，没有什么扩展性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 相比较仅仅一个权值方程和策略，相比较仅仅老师告诉你的什么是应该做的事，还有太多的东西要学。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4. 世界经验知识的大挑战（知识表达与推理）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;a. 知识的定义：知识是关于世界的状态和变化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp; i. 状态是事物过去的总结，它可以用来预测它将来的状态。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp; ii. 有了状态的知识就是有了一个好的总结，它能够使预测更精确。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp; iii. 预测本身就是动态的知识。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp; iv. 需要预测的最重要的东西是状态和奖惩，当然，这取决于 agent 是做什么的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;b. 举个例子，知识可以是知道象棋里的每一小步如何走，知道什么导致了什么，预测下面会发生什么。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;c. 知识必须具有可表达性（可以表示所有重要的事物）、可学习性（监督的或者非监督的）、适合推理和论证。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;d. 感觉运动观点（与感觉运动阶段有关的感觉运动）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp; i. 你的数据流其实就是你所知的世界中的每一件事。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp; ii. 知识在数据中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;5. 一个古已有之的宏伟目标是用感觉运动数据来理解世界。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;a. 能够在各个抽象层次做预测。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;b. 这个目标非常适合进行扩展，它利用大量的数据来学习预测行为以及搜寻最好的抽象。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;6. 在未来 12 个月中机器学习领域最重要的进展将会是：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;a. 从寻常知识中进行大规模学习的能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp; i. 从与世界的互动中进行大规模学习的能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp; ii. 这种学习不再需要已标注数据的训练集。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp; iii. 以一种更自然的方式学习，就像儿童或者动物那样。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp; iv. 学习世界如何，以及理解因果性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;b. 能够使机器学习扩展到更高的水平。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;c. 使用深度强化学习来进行远期预测（可能）和/或 无监督的学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;7. 新工具&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;a. 通用的价值函数为高效可学习可预测的知识提供了一种统一语言。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;b. 可选项以及备选模型（时域抽象）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;c. 可预测的状态表达。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;d. 新的离策略（off-policy）学习算法（梯度-TD，强度-TD）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;e. 时域差分网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;f. 深度学习，表达搜索。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;结论（最终看法）&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 摩尔定律极大地影响了人工智能的发展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 人工智能的未来属于可扩展的方法、搜索与学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 能够从平常经验中学习知识是一种巨大的进步。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4. 我们的计划应该具有雄心，并且可扩展，还要有耐心。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;5. 在 AI 领域的研究者中，对于着眼于未来的可扩展性并不是十分有吸引力。因为对于想要出成绩的研究者而言，他们更希望自己对相关领域的贡献可以在短期内有显著的影响力，更希望自己的知识与新奇的想法应用的现有的研究当中。然而，随着硬件计算能力的提升，即使是一个算法具有优秀扩展性的算法没法在短期内满足研究应用的需求，从长远来看这样的算法将会很有竞争力。这就像「一步到位方法」vs.」长期演进方法」。研究者们应在他们自己的研究中找到平衡点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;相关阅读&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过强化学习教机器下象棋&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://www.technologyreview.com/s/541276/deep-learning-machine-teaches-itself-chess-in-72-hours-plays-at-international-master/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关于假肢的实时预测&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://webdocs.cs.ualberta.ca/~sutton/papers/PDDCCHS-13.pdf&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Rich NIPS 2015 RL tutorial&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://www.microsoft.com/en-us/research/video/tutorial-introduction-to-reinforcement-learning-with-function-approximation/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心原创，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 30 Jan 2017 13:38:10 +0800</pubDate>
    </item>
    <item>
      <title>人工智能从入门到进阶，机器之心高分技术文章全集</title>
      <link>http://www.iwgc.cn/link/4516627</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：吴攀&lt;span&gt;、&lt;span&gt;蒋思源&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;新的一年到来了，过去的 2016 年可以说是有史以来机器学习领域进展最显著的一年。在大数据和高性能计算设备的助力下，具备学习能力的机器在围棋、语音识别、翻译、图像渲染和识别等许多领域都实现了惊人的成就。但那远远还不是这一领域的终点，大部分媒体和投资者仍然还看好以机器学习为主的人工智能技术的未来发展，市场也无法掩饰地表现出了对这方面的人才的需求。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这篇文章尽可能地全面地梳理了机器之心在 2016 年发过的基础知识和技术指导方面的文章，希望能为读者通往人工智能领域的专业人才乃至学界大牛之路提供一点助力。本文按照从基础到前沿划分对文章进行了分类（学习资源、基础介绍文章、技术起点、继续进阶、前沿研究），读者可方便地根据自己的学习进度选择合适的文章阅读。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;一、学习资源&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWic17FA5ZBlbiaEavsI2wmR5XHRc2ibiaJJr5Ho8fkLeb2pXZMrHqbzLImYFBhjg4kwVZnA9oOR9cjR4g/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721853&amp;amp;idx=3&amp;amp;sn=f9f0048cccefbf9c00dc94f2a71c7d00&amp;amp;chksm=871b0a43b06c8355376d1bc897b4f3585b4a129d77a9e5b025f4c344f2ef264c05133cff7682&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721853&amp;amp;idx=3&amp;amp;sn=f9f0048cccefbf9c00dc94f2a71c7d00&amp;amp;chksm=871b0a43b06c8355376d1bc897b4f3585b4a129d77a9e5b025f4c344f2ef264c05133cff7682&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;深度学习资料大全：从基础到各种网络&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719733&amp;amp;idx=1&amp;amp;sn=2fce6d18e8fcae9b805d4652a7c702e9&amp;amp;chksm=871b018bb06c889d339f34b192579f2e7f97e2f7b64cbe3ccd85ec7b3ed9022178ed5a150359&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719733&amp;amp;idx=1&amp;amp;sn=2fce6d18e8fcae9b805d4652a7c702e9&amp;amp;chksm=871b018bb06c889d339f34b192579f2e7f97e2f7b64cbe3ccd85ec7b3ed9022178ed5a150359&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;30个深度学习库：按Python和C++等10种语言分类&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721418&amp;amp;idx=1&amp;amp;sn=71b28bce48b70f9fa30929db29e685e1&amp;amp;chksm=871b08f4b06c81e24d16ef66265e142de1fd8a18fd872da99a2e70c4e10062ac41575ec0e382&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721418&amp;amp;idx=1&amp;amp;sn=71b28bce48b70f9fa30929db29e685e1&amp;amp;chksm=871b08f4b06c81e24d16ef66265e142de1fd8a18fd872da99a2e70c4e10062ac41575ec0e382&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;2016年不可错过的21个深度学习视频、教程和课程&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721817&amp;amp;idx=4&amp;amp;sn=a2e9f4c19f92fd95040f4b13935c6681&amp;amp;chksm=871b0a67b06c837108989bc0cd0b2dc06ce2c0009190f1ab6cfd38bca5f6d08d6b56e776d811&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721817&amp;amp;idx=4&amp;amp;sn=a2e9f4c19f92fd95040f4b13935c6681&amp;amp;chksm=871b0a67b06c837108989bc0cd0b2dc06ce2c0009190f1ab6cfd38bca5f6d08d6b56e776d811&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;程序员实用深度学习免费课程:从入门到实践&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721817&amp;amp;idx=3&amp;amp;sn=f03d9c31c8db61c7d980b0137c9e2da3&amp;amp;chksm=871b0a67b06c8371ddaa7a49f56ee7b5b9725f52e0a3a930b9d424e7d6fae0ca24bca7e319af&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721817&amp;amp;idx=3&amp;amp;sn=f03d9c31c8db61c7d980b0137c9e2da3&amp;amp;chksm=871b0a67b06c8371ddaa7a49f56ee7b5b9725f52e0a3a930b9d424e7d6fae0ca24bca7e319af&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;9本不容错过的深度学习和神经网络书籍&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719393&amp;amp;idx=1&amp;amp;sn=41ed306d26dd209acfd61ee70efc8cf6&amp;amp;chksm=871b00dfb06c89c9dc8d5da87a0be1b3666c439909b41559097e952b7ccec29bae09823521bf&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719393&amp;amp;idx=1&amp;amp;sn=41ed306d26dd209acfd61ee70efc8cf6&amp;amp;chksm=871b00dfb06c89c9dc8d5da87a0be1b3666c439909b41559097e952b7ccec29bae09823521bf&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;深度学习专业名词表：从激活函数到word2vec&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721717&amp;amp;idx=2&amp;amp;sn=6a58289f9f65448339a845f88f168088&amp;amp;chksm=871b09cbb06c80dd7b790d34e3627eaf3f330b8670350ee5ad3718bc36e3d5f3f30581fe8453&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721717&amp;amp;idx=2&amp;amp;sn=6a58289f9f65448339a845f88f168088&amp;amp;chksm=871b09cbb06c80dd7b790d34e3627eaf3f330b8670350ee5ad3718bc36e3d5f3f30581fe8453&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;2016年年度十大Python库盘点&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716071&amp;amp;idx=1&amp;amp;sn=7aa209732425c6a52536fbb9012a09fd&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716071&amp;amp;idx=1&amp;amp;sn=7aa209732425c6a52536fbb9012a09fd&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;2010-2016年被引用次数最多的深度学习论文&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722147&amp;amp;idx=1&amp;amp;sn=0584e654c66f694502ff2918dcbc3ca1&amp;amp;chksm=871b0b1db06c820bc8396e6b4ab1ced5f0bada892385eabed7fb581c5b911162bfe326bc36a0&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722147&amp;amp;idx=1&amp;amp;sn=0584e654c66f694502ff2918dcbc3ca1&amp;amp;chksm=871b0b1db06c820bc8396e6b4ab1ced5f0bada892385eabed7fb581c5b911162bfe326bc36a0&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;自学数据科学&amp;amp;机器学习，19个数学和统计学公开课推荐&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721121&amp;amp;idx=5&amp;amp;sn=5af0fb9465ce9345c017adfb1d0c9796&amp;amp;chksm=871b0f1fb06c8609b8b9d792b222b16f7b6fa4479a6d426663ab03cf1ebebd5209080bebe48b&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721121&amp;amp;idx=5&amp;amp;sn=5af0fb9465ce9345c017adfb1d0c9796&amp;amp;chksm=871b0f1fb06c8609b8b9d792b222b16f7b6fa4479a6d426663ab03cf1ebebd5209080bebe48b&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;Yoshua Bengio新书《Deep Learning》中文版开放预览（附PDF下载链接）&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715120&amp;amp;idx=2&amp;amp;sn=108bc0f1bac2deb0b423a2587ebe306a&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715120&amp;amp;idx=2&amp;amp;sn=108bc0f1bac2deb0b423a2587ebe306a&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;数据科学家应该掌握的12种机器学习算法（附信息图）&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720472&amp;amp;idx=1&amp;amp;sn=a0d8f835a300fb5d0c4a3a224cc17924&amp;amp;chksm=871b0ca6b06c85b0461163c3043bf45ab6d58dd57263ce381646ba71842608785d97e00014f6&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720472&amp;amp;idx=1&amp;amp;sn=a0d8f835a300fb5d0c4a3a224cc17924&amp;amp;chksm=871b0ca6b06c85b0461163c3043bf45ab6d58dd57263ce381646ba71842608785d97e00014f6&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;从入门到研究，人工智能领域最值得一读的20份资料&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715104&amp;amp;idx=3&amp;amp;sn=2f3c9a625519f6265a3ba755697cad56&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715104&amp;amp;idx=3&amp;amp;sn=2f3c9a625519f6265a3ba755697cad56&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;关于数据科学的十本好书&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719875&amp;amp;idx=1&amp;amp;sn=f1030f9dbd1d8080585b4d3bba3a9b73&amp;amp;chksm=871b02fdb06c8beb2dc94e3f69a76fa56aafb3c310d03e53f3aca2167a27a9e115fbb6b0bfe2&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719875&amp;amp;idx=1&amp;amp;sn=f1030f9dbd1d8080585b4d3bba3a9b73&amp;amp;chksm=871b02fdb06c8beb2dc94e3f69a76fa56aafb3c310d03e53f3aca2167a27a9e115fbb6b0bfe2&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;哈佛大学九大自然语言处理开源项目&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718688&amp;amp;idx=1&amp;amp;sn=c473fd7fe002fe6b8b5b917c432daf27&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718688&amp;amp;idx=1&amp;amp;sn=c473fd7fe002fe6b8b5b917c432daf27&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;ICML 2016演讲视频：数百个演讲带你读懂机器学习&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721717&amp;amp;idx=1&amp;amp;sn=470fef6589c81afa913b2e0572996f92&amp;amp;chksm=871b09cbb06c80ddc4c21fc55511b30c6e1a0461c9f1c0588ce9dd484d6216d819e949a1a259&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721717&amp;amp;idx=1&amp;amp;sn=470fef6589c81afa913b2e0572996f92&amp;amp;chksm=871b09cbb06c80ddc4c21fc55511b30c6e1a0461c9f1c0588ce9dd484d6216d819e949a1a259&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;Yoshua Bengio研究生科研指导演讲：解读人工智能全貌和下一个前沿&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720663&amp;amp;idx=2&amp;amp;sn=d06c7a2e8cdde84901ffd8335a775737&amp;amp;chksm=871b0de9b06c84ff467a63042b17ad1622224fc1ab84597ab80b64ab0049c4f4b09cabc3d7dc&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720663&amp;amp;idx=2&amp;amp;sn=d06c7a2e8cdde84901ffd8335a775737&amp;amp;chksm=871b0de9b06c84ff467a63042b17ad1622224fc1ab84597ab80b64ab0049c4f4b09cabc3d7dc&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;&lt;span&gt;Yann LeCun演讲&lt;span&gt;：人工&lt;/span&gt;&lt;/span&gt;智能的下一个前沿——无监督学习&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720780&amp;amp;idx=1&amp;amp;sn=39ac663849c90ab31d3dd04013f7e646&amp;amp;chksm=871b0e72b06c8764becc21ecb10ece2b7d285f72a85cec79920967abe53bdbf7a16522623caf&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720780&amp;amp;idx=1&amp;amp;sn=39ac663849c90ab31d3dd04013f7e646&amp;amp;chksm=871b0e72b06c8764becc21ecb10ece2b7d285f72a85cec79920967abe53bdbf7a16522623caf&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;今年GitHub排名前20的Python机器学习开源项目&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715438&amp;amp;idx=3&amp;amp;sn=2c2a6e4dfda2307d818dcab385ef6727&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715438&amp;amp;idx=3&amp;amp;sn=2c2a6e4dfda2307d818dcab385ef6727&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;机器学习工程师和数据科学家最应该读的16本书&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722365&amp;amp;idx=4&amp;amp;sn=af6b4a85b4e447d0d54e71399f6d8e93&amp;amp;chksm=871b1443b06c9d55f1678dbe89573c1fcb31758b12b6b992cb63be11b7b1dc6b9f1874cee0bc&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722365&amp;amp;idx=4&amp;amp;sn=af6b4a85b4e447d0d54e71399f6d8e93&amp;amp;chksm=871b1443b06c9d55f1678dbe89573c1fcb31758b12b6b992cb63be11b7b1dc6b9f1874cee0bc&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;任何阶段的学习者都适用的参考：机器学习领域书目全集&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718578&amp;amp;idx=1&amp;amp;sn=ff7d748b149e7952c9fa3b53cefd5afc&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718578&amp;amp;idx=1&amp;amp;sn=ff7d748b149e7952c9fa3b53cefd5afc&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;Yoshua Bengio深度学习暑期班学习总结，35个授课视频全部开放&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722318&amp;amp;idx=2&amp;amp;sn=f03f56fb91bfd5fe393268f74435349f&amp;amp;chksm=871b1470b06c9d661a72d727c76e7f75a8cf57c17c97542cc1c8b330b8969b1fd2748722fb95&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722318&amp;amp;idx=2&amp;amp;sn=f03f56fb91bfd5fe393268f74435349f&amp;amp;chksm=871b1470b06c9d661a72d727c76e7f75a8cf57c17c97542cc1c8b330b8969b1fd2748722fb95&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;Andrej Karpathy CS294课程总结：可视化和理解深度神经网络&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719828&amp;amp;idx=2&amp;amp;sn=c6a73c885c3a8db5f2b0484f7c20498a&amp;amp;chksm=871b022ab06c8b3c8e93ff797be2d68d96945f01b617584e79593e16dcd4a76b19a4642b441d&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719828&amp;amp;idx=2&amp;amp;sn=c6a73c885c3a8db5f2b0484f7c20498a&amp;amp;chksm=871b022ab06c8b3c8e93ff797be2d68d96945f01b617584e79593e16dcd4a76b19a4642b441d&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;Geoffrey Hinton最新演讲梳理：从人工神经网络到RNN应用&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a target="_blank" data_ue_src="http://"&gt;&lt;span&gt;吴恩达NIPS 2016演讲现场直击：如何使用深度学习开发人工智能应用&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721406&amp;amp;idx=1&amp;amp;sn=8251dfebd3c360d180339c34c4710fa7&amp;amp;chksm=871b0800b06c81160244fcda78d7816da8ec31d5fbec546ba6e36241e6d32c0ca943ce9ce73d&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721406&amp;amp;idx=1&amp;amp;sn=8251dfebd3c360d180339c34c4710fa7&amp;amp;chksm=871b0800b06c81160244fcda78d7816da8ec31d5fbec546ba6e36241e6d32c0ca943ce9ce73d&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;NIPS 2016最全盘点：主题详解、前沿论文及下载资源&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719377&amp;amp;idx=1&amp;amp;sn=114e536fc2ca22edcb6ad6ceb332228e&amp;amp;chksm=871b00efb06c89f953e6d7320a7f5fed54e062687425c1dee8166b16704fef23f4eb53b1a473&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719377&amp;amp;idx=1&amp;amp;sn=114e536fc2ca22edcb6ad6ceb332228e&amp;amp;chksm=871b00efb06c89f953e6d7320a7f5fed54e062687425c1dee8166b16704fef23f4eb53b1a473&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;斯坦福大学周末学习盛宴：12位大牛解读深度学习&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719367&amp;amp;idx=1&amp;amp;sn=1cd2e133a56eb3e841e98ab837086df8&amp;amp;chksm=871b00f9b06c89eff783040ad6b30152440e628908fc478b9b8cbce991f914f94237e1333fb1&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719367&amp;amp;idx=1&amp;amp;sn=1cd2e133a56eb3e841e98ab837086df8&amp;amp;chksm=871b00f9b06c89eff783040ad6b30152440e628908fc478b9b8cbce991f914f94237e1333fb1&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;提升深度学习模型的表现，你需要这20个技巧&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720407&amp;amp;idx=1&amp;amp;sn=768d7248e0ab5fa469dbae86d11152e1&amp;amp;chksm=871b0ce9b06c85ffefa2e0c8f6fb7ae4cc1c0500cda7bad008fe68ed6b87d7c8765d138e1fd1&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720407&amp;amp;idx=1&amp;amp;sn=768d7248e0ab5fa469dbae86d11152e1&amp;amp;chksm=871b0ce9b06c85ffefa2e0c8f6fb7ae4cc1c0500cda7bad008fe68ed6b87d7c8765d138e1fd1&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;TensorFlow开源一周年：这可能是一份最完整的盘点&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718160&amp;amp;idx=3&amp;amp;sn=a2114e3324f28740d2603da26fbbdfb4&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718160&amp;amp;idx=3&amp;amp;sn=a2114e3324f28740d2603da26fbbdfb4&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;五大主流深度学习框架比较分析：MXNET是最好选择&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;二、基础介绍文章&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWic17FA5ZBlbiaEavsI2wmR5XlcKzbS0htgFjBuzZZqdvgnBw0XiavstyaNKmgde7F4QyKZRdrR0IYKg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719723&amp;amp;idx=3&amp;amp;sn=0338d470c8668aa912aeebc18c1ced0e&amp;amp;chksm=871b0195b06c8883bab39807043824dcec576180f006226672da649459e7c2de0ecd3fd98c6e&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719723&amp;amp;idx=3&amp;amp;sn=0338d470c8668aa912aeebc18c1ced0e&amp;amp;chksm=871b0195b06c8883bab39807043824dcec576180f006226672da649459e7c2de0ecd3fd98c6e&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;2016伦敦深度学习峰会观感：人工智能面临的三大难题&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722085&amp;amp;idx=1&amp;amp;sn=14a9cc3610e0de25587a707f554939f0&amp;amp;chksm=871b0b5bb06c824da313d70525cca67c9c7417951174455f1e27d9431af132e914c5ab4f6be5&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722085&amp;amp;idx=1&amp;amp;sn=14a9cc3610e0de25587a707f554939f0&amp;amp;chksm=871b0b5bb06c824da313d70525cca67c9c7417951174455f1e27d9431af132e914c5ab4f6be5&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;2016机器学习与自然语言处理学术全景图：卡耐基梅隆大学排名第一&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720407&amp;amp;idx=3&amp;amp;sn=f8484e3aa14bfe9b925d75bb9acc52e2&amp;amp;chksm=871b0ce9b06c85ff78b2ec6a708e0a9128027a8e862a08a2fca38a17d1aa117f48b27402f133&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720407&amp;amp;idx=3&amp;amp;sn=f8484e3aa14bfe9b925d75bb9acc52e2&amp;amp;chksm=871b0ce9b06c85ff78b2ec6a708e0a9128027a8e862a08a2fca38a17d1aa117f48b27402f133&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;2016年美国机器人路线图出炉，最新机器人产业盘点&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720758&amp;amp;idx=3&amp;amp;sn=0d7e70cfd3624296fc8aac4944a359dc&amp;amp;chksm=871b0d88b06c849e71808681107f2b695233bdd37d7a79249cad5b2721f4285ed50577bee89d&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720758&amp;amp;idx=3&amp;amp;sn=0d7e70cfd3624296fc8aac4944a359dc&amp;amp;chksm=871b0d88b06c849e71808681107f2b695233bdd37d7a79249cad5b2721f4285ed50577bee89d&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;一张图看懂全球Bot布局&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715580&amp;amp;idx=1&amp;amp;sn=cc67a90fe35702732f1a67e3e59d80f6&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715580&amp;amp;idx=1&amp;amp;sn=cc67a90fe35702732f1a67e3e59d80f6&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;Yoshua Bengio：深度学习崛起带来人工智能的春天&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718943&amp;amp;idx=1&amp;amp;sn=258117d392ca1bfc37d6496992da5eae&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718943&amp;amp;idx=1&amp;amp;sn=258117d392ca1bfc37d6496992da5eae&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;神经网络架构演进史：全面回顾从LeNet5到ENet十余种架构&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719010&amp;amp;idx=1&amp;amp;sn=aaa7cc47f27129bbced25e6d090e2c1d&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719010&amp;amp;idx=1&amp;amp;sn=aaa7cc47f27129bbced25e6d090e2c1d&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;Andrej Karpathy：计算机科学博士的生存指南&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721559&amp;amp;idx=3&amp;amp;sn=98a74c48397f8a8d9166a3bf0b74fb4f&amp;amp;chksm=871b0969b06c807f90e72c890c4b23308501f46c7315823c3fee1c423817ed81626d3da9d711&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721559&amp;amp;idx=3&amp;amp;sn=98a74c48397f8a8d9166a3bf0b74fb4f&amp;amp;chksm=871b0969b06c807f90e72c890c4b23308501f46c7315823c3fee1c423817ed81626d3da9d711&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;贝叶斯神经网络简史&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720407&amp;amp;idx=2&amp;amp;sn=86603b0276580e9e969e78cac606fe3c&amp;amp;chksm=871b0ce9b06c85ff79c95b4b42ad8bfa8fa14438266e689e7ffe3a882ee024bfd3e0ac90655e&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720407&amp;amp;idx=2&amp;amp;sn=86603b0276580e9e969e78cac606fe3c&amp;amp;chksm=871b0ce9b06c85ff79c95b4b42ad8bfa8fa14438266e689e7ffe3a882ee024bfd3e0ac90655e&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;百度首席科学家吴恩达刊文：人工智能的能力和不足&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721378&amp;amp;idx=1&amp;amp;sn=16f8a955e1459926dd1e66f82e26028c&amp;amp;chksm=871b081cb06c810aedab8a7c1902daf18f3d00f20c1b04ec0645303ffe2023b5e4dd87c41ee8&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721378&amp;amp;idx=1&amp;amp;sn=16f8a955e1459926dd1e66f82e26028c&amp;amp;chksm=871b081cb06c810aedab8a7c1902daf18f3d00f20c1b04ec0645303ffe2023b5e4dd87c41ee8&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;高盛百页人工智能生态报告：美国仍是主导力量，中国正高速成长&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720663&amp;amp;idx=1&amp;amp;sn=ffadef6ce7d0e2d60e09c0c8bdc366c5&amp;amp;chksm=871b0de9b06c84ffad7621ec0b3e7578d085d9557f029067d978a286e22ff5e67e0b98ed209b&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720663&amp;amp;idx=1&amp;amp;sn=ffadef6ce7d0e2d60e09c0c8bdc366c5&amp;amp;chksm=871b0de9b06c84ffad7621ec0b3e7578d085d9557f029067d978a286e22ff5e67e0b98ed209b&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;伯克利教授Stuart Russell：人工智能基础概念与34个误区&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720174&amp;amp;idx=2&amp;amp;sn=cb195f4dfda478510479eba5dc53fc99&amp;amp;chksm=871b03d0b06c8ac674234d2bcea8515c2720bb502bcb281024b71ebaf4864e1e6fad863d3ebd&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720174&amp;amp;idx=2&amp;amp;sn=cb195f4dfda478510479eba5dc53fc99&amp;amp;chksm=871b03d0b06c8ac674234d2bcea8515c2720bb502bcb281024b71ebaf4864e1e6fad863d3ebd&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;初学者必读：解读14个深度学习关键词&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720335&amp;amp;idx=3&amp;amp;sn=7552135b320b24ce9b273423187b5a78&amp;amp;chksm=871b0c31b06c852753124d9962aff43c049f2283dcfa78cc8ca51289aa0dd2db53d88b2c2e96&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720335&amp;amp;idx=3&amp;amp;sn=7552135b320b24ce9b273423187b5a78&amp;amp;chksm=871b0c31b06c852753124d9962aff43c049f2283dcfa78cc8ca51289aa0dd2db53d88b2c2e96&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;智能时代每个人都应该了解：什么是深度学习？&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720553&amp;amp;idx=2&amp;amp;sn=8f77792079e14219da4006247d738652&amp;amp;chksm=871b0d57b06c84414a164a210ac350e6fc22af6ba06c2604c749776431fef53731c7f40439c7&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720553&amp;amp;idx=2&amp;amp;sn=8f77792079e14219da4006247d738652&amp;amp;chksm=871b0d57b06c84414a164a210ac350e6fc22af6ba06c2604c749776431fef53731c7f40439c7&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;CMU机器学习系负责人：人工智能与人类的未来是共生自主&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715759&amp;amp;idx=2&amp;amp;sn=d005ca89ba3b0bd2eae4b7677cbb8be2&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715759&amp;amp;idx=2&amp;amp;sn=d005ca89ba3b0bd2eae4b7677cbb8be2&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;CMU教授邢波：人工智能的路径、方向与未来&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716455&amp;amp;idx=2&amp;amp;sn=48da4b101ef293de0f627aeb3ba3231b&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716455&amp;amp;idx=2&amp;amp;sn=48da4b101ef293de0f627aeb3ba3231b&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;从供应链优化到差异化定价：机器学习十种方式变革制造业&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721938&amp;amp;idx=1&amp;amp;sn=a7568453296f8b34f1bbb6287cb994d0&amp;amp;chksm=871b0aecb06c83fad3b111c2f48206b26c85762e2b9834a07dddd7a282b60a5df2f78c104de5&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721938&amp;amp;idx=1&amp;amp;sn=a7568453296f8b34f1bbb6287cb994d0&amp;amp;chksm=871b0aecb06c83fad3b111c2f48206b26c85762e2b9834a07dddd7a282b60a5df2f78c104de5&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;对比深度学习十大框架：TensorFlow最流行但并不是最好&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721480&amp;amp;idx=3&amp;amp;sn=0ee6a881f01d8d1bee16d2042ac93e5f&amp;amp;chksm=871b08b6b06c81a027a5b5490f1c9decf3d70002e1f1e1869c25c7a12657f9cfa518b855cf9b&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721480&amp;amp;idx=3&amp;amp;sn=0ee6a881f01d8d1bee16d2042ac93e5f&amp;amp;chksm=871b08b6b06c81a027a5b5490f1c9decf3d70002e1f1e1869c25c7a12657f9cfa518b855cf9b&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;当AI遇上AR ——从微软HPU说起&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720922&amp;amp;idx=5&amp;amp;sn=110bf38376c42b55d95521dd04944828&amp;amp;chksm=871b0ee4b06c87f2315db196b47620853d3587c69f9486cf5ae9a19c5aa2d4fa101f4541888b&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720922&amp;amp;idx=5&amp;amp;sn=110bf38376c42b55d95521dd04944828&amp;amp;chksm=871b0ee4b06c87f2315db196b47620853d3587c69f9486cf5ae9a19c5aa2d4fa101f4541888b&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;洞悉AlphaGo超越围棋大师的力量：机器之心邀你一起强化学习&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719022&amp;amp;idx=2&amp;amp;sn=6efb98d3650bd963122744b14b09e1d9&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719022&amp;amp;idx=2&amp;amp;sn=6efb98d3650bd963122744b14b09e1d9&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;东南大学漆桂林教授：知识图谱不仅是一项技术，更是一项工程&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717374&amp;amp;idx=1&amp;amp;sn=14c7af07c4d6859a7cb8d7a8650d5825&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717374&amp;amp;idx=1&amp;amp;sn=14c7af07c4d6859a7cb8d7a8650d5825&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;人工智能全局概览：通用智能的当前困境和未来可能&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722118&amp;amp;idx=1&amp;amp;sn=1934dfd96eedb777b506a7f9fca1c44a&amp;amp;chksm=871b0b38b06c822e4419d7263ece28aa7ad683c4478eb908397c2fae2aa7505529f9708c72d4&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722118&amp;amp;idx=1&amp;amp;sn=1934dfd96eedb777b506a7f9fca1c44a&amp;amp;chksm=871b0b38b06c822e4419d7263ece28aa7ad683c4478eb908397c2fae2aa7505529f9708c72d4&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;访谈百度IDL林元庆：百度大脑如何在人脸识别上战胜人类「最强大脑」&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720302&amp;amp;idx=4&amp;amp;sn=5a54ac9d2097f0db11d1da8a65cf2e4c&amp;amp;chksm=871b0c50b06c85466eb0bb5e455e306deca82662d83895f9d6ad2311539a9adf7056dac306ac&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720302&amp;amp;idx=4&amp;amp;sn=5a54ac9d2097f0db11d1da8a65cf2e4c&amp;amp;chksm=871b0c50b06c85466eb0bb5e455e306deca82662d83895f9d6ad2311539a9adf7056dac306ac&amp;amp;scene=21#wechat_redirect"&gt;TensorFlow 生态系统：与多种开源框架的融合&amp;nbsp;&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719511&amp;amp;idx=2&amp;amp;sn=ef5f5c1d8d70cc81cdcd2c6fde36f695&amp;amp;chksm=871b0169b06c887f46d4b87987bd58881875f352c3bdb5d8c2e39d9898b6bcac8b7c0c31783d&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719511&amp;amp;idx=2&amp;amp;sn=ef5f5c1d8d70cc81cdcd2c6fde36f695&amp;amp;chksm=871b0169b06c887f46d4b87987bd58881875f352c3bdb5d8c2e39d9898b6bcac8b7c0c31783d&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;Kaggle创始人问答：深度学习会淘汰其他的机器学习方法吗？&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721755&amp;amp;idx=1&amp;amp;sn=61837dc0127c1c829522e1772959a0dd&amp;amp;chksm=871b09a5b06c80b3d89848a140f13519bf2c3e264724a8604603751079f43252365e5f40dadd&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721755&amp;amp;idx=1&amp;amp;sn=61837dc0127c1c829522e1772959a0dd&amp;amp;chksm=871b09a5b06c80b3d89848a140f13519bf2c3e264724a8604603751079f43252365e5f40dadd&amp;amp;scene=21#wechat_redirect"&gt;机器之心年度盘点 | 从技术角度，回顾2016年语音识别的发展&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719333&amp;amp;idx=2&amp;amp;sn=ba2491a4c22da7512d9add55c1ac50ee&amp;amp;chksm=871b001bb06c890d71a688cd127557913694240b6a81ea1681552677d63cec27fcd45570dc4d&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719333&amp;amp;idx=2&amp;amp;sn=ba2491a4c22da7512d9add55c1ac50ee&amp;amp;chksm=871b001bb06c890d71a688cd127557913694240b6a81ea1681552677d63cec27fcd45570dc4d&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;机器学习的基本局限性：从一个数学脑筋急转弯说起&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721777&amp;amp;idx=3&amp;amp;sn=20cf64536919147639b2f5cbad38df0f&amp;amp;chksm=871b098fb06c80995100a9afee640203b14f5429f72ee9259b01b6c87d72396beeecdea99144&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721777&amp;amp;idx=3&amp;amp;sn=20cf64536919147639b2f5cbad38df0f&amp;amp;chksm=871b098fb06c80995100a9afee640203b14f5429f72ee9259b01b6c87d72396beeecdea99144&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;人们都在说人工智能，其实现在我们真正做的是智能增强&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717606&amp;amp;idx=4&amp;amp;sn=b94b58d4fe75c1a1e42274720a269a99&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717606&amp;amp;idx=4&amp;amp;sn=b94b58d4fe75c1a1e42274720a269a99&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;人工智能、机器学习、深度学习，三者之间的同心圆关系&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722126&amp;amp;idx=1&amp;amp;sn=00b5c6ed7e4c576c8be3eae1dc348cfe&amp;amp;chksm=871b0b30b06c8226b163198b78ad40b52715509d3b36f0774670d6e0e284378cc3bdeca42d4a&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722126&amp;amp;idx=1&amp;amp;sn=00b5c6ed7e4c576c8be3eae1dc348cfe&amp;amp;chksm=871b0b30b06c8226b163198b78ad40b52715509d3b36f0774670d6e0e284378cc3bdeca42d4a&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;R vs Python：R是现在最好的数据科学语言吗？&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722239&amp;amp;idx=3&amp;amp;sn=aa556d22c8dc71195175930fda1655d0&amp;amp;chksm=871b0bc1b06c82d70e62081d87c1e75291ea15f631aff5c0a5d03de41ffbbcc4be650e63b014&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722239&amp;amp;idx=3&amp;amp;sn=aa556d22c8dc71195175930fda1655d0&amp;amp;chksm=871b0bc1b06c82d70e62081d87c1e75291ea15f631aff5c0a5d03de41ffbbcc4be650e63b014&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;斯坦福NLP团队介绍交互式语言学习：从语言游戏到日程规划&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720597&amp;amp;idx=2&amp;amp;sn=815b3426c4855e446e4aa118abdee0d6&amp;amp;chksm=871b0d2bb06c843da11f16f85510da8cb398542c82a80a8822ac9f78beb24aaf58f066eaaed2&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720597&amp;amp;idx=2&amp;amp;sn=815b3426c4855e446e4aa118abdee0d6&amp;amp;chksm=871b0d2bb06c843da11f16f85510da8cb398542c82a80a8822ac9f78beb24aaf58f066eaaed2&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;斯坦福大学副教授Reza Zadeh：神经网络越深就越难优化&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=402228099&amp;amp;idx=1&amp;amp;sn=a8e664d332f7d28250fbbf357c773f62&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=402228099&amp;amp;idx=1&amp;amp;sn=a8e664d332f7d28250fbbf357c773f62&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;神经网络和深度学习简史（三）：强化学习与递归神经网络&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=402552632&amp;amp;idx=1&amp;amp;sn=694a4a327a79c4efeeb4db15b3ff4a28&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=402552632&amp;amp;idx=1&amp;amp;sn=694a4a327a79c4efeeb4db15b3ff4a28&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;神经网络和深度学习简史（四）：深度学习终迎伟大复兴&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717977&amp;amp;idx=2&amp;amp;sn=705d47688adadcdce6e09a81e3381e2d&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717977&amp;amp;idx=2&amp;amp;sn=705d47688adadcdce6e09a81e3381e2d&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;深度学习技术在股票交易上的应用研究调查&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721378&amp;amp;idx=4&amp;amp;sn=cb49818959281909d8878bea5b34e837&amp;amp;chksm=871b081cb06c810a0075a475beeecbbe41a915679f05d629aa2e4d3a38da45e0899a764a98be&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721378&amp;amp;idx=4&amp;amp;sn=cb49818959281909d8878bea5b34e837&amp;amp;chksm=871b081cb06c810a0075a475beeecbbe41a915679f05d629aa2e4d3a38da45e0899a764a98be&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;深度学习十大飙升趋势&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=401846516&amp;amp;idx=1&amp;amp;sn=ed76da1e8f99c604957c8889692de884&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=401846516&amp;amp;idx=1&amp;amp;sn=ed76da1e8f99c604957c8889692de884&amp;amp;scene=21#wechat_redirect"&gt;深度学习入门，以及它在物联网和智慧城市中的角色&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720765&amp;amp;idx=3&amp;amp;sn=a9ec5e451cc7e46ab254b663ec78c3b6&amp;amp;chksm=871b0d83b06c8495b977ba6f82c3aa5974a6d2066e3fec63f9fc33e7e0766a2008804795895e&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720765&amp;amp;idx=3&amp;amp;sn=a9ec5e451cc7e46ab254b663ec78c3b6&amp;amp;chksm=871b0d83b06c8495b977ba6f82c3aa5974a6d2066e3fec63f9fc33e7e0766a2008804795895e&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;服务器端人工智能，FPGA和GPU到底谁更强？&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721102&amp;amp;idx=1&amp;amp;sn=347d3a3b5fd136df7bc51fb67948fd30&amp;amp;chksm=871b0f30b06c86263fd2d51665aaa5e81d1e3cbc0044ed71ab0f74238a461ba0e75490a04af7&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721102&amp;amp;idx=1&amp;amp;sn=347d3a3b5fd136df7bc51fb67948fd30&amp;amp;chksm=871b0f30b06c86263fd2d51665aaa5e81d1e3cbc0044ed71ab0f74238a461ba0e75490a04af7&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;Science「机器人子刊」创刊号，五大研究解读机器人领域最新进展&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718975&amp;amp;idx=1&amp;amp;sn=2b0ccf0c746e6f10707e5357168d51d6&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718975&amp;amp;idx=1&amp;amp;sn=2b0ccf0c746e6f10707e5357168d51d6&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;西红柿还是猕猴桃？一个案例帮你入门机器学习&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715201&amp;amp;idx=1&amp;amp;sn=d7ad8c79bf060875b6247d634c52449b&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715201&amp;amp;idx=1&amp;amp;sn=d7ad8c79bf060875b6247d634c52449b&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;详细解读神经网络十大误解，再也不会弄错它的工作原理&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719646&amp;amp;idx=2&amp;amp;sn=3f84e8af0ca03476eb843f57b497465e&amp;amp;chksm=871b01e0b06c88f6c77601db4a1d224a5007ba306eac7d0522c0b973ca9c3d57c4fabf57a5c4&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719646&amp;amp;idx=2&amp;amp;sn=3f84e8af0ca03476eb843f57b497465e&amp;amp;chksm=871b01e0b06c88f6c77601db4a1d224a5007ba306eac7d0522c0b973ca9c3d57c4fabf57a5c4&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;基于图的机器学习技术：谷歌众多产品和服务背后的智能&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;三、技术起点&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWic17FA5ZBlbiaEavsI2wmR5XUUmTqyW1ichwTzcwbmWWCEickQ9R8YSQibE6icRr4oicQsJeDPxKUOSAXHA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719723&amp;amp;idx=4&amp;amp;sn=f86e2f30bcee67a424d4617b72560b8d&amp;amp;chksm=871b0195b06c88832108944311c2494a30483590c8c301b0076e2190734a3271e2929db312ed&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719723&amp;amp;idx=4&amp;amp;sn=f86e2f30bcee67a424d4617b72560b8d&amp;amp;chksm=871b0195b06c88832108944311c2494a30483590c8c301b0076e2190734a3271e2929db312ed&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;10种深度学习算法的TensorFlow实现&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719794&amp;amp;idx=2&amp;amp;sn=8e320caa1d32f7a444a17bfa93b318ad&amp;amp;chksm=871b024cb06c8b5a421efa2eedff5b7149d17028d99e95a38857785db06c1eb2b7796d6e7e4f&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719794&amp;amp;idx=2&amp;amp;sn=8e320caa1d32f7a444a17bfa93b318ad&amp;amp;chksm=871b024cb06c8b5a421efa2eedff5b7149d17028d99e95a38857785db06c1eb2b7796d6e7e4f&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;数十种TensorFlow实现案例汇集：代码+笔记&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720367&amp;amp;idx=2&amp;amp;sn=d71e1e6550faece1cb5fb58bd7c919d9&amp;amp;chksm=871b0c11b06c8507d765a781b3ff49c1755deba7f12f36763b468aa23dfafccd768f59538004&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720367&amp;amp;idx=2&amp;amp;sn=d71e1e6550faece1cb5fb58bd7c919d9&amp;amp;chksm=871b0c11b06c8507d765a781b3ff49c1755deba7f12f36763b468aa23dfafccd768f59538004&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;机器学习入门必备：如何用Python从头实现感知器算法&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718527&amp;amp;idx=1&amp;amp;sn=04db4fc59cc23c079a17573657d2b1c7&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718527&amp;amp;idx=1&amp;amp;sn=04db4fc59cc23c079a17573657d2b1c7&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;ACM 最新月刊文章：强化学习的复兴&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720174&amp;amp;idx=4&amp;amp;sn=da197d35bf9b5ac59b9ffb8e442264f0&amp;amp;chksm=871b03d0b06c8ac622e5ff2b83c786b7fb34d49b6186f1d9f1964b28e31c1e0d7b2ac3863afc&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720174&amp;amp;idx=4&amp;amp;sn=da197d35bf9b5ac59b9ffb8e442264f0&amp;amp;chksm=871b03d0b06c8ac622e5ff2b83c786b7fb34d49b6186f1d9f1964b28e31c1e0d7b2ac3863afc&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;人工智能开发者的入门指南&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717691&amp;amp;idx=2&amp;amp;sn=3f0b66aa9706aae1a30b01309aa0214c&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717691&amp;amp;idx=2&amp;amp;sn=3f0b66aa9706aae1a30b01309aa0214c&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;从入门到精通：卷积神经网络初学者指南&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718466&amp;amp;idx=1&amp;amp;sn=016f111001e8354d49dd4ce279d283cd&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718466&amp;amp;idx=1&amp;amp;sn=016f111001e8354d49dd4ce279d283cd&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;机器学习敲门砖：任何人都能看懂的TensorFlow介绍&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720463&amp;amp;idx=2&amp;amp;sn=50d88169778ec31a1e1e2d801325005d&amp;amp;chksm=871b0cb1b06c85a7e0299fc733b67d3107970f1176186a2ac8ca2dd5a23d896b5041e592ab4d&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720463&amp;amp;idx=2&amp;amp;sn=50d88169778ec31a1e1e2d801325005d&amp;amp;chksm=871b0cb1b06c85a7e0299fc733b67d3107970f1176186a2ac8ca2dd5a23d896b5041e592ab4d&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;DeepMind提出的可微神经计算机架构的TensorFlow实现&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718229&amp;amp;idx=4&amp;amp;sn=f47990a661e1522a5794d6334a334830&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718229&amp;amp;idx=4&amp;amp;sn=f47990a661e1522a5794d6334a334830&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;RNN 怎么用？给初学者的小教程&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=401970614&amp;amp;idx=2&amp;amp;sn=479370f70613e431d35c752139c0b602&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=401970614&amp;amp;idx=2&amp;amp;sn=479370f70613e431d35c752139c0b602&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;深度学习教程：从感知器到深层网络&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721559&amp;amp;idx=4&amp;amp;sn=950d87934d39712fab6164d3d2a37be5&amp;amp;chksm=871b0969b06c807f47b6fac20daae25d6d2f57495f6624554550fad7177f56657d208f40690d&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721559&amp;amp;idx=4&amp;amp;sn=950d87934d39712fab6164d3d2a37be5&amp;amp;chksm=871b0969b06c807f47b6fac20daae25d6d2f57495f6624554550fad7177f56657d208f40690d&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;OpenAI 的 PixelCNN++实现：基于 Python的实现&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719828&amp;amp;idx=2&amp;amp;sn=c6a73c885c3a8db5f2b0484f7c20498a&amp;amp;chksm=871b022ab06c8b3c8e93ff797be2d68d96945f01b617584e79593e16dcd4a76b19a4642b441d&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719828&amp;amp;idx=2&amp;amp;sn=c6a73c885c3a8db5f2b0484f7c20498a&amp;amp;chksm=871b022ab06c8b3c8e93ff797be2d68d96945f01b617584e79593e16dcd4a76b19a4642b441d&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;Geoffrey Hinton最新演讲梳理：从人工神经网络到RNN应用&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717557&amp;amp;idx=1&amp;amp;sn=6c8239ec01c2a3f0def744063d070eec&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717557&amp;amp;idx=1&amp;amp;sn=6c8239ec01c2a3f0def744063d070eec&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;官方指南：如何通过玩TensorFlow来理解神经网络&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720174&amp;amp;idx=1&amp;amp;sn=d770ab6ccbf25c6569d002472daf1b3b&amp;amp;chksm=871b03d0b06c8ac6c16a6e37e1dcc2a5f490e4ab5a21b82b76a2a41d3a1d35d76a6a3d21fdc3&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720174&amp;amp;idx=1&amp;amp;sn=d770ab6ccbf25c6569d002472daf1b3b&amp;amp;chksm=871b03d0b06c8ac6c16a6e37e1dcc2a5f490e4ab5a21b82b76a2a41d3a1d35d76a6a3d21fdc3&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;一篇文章带你进入无监督学习:从基本概念到四种实现模型&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721979&amp;amp;idx=2&amp;amp;sn=146a34534414fb4842398cac62cd201a&amp;amp;chksm=871b0ac5b06c83d3eeb71d5b39d74f9d5648d7e334039cf6d6a3d42b18856abc47ba229b8890&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721979&amp;amp;idx=2&amp;amp;sn=146a34534414fb4842398cac62cd201a&amp;amp;chksm=871b0ac5b06c83d3eeb71d5b39d74f9d5648d7e334039cf6d6a3d42b18856abc47ba229b8890&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;NIPS 2016上22篇论文的实现汇集&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721979&amp;amp;idx=1&amp;amp;sn=82ccf18462e569d43d72736aef57177a&amp;amp;chksm=871b0ac5b06c83d30e65fcd1344bf4b9773281af6cd58f4d3e6709f24d66f6c2bbbfaddb8ccf&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721979&amp;amp;idx=1&amp;amp;sn=82ccf18462e569d43d72736aef57177a&amp;amp;chksm=871b0ac5b06c83d30e65fcd1344bf4b9773281af6cd58f4d3e6709f24d66f6c2bbbfaddb8ccf&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;机器学习初学者入门实践：怎样轻松创造高精度分类网络&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718717&amp;amp;idx=1&amp;amp;sn=85038d7c906c135120a8e1a2f7e565ad&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718717&amp;amp;idx=1&amp;amp;sn=85038d7c906c135120a8e1a2f7e565ad&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;解决真实世界问题：如何在不平衡类上使用机器学习？&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717628&amp;amp;idx=1&amp;amp;sn=a6f1b35f8168f1bc842ca36bb3a69368&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717628&amp;amp;idx=1&amp;amp;sn=a6f1b35f8168f1bc842ca36bb3a69368&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;卷积神经网络架构详解：它与神经网络有何不同？&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717709&amp;amp;idx=2&amp;amp;sn=2bff1e56bc75d65e178476ea9a93b2c5&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717709&amp;amp;idx=2&amp;amp;sn=2bff1e56bc75d65e178476ea9a93b2c5&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;LSTM和递归网络基础教程&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718717&amp;amp;idx=2&amp;amp;sn=9cf62b1b684f5dea3c735d1413a50689&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718717&amp;amp;idx=2&amp;amp;sn=9cf62b1b684f5dea3c735d1413a50689&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;门外汉如何使用谷歌的Prediction API做机器学习&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718597&amp;amp;idx=2&amp;amp;sn=98c141c6d73eb62a0f3f8aa2a8231b66&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718597&amp;amp;idx=2&amp;amp;sn=98c141c6d73eb62a0f3f8aa2a8231b66&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;NVIDIA趣味解读：深度学习训练和推理有何不同？&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722126&amp;amp;idx=4&amp;amp;sn=96b2fa1fe3fc858d415ddddf2ac3f8e5&amp;amp;chksm=871b0b30b06c82262fec886bc76b0427542dcf8b1fb4bae62d851d032e4fc22d247e981f263f&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722126&amp;amp;idx=4&amp;amp;sn=96b2fa1fe3fc858d415ddddf2ac3f8e5&amp;amp;chksm=871b0b30b06c82262fec886bc76b0427542dcf8b1fb4bae62d851d032e4fc22d247e981f263f&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;如何利用 Python 打造一款简易版 AlphaGo&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715104&amp;amp;idx=2&amp;amp;sn=f6ba338c02f8e08c7821b4ecd5a527e9&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715104&amp;amp;idx=2&amp;amp;sn=f6ba338c02f8e08c7821b4ecd5a527e9&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;如何用图像识别技术来变革商业？这里有份操作指南&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719093&amp;amp;idx=4&amp;amp;sn=d852318f6b3adb5ef7730def66fb0a93&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719093&amp;amp;idx=4&amp;amp;sn=d852318f6b3adb5ef7730def66fb0a93&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;MIT生成视频模型，预测静态图片的未来场景&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720257&amp;amp;idx=1&amp;amp;sn=92ac1424c5880a406c1a00558359792b&amp;amp;chksm=871b0c7fb06c8569e23927623aa3c98af8a3377069ba6cd11a0acecb54cd8ce7896e29238b97&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720257&amp;amp;idx=1&amp;amp;sn=92ac1424c5880a406c1a00558359792b&amp;amp;chksm=871b0c7fb06c8569e23927623aa3c98af8a3377069ba6cd11a0acecb54cd8ce7896e29238b97&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;EMNLP 2016干货：从原理到代码全面剖析可用于NLP的神经网络&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718504&amp;amp;idx=1&amp;amp;sn=ba884ec5bd9dd93b77c85f91d8371056&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718504&amp;amp;idx=1&amp;amp;sn=ba884ec5bd9dd93b77c85f91d8371056&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;使用机器学习翻译语言：神经网络和seq2seq为何效果非凡？&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720758&amp;amp;idx=1&amp;amp;sn=3004c425e0d427f4900a182d74bed31d&amp;amp;chksm=871b0d88b06c849e951469ae1ed54e5f66074d6322eb6681c85727bb8199154709c04c48c034&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720758&amp;amp;idx=1&amp;amp;sn=3004c425e0d427f4900a182d74bed31d&amp;amp;chksm=871b0d88b06c849e951469ae1ed54e5f66074d6322eb6681c85727bb8199154709c04c48c034&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;神经网络快速入门：什么是多层感知器和反向传播？&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718853&amp;amp;idx=4&amp;amp;sn=4f33d503f1602e608b34c6cda4e55dad&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718853&amp;amp;idx=4&amp;amp;sn=4f33d503f1602e608b34c6cda4e55dad&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;神经网络中激活函数的作用&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720582&amp;amp;idx=2&amp;amp;sn=06076c800c912622d8fa42665d7de1fc&amp;amp;chksm=871b0d38b06c842e3f6edaa5d36046b6702d26a0bcfb710c2010e5f0815389bf4f60077441ef&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720582&amp;amp;idx=2&amp;amp;sn=06076c800c912622d8fa42665d7de1fc&amp;amp;chksm=871b0d38b06c842e3f6edaa5d36046b6702d26a0bcfb710c2010e5f0815389bf4f60077441ef&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;逐层剖析，谷歌机器翻译突破背后的神经网络架构是怎样的？&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719294&amp;amp;idx=1&amp;amp;sn=f1a01cd6710e6ea9629619cd3324d102&amp;amp;chksm=871b0040b06c895642ff961a6fe81f05c5e9776aff5da4845f2d3d874f88213863afd2059833&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719294&amp;amp;idx=1&amp;amp;sn=f1a01cd6710e6ea9629619cd3324d102&amp;amp;chksm=871b0040b06c895642ff961a6fe81f05c5e9776aff5da4845f2d3d874f88213863afd2059833&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;深度学习漫游指南：强化学习概览&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717969&amp;amp;idx=1&amp;amp;sn=712e4880e63db42bcb4db5ba06c9856d&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717969&amp;amp;idx=1&amp;amp;sn=712e4880e63db42bcb4db5ba06c9856d&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;深度学习与神经网络全局概览：核心技术的发展历程&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=402261356&amp;amp;idx=1&amp;amp;sn=f66ee62b002b8a9879d3c428f846e440&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=402261356&amp;amp;idx=1&amp;amp;sn=f66ee62b002b8a9879d3c428f846e440&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;最全的深度学习硬件指南&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719118&amp;amp;idx=2&amp;amp;sn=fad8b7cad70cc6a227f88ae07a89db66&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719118&amp;amp;idx=2&amp;amp;sn=fad8b7cad70cc6a227f88ae07a89db66&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;主流深度学习框架对比：看你最适合哪一款？&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;四、继续进阶&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWic17FA5ZBlbiaEavsI2wmR5XyMML92qa5OichfA9LIr2ZV4hAIqkcSaVZr3RiajjE1rR2Vic6SDlQebXA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720132&amp;amp;idx=1&amp;amp;sn=d630d47c4ab60d35752aba74a9d53361&amp;amp;chksm=871b03fab06c8aec767776a6a4a407c3897dcad26392b24a22536261565e9dc6b5ce52df0816&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720132&amp;amp;idx=1&amp;amp;sn=d630d47c4ab60d35752aba74a9d53361&amp;amp;chksm=871b03fab06c8aec767776a6a4a407c3897dcad26392b24a22536261565e9dc6b5ce52df0816&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;40年认知架构研究概览：实现通用人工智能的道路上我们已走了多远？&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721682&amp;amp;idx=1&amp;amp;sn=6bdbf5739bb312449cb60cb6679f98d2&amp;amp;chksm=871b09ecb06c80fa59dba741fb79e44021d5ae16f67488c38b3fb477235a203931da86c829bc&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721682&amp;amp;idx=1&amp;amp;sn=6bdbf5739bb312449cb60cb6679f98d2&amp;amp;chksm=871b09ecb06c80fa59dba741fb79e44021d5ae16f67488c38b3fb477235a203931da86c829bc&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;第四范式联合创始人陈雨强：机器学习在工业应用中的新思考&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719971&amp;amp;idx=2&amp;amp;sn=c7e0d1f6dd4e9ddce291e9bc2c85c65f&amp;amp;chksm=871b029db06c8b8b7557095989dd3fdb57b86a1d7923c388ca1e74255d07f08992bb0461d958&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719971&amp;amp;idx=2&amp;amp;sn=c7e0d1f6dd4e9ddce291e9bc2c85c65f&amp;amp;chksm=871b029db06c8b8b7557095989dd3fdb57b86a1d7923c388ca1e74255d07f08992bb0461d958&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;词嵌入系列博客Part1：基于语言建模的词嵌入模型&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720050&amp;amp;idx=2&amp;amp;sn=9fedc937d3128462c478ef7911e77687&amp;amp;chksm=871b034cb06c8a5a8db8a10f708c81025fc62084d871ac5d184bab5098cb64e939c1c23a7369&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720050&amp;amp;idx=2&amp;amp;sn=9fedc937d3128462c478ef7911e77687&amp;amp;chksm=871b034cb06c8a5a8db8a10f708c81025fc62084d871ac5d184bab5098cb64e939c1c23a7369&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;词嵌入系列博客Part2：比较语言建模中近似 softmax 的几种方法&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720074&amp;amp;idx=2&amp;amp;sn=183fc6285835a48ae7c6bbcce228b063&amp;amp;chksm=871b0334b06c8a22b072f61d4f914210468db7df36a1c6586bd9b6bf3fc6d9f821101d5254c0&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720074&amp;amp;idx=2&amp;amp;sn=183fc6285835a48ae7c6bbcce228b063&amp;amp;chksm=871b0334b06c8a22b072f61d4f914210468db7df36a1c6586bd9b6bf3fc6d9f821101d5254c0&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;词嵌入系列博客Part3：word2vec 的秘密配方&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718853&amp;amp;idx=1&amp;amp;sn=17462cfef179876db1f9d29dbd95ba2c&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718853&amp;amp;idx=1&amp;amp;sn=17462cfef179876db1f9d29dbd95ba2c&amp;amp;scene=21#wechat_redirect"&gt;从分割到识别，全面解析Facebook开源的3款机器视觉工具&amp;nbsp;&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718786&amp;amp;idx=1&amp;amp;sn=58e6cdf2ffb0f47eb831e0cd623ce0e1&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718786&amp;amp;idx=1&amp;amp;sn=58e6cdf2ffb0f47eb831e0cd623ce0e1&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;从硬件到软件：OpenAI 解读自家的深度学习基础架构&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719694&amp;amp;idx=1&amp;amp;sn=93c5aa0b6dd9cdb35c8b8186ce70afff&amp;amp;chksm=871b01b0b06c88a6ee9c3264e67b3e3256f007c4046fefb1d003f91ada71d00547f91b48ca21&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719694&amp;amp;idx=1&amp;amp;sn=93c5aa0b6dd9cdb35c8b8186ce70afff&amp;amp;chksm=871b01b0b06c88a6ee9c3264e67b3e3256f007c4046fefb1d003f91ada71d00547f91b48ca21&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;分布式深度学习：神经网络的分布式训练&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720463&amp;amp;idx=4&amp;amp;sn=ddffc71e49002f731ada533cf05cc84d&amp;amp;chksm=871b0cb1b06c85a73aeb3562836c2ff15357417ce7106ceed06f8987b1cdb70a990895592e9d&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720463&amp;amp;idx=4&amp;amp;sn=ddffc71e49002f731ada533cf05cc84d&amp;amp;chksm=871b0cb1b06c85a73aeb3562836c2ff15357417ce7106ceed06f8987b1cdb70a990895592e9d&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;Embedding 新框架模型：Exponential Family Embeddings&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719294&amp;amp;idx=3&amp;amp;sn=d23a6d7c03732f7218f70447336801bd&amp;amp;chksm=871b0040b06c89564722f7292215997f474374d43d26761700f00b240e83a9c5dc2dd7595a26&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719294&amp;amp;idx=3&amp;amp;sn=d23a6d7c03732f7218f70447336801bd&amp;amp;chksm=871b0040b06c89564722f7292215997f474374d43d26761700f00b240e83a9c5dc2dd7595a26&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;FPGA vs. ASIC，谁将引领移动端人工智能潮流？&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717977&amp;amp;idx=3&amp;amp;sn=e07366137aab6694c3d3d4a311ed6c54&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717977&amp;amp;idx=3&amp;amp;sn=e07366137aab6694c3d3d4a311ed6c54&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;概述性论文：卷积神经网络的近期研究进展&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715279&amp;amp;idx=2&amp;amp;sn=fd25ed0539b7bf8e79f5e99eea47b889&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715279&amp;amp;idx=2&amp;amp;sn=fd25ed0539b7bf8e79f5e99eea47b889&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;《Nature》 封面文章：人工智能引发材料科学变革&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721922&amp;amp;idx=3&amp;amp;sn=b7af3daa477955e0466c521fd45a23e6&amp;amp;chksm=871b0afcb06c83ead80f3cc7e2e650ba441d4068ecd10532272fc4c0b88aadf8b9b24fa8cc19&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721922&amp;amp;idx=3&amp;amp;sn=b7af3daa477955e0466c521fd45a23e6&amp;amp;chksm=871b0afcb06c83ead80f3cc7e2e650ba441d4068ecd10532272fc4c0b88aadf8b9b24fa8cc19&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;概述论文：迁移学习研究全貌&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721602&amp;amp;idx=2&amp;amp;sn=f18e2d3a23dec485350611651e571031&amp;amp;chksm=871b093cb06c802aecc953e10c6bf5a14784ce3bad2c82170262ed6d6d7daedfcea9cceb804d&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721602&amp;amp;idx=2&amp;amp;sn=f18e2d3a23dec485350611651e571031&amp;amp;chksm=871b093cb06c802aecc953e10c6bf5a14784ce3bad2c82170262ed6d6d7daedfcea9cceb804d&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;Andrej Karpathy：你为什么应该理解反向传播&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721284&amp;amp;idx=1&amp;amp;sn=427e7f45c8253ab22a3960978409f5d1&amp;amp;chksm=871b087ab06c816c424ad03810be3e1b3aa9d6e99a5f325047796f110d178a07736f667d1a10&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721284&amp;amp;idx=1&amp;amp;sn=427e7f45c8253ab22a3960978409f5d1&amp;amp;chksm=871b087ab06c816c424ad03810be3e1b3aa9d6e99a5f325047796f110d178a07736f667d1a10&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;GAN之父NIPS 2016演讲现场直击：全方位解读生成对抗网络的原理及未来&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719228&amp;amp;idx=2&amp;amp;sn=b3ccd8c77c2ef81369c02b85de013038&amp;amp;chksm=871b0782b06c8e94e88ce927f8357a6637b051c9f2ace9dbadea84c77b1b8ca0fec7efdb7448&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719228&amp;amp;idx=2&amp;amp;sn=b3ccd8c77c2ef81369c02b85de013038&amp;amp;chksm=871b0782b06c8e94e88ce927f8357a6637b051c9f2ace9dbadea84c77b1b8ca0fec7efdb7448&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;Google Brain 讲解注意力模型和增强RNN&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719723&amp;amp;idx=2&amp;amp;sn=03925a0eb5a8b78cc2642781b924032c&amp;amp;chksm=871b0195b06c888336f97ac330524580589bf29b073aa76585319a6ad43744a5697d6a424b0f&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719723&amp;amp;idx=2&amp;amp;sn=03925a0eb5a8b78cc2642781b924032c&amp;amp;chksm=871b0195b06c888336f97ac330524580589bf29b073aa76585319a6ad43744a5697d6a424b0f&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;谷歌Magenta项目是如何教神经网络编写音乐的？&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721644&amp;amp;idx=4&amp;amp;sn=51ff444c29797ea83f55f47c694b2e84&amp;amp;chksm=871b0912b06c8004a9d5cf461a496b693f5c5010896a0b32f1ae5ede9ab32ce2de4b2a8f37b0&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721644&amp;amp;idx=4&amp;amp;sn=51ff444c29797ea83f55f47c694b2e84&amp;amp;chksm=871b0912b06c8004a9d5cf461a496b693f5c5010896a0b32f1ae5ede9ab32ce2de4b2a8f37b0&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;基于MXNet 的神经机器翻译实现&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721121&amp;amp;idx=3&amp;amp;sn=e21d84cb34b75b744a31fb27c3af8528&amp;amp;chksm=871b0f1fb06c8609de11c76854c1ad9582aece4b79eed6d94b588498109d78a2c62ffe69e02c&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721121&amp;amp;idx=3&amp;amp;sn=e21d84cb34b75b744a31fb27c3af8528&amp;amp;chksm=871b0f1fb06c8609de11c76854c1ad9582aece4b79eed6d94b588498109d78a2c62ffe69e02c&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;2016深度学习重大进展：从无监督学习到生成对抗网络&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715145&amp;amp;idx=1&amp;amp;sn=84ddd1cbb981e260e49100ec39d01663&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715145&amp;amp;idx=1&amp;amp;sn=84ddd1cbb981e260e49100ec39d01663&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;深度学习遇上基因组，诊断疾病和揭示深层生物原理或迎来突破&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719794&amp;amp;idx=3&amp;amp;sn=a64c739eab79f95c85685db7b06d3649&amp;amp;chksm=871b024cb06c8b5aa3e8b3ddd59de64dcf32f05b068bda1fa6c9400a491de6f63b1ca4a81d14&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719794&amp;amp;idx=3&amp;amp;sn=a64c739eab79f95c85685db7b06d3649&amp;amp;chksm=871b024cb06c8b5aa3e8b3ddd59de64dcf32f05b068bda1fa6c9400a491de6f63b1ca4a81d14&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;King+Woman-Man=Queen:用基于Spark的机器学习来捕捉词意&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721817&amp;amp;idx=2&amp;amp;sn=110962b592985cb01216feafe0d8510e&amp;amp;chksm=871b0a67b06c8371b96cff1675cc762f4677dc02a94d985c21c28ba8af1c1afccca64080e41f&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721817&amp;amp;idx=2&amp;amp;sn=110962b592985cb01216feafe0d8510e&amp;amp;chksm=871b0a67b06c8371b96cff1675cc762f4677dc02a94d985c21c28ba8af1c1afccca64080e41f&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;初学者必读:从迭代的五个层面理解机器学习&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722553&amp;amp;idx=5&amp;amp;sn=81228e1becc1895699fd5a87e120be05&amp;amp;chksm=871b1487b06c9d915136b64c14800f60af13ac956060716b654b1a8944beffe0947b036cce47&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722553&amp;amp;idx=5&amp;amp;sn=81228e1becc1895699fd5a87e120be05&amp;amp;chksm=871b1487b06c9d915136b64c14800f60af13ac956060716b654b1a8944beffe0947b036cce47&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;轻量级Matlab深度学习框架LightNet的实现&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650714956&amp;amp;idx=3&amp;amp;sn=de8326724feb96cd5891e6198226a365&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650714956&amp;amp;idx=3&amp;amp;sn=de8326724feb96cd5891e6198226a365&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;如何基于机器学习设计一套智能交易系统？&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718229&amp;amp;idx=1&amp;amp;sn=adaf68f2c193028f1c4de5b8d3217cca&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718229&amp;amp;idx=1&amp;amp;sn=adaf68f2c193028f1c4de5b8d3217cca&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;如何在TensorFlow中用深度学习修复图像？&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720420&amp;amp;idx=2&amp;amp;sn=179fa42fafe685265fef3b88f186fd62&amp;amp;chksm=871b0cdab06c85cc1500ab14605fe2848188bb55cebd0cfdb1af6c6b1e0c1d2f2b3cf886394a&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720420&amp;amp;idx=2&amp;amp;sn=179fa42fafe685265fef3b88f186fd62&amp;amp;chksm=871b0cdab06c85cc1500ab14605fe2848188bb55cebd0cfdb1af6c6b1e0c1d2f2b3cf886394a&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;机器学习中的并行计算：GPU、CUDA和实际应用&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720922&amp;amp;idx=5&amp;amp;sn=110bf38376c42b55d95521dd04944828&amp;amp;chksm=871b0ee4b06c87f2315db196b47620853d3587c69f9486cf5ae9a19c5aa2d4fa101f4541888b&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720922&amp;amp;idx=5&amp;amp;sn=110bf38376c42b55d95521dd04944828&amp;amp;chksm=871b0ee4b06c87f2315db196b47620853d3587c69f9486cf5ae9a19c5aa2d4fa101f4541888b&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;深度解读AlphaGo胜利背后的力量：强化学习&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718429&amp;amp;idx=1&amp;amp;sn=46214968459af95e85efe12b8a26b11b&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718429&amp;amp;idx=1&amp;amp;sn=46214968459af95e85efe12b8a26b11b&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;英伟达自动驾驶技术解读：用于自动驾驶汽车的端到端深度学习&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720663&amp;amp;idx=3&amp;amp;sn=d9f671f77be23a148d1830448154a545&amp;amp;chksm=871b0de9b06c84ffaf260b9ba2a010108cca62d5ce3dcbd8c98c72c9f786f9cd460b27b496ca&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720663&amp;amp;idx=3&amp;amp;sn=d9f671f77be23a148d1830448154a545&amp;amp;chksm=871b0de9b06c84ffaf260b9ba2a010108cca62d5ce3dcbd8c98c72c9f786f9cd460b27b496ca&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;深度解读最流行的优化算法：梯度下降&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718391&amp;amp;idx=1&amp;amp;sn=99fd9d942768706e93f7f1aa744ea4b7&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718391&amp;amp;idx=1&amp;amp;sn=99fd9d942768706e93f7f1aa744ea4b7&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;Science：斯坦福大学用迁移学习预测非洲贫困状况&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720823&amp;amp;idx=4&amp;amp;sn=2ed3964e94e3076e060e48a4708faa2a&amp;amp;chksm=871b0e49b06c875fd2ead27692e8c2b35ac38724adc0215183a434283f4f869fde11e7036c5e&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720823&amp;amp;idx=4&amp;amp;sn=2ed3964e94e3076e060e48a4708faa2a&amp;amp;chksm=871b0e49b06c875fd2ead27692e8c2b35ac38724adc0215183a434283f4f869fde11e7036c5e&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;用 Word2vec 轻松处理新金融风控场景中的文本类数据&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720969&amp;amp;idx=1&amp;amp;sn=d5723c205f594616932624684d3a1327&amp;amp;chksm=871b0eb7b06c87a1d4d9809b35c361a4d8a4bf75315eaa9502a051058b184fb233e5b2d2695c&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720969&amp;amp;idx=1&amp;amp;sn=d5723c205f594616932624684d3a1327&amp;amp;chksm=871b0eb7b06c87a1d4d9809b35c361a4d8a4bf75315eaa9502a051058b184fb233e5b2d2695c&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;Science：实用量子计算机已近在咫尺&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720561&amp;amp;idx=3&amp;amp;sn=76741dd8ae09d6493b3abebcbd387520&amp;amp;chksm=871b0d4fb06c8459752dff98c4ffd59a8fd6114f1c43b2e1e9c85294402f3adf7947f74e1bab&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720561&amp;amp;idx=3&amp;amp;sn=76741dd8ae09d6493b3abebcbd387520&amp;amp;chksm=871b0d4fb06c8459752dff98c4ffd59a8fd6114f1c43b2e1e9c85294402f3adf7947f74e1bab&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;深度学习硬件架构简述&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718634&amp;amp;idx=1&amp;amp;sn=1220e691541c34281c64655a01793cb0&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718634&amp;amp;idx=1&amp;amp;sn=1220e691541c34281c64655a01793cb0&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;深度学习系列Part2：迁移学习和微调深度卷积神经网络&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719170&amp;amp;idx=1&amp;amp;sn=68b6b7f87677f5287b6e5a306409653b&amp;amp;chksm=871b07bcb06c8eaa0a649d7d3fd7963423dd4ea51b6e7711bc63653a528fbf196566345ae064&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719170&amp;amp;idx=1&amp;amp;sn=68b6b7f87677f5287b6e5a306409653b&amp;amp;chksm=871b07bcb06c8eaa0a649d7d3fd7963423dd4ea51b6e7711bc63653a528fbf196566345ae064&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;图文并茂的神经网络架构大盘点：从基本原理到衍生关系&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717143&amp;amp;idx=1&amp;amp;sn=4eb48040935380a7c87d18efea403d58&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717143&amp;amp;idx=1&amp;amp;sn=4eb48040935380a7c87d18efea403d58&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;为你的深度学习任务挑选性价比最高GPU&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719511&amp;amp;idx=3&amp;amp;sn=0674ef2a2e995d180ca081ed3a6ae1b9&amp;amp;chksm=871b0169b06c887feefc5604f1f53081e919eadec5c3d02c25d8da786de0bfa23141bd3f184e&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719511&amp;amp;idx=3&amp;amp;sn=0674ef2a2e995d180ca081ed3a6ae1b9&amp;amp;chksm=871b0169b06c887feefc5604f1f53081e919eadec5c3d02c25d8da786de0bfa23141bd3f184e&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;详解谷歌神经网络图像压缩技术：高质量地将图像压缩得更小&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718229&amp;amp;idx=3&amp;amp;sn=bb2fd16046e6e08bea612a5f7fd0f2dd&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718229&amp;amp;idx=3&amp;amp;sn=bb2fd16046e6e08bea612a5f7fd0f2dd&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;用于视觉任务的CNN为何能在听觉任务上取得成功？&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722208&amp;amp;idx=1&amp;amp;sn=52397806416c7d7f570d5c8fc9ecb96e&amp;amp;chksm=871b0bdeb06c82c85c03e7a07a3c71d9258969470ed8b70eeff850db98a0b7b98cda6fe787ee&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722208&amp;amp;idx=1&amp;amp;sn=52397806416c7d7f570d5c8fc9ecb96e&amp;amp;chksm=871b0bdeb06c82c85c03e7a07a3c71d9258969470ed8b70eeff850db98a0b7b98cda6fe787ee&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;自然语言处理领域深度学习研究总结：从基本概念到前沿成果&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720780&amp;amp;idx=3&amp;amp;sn=bac6cbe4972c236ee0bcdbf76139fa98&amp;amp;chksm=871b0e72b06c8764837fdf6f6cc8b01361b883c0a86bb253163cde5f380beb2e413d855d84b9&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720780&amp;amp;idx=3&amp;amp;sn=bac6cbe4972c236ee0bcdbf76139fa98&amp;amp;chksm=871b0e72b06c8764837fdf6f6cc8b01361b883c0a86bb253163cde5f380beb2e413d855d84b9&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;专访谷歌Jeff Dean：强化学习适合的任务与产品化应用&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720302&amp;amp;idx=1&amp;amp;sn=c88634da158f36db23b9dc7d0dc550ad&amp;amp;chksm=871b0c50b06c854694984e193f289deb51a5efe71f53223dc37feb70509fd957c8af5bb61ab3&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720302&amp;amp;idx=1&amp;amp;sn=c88634da158f36db23b9dc7d0dc550ad&amp;amp;chksm=871b0c50b06c854694984e193f289deb51a5efe71f53223dc37feb70509fd957c8af5bb61ab3&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;重磅论文：解析深度卷积神经网络的14种设计模式&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;五、前沿研究&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWic17FA5ZBlbiaEavsI2wmR5XZribybxutUNvxSC3xw8gcIg3fUbQuD240T0iceS1hsA3ob3XGzH8UH0g/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721777&amp;amp;idx=4&amp;amp;sn=a55d6807a8e65059c426876c623f655b&amp;amp;chksm=871b098fb06c80990a07affb5ecae55b496ca5e3a8b42e686d287b3bd308235c04a2d29c9a28&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721777&amp;amp;idx=4&amp;amp;sn=a55d6807a8e65059c426876c623f655b&amp;amp;chksm=871b098fb06c80990a07affb5ecae55b496ca5e3a8b42e686d287b3bd308235c04a2d29c9a28&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;并行运算，Facebook提出门控卷积神经网络的语言建模&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718798&amp;amp;idx=3&amp;amp;sn=6ec32a0f0f09b8f193c578ee0af9d7ae&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718798&amp;amp;idx=3&amp;amp;sn=6ec32a0f0f09b8f193c578ee0af9d7ae&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;FAIR与微软研究院合著论文：通过虚拟问答衡量机器智能&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717728&amp;amp;idx=2&amp;amp;sn=228e5905d7cd6fd175fc596e2d511eed&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717728&amp;amp;idx=2&amp;amp;sn=228e5905d7cd6fd175fc596e2d511eed&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;FusionNet融合三个卷积网络：识别对象从二维升级到三维&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720234&amp;amp;idx=3&amp;amp;sn=1fe8cce38750ad900e31109e4358ee0a&amp;amp;chksm=871b0394b06c8a826c9af5302dc38ccc8279db3288b573227d0547d27a720aec5dba2592e0e6&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720234&amp;amp;idx=3&amp;amp;sn=1fe8cce38750ad900e31109e4358ee0a&amp;amp;chksm=871b0394b06c8a826c9af5302dc38ccc8279db3288b573227d0547d27a720aec5dba2592e0e6&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;谷歌新论文提出神经符号机：使用弱监督在Freebase上学习语义解析器&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720399&amp;amp;idx=4&amp;amp;sn=3dcdb45229af883cd646985fe0964537&amp;amp;chksm=871b0cf1b06c85e7eeebdb857bcc95b456e5f5ccdb597c9739d6b2fda96069bc1fc53cb32b6b&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720399&amp;amp;idx=4&amp;amp;sn=3dcdb45229af883cd646985fe0964537&amp;amp;chksm=871b0cf1b06c85e7eeebdb857bcc95b456e5f5ccdb597c9739d6b2fda96069bc1fc53cb32b6b&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;Google Brain与OpenAI合作论文：规模化的对抗机器学习&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721644&amp;amp;idx=5&amp;amp;sn=55b63682dc248b842e9229f6db251c6e&amp;amp;chksm=871b0912b06c800437eedb3fab4ca179a8e83aac4c2879b218974a26e26f79cf6829aa6f4dfd&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721644&amp;amp;idx=5&amp;amp;sn=55b63682dc248b842e9229f6db251c6e&amp;amp;chksm=871b0912b06c800437eedb3fab4ca179a8e83aac4c2879b218974a26e26f79cf6829aa6f4dfd&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;谷歌新论文：使用生成对抗网络的无监督像素级域适应&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720367&amp;amp;idx=3&amp;amp;sn=15551131dbd1d1fad15d2752dd78fe83&amp;amp;chksm=871b0c11b06c8507b17d846e7d09b8fc4f0f12267d2f7dd019afa3d0ca3345a8774041ef5c84&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720367&amp;amp;idx=3&amp;amp;sn=15551131dbd1d1fad15d2752dd78fe83&amp;amp;chksm=871b0c11b06c8507b17d846e7d09b8fc4f0f12267d2f7dd019afa3d0ca3345a8774041ef5c84&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;谷歌ICLR 2017论文提出超大规模的神经网络：稀疏门控专家混合层&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718466&amp;amp;idx=3&amp;amp;sn=ffeb503724abb0934c5c60e1202b12c0&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718466&amp;amp;idx=3&amp;amp;sn=ffeb503724abb0934c5c60e1202b12c0&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;谷歌论文：使用循环神经网络的全分辨率图像压缩&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722239&amp;amp;idx=4&amp;amp;sn=3544eee8b2bf5eeab1ae852ba9fde64c&amp;amp;chksm=871b0bc1b06c82d74fa57cbcb0d9f6178a78d474c6bfe93db174dd0c8f580272e398006b0f14&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722239&amp;amp;idx=4&amp;amp;sn=3544eee8b2bf5eeab1ae852ba9fde64c&amp;amp;chksm=871b0bc1b06c82d74fa57cbcb0d9f6178a78d474c6bfe93db174dd0c8f580272e398006b0f14&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;谷歌新论文提出适应性生成对抗网络AdaGAN：增强生成模型&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718943&amp;amp;idx=4&amp;amp;sn=f93b540a0b28100a6912e916d2ad1ac0&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718943&amp;amp;idx=4&amp;amp;sn=f93b540a0b28100a6912e916d2ad1ac0&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;谷歌技术论文：用于YouTube推荐的深度神经网络&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719170&amp;amp;idx=3&amp;amp;sn=5c9dd730e1454335efdae14b24cd2053&amp;amp;chksm=871b07bcb06c8eaa7e4e210727f03214ddf633513522828ac2d3c5a339ee50486d5f32833566&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719170&amp;amp;idx=3&amp;amp;sn=5c9dd730e1454335efdae14b24cd2053&amp;amp;chksm=871b07bcb06c8eaa7e4e210727f03214ddf633513522828ac2d3c5a339ee50486d5f32833566&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;谷歌与微软合著论文：由知识引导的结构化注意网络&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719594&amp;amp;idx=2&amp;amp;sn=b8398c3059b23babb02487baf2cc738f&amp;amp;chksm=871b0114b06c8802ed86e1bc0a17fb33d79500962206eb480bdf023b25c753a7535bb877df2b&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719594&amp;amp;idx=2&amp;amp;sn=b8398c3059b23babb02487baf2cc738f&amp;amp;chksm=871b0114b06c8802ed86e1bc0a17fb33d79500962206eb480bdf023b25c753a7535bb877df2b&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;谷歌深度解读：机器人可以如何通过共享经历学习新技能&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719099&amp;amp;idx=2&amp;amp;sn=52807674a2235e7ed8065a165427e1d6&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719099&amp;amp;idx=2&amp;amp;sn=52807674a2235e7ed8065a165427e1d6&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;谷歌NIPS 2016提交的8篇论文：从无监督学习到生成模型&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718429&amp;amp;idx=2&amp;amp;sn=2dad7f9aab23cf05323bb9d01c49d11b&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718429&amp;amp;idx=2&amp;amp;sn=2dad7f9aab23cf05323bb9d01c49d11b&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;谷歌DeepMind论文：使用合成梯度的解耦神经接口&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722118&amp;amp;idx=2&amp;amp;sn=42199ff21f3b06912e487de2c83eca1b&amp;amp;chksm=871b0b38b06c822ef121554a1f9bf23ef49e15cbbe6d84ac11c8e68eb377746a24809aa8e34c&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722118&amp;amp;idx=2&amp;amp;sn=42199ff21f3b06912e487de2c83eca1b&amp;amp;chksm=871b0b38b06c822ef121554a1f9bf23ef49e15cbbe6d84ac11c8e68eb377746a24809aa8e34c&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;谷歌提交ICLR 2017论文：学习记忆罕见事件&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722472&amp;amp;idx=4&amp;amp;sn=892464db8e5e2d1e060bfeeacef63882&amp;amp;chksm=871b14d6b06c9dc0e5f870684b95dee11d47f75d155d601f86e9700ddc0c1b65191d9c46e19b&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722472&amp;amp;idx=4&amp;amp;sn=892464db8e5e2d1e060bfeeacef63882&amp;amp;chksm=871b14d6b06c9dc0e5f870684b95dee11d47f75d155d601f86e9700ddc0c1b65191d9c46e19b&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;谷歌提出深度概率编程语言Edward：融合了贝叶斯、深度学习和概率编程&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721938&amp;amp;idx=4&amp;amp;sn=64634dd519ee70c35fdf1e771da7d9e5&amp;amp;chksm=871b0aecb06c83face511e46c836911a7a15c69980a76198ae928aa935b51d162ebe20946a35&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721938&amp;amp;idx=4&amp;amp;sn=64634dd519ee70c35fdf1e771da7d9e5&amp;amp;chksm=871b0aecb06c83face511e46c836911a7a15c69980a76198ae928aa935b51d162ebe20946a35&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;谷歌新论文提出预测器架构：端到端的学习与规划&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720220&amp;amp;idx=4&amp;amp;sn=85923b1102993f0c88c0394ae0ecb4fc&amp;amp;chksm=871b03a2b06c8ab4ca055cc73ee73c50275f70990ccdab71107626640548b916d383c549ea18&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720220&amp;amp;idx=4&amp;amp;sn=85923b1102993f0c88c0394ae0ecb4fc&amp;amp;chksm=871b03a2b06c8ab4ca055cc73ee73c50275f70990ccdab71107626640548b916d383c549ea18&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;DeepMind最新论文：线性时间的神经机器翻译&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718504&amp;amp;idx=3&amp;amp;sn=0469d037c1d004270da3006216a97cef&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718504&amp;amp;idx=3&amp;amp;sn=0469d037c1d004270da3006216a97cef&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;DeepMind David Silver论文：学习跨多个数量级的值&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719494&amp;amp;idx=3&amp;amp;sn=67ed3e91731a47abe1a29df4c949119b&amp;amp;chksm=871b0178b06c886e6da4c83c0c26476c2f679f5e72d542531c5fbb8c798b6d768f9a9c596485&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719494&amp;amp;idx=3&amp;amp;sn=67ed3e91731a47abe1a29df4c949119b&amp;amp;chksm=871b0178b06c886e6da4c83c0c26476c2f679f5e72d542531c5fbb8c798b6d768f9a9c596485&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;DeepMind论文：在线Segment to Segment神经传导&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719745&amp;amp;idx=2&amp;amp;sn=242eda88fa9a5572e60b43e451a1549b&amp;amp;chksm=871b027fb06c8b693cff17f43553625f008fcb7965582119b651dbbd17e116e35dc801ebeec3&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719745&amp;amp;idx=2&amp;amp;sn=242eda88fa9a5572e60b43e451a1549b&amp;amp;chksm=871b027fb06c8b693cff17f43553625f008fcb7965582119b651dbbd17e116e35dc801ebeec3&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;DeepMind深度解读Nature论文：可微神经计算机&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719843&amp;amp;idx=4&amp;amp;sn=d54e7e415990bcfe69727e0b9f4c5f98&amp;amp;chksm=871b021db06c8b0b008c7004e130d596ae14f4b4de017098ecc4409e54fad8a4a77d3bcb93f4&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719843&amp;amp;idx=4&amp;amp;sn=d54e7e415990bcfe69727e0b9f4c5f98&amp;amp;chksm=871b021db06c8b0b008c7004e130d596ae14f4b4de017098ecc4409e54fad8a4a77d3bcb93f4&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;DeepMind论文：调控运动控制器的学习和迁移&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720969&amp;amp;idx=2&amp;amp;sn=d1fae404486906125e01b5def7e26d94&amp;amp;chksm=871b0eb7b06c87a1d3e7d0b29e8c8f9e4c86f4949d04b0485df1b45823555a6c88a25ccf4dc4&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720969&amp;amp;idx=2&amp;amp;sn=d1fae404486906125e01b5def7e26d94&amp;amp;chksm=871b0eb7b06c87a1d3e7d0b29e8c8f9e4c86f4949d04b0485df1b45823555a6c88a25ccf4dc4&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;DeepMind NIPS 2016论文盘点（Part1）：强化学习正大步向前&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721102&amp;amp;idx=2&amp;amp;sn=cbc44a149457d31ed9a8bbe825f09378&amp;amp;chksm=871b0f30b06c8626bb94cbd7a08fd4a5c8bec747082f49280fbd27e9c87c965de983a279796c&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721102&amp;amp;idx=2&amp;amp;sn=cbc44a149457d31ed9a8bbe825f09378&amp;amp;chksm=871b0f30b06c8626bb94cbd7a08fd4a5c8bec747082f49280fbd27e9c87c965de983a279796c&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;DeepMind NIPS 2016论文盘点（Part2）：无监督学习的新进展&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719772&amp;amp;idx=2&amp;amp;sn=9540989a7862ef93d1e5146a7b5641c9&amp;amp;chksm=871b0262b06c8b74bcd961a7bfe45076a92c1d9456af235f8e84a4bce6e15d120f295cab5576&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719772&amp;amp;idx=2&amp;amp;sn=9540989a7862ef93d1e5146a7b5641c9&amp;amp;chksm=871b0262b06c8b74bcd961a7bfe45076a92c1d9456af235f8e84a4bce6e15d120f295cab5576&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;ECCV 2016 最佳论文新鲜出炉&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719971&amp;amp;idx=3&amp;amp;sn=c23aa4b6172bd4ccea042d139ffa5daf&amp;amp;chksm=871b029db06c8b8b939ba2e0eb256db1d5fdd5ce2b229139cb31e7e54e5bdd2772761ce01c19&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719971&amp;amp;idx=3&amp;amp;sn=c23aa4b6172bd4ccea042d139ffa5daf&amp;amp;chksm=871b029db06c8b8b939ba2e0eb256db1d5fdd5ce2b229139cb31e7e54e5bdd2772761ce01c19&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;Geoffrey Hinton论文：使用快速权重处理最近的过去&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717143&amp;amp;idx=2&amp;amp;sn=dbb912c06671f0ba4bb7faf8b1677831&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717143&amp;amp;idx=2&amp;amp;sn=dbb912c06671f0ba4bb7faf8b1677831&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;哈工大讯飞联合实验室最新论文刷新机器阅读理解纪录&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715759&amp;amp;idx=3&amp;amp;sn=20d16db66afb2d742422f0a3abfa7f1e&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715759&amp;amp;idx=3&amp;amp;sn=20d16db66afb2d742422f0a3abfa7f1e&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;华盛顿大学论文：使用机器学习分析科学文献中的视觉信息&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718786&amp;amp;idx=5&amp;amp;sn=1c91d80ce0422c7049bfdbaa8188d56f&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718786&amp;amp;idx=5&amp;amp;sn=1c91d80ce0422c7049bfdbaa8188d56f&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;Ian Goodfellow 论文：通过视频预测的用于物理交互的无监督学习&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719909&amp;amp;idx=4&amp;amp;sn=90e189c8989817e3b52d2a40c355da10&amp;amp;chksm=871b02dbb06c8bcdc29a69b7a9ba2711f3ba1e2a08192e184f298093b404fa57272cdfdf81b9&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719909&amp;amp;idx=4&amp;amp;sn=90e189c8989817e3b52d2a40c355da10&amp;amp;chksm=871b02dbb06c8bcdc29a69b7a9ba2711f3ba1e2a08192e184f298093b404fa57272cdfdf81b9&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;Ian Goodfellow 论文：用于隐私训练数据的深度学习的半监督知识迁移&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715900&amp;amp;idx=4&amp;amp;sn=948406fcbd53cdca4ce96bd33a28874d&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715900&amp;amp;idx=4&amp;amp;sn=948406fcbd53cdca4ce96bd33a28874d&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;IBM论文：多尺度循环神经网络在对话生成中的应用&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715145&amp;amp;idx=3&amp;amp;sn=21d98866046180034d68da334501ce24&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715145&amp;amp;idx=3&amp;amp;sn=21d98866046180034d68da334501ce24&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;ICLR2016会议，不可错过Facebook提交的七篇论文&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718262&amp;amp;idx=1&amp;amp;sn=0391500e43530e7f4a8b8053176e5d7f&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718262&amp;amp;idx=1&amp;amp;sn=0391500e43530e7f4a8b8053176e5d7f&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;计算机科学领导者：卡内基梅隆大学ACL2016论文汇总&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715794&amp;amp;idx=3&amp;amp;sn=3c328f66f24dee02b6a29a7821c7f6a1&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715794&amp;amp;idx=3&amp;amp;sn=3c328f66f24dee02b6a29a7821c7f6a1&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;论文：TensorFlow，一个大规模机器学习系统&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717969&amp;amp;idx=4&amp;amp;sn=7fa67419573685604dde9811d434f6b8&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717969&amp;amp;idx=4&amp;amp;sn=7fa67419573685604dde9811d434f6b8&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;论文：通过连续奖励策略梯度学习在线比对&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718688&amp;amp;idx=4&amp;amp;sn=17b45f18ccb1e29e80fdca1645a71e5c&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718688&amp;amp;idx=4&amp;amp;sn=17b45f18ccb1e29e80fdca1645a71e5c&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;论文：基准评测当前最先进的深度学习软件工具&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720189&amp;amp;idx=3&amp;amp;sn=8e0d8f7d3b9c037935736e09f85a4884&amp;amp;chksm=871b03c3b06c8ad57d13417933b779f6b0a5931c3448ef9bf2129fb64b0c3f4c84293358aebf&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720189&amp;amp;idx=3&amp;amp;sn=8e0d8f7d3b9c037935736e09f85a4884&amp;amp;chksm=871b03c3b06c8ad57d13417933b779f6b0a5931c3448ef9bf2129fb64b0c3f4c84293358aebf&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;论文：一种用于训练循环网络的新算法Professor Forcing&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718988&amp;amp;idx=4&amp;amp;sn=79c38974f2908e909e0f3bdd140cfa88&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718988&amp;amp;idx=4&amp;amp;sn=79c38974f2908e909e0f3bdd140cfa88&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;论文：高斯混合模型的似然方法中的局部极大值：结构结果和算法结果&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721081&amp;amp;idx=3&amp;amp;sn=111d844d50c98582695d04fa2b252c89&amp;amp;chksm=871b0f47b06c86514ac934c44fe4df92f5d4209f209b94b4c89d1f138492dbaf7e47479803a3&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721081&amp;amp;idx=3&amp;amp;sn=111d844d50c98582695d04fa2b252c89&amp;amp;chksm=871b0f47b06c86514ac934c44fe4df92f5d4209f209b94b4c89d1f138492dbaf7e47479803a3&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;NIPS 2016现场：谷歌发布 28 篇机器学习论文&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715615&amp;amp;idx=1&amp;amp;sn=f114c4683656991bd331dc9971499a02&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715615&amp;amp;idx=1&amp;amp;sn=f114c4683656991bd331dc9971499a02&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;Nature论文：无监督表征学习，用电子健康病历增强临床决策&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716475&amp;amp;idx=1&amp;amp;sn=2b03deead0c1e63be80fdc239293e805&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716475&amp;amp;idx=1&amp;amp;sn=2b03deead0c1e63be80fdc239293e805&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;Nature论文：从不确定性表征到自动建模&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718527&amp;amp;idx=2&amp;amp;sn=8d054db2eca7a0b25190a6cc050fc1d7&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718527&amp;amp;idx=2&amp;amp;sn=8d054db2eca7a0b25190a6cc050fc1d7&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;NIPS 2016 公布571篇接收论文&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719581&amp;amp;idx=3&amp;amp;sn=e75b2fcd08d4ef5d8feeb79ebc223d18&amp;amp;chksm=871b0123b06c883511d8dbf853bb60f8e0903e335ed384421d1ab8db96ebf45d9b4cf3e96356&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719581&amp;amp;idx=3&amp;amp;sn=e75b2fcd08d4ef5d8feeb79ebc223d18&amp;amp;chksm=871b0123b06c883511d8dbf853bb60f8e0903e335ed384421d1ab8db96ebf45d9b4cf3e96356&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;OpenAI与NASA论文：用于张拉整体机器人运动的深度强化学习&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720257&amp;amp;idx=3&amp;amp;sn=4dfc480bfc70691f5baa44a75a0c1b82&amp;amp;chksm=871b0c7fb06c85696574d7f15d160afd3f45aa669bad4d1589f908c2fe0f56a3f34946bb6e73&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720257&amp;amp;idx=3&amp;amp;sn=4dfc480bfc70691f5baa44a75a0c1b82&amp;amp;chksm=871b0c7fb06c85696574d7f15d160afd3f45aa669bad4d1589f908c2fe0f56a3f34946bb6e73&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;OpenAI论文：神经GPU的扩展和限制&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721777&amp;amp;idx=1&amp;amp;sn=a51774b58c1b39ae9cb23c41361780af&amp;amp;chksm=871b098fb06c80992893818772a5c9410adb8826f60ae44d9468685413708c9c1c4583f967df&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721777&amp;amp;idx=1&amp;amp;sn=a51774b58c1b39ae9cb23c41361780af&amp;amp;chksm=871b098fb06c80992893818772a5c9410adb8826f60ae44d9468685413708c9c1c4583f967df&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;苹果发布第一篇人工智能研究论文：模拟+无监督方法改善合成图像&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716071&amp;amp;idx=2&amp;amp;sn=fb8944218199ac4c29af926d8847cc58&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716071&amp;amp;idx=2&amp;amp;sn=fb8944218199ac4c29af926d8847cc58&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;商汤科技论文解析：人脸检测中级联卷积神经网络的联合训练&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717606&amp;amp;idx=3&amp;amp;sn=9d20357d6ce5877e7df31058c1ba0b4c&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717606&amp;amp;idx=3&amp;amp;sn=9d20357d6ce5877e7df31058c1ba0b4c&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;斯坦福大学李飞飞最新论文：弱监督动作标记的连接时序模型&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720285&amp;amp;idx=5&amp;amp;sn=583751084a6855b35f684f582afd7976&amp;amp;chksm=871b0c63b06c857523341e94380cd6b87e84502854886f7aa8fa40ff665166db4ffda8a5ea1b&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720285&amp;amp;idx=5&amp;amp;sn=583751084a6855b35f684f582afd7976&amp;amp;chksm=871b0c63b06c857523341e94380cd6b87e84502854886f7aa8fa40ff665166db4ffda8a5ea1b&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;Vicarious在ICLR2017提交无监督学习论文：层级组合特征学习&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719118&amp;amp;idx=3&amp;amp;sn=4565fb14db41208571b808956a39e310&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719118&amp;amp;idx=3&amp;amp;sn=4565fb14db41208571b808956a39e310&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;Yann LeCun论文：基于能量的生成对抗网络&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717728&amp;amp;idx=3&amp;amp;sn=2de2d33afc32c04f2bcb1cfe1a788c0f&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717728&amp;amp;idx=3&amp;amp;sn=2de2d33afc32c04f2bcb1cfe1a788c0f&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;Yoshua Bengio 论文：一种神经知识语言模型&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720390&amp;amp;idx=1&amp;amp;sn=8ad603e853b88706ca4916495f59b228&amp;amp;chksm=871b0cf8b06c85ee216eb2d46361de137679cd9fd7d09a2a72cdf06d79d6c01dfe1683eb003c&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720390&amp;amp;idx=1&amp;amp;sn=8ad603e853b88706ca4916495f59b228&amp;amp;chksm=871b0cf8b06c85ee216eb2d46361de137679cd9fd7d09a2a72cdf06d79d6c01dfe1683eb003c&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;Yann LeCun提交ICLR 2017论文汇总：从GAN到循环实体网络等&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717572&amp;amp;idx=2&amp;amp;sn=da7a53cde74285f229fcf6827bbb17d6&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717572&amp;amp;idx=2&amp;amp;sn=da7a53cde74285f229fcf6827bbb17d6&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;Bengio论文：用于序列预测的actor-critic算法&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718133&amp;amp;idx=4&amp;amp;sn=97ce57340e916cb049ec96c96fa55fe3&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718133&amp;amp;idx=4&amp;amp;sn=97ce57340e916cb049ec96c96fa55fe3&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;Yoshua Bengio论文：迈向生物学上可信的深度学习&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719794&amp;amp;idx=4&amp;amp;sn=8a1d4e46663439c509f8d580e2b871e8&amp;amp;chksm=871b024cb06c8b5a1cbc79b9b2d9ff0d312842f04ad375ef7838c30f1b639cb3d1e1724f2902&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719794&amp;amp;idx=4&amp;amp;sn=8a1d4e46663439c509f8d580e2b871e8&amp;amp;chksm=871b024cb06c8b5a1cbc79b9b2d9ff0d312842f04ad375ef7838c30f1b639cb3d1e1724f2902&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;Yoshua Bengio论文：使用线性分类器探头理解中间层&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718391&amp;amp;idx=3&amp;amp;sn=75cac85169b49af157755a3cbc68670e&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718391&amp;amp;idx=3&amp;amp;sn=75cac85169b49af157755a3cbc68670e&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;Yoshua Bengio论文：Mollifying Networks&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720220&amp;amp;idx=2&amp;amp;sn=0f2f5061e470ffbf76fee6ac77b3cf52&amp;amp;chksm=871b03a2b06c8ab4a0cb275b1044fb23a646997af91d5753439488ee976512c84979eadd2293&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720220&amp;amp;idx=2&amp;amp;sn=0f2f5061e470ffbf76fee6ac77b3cf52&amp;amp;chksm=871b03a2b06c8ab4a0cb275b1044fb23a646997af91d5753439488ee976512c84979eadd2293&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;微软重磅论文提出LightRNN：高效利用内存和计算的循环神经网络&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718106&amp;amp;idx=2&amp;amp;sn=93aceb9b6e4a0772bbaf9257a4def3d2&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718106&amp;amp;idx=2&amp;amp;sn=93aceb9b6e4a0772bbaf9257a4def3d2&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;微软ACL 2016论文汇集，自然语言技术逼近人类对话水平&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718072&amp;amp;idx=2&amp;amp;sn=dc0f5e9ac4ca943afe91ea8d4e08f78c&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718072&amp;amp;idx=2&amp;amp;sn=dc0f5e9ac4ca943afe91ea8d4e08f78c&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;自然语言顶级会议ACL 2016谷歌论文汇集&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心原创，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 29 Jan 2017 13:31:25 +0800</pubDate>
    </item>
    <item>
      <title>盘点 | Github上的18个顶级深度学习项目</title>
      <link>http://www.iwgc.cn/link/4516628</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Github&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;hunkim 盘点了 Github 上 18 个深度学习项目，根据收藏数自动排名。最新的一次 update 在几小时前完成。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;项目地址：https://github.com/hunkim/DeepLearningStars&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面是在 Github 上和深度学习相关的项目：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1.TensorFlow&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://github.com/tensorflow/tensorflow&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Stars：44,201&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;介绍：为可扩展机器学习提供使用数据流图的计算。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2.Caffe&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://github.com/BVLC/caffe&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Stars：15,615&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;介绍：Caffe: 一个为深度学习提供的快速开放式框架&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3.neural-style&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://github.com/jcjohnson/neural-style&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Stars：12,496&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;介绍：神经风格算法的 Torch 实现&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4.keras&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://github.com/fchollet/keras&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Stars：11,632&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;介绍：Python 上的深度学习库。提供循环神经网络和卷积神经网络等算法。在 Theano 或 TensorFlow 平台上运行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;5.deepdream&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://github.com/google/deepdream&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Stars：9,764&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;介绍：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;6.RocAlphaGo&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://github.com/Rochester-NRT/RocAlphaGo&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Stars：7,807&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;介绍：一个独立的，由 DeepMind 在自然期刊发表的「掌控围棋游戏的深度神经网络和树搜索（Mastering the game of Go with deep neural networks and tree search）」(Nature 529, 484-489, 28 Jan 2016) 引起的项目。详情请见 DeepMind 网站：https://deepmind.com/publications.html.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;7.char-rnn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://github.com/karpathy/char-rnn&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Stars：4,793&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;介绍：在 Torch 上为字符级自然语言模型而构建的多层循环神经网络 (LSTM, GRU, RNN)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;8.gym&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://github.com/openai/gym&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Stars：4,747&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;介绍：开发和对比强化学习算法的工具包。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;9.tflearn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://github.com/tflearn/tflearn&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Stars：4,677&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;介绍：以针对 TensorFlow 的高层 API 为特色的深度学习库。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;10.playground&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://github.com/tensorflow/playground&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Stars：4,154&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;介绍：玩转神经网络！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;11.neuraltalk&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://github.com/karpathy/neuraltalk&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Stars：3,977&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;介绍：NeuralTalk 是一个 Python 加 numpy 的项目，来学习多模式循环神经网络，从而使用语句描述图片。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;12.Machine-Learning-Tutorials&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://github.com/ujjwalkarn/Machine-Learning-Tutorials&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Stars：3,583&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;介绍：机器学习和深度学习教程、文章和其他资源。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;13.TopDeepLearning&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://github.com/aymericdamien/TopDeepLearning&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Stars：3,563&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;介绍：关于深度学习的流行 Github 项目清单。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;14.TensorFlow-Tutorials&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://github.com/nlintz/TensorFlow-Tutorials&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Stars：3,119&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;介绍：使用谷歌 TensorFlow 框架的简易教程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;15.tensorflow_tutorials&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://github.com/pkmital/tensorflow_tutorials&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Stars：3,021&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;介绍：Tensorflow 从基础到某些趣味性的应用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;16.word-rnn-tensorflow&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://github.com/hunkim/word-rnn-tensorflow&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Stars：284&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;介绍：TensorFlow 上的 Python 库，为单词级的语言模型提供多层循环神经网络（LSTM、RNN）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;17.tensorflow-aws-ami&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://github.com/ritchieng/tensorflow-aws-ami&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Stars：47&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;介绍：一个 TensorFlow 的亚马逊网页服务（AWS）AMI，它开放、免费且性能强大。可在 5 分钟内运行 TensorFlow。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;18.DeepLearningStars&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;链接：https://github.com/hunkim/DeepLearningStars&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Stars：26&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;介绍：包含受关注最高的一些深度学习项目。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本排名于 2017 年 1 月 29 日自动更新。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 29 Jan 2017 13:31:25 +0800</pubDate>
    </item>
    <item>
      <title>教程 | 从头开始：用Python实现带随机梯度下降的线性回归</title>
      <link>http://www.iwgc.cn/link/4516629</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自machine learning mastery&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：Linjing、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;许多机器学习算法的核心是优化。优化算法用于在机器学习中为给定训练集找出合理的模型参数设置。机器学习最常见的优化算法是随机梯度下降（SGD：stochastic gradient descent）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本教程将指导大家用 Python 实现随机梯度下降对线性回归算法的优化。通过本教程的学习，你将了解到：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如何用随机梯度下降估计线性回归系数&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如何对多元线性回归做预测&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如何用带随机梯度下降的线性回归算法对新数据做预测&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;说明&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本文将对线性回归、随即梯度下降方法以及本教程所使用的葡萄酒品质数据集做一个集中阐释。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;多元线性回归&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;线性回归是一种用于预测真实值的方法。让人困惑的是，这些需要预测真实值的问题被称为回归问题（regression problems）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;线性回归是一种用直线对输入输出值进行建模的方法。在超过二维的空间里，这条直线被想象成一个平面或者超平面（hyperplane）。预测即是通过对输入值的组合对输出值进行预判。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;y = b0 + b1 * x1 + b2 * x2 + ...&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;系数 (b) 用于对每个输入属性 (x) 进行加权，而学习算法的目的正是寻找一组能导出好的预测值 (y) 的系数。这些系数可以使用随机梯度下降的方法找到。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;随机梯度下降&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;梯度下降（Gradient Descent）是遵循成本函数的梯度来最小化一个函数的过程。这个过程涉及到对成本形式以及其衍生形式的认知，使得我们可以从已知的给定点朝既定方向移动。比如向下朝最小值移动。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在机器学习中，我们可以利用随机梯度下降的方法来最小化训练模型中的误差，即每次迭代时完成一次评估和更新。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种优化算法的工作原理是模型每看到一个训练实例，就对其作出预测，并重复迭代该过程到一定的次数。这个流程可以用于找出能导致训练数据最小误差的模型的系数。用机器学习的术语来讲，就是每次迭代过程都用如下等式更新系数（b）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;b = b - learning_rate * error * x&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中 b 是系数或者被优化的权重，learing_rate 需手动设定（如 0.01），error 是取决于权重的训练数据模型的预测误差，x 是输入值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;葡萄酒品质数据集&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;开发了具有梯度下降的线性回归算法之后，我们可以将其运用到一个关于葡萄酒品质的数据集当中。这个数据集囊括了 4898 种白葡萄酒的测量标准，包括酸度和 ph 值。目的是用这些客观标准来预测葡萄酒的品质，分为 0 到 10 级。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下表给出了 5 个数据样本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;7,0.27,0.36,20.7,0.045,45,170,1.001,3,0.45,8.8,6&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;6.3,0.3,0.34,1.6,0.049,14,132,0.994,3.3,0.49,9.5,6&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;8.1,0.28,0.4,6.9,0.05,30,97,0.9951,3.26,0.44,10.1,6&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;7.2,0.23,0.32,8.5,0.058,47,186,0.9956,3.19,0.4,9.9,6&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;7.2,0.23,0.32,8.5,0.058,47,186,0.9956,3.19,0.4,9.9,6&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所有数据需归一化为 0-1 之间的值。每种属性标准单位不同，因而有不同的缩放尺度。通过预测该归一化数据集的平均值（零规则算法），达到了 0.148 的基准方均根差（RMSE）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该数据集详情请参阅 UCI Machine Learning Repository：http://archive.ics.uci.edu/ml/datasets/Wine+Quality&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下载该数据集并将其保存到当前工作目录，文件名为 winequality-white.csv。（注意：文件开头的头信息需去除，用作分隔符的 『；』 需改为符合 CSV 格式的 『，』。）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;教程&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本教程分为三个部分：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 预测&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 估计系数&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 葡萄酒品质预测&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这将能让你了解在你自己的预测建模问题上实现和应用带有随机梯度下降的线性回归的基础。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1. 预测&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先建立一个用于预测的函数。这将用于对随机梯度下降的候选系数的评估，且模型确定之后也需要这个函数。我们会在测试集或者新的数据上用该函数来进行预测。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;函数 predict() 如下所示，用于预测给定了一组系数的行的输出值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一个系数始终为截距，也称为偏差或 b0，因其相对独立且不与特定的输入值相关。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;# Make a prediction with coefficients&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;def predict(row, coefficients):&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;yhat = coefficients[0]&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;for i in range(len(row)-1):&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;yhat += coefficients[i + 1] * row[i]&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;return yhat&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们可以用一个小的数据集对这个函数进行测试。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;x, y&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;1, 1&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;2, 3&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;4, 3&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;3, 2&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;5, 5&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下图是一小部分数据：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibsia3lXaUiaMsqwCXauCbKhHLwmpDfV24ibOrbaNRJvhfSqTQo4vJ8P8YzwEczcpgYayr5oiaFFEmQVw/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;线性回归的部分转换数据&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们也可用之前准备好的系数为这个数据集做预测。predict() 函数测试如下。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;# Make a prediction with coefficients&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;def predict(row, coefficients):&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;yhat = coefficients[0]&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;for i in range(len(row)-1):&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;yhat += coefficients[i + 1] * row[i]&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;return yhat&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;dataset = [[1, 1], [2, 3], [4, 3], [3, 2], [5, 5]]&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;coef = [0.4, 0.8]&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;for row in dataset:&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;yhat = predict(row, coef)&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;print("Expected=%.3f, Predicted=%.3f" % (row[-1], yhat))&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;单个输入值 (x) 和两个系数（b0 和 b1）。用于建模该问题的预测方程为：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;y = b0 + b1 * x&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;或者，手动选择特定系数：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;y = 0.4 + 0.8 * x&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;运行此函数，我们将得到一个相当接近预测值的输出值（y）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;Expected=1.000, Predicted=1.200&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;Expected=3.000, Predicted=2.000&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;Expected=3.000, Predicted=3.600&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;Expected=2.000, Predicted=2.800&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;Expected=5.000, Predicted=4.400&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在我们可以用随机梯度下降来优化我们的系数值了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2. 估计系数&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们可以使用随机梯度下降来为我们的训练数据估计系数值。随机阶梯下降需要两个设定参数：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;学习率（Learning Rate）：用于限制每次更新时被修正的系数的数量。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Epochs：更新系数的同时运行训练集的次数。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这两个值和数据集都是函数的参数。我们的这个函数将执行三个遍历循环：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 单次 epoch 循环&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 单次 epoch 中训练集中的每行循环&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 单次 epoch 中每个系数循环并为每一行更新它&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;可以看到，每次 epoch，我们都会更新数据集里每行的系数。系数的更新是基于模型生成的误差。该误差被算作候选系数的预测值和预期输出值之间的差。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;error = prediction - expected&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有一个系数用于加权每一个输入属性，这些属性将以连续的方式进行更新，比如&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;b1(t+1) = b1(t) - learning_rate * error(t) * x1(t)&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;列表开始的特殊系数，也被称为截距（intercept）或偏差（bias），也以类似的方式更新，但因其不与特定输入值相关，所以无输入值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;b0(t+1) = b0(t) - learning_rate * error(t)&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在我们把所有东西组合在一起。coefficients_sgd() 函数正是用随机梯度下降来计算一个训练集的系数值，下面即是该函数：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;# Estimate linear regression coefficients using stochastic gradient descent&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;def coefficients_sgd(train, l_rate, n_epoch):&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;coef = [0.0 for i in range(len(train[0]))]&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;for epoch in range(n_epoch):&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;sum_error = 0&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;for row in train:&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;yhat = predict(row, coef)&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;error = yhat - row[-1]&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;sum_error += error**2&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;coef[0] = coef[0] - l_rate * error&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;for i in range(len(row)-1):&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;coef[i + 1] = coef[i + 1] - l_rate * error * row[i]&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;print('&amp;gt;epoch=%d, lrate=%.3f, error=%.3f' % (epoch, l_rate, sum_error))&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;return coef&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此外，我们追踪每个 epoch 的方差（正值）总和从而在循环之后得到一个好的结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;# Make a prediction with coefficients&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;def predict(row, coefficients):&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;yhat = coefficients[0]&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;for i in range(len(row)-1):&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;yhat += coefficients[i + 1] * row[i]&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;return yhat&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;# Estimate linear regression coefficients using stochastic gradient descent&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;def coefficients_sgd(train, l_rate, n_epoch):&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;coef = [0.0 for i in range(len(train[0]))]&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;for epoch in range(n_epoch):&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;sum_error = 0&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;for row in train:&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;yhat = predict(row, coef)&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;error = yhat - row[-1]&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;sum_error += error**2&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;coef[0] = coef[0] - l_rate * error&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;for i in range(len(row)-1):&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;coef[i + 1] = coef[i + 1] - l_rate * error * row[i]&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;print('&amp;gt;epoch=%d, lrate=%.3f, error=%.3f' % (epoch, l_rate, sum_error))&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;return coef&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;# Calculate coefficients&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;dataset = [[1, 1], [2, 3], [4, 3], [3, 2], [5, 5]]&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;l_rate = 0.001&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;n_epoch = 50&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;coef = coefficients_sgd(dataset, l_rate, n_epoch)&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;print(coef)&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们用 0.001 的学习速率训练该模型 50 次，即把整个训练数据集的系数曝光 50 次。运行一个 epoch 系统就将该次循环中的和方差（sum squared error）和以及最终系数集合 print 一次：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&amp;gt;epoch=45, lrate=0.001, error=2.650&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&amp;gt;epoch=46, lrate=0.001, error=2.627&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&amp;gt;epoch=47, lrate=0.001, error=2.607&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&amp;gt;epoch=48, lrate=0.001, error=2.589&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&amp;gt;epoch=49, lrate=0.001, error=2.573&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;[0.22998234937311363, 0.8017220304137576]&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;可以看到误差是如何在历次 epoch 中持续降低的。或许我们可以增加训练次数（epoch）或者每个 epoch 中的系数总量（调高学习速率）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尝试一下看你能得到什么结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在，我们将这个算法用到实际的数据当中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3. 葡萄酒品质预测&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们将使用随机阶梯下降的方法为葡萄酒品质数据集训练一个线性回归模型。本示例假定一个名为 winequality—white.csv 的 csv 文件副本已经存在于当前工作目录。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先加载该数据集，将字符串转换成数字，并将输出列从字符串转换成数值 0 和 1. 这个过程是通过辅助函数 load_csv()、str_column_to_float() 以及 dataset_minmax() 和 normalize_dataset() 来分别实现的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们将通过 K 次交叉验证来预估得到的学习模型在未知数据上的表现。这就意味着我们将创建并评估 K 个模型并预估这 K 个模型的平均误差。辅助函数 cross_validation_split()、rmse_metric() 和 evaluate_algorithm() 用于求导根均方差以及评估每一个生成的模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们用之前创建的函数 predict()、coefficients_sgd() 以及 linear_regression_sgd() 来训练模型。完整代码如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;# Linear Regression With Stochastic Gradient Descent for Wine Quality&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;from random import seed&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;from random import randrange&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;from csv import reader&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;from math import sqrt&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;# Load a CSV file&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;def load_csv(filename):&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;dataset = list()&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;with open(filename, 'r') as file:&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;csv_reader = reader(file)&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;for row in csv_reader:&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;if not row:&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;continue&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;dataset.append(row)&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;return dataset&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;# Convert string column to float&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;def str_column_to_float(dataset, column):&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;for row in dataset:&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;row[column] = float(row[column].strip())&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;# Find the min and max values for each column&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;def dataset_minmax(dataset):&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;minmax = list()&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;for i in range(len(dataset[0])):&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;col_values = [row[i] for row in dataset]&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;value_min = min(col_values)&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;value_max = max(col_values)&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;minmax.append([value_min, value_max])&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;return minmax&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;# Rescale dataset columns to the range 0-1&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;def normalize_dataset(dataset, minmax):&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;for row in dataset:&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;for i in range(len(row)):&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;row[i] = (row[i] - minmax[i][0]) / (minmax[i][1] - minmax[i][0])&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;# Split a dataset into k folds&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;def cross_validation_split(dataset, n_folds):&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;dataset_split = list()&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;dataset_copy = list(dataset)&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;fold_size = len(dataset) / n_folds&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;for i in range(n_folds):&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;fold = list()&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;while len(fold) &amp;lt; fold_size:&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;index = randrange(len(dataset_copy))&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;fold.append(dataset_copy.pop(index))&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;dataset_split.append(fold)&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;return dataset_split&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;# Calculate root mean squared error&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;def rmse_metric(actual, predicted):&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;sum_error = 0.0&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;for i in range(len(actual)):&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;prediction_error = predicted[i] - actual[i]&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;sum_error += (prediction_error ** 2)&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;mean_error = sum_error / float(len(actual))&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;return sqrt(mean_error)&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;# Evaluate an algorithm using a cross validation split&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;def evaluate_algorithm(dataset, algorithm, n_folds, *args):&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;folds = cross_validation_split(dataset, n_folds)&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;scores = list()&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;for fold in folds:&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;train_set = list(folds)&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;train_set.remove(fold)&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;train_set = sum(train_set, [])&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;test_set = list()&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;for row in fold:&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;row_copy = list(row)&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;test_set.append(row_copy)&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;row_copy[-1] = None&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;predicted = algorithm(train_set, test_set, *args)&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;actual = [row[-1] for row in fold]&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;rmse = rmse_metric(actual, predicted)&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;scores.append(rmse)&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;return scores&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;# Make a prediction with coefficients&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;def predict(row, coefficients):&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;yhat = coefficients[0]&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;for i in range(len(row)-1):&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;yhat += coefficients[i + 1] * row[i]&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;return yhat&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;# Estimate linear regression coefficients using stochastic gradient descent&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;def coefficients_sgd(train, l_rate, n_epoch):&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;coef = [0.0 for i in range(len(train[0]))]&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;for epoch in range(n_epoch):&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;for row in train:&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;yhat = predict(row, coef)&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;error = yhat - row[-1]&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;coef[0] = coef[0] - l_rate * error&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;for i in range(len(row)-1):&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;coef[i + 1] = coef[i + 1] - l_rate * error * row[i]&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;# print(l_rate, n_epoch, error)&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;return coef&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;# Linear Regression Algorithm With Stochastic Gradient Descent&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;def linear_regression_sgd(train, test, l_rate, n_epoch):&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;predictions = list()&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;coef = coefficients_sgd(train, l_rate, n_epoch)&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;for row in test:&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;yhat = predict(row, coef)&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;predictions.append(yhat)&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;return(predictions)&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;# Linear Regression on wine quality dataset&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;seed(1)&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;# load and prepare data&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;filename = 'winequality-white.csv'&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;dataset = load_csv(filename)&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;for i in range(len(dataset[0])):&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;str_column_to_float(dataset, i)&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;# normalize&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;minmax = dataset_minmax(dataset)&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;normalize_dataset(dataset, minmax)&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;# evaluate algorithm&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;n_folds = 5&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;l_rate = 0.01&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;n_epoch = 50&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;scores = evaluate_algorithm(dataset, linear_regression_sgd, n_folds, l_rate, n_epoch)&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;print('Scores: %s' % scores)&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;print('Mean RMSE: %.3f' % (sum(scores)/float(len(scores))))&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个等于 5 的 k 值被用于交叉验证，给每次迭代 4898/5 = 979.6（低于 1000 都行）条记录来进行评估。对一个小实验选择了 0.01 的学习率和 50 训练 epoch.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你可以尝试你自己的配置，看你能否超过我的分数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;运行这个样本，为 5 次交叉验证的每一次 print 一个分数，然后 print 平均均方根误差（RMSE）。我们可以看到（在归一化的数据集上）该 RMSE 为 0.126。如果我们只是预测平均值的话（使用 Zero Rule Algorithm），那么这个结果就低于基准值 0.148。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;Scores: [0.12259834231519767, 0.12733924130891316, 0.12610773846663892, 0.1289950071681572, 0.1272180783291014]&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;Mean RMSE: 0.126&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;扩展&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里给出了一些扩展练习，你可以思考并尝试解决它们：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;调整该实例。调整其学习率、epoch 的数量甚至原始数据处理和准备的方法，以期能提高最终结果。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;批量进行随机梯度下降。改变随机梯度下降算法使其在每个 epoch 上累积更新，且仅在 epoch 结束时批量更新系数。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;额外的回归问题。应用该技术来解决 UCI 机器学习库中的其它回归问题。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你会探索这些扩展任务吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;回顾总结&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本教程介绍了如何用 Python 实现带有随机梯度下降的多元线性回归算法。其中包括：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如何对多元线性回归问题做预测&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如何优化用于随机梯度下降的系数设置&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如何将该方法用于实际的回归预测模型问题&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;原文：http://machinelearningmastery.com/implement-linear-regression-stochastic-gradient-descent-scratch-python/&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 29 Jan 2017 13:31:25 +0800</pubDate>
    </item>
  </channel>
</rss>
