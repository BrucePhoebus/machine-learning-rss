<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>重磅论文 | 动态神经网络工具包DyNet：比Theano和TensorFlow更快</title>
      <link>http://www.iwgc.cn/link/4390009</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心编译&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：杨旋、袁泽林、赵华龙、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;近日，来自卡内基梅隆大学、日本奈良先端科学技术大学、Google DeepMind、以色列巴伊兰大学、艾伦人工智能研究所、IBM T.J. Watson 研究中心、澳大利亚墨尔本大学、约翰·霍普金斯大学、谷歌、华盛顿大学、微软和英国爱丁堡大学的研究者共同发表了一篇重磅论文《DyNet: The Dynamic Neural Network Toolkit》，正式介绍了动态神经网络工具包 DyNet；该工具包也已在 GitHub 上开源：http://github.com/clab/dynet。机器之心对这篇论文进行了摘要性的介绍，论文原文可点击文末「阅读原文」下载。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8mkkOTgrRQux7YyjNTL5mdAHHI8EQfCD4wtrK852QfSsIeias3GwazaxzHvGyicv8wjREo98e0DibiaQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：在本论文中，我们将介绍 DyNet——一个基于网络结构的动态声明（dynamic declaration of network structure）的用于实现神经网络模型的工具包。在 Theano、CNTK 和 TensorFlow 等工具包中所用的静态声明策略（static declaration strategy）中，用户需要首先定义计算图（computation graph，即计算过程的符号表示），然后样本会被传递给执行该计算的引擎并计算其导数。而在 DyNet 的动态声明策略中，计算图的构建（construction）基本上是透明的，通过执行用于计算网络输出的程序代码来隐式地构造；对于任意一个输入，用户都可以自由得使用不同的网络结构。因此，动态声明有助于实现更复杂的网络架构；特别的，DyNet 允许用户使用他们喜爱的编程语言（C ++ 或 Python）以一种他们惯用的方式来实现他们的模型。在动态声明中，有一件充满挑战的事情：由于对于每个训练样本都要重新定义符号计算图，所以其构建的开销必须要低。为了实现这一点，DyNet 使用了一个经过优化的 C ++ 后端和轻量级的图表示（graph representation）。实验表明，DyNet 的速度与静态声明工具包相当甚至比其更快，并且明显快于另一个动态声明工具包 Chainer。DyNet 根据 Apache 2.0 许可证进行了开源，可以在这里访问：http://github.com/clab/dynet&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;1. 引言&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深度神经网络现在是机器学习开发者的工具箱中不可或缺的工具，它在图像理解 [39]、语音的识别与合成 [29,65]、游戏 [45,54]、语言建模和分析 [6, 14 ] 等领域中拥有重要的地位。首先，深度学习将应用特定的特征工程（加上理解良好的模型，这是经典的「浅度」学习的范式）替换成了应用特定的模型工程（model engineering，通常结合了输入的不太复杂的特征）。因此，深度学习范式在不断发展新的模型变体。要开发有效的模型不仅仅需要洞察力和进行分析，还需要实现一些新模型并评估其在实际任务上的表现。因此，快速的原型设计、高效轻松的维护和正确的模型代码在深度学习中至关重要。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深度学习模型以两种模式操作：在给定输入的情况下计算预测值（或者是预测上的分布），或者在监督学习训练的时候计算相关模型参数的预测误差「损失」的导数，用于使用梯度下降方法的某些变体来最小化和类似输入之间后续的误差。因为实现模型需要同时实现模型预测的代码和进行梯度计算和学习的代码，所以模型开发是一个非常困难的工程挑战。通过使用简化神经网络计算的工具，可以减少这种挑战的难度。这些工具包括 Theano [7]、TensorFlow [1]、Torch [13]、CNTK [64]、MxNet [10] 和 Chainer [62]，它们提供了神经网络功能原语（例如线性代数运算、非线性变换等）、参数初始化和程序优化以及表达特定任务预测和误差的复合能力——这些预测和误差然后会被自动微分（autodiff）以获取驱动学习算法所需的梯度。最后的自动微分（autodiff）组件可以说是它们最重要的节省劳动的功能，因为如果要改变计算训练输入损失值的函数，那么其导数的计算过程也要做出相应的改变。如果工程师独立地维护这些代码路径，则它们很容易导致它们不能同步。此外，由于对复合表达式的微分的算法相对简单 [63,31]，所以使用 autodiff 算法代替手写代码计算导数是个不错的选择。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;简言之，由于这些工具有效地解决了一些关键的软件工程问题，它们让深度学习取得了成功。不过仍然存在一些问题：因为工程（engineering）是深度学习实践的关键组成部分，什么工程问题是现有工具无法解决的呢？它们能让程序员比较自然地实现自己的想法吗？它们是否便于调试？它们是否方便大型项目的维护？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在本论文中，我们将推荐一个基于几个流行工具包的编程模型——即将网络架构的声明和执行（我们称为静态声明）进行分离，在这其中必然会存在一些严重的软件工程风险，特别是在处理动态结构化网络架构（例如，可变长度的序列和树形结构的递归神经网络）的时候。作为一种替代方案，我们提出了一个替代的编程模型，它可在 autodiff 库中进行统一声明和执行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;作为我们推荐的编程模型的概念证明，我们通过论文《DyNet: The Dynamic Neural Network Toolkit》进行了描述。DyNet 是一个基于统一声明和执行编程模型的工具包，我们称之为动态声明（dynamic declaration）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在单台机器环境（single-machine environment）中的一系列案例研究中，我们表明 DyNet 的执行效率与标准模型架构的静态声明工具包相当。和使用动态架构（例如，其中每个训练实例具有不同的模型架构）的模型相比，DyNet 的实现得到了显著的简化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;2. 静态声明 vs. 动态声明&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在本节中，我们更具体地描述了静态声明（§2.1）和动态声明（§2.2）的两种范式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;3.范式编码&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3.1 编码范式概述&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从用户的角度来看，使用 DyNet 编写程序的目的是创建对应于需要被执行的计算的表达式（Expression）。这首先从基本的表达式开始，基本表达式通常是常量输入值或模型参数（Parameters）。然后，通过进行运算（Operation）从其他表达式进一步构建复合表达式，并且运算链（chain of operations）隐含地为所需的计算定义一个计算图（ComputationGraph）。该计算图表示了符号计算，并且计算的结果是被动的：仅当用户显式地请求它时（在该点触发「前向（forward）」计算）才执行计算。评估标量（即损失值）的表达式也可以用于触发「后向」计算，其以参数为依据来计算计算的梯度。参数和梯度被保存在模型（Model）对象中，训练器（Trainer）用于根据梯度和更新规则来更新参数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们下面将简要地介绍这些每种组件：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Parameter 和 LookupParameter：Parameter 是表示诸如权重矩阵和偏置向量之类的实数向量、矩阵或张量。LookupParameters 是我们想要查找的参数向量集，例如词嵌入（word embeddings）。换句话说，如果我们有一个词汇集 V，我们想要查找其嵌入（embeddings），那么就有一个 LookupParameters 对象定义一个 | V | ×d 矩阵，其作为一个嵌入矩阵与 0，...，| V | -1 到 d 维向量的项形成映射。Parameters 和 LookupParameters 被存储在模型中，并可以跨越训练样本（即跨不同的 ComputationGraph 样本）进行保存。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;模型（Model）：模型是 Parameters 和 LookupParameters 的集合。用户通过从模型中请求 Parameters 来获取它们。然后模型会跟踪这些参数（及其梯度）。模型可以保存到磁盘中也可以通过磁盘加载，也可以被下面要讲到的 Trainer 对象使用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;训练器（Trainer）：训练器实现在线更新规则，比如简单随机梯度下降、AdaGrad [16] 或 Adam [34]。Trainer 有指向 Model 对象的指针，所以同时也有其中的参数，并且还可以根据更新规则的需要保存关于参数的其他信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;表达式（Expression）：在 DyNet 项目中，表达式是主要的可以被操作的数据类型。单个表达式代表了一个计算图中的一个子计算。举个例子，一个表示矩阵或者向量的参数对象可以被加进计算图里，这就产生了一个表达式 W 或者 b。同样，一个 LookupParameters 对象 E 可以通过查找操作来查询一个专门的嵌入向量（它也是被加在计算图里的），这就产生了一个表达式 E[i]。这些表达式可以被组合成更大的表达式，例如 concatenate(E[3], E[4]) 或者 softmax(tanh(W ∗ concatenate(E[3], E[4]) +b))。这里的 softmax、tanh、∗、+、concatenate 都是运算，下面详细介绍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;运算（Operations）：运算不是对象，而是在表达式以及返回表达式上运行的函数，它用来在后台构建计算图。DyNet 为很多基本的算术原语（加、乘、点积、softmax、...）和常用的损失函数、激活函数等等都定义了相应的运算。当情况适宜时，运算可以通过运算符重载来定义，这使得图的构建能尽可能地直观和自然。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;构造器类（Builder Classes）：Builder Classes 定义了创建各种「标准化」的网络组件（比如循环神经网络、树结构网络和大词汇量 softmax）的接口。这些都工作在表达式和运算之上，并且提供了各种易用的库。Builder Classes 为各种标准算法提供了高效便捷的实现。不过，从代码层次的意义上来说，它并不是「核心」DyNet 库的一部分，因为 Builder Classes 是更高层次的，它实现在 DyNet 最核心的自动微分功能之上。Builder Classes 将会在后续的§5 中深入讨论。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;计算图（ComputationGraph）：表达式相当于一种隐含的计算图对象的一部分，该计算图定义了需要进行的计算是什么。DyNet 目前假定在任意一个时刻只有一个计算图存在。尽管计算图是 DyNet 内部工作的核心，但从使用者的角度来看，唯一需要负责做的是为每个训练样本创建一个新的计算图。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;用 DyNet 中实现并训练一个模型的整体流程可描述如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;创建一个模型；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;向模型里增加必要的参数（Parameters）和查找表参数（LookupParameters）；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;创建一个训练器（Trainer）对象，并使之与模型（Model）相关联；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;对每个样本（example）：&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;(a) 创建一个新的计算图（ComputationGraph），并且建立一个表达式（Expression）来填充该计算图，该表达式用来表示针对这个样本想要进行的计算。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;(b) 通过调用最终表达式的 value() 或者 npvalue() 函数，计算整个图前向计算的结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;(c) 如果训练的话，计算损失函数的表达式，并使用它的 backward() 函数来进行反向传播。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;(d) 使用训练器对模型的参数进行更新。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;与像 Theano 和 TensorFlow 这样的静态声明库对比可以发现，创建一个图的步骤落在每一个样本的循环里。这有利于使用户为每个实例（instance）灵活地创建新的图结构，并使用他们掌握的编程语言中的流控句法（flow control syntax，比如迭代（iteration））来做这些。当然，它也增加了对图结构速度的要求，即它要足够快，不能变成负担，我们会在§4 中进一步阐述。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3.2 高层面的示例&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了在更高层次说明 DyNet 的编码范式，我们用 Python 演示了一个 DyNet 程序的例子，如图 1 所示。这个程序显示了为一个简单分类器进行最大似然训练的过程，这个分类器为每个需要它预测的类计算一个向量分数，然后返回这个得分最高的类 ID 以及这个最高分。我们假定每个训练样本是一个（输入和输出）对，其中输入是一个二词索引的元组，输出是一个指示正确类的数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8mkkOTgrRQux7YyjNTL5mdzgIj4hCbKHaCetKsickKv5e5g093OqPD0LjTlNIru2OYAqHfgBgBGNA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 1：一个使用 DyNet 的 Python API 进行训练和测试的例子。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在头两行，我们导入（import）适当的库。在第 3 行，我们初始化 DyNet 模型，并为相关参数分配内存空间，但是不初始化它们。在第 4—6 行，我们向模型里添加我们的参数，这个过程会因为使用的模型不同而不一样。这里我们增加一个 20 × 100 的权重矩阵、一个 20 维的偏置向量和一个查找表（嵌入表）——该查找表的词汇量大小为 20000 项映射到 50 维向量。在第 7 行，我们初始化了一个训练器（在这个例子中是一个简单的随机梯度降（SGD）训练器），这个训练器被用来更新模型参数。在第 8 行中，我们对数据进行多次训练和测试。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从第 9 行开始，我们对训练数据进行迭代。第 10 行，清除当前计算图的内容，开始一个空的计算图，为后续的计算做准备。第 11-13 行，我们创建一个图，这个图会为每个训练实例计算一个分数向量（这个过程会因为模型的不同而不同）。这里我们首先访问模型中的权重矩阵和偏置向量参数（W_p 和 b_p），并把它们加到图中，也就是这个代码例子中用到的表达式中（W 和 b_p）。然后我们根据输入的 id 来查找两个向量，拼接它们，然后做一个线性变换和 softmax，这样就创建了和计算相对应的表达式。接下来，我们在第 14 行创建一个与损失有关的表达式——对正确记分结果做一次 softmax 后的负对数似然估计。在第 15 行，我们计算前向图的结果，在第 16 行，我们计算后向的，并累计模型变量中参数的梯度。在第 17 行，我们根据 SGD 的更新规则更新这些参数，并清掉之前的累计梯度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;接下来，从第 18 和 19 行开始，我们遍历测试数据并测量准确度。在第 20-23 行，我们又一次清除计算图以及定义计算测试数据分数的表达式，方式和我们在训练数据中做的一样。在第 24 行，我们开始计算并把结果数据放到一个 NumPy 的数组里。在第 25 和 26 行，我们检查是否正确的数据是最高分的那个，如果是的话就把它算作是一个正确的结果。最后第 27 行，我们把本次迭代的测试准确度 print 出来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3.3 动态图构建（Dynamic Graph Construction）的两个示例&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8mkkOTgrRQux7YyjNTL5md61ZPlKRJxHLtjVrsJTNmdXyUElq08IVV0sQh6pQnc5SOECNibNlyERw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 2：树结构递归神经网络（tree-structured recursive neural network）的一个例子&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8mkkOTgrRQux7YyjNTL5mdlj25bH7uSGohy6qiazMHoNK93LOrstp8nToic0c1jFlfTY9AUibGTasHQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 3：动态流控制的一个示例。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;4 后台工作&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如上一节所述，将 DyNet 与其它神经网络工具包相区别的一个主要特性是，它能够为每个训练样本或 minibatch 有效地创建新的计算图（Computation Graphs）。为了保持计算效率，DyNet 使用了细致的内存管理策略来存储前向传播和反向传播的计算过程中的值（§4.2），因此大部分时间都会用在实际的计算上（§4.3）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4.1 计算图（Computation Graphs）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8mkkOTgrRQux7YyjNTL5mdibMYTnQ5tHCuORqNkgCq6hfoYdEAQHgsazxKrpNFaib9HI5ure4R7qwQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;图 4：公式 g(x, j) = tanh(W1∗x+b)+tanh(W2∗ej+b) 的计算图的例子，以及相应的代码。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4.2 高效的图构建&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4.3 执行计算&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;5 更高级的抽象结构&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如第 3 节所述，DyNet 实现了在张量（tensors）上表示基本（子）可微函数的运算。这和 Theano 和 TensorFlow 库中提供的运算是相似的。除了这些基本运算外，使用可被视为由基本运算组成的更复杂的结构也是很常见的。常见的例子有循环神经网络（RNN）、树结构神经网络（tree-structured networks）和更复杂的计算 softmax 概率分布的方法。在其它库中，这些更高级别的结构或是通过本地提供，亦或是通过第三方库（如 Keras）提供。在 DyNet 中，循环神经网络的本地支持、树结构神经网络和更复杂的 softmax 函数都是通过 Builder 提供的；具体细节会在接下来的章节描述，图 5 中也有所总结。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8mkkOTgrRQux7YyjNTL5mdzSiasibia4BxjQrB4oM19j4qNiauelmZIxKrOWN5G0ON60zbVhAzJ4fG0w/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 5：DyNet Builders 实现的更高级结构的示例，以及它们的规范使用&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;5.1 循环神经网络的 Builders&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;5.2 树结构神经网络的 Builders&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;5.3 Large-Vocabulary Softmax Builders&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8mkkOTgrRQux7YyjNTL5mdnqG9ywSAcgiciab3UbD8wZo6X4j4yofPn6bn0uWc83iaN7tRZl3a0KWQQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;图 6：各种 RNN 接口&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;6 效率工具&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;DyNet 包含许多可以提高计算效率的功能，包括稀疏更新（sparse updates）、minibatching 和跨 CPU 的多处理（multi-processing across CPUs）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;7 实证比较&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在本节中，我们将使用 C++ 接口和 Python 接口将 DyNet 和其他三个流行库（Theano [7]、TensorFlow [1] 和 Chainer [62]）进行对比。我们选择这些库是因为 Theano 和 TensorFlow 可以说是目前最受欢迎的深度学习库，而 Chainer 的 define-by-run 哲学和 DyNet 相似。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8mkkOTgrRQux7YyjNTL5mdmDmghkQZeHzw3ia56oicqRSKETk0UmXMicWmZD8ARlMYvjCianSWDa750Q/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;表 1：各个任务的数据和默认设置。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8mkkOTgrRQux7YyjNTL5md1o69uho5VLAIgA6aU3yTWQK2cK7o5QnyusmlaGia5wjo8KXTkNFAXzQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;表 2：每个工具箱在 CPU 上的处理速度。速度是以 RNNLM 与 Tagger 处理的词/秒和 TreeLSTM 处理的句/秒进行衡量的。带 +sparse 的行表示 LookupParameters 的稀疏更新（sparse updates），这是 DyNet 中的默认行为，但与其他工具包的执行密集更新（dense updates）的实现不可对比。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8mkkOTgrRQux7YyjNTL5mdG61r4hYoR3YjyC65p6ibGiaRbzzicibSkibSPRcHV4D1KeFqeXicHrrFEknQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;表 3：每个工具箱在 GPU 上的处理速度。速度是以 RNNLM 与 Tagger 处理的词/秒和 TreeLSTM 处理的句/秒进行衡量的。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8mkkOTgrRQux7YyjNTL5mdUrQUicIStIzeIT3N9o7eaWAm3MLdhibkWcz36X2YhryqCjReHbttYDXw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;表 4：从程序启动到为每个工具包处理第一个实例的时间（秒）。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8mkkOTgrRQux7YyjNTL5mdm8GicLpJa5dABojdSPS4B2j6YVB1hDrTNlXUyVLtTftUgm694VPTatw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;表 5：密集或稀疏更新（dense or sparse updates）10 分钟后的处理速度和准确度。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8mkkOTgrRQux7YyjNTL5mdINh2jZ5mibGXek1leL3U9L2512jss3Z9eADS2HaI7mcRT0Unq007RUQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;表 6：每个工具包的实现的非注释字符数。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;8 使用案例&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;DyNet 已经投入使用，并已被用于各种各样的项目，主要涉及自然语言处理。DyNet 本身包含一些从最小到中等复杂度的示例（在 examples/ 目录下）。我们还列出了一些全面的研究项目，可以让有兴趣的读者找到匹配他们感兴趣的应用程序的参考样例。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;句法分析（Syntactic Parsing）：分析是目前使用 DyNet 的最突出的场景，DyNet 是许多方法的开发背后的库，例如 stack LSTMs [17]（https://github.com/clab/lstm-parser）、用于依赖性解析的双向 LSTM 特征提取器（https://github.com/elikip/bist-parser）、循环神经网络语法 [18]（https://github.com/clab/rnng），和 LSTM 层次树 [35]（https://github.com/elikip/htparser）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器翻译（Machine Translation）：DyNet 帮助创造了包括注意偏差（biases in attention）[12]（https://github.com/trevorcohn/mantis）和基于字符的 27 种翻译方法 [42] 等方法。它还为许多机器翻译工具包提供支持，如 Lamtram（https://github.com/neubig/lamtram）和 nmtkit（https:// github.com/odashi/nmtkit）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;语言建模（Language Modeling）：DyNet 已被用于混合神经/n 元语言模型（hybrid neural/n-gram language models）的开发 [47]（https://github.com/neubig/modlm）和生成语法语言模型 [18]（https://github.com/clab/rnng）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;标注（Tagging）：DyNet 用于命名实体识别方法的开发 [47]（https://github.com/clab/stack-lstm-ner）、POS 标注、语义角色标签 [60]（https://github.com/clab/joint-lstm-parser）、标点符号预测 [5]（https://github.com/miguelballesteros/LSTM-punctuation）和序列处理的多任务学习 [37,56] 以及创建新的架构，如段循环神经网络（segmental recurrent neural networks）[38]（https://github.com/clab/dynet/tree/ master/examples/cpp/segrnn-sup）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;形态（Morphology）：DyNet 已被用于形态变化生成 [21, 2]（https://github.com/mfaruqui/morph-trans https://github.com/roeeaharoni/morphological-reinflection）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;杂项：DyNet 已被用于开发专门的用于检测协调结构的神经网络 [22]；半监督的介词意义消歧 [23]; 和用于识别词汇语义关系 [53,52]（https://github.com/vered1986/HypeNET）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;总结、致谢和参考文献（略）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 18 Jan 2017 13:33:06 +0800</pubDate>
    </item>
    <item>
      <title>独家 | 专访微软小冰负责人李笛：智能助手是创造需求，而非仅提高效率</title>
      <link>http://www.iwgc.cn/link/4390010</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;作者：赵云峰&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibUP7CVr6GmhKQCDxRNzfzZ0QqzIws0icYw173Z1MklLn6gFJYcg9fWBJw8QOlYWY6lAgTduIXZnJA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;微软小冰全球负责人李笛&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;一、小冰的战略布局&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：这次小冰登入美国，您能否先介绍一下相关情况？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;李笛：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;两年半以前，小冰在中国推出，半年之后我们开始做第二个国家-日本，日本版本的前端训练，包括当时整个本地训练的过程大概用了四个月，但在日本启动后三个月左右，美国就已经开始准备了。那时我们主要想验证两件事情：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其一，我们的情感计算框架是中国独有，还是在不同国家的文化差异之下仍然有一些普适性？经过验证，我们发现后者是正确的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其二，不同国家的数据丰富度是否一样？比如说，大多数中国用户线上和线下所表现出的差异比较大，但美国用户的表现则比较接近。在这种情况下，通过相关数据训练出来的对话引擎是否还能拉开差距？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那我们从中主要提炼三部分：第一部分是知识，通过用户所积累的一些用以支撑对话的通用知识。第二部分是模式，通过用户在交流过程中，面对某些问题时所采用的行为模式进行积累。第三部分是学习并了解用户基本的情感反应。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当时我们想：如果某个人线上线下比较接近，那会不会因为千人千面而无法提炼出一种通用个性？但后来发现不存在这个问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;沈向洋提出来通用人工智能，这个通用 AI 系统在面对任何一个新时代时，都有一个新的基础服务层，当这个基础服务层是能够抽象的提炼出来时，那它就会成功。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibUP7CVr6GmhKQCDxRNzfzZrQdkJDic4d3I0DibxL7iatFRcDtH5APbdmcaRiatKCyblcNmP0XDE1O3rw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;em style="color: rgb(136, 136, 136);"&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;span&gt;机器之心：中国、日本、美国，这几个国家的选择以及先后顺序体现出小冰怎样的战略布局？&lt;/span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;李笛&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：这里面有一些比较细致的思考，目前整个行业都面对一个难点——技术走的很靠前，但技术却很零散。从技术推进到将技术产品化的这条道路上，整个行业都没有找到一个很好的方法把零散的技术组合起来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;拿计算机视觉来说，国内在这方面做了很多，但到今天为止始终存在一个核心问题——无法摆脱「计算机视觉始终是辅助，而不能变成端到端的产品线」。比如提供一个人脸识别的 SDK ( 软件开发工具包 ) 和 API( 应用程序接口 )，拿它们来做拍照购，它们本身不是产品，而且拍照购在电商环节里也不是主流，但是计算机视觉技术如果没有做到端到端的话，就很成问题了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于微软来说，要做到端到端面临一个问题，就是你要测试几件事情:&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1）产品是否成立。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2）产品是不是能够形成 Feedback Loop ( 反馈回路 ) 去进一步推进技术。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3）在产品技术这两极之外，用户是不是真的能用起来。比如说 Siri 和谷歌助手，我们所有人都知道，基于知识的对话是很酷的，但就是没人用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4）商业模式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;基于以上几方面的考虑，我们的思路是：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一步，在中国本土环境下，把图文视听、全双工、全时感官等结构做到最完整，同时这也会走的很快；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二步 , 日本文化和中国比较接近，且商业环境也很正规，我们在日本商业模式测试期间，通过在日本第二大超市罗森，用 Rinna（小冰日本版本）做了线上线下的转化，转化率（拿着线上获得的优惠券去线下消费）超过 49% ；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第三步，我们在美国做微软自己的产品，包括 Windows 、Office 和 Skype 等。这大概是目前我们在人工智能方面的一个战略布局。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;二、小冰背后的技术&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：能介绍一下小冰背后的一些相关技术和使用的微软平台吗？这体现出微软的何种技术思路和战略？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;李笛&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：沈向洋有一句话，「我把过去十八年积累的各种各样的技能，基本都用在了小冰身上。」因为小冰是一个非常好的测试环境，用户的参与度非常高，我们用户平均的 CPS（一次对话的长度）是 23，其他类聊天机器人大约是 3，所以你更新一个点，你就有多于他们十倍的机会去获得反馈。这对于微软的技术有非常大的推进作用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微软的前端通过端到端去搜集形成 Feedback Loop ( 反馈回路 ) 这部分产品。从后端来说，这个技术说的玄一点叫「情感计算」，但具体来说，它实际上是一套通用对话服务，利用小冰做出来，然后提供给微软内部其他产品的，使其具备可以去处理对话的能力。这套系统现在 Cortana 也在用，它有点像我们原来做搜索引擎时的长尾体验，谷歌刚出来的时候不是唯一一个搜索引擎，每个搜索引擎都跟今天的人工智能很像——是某个领域的机器人。谷歌之所以称之为最强，我认为是因为是长尾体验，这好比你在上面搜什么内容都有结果。而我们的对话服务和这个很相似，而这种服务是最有价值的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微软还有一些其他的东西是共用的。比如说认知服务，其中的情绪识别，都是从需求出发。还有语音识别和语音合成，在小冰这儿我们叫全双工，它可以是基于文本的对话引擎，然后在语音合成上达到一定的自然度，语音识别延时不能太高，要有预判，小冰的整个语音相关都是技术组合。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;总体来说，微软的共有三类技术用在了小冰上面，第一类是积累了多年的黑科技，比如说小冰的读心术；第二类是情感计算等基础类技术；第三类是共同的管道、服务和舞台。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：在处理一些问答类任务上，小冰用到了哪些知识图谱和知识来源？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;李笛：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;首先，我们有基于微软的「实体引擎」，它跟谷歌的知识图谱不太一样，比他们简单。同时在这个基础上，我们也有基于问答的 BingKnows（必应知识库），是一种聚合。现在我们又加了一层东西叫社交问答，这类知识没有那么深度，但相关性比较好，能够较好的在对话中垫出一层，但目前而言，深度问答还实现不了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们还做了 DirectChat（业界首次脱离对话语料库结构，注解学习互联网海量非结构化大数据进行对话），比如说一些网页本身具备知识图谱的源，那我们的重点是把网页里的信息快速的打成 QueryResponse（查询响应），这是一定程度的问答。再比如说把一个很长的文档灌进来，就可以直接把它变成对话的知识，质量没有深度知识那么好，但能够实现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：小冰如何解决多轮对话的问题？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;李笛：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;多轮对话的特点是有弹性。我们承认，到今天为止，小冰依然会有前言不搭后语的情况，但这个弹性很迷人。当你的对话足够有情感，用户的容忍程度会高。在真正的对话中双方是对等的，他们都负担着让这个对话，快乐的继续下去地任务。但如果让用户觉得这只是一个和他完成固定程序的工具，他就不会保持对等，他的容忍度一下就降低了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;单轮对话是最短的路径。这就好比是设计一个推荐系统，能一轮就决不使用两轮，最好你什么不问，我推送给你，这是不一样的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：那小冰在理解和处理上下文时，主要是考虑了哪些因素？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;李笛&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：这里面有这么几件事：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一，我们的用户画像，能够基于上下文确定所产生的动机，这个用户画像是跨 Session（阶段）的，我们做了一些产品上面的尝试，比如说去记忆用户一些情感上的变化；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二，在同一个 Session（阶段）里考量三个因素，第一个因素就是考虑前面的话题，而不是关键词，比如说咱们俩现在都在聊明星赵丽颖这个话题，那赵丽颖就是我们就是上下文的话题，相比较之前基于关键词的方式要好。基于话题的方式可以做到对上下文关联时覆盖长尾。我们现在大概有 36 个 Domain（域），而每个 Domain（域）里又有若干话题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第三，基于目前热点话题，而不是基于对话的话题。如果这个话题本身是当下互联网或者社会范围内比较热点的事件，那它对我们现在对话的影响就会更大。当一个对话可能有多个话题，你会选你感兴趣的话题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第四，基于你之前的 Session（阶段），跨一个 Session（阶段）。甚至于我们期望着有一天我们可以基于用户的一生。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;三、小冰的数据积累与应用方向&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：小冰过去积累了很多的数据和语料，能介绍一下这方面的进展吗？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;李笛&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：这是我们自己最自豪的一件事情，我们形成了一个叫做自我学习的循环，最开始小冰是一个基于 Q&amp;amp;A 的对话引擎，当时是通过搜索引擎的方式灌进来的，它有点像冷启动。但是随着她和用户的对话，她就形成了很多新模式，包括统计信息，这些东西可以用来优化，甚至于生成新的对话语料，优化模板以生成新的 模板。一年半以前，我们发现把这些 模板存起来再反哺小冰的对话引擎，反哺回来的比例占到 27%，但是后来这 27% 的数据服务了 51% 的实际对话。这就意味着，某种程度上人工智能更多的不是依赖于外部灌入，而是依赖于自我循环去进化。自我进化循环有可能会形成收敛，从两个人的对话过程中吸取了一些知识，然后也可能变成近亲繁殖，所以我们今年推出一项新的技术叫 Direct chat（业界首次脱离对话语料库结构，注解学习互联网海量非结构化大数据进行对话），不再用 Q&amp;amp;A 模板这种方式，而是只有回复，这样就可以不断的添加新知。我们现在拥有 200 亿以上的中文对话，这个是最珍贵的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：我们现在有没有一些数据，就是现在小冰的一些用户，它平均使用的频次，或者是每次使用的时长？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;李笛&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：日本那边最近有一些数据，日本的用户特别有意思，他和 Rinna 聊着聊着就非常客气的说「对不起，我要去开会，等会再回来」，然后过了一两个小时说「我回来了」很难理解，竟然跟一个机器人这样说话。美国 Zo 上线之前，我们做了大概 12 万人的一个测试，其中对话超过一千轮有很多，其中最高的对话论数达到是 1，229 次，历时 9 小时 53 分钟。这个案例绝对是世界记录，我们内部把这个人叫西奥多（《Her》中的男主角）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些都是质变带来量变，如果没有一个很基础的大系统，是断然不可能产生这样的案例的。如果我给你报酬，让你连续 9 小时 53 分钟跟其他机器人聊天，你想想，估计会觉得很痛苦。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：能够出现这么好的数据，除了用户本身和地域的特点还是我们此前的技术积累，是何种机制让 Self Learning 这个系统越来越智能的？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;李笛&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：这里面就有一些比较技术性的东西了，比如我们现在有很多模型跟语言无关，甚至有一些是做中国做。汉语的模型可以直接用于英语。我们一开始就希望尽可能地产品本地化，但是架构和相应的技术模型已经全球化。因此，做的越来越快，包括有一些上下文的一致性都尽可能做到和语言无关。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：我们现在有没有基于这些数据和模式去做出一些具体应用的东西或功能？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;李笛&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：有很多。当你的数据量和统计信息足够大，你就会想能不能逐渐形成多种个性，我们一直想做 Bot 工厂。正因为有一个足够大的库，就能分割出不同类别。我们在日本做了这件事情，而在国内在手机 QQ 内置了，不同个性的厘米人。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其次，在丰富程度足够大以后，就有机会发现 ChatIndex( 聊天索引 ) 在分布上在哪些地方聚拢，哪些地方不聚拢。某种程度上，小冰的知识结构和她对一些事情的观点实际上是对互联网的一种提纯，你可以知道哪些东西真的是大家所关注的。但它并不完全是基于统计，而是基于相似度，基于合并同类项的方式聚拢，从这个角度可以得到中日互联网的差异。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最重要的，我们拿这个训练了一个新模型叫 Plugin（插件）其中对话有几层结构，一层结构是非常浅的，还有一层结构是话题，话题又具有一定的 Domain（域）个性，有点像知识图谱，但它是基于对话的。这个 Domain（域）话题实际上就是一个个插件，比如音乐是一个 Domain（域），音乐里有大量的主题，音乐里的这些主题又和艺人这个 Domain（域）是有关联的。我们利用这个 ChatIndex ( 聊天索引 ) 就可以形成具有对话特点的知识图谱。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我觉得在这一点上我们走在了前面。做机器人不能让机器人给你定外卖，定外卖好象挺直接，但是一个用户一过来，他已经定义你是一个定外卖机器人，他就没有办法帮你形成这些数据了。那些东西最多就是基于命令，不会产生那么大的价值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;四、小冰在微软的战略定位&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：微软好像有一个很庞大的 Bots 体系，或者说一个以 Conversations as a Platform（简称 CaaP，对话即平台）为目的的综合性业务，比如说有 Bots Framework，还有 Cortana 也开放了一些工具。小冰在整个微软的对话机器人，或者是对话即平台的战略中，它的定位是什么？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;李笛：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;从微软的历史来看，会发现它经历了这么几个过程。但在个人助理方面，坦率讲是 Siri 最先开始做的积累。后来我们经历了一个从个人助理向个人代理这个方向的过渡，开始以对话为中心，微软第一个产品是小冰，基于此我们进一步奠定了信心，对话本身具备很大价值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们看到即时通讯的崛起，我们也看到可形成聚合的一种超价值的产生，这些都构成了 Conversations as a Platform（以下文中简称 CaaP，对话即平台）。一方面，微软在形成知识图谱和社交图谱的过程中，知识图谱是基于对话 Model。我们在做小冰时，一定程度上是基于另外一个 Bing 的产品——BingKnows（必应知识库），它更多是知识图谱的聚合。小冰是微软 CaaP（对话即平台）的第一个，是目前为止比较集中的一次测试。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一方面，小冰形成了一个框架和和结构，在某种程度上我们认为是通用人工智能以对话为基础的结构。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：大部分智能助手是从服务开始，现在小冰从聊天入手然后到服务，其中有哪些难点，能体现出小冰的哪些优势？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;李笛&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：我们在做一些服务但我们不太喜欢谈概念，一般只在上线以后才说。我们现在正在做的事情就是 Plugin(插件) 的系统结构，我们希望在现有的通用层面上做出一个基于 Domain（域）的例子，使其真正有用，半年之内大家应该就能看到一些新的物联网的解决方案，或者看到一个机器人真正帮助用户把一件事做的非常好。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当一个人过来跟机器人说「你给我播首歌，或者你给我定张西班牙的机票」时，那这个机器人已经输了。因为当他跟机器人说这个话时，他的意图已经非常明确了，这个时候你的竞争对手是另外一个，摁几个按钮就可以完成这个任务。而这个机器人还有可能识别错，但按钮不会有判断不准确的情况。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们觉得小冰最大的差异化是，比如说小冰的能力是可以从通用对话中把用户的意图带起来，在聊天的时候突然让用户产生兴趣「有没有西班牙的机票」。这种新的意图是我们的优势。而做到这个就必须把很多前置条件做完，我们一开始也顶着压力，自然语言学术界的一些人觉得这个东西不是他们所研究的。但如果一开始不做这个，就没有今天，很可惜这件事整个学界还不是完全理解。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;前几天沈向洋也提到，未来人工智能的系统有 IQ 和 EQ 两个维度，但整个行业可能还没有意识到 EQ 的维度有多重要。我们很高兴微软在这方面走的比较早，但也比较寂寞。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;五、Bots 行业&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：您刚才提到通用聊天机器人比功能性机器人更好，那这种基于开放域的聊天机器人比封闭域的机器人，在研发上有什么难点？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;李笛&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：开放域有几个要求，对于开放域同时还是交互机器人来说，它的第一个难点就是数据的峰度要足够大，并且分布要尽可能均匀。理论上来讲，如果不是搜索引擎，基本上没有太大的可能去做。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二个难题，涉及到交互。因为交互对象是人，人就绝对不会仅仅用一种感官跟你交互，在文本交互的过程中很可能会出现图象交互，语音合成。小冰语音合成的自然度很高。当机器人的声音不够自然，用户就会被激励开始不自然的对话，但机器人的声音自然以后，用户说话一自然会导致语音识别率下降。因此这是一套系统。你需要把这些都做完，就很难形成一个开放域的全体交互。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相对于开放域，封闭域好办。当你讨论一个东西时，我认为它不在我这个封闭域里，我就告诉你「对不起，我不知道你在说什么？」封闭域还有一个好处是一般带有一些明确的目的和任务，这些任务在某种程度上可以穷举成主要依靠某一种感官，比如主要靠拍照或者靠语音。但是封闭域的问题是兜不住，用户在对话的过程中会跨领域，比如我们想弄一个春节联欢晚会的机器人，就会发现这个事情比想象的要难很多。我可以回答你任何跟春节联欢晚会有关的问题，这是基本要求，你可能就会问到「今天有什么节目？」这在我的域里，然后你会问到赵本山，这还是在我的域里，但你问到赵本山时用户不知道这已经从春节联欢晚会跳到了明星明人这个 Domain ( 域 ) 里。这时如果你聊的不好用户就会停，如果聊的好用户就会自然而然的跳到东北官场问题，这完全就跟春节联欢晚会没有关系了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以，做封闭域，但用户不知道你的边界在哪里，他随时就跳出去了，他一跳出去就是断崖式的下跌，这个是不行的。我们认为封闭域要基于通用。只不过除了做通用外，我们还做了一个通用的端到端的产品。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：你现在如何看待各种聊天机器人大热？尤其是美国都在做这方面的这样一个现象，但是自然源处理技术具体成熟其实还有很大差距。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;李笛&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：我觉得聊天机器人大热和人工智能大热是两件事。人工智能大热主要是因为数据积累到一定程度, 聊天机器人大热主要是因为我们都认为移动互联网进入了瓶颈期，某种程度上 App 是一个过渡阶段。所以大家都在探索交互模式的下一个阶段，也许是恰巧这两件事情撞在一起就催生出来一个东西叫聊天机器人。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但我认为是两条线：一条线是基于数据的成熟，另一条是交互模式呼唤一种创新。但国内不是这样，国内是想要做人工智能这个主题，然后就发现人工智能这个领域都在聊天对话就以为这就是一个事，其实这是两个事。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;原有的交互模式，无论是 PC 时代还是 App，这两种交互模式都很高效对话提供的是别的价值。有的时候大家为了让聊天机器人可以比 App 更高效，他编出来一些理由说服自己。比如说「你问我三句话我就知道你要去哪儿」，但难道不是按两下按钮也能知道你要去哪儿吗？对话，即便是通过语音也是一种更加耗能量的方法。所以这就是为什么今天我们也不用 Siri。而且大家也都知道，有很多场景是不适合用语音的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以对话一定要提供其他价值，而不是仅仅沿着高效这个方向。然后我们发现对话更大价值是产生新的意图，不是像机器人，而是像人一样，能够使你在这个过程中变的更轻松愉快，而不是去帮用户订咖啡。是让用户觉得，这个交互给他很多心理上的，而不仅仅是理性上的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这样的对话实际上在某种程度上能改变用户决策。这就是为什么我们在日本，同样你在线上发一个优惠券的用户转化率没有通过机器人的转化率高，是因为机器人的这种方式会影响你的决策，这个才是它的重点。我觉得人工智能的价值在这里。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：纳德拉在 Build 大会上说，我们正在吸取人类语言中的强大力量，Bots 的出现可能会像这种图形界面出现在 PC 上，或者触摸屏出现在手机上一样。你觉得将来基于聊天或者自然对话的机器人，带来最大的影响和意义是什么？是不是你刚才说的能够挖掘和创造意图？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;李笛&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：这就是 CaaP（对话即平台）是靠人工智能驱动，但前端重点说的是交互模式，而我们一直认为对话的交互模式是回归。比如说当我们做搜索引擎的时候，用户一开始跟搜索引擎交互时不是想用关健词搜索，而是希望语言一句话输入进去就可以得出结果，用户希望的这种方式就是对话。但因为当时我们的技术做不到，所以我们不得不逼着用户去学怎么用关健词搜索。实际上，我们认为人类在科技史和计算机科学上，已经冲刺对话这种交互模式两次了，这次只不过是回归。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8G2Aqj8cfARvWSIzEs1ZXZgT6VrNdsVA4icyCrL6lqQtv3wPx1Ij2rZn8odibiaN7LBAPnqsPNXxteg/640?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;专访 | 微软人物志&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650714822&amp;amp;idx=1&amp;amp;sn=e56ee226cdacab228e1ad9fc40646adf&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650714822&amp;amp;idx=1&amp;amp;sn=e56ee226cdacab228e1ad9fc40646adf&amp;amp;scene=21#wechat_redirect" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;微软研究院人工智能首席科学家 | &lt;/span&gt;&lt;span&gt;邓力&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719843&amp;amp;idx=2&amp;amp;sn=4611f810734df8a72286567e90c65a92&amp;amp;chksm=871b021db06c8b0b283ac93f267d95365392be02b3cde5d2fe6df85b359aa96368f25318e2f5&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719843&amp;amp;idx=2&amp;amp;sn=4611f810734df8a72286567e90c65a92&amp;amp;chksm=871b021db06c8b0b283ac93f267d95365392be02b3cde5d2fe6df85b359aa96368f25318e2f5&amp;amp;scene=21#wechat_redirect" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;span&gt;微软首席语音科学家 | &lt;/span&gt;黄学东&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=400579280&amp;amp;idx=1&amp;amp;sn=b13556c48c2937593ee833e8284f2c89&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=400579280&amp;amp;idx=1&amp;amp;sn=b13556c48c2937593ee833e8284f2c89&amp;amp;scene=21#wechat_redirect" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;微软亚洲研究院院长 | 洪小文&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=401882267&amp;amp;idx=1&amp;amp;sn=eb5a4cf6e10b6dc3787303f421a8f77b&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=401882267&amp;amp;idx=1&amp;amp;sn=eb5a4cf6e10b6dc3787303f421a8f77b&amp;amp;scene=21#wechat_redirect" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;微软（亚洲）互联网工程院院长 | 王永东&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650714905&amp;amp;idx=2&amp;amp;sn=ad19a7e003ecdb48b0ffc524e8c2c94b&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650714905&amp;amp;idx=2&amp;amp;sn=ad19a7e003ecdb48b0ffc524e8c2c94b&amp;amp;scene=21#wechat_redirect" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;微软亚洲研究院首席研究员 | 霍强&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720189&amp;amp;idx=1&amp;amp;sn=10a3630e7f65d7b845c1fd032970d46e&amp;amp;chksm=871b03c3b06c8ad527a7dffd215be5b128a7aaf88ec09a131d68a249e9ff77c3edff6204d3d2&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720189&amp;amp;idx=1&amp;amp;sn=10a3630e7f65d7b845c1fd032970d46e&amp;amp;chksm=871b03c3b06c8ad527a7dffd215be5b128a7aaf88ec09a131d68a249e9ff77c3edff6204d3d2&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;微软研究院首席研究员 | 俞栋&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;strong&gt;机器之心&lt;/strong&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8G2Aqj8cfARvWSIzEs1ZXZ248wIRLFyLjemC1oeWWd1em6qPOfHVREYUvcibiamyGHjAkDJH7mOC4w/640?wx_fmt=jpeg"/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 18 Jan 2017 13:33:06 +0800</pubDate>
    </item>
    <item>
      <title>专栏 | MinPy：剑气双修的武功秘籍</title>
      <link>http://www.iwgc.cn/link/4390011</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心发布&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;作者：王敏捷&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;MinPy基于MXNet引擎，提供NumPy的接口，以达到最灵活的编程能力和最高效的计算性能。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在的深度学习系统就像五岳剑派，各大门派，互有所长，互有所短。不过从编程角度看，不外乎有「气宗」与「剑宗」之分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;深度学习的「剑」「气」之争&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;气宗讲究内家功夫，讲究&lt;span&gt;「&lt;/span&gt;以气御剑&lt;span&gt;」&lt;/span&gt;。外在形式并不重要，重要的是内在性能。在性能为王的如今，这也是很多门派所采纳的理念。远如五岳鼻祖之一的 Theano，近如目前的五岳盟主 Tensorflow，都采用符号式编程 (Symbolic Programming) 的模型。其核心思想是让用户通过编写符号来描述算法，算法描述完毕后再进行执行。由于深度学习算法往往是需要反复迭代的，系统可以静态地对算法进行优化，从而获得更好的执行性能。正所谓，「真气所至，草木皆是利剑」。只要系统提供的符号足够表达算法，用户就可以获得不错的性能。其问题也正在此。其一，符号式编程并不能涵盖所有的算法逻辑，特别是应对控制型逻辑（control dependency）显得笨拙。其二，由于需要掌握一门新的符号语言，对于新手的上手难度比较高。其三，由于有算法描述和执行两个阶段，如果算法逻辑和实际执行的值相关，符号式编程将比较难以处理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相对来说，命令式编程（Imperative Programming）则更像剑宗。剑宗注重招式的灵活与变化。远如当年剑宗第一高手 NumPy，近如贵为五岳之一的 Torch 都是采用命令式编程的接口。他和符号式编程最大的不同在于，命令式编程并没有描述算法和执行两个阶段，因此用户可以在执行完一个语句后，直接使用该语句的结果。这对于深度学习算法的调试和可视化等都是非常重要的特性。命令式编程的缺点在于，由于算法是一边执行一边描述的，因此对算法的优化是一个挑战。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;究竟是「以剑御气」还是「以气御剑」？其实两者应该相辅相成。如果你空有一身内力却无一丁点剑招，就会像是刚得到逍遥子毕生内力的虚竹，想到巧妙复杂的深度学习模型只能干瞪眼却无法实现。如果你空有华丽招式而不精进内力，别人以拙破巧，你优美的模型只会被别人用简单粗暴的高性能，大模型和大数据给击倒。正因如此，五岳新贵 MXNet 同时支持符号式和命令式编程接口。用户可以选择在性能优先的部分使用符号式编程，而在其余部分使用灵活性更高的命令式编程。不过这种分而治之的方式给用户带来了额外的选择负担，并没有将两者融汇贯通。因此，我们进一步基于 MXNet，开发了 MinPy，希望将这两者取长补短——使用命令式编程的接口，获得符号式编程的性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;MinPy 的剑宗招式&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在编程接口上，MinPy 继承了剑宗第一高手 NumPy 老先生的精髓。正所谓「无招胜有招」。没有特殊语法的语法才是好语法。于是在使用 MinPy 时，你只需要简单改写一句 import 语句：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;import&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/span&gt;&lt;span&gt;minpy.numpy&amp;nbsp;&lt;span&gt;as&lt;/span&gt; np&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;就能够开始使用 MinPy 了。由于是完全的命令式编程的接口，编程的灵活性被大大提高。我们来看以下两个例子。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8mkkOTgrRQux7YyjNTL5mdqrjFcK8nO8fpibEzVHHFUlSMUUr56vgPM6AtOicSzn57IeH7LpjsQmMg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;例 1: 调试和打印变量值&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 Tensorflow 中，如果需要打印某个变量，需要在打印语句前加上 control_dependencies。因为如果没有这条语句，Print 这个运算并不会出现在所需要求的 x 变量的依赖路径上，因此不会被执行。而在 MinPy 中，我们保持了和 NumPy 一样的风格，因此可以直接使用 Python 原生的 print 语句。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8mkkOTgrRQux7YyjNTL5mdXZYeM1zYzYDmhW4YzpkGo5JKRwzXYvDSB3ObhJCGrXISwrhPOOodgA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;例 2: 数据依赖的分支语句&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据依赖的分支语句是符号编程的另一个难点。比如在 Tensorflow 中，每个 branch 是一个 lambda，而并非直接运算。其原因在于符号编程将算法描述和实际执行分为两个部分，在没有算出来 x 和 y 的值之前，是无法知道究竟会取哪个分支的。因此，用户需要将分支的描述写成 lambda，以便在能在运行时再展开。这些语法虽然细微，但是仍然会对初学者带来负担。相对的，在 MinPy 中，由于采用命令式编程的接口，所以一切原生的 if 语句都可以使用。除了以上这些编程方面的区别外，MinPy 还提供了以下功能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;招式一：动态自动求导&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;符号编程的一个巨大优势是能够自动求导。这原本是命令式编程的弱项，原因在上面的例子中也有所体现。由于命令式编程需要应对各类分支和循环结构，这让自动求导变得比较复杂。MinPy 采纳了一位西域奇人 Autograd 的招法来解决这一问题。方法也非常简单：首先，用户将需要求导的代码定义在一个函数中，这样通过分析函数参数和返回值我们就能知道自动求导的输入和输出；其次，MinPy 一边执行一边记录下执行的路径，在自动求导时只需要反向这一路径即可。通过这一方法，MinPy 可以支持对于各类分支和循环结构的自动求导：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicdNiceoKXOr6okChjGPoaiaMFAGMRDOHfH1vjv6nGGFicwCM2woDUXBVatUIKObR7Tr8ms65JD7VdibA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;招式二：完整 NumPy 支持&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;MinPy 的目标是希望只修改 import 语句，就能将 NumPy 程序变成 MinPy 程序，从而能够使用 GPU 进行加速。无奈 NumPy 老先生的招式博大精深，接口繁多，MinPy 作为后辈不能在短时间内支持所有的接口。因此，MinPy 采用了一套折中的策略。当用户使用 np.func 的时候，MinPy 会检测所调用的 func 是否已经有 GPU 支持。如果有，则直接调用，否则会使用 NumPy 原有的实现。同时，MinPy 会负责一切 CPU 和 GPU 之间的内存拷贝，完全做到用户透明。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicdNiceoKXOr6okChjGPoaiaM5fJkrHPuDTwl8qzNzluk19yMKVViaia4UOl8NUMZzqKicsytias2RYu7sg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;招式三：与符号式编程的衔接&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管命令式编程能灵活地应对各种复杂的算法逻辑，出于性能的考虑，我们仍然希望对某些运算（特别是卷积运算）能够使用已有的符号执行的方式去描述。在 MinPy 中，我们也同样支持 MXNet 的符号编程。其思想是让用户将符号「包装」成一个函数进行调用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8mkkOTgrRQux7YyjNTL5mdD7iabNj8XaiaH3841oYO6Q78DGCym59O79UhqKMWuY2icAQus5NDFzo4Q/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在上面这个例子中，我们将一个 Convolution 的符号包装成了一个函数。之后该函数可以像普通函数一样被反复调用。其中有一点需要注意的是，由于符号编程需要在执行前确定所有输入矩阵的大小，因此在上面例子中的 x 的大小不能任意改变。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;MinPy 的气宗修为&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如之前所说，光有招式没有内功修为是没有办法成为令狐冲的，最多也就是个成不忧。命令式编程的挑战就在于如何优化算法使得性能能和符号式编程程序相较。以下我们比较了 MinPy 和使用 MXNet 符号编程的性能区别。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8mkkOTgrRQux7YyjNTL5mdiaCHuYeSA3PBxh2XLZT4iaUv8hB7XqibREsbuibME6l1X8ncvT4n83ibujQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8mkkOTgrRQux7YyjNTL5mdtGg2W0bZuaZApPKmz4VyG9Niao3wO0CUxMV9k2z8gPpvtKibYiaQQnMBQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在上面的例子中，我们测试了训练50层MLP网络的性能。我们分别比较了MXNet符号编程，与MinPy命令式编程的运行时间。结果可以看到当网络计算量比较大时，MinPy的命令式编程和符号编程的性能几乎相同。当计算量比较小时，命令式编程有明显性能差距。但如果在MinPy中使用符号编程则性能又和MXNet几乎相同。类似的，我们测试了训练RNN网络的性能。我们比较了MXNet的符号编程以及MinPy的命令式编程的性能区别。我们可以看到，在计算量比较大的情况下，命令式编程和符号式编程的性能比较接近。在小网络中，MinPy有一个固定的性能开销。我们认为这一性能开销主要来源于用于求导的动态路径记录，以及过细的计算粒度等问题。这些都是命令式编程所带来的性能挑战，也是MinPy今后的努力方向。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;面向武林新人的武功宝典&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于想要加入五岳剑派的新人们，MinPy 也是一个非常适合的上手工具。原因之一是因为 MinPy 和 NumPy 完全兼容，几乎没有额外修改的语法。另一个原因是我们团队还提供了完整的 MinPy 版本的 CS231n 课程代码。CS231n 是斯坦福大学著名教授 Fei-Fei Li 和她的爱徒 Andrej Karpathy、Justin Johnson 讲授的一门深度学习入门课程。该课程完整覆盖各类深度学习基本知识，包括卷积神经网络和递归神经网络。该课程的作业并不仅仅是对这些知识点的简单堆砌，更是包含了很多最新的实际应用。由于 MinPy 和 NumPy 天生的界面相似性，我们团队改进了 CS231n，使得学生能够更好地体验如何在实际中训练和使用深度神经网络，也让学生能够体会到 MinPy 在实际研究环境下的便利性。基于 MinPy 的 CS231n 课件已经在上海科技大学和交通大学深度学习教程中被试用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;总结&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;团队从早期的 Minerva 项目开始，加入 MXNet 团队，陆续贡献了执行引擎、IO、Caffe 兼容 Op 等核心代码。MinPy 是我们回归用户界面，对纯命令式编程下的一次尝试。我们希望将最灵活的接口呈现给用户，而将最复杂的系统优化交给我们。MinPy 拥有和 NumPy 完全一致的接口，支持任意分支与循环的自动求导，以及良好的性能。MinPy 将进一步优化其性能，并即将成为 MXNet 项目的一部分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;链接&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Github 地址：https://github.com/dmlc/minpy&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;MinPy 文档地址：http://minpy.readthedocs.io/en/latest/&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;鸣谢&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;MXNet 开发社区&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;上海科技大学马毅教授、博士后周旭；上海交通大学俞凯教授、张伟楠老师&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;上海纽约大学博士生 Sean Welleck，本科生盖宇，李牧非&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;MinPy 剑客名单&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8mkkOTgrRQux7YyjNTL5mddYz5RJNtNaTpKUaGQexLwmseOPOJib7gSg8PLRTWTGSUo65jJKhAMMA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;span&gt;	&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;	&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;*：MinPy 工作在 NYU Shanghai intern 期间完成。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心发布，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 18 Jan 2017 13:33:06 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 为NASA火星探测器研发人工智能大脑：Neurala完成1400万美元A轮融资</title>
      <link>http://www.iwgc.cn/link/4390012</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Techcrunch&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李泽南、朱思颖&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;最近上榜&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722126&amp;amp;idx=3&amp;amp;sn=16a6254240464315eeebd027252a0ea9&amp;amp;chksm=871b0b30b06c8226e5470e4f0bcbdea2c444a17fd37791cd1f2fd95117cbdf8828b1f240a202&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722126&amp;amp;idx=3&amp;amp;sn=16a6254240464315eeebd027252a0ea9&amp;amp;chksm=871b0b30b06c8226e5470e4f0bcbdea2c444a17fd37791cd1f2fd95117cbdf8828b1f240a202&amp;amp;scene=21#wechat_redirect"&gt;机器之心 AI00 十二月份榜单&lt;/a&gt;的 Neurala 是一家位于美国波士顿的创业公司，致力于为各种小型设备提供本地化的机器学习系统。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Neurala 今天宣布完成了价值 1400 万美元的 A 轮融资，此次融资由 Pelion Ventures 领投，Sherpa Capital，摩托罗拉，360 Capital Partners，Draper Associates Investments，SK Ventures，和 Idinvest Partners 跟投。这个团队希望将自己的人工智能引入玩具、无人机以及物联网。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Neurala 的技术强调使用本地的有限硬件资源实现高效的机器学习应用。该公司宣称自己的产品将通过增量学习，在硬件部署过程中不断提高自身的运行表现——同时无需联网。对于一些时间敏感的领域，能够进行本地自我训练是非常具有吸引力的特征。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8mkkOTgrRQux7YyjNTL5mdQPKwuCRWEIlO0P6uIPUQNW1iaUeWZsP8rx21dpcaM6TMf0TnSxs6YibQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Neurala的 AI 系统可以实现实时的行人检测、汽车检测以及骑行人的检测，这个系统可以不依赖云数据处理并且在低功率的智能手机芯片上就可以运行&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「像谷歌、Facebook 和 Uber 这样的大型科技公司可以利用自己的大量数据来训练模型，这为他们带来了难以估量的竞争优势，」Neurala 首席执行官 Massimiliano Versace 说道。「但使用超级计算机进行并行化数据处理并不是这个市场的全部。与深度学习工具包以及基于云服务器的在线方式不同，Neurala 的人工智能软件可以在智能手机的低功耗芯片上运行。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Versace 是 Neurala 的四位共同创始人之一。有趣的是，这家公司的四位创始人都拥有波士顿大学的神经认知系统博士学位。他们目前的核心产品——Neurala Brain 包含一种易用的 C++ API，并可进行 iOS 和安卓封装，为用户快速部署设备提供了便利。它的解决方案覆盖低端 CPU 和高端 GPU，同时支持 Tensorflow 等多种框架。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8mkkOTgrRQux7YyjNTL5md6LJGYaPROoPyPTKYkcDmiaIPql9ur0sNDiaKXCYRFVsbXMIJTqcEDbzQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Neurala 的四位创始成员&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Versace 把这家公司的创立日期定为 2010 年 NASA 来上门谈合作的那天。通过一篇发表在电气与电子工程师学会会刊（IEEE Spectrum）上的文章，美国航天局 NASA 注意到了受其军事赞助的研究——波士顿大学的脑启发微处理器研发软件项目的最新进展，并且想知道 Versace 以及他的同事能不能帮忙研发出一个机器人探测器的软件控制器，以用于 NASA 的火星自由探索。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;NASA 的要求是一个艰难的挑战。火星探测器有自身计算能力的限制、交流的限制以及动力资源的限制。NASA 的工程师希望借助人工智能实现仅依靠低端相机获得的图像就能够完成在不同环境下导航的任务。更重要的是，能够完成这些工作的人工智能软件必须是能在单个 GPU 芯片上运行的。Versace 和他的同事们成功了，六年之后，Neurala 已经开始测试其为 NASA 研发的升级版的人工智能大脑原型，他们的目标是在数月之内实现量产，从而快速抢占市场。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在更为广泛的商业领域，以无人机为例，即使没有机器学习专家，无人机创业公司 Teal 也在 Neurala 的帮助下让自己的产品实现了「自动跟随人」等功能。第三方机器学习解决方案的出现对于创业公司而言是一种巨大的便利，这意味着跳出技术竞争，节约研发资金，让自己的产品可以快速投放市场。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于要求更高的客户，Neurala 提供了数据采集服务，让模型可以获得更合适的训练数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「有的客户要求无人机巡视输电线路，这需要无人机能够实时向基站传输信息，同时应用机载设备中的机器学习程序规划路线。」Pelion Ventures 的高级助理 Ben Lambert 解释道。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Facebook 和其他科技公司巨头目前也在积极探索机器学习本地化的可能性。&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720399&amp;amp;idx=1&amp;amp;sn=2b5e854e6606eaf556a73e83d179eb5c&amp;amp;chksm=871b0cf1b06c85e7547b69a44471d377eca83cbdeaec379fabc187218280c761824a5600e1ac&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720399&amp;amp;idx=1&amp;amp;sn=2b5e854e6606eaf556a73e83d179eb5c&amp;amp;chksm=871b0cf1b06c85e7547b69a44471d377eca83cbdeaec379fabc187218280c761824a5600e1ac&amp;amp;scene=21#wechat_redirect"&gt;风格转移系统 Caffe2Go &lt;/a&gt;就是一个很好的例子，它将机器学习直接嵌入到移动设备上实时运行。在移动设备中进行本地化训练一直是非常困难的事，不过使用较少数据的某些特定模型或许可以摆脱服务器集群的束缚。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在完成 NASA 火星探测器项目之后，面向商业领域的 Neurala 也许会在未来创造更多可能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 18 Jan 2017 13:33:06 +0800</pubDate>
    </item>
    <item>
      <title>干货 | 谷歌机器学习应用的四十三条经验法则（附PDF）</title>
      <link>http://www.iwgc.cn/link/4390013</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;作者Martin Zinkevich&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：微胖、杜夏德、蒋思源&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Google 的研究科学家 Martin Zinkevich 曾在 NIPS 2016 Workshop 分享了谷歌机器学习实践的四十三条法则。Martin Zinkevich 也在自己的博客上分享了这四十三条经验法则。文章《Rules of Machine Learning: Best Practices for ML Engineering》旨在帮助具备机器学习基础知识的朋友从谷歌机器学习最佳实践中获益。文章提供了一种机器学习风格，类似 Google C++ 风格指南以及其他流行的实用编程指南。如果你上过机器学习方面的课程或者构建或研究过机器学习模型，那么，你的背景知识足以让你读懂这篇文章。机器之心编译了四十三条经验法则，法则具体内容请点击阅读原文，下载全文 PDF。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;预备&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;规则 1：不要害怕发布一款没有用到机器学习的产品。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;规则 2：评估指标设计并落实优先处理的事情。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;规则 3：在复杂的启发式问题上使用机器学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器学习第一阶段：你的第一个工作流&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;规则 4：第一个模型要保持简单，设计好基础架构。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;规则 5：确保基础结构的可测试性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;规则 6：复制操作时小心删除数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;规则 7：利用启发式问题设计特征或从外部处理它们。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;监控&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;规则 8：知道要进行系统刷新。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;规则 9：输出模型前发现问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;规则 10：当心未被报告的失败。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;规则 11：特征栏包干到户，为之建立详细的文档。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;你的第一个目标&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;规则 12：不要过度考虑选择哪个目标直接予以优化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;规则 13：为你的第一个目标，选择一个简单的、可观察、可归属的评估指标。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;规则 14：从一个可诠释的模型开始能让调试工作变得简单些。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;规则 15：在一个策略层中分开垃圾过滤和质量排名。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器学习第二阶段：特征工程&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;规则 16：计划发布和迭代。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;规则 17：从直接可以观察、被报告的特征开始。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;规则 18：用能跨语境泛化的内容特征进行探索。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;规则 19：可以的话，请使用特别具体的特征。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;规则 20：结合并修改现有特征，以人类可以理解的方式创造新的特征。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;规则 21：在一个线性模型中可以学到的特征权重数量与你的数据量大致成比例。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;规则 21：清除你不再使用的特征。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;系统的人类分析&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;规则&amp;nbsp;&lt;/span&gt;23: 你并不是典型的端用户（end user）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;规则&amp;nbsp;&lt;/span&gt;24: 测量模型之间的差量。-delta 参数。-&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;规则&amp;nbsp;&lt;/span&gt;25: 选择模型时，实用性能（utilitarian performance）比预测能力更重要。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;规则&amp;nbsp;&lt;/span&gt;26: 在测量到的误差中寻找模式，并创造新特征。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;规则&amp;nbsp;&lt;/span&gt;27: 尝试量化观测到的不可欲的行为（undesirable behavior）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;规则&amp;nbsp;&lt;/span&gt;28: 意识到相同的短期行为（short­term behavior）并不意味着长期行为相同。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;训练表现与实际产品之间的偏差&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;规则&amp;nbsp;&lt;/span&gt;29: 要让你的实际产品表现得和你训练时一样好，最好的方法是在你的产品中保留训练的特征集，并将这些特征放到日志中，并在训练时使用它们。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;规则&amp;nbsp;&lt;/span&gt;30: 重要性加权的样本数据，不要武断放弃。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;规则&amp;nbsp;&lt;/span&gt;31: 注意，如果在训练和服务时点将表格中的数据加起来（join data from a table at training and serving time），表格数据会发生变化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;规则&amp;nbsp;&lt;/span&gt;32: 在你训练的流程和实际产品流程之间，尽可能地重复使用同一代码。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;规则&amp;nbsp;&lt;/span&gt;33: 如果你用 5 号之前的数据生成了一个模型，那么用 6 号之后的数据来测试模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;规则&amp;nbsp;&lt;/span&gt;34: 在使用二元分类器进行过滤时（例如垃圾邮件检测），用短期的牺牲获得清洁数据的优良性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;规则&amp;nbsp;&lt;/span&gt;35: 注意在排序问题中的固有偏差（inherent skew）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;规则 36: 用位置特征避免反馈循环（feedback loops）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;规则 37: 测量训练/实际产品表现之间的偏差（Measure Training/Serving Skew）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器学习第三阶段：放慢速度、优化细化和复杂的模型&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;规则 38：如果出现目标不对齐的问题就不要在新的特征上浪费时间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;规则 39：决定不只是基于一个标准做出。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;规则 40：保证组件简单。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;规则 41： 性能达到高峰时，要寻找新的信息源加以补充，而不是精化现有的信号。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;规则 42：不要期望多样性、个性化或者与你所认为的流行性关联。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;规则 43：在不同的产品中你的伙伴可能倾向于同一个产品。而你的兴趣不是。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 18 Jan 2017 13:33:06 +0800</pubDate>
    </item>
    <item>
      <title>独家 | Jeff Dean 领衔，硅谷 AI Frontiers大会全程亮点回顾</title>
      <link>http://www.iwgc.cn/link/4376153</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;现场报道：Alex Chen，ChainnZ&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2016 年 3 月，AlphaGo 横空出世，举世哗然；2017 年 1 月，Master 再次横扫人类旗手，却已在大众意料之中。在过去的 2016 年里，以深度学习为首的机器学习技术引领的人工智能热潮迅速从学界和工业界扩散到了整个社会。大众对人工智能的不切实际的期待又达到了一个新的高度，仿佛只要使用深度学习一切就可以迎刃而解。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而对于真正的从业者来说，每天面对的真实问题则是，深度学习技术能否对当下问题提供解决方案；如何让深度学习与现有问题结合，真正帮助我们做出判断，如何结和深度学习优化现有的系统等等这类直接和现实的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2017 年 1 月 11-12 日首届人工智能前沿峰会（AI Frontiers）于美国加利福尼亚州「硅谷」中心圣克拉拉举行。这次大会邀请来自谷歌、 脸书、微软和亚马逊等人工智能前沿公司的顶级科学家，分享他们在人工智能研究及应用上的最新成果；谷歌和亚马逊团队在第二天的分会场举行了深度学习开发框架的实践课程；人工智能创业公司也在此这里聚集，分享自己的产品和想法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicdNiceoKXOr6okChjGPoaiaMppXz8IviaQzZhXKTEZiaGexo31ZuXl2eSCVic9xRZHw9OTE54fKEicShQw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicdNiceoKXOr6okChjGPoaiaMkTYzgm3xvkdxgLfkVicZXdcOzFRvNhwoJKicEatMkgWibBqWGBic2CSJWA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首届人工智能前沿峰会（AI Frontiers）阵容强大，与会者超过 1600 人，覆盖 15 个国家地区，人工智能巨头公司专家工程师云集；内容覆盖人工智能业界 6 大热门主题，直切前沿：自动驾驶、语音人工助手、自然语言处理、计算机视觉、物联网、和深度学习框架。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicdNiceoKXOr6okChjGPoaiaMdTE2qJ7tccLAZNqNBmrBcfjGsQHrUooslxy2jDZiaFf62tScgaqN6xQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;AI Frontiers 人工智能前沿大会不仅为世界各地的人工智能关注者提供了最尖端的人工智能知识分享，也把人工智能领域的巨头公司研发高管、研究科学家及工程师聚拢在一起，提供非常难得地一个平台，让大家面对面交流，分享了自己对人工智能的最新认识。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器之心作为本次大会首家华语媒体合作伙伴，对本次人工智能前沿峰会（AI&amp;nbsp;Frontiers）进行专题报道。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;Jeff Dean Keynote: 深度学习研究趋势与发展&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicdNiceoKXOr6okChjGPoaiaMsuyBsm3Fib4DmyVO8Drfop9J5Y24koMBtgmGbicEibqSnFLE0ibZOUY0og/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大会第一天，大会主席胡峻玲博士致开幕辞后，谷歌大脑负责人 Jeff Dean 进行了 Keynote 演讲。Jeff Dean 介绍了谷歌大脑团队的研究进展和成果，这些研究在谷歌产品线的应用，以及团队在开源工具方面的成果（&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722239&amp;amp;idx=1&amp;amp;sn=78a5256ec684e13c32a6fd4161c40470&amp;amp;chksm=871b0bc1b06c82d750c459feac8a3c22758aa20711adc33555e9b103fa3bad9b0849d8a9173a&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722239&amp;amp;idx=1&amp;amp;sn=78a5256ec684e13c32a6fd4161c40470&amp;amp;chksm=871b0bc1b06c82d750c459feac8a3c22758aa20711adc33555e9b103fa3bad9b0849d8a9173a&amp;amp;scene=21#wechat_redirect"&gt;谷歌博客于次日发布了相关内容的年度回顾&lt;/a&gt;）&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicdNiceoKXOr6okChjGPoaiaMlh5R8JKr4rO9cXGTyLXhu80kj2wsDJw2CtkRYcE0xLAOjvNyVvoTvg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;「工欲善其事，必先利其器」： TensorFlow&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;开发 TensorFlow 的初衷关键词：通用平台，最优质的，开放平台&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicdNiceoKXOr6okChjGPoaiaMVaJNcaXKwVibKvGbeVxsr7YLnGCjAIQeNhdYejg1xsAuVgWD3Z09ZyA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicdNiceoKXOr6okChjGPoaiaMmqN77VIuaMp7bvGgib4wSaiapnpVouuibic7ic8b9l3iagqn5kd7QOIVEJ9A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关于机器学习系统的设计，Jeff Dean 给出了以下 5 条设计思路：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;易于开发者表达其基于机器学习的想法和算法&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;可缩放性：可在短时间内迅速地进行试验，测试想法（并且实验结果可以良好地直接规模化）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;多平台兼容&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;易于进行重现及分享&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;易于产品化&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;基于以上设计思路，从 2015 年 11 月 TensorFlow 正式发布起，TensorFlow 逐渐得到发展和完善：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;多语言支持&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;性能提升&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;开发体验&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722208&amp;amp;idx=5&amp;amp;sn=392a6aa77f0f5eeb976636f4fe791cc7&amp;amp;chksm=871b0bdeb06c82c84cb811fa6e059b988f56249d027dbdcb5f28fe45a1167f27c1f1e1cd6de2&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722208&amp;amp;idx=5&amp;amp;sn=392a6aa77f0f5eeb976636f4fe791cc7&amp;amp;chksm=871b0bdeb06c82c84cb811fa6e059b988f56249d027dbdcb5f28fe45a1167f27c1f1e1cd6de2&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;近日发布的 TensorFlow1.0 版本&lt;/span&gt;&lt;/a&gt;&lt;span&gt;将在保证向下兼容的前提下，提高开发者体验，加强文档撰写、提供更多可以直接使用的库以及可用于协助开发者进行开发的模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此外 Jeff Dean 特别在现场介绍了 TensorFlow 基于 XLA (Accelerated Linear Algebra) 的即时编译（JIT Compilation )&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;深度学习于谷歌无所不在&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;基于 TensorFlow 或更早期的机器学习系统，谷歌成功地开发了大量的应用解决方案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Jeff Dean 列举了其中的一部分使用案例：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;谷歌语音识别通过使用深度循环神经网络减低超过 30% 地错误率&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicdNiceoKXOr6okChjGPoaiaM4uusicE1ibbPOKIsQ1wOzEhBPgGbuFkAWqlC6WaamyUMWW3k2UDOtvHQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;照片搜索通过使用深度卷积神经网络自动升成照片标签&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;从图片中标出文字，并进行识别&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicdNiceoKXOr6okChjGPoaiaM4ObtoyhgejwTsDYF7xQPSlfcibiaJic0tibBrQqhibqdVqkdAuWyZRo93Qw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;使用深度学习检测糖尿病性视网膜病变&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;机器学习在机器人上的应用&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicdNiceoKXOr6okChjGPoaiaMtaDmgeYL5QXLicbaqeoJ1EJZod95HNia3j7CSicibLVxMD7W3C55kic0PHA/0?wx_fmt=png"/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;更好的自然语言理解&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicdNiceoKXOr6okChjGPoaiaM6cb9KVjFxwaUjNAYykwGyjOYicg9qicT2KGibMticdtQPich3OZrIczjDVw/0?wx_fmt=png"/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;结合图像与语言&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicdNiceoKXOr6okChjGPoaiaM7GHYJdIWNQrQF5Kib7bUE2BmT3cWzQicjaCurWxAnlbGEAySviczmibeYw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;更好的「翻译」为「理解」铺路&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicdNiceoKXOr6okChjGPoaiaMgJdEow5Tt9C5Lndx3Diap7FM5iaAqN8mlgRQvcC3KeDicFKFbNU172odA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;将参数分布于多个分布式参数服务器上，数据+模型并行化：成功解决神经翻译机的规模化问题&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;对于深度学习在谷歌未来的发展，Jeff Dean 谈论了以下几个方面：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;更多地使用：迁移学习、Multi-task Learning 以及 Zero-Shot Learning&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大多数的任务都为了这个任务从头进行模型训练，这样在数据使用、计算资源以及人员使用上效率都非常低。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;对于更大的模型，使用自动机器学习&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;深度学习改变计算机架构设计（TPU 等其他计算架构）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 对减低精准度的容忍&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 增加常用的运算操作&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;无人驾驶&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicdNiceoKXOr6okChjGPoaiaM2Ev3OjzzxeR2FG5r5k4lyv25n7LNotBhlN4brdArBMVoLdiakPrJuNw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本次会议主办方邀请到来自谷歌 Waymo，特斯拉和百度无人驾驶的专家同台讨论。谷歌 Waymo 的技术经理贾兆寅分享了谷歌 Waymo 一步步的发展历程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Waymo 坚持 4 条做法：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 尽可能覆盖更多&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 创造简单的目标代表（create simple object representations)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 不要去试着理解其他人在做什么&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4. 避免视觉处理（因为还不够 robust 健壮）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;来自特斯拉的机器学习负责人谷俊丽也分享了她对无人驾驶的展望和对机器学习的观点。她认为交通工具的发展现在处于从数字化变成智能化的关键阶段，我们已经看到了智能化的曙光。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicdNiceoKXOr6okChjGPoaiaMmibzQb7a2lBoDx3oAytpNC5Ucycohicib0pIxyeUFEPMSZXbpW6E1mDzw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谈到传感器，谷俊丽表示输入混合信号的技术还不成熟，不同传感器通常是分开计算。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;接下来百度无人驾驶总监韩旭（Tony Han），首先他针对中国市场的特点表达了自己的看法，情况更多更复杂，但意义也非常重大，之后分享了关于百度无人驾驶的进展与测试视频。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在讨论环节中，主持人问嘉宾：「在深度学习中，计算能力越强数据越多效果往往越好，关于无人车计算能力的成本需要考虑吗？」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;两位嘉宾展现了不一样的看法。谷俊丽表示这应该不会成为一个问题，关键是对不同的数据采取不同的计算策略。如果这种计算策略得当，应该会有有效的解决方案。韩旭（Tony Han）则认为计算成本的问题迟早会解决，但目前我们无法忽视计算成本带来的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;语音助理&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicdNiceoKXOr6okChjGPoaiaMNZ1Uohr437gn6HRB0ppnc4AfXFBT7Ouh5wf2ob8OFb1rW8UYNZBVng/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;微软邓力：历经三代对话系统&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;来自微软 AI 的首席科学家邓力教授首先介绍了语音识别和字符识别的系统，是深度学习让对话系统（Dialogue System) 不局限于一个狭窄的领域，然后嘉宾回顾了对话系统近 30 年的发展与沿革，该部分内容可参考文章 ：http://venturebeat.com/2016/08/01/how-deep-reinforcement-learning-can-help-chatbots/。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;之后邓力教授介绍了三代聊天技术的不同特点：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一代系统是基于符号规则/Template 的系统，专注与语法但应用范围有限，所用的数据只是为了设计规则，不涉及学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二代系统是数据驱动，浅层学习，数据在这里是用来学习统计参数的工具。这种系统不利于及时与更新，同样局限于一定范围的应用。第二种方法参考文章：http://mi.eng.cam.ac.uk/~sjy/papers/ygtw13.pdf&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第三代系统同样为数据驱动，但结合了深度学习，使端到端的学习成为可能，不易解释但应用范围较广。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后邓力认为用自然语言理解（Natural Language Understanding）来模拟 Long-span Dependency 对语义和语法连贯性识别，在 ASR 领域很有潜力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;百度展示语音实力，亚马逊力推 Alexa&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该部分的第二位嘉宾是百度硅谷人工智能实验室总监 Adam Coates，Adam 主要介绍了让深度学习惠及 1 亿人的想法 – 让语音识别既多样又快捷：同传统的 ASR 方法相比，深度学习有很多优点，比如准确率高，利于扩大数据量等 ( Scaling )。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后一位嘉宾是来自亚马逊的资深首席科学家 Nikko Ström。Nikko 以「Jeff Dean 也用我们的产品是个巨大的胜利」轻松开场。Nikko 之后回顾了 Alexa 中深度学习技术的发展，以及巨大的存储与分布式训练模式，Alexa 的唤醒原理以及语义理解过程，并且介绍了有韵律地阅读内容。下一步 Alexa 的目标是更准确识别不同方向不同源头的音源，或者在两人对话过程中判断识别出两个人。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在之后的讨论环节，各位嘉宾关于聊天机器人取代手机应用的看法进行了探讨。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;邓力表示很多手机应用没有被使用过，通过手机接入网站的比例也非常低，这就给聊天机器人留下来空间。Adam 则表示顶尖的应用程序还会被保留，因为较好的视觉反馈会很有吸引力。Nikko 提到这就是他们做 Alexa 的目的之一，用户不需要下载，安装和调试任何应用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;机器之心将在之后对本部分分享内容进行更加详尽的重现报道。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWicdNiceoKXOr6okChjGPoaiaMgWLic5iaK8JytsPVXF7YTmsQticDGic4GPaicnm71BP7r8I7qpsyXvKPVpw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;谷歌大脑 Lukasz Kaiser：自然语音处理&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicdNiceoKXOr6okChjGPoaiaMnTnicSOJST8JqDglZIMWT0aQ3dE1aXPAs8pUkqRLXibar54EQfCSlYkg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大会第一天下午的第一位嘉宾是来自谷歌大脑高级研究科学家，NLP 专家 Lukasz Kaiser。Lukasz 分享了在多年实践后，他对深度学习与 NLP 的看法和经验。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先，Lukasz 明确了 NLP 具体需要处理哪些问题，比如语音标记，解析，语言模型等。在面对不一样大小且不断变化的输入输出，RNN 可以很好的起到作用，一种 Encoder-Decoder ( Sequence-to-sequence) 的构架应运而生（此处我们之后会有详细解读，尽情关注）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这种高级的 Sequence-to-sequence 的 LSTM 框架下，Lukasz 又举了具体例子来说明，各种场景均有应用且效果不错。最后 Lukasz 也指出了这种方法的局限性：速度慢和需要大量数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心将在之后对本部分分享内容进行更加详尽的重现报道。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;计算机视觉&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicdNiceoKXOr6okChjGPoaiaMtlcX7096NJpeucG09riat4oicwPCueVo0shSQbILBRqNErZJZBJWYiaRQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下午的第一个论坛是关于计算机视觉，大会邀请到了 OpenCV 的创始人兼首席执行官 Gary Bradski，Bosch 的首席科学家任骝和谷歌计算机视觉负责人 Jay Yagnik。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Gary 主要分享了 OpenCV 3+的最新情况，OpenCV 3+ 将会支持硬件加速，更好的校正，将利用 DNN 和 Tiny-DNN 技术。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二位嘉宾 Jay 主要介绍了机器理解的演进和未来，包括不同的应用场景如视频理解，手写识别等，以及深度学习在该领域的应用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;视觉部分最后一位嘉宾任骝主要介绍了传感器可意识的增强现实技术，该技术与机器学习配合可以让我们更好的处理人机接口（HMI）问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;麦肯锡自动化报告&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;之后登场的同样是一位重量级嘉宾——来自 McKinsey 的 MGI 总监，高级合伙人 James Manyika。他分享了关于 AI 对就业及市场驱动因素的影响：技术和经济会起到主导因素。对这份报告感兴趣的读者可以参考之前机器之心的&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722261&amp;amp;idx=2&amp;amp;sn=7fbbb28935dce4020d7c89b698551426&amp;amp;chksm=871b0babb06c82bd695f2ec64809f84133047702ffed713bddef9767c8e100b038c40d2b9730&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722261&amp;amp;idx=2&amp;amp;sn=7fbbb28935dce4020d7c89b698551426&amp;amp;chksm=871b0babb06c82bd695f2ec64809f84133047702ffed713bddef9767c8e100b038c40d2b9730&amp;amp;scene=21#wechat_redirect"&gt;相关报道&lt;/a&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWicdNiceoKXOr6okChjGPoaiaM6urEZsIhLZfsDjo5777boMeoFvILzjSoWXM2mQ5ulESgqWp5yOzkgg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;物联网： 人工智能硬件不能遗忘的 4S 机遇&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicdNiceoKXOr6okChjGPoaiaMic0S1eianpIlEMnSlmoicnaAG0WhS29NFtY7KeicGwnA4AchsHwfNEBjgA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面一组嘉宾是物联网方面的专家，包括来自 Bosch 的数据科学负责人 Mohak Shah，来自 Intel 的深度学习架构师 Andres Rodriguez 以及来自中国的企业——文安科技创始人及首席执行官陶海。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;来自 Bosch 的 Mohak 的讲座主要在于深度学习与物联网的结合。物联网的影响范围会越来越大，逐步渗透各个行业，但同时面临很多挑战，比如时间序列，不均一性，异步性等。深度学习技术可以给物联网领域带来很多机会，比如它的多功能性，便于训练与高度整合。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;来自 Intel 的 Andres 完整地介绍了一个公司需要采用人工智能解决方案的完整过程和可能遇到的问题。最后嘉宾也覆盖了 Intel Nervana 的特性和应用领域。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;物联网的最后一位嘉宾是北京文安的陶海, 他主要分享了文安的产品和最新技术，通过深度学习和计算机视觉的结合，通过嵌入式 CV 硬件，GPU，VPU 和 FPGA 的加速产生的一系列智能产品。在提高了处理速度的同时，增加了设备性能，同时针对不同场景设计了不同的硬件，并在国内外都取得了良好地市场反馈。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在之后的讨论环节，主持人首先问诸如 Bosch 这样的大公司会自己建造自己的深度学习应用还是通过世面上已有的程序库？Mohak 表示他既会关注需要的软件包，也会自己尝试解决问题，这个主要是根据问题本身决定。Andres 则说他们会利用一些开源的库来实现自己的目的。陶海表示他们使用 Caffe 和 TensorFlow，这主要基于两点考虑，分布式和支持丰富。下面一个问题是怎么在设备端训练数据？Andres 认为在设备端训练会有优势有劣势。优势是提高了性能，劣势是收集的数据不稳定造成影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器之心携手硒说对本版块进行了分析报道，感兴趣的读者可以阅读&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722261&amp;amp;idx=3&amp;amp;sn=d25bda87c40354ecd350d5a9c41ef10a&amp;amp;chksm=871b0babb06c82bd353d9820c5ab60a51e89f5bbe13339425508e396bf89c687ef0b792d1dff&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722261&amp;amp;idx=3&amp;amp;sn=d25bda87c40354ecd350d5a9c41ef10a&amp;amp;chksm=871b0babb06c82bd353d9820c5ab60a51e89f5bbe13339425508e396bf89c687ef0b792d1dff&amp;amp;scene=21#wechat_redirect"&gt;相关文章&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;谷歌、Facebook、亚马逊研发负责人同台共议深度学习框架&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicdNiceoKXOr6okChjGPoaiaMvhWyA3MByyzQM1ghwibg89jFjHsMKClicvDfn5icWsSDGORtM69IXbFYA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本板块嘉宾包括谷歌工程技术总监 Rajat Monga，Caffe 作者、Facebook 研究科学家贾扬清，来自亚马逊机器学习团队负责人的 Alex Smola 和来自 Facebook 的研究工程师 Soumith Chintala。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先 Rajat 回顾总结了深度学习的发展，并介绍了 TensorFlow 的基本构架和具体实现实例。Rajat 提到，随着深度学习的复杂性提高，出现数据包成为大势所趋。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;贾扬清以 Caffe 的设计为载体，分享了如何设计深度学习框架——一个好的深度学习框架具有以下几个特征：可拓展性，便携性，增强的数值类型，可移动性。随后贾扬清对 Caffe 和 Torch 进行了对比。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;亚马逊机器学习总监 Alex Smola 首先深入浅出地讲解了编译环境中函数性质不同带来的优缺点：优点在于直接和灵活，缺点在与该系统很难优化；随后 Alex 介绍了 MXNet 强大的兼容性和分布式深度学习性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本板块最后一位嘉宾，来自 Facebook 的 Soumith Chintala 介绍了 Torch 可以应用的种种场景以及核心逻辑，并为后来的深度学习培训做了铺垫，最后还展望了下一代深度学习构架的特点，比如支持各种科学计算，动态的神经网络等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;机器之心将在之后对本部分分享内容进行更加详尽的重现报道。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;a16z 合伙人 Frank Chan Keynote：人工智能的未来，降低成本与市场影响&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicdNiceoKXOr6okChjGPoaiaMBjA0UzAEHz8EBGKvhgdvWhrC89hw5HI4UGZx8KtrAjKf3gibYia3UEew/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;晚宴期间，大会请到了来自硅谷著名风投 Andreessen Horowitz（a16z）的合伙人 Frank Chan。Frank 解读了人工智能将大幅度降低成本的重要领域，以及可能将带来的市场影响。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;演讲重点了覆盖以下领域：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;自动驾驶和飞行&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;理解物理世界中的物件和形式&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;内容生产&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;预测未来&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;自动优化复杂系统&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;理解&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;机器之心将在之后对本部分分享内容进行更加详尽的解读报道。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心原创，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 17 Jan 2017 16:38:52 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 百度宣布原微软高管陆奇加盟，任总裁兼COO</title>
      <link>http://www.iwgc.cn/link/4376154</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心报道&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;编辑：李泽南&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;百度于今日宣布，正式任命陆奇博士担任百度集团总裁兼首席运营官（COO）。据称，陆奇将主要负责百度的产品、技术、销售及市场运营。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWicdNiceoKXOr6okChjGPoaiaMb2icx5533VHYLKz3Lib9J09HU5zjaHTrAX29dbzxvKK0tTUSBiaricutpw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;百度发言人称，集团现有的各业务群组及负责人都将直接向陆奇汇报工作，包括搜索公司总裁向海龙、技术体系和新兴业务群组总裁张亚勤、高级副总裁朱光携金融业务群组、高级副总裁王劲携无人驾驶事业部和首席科学家吴恩达带领的人工智能技术团队，而陆奇将向百度集团 CEO 李彦宏直接汇报。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对此，百度 CEO 李彦宏表示：「我非常高兴能够邀请陆奇博士加盟百度，陆奇是在全球科技界都享有盛誉的杰出管理人才，也曾是美国科技巨头中职位最高的华人高管。他拥有丰富的管理经验、出色地技术洞察力和卓越的团队领导力。同时，陆奇还是人工智能领域世界级的技术权威。我相信陆奇的加盟将极大地提升百度的综合管理水平和技术实力，他将和现有团队一起把百度从一家优秀的中国公司提升为一家卓越的世界级公司。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「百度已经决定将人工智能列为公司未来十年最重要的战略方向，而要落地这一战略就需要不断吸引世界级的一流人才，陆奇的加盟将极大地确保这一战略得以顺利实现，帮助百度在人工智能时代奠定全球领先地位、成为令中国人为之骄傲的世界级高科技公司。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在加入百度之前，陆奇曾担任微软集团全球执行副总裁，他于 2016 年 9 月底从微软离职。在微软，接替陆奇职位的是原先负责 Outlook 和 Office 365 团队的全球资深副总裁 Rajesh Jha。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在宣布任命时，陆奇表示：「我很高兴能够受李彦宏的邀请加盟百度，李彦宏将人工智能定为百度未来十年最重要的战略方向是极富远见且非常正确的决定，对于承担具体管理、执行和落实这一战略的重要职责，我深感责任重大。同时对于有机会帮助百度成为人工智能时代的世界级科技巨头，我感到非常兴奋！」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;从上海到硅谷&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;陆奇现年 55 岁，毕业于复旦大学，获计算机科学学士、硕士学位，并于 1992 年赴美国卡耐基梅隆大学攻读计算机科学博士学位，师从 Nico Habermann、Mahadev Satyanarayanan 等人，他在 1996 年毕业&lt;/span&gt;&lt;span&gt;，博士论文题目为《Improving Data Consistency in Mobile File Access Using Isolation-Only Transactions》。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;毕业后，陆奇成为了 IBM Almaden 研究所的一员，随后很快加入了雅虎公司，并于 2007 年被晋升为雅虎执行副总裁。2008 年 8 月，陆奇离开雅虎，并于次年 1 月正式加盟微软担任网络服务集团总裁，2013 年出任微软集团全球执行副总裁。在微软工作期间，他领导了包括 Microsoft Office、Office365、SharePoint、Exchange、Yammer、Lync、Skype、Bing 搜索、Bing 应用、MSN 及广告平台在内的多项业务，是大陆华人在全球科技公司总部所任职位的最高级别。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;低调离职微软&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2016 年 9 月 30 日，有消息称，微软全球执行副总裁陆奇即将从微软离职。陆奇此前在自行车运动中受伤，伤情一直没有好转。尽管微软没有正式回应，但并未对「陆奇离职」的消息并未进行否认。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;据称，导致陆奇离职的是几个月前一次自行车事故，他在那次事故中摔伤了自己的腿部，在接下来几个月中一边工作，一边先后在美国、台湾等地进行治疗。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;陆奇上一次在国内的公开露面需要追溯到 2016 年 8 月 5 日，微软人工智能应用「小冰」第四代的发布会。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;陆奇的离职对微软的领导层产生不小的影响。他离职前掌管的 Office 业务是微软最为重要的收入来源，在微软时，陆奇直接向 CEO 纳德拉汇报。同时他还负责微软人工智能应用「小冰」团队的管理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了填补陆奇留下的空缺，微软除了提拔 Rajesh Jha 以外，也将「小冰」团队暂时交给微软全球执行副总裁、技术与研发部门主管沈向洋主管。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前，将重点转向人工智能的百度市值约为 612 亿美元，与国内领跑的阿里巴巴（2407 亿美元）、腾讯（2422 亿美元）之间的距离正在逐渐被拉大。随着最近百度的一系列人事和机构新动作，相信在 2017 年，这家科技企业将会对后两者发起新的挑战。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心发布，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 17 Jan 2017 16:38:52 +0800</pubDate>
    </item>
    <item>
      <title>深度 | 经济学人特别报道：人工智能和自动化时代需要怎样的教育</title>
      <link>http://www.iwgc.cn/link/4376155</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自The Economist&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;2016 年 6 月，《经济学人》专题报道了人工智能进步对社会可能产生的巨大影响（&lt;/span&gt;&lt;/em&gt;&lt;em&gt;&lt;span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716375&amp;amp;idx=1&amp;amp;sn=b4eaa0e0bcdfaf7b2d47ab95e91c1358&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716375&amp;amp;idx=1&amp;amp;sn=b4eaa0e0bcdfaf7b2d47ab95e91c1358&amp;amp;scene=21#wechat_redirect"&gt;《经济学人》封面报道：从技术、就业、教育、政策、道德五大维度剖析人工智能&lt;/a&gt;）。2017 年伊始，《经济学人》再度指出，和工业革命一样，人工智能和自动化时代需要另一场教育革命并对新的教育模式、当前现状及其存在的严重问题进行了深入剖析。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;《特别报告：终身学习》的深度分析共包括六个部分：（1）学习和挣钱：终身学习具有经济上的紧迫性；（2）认知变换：为了鼓励员工接受再教育，雇主可以做些什么；（3）旧瓶新酒：年长的雇员如何在单位大展拳脚；（4）MOOC 的回归：现有的教育提供商 vs 新的竞争者；（5）必由之路：将条件转变成工作；（6）显而易见的问题：低技能工人的再教育。机器之心对全部内容进行了有删减的编译。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;引言：终身学习，知易行难&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当教育的步伐跟不上技术发展，就会产生不公平。创新到来之际，工人没有「被利用的价值」就会遭殃——如果这些工人被技术革新远远抛在后面，社会就会分崩离析。这一洞见从根本上影响了工业革命的改革者们，也推动了国家资助全民基础教育。接下来，工厂和办公室自动化引发了大学生人数猛增。历经数十年，教育和创新共同推动人类社会走向繁荣。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今天，机器人和人工智能召唤者另一场教育革命。不过，这一次，工作生涯如此漫长而且变化迅速，只在人生初期强加更多教育是不够的。获取新技能必须贯穿人们的整个职业生涯。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不幸的是，正如我们本期特别报道所述，今天，终身学习的受益方主要是成功人士，而这更可能加剧不平等而不是减少。21 世纪经济体不想要产生一个庞大的底层阶级的话，政策制定者亟需制定措施，帮助国民边谋生边学习。迄今为止，他们的抱负小得可怜。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;传统教育模式——人生初期集中学习，之后公司培训加以补充——正在瓦解。原因之一是需要新的、不断更新的技能。制造业越来越多地需要脑力而非蛮力。与此同时，在职培训也在萎缩。市场正在创新以让工人能够有新方法学习和赚钱。报告谈到的那些革新展示了工作与学习如何交织在一起。然而任其自行发展，这一新生市场将会主要服务于那些已经具备优势的人。如果新的学习方式是要帮助那些最需要帮助的人，则政策制定者应该瞄准远为根本的举措。19 和 20 世纪见证了教育的令人震惊进步。今天的抱负应当不逊于当年。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;一、学习与挣钱：终身学习变得具有经济上的急迫性&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Andrew Palmer 说道：技术变迁将会要求教育和就业间更加紧密和连续的关系。这样一个系统的大纲正逐渐露出水面。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;游客正在接待区等待一部已退役的地铁车厢来接他们。每一个房间，主题是分别关于代码、网页发展和数据科学。第一眼看上去，General Assembly 的办公室和其他任何一所技术型创业公司没什么两样。但是有一点非常不同：绝大多数公司使用技术来在线出售他们的产品，然而 General Assembly 通过物理世界来教导技术。办公室同时也是一个校园。教室里充满了学习和实践代码的学生，他们中的绝大多数为来到这里已经放弃了工作。全日制参与者要支付 8000-10000 英镑（9900-12400 美元）来学习为期 10-12 周的数字经济通用语。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从西雅图到悉尼，General Assembly 在 20 个城市的校园里拥有接近 35000 毕业生。注册成为全日制学生的人员大多数都希望他们能展开新的职业生涯。公司的课程表是基于和雇主讨论他们极其缺乏的技能的谈话的基础上制定的。General Assembly 会举办「遇见、招聘」大会，在这里，公司能够看到代表大会的学生完成编程工作。置业顾问帮助指出学生展示的不足之处和提高他们的面试技巧。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;General Assembly 通过有多少毕业生在他们渴望的领域里获得了一个有薪水的永久的全日制工作来测量它的成功。在 2014-2015 年度，有四分之三的学生使用了公司的职业建议服务，其中 99% 在开始寻找工作的 180 天内就求职成功。公司创始人 Jake Schwartz 当初创立公司，是被两次个人经历所启发的。一个是根本没有赋予实际技能的耶鲁学位，还有一个两年的 MBA 学位，他感觉到花费了太多的时间和精力：「我想要通过降低学费和提供雇主迫切渴望的技能来改变教育行业的投资回报方程。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在富裕的国家里，学习和赚钱的联系似乎遵循着一个简单的规则：青少年应该尽可能多的获得正式教育，这样，在剩余的职业生涯中就可以收获对应的奖励。文献表明每一年额外的学校教育会带来每小时 8-13% 的收入增长。自从经济危机以来，提前辍学的代价越来越清晰。在美国，随着教育稳步提高，失业率也在稳步下降。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有许多人相信技术变化只能加强正式教育。容易就能被自动化取代的日常工作已渐渐消失。这种观察的另一面是需要更多认知能力的工作正在增长。劳动力市场正在分流，而有大学毕业证书的毕业生将很自然的转向更高薪水的工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而现实看起来是更加复杂。教育的回报，即使对于高技能工作者来说，也已变得不那么清晰。根据纽约联邦储备观察，1982-2001 年间，拥有学士学位的美国工人的平均工资上涨了 31%，然而对于只有高中学历的人来说，平均工资一点也没动。但是在接下来的 12 年，大学毕业生的工资下降率超过了学历没有他们高的同龄人。与此同时，大学学费还在不断增长。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于绝大多数人来说，决定去上大学依然很有道理，但是有关教育和工资间机械关系的想法被打破了。由皮尤研究中心做的一个最近调查显示：将近 16% 的美国人认为在现代经济中，四年的大学生涯已让学生为高薪水工作做好准备。这种想法一部分是由经济危机的周期性影响和其余波导致的。这其中也可能仅是供给问题：随着更多人有了大学学历，相应优质工作就会减少。但是技术又似乎给未来蒙上了一层纱。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2013 年由加拿大经济学家三人组——Paul Beaudry，David Green 和 Benjamin Sand 共同发表的一篇文章质疑了对非常规工作需求的乐观估计。作者说，在 2000 年之前的 20 年，作为 IT 时代建立的基本设施（计算机、服务器、基站和光纤电缆），对认知技能的需求如日中天。现在既然技术已经大部分安排妥当，此类职业也衰落了。他们的调查显示从 2000 年起，美国高技能工作的占比就一直在下滑。现在，大学毕业的求职者不得不从事对认知技能要求较少的工作，替代教育程度不高的工人。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这项分析证实了技术会颠覆就业这一观点。熟练和不熟练的工人都陷入了麻烦。虽然受教育程度高的人更可能找到工作，不过现在有了公平的机会，这让人感到不太愉快。那些从未上过大学的人都被挤出了职场。这是技术悲观主义者的论点，牛津大学的 Carl-Benedikt Frey 和 Michael Osborne 的预测体现了这一点，他们曾在 2013 年计算出 47％的美国现有工作容易受到自动化技术的影响的著名结论。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里还有另一个不那么具有决定性的可能。波士顿大学经济学家 James Bessen 研究了自动化技术对特定职业的影响，发现自 1980 年以来，使用计算机的职业的就业增长速度快于不使用计算机的职业。这是因为自动化技术倾向于影响职业内的任务，而不是完全消除对应的岗位。部分自动化实际上可以通过降低成本来增加需求：例如，尽管在超市中和在银行中的 ATM 中引入了条形码扫描器，但是出纳员和银行柜员的数量却增加了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但即使技术不会在总体上毁灭工作，它也会迫使许多人做出改变。从 1996 至 2015 年，在日常办公工作中雇用的美国劳动力的比例从 25.5％下降到 21％，减少了 700 万个工作岗位。根据麻省理工学院（MIT）的 Pascual Restrepo 的研究，2007-08 年的金融危机使情况变得更糟：2007 至 2015 年，非熟练日常工作的工作机会相比其他工作下降了 55％。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在许多职业中，获得新技能变得至关重要，因为现有的许多东西都已经过时了。Burning Glass Technologies 是一家波士顿的创业公司，它通过从在线招聘广告中提取数据来分析劳动力市场，发现需求最多的是技能的新组合——该公司的老板 Matt Sigelman 称之为「混合型工作」。例如，编程技能现在的需求量远远超过其他技术部门。在美国，薪酬前四分之一高的职业中有 49％的职位是动辄要求编程技能的工作。新工作的组成也在迅速变化。在过去五年中，对数据分析师的需求增长了 372％; 在该部门内，对数据可视化技能的需求激增了 2574％。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在职业生涯的开始，大学文凭并不能迎合持续获取新技能的需要，尤其是职业持续时间更长的时候。职业培训善于教会人们特定工作的技能，但这些技能也需要在持续几十年的职业生涯中反复更新。由多数富裕国家加入的经合组织（OECD）的教育主管 Andreas Schleicher 说，「德国经常因其学徒制而受到赞扬，但其经济却未能适应知识经济。职业培训有一定的作用，但是训练一个人早一点去做一件持续终生的事情并不是终身学习的答案」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种特定的专门知识意味着在工作中需要它，但是雇主似乎变得不那么愿意投资培训他们的工作人员。美国经济顾问委员会在总统的「2015 年经济报告」中发现，在 1996 至 2008 年间，接受有报酬培训或在职培训的工作者的比例稳步下降。在英国，工人平均接受的培训在 1997 年至 2009 年间几乎减少了一半，每周只有 0.69 小时。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;也许雇主自己不知道他们需要什么样的专业知识。但也可能是，当有压力的时候，培训预算特别容易被削减。劳动力市场模式的变化也可能发挥作用：企业现在拥有更广泛的选择来完成工作，从自动化技术和外包到使用自雇者和众包。就业咨询公司 Manpower 的老板 Jonas Prizing 说：「组织已经从创造人才转向消费工作（consuming work）」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;总结以上，我们可以发现，时代对各种各样的工作者都更加艰难了。大学学位仍然是许多工作的先决条件，不过如果没有足够经验的话，雇主已经不会以学位作为雇佣工作者的充分条件了。公司的许多职员面临着他们的技能将要过时的未来，但是获得新的技能的途径却通常难以找到。「现在，要求营销专业人员具有开发算法的能力是合理的，」Sigelman 先生说，「但是营销的线性职业不能提供获得这些技能的机会」。现在越来越多的人成为了自雇者。在美国，临时工、承包商和自由职业者在劳动力中的比例已经从 2005 年的 10.1％上升到了 2015 年的 15.8％。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;持续学习阵营&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;答案看起来很明显。为了保持竞争力，并为低技术工人和高技能工人都提供最好的通向成功的机会，经济需要在人们的工作生活中提供培训和以职业为重点的教育。这份特别报告将列出人们为以新的方式连接教育和就业做出的努力；人们主要通过平缓成为劳动力的开始和使人们能够在他们的职业生涯中学习新的技能这两种方式来达成这一目标。许多这些提议还处于初级阶段，但它们也提供了对未来的一些预测和关于由终身学习新技能引起的问题的指导。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;许多东西已经确实的发生了。比如 General Assembly 只是编程训练营（coding-bootcamp）的提供者之一。由 Coursera 和 Udacity 等公司在十年前提供、在近几年大肆宣传的大规模开放在线课程（MOOC），已经采用了新的以就业为重点的业务模式。LinkedIn 是一个专业的网站，于 2015 年购买了在线培训业务 Lynda，现在正通过名为 LinkedIn Learning 的服务提供课程。Pluralsight 有一个按需培训视频库，并且是一家独角兽公司。亚马逊的云计算部门也有一个教育机构。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大学正在更加积极地接受在线和模块化学习。像新加坡这样的地方正在大力投资，为他们的公民提供可以在他们的工作生活中使用的学习贷款。个人也越来越似乎接受继续持续学习的需要。根据皮尤的调查，54％的美国工人认为，在他们的工作生活中发展新技能是至关重要的；这个比例在 30 岁以下的成年人中则达到 61％。Manpower 在 2016 年进行的另一项调查发现，93％的千禧一代愿意将自己的钱用于进一步的培训。与此同时，雇主也越来越重视学习本身这一技能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;二、认知转换：雇主能做些什么来鼓励员工进行再教育&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Infosys 在 Palo Alto 的办公室里有一间摆满扶手椅、抽屉柜、桌子等古董家具的奇怪房间。衣架上挂着粗花呢夹克，一架快报废的钢琴。房间结构粗糙，好像未完成。据 Sanjay Rajagopalan 所说，这才是重点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Rajagopalan 先生是印度商业服务公司设计研发的负责人。他是「设计思维（design thinking）」的信徒，这是一种根植于观察成功创新者的问题解决方法论。他的目标雄心勃勃：把一家按照客户要求建立全球外包业务的公司转变为一个可以为自己的项目设置条款的公司。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;设计思路强调在整个计划中的行动并鼓励大家以受影响者的眼光看待问题。大约有 100000 名员工已经通过了一系列的 workshop。第一个 workshop 为参与者设定了一个任务：例如改善数码摄影的体验。这就需要把思路从制作一个更好的相机的想法调整到考虑为什么人们首先看重照片，因为这是扑捉记忆的一种方式。随着思路的延伸，参与 workshop 的人们立即开始用简单的材料如纸板和纸生产相机原型。「当下流行的趋势是在做之前就计划好所有的细节，」Rajagopalan 先生说，「而我们的方法是先做，然后测试，之后才是计划。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 Palo Alto，奇怪的结构是另一个教学工具。Rajagopalan 先生让一个小团队重新构想数字零售经验。不是再建一个电子商务网站，而是他们在用多种技术试验一个物理空间。（比如说一个疲倦的购物者坐在椅子上，邻桌上的一壶茶就会自动烧起来。）在公司的办公室里的商店原型结构是有记录的，员工可以看到设计思想一步步的实施。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Infosys 正在解决一个非常重要的问题：人们需要怎样才能在工作中取得成功？无论是什么工作，答案总是基于特定行业的知识和经验，涉及一些技术上的和具体的技能。但是有了设计思路，Infosys 正在专注于「基本的技术」（比如创新性，问题解决和同理心）。当机器能让人类在执行日常工作任务时感到羞愧时，就应该考虑掌握一些计算机很难学会的技能了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;哈佛大学的 David Deming 发现劳动力市场提供一些需要社交技能的人。自 1980 年起，在有薪资层次上的就业和收入的的增长速度最快的行业在社会技能方面的溢价很高（见图表）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;社交技能对很多工作都很重要，不仅仅是医疗护工、治疗师和其他需要与客户接近的工作。Deming 先生认为主要价值在于同事之间的关系：那些能快速有效地划分任务的人能形成更有效率的团队。如果未来的工作越来越多地由承包人和自由职业者完成，那么合作能力将变得更加重要。即便是极客也需要学习这些技巧。Ryan Roslansky 负责 LinkedIn 的在线教育，他注意到许多软件工程师正在他们的网站上学习管理和沟通课程来提升自己的全面技能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;打造一个更好的学习者&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;发现并保住饭碗的另一个越来越重要的技能是不停地学习。当技术正在以一种无法预测的方式改变，工作变得富有交叉性时，人类就需要能学习掌握新技能。在 Infosys，Rajagopalan 强调「学习速率（learning velocity）」，在几天或几周内从一个问题变成一个好想法的过程。Alphabet 目前的执行总裁 Eric Schmidt 谈到谷歌的招聘重点放在了「学习动物（learning animal）」上。Facebook 的创始人 Mark Zuckerberg 每年都会为自己设下一个新的学习目标。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;强调学习一直是 United Technologies（UTC）的一个标志，这是一家企业集团，旗下业务包括飞机发动机制造商普惠公司（Pratt &amp;amp; Whitney）和电梯制造商奥的斯（Otis）。1996 起，UTC 启动了一项学习计划，旗下员工可以其中获得一个业余学位，并为他们提供每年高达 12000 美元的学费，没有任何附加条件。雇主往往不愿给员工做培训，怕他们技术提升后，离职去竞争对手公司。但该公司的人力资源副总裁 Gail Jackson 有不同的观点。「我们希望招来有求知欲的人，」她说。「给他们培训让其变得更好总比没有培训让他们留下的好。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种观点变得越来越常见。当 Satya Nadella 2014 年掌管微软时，他借助斯坦福大学心理学教授 Carol Dweck 的作品来推动公司文化朝新方向发展。Dweck 女士将学生划分为两大阵营：认为能力是天生且不可改变的人（需要给其学习动机）和认为能力是可以通过学习提升的人。这种「增长心态（growth mindset）」是公司试图鼓励的。微软已修订其业绩审查标准，包括评估员工如何学习他人然后应用知识。微软还建立了一个内部的门户网站，整合了通过 LinkedIn 购买的培训供应商（微软自己也在购买）Lynda。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;电信和媒体公司 AT&amp;amp;T 拥有大约 300000 名员工，这家公司面临着两大劳动力问题：在大数据和云计算时代的背景下快速更新技能的需求，不断的员工流失使公司不得不每年填补 50000 个职位。从外部招聘很难很贵，而且极易招致现有员工的不满。这家公司的方法是对现有员工进行培训。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;每个员工都有自己的职业简介，里面包括他们的技能和经历过的培训。他们还可以访问一个名为「职业智能（career intelligence）」的数据库，向他们展示公司内部所提供的工作及相应的技能需求和薪资水平。该公司还与 Udacity 合作开了一个短期课程，同时正在与多所大学一起开发课程。员工利用自己的时间开发自己的技能。但 AT&amp;amp;T 用「胡萝卜加大棒」策略来鼓励他们，给那些积极参与课程的员工慷慨地赞助学费（2015 年共计 3000 万美元），同时对于那些没有兴趣的员工给予负面评价。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随着持续学习成为公司的优先事项，出现了两个问题。第一个是，公司是否有可能根据好奇心（心理学家称之为「认知需求」）来筛选候选人和员工？上大学是一种非常粗糙的获得基本技能的途径，这解释了为什么那么多雇主要求学历，而事实上这份工作不需要这些。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;越来越好奇&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;更多由数据驱动的方式也正在被尝试。Manpower 是 一个人力资源咨询公司，正在一个 app 应用上运行自己的试验，这个 app 可以对个人的学习能力打分。Knack 是另外一家初创公司，提供一系列实际上是游戏化了的心理测试 app。而在 Dashi Dash，参与者扮演服务生的角色，然后根据顾客的表情（通常非常难懂）来给顾客下单。随着越来越多的顾客的出现，管理工作流程的工作变得越来越难。每一个决定和每分钟的决策改变都会被捕获到并以数据点的形式传到云端，通过云端数据里对 2 万 5 千人的数据参考，机器学习的算法开始分析玩家的能力。具备读取顾客表情的能力将会在同理心方面获取相应的加分；一个按照顾客进店先后顺序来招待顾客的决策将会是诚信品格的一个指向标。好奇心是 Knack 测试的特质之一。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二个问题是，有没有可能做到训练人去学习。成像技术正在帮助我们揭开好奇心比较强的人的脑内活动情况之谜。在神经科学期刊 Neuron 2014 年发表的一项研究中，参与者首先被要求给自己在学习不同问题解答上的好奇心程度打分。随后，那些所要学习的问题的解答将会展示给参与者，同时展示给参与者的还有一张陌生人的脸部照片；最后参与者要完成一个对答案内容回顾的测试和一个脸部识别测试。好奇心较强的参与者在这两个测试上，对内容的记忆保持较好，脑部扫描的结果显示他们中脑边缘多巴胺系统的活动更频繁，中脑边缘多巴胺系统是一个奖励通路。同时海马体的活动也更频繁，海马体是一个形成新记忆的关键区。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;想知道人的特质（类如好奇心）能不能通过教导而习得现在还为时尚早。但是目前通过让个体对自己的思考过程更关注从而让其变成更有效的学习者是越来越容易了。随着网络教育的兴起，关于什么在教育和学习中起到作用的假说变得越来越容易检测。MIT 已经率先提出了一个研究计划，这个计划是对学习机制的跨学科研究并将研究成果用于自己的教学中，包括线上和线下的教学。MIT 有自己的线上学习平台，包括一个同哈佛共建的 MOOC 平台——edX，可以为这项研究提供试验环境。当 MOOC 的学习者被要求写下所参与的某个课程的学习计划时，他们将比另外一个对照组成员有 29% 的比率更可能完成所参与的课程学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有关有效学习策略的信息也可以个性化。Open University，一个英国远程学习机构，已经使用控制板来管理每个学生个体的线上行为和表现。Knewton，这个机构的学习平台已经获取了 1 千万当前美国学生的数据，然后向学生推荐个性化的学习内容。个性化的内容推荐以帮助人们更多的关注自己的思考过程，从而使他们更有可能能够学习到他们后面所需的新技能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;三、旧瓶装新酒：年长的雇员如何在单位大展拳脚&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人们处理信息的速度从 20 多岁开始就稳步下降。你的认知能力可能已经在减弱。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;处理速度最常见的测试是「数字符号替换测试（digit symbol substitution test）」，其中一系列符号与代码中的一组数字配对。将代码展示给参与者，并给他们一排符号，然后要求他们在一个设定的时间内写下相应的数字。没有什么认知挑战性的任务；教育程度对绩效没有影响。但年龄有影响。随着年龄的增长，配对速度持续下降。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于这种机制的解释目前还停留在假设层面，但是，人们已经提出不少实验性的解释。有观点将原因指向了髓磷脂，一种覆盖轴突（负责将信号从一个神经元传给另一个神经元）的脂肪物质。随着年龄的增长，髓磷脂的稳定减少可能会让这些链接速度慢下来。另一种解释认为这与多巴胺减少有关。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;幸运的是，年龄的增长有利有弊。心理学家区分了「流动智力（fluid intelligence）」，大致等同于人类解决新问题的能力，以及「晶体化智力（crystallised intelligence）」，大致等同于个体的知识储量。知识储量会随着年龄的增长继续递增：在词汇、通识测试（general-knowledge）中，人类表现会持续提升，直到 70 多岁。而且经验常常能抵消认知能力的下降。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于终身学习，所有这些意味着什么？只要人们在熟悉的领域中学习新知识，这就会很棒。不过，如果年长的工人尝试全新知识领域，进展可能就不会顺利。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;四、MOOC 的回归：过去的教育提供商 v. 新的竞争者&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;MOOC 的热潮高峰出现在 2012 年，投资分析师 Salman Khan 通过互联网给他的表弟教授的小规模课程最终变成了广受欢迎的教育资源——可汗学院（Khan Academy），那年他登上了《福布斯》的封面。另一家 MOOC 提供商 Udacity 的创始人 Sebastian Thrun 则在《连线》上预言未来 50 年内，全世界的大学数量将会降至仅仅 10 所。《纽约时报》则将那一年称为 MOOC 的一年。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;蜂拥而来的学习者似乎预示着一种全新的开放式教育方式即将兴起，但现在 MOOC 的怀疑者却超过了信徒。尽管现在仍然还有很多人注册 MOOC，但辍学率也高得惊人。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicdNiceoKXOr6okChjGPoaiaMQKVE4hicwuKVB90vttzktm7BRicf5MJOzvkoicCp41bPic8egict7J93JPA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前，可汗学院每个月有大约 1400 万到 1500 万用户至少会进行一项学习活动；Coursera 有 2200 万注册用户。这些数字还在增长。英国 Open University 所有的 MOOC 则还有大计划。牛津大学在去年 11 月份宣布将在 edX 平台上推出其第一个 MOOC。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在商业模式上（尽管可汗学院等一些是非营利的），比如，Udacity 推出了一些以技术为核心的纳米学位（nanodegree），范围从基础一直到前沿。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Coursera 的内容大多来自大学，而非专家导师；其涵盖的范围也广得多；而且其还提供完全学位以及短期课程。Coursera 也有一些收费项目（发布认证等等）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前还处于非常早期的阶段。Coursera 并未公布其付费学习者的人数；Udacity 则表示其纳米学位参与者有 13000 人。但不管数据如何，重新发明的 MOOC 总归帮助学习者的继续教育解决了两个问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一是学习的成本——不只是金钱成本，而且还包括时间成本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;二是能为人们提供快速反应的能力。现在的技术发展速度如此之快，教育系统必须做出快速反应才能培养出社会所需的人才。MOOC 凭借高度的灵活性也许就能够为这种需求提供帮助。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;密歇根大学 Ross 商学院的院长 Scott DeRue 将教育和音乐这个行业进行了比较。在 iTunes 和流媒体服务出现之前，音乐是以唱片的形式销售的。而对比教育行业，学位就相当于唱片，MOOC 上的免费课程内容就相当于免费的流媒体音乐服务，而纳米学位这样的「微认证（microcredential）」就像是 iTunes 上的付费单曲。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大学应该对此做出怎样的回应呢？DeRue 再次使用了音乐行业这个比较。面对互联网所带来的颠覆，大学教育将会变成现场演唱会，将能提供网络课程所不能提供的独特优质体验。从学校获得的学位将成为这种优质经历的象征。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大学也可以让他们的教育资源更容易通过网络获取。这正在开始发生。当乔治亚理工决定以低成本提供其计算机科学硕士课程的在线版本时，很多人都惊呆了：这似乎会有损于其学校课程。但据学习该课程的哈佛大学的 Joshua Goodman 说，这个决定是正确的。校园课程仍将继续吸引 20 岁出头的学生，而网络课程则能吸引到无法离开工作岗位的 30 几岁的职场人士。Goodman 估计这个课程能每年将美国计算机科学新硕士的数量提升 7% 到 8%。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;教育的乐高&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大学也可以变得更加的模块化。EdX 的供应链管理课有一个微硕士学位，这个课可以作为单独学习的课程，同时也纳入 MIT 硕士学习课程之中。威斯康辛麦迪孙大学已经构建了一个名为 University Learning Store 的网站，这个网站提供实用学科（例如项目管理和商业写作）的线上学习内容。热心家们在讨论一个「证书堆叠」的世界，也即资格证书就像乐高的基本模块一样能够被组装在一起。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是，大学在朝着这个方向发展的道路上能走多远和多快还不可知。学位目前还是被高度重视，并且批判性思考和社交技能将在更多的地方显示出自身价值的观点越来越得到重视。「大学的校园、终身教职机制等等对短期课程没有作用，」Jake Schwartz 补充说到，他是 General Assembly 的老板。「覆盖固定成本的经济因素促使他们在这个方向上走的更久。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;教育机构同时努力去提供非常快速更新的内容。Pluralsight 用一个类似于书籍出版的模型，通过 1000 个专家组成的网络来生产和更新其 IT 和创造技能视频库的内容。这些专家根据他们内容被观看的频率来获得相应的版税；Pluralsight 上去年收益最高的专家赚取了 2 百万美金，这一数据来源于这家公司老板 Aaron Skonnard。这样的回报对网站视频内容的生产者持续更新他们的内容是一个极大的鼓舞。大学的院系制度有其他优势。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除了成本，MOOC 面临的第二个问题是认证的问题。现代劳动力市场广泛地通过学位和职业证书来了解一个人的技能和专业知识。MOOC 则希望通过微学位的方式来解决这个问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但雇主需要相信这些认证是可靠的。LinkedIn 想出的方法是让会员的联系人为他/她的技能「背书」，并以此来认证一个人的技能水平。这能够减少对学位认证的需求。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;MOOC 还可以通过大学来协助认证。Coursera 依赖大学和商学院来为其提供内容；这些大学的名字也会出现在相关的证书上。另外也有一些公司企业也能够起到学术认证的作用，比如谷歌的安卓开发纳米学位。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不管在哪里学习，学生都应该寻求获得可信的认证。当一门课学生数量少时，也许可以得到老师的直接认证。但有的 MOOC 的学生数量非常大，让少数几位老师来进行认证是不切实际的。自动化认证能帮上我们的忙。Udacity 让其学生将代码上传到 GitHub，机器学习毕业生可以在几个小时之内就给出反馈。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但即便这个问题可以解决，但微学位可能是会有很多水分的。虽然和大学学位一样，微学位也需要一些认证和考试，但微学位的很多学习过程都是在非正式的场景中，很多工作所需的技能无法在这个过程中被学习到。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一种处理方式，是通过发行「数字标牌（digital badges）」将知识货币转化为小面额货币来认证不太正式的成果。澳大利亚最大的高等教育机构墨尔本皇家理工大学（RMIT），正在与资格认证平台 Credly 合作，为那些没有通过测试但是对企业依然有价值的技能签章。RMIT 的副校长 Belinda Tynan，引进了工程学学生做的一辆电动汽车，进入比赛并赢得赞助商作为一个例子。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数字标牌的麻烦是它增长的太快了。在 2016 年与 Credly 合作的一个项目中，伊利诺斯州立大学单独创建了 110 个 badge。加上 MOOC 证书，LinkedIn Learning 课程、能力本位教育 General Assembly 等诸如此类，和创造新知识的货币看起来更会导致恶性膨胀。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;David Blake 是创业公司 Degreed 的创始人，希望通过打造成一个资格的中央银行来解决这个问题。他想发布一个标准化的技能水平评估，不管人们用什么方法获得这项技能。该计划是建立一个主题专家网络来评估员工的技能（比如说，复制编辑或信用分析），和一个标准化的分级语言，不论何时何地对所有人都是一样的标准。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Pluralsight 也在朝类似的方向发展。它是一个诊断工具，使用一种称为项目反应理论的技术来计算用户在编码等领域的技能水平，给他们评分。该系统有助于某人下一步应该学习什么，还为公司提供了一个标准化的方法来评估人们的技能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而，一套标准化技能测量系统有它自己的问题。让专家给能力打分所产生的问题是对这些专家的资格的质疑。项目反应理论难以评价主观技能，例如构造论点的能力。在 IT 这种领域，具体可评估的技能。更适合这种方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;是非常的适合。事实上，它们可以直接测试。一个在亚美尼亚的青少年 Tigran Sloyan 过去常常参加数学奥林匹克竞赛。那段经历帮助他赢得去麻省理工学院读书的机会，还让他在旧金山创建了一家名为 CodeFights 的公司。该网站为 500000 用户提供免费的游戏化的挑战作为一种帮助程序员学习的方式。当他们足够了解，他们将向雇主输送人才，如果推荐的人才被成功录用，雇主会向这家公司支付人才薪水 15% 的钱。斯德哥尔摩的创业公司 Sqore 利用竞赛为其客户筛选工作申请。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;五、路径依赖：将条件转化为工作&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大学教育旨在作为一个缓冲期，让学生进入更广阔的世界，期望能指导他们加入工作。但是 在实践中，许多人还是陷入了困境，因为雇主要求的是具有特定经验的证明。-这是否是技能鸿沟（skills gap）是辩论上的问题。- 宾夕法尼亚大学沃顿商学院（Wharton School）的 Peter Cappelli 说：「如果我找不到一辆价格 15000 美元的强劲、节能和易于停放的汽车，那这并不意味着汽车短缺。」但是，无论是教育者还是雇主方向有问题，我们都需要引导个人进入就业的道路。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有时，一些工作基础医学和法律已经明确地界定了。职业教育将课堂和基于工作的学习相结合，为准备进入特定行业的年轻人做好准备。在许多欧洲国家，三分之一到半数的高中毕业生将进入职业道路上（见图表）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicdNiceoKXOr6okChjGPoaiaMFefDQ3jPHfYQoH5kVicMhibjYka7df9bAIsPjCknxh0XUlDfp74Gyiavg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是，在其他国家（例如美国，缺乏职业教育的传统）需要更多途径来将正规教育毕业生平稳地过渡到工作中。纳米学位（nanodegree）就是这种方式的一个例子，它非常依赖雇主提供的内容评论。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这在人们职业生涯的早期阶段尤为重要，这不仅仅是因为他们缺乏经验，同时还因为收入增长最快。从美联储经济学家对美国工资增长的分析表明，大部分收入增长发生在 25 岁至 35 岁之间，平均而言，在 45 岁之后，只有 2% 的工作者能拥有提薪的机会。因此，对于人们来说，一旦获得资格证明，就必须迅速加入工作岗位中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是初创公司 LearnUp 的见解，它通过与没有大学学位的申请人合作开展入门级职业教育。在线申请工作的用户可以点击一个链接，参加一小时的在线培训课程，了解如何成为出纳员、销售员或这些之类的。雇主向 LearnUp 支付固定费用以提高候选人的人数，从而使招聘和留任率上升。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Generation 是由麦肯锡社会倡议运营的慈善社会计划，是一家非营利性的咨询机构，它采用了一种训练营方式和一些典型的麦肯锡思维方式来培训对申请中等职位有困难的求职者。该程序从进入工作场所并识别关键事件开始做分析。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;课程设计师然后使用该分析创建一个涵盖技术知识和行为技能并持续 4 至 12 周的全日制培训计划。该计划已在美国、西班牙、印度、肯尼亚和墨西哥上线。到 2016 年年底，它有一万名毕业生。这个项目学员不用付钱，但雇主需要支付。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这样教育就可以让人们从事特定的工作。职业教育有利于让毕业生尽快上班，但对人们适应工作世界的变化并没有帮助。实际上，胡佛研究所（Hoover Institution）的研究人员在 2015 年进行的一项跨国研究表明，接受职业教育的人们比那些接受普通教育的人更有可能随着年龄的增长而退出劳动力市场。在严重依赖学徒制度的国家，如丹麦、德国和瑞士，这种模式尤为明显。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大公司可能更有规模地为员工提供内部培训来提高他们的技能。但许多工作者并不知道走怎么样的发展路线。这表明，企业很可能在行动、实效上作为职业顾问。去年推出了一个名为 MyPath 的计划，该计划基于学习和工作迭代的想法。它允许美国临时工人从西方国际大学（Western International University）获得学位，并且不需要支付费用。该学位的结构是由一系列教育阶段组成，在教育阶段后是工作阶段，他们期望人力资源有良好的评价，从而有高薪工作的机会。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;领英是另一个对更广泛趋势有正确理解的组织。专业网络站点喜欢称它拥有的数据为「经济图谱」，即全球经济的数字地图。它的求职者数据及招聘平台，为其提供了关于雇主的需求以及求职者需要什么技能的信息。通过领英学习（LinkedIn Learning），它现在也可以提供培训资源。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;提供大众市场职业建议的困难是怎样找到一个商业模式为其买单。领英主要针对专业人士来解决这个问题，他们自己对支付服务或招聘人员感兴趣。但这又产生了一个更大的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;六、显而易见的问题：低技能工人的再教育&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;想象下你是 45 岁的长途货车司机，从来没有享受过学校生活，并总想尽快离开它，证书很少。虽然工作很累很孤独，但它至少似乎提供了体面的工作保障：司机短缺在行业内常年是一个问题，并且劳动力的平均年龄很高（英国是 48 岁），所以缺口很可能变得更糟。BLS 网站预测，「随着经济的增长，货物需求将急剧增加，从而需要更多的卡车司机来保持供应链的正常运行。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但未来可能会有很大的不同。货运行业可能更快地采用自动驾驶汽车。根据 2014 年摩根史丹利投资公司（Morgan Stanley）的报告，全自动化可能会使美国卡车司机的数量减少三分之二。这些预测是警告，但它又是正确的。采用无人车的速度很可能会由于监管而减缓，可能仍然需要司机来处理不可预见的问题，如果这些新出现的司机工作需要更多的技术知识，他们甚至可以获得更高的薪水。但其他部门的就业可能会随着运费降低而增加。但也有可能在不久的将来，大量的卡车司机发现他们自己是多余的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;知道什么时候跳槽也是一个问题。对于那些有着几十年工作经验的人来说，放弃还太早，但是，认为变化不会发生，也是有风险的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于这种低技术工人而言，他们与 MOOC、General Assembly 和领英的世界距离很远。约有 80％的 Coursera 学习者拥有大学学位。在时间和金钱方面，再培训的成本对于他们来说也是很少的。而动机是大问题：互联网提供的巨大的学习机会根本不会吸引每个人。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;再教育回报最高的是计算机技能，但是，从卡车司机到程序员，没有一条自然路径。在一个评估全球成人技能的项目中，OECD 给出了 33 个成员国成年人计算机水平的暗淡图景（如图）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicdNiceoKXOr6okChjGPoaiaMIqic8aPzjP753fmAbQZteyGicKY30BkyoDMBG5iaAuvibqicawAPsA1IWfA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;每五个成年人中，就有一人的阅读和数字水平很差。每四个人中，就有一人几乎没有计算机经验。使用技术来解决问题的能力，几乎所有的成年人都在最低的熟练水平之下。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而且，如果要掌握新技能，最好的办法就是实践，但是，许多工作包括卡车司机几乎无法提供这样的机会，有些工作甚至是进一步去技术化的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此，卡车司机的难题很难解决。任何体面的答案都需要个体、雇员、教育提供商的协作努力。特别是两个单位的角色，很重要。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个是工会。他们了解全产业的发展趋势，而小一些的雇主可能没有这样的视野。工会还可以陪伴工人职业生涯，在一个自我雇佣呈上升趋势的世界里，这会变得更加重要。丹麦著名的「弹性安全（flexicurity」系统就是一个很好的例子，为失业工人提供一张有关行业培训计划的清单。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二个是政府。虽然终身学习谈得多，但是，只有少数国家正在付诸实践，比如新加坡政府。考虑到国家大小、政治系统的不同，新加坡的办法虽然难以复制，但是仍然可以从中学习到东西。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2016 年 6 月，我们曾经调查过人工智能领域以及工作变化时工人所需要做出的调整。「那意味着要让教育和培训变得足够灵活，快速而高效地教授新的技术，」我们总结说，「这更需要强调终身学习以及在职培训，更广泛地使用在线学习和视频游戏风格的模拟。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;技术变迁的步伐和范围所带来的不确定性是巨大的。不过，毋庸置疑的是需要找到新的、更有效的方法来发展、增加工作技能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;连接雇佣教育的新生态系统的微弱轮廓正变得可加辨识。雇主更加强调雇员的适应能力，好奇心和学习。他们正在和大学以及新的教育提供商合作，打造和提升自己的人才供应链。短期课程、低成本、在线学习正让人们更加容易将工作和培训结合起来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;与此同时，新技术也让学习更高效，更有必要。虚拟和增强现实能更本上改善职业培训。大数据为个性化教育提供良机。平台使得不同知识水平的人连接起来更容易，还能进行 p2p 教育和指导。「教育正变得灵活、模块化、易接触到和学的起。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是，到目前为止，这个尚处初期的生态系统可能不对称地让那些最不需要帮助的人群。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 17 Jan 2017 16:38:52 +0800</pubDate>
    </item>
    <item>
      <title>学界 | 谷歌提出深度概率编程语言Edward：融合了贝叶斯、深度学习和概率编程</title>
      <link>http://www.iwgc.cn/link/4376156</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自arXiv&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;近日，哥伦比亚大学、Adobe Research、Google Research 和 Google Brain 的研究者联合发表了一篇论文，介绍一种新的图灵完备的概率编程语言。该论文表示 Edward 集成到了 TensorFlow 中。以下是该论文及 Edward 的简单介绍，论文全文请点击文末「阅读原文」查看。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://arxiv.org/pdf/1701.03757v1.pdf&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Edward 官网：http://edwardlib.org/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Edward 官网对这门新语言的描述是：Edward 是一个用于概率建模、推理和评估的 Python 库。它是一个用于快速实验和研究概率模型的测试平台，其涵盖的模型范围从在小数据集上的经典层次模型到在大数据集上的复杂深度概率模型。Edward 融合了以下三个领域：贝叶斯统计学和机器学习、深度学习、概率编程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;它支持以下方式的建模：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;定向图模型&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;神经网络（通过 Keras 和 TensorFlow Slim 等库）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;条件特定的无向模型&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;贝叶斯非参数和概率程序&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;它支持以下方式的推理&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;变分推理（Variational inference）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: circle;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;黑箱变分推理&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;随机变分推理&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;包容 KL 散度（Inclusive KL divergence）：\text{KL}(p\|q)KL(p∥q)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;最大后验估计&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;蒙特卡洛（Monte Carlo）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: circle;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;哈密尔顿蒙特卡罗（Hamiltonian Monte Carlo）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;随机梯度 Langevin 动态&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Metropolis-Hastings&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;推理的组成&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: circle;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;期望最大化（Expectation-Maximization）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;伪边界和 ABC 方法（Pseudo-marginal and ABC methods）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;消息传递算法（Message passing algorithms）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;它支持以下的模型评估和推理&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;基于点的评估（Point-based evaluations）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;后验预测检查（Posterior predictive checks）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Edward 构建于 TensorFlow 之上。它支持诸如计算图、分布式训练、CPU/GPU 集成、自动微分等功能，也可以用 TensorBoard 可视化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以下是介绍论文的摘要介绍&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;论文标题：深度概率编程（DEEP PROBABILISTIC PROGRAMMING）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicdNiceoKXOr6okChjGPoaiaMKQd4XEYvt720ClBzic0RfFcw9Uw0ue2SCbSm9p8dZnZpY6ibqricUTtdQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;摘要&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们提出了一种图灵完备的概率编程语言 Edward。Edward 构建于两种组合式表示的基础上——随机变量和推理（random variables and inference）。通过将推理看作「第一类公民」，与建模（modeling）一样，我们表明概率编程可以做到和传统深度学习一样灵活和有计算效率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于灵活性，Edward 让我们可以使用从点估计（point estimation）到变分推理和 MCMC 等各种可组合的推理方法来拟合相同的模型。此外，Edward 还可以将建模表征复用作推理的一部分，这能促进丰富的变分模型和生成对抗网络的设计。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于效率，Edward 集成到了 TensorFlow 之中，在已有的概率系统基础上提供了显著的加速。比如，在基准 logistic 回归任务上，Edward 至少比 Stan 和 PyMC3 快 35 倍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;引言&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深度神经网络的本质是组合式的（compositional）。用户可以以创造性的方式来将层连接起来，而无需担忧如何去执行测试（前向传播）或推理（基于梯度的优化，通过反向传播和自动微分）。在这篇论文中，我们为概率变成设计组合式表示（compositional representations）。概率编程让用户可以将生成概率模型指定为程序（program），然后将这些模型「编译（compile）」为推理过程（inference procedures）。概率模型本质上也是组合式的，而之前的大部分工作都集中在通过组合随机变量来构建丰富的概率程序上（Goodman et al., 2012; Ghahramani, 2015; Lake et al., 2016）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但很少有研究考虑过用于推理的类似的组合性。相反，现在大多数已有的概率编程语言都将推理引擎当作从模型中抽象出来的黑箱来处理。这些方法不能代表在复用模型表征的概率推理中的最新进展。比如，在变分推理（Kingma &amp;amp; Welling, 2014; Rezende &amp;amp; Mohamed, 2015; Tran et al., 2016b）和生成对抗网络（Goodfellow et al., 2014）上的进展已经变得非常重要了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们提出了一种图灵完备的概率编程语言 Edward。Edward 构建于两种组合表示的基础上——随机变量和推理（random variables and inference）。我们给出了如何将 Edward 集成到已有的计算图框架（如 TensorFlow）中的方法。TensorFlow 这样的框架能够「免费」提供分布式训练、并行性、向量化和 GPU 支持等计算优势。我们还表明 Edward 可以如何让我们轻松使用从点估计（point estimation）到变分推理和 MCMC 等各种可组合的推理方法来拟合相同的模型。通过将推理看作「第一类公民」，与建模（modeling）一样，我们表明概率编程可以做到和传统深度学习一样灵活和有计算效率。比如，我们的哈密尔顿蒙特卡罗（Hamiltonian Monte Carlo）实现比现有的软件快 35 倍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicdNiceoKXOr6okChjGPoaiaM9Rpd7rZs2Ric0Tqt6aBj7cSOEI8wdcs2mF4pZC7ibG2HDz8rEonkXtwQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 1：Beta-Bernoulli 程序（左）与其计算图（右）。从图中取 x 会生成一个有 50 个元素的二值向量&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicdNiceoKXOr6okChjGPoaiaMia3zWhs4NH8tiajnMgox42qGbKVLelaSxbczbf3ibJuIyVIEgA9I1Q9tQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 2：用于一个 28×28 像素图像的数据集的变自编码器：（左）图模型，其中虚线表示推理模型；（右）概率程序，带有 2 层神经网络&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicdNiceoKXOr6okChjGPoaiaM0F6Cf44ytVVdBnFGzpR1GIyWAoA4ic1bHCvymMZSpJdtwTxPSFFjCTg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 3：贝叶斯 RNN：（左）图模型；（右）概率程序。该程序的时间步骤未指定；其为循环使用了一个符号（tf.scan）&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicdNiceoKXOr6okChjGPoaiaMoibae7czTyyY3FrNp75ricPV1ticbJobjSXNmgiac2ueiadjr6yu8E4JUAQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 6：（左）变分推理；（右）蒙特卡洛&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicdNiceoKXOr6okChjGPoaiaMiahBTAoEsJm8hyCia8iclFnOJUtWGwfgXCppVjag1LNmIOfpHiaLB31BRA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 7： 生成式对抗网络：（左侧）概率图模型（右侧）概率程序。加入一些假数据以及训练其判别式模型，能不断强化该生成模型&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicdNiceoKXOr6okChjGPoaiaMyVJQDHORSUr3ebFiaAE9ztUKV2tf62rEl8qurjNPXy4owTD0mq9MrUQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;图 13：LDA 文档主题生成模型，隐含狄利克雷分布 (Blei et al., 2003）&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicdNiceoKXOr6okChjGPoaiaMT25gZ6GhOiazxvUAIIIH9rae7TWicl65FPArtFy5cj6JXvyuupwJClkw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 14： 高斯矩阵分解&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 17 Jan 2017 16:38:52 +0800</pubDate>
    </item>
    <item>
      <title>招募 | 加入地平线，做最酷的语音交互</title>
      <link>http://www.iwgc.cn/link/4376157</link>
      <description>&lt;p&gt;&lt;span&gt;地平线机器人是嵌入式人工智能领导者，致力于提供高性能、低功耗、低成本、完整开放的嵌入式人工智能解决方案。地平线的愿景是为包括自动驾驶汽车等世界上超过 1,000 种设备装上「大脑」，让它们具有从感知、交互、理解到决策的智能，让每个人的生活更便捷、更安全、更有趣。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibUP7CVr6GmhKQCDxRNzfzZlnmEUMAahfPw23hMxyjib4qPo4A5btsKmSm56cSy8SibxUkYGbrxeklg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地平线从创立伊始就开始了语音技术的研究，并将家居场景作为语音交互的核心场景，解决远场识别、无延迟的交互相应、服务种类复杂等方面的问题。地平线通过云端+嵌入式的结合，语音信号处理、语音识别和语义理解的结合，以及软硬结合（包括麦克风阵列），提供语音全自然交互的解决方案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不久之前，&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722365&amp;amp;idx=1&amp;amp;sn=9ffce4228e73a9d1f711d463536430eb&amp;amp;chksm=871b1443b06c9d5556720e018bcbd3812cc7d733b73569b9583ed2bfee11a3ae51e1b3c67f67&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722365&amp;amp;idx=1&amp;amp;sn=9ffce4228e73a9d1f711d463536430eb&amp;amp;chksm=871b1443b06c9d5556720e018bcbd3812cc7d733b73569b9583ed2bfee11a3ae51e1b3c67f67&amp;amp;scene=21#wechat_redirect"&gt;机器之心曾对地平线联合创始人&amp;amp;算法 VP 黄畅，以及首席语音算法工程师&amp;amp;语音识别团队负责人牛建伟的独家专访&lt;/a&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地平线为员工提供了豪华的「福利礼包」，包括但不限于：超长产假和陪产假、在家办公机会、每年全方位的体检套餐、任性的补充医疗保险、按摩椅健身器等休闲设施、部门活动费、图书购置费、餐补交通补住房补······当然最重要的是，有无数的各路大牛与你共事交流，收获最最宝贵的想法和经验。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;So~&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;想做最酷的语音交互技术？快快加入地平线吧：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;语音音频信号处理算法工程师&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;工作职责&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;负责语音识别前端的信号处理算法的设计和实现&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;配合语音识别工程师优化识别系统的整体性能&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;配合相关同事进行算法定点化的工作&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;职位要求&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;熟悉基本的音频信号处理知识，在 Speech Enhancement，Acoustic Echo Cancellation 和 Microphone Array 这三个方向其中之一有过实际系统的开发经验。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;能够根据实际产品需求评估并调整算法实现或者参数&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;有实际项目经验者优先&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;有语音识别相关经验者优先&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;NLP 算法工程师&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;工作职责：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;从智能家居语音交互角度，利用 NLP 算法/技术解决实际问题。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;研发方向分为语义理解和对话系统&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;职位要求：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;精通 NLP 中常见的统计模型，深度学习方法，扎实的 NLP 技术积累&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;具备一定的工程能力，有 NLP 相关的项目经验或研究经历&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;强烈的责任感，严密的逻辑思维，良好的沟通表达，分析和解决问题的能力&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;机器学习方面有深刻的理解者优先&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;语义理解和对话系统开发经验者优先&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;语音识别算法工程师&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;职位要求&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;熟练掌握语音识别方面算法，精通声学模型或者语言模型的建模方法&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;了解最新的语音方面的技术进展，有扎实的机器学习背景&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;熟练掌握 Kaldi、HTK、MXNet 等开源工具，有一定的工程实践能力&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;有语音识别相关项目经验者优先&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;语音交互技术专家&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;工作职责：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;语音人机交互语音平台服务架构搭建；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;嵌入式系统软件架构优化；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;人机交互项目开发。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;职位要求：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;精通嵌入式语音系统软件架构或人机交互语音平台服务的架构；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;精通语音信号处理，语音识别，自然语言处理，机器学习；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;完整人机交互系统研发经验；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;至少 3 年以上人机语音交互系统研发、课题/项目或团队经验&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;简历请投递至&lt;/span&gt;&lt;span&gt;：&lt;/span&gt;&lt;span&gt;dream@hobot.cc&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 17 Jan 2017 16:38:52 +0800</pubDate>
    </item>
  </channel>
</rss>
