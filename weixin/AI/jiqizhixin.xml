<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>成本14,000元，如何自己动手搭建深度学习服务器？</title>
      <link>http://www.iwgc.cn/link/</link>
      <description>
&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自medium&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：曹瑞、李泽南&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在完成 Jeremy Howard 非常出色的深度学习第一部分课程之后，我查看了一下我的亚马逊网络服务（AWS）账单，发现我每个月运行 GPU 都要花费差不多 200 美元。以这样的代价来完成网络课程看起来代价有点大，而且我已开始着手研究一些课程以外的数据集，并迫切地想得出结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过与大家进行交流，阅读了大量博客文章之后，我最终决定开始配置自己的深度学习服务器。当今科技和硬件的发展是如此的迅猛，我担心我曾阅读过的文章很快就会过时，但我希望自己的以下总结能够为大家带来帮助。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;配置服务器的 6 大步骤：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 选择组件&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 组装&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 安装操作系统&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4. 安装驱动程序&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;5. 安装库&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;6. 设置远程访问&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1. 选择部件&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我阅读了大量博客，最终形成了现在应该选择哪种配置的概念。因为硬件更新换代太快，在下个世代到来时到底该买哪些型号的部件，这一问题还是得留给你们研究。但是一般而言，你需要选购以下部件：主板、CPU、内存（随机存取存储器，RAM）、硬盘驱动器（固态硬盘，SSD）、显卡（GPU）、CPU 风扇、电源和机箱。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/1f92067a900a7b0e6e83faa572db11a7ec9e6788"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P.S. 我强烈建议你在购买之前在 pcpartpicker.com 上创建一个清单。这个网站的特色在于它有一个「兼容性检查」的功能，它会告诉你自己选择的部件是否互相兼容。我的列表在这里。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;部件清单（原文为美国市场价，机器之心将其替换为 2 月 23 日，京东自营/淘宝价）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;CPU&amp;mdash;英特尔 i7 7700k（Kabylake）4.2GHz 四核 2799 元&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;内存&amp;mdash;海盗船 复仇者 LPX 32GB (2 x 16) DDR4&amp;ndash;3200 2499 元&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;固态硬盘&amp;mdash;三星 850 EVO sata3 500G 1299 元&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;GPU&amp;mdash;索泰 GeForce GTX 1080 8GB 4999 元&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;主板&amp;mdash;微星 Z270-A PRO ATX LGA1151 1299 元&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;CPU 风扇&amp;mdash;酷冷至尊 Hyper 212 EVO 82.9 CFM 128 元&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;供电电源&amp;mdash;EVGA SuperNOVA G2 750W ATX 879 元&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机箱&amp;mdash;NZXT S340 (White) ATX Mid Tower Case 369 元&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;总价：14,271 元&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我决定从单块显卡开始自己的装机之路，但我选择的微星 (MSI) 主板有多个 PCIe 通道，这意味着如果有需要，我可以在未来添加更多的 GPU。一般而言，我都会选择那些用户评论数最多的硬件，即使这些评论褒贬不一。但评论意味着部件受欢迎的程度，用户数量越大，就越有可能出现用户自行创建的使用指南和建议。这会为你接下来的两个步骤免去了很大的痛苦。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一些实用的文章：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Build Personal Deep Learning Rig (http://guanghan.info/blog/en/my-works/building-our-personal-deep-learning-rig-gtx-1080-ubuntu-16-04-cuda-8-0rc-cudnn-7-tensorflowmxnetcaffedarknet/)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Optimizing a Starter CUDA Build (https://www.servethehome.com/optimizing-a-starter-cuda-machine-learning-ai-deep-learning-build/)&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Building a Deep Learning Dream Machine (http://graphific.github.io/posts/building-a-deep-learning-dream-machine/)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719346&amp;amp;idx=1&amp;amp;sn=64b5198e70558eb8fdac439cdf8db81b&amp;amp;chksm=871b000cb06c891ac7ba594b4ae9bae68f6f533040fb1f9aef5c70613c77f0cf849807216758&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719346&amp;amp;idx=1&amp;amp;sn=64b5198e70558eb8fdac439cdf8db81b&amp;amp;chksm=871b000cb06c891ac7ba594b4ae9bae68f6f533040fb1f9aef5c70613c77f0cf849807216758&amp;amp;scene=21#wechat_redirect" target="_blank"&gt;&lt;span&gt;Deep Learning Hardware Guide &lt;/span&gt;&lt;/a&gt;&lt;span&gt;(http://timdettmers.com/2015/03/09/deep-learning-hardware-guide/)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2. 组装&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这一部分非常有趣。几乎所有的部件，我都可以在网上找到相关的指导性视频，但是有一些部件我必须要根据相似型号的安装视频才可以。微星主板、酷冷至尊风扇和 NZXT 机箱的指导手册非常不错，但是我还是需要再找一些其他的材料。下面是我找到的一些有用的视频：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;iframe allowfullscreen="" class="video_iframe" data-vidtype="1" frameborder="0" height="417" src="https://v.qq.com/iframe/preview.html?vid=m0377hib5bz&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0" width="556"&gt;&lt;/iframe&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;iframe allowfullscreen="" class="video_iframe" data-vidtype="1" frameborder="0" height="417" src="https://v.qq.com/iframe/preview.html?vid=f0377tz8scp&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0" width="556"&gt;&lt;/iframe&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;iframe allowfullscreen="" class="video_iframe" data-vidtype="1" frameborder="0" height="417" src="https://v.qq.com/iframe/preview.html?vid=f0377e0ok4x&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0" width="556"&gt;&lt;/iframe&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;经验总结&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;买一把好用的螺丝刀&amp;mdash;&amp;mdash;我的螺丝刀非常的差劲，所以很快就让我停滞不前了。买一个杆长一点的螺丝刀，这样你就可以够得到很紧的地方，也是为自己省力。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;不要吝惜自己的力量&amp;mdash;&amp;mdash;免责声明：要是把什么东西弄坏了，不要怪我。但是至少在两种情况下（CPU 和内存），我因为在安装部件时候用劲太小浪费了好多时间。我担心太过用力，所以如果部件不能够轻松放进去，我就放弃了。至于内存，我几乎在亚马逊上购买了一整套新的芯片。这些情况下，解决的办法就是用力压。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;理解你的 BIOS&amp;mdash;&amp;mdash;BIOS 是一个预先安装在主板上的软件，是你的机器启动时加载的第一个软件。它基本上是你配置硬件和安装操作系统的一个控制面板。学会如何在 BIOS 上找到「引导盘」（U 盘或是包含操作系统的固态硬盘），怎样选择使用哪一张显卡都是非常重要的。遗憾的是微星的用户手册在这些问题上表达得不甚清楚，但是这个视频（https://www.youtube.com/watch?v=C6mQqlmL5Sc）会让你更好地进行理解。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;你的显示器没有坏&amp;mdash;&amp;mdash;弄清怎样让显示屏在我的新机器上工作花了我不少时间。我之前曾听说在你第一次启动的时候，你需要将你的 HDMI 线插到主板的某个位置，因为一开始显卡驱动还没有安装。我照做了，但是当我最后启动的时候，显示器上什么都没有。接着我尝试把线插到显卡上，也没有用。最后我尝试将显卡拔出来，把线连上主板并重新启动。终于能看到东西了！这意味着，微星的主板如果不能在 PCIe 通道找到其他的外置显卡，就会默认使用核显。因为在我第一次启动的时候，就安装了显卡，主板就选择使用我的的新新卡。显示器上看不到任何东西是因为我没有安装英伟达的驱动。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，大功告成了！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/1702d7fa9c681b253dc3bf2a99f6b5135c4a55b7"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/5f94f61049f9b317ad4e85e540dcb57060da63be"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3. 安装操作系统&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在显示器可以工作之后，你会看到一个这样的界面。这就是你的 BIOS（注：不同品牌的主板，BIOS 界面略有不同）。我需要更改两处配置，以保证所有的东西都能正常运行：更改启动优先级，替换默认的显卡。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/8e0aa76f64af620ebc193f6636523d2a013f94dd"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;在 MSI 主板上预置的 BIOS&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我计划主要将我的机器用于编程和机器学习，所以我决定要安装 Ubuntu 操作系统。我还希望能够通过我的 Mac 对它进行远程操作，所以我可能不需要 Windows，但是你可以安装双系统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;制作安装 Ubuntu 的 U 盘&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我依照针对 Mac 的说明（https://www.ubuntu.com/download/desktop/create-a-usb-stick-on-macos），下载了一个叫做 UNetBootin (https://unetbootin.github.io/) 的客户端，它可以为你把所有的事情都处理好。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;启动 UBUNTU&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;若是一切正常，我应该能够插入我的 U 盘，重启，回答问题，安装一个完全可运行版本的 Ubuntu，准备好进行下一步。但是，我得到的确实这样的错误信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/bc2dee79ab7c505ed6e6f022514c6b28e68e9ebc"/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;我按了好几次退出键，之后按了删除键，之后 F1、 F10、 F12、 #%^ 、 $\&amp;amp;]&amp;amp;&amp;amp;&amp;amp;#^，但都没有用。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;问题在于微星主板已经选择了默认的「启动优先级」。再次进入 BIOS（在开机之后立刻按 F11），我看到 BIOS 的配置是首先启动硬件驱动（三星固态硬盘），这里面是空的，但是也可能会有一大堆选项。解决办法就是把 USB 选项拉到优先级列表的顶部，然后重启。最后，我看到了这十分友好的 Ubuntu 安装屏幕！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/fa233e513ad9747697b09260cf2bcbd83c603e30"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在安装了 Ubuntu 并且重启之后，我很失望地发现我卡在了 Ubuntu 的加载屏幕上，它就停在了那里，最终超时。这又是怎么了呢？！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;原来问题在于微星主板内置的显卡（我的 GTX 1080 还在我的咖啡桌上）。它与 Ubuntu 的图形用户界面（GUI）不兼容！这真是经典的鸡和蛋的问题。没有 Ubuntu，我不能下载使用显卡所需的驱动，但是没有显卡，我不能安装 Ubuntu！进入 GRUB (https://help.ubuntu.com/community/Grub2)。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/252eaa3f66083bb2467cc7e5b7d60abff89bacad"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Ubuntu 启动菜单。你可以在开机后按压左 Shift 键进入这一菜单。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，我找到了两篇非常好的文章（http://askubuntu.com/questions/162075/my-computer-boots-to-a-black-screen-what-options-do-i-have-to-fix-it，http://askubuntu.com/questions/716957/what-do-the-nomodeset-quiet-and-splash-kernel-parameters-mean）帮我解决了这个问题。解决办法就是在启动命令中添加一个 *nomodeset*参数。这帮我安装了一个普通版本的 Ubuntu GUI，得以让我继续进行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4. 安装驱动程序&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;英伟达的驱动是出了名地难运行，这一个也不例外。在其他用户的引导下，我去英伟达的网站下载了 GeForce 驱动程序，接着利用 Ubuntu GUI 对它进行安装。这个错误给我带来了很大的痛苦。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;无法检测到可兼容的英伟达显卡&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这又是一个鸡和蛋的问题。我没有再重新接上 GTX 1080 是因为没有驱动程序它无法工作。如果我重新接上，MSI 主板就会开始再次使用它，我就又回到了我开始的地方。解决办法是重新进入 BIOS，改变显卡优先级。我更新了设置，将优先级赋予给内置显卡，而不是选择新的显卡。这样我又可以重新接入 GTX 1080，并正常进入 Ubuntu。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;你好像在运行 X 服务器&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我通过使用这里的说明 (http://askubuntu.com/questions/149206/how-to-install-nvidia-run) 解决了这个问题，但是在最初，我都无法通过第一步：「点击 CTRL+ALT+F1，使用你的凭据登录。」我这样做了之后，屏幕又变成了空白，和显示器的连接就断开了。解决方法是启动 Ubuntu，进入文本模式，完成命令行的步骤。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;更好的办法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最终让我感到欣慰的是所有的东西（驱动程序、CUDA、深度学习库等）都可以运行了。但是没过多久，因为一些配置文件我又把事情搞得一团糟。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 Ask Ubuntu 网站上浏览了几个小时之后，我注意到英伟达驱动程序上预先安装了新的 CUDA 8.0 工具箱，让你可以同时安装 CUDA 和驱动程序。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我清除了现有的英伟达库，运行了下面的代码，然后一切都便正常运行了。你可以在这里 (http://docs.nvidia.com/cuda/cuda-quick-start-guide/index.html#ubuntu-x86_64) 看到完整的说明。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;code class="markup--code markup--pre-code" style="font-family: inherit; font-size: 1em;"&gt;&lt;span&gt;wget http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/cuda-repo-ubuntu1604_8.0.44-1_amd64.deb&lt;br&gt;sudo dpkg -i cuda-repo-ubuntu1604_8.0.44-1_amd64.deb&lt;br&gt;sudo apt-get update&lt;br&gt;sudo apt-get install cuda&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然后将下面的代码添加多你的~/.bash_文件中：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;export PATH=/usr/local/cuda-8.0/bin${PATH:+:${PATH}}&lt;br&gt;export LD_LIBRARY_PATH=/usr/local/cuda-8.0/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}&lt;br&gt;export LIBRARY_PATH=/usr/local/cuda-8.0/lib64${LIBRARY_PATH:+:${LIBRARY_PATH}}&lt;/span&gt;&lt;/pre&gt;&lt;p&gt;&lt;br&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;5. 安装深度学习库&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有很多的好文章都对必要的深度学习库和如何安装进行了描述。关键点在于你不能够盲目地跟随这些说明，尤其是关于如何安装的部分。因为这些说明经常更新，你可以在这些库的网站上找到更好的示例。下面是我安装的一些工具：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;CUDA&amp;mdash;利用 GPU 的并行计算平台&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;cuDNN&amp;mdash;加速深度学习的英伟达库&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Anaconda&amp;mdash;Python 数据科学 (numpy, scikit, jupyter..)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;OpenBLAS&amp;mdash;快速的线性代数方法&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Tensorflow&amp;mdash;谷歌的机器学习框架&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Theano&amp;mdash;深度学习框架&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Keras&amp;mdash;另一种框架，可以简化 Tensorflow 或 Theano 的工作&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这之后，我进行了一些测验以保证一切正常运行，并开始运行 Jupyter 笔记本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;6. 设置远程访问&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;再是一个可选步骤。但是如果你希望通过笔记本电脑远程操作，下面是一些方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Teamviewer 是一款屏幕分享软件。如果你安装了这一软件，并在两个机器上运行，你便可以通过你的笔记本电脑控制 Ubuntu 主机，反之亦可。这让工作变得更加方便，但是在进行屏幕分享时做所有的事情都会有一点延迟且不灵活。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/9758d76705547795e4515177a570e9b5c0c3c059"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;SSH 和端口转发&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我想要远程通过 SSH 访问我的新机器，并且和它进行互动，就好像它是我在笔记本上多了个 Tab 键一样。为了做到这一点，我在 Ubuntu 上安装了 OpenSSH。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;sudo apt-get install openssh-server&lt;br&gt;sudo service ssh status&lt;/span&gt;&lt;/pre&gt;&lt;p&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;之后，我将 Comcast 路由器配置到将外部通信量直接转发到我的主机。我根据 Comcast 的说明，出乎意料的是这居然管用！我通过在 www.canyouseeme.org 查看端口 22，确认了这一点。部分过程可能需要你的公共 IP 地址，你可以通过运行下面的代码找到：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;dig +short myip.opendns.com @resolver1.opendns.com&lt;/span&gt;&lt;/pre&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;远程笔记本&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外一个很酷的技巧就是，如果你喜欢 Jupyter，你可以在你的深度学习主机上运行你的笔记本，但是在你笔记本电脑上进行浏览和编辑。这里有关于这一技巧的一些教程 (http://www.justinkiggins.com/blog/zero-configuration-remote-jupyter-server/)，所以我在下面只列出了命令：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;$laptop: ssh -l bfortuner@DEEPLEARNINGIP&lt;br&gt;$server: jupyter notebook --no-browser --port=8888&lt;br&gt;$laptop: ssh -NL 8888:localhost:8888 bfortuner@DEEPLEARNINGIP&lt;/span&gt;&lt;/pre&gt;&lt;p&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在你就可以在笔记本电脑的浏览器上访问 http://localhost:8888，开始编辑你在深度学习机器上的笔记本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;原文地址：https://medium.com/@bfortuner/building-your-own-deep-learning-box-47b918aea1eb#.o5pbw9xao&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Thu, 23 Feb 2017 12:29:28 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 谷歌发布tf.Transform：一个TensorFlow数据预处理库</title>
      <link>http://www.iwgc.cn/link/</link>
      <description>
&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自Google Research Blog&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当我们将机器学习应用于真实世界数据集时，我们需要花费大量工作来将数据处理成适合标准机器学习模型（比如神经网络）的格式。这种预处理（preprocessing）有许多不同的形式&amp;mdash;&amp;mdash;从格式之间的转换，到文本的标记化（tokenizing）和提干（stemming）以及形成词汇表，再到执行各种数值运算（例如归一化）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今天，我们宣布发布 tf.Transform，这是一个 TensorFlow 库，可以让用户定义预处理流程（preprocessing pipelines）和使用大规模数据处理框架运行这些流程，同时还能让用户以一种将这些流程作为 TensorFlow graph 一部分的方式运行从而利用这些流程。用户可以通过将模块化的 Python 函数组合到一起来定义一个流程，然后 tf.Transform 会使用 Apache Beam 来执行它。Apache Beam 是一个用于大规模数据的、高效的、分布式的数据处理框架。通过 Apache Beam 计划好的对其它框架的运行支持，Apache Beam 流程还能运行在 Google Cloud Dataflow 上。通过 tf.Transform 导出的 TensorFlow graph 可以让预处理步骤在训练好的模型被用于预测时被复制，比如当使用 TensorFlow Serving 将模型投入应用时。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相关链接：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;tf.Transform：https://github.com/tensorflow/transform&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Apache Beam：https://beam.apache.org/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Google Cloud Dataflow：https://cloud.google.com/dataflow &lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;TensorFlow Serving：https://tensorflow.github.io/serving/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在生产中运行机器学习模型时会常常遇到一个问题：「训练-应用偏差（training-serving skew）」，参阅机器之心文章《&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722526&amp;amp;idx=5&amp;amp;sn=4fd5eddcd49ffdc64f6b96dbe3597d25&amp;amp;chksm=871b14a0b06c9db68a9422f4c7de72acf7c9ef90cc9370de9e1defd36c2a74dcab8a69ef8c83&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722526&amp;amp;idx=5&amp;amp;sn=4fd5eddcd49ffdc64f6b96dbe3597d25&amp;amp;chksm=871b14a0b06c9db68a9422f4c7de72acf7c9ef90cc9370de9e1defd36c2a74dcab8a69ef8c83&amp;amp;scene=21#wechat_redirect" target="_blank"&gt;谷歌机器学习应用的四十三条经验法则&lt;/a&gt;》。「训练-应用偏差」是指当投入产品应用阶段的模型所收到的数据在某些方面不同于该模型在训练过程中所使用的数据时，预测质量出现下降的情况。tf.Transform 通过保证应用阶段的变换和训练阶段所执行的变换完全相同，能够确保在预处理过程中不会出现偏差，这不同于训练阶段和应用阶段的预处理在两个不同的环境中分别实现的情况（比如，分别在 Apache Beam 和 TensorFlow 环境中）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除了方便预处理之外，tf.Transform 允许用户为他们的数据集计算汇总的统计。在每一个机器学习项目中，理解数据都是非常重要的，因为如果对基本数据做出了错误的假设，那么就会产生一些微妙的错误。为了使这种汇总统计的计算简单有效，tf.Transform 允许用户检查他们关于原始数据和预处理后的数据的假设。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/3db4601ebedec7e0b9532f639c4607b933851ace"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;tf.Transform 允许用户定义预处理流程。用户能够在 TensorFlow 训练中具体化要预处理的数据，也能导出一个 tf.Transform graph，其能将转换过程编码为 TensorFlow graph。然后这一转换图（transformation graph）可被整合进用于推断的模型图。&lt;/span&gt;&lt;/em&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们非常高兴能把这个最新版本添加到 TensorFlow 生态系统中，我们希望用户发现它对预处理、理解数据有所帮助。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;致谢&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们感谢以下 tf.Transform 成员为该项目所作出的贡献： Clemens Mewald, Robert Bradshaw, Rajiv Bharadwaja, Elmer Garduno, Afshin Rostamizadeh, Neoklis Polyzotis, Abhi Rao, Joe Toth, Neda Mirian, Dinesh Kulkarni, Robbie Haertel, Cyril Bortolato and Slaven Bilac。也感谢 TensorFlow、TensorFlow Serving 和 Cloud Dataflow 团队的支持。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;原文地址：https://research.googleblog.com/2017/02/preprocessing-for-machine-learning-with.html&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Thu, 23 Feb 2017 12:29:28 +0800</pubDate>
    </item>
    <item>
      <title>前沿 | 脑机接口新突破：实现迄今为止最快的打字速度</title>
      <link>http://www.iwgc.cn/link/</link>
      <description>
&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自ScientificAmerican&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;strong&gt;作者：Simon Makin&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;编译：侯韵楚 ，微胖&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;一个新型接口系统&amp;mdash;&amp;mdash;使三位瘫痪病人的打字速度比之前快出 4 倍。&lt;em style="color: rgb(136, 136, 136); line-height: 25.6px; text-align: justify; white-space: normal;"&gt;&lt;span&gt;&lt;em style="max-width: 100%; font-size: 16px; line-height: 28px; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;span&gt;读者可点击阅读原文下载此论文。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/db261f606792b38b46f4355e23947e19f245edb8"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;斯坦福大学的 BrainGate 临床试验中，一位被试使用脑机接口，通过她的思想控制计算机光标来打字。来源：Courtesy Stanford University&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;十年前的一个雨天，Dennis Degray 出门扔垃圾时不慎滑倒，从此他的生活轨迹迥然改变。他撞到了下巴，造成了严重的脊髓损伤，以至于脖子以下全部瘫痪。如今研发出了一个系统，意在使瘫痪病人仅用大脑便可以打字；而他便是这个系统调查实验的明星参与者。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了应用脑机接口（Brain-Computer Interface，BCI）使残疾人得到康复，研究人员努力了几十年，但能够被广泛应用的设备却很少，根据具体应用情况，会存在一些障碍。然而，对于打字而言，一个很大的障碍是不是足够快，这样，该技术才有采用价值，而这往往要动手术。eLife 在周二发表了一项研究成果，揭示了该系统的成效：三位被试&amp;mdash;&amp;mdash;Degray，以及两位患肌萎缩侧索硬化症的病人（ALS，或称葛雷克氏症，一种导致进行性瘫痪的神经变性疾病）使用 BCI 后，能以最快速度打字，该技术的具体应用变得切实可行。斯坦福大学的神经外科医生及共同作者 Jamie Henderson 说：「我们已经成功了一半，例如，我可以在手机上打字」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/de0edd50e882e5c2f8025f9c4efc2d9ee852f385"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 1：实验配置 (a) 和在自由书写的问答环节的键入速度 (b)&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;研究人员用三个任务来测评其性能。为了尽可能在最自然的情境中证实该系统性能，研究人员会在「自由打字」任务中，评估一位被试情况，在这一任务中，被试要做的仅仅是使用设备来回答问题。但是，我们通常使用复制打字（copy typing，包括打出固定短语）来评测打字速度，所以，这三位被试都会以这种方式评估。进行「自由打字」的女士快于每分钟六个单词，另一个 ALS 病人打出了约三个单词，而 Degray 打出了约八个单词。2015 年 一期 *Nature Medicine *介绍了可比较的结果，不过，它们都是通过软件实现的，这些软件能够利用英语的统计学数据来预测后续字母。而这项研究中并未应用这类软件。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;复制打字的缺点是：成绩可能会随所用特定短语和键盘布局的变化而变化。为了找到一个不受这些因素影响的度量，第三个任务便与在随机点亮的六乘六网格上选择正方形有关；这样更能接近量化系统输出信息的最大速度，并能轻易转换为数字「比特每秒」的度量。这个团队采用了这一系列任务，但没有使用预测软件，因为该研究的中心目标之一就是制定标准化的度量。斯坦福的博士后研究员及第一作者 Chethan Pandarinath 说：「我们需要建立度量，从而当受试者、方法和研究人员之间存在潜在差异时，同样可以说这种进步显著提高了绩效，因为我们有系统的比较方法，而这是推进该技术的关键。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;两个 ALS 患者分别达到 2.2 和 1.4 比特每秒，是之前记录（相同的参与者在之前的记录）的两倍以上。Degray 达到了 3.7 比特每秒，这比之前的最高速度快四倍。Pandarinath 说：「与之前的 BCI 临床研究相比，这在性能上是巨大的飞跃」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;iframe allowfullscreen="" class="video_iframe" data-vidtype="1" frameborder="0" height="417" src="https://v.qq.com/iframe/preview.html?vid=x03777mt4pc&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0" width="556"&gt;&lt;/iframe&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其他研究者认为这些是最前沿的成果。匹兹堡大学的生物医学工程师 Jennifer Collinger 说：「他是使用 BCI 打字速度最快的一位。这项技术与眼动仪相同，但有些团队的技术对于如被锁定的人来说无效。这些速度也接近 ALS 患者在调查中所提出的 BCI 设备理想值。」他并没有参与到这项研究中。Collinger 说：「你们的技术性能已经足够顶尖，用户也真正想要这类设备」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在受试者的大脑表面植入一或两个小型（六分之一英寸）电极阵列，这些「皮质内」植入物含有 96 个微电极，这些微电极能够穿透 1~1.5 毫米，进入控制手臂运动的运动皮质部分。其中两项手术由 Henderson 执行，他与资深共同作者生物工程师 Krishna Shenoy 共同领导斯坦福的神经假体平移实验室（Stanford&amp;lsquo; s Neural Prosthetics Translational Laboratory）。由电极记录的神经信号通过电缆传输到计算机，在这个计算机中，Shenoy 的实验室开发的算法会解码受试者的想法，并将信号转换为计算机光标的移动。斯坦福大学的团队是一个名为 BrainGate 的多学科联盟的一个分支，这个联盟还包括马萨诸塞州总医院以及布朗大学等等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过电极与大脑相连接的其他方法，包括将电极置于头皮上用于制作脑电图（EEG），以及将电极置于脑表面的头骨之下，制成脑电图（ECoG）。皮质内植入物的优点是：可以从单一细胞挑出具体行为，也可用其他方法捕获数千神经元的平均活动。匹兹堡大学的神经生物学家 Andrew Schwartz 说：「这比从 EEG 或 ECoG 得到的结果要好 10 倍，因为它们所拥有的信息，不足以完成该水平任务。」他同样没有参与到研究中。运动和疤痕会使约前两年植入的信号质量下降，但剩下的信号仍然有效&amp;mdash;&amp;mdash;「比任何其他技术要好得多」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前最大的缺点便是从头部发出，将电线接到电缆上，这很繁琐也有风险。Pandarinath 说：「我们未来的目标便是研发无线设备，虽然现在还未实现，但 5 到 10 年后也许就会成为可能。这是关键的进步&amp;mdash;&amp;mdash;你能用它来送一个人回家，而不必担心譬如感染这类潜在的风险」。这样的设备需要无线电源，已经有几个小组投入研究。Schwartz 说：「基本上大多数技术都是已知的，可以用线圈感应来实现，就像将你的手机置于一边带有线圈的支架上充电。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;团队把这些进展归功于更优的系统工程和解码算法。Pandarinath 说：「在实时控制系统中，快速执行重复计算至关重要」。去年，研究人员发表了一项斯坦福生物工程师 Paul Nuyujukian 领导下的研究。通过训练两只猕猴来执行与类似于本研究所用的网格练习的任务。猴子打字的方式是，通过改变屏幕上字符的颜色来选择字符，生成句子。（尽管他们不会理解这些单词的意思）。当他们添加了一个独立的算法来检测猴子的停止意图时，相应的最快速度每分钟增加了两个单词。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个「离散型点击解码器（discrete click decoder）」也被用于当前的研究。Pandarinath 说：「基本上，我们在这里创建了一个类似于鼠标指明和点击的接口。对于现代智能手机或平板电脑而言，这是一个优质接口；它将开启超越沟通的全新功能领域：上网，播放音乐等正常人认为理所当然的各种方面。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;斯坦福大学的团队已在研究无线技术，并为该项目制定了雄伟的长期目标。Henderson 说：「我们的愿景是使无线接收器能够插入所有计算机，并能通过大脑进行使用。我们的目标之一便是：一年中的每日每夜，每分每秒都能够使用大脑信号来控制标准的计算机接口。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;论文：瘫痪者使用脑皮质内脑机接口的高性能通信（High performance communication by people with paralysis using an intracortical brain-computer interface）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/57b97864b615a153c68315c06dcb49d9698e9ef2"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：脑机接口（BCI）有望通过将神经活动翻译成辅助通信设备的控制信号而帮助患有四肢瘫痪和构音不全的人重新获得交流能力。尽管之前的临床前和临床研究已经给出了有潜力的概念验证（(Serruya et al., 2002; Simeral et al., 2011; Bacher et al., 2015; Nuyujukian et al., 2015; Aflalo et al., 2015; Gilja et al., 2015; Jarosiewicz et al., 2015; Wolpaw et al., 1998; Hwang et al., 2012; Sp&amp;uuml;ler et al., 2012; Leuthardt et al., 2004; Taylor et al., 2002; Schalk et al., 2008; Moran, 2010; Brunner et al., 2011; Wang et al., 2013; Townsend and Platsko, 2016; Vansteensel et al., 2016; Nuyujukian et al., 2016; Carmena et al., 2003; Musallam et al., 2004; Santhanam et al., 2006; Hochberg et al., 2006; Ganguly et al., 2011; O』Doherty et al., 2011; Gilja et al., 2012），但人类临床 BCI 系统的表现还并不够好，还不足以支撑有语音方面的身体限制的人的广泛采用。在这里我们报告了一种用于交流的高性能的皮质内脑机接口（intracortical BCI / iBCI），其已经在三位瘫痪的临床试验参与者的身上进行了测试。该系统利用了之前的临床前和临床研究（Gilja et al., 2015; Kao et al., 2016; Gilja et al., 2012）所发展的解码器设计上的进步。在打字速度（是原来的 1.4&amp;ndash;4.2 倍）和信息流通量（是原来的 2.2&amp;ndash;4.0 倍）上，所有三位参与者的表现都超过了之前的 iBCI（Bacher et al., 2015; Jarosiewicz et al., 2015）。这种高水平的表现表明了 iBCI 作为运动功能受限者的强大辅助交流设备的潜在应用价值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;原文地址：https://www.scientificamerican.com/article/brain-computer-interface-allows-speediest-typing-to-date/&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Thu, 23 Feb 2017 12:29:28 +0800</pubDate>
    </item>
    <item>
      <title>学界 | Yoshua Bengio 等人提出 Char2Wav：实现端到端的语音合成（附资源）</title>
      <link>http://www.iwgc.cn/link/</link>
      <description>
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自arXiv&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;近日，来自印度理工学院坎普尔分校、INRS-EMT、加拿大高等研究院（CIFAR）的研究者在 arXiv 上发布了一篇 workshop track 论文，介绍他们在端到端语音合成上的研究成果 Char2Wav。据介绍，该模型可以直接根据文本生成高质量的音频。目前，该研究团队已经将相关的研究代码开源并且公布了合成的样本示例。&lt;em style="max-width: 100%; color: rgb(136, 136, 136); font-size: 16px; line-height: 28px; text-align: justify; white-space: normal; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(255, 255, 255);"&gt;&lt;span&gt;读者可点击阅读原文下载此论文。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GitHub 开源地址：http://github.com/sotelo/parrot&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;合成语音样本地址：http://josesotelo.com/speechsynthesis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/f29e2a312f734ae79cd4fee21aaa238420dccbcc"/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;摘要&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们提出一种端到端的用于语音合成的模型 Char2Wav，其有两个组成部分：一个读取器（reader）和一个神经声码器（nerual vocoder）。该读取器是一个带有注意（attention）的编码器-解码器模型。其中编码器是一个以文本或音素作为输入的双向循环神经网络（RNN），而解码器则是一个带有注意的循环神经网络，其会产出声码器声学特征（vocoder acoustic features）。神经声码器是指 SampleRNN 的一种条件式的扩展，其可以根据中间表征（intermediate representations）生成原始的声波样本。与用于语音合成的传统模型不同，Char2Wav 可以学习直接根据文本生成音频。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1 引言&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;语音合成的主要任务包括将文本映射为音频信号。语音合成有两个主要目标：可理解性（intelligibility）和自然感（naturalness）。可理解性是指合成音频的清晰度，特别是听话人能够在多大程度上提取出原信息。自然感则描述了无法被可理解性直接获取的信息，比如听的整体容易程度、全局的风格一致性、地域或语言层面的微妙差异等等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;传统的语音合成方法是将这个任务分成两个阶段来完成的。第一个阶段被称为前端（frontend）是将文本转换为语言特征，这些特征通常包括音素、音节、词、短语和句子层面的特征（Zen, 2006; Zen et al., 2013; van den Oord et al., 2016）。第二个阶段被称为后端（backend），以前端所生成的语言特征为输入来生成对应的声音。WaveNet（van den Oord et al., 2016）就是一种可实现高质量的「神经后端（neural backend）」的方法。要更加详细地了解传统的语音合成模型，我们推荐参阅 Taylor (2009)。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;定义好的语言特征通常需要耗费大量时间，而且不同的语言也各有不同。在本论文中，我们将前端和后端整合到了一起，可以通过端到端的方式学习整个过程。这个流程消除了对专业语言学知识的需求，这就移除了在为新语言创建合成器时所面临的一个主要瓶颈。我们使用了一个强大的模型来从数据中学习这种信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2 相关研究&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;基于注意（attention）的模型之前已经在机器翻译（Cho et al., 2014; Bahdanau et al., 2015）、语音识别（Chorowski et al., 2015; Chan et al., 2016）和计算机视觉（Xu et al. 2015）等领域得到了应用。我们的工作受到了 Alex Graves (Graves, 2013; 2015) 的工作很大的影响。在一个客座讲座中，Graves 展示了一个使用了一种注意机制的语音合成模型，这是他之前在手写生成方面的研究成果的延伸。不幸的是，这个语音方面的延伸没有被发表出来，所以我们不能将我们的方法和他的成果进行直接的比较。但是，他的结果给了我们关键的启发，我们也希望我们的成果能有助于端到端语音合成的进一步发展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3 模型描述&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3.1 读取器&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们采用了 Chorowski et al. (2015) 的符号。一个基于注意的循环序列生成器（ARSG/attention-based recurrent sequence generator）是指一种基于一个输入序列 X 生成一个序列 Y= (y1, . . . , yT ) 的循环神经网络。X 被一个编码器预处理输出一个序列 h = (h1, . . . , hL)。在本研究中，输出 Y 是一个声学特征的序列，而 X 则是文本或要被生成的音素序列。此外，该编码器是一个双向循环网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/a2e4287b948fd6fa4222628bc597e4c6129fefcd"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;图 1：Char2Wav：一种端到端的语音合成模型&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在第 i 步，ARSG 重点关注 h 并生成 yi：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/9b31fd19e3eea42c8b26f59e0a83bcf1e7e12e46"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中 si-1 是该生成器循环神经网络的第 i-1 个状态，而&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/0a3c1c0b88f1585688217c4a55202c39b00126fb"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;是注意权重（attention weight）或对齐（alignment）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这项成果中，我们使用了由 Graves (2013) 开发的基于位置的注意机制（location-based attention mechanism）。我们有&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/dd54b25c3920090050a896ed33f2483011f413d4"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而给定一个调节序列 h 的长度 L，我们有：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/55a31e75716ea891fea06f5850e1bc269ffb4436"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中 &amp;kappa;i、&amp;beta;i 和 &amp;rho;i 分别表示该窗口的位置、宽度和重要程度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3.2 神经声码器&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使用声码器进行语音合成受到特定声码器重建质量的限制。为了获得高质量的输出，我们使用一个学习到的参数神经模块（parametric neural module）替代了该声码器。为了该目标，我们使用 SampleRNN(Mehri et al., 2016）作为增强的函数逼近器（function approximator）。SampleRNN 最近被提出用于在音频信号这样的序列数据中建模极其长期的依存关系。SampleRNN 中的层级结构被设计来捕捉不同时间尺度中序列的动态。这对捕捉远距音频时间步骤（例如，语音信号中的词层面关系）之间的长距关联以及近距音频时间步骤的动态都是有必要的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们使用同一模型的条件式版本学习把来自声码器特征序列映射到相应的音频样本。每个声码器的特征帧（feature frame）被加了进来用作相应状态的最好的额外输入。这使得该模块能使用过去的音频样本和声码器特征帧来生成当前的音频样本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4. 训练细节&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先，我们分别预训练读取器和神经声码器然后使用标准的 WORLD 声码器特征（Morise et al., 2016; Wu et al., 2016）作为读取器的目标和神经声码器的输入。最终，我们端到端的微调整个模型。代码已经在网上公开。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;5 结果&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此次我们并未提供对结果的综合的定量分析。相反，我们提供了来自模型 2 的样本。在图 2 中，我们演示了模型生成的样本以及相应的文本对齐。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/44a74c308b7048dfacf8f772f6545d021da5a08f"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 2：以上样本分别来自以 a) 英语音素、b) 英语文本和 c) 西班牙语文本为条件的模型。a) 和 b) 的模型是在 VCTK 数据集（Yamagishi, 2012）上进行训练的，而 c) 模型是在 DIMEX-100 数据集（Pineda et al., 2010）上训练的&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;致谢与参考文献（略）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Thu, 23 Feb 2017 12:29:28 +0800</pubDate>
    </item>
    <item>
      <title>2016 年度学术公众号 TOP10 重磅发布</title>
      <link>http://www.iwgc.cn/link/</link>
      <description>
&lt;p&gt;&lt;br&gt;&lt;img src="http://img04.iwgc.cn/mpimg/8d83cf30400d526eb422666a4554ae05f73e8b12"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;7大领域专家参与评审&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;235个学术公众号参选&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;31969次网络不记名投票&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;历时88天&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;打造一份科研人不能错过的&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;学术公众号榜单&amp;mdash;&amp;mdash;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;2016年，一批独具特色的学术公众号崭露头角，它们为科研人员提供的研究动态、学术服务和交流平台，受到越来越多科研人员关注，也逐渐成为中国科研生态的一部分。为促进学术传播、传递更多优质科研资源，《环球科学》旗下学术服务平台&amp;ldquo;科研圈&amp;rdquo;发起2016年度学术公众号评选，为研究者甄选垂直领域&amp;ldquo;十大最受关注学术公众号&amp;rdquo;。&lt;br&gt;&lt;br&gt;历时三个月，经过粉丝提名、大规模网络投票、专家团评议环节，十个在专业性、前沿性、传播力、实用性、发展潜力方面有着出色表现的公众号脱颖而出，入选&amp;ldquo;十大最受关注学术公众号&amp;rdquo;。&lt;br&gt;&lt;br&gt;过去一年，它们在跟踪学术前沿、传播科研进展、促进交流的同时，自身也成为中国科研文化的一部分。2017年，我们期待微信平台出现更多优质学术媒体，共同催生科研服务的新生态。&lt;br&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/f1d3a361ce3f3bb1516a0fe91f2a4a99e567aeac"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/60250c86432297028b8326903ea61c3aca392dd9"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/9000f7c3b9ebf1ed3e89529501bdf07e86a38154"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/a4235f04a7e575e630a70f195dce07a4d9548fd4"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/a3f9c566da62a0cdeb77762ec4fb018eabd4a7af"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/d5ebcc4b00ef7718de940c9f3c2d6178c18856b0"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/e6619053b5800d462faa3c8e3531ea46001a92f8"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/32986454fbbb82c712e09630d3207943b60bbcb6"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/6df7b6b87b067661c0d267e0bbcf869701032b62"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/c3ce19c5e31986736702f2bdf9300c160a7bc108"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/8dc02019bf22e449fc7778e08c0ee08674f9f80e"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/4dd1cac5531db3127e67b6f08d9789280ed35b01"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;
</description>
      <pubDate>Thu, 23 Feb 2017 12:29:28 +0800</pubDate>
    </item>
    <item>
      <title>百度将高性能计算引入深度学习：可高效实现模型的大规模扩展（附资源）</title>
      <link>http://www.iwgc.cn/link/</link>
      <description>
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自Baidu Research&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀、黄小天、晏奇&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote style="color: rgb(62, 62, 62); font-size: 16px; white-space: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;神经网络在过去几年中规模不断扩大，训练需要大量的数据和计算资源。为了提供所需的计算能力，我们可以使用高性能计算（HPC）中常见的技术将模型扩展到几十个 GPU，但该技术在深度学习中未被充分利用。这项技术，Ring Allreduce，还能减少不同 GPU 之间的通信时间，从而允许将更多时间用在有用计算上。在百度的硅谷人工智能实验室（SVAIL），我们已经成功地使用这些技术训练了当前最先进的语音识别模型。我们很高兴以库和 TensorFlow 软件补丁的形式推出 Ring Allreduce 的实现。我们也希望通过发布这些库可以使深度学习社区更有效地扩展他们的模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;引言&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在过去的几年中，神经网络已被证明是解决各种问题的非常有效的工具，并在规模和计算需求上快速增长。在用两个 GPU 运行一周并调节了 6000 万参数之后，用于图像识别的 SuperVision 卷积网络在物体识别方面取得了巨大成功 [1]。在 2016 年，对一个有超过 10 亿个参数的网络在 32 个 GPU 上训练了 3 周之后，研究人员在语言建模方面取得了突破性进展 [2]。在 SVAIL，2014 年我们的 Deep Speech 语音识别系统的第一次迭代约有 1100 万个参数 [5]，而一年后的下一次迭代已经增长到 1 亿个参数 [3]。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随着参数数量以及神经网络计算需求的不断增长，在多节点、多 GPU 上进行高效并行的神经网络训练已经变得越发重要，因为等待几个月时间训练大型网络会减慢试验进程，限制进一步开发。在这篇博文中，我们提出了一种来自高性能计算（HPC）领域的技术，并演示如何将其应用于深度学习以在神经网络训练中取得显著的表现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;通信问题&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当在多个 GPU 上并行训练一个神经网络，你必须选择如何将不同的运算分布到不同的 GPU 上。本文中，我们将介绍一种被称为数据并行随机梯度下降（data parallel stochastic gradient descent）的技术。在标准随机梯度下降（SGD）中，梯度下降通过使用数据的子集（minibatch）来完成，它们通过进行多次迭代来遍历整个数据集。然而，在数据并行训练中，每个 GPU 都有一个完整的神经网络模型的副本，并且每一次迭代只会被分配 minibatch 样本中的一个子集。对于每次迭代，每个 GPU 在自己处理的数据上将神经网络向前传播，随后再进行误差反向传播（error backpropagation）来计算相对于神经网络参数的损失的梯度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，GPU 通过相互通信来平均不同 GPU 计算的梯度，将平均梯度应用于权重来获取新权重。GPU 在锁步（lock-step）中都进行迭代，并且一旦一个 GPU 完成了自己的迭代，它必须要等待其它所有 GPU 都完成，这样以保证权重可以被适当地更新。这等价于在单块 GPU 上处理 SGD，但是我们通过把数据分配给多个 GPU 来并行运算，从而获得了计算速度的提升。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当你仅仅只有两块 GPU 和数以兆字节（MB）的参数时，这些 GPU 如何通信可能看上去没什么影响。但是，当你的模型有数十亿个参数时，梯度就会占用千兆字（GB）节的空间（因为每个参数都有一个梯度值），并且你还在同时协调几十个 GPU，那么此时 GPU 之间的通信机制就显得非常重要了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;例如，我们考虑一下可能的最直接的通信机制。每个 GPU 都在 minibatch 上的一个子集里计算一个梯度。然后，每个 GPU 都将该子集的梯度发送给同一个 GPU，让这个 GPU 来计算所有梯度的平均值，最后它会将平均值发送回给其它 GPU。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/2e452cd8c1f1703f8ff30c95b0a6f293f53254c6"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;与单个 reducer GPU 之间的数据传输&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果存在越多需要被发送的数据，那么发送的时间就越长；每个通信信道都有一个最大吞吐量（带宽）。例如，一个好的网络连接可以提供 15MB/s 的带宽，一个千兆以太网连接能提供 125MB/s 的带宽。搭载在高性能计算集群（HPC cluster）上的专业网络硬件（比如 InfiniBand）可以在结点之间提供高达数 GB/s 的带宽。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在数据于单个 GPU 上传输的直接机制（straight-forward mechanism）中，这个 GPU 必须接收来自所有其它 GPU 的所有参数，并且它还要将所有参数发回给所有 GPU。于是，系统中存在的 GPU 越多，通信成本就越大。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在，让我们来评估一下这种通信机制在真实模型上的能力，例如，有一个基于百度语音识别系统 Deep Speech 2 开发的语音识别网络 [3]，它有 3 亿个可训练参数，每个参数占 4 字节（Byte），也就是大概 1.2 GB 的数据量。让我们假设你系统上的网络硬件能够支持 1GB/s 的带宽，那也就是说，如此将你的系统在如上所述的两块 GPU 上并行训练，将会让每次迭代都变慢 1.2 秒。如果在 10 个 GPU 上并行训练，将会让每次迭代都变慢 10.8 秒。随着 GPU 数量的增加，处理每次迭代的时间都会线性增长。即便每个迭代会花个几秒钟，这种在通信成本中的快速线性增长也会使接下来的并行处理变得不现实，它大大降低了你训练的效率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一种替代办法就是放弃训练算法的同步性质，去除所有 GPU 在锁步中遍历梯度下降迭代的约束。然而，尽管这可以使得你模型的并行处理更加简便，去除了这些限制的算法（各种异步随机梯度下降）还是会很难调试，因为有些模型会收敛到欠佳的结果上。不过由于这篇博文意不在此，我们就不在这里考虑它了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不过，我们可以通过使用来自高性能计算领域的分布式简约算法（distributed reduction algorithms）并利用带宽优化环衰减（bandwidth-optimal ring allreduce）来解决通信问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Ring Allreduce&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;上述简单通信策略的主要问题是通信成本随系统中的 GPU 数量线性增长。相反，ring allreduce 是这样一种算法&amp;mdash;&amp;mdash;其通信成本是恒定的，与系统中的 GPU 的数量无关，并且仅由系统中的 GPU 之间的最慢连接来确定。事实上，如果在通信成本上你只考虑带宽这一因素（并忽略延迟），那么 ring allreduce 就是一个最佳的通信算法 [4]（当你的模型较大时，这是一个很好的通信成本估算，你需要在较少的次数内发送大量数据）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Ring Allreduce 中的 GPU 被布置在一个逻辑环路（logical ring）之中。每个 GPU 左右两个各有一个 GPU，并且只从左边的 GPU 接收数据，再把数据发送至右边的 GPU。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/8a9a5dce66dd7ea1dd970e73d342e17faee29947"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;被布置在逻辑环中的 GPU&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;算法的进行分两步：第一步，scatter-reduce；第二步，allgather。在第一步中，GPU 将交换数据，使得每个 GPU 最终都有一个最终结果的数据块。在第二步中，GPU 将交换那些块，使得所有 GPU 最终得到完整的最后结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Scatter-Reduce&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了简单起见，让我们假设目标是以元素方式求和浮点数的单个大数组的所有元素。在系统中有 N 个 GPU, 其中每个 GPU 有一个相同大小的数组。在 allreduce 的最后，每个 GPU 都应该有一个同样大小的包含了原数组中数值的和的数组。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一开始，GPU 把数组分割成 N 个较小的块（其中 N 是 GPU 在环中的数量）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/03e939dc2417a94c2e34f71b807b8d82552dbefc"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;接着，GPU 会执行 N-1 次迭代 scatter-reduce。在每一次迭代中，GPU 将发送其中一个块到右边的 GPU，并从左边的 GPU 接收一个块，把数据累积进该块。在每一次迭代中，被发送的块和被接收的块是不同的。第 n 个 GPU 以发送块 n 和接收块 n &amp;ndash; 1 开始，并从那儿接着向后运行。每次迭代发送的块即是上次迭代所接收的块。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;例如，在第一次迭代中，上图表中的 5 个 GPU 将会发送和接收以下的块：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GPU 发送 接收&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;0 Chunk 0 Chunk 4&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;1 Chunk 1 Chunk 0&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;2 Chunk 2 Chunk 1&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;3 Chunk 3 Chunk 2&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;4 Chunk 4 Chunk 3&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/298b2ddcdd9db2d061c6e93fd30daaee09f61540"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;在 scatter-reduce 的第一次迭代中的数据传输&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在第一次的发送和接收完成之后，每个 GPU 会有一个由两个不同 GPU 中的相同块的总和组成的块。例如，第二个 GPU 上的第一块将是来自第二个 GPU 和第一个 GPU 的那个块中的值的和。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/e0baa9c3f46ce9e6ca0157882a84d46b9bb330a8"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;scatter-reduce 的第一次迭代完成之后的中间和&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在下一次迭代中，进程继续，直到最后，每个 GPU 会有一个块包含所有 GPU 中的那块的所有值的和。下面的图像演示了所有的数据传输和中间结果，从第一次迭代开始，一直持续到 scatter-reduce 结束。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/298b2ddcdd9db2d061c6e93fd30daaee09f61540"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;scatter-reduce 数据传输（迭代 1）&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/5bf339f42ee7eb9bd7cb64b8025159a2599e61e7"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;scatter-reduce 数据传输（迭代 2）&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/e9ca1c34c3073bf201acd3eace03e168c7bf43be"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;scatter-reduce 数据传输（迭代 3）&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/6749cb889fbf498b6ae0b93800bc67c411c92d69"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;scatter-reduce 数据传输（迭代 4）&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/10445f6091c0b46aad4a80d3ce80a5a3a135f079"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;所有 scatter-reduce 传输结束之后的最后状态&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Allgather&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;scatter-reduce 这一步完成之后，每个 GPU 有一个值的数组，其中这些值（每个 GPU 一个块）中的一些是包含来自所有 GPU 贡献的最后值。为了完成 allreduce，GPU 必须交换这些块，从而所有的 GPU 获得所有的必需值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该环路的 allgather 的执行等同于 scatter-reduce（通过 N-1 次发送和接收的迭代），除了不是累加 GPU 接收的值，而是简单地重写块。第 n 个 GPU 通过发送第 n+1 个块和接收第 n 个块开始，并在未来的迭代中一直发送它刚接收的块。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;例如，在我们的 5 个 GPU 设置中的第一次迭代，GPU 会发送和接收以下的块:&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GPU 发送 接收&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;0 Chunk 1 Chunk 0&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;1 Chunk 2 Chunk 1&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;2 Chunk 3 Chunk 2&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;3 Chunk 4 Chunk 3&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;4 Chunk 0 Chunk 4&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/79e4e099a0881d4cebf0ebacc8c3be9f5b590779"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;allgather 的第一次迭代中的数据传输&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在首次迭代完成之后，每个 GPU 将有最终数组（final array) 的两个块。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在接下来的迭代中，该进程会继续运行，一直到最后每个 GPU 都会有整个数组的全部累计值。下面的图像演示了从第一次迭代到 allgather 完成的所有数据传输和中间结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/79e4e099a0881d4cebf0ebacc8c3be9f5b590779"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Allgather 数据传输（第 1 次迭代）&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/339944a59d36b68552fc323fa725a963f83639a6"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Allgather 数据传输（第 2 次迭代）&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/17f43e3b5060b7b6eab15ff1fa5e7ac5cc083a83"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Allgather 数据传输（第 3 次迭代）&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/836afc42d7f093cee4340503603b100396a61ac3"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Allgather 数据传输（第 4 次迭代）&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/d1667b21797b17d1d3718656cbc4835380fe3b1a"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;所有 allgather 完成后的最终状态&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Allreduce 通信成本&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;回到引言中描述的简单的通信算法，通信成本（communication cost）会随 GPU 的数量而线性增长。allreduce 效果良好的主要原因是情况已经发生了变化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在我们描述的系统中，每 N 个 GPU 都会因为 scatter-reduce 而接收 N-1 次值，还为 allgather 接收 N-1 次值。每一次，GPU 都会发送 K/N 个值，其中 K 是指数组中值的总数量，这是在不同 GPU 上相加得到的。因此，每个 GPU 的传入和传出数据总量为：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;被传输的数据=2(N&amp;minus;1)N&amp;sdot;K&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其独立于 GPU 的数量，这是很关键的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因为在离散的迭代中，所有的传输都是同时发生的，所以 allreduce 的速度受限于该环路中相邻 GPU 之间的最慢（最低带宽）的连接。为每个 GPU 选择合适的邻居，该算法能在所有 allreduce 上做到带宽最优并且可能是最快的算法（假设相比于带宽，其延迟成本可以忽略不计）[4]。总的来说，如果在一个节点上的所有 GPU 都临近该环路中的其它 GPU，那么该算法可以得到最好的效果；这能最小化网络连接的数量，从而显著增加这种 GPU-GPU 连接的有效带宽。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;将该 Allreduce 应用于深度学习&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;ring allreduce 是高性能计算领域内一个众所周知的算法，但在深度学习领域内的应用相对较少。在我们的实验室中，我们已经成功地将这种工具用作我们所有的数据并行训练的基础，让我们可以将训练有效地扩展到十余个 GPU。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了最小化通信负载，我们可以利用神经网络的结构。在每一次迭代中，每一个 GPU 都会运行前向传播来计算错误，然后再运行反向传播来为该神经网络的每一个参数计算梯度。反向传播是从输出层开始计算梯度，然后向输入层移动，这意味着输出层参数的梯度在更早的层的梯度之前是显著可用的。因为该 allreduce 能一次操作该网络的参数的一个子集，所以我们可以在其输出层参数上开始 allreduce，同时还能计算其它梯度。这样做使得该计算可以和反向传播步骤中的其它计算一起进行，所以可以减少每个 GPU 用于等待通信完成的总时间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;比如，假设有一个类似于 [2] 中的语言模型，但带有大约 3 亿个可学习的参数（因此总梯度大小为 1.2 GB）。使用 allreduce，每个 GPU 必须发送和接收大约 2.4 GB 的数据。使用一种 CUDA-aware MPI 实现（比如 OpenMPI），我们可以使用 GPUDirect RDMA 在 GPU 之间传输数据，带宽大约为 10 GB/s；但是，在我们的集群中的节点之间的连接更慢&amp;mdash;&amp;mdash;Infiniband 提供了大约 6 GB/s 的带宽。因为 Infiniband 连接是这里的限制因素，那么单次迭代就需要大约&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;每秒 2.4 GB/6.0 GB &amp;asymp; 每次迭代 400 ms&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因为更深入到网络中的层一开始就有可用的梯度，所以我们可以在整个反向传播通过完成之前就开始进行数据传输，所以其真正的开销可能会少于 400 ms；通信和计算之间的这种重叠可能会随被优化的神经网络的本质而发生改变。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们实现了之前提到的语言模型，并且在我们从单个 GPU（没有通信开销）扩展到 40 个 GPU 时测试了每次迭代所用的时间。这 40 个 GPU 被布置成了 5 个节点，每个节点 8 个 GPU，它们之间通过 Infiniband 连接。我们以 32 的批大小对该语言模型运行了 300 迭代，然后计算了其每秒所处理的样本的数量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/8a8cc4abeb192761ca7b5b9da99aa49ecb2def20"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;对于一个有 3 亿个参数的语言模型，每秒所处理的样本的数量会随同时进行同步训练的 GPU 的数量而线性增长。&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如你所见，整个系统的吞吐量会随 GPU 的数量线性扩展；但超过一个特定的点之后，增加更多 GPU 并不会导致每次迭代的显著减速。在 40 个 GPU 上运行该模型的时间是每次迭代 650-700 ms，而在单个 GPU 上该数字为大约 370 ms。因为据我们估计通信大约需要 400 ms，所以我们通过将反向传播和数据传输重叠起来进行而为每次迭代节省了 70-120 ms 的时间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;总结&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;来自于高性能计算领域的 Ring Allreduce 技术让我们可以高效地在跨多设备和多节点的神经网络上对梯度进行平均。通过在训练过程中使用这种带宽优化算法，你可以极大地减少通信负载并扩展到远远更多的设备，同时仍能保留同步随机梯度下降的确定性和可预测的收敛性。该算法并不特定于任何网络架构和深度学习框架，能够为数据并行训练的效率提供显著的和直接的好处，同时其部署实现也是相当直接和容易的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了让你能更轻松地使用这些技术，今天我们也发布了一个演示该 allreduce 算法的 C 语言库：，你可以将其嵌入到任何使用 MPI 的应用中。此外，我们也已经将该 allreduce 整合到 TensorFlow 中（可在 tensorflow.contrib.mpi 模块获取文档）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;C 语言 baidu-allreduce：https://github.com/baidu-research/baidu-allreduce&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;TensorFlow-allreduce：https://github.com/baidu-research/tensorflow-allreduce&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们希望其它深度学习框架也能在合适的地方使用类似的技术；通过使用这些工具，你可以轻松有效地将你的神经网络模型扩展到许多机器，而且不论你选择的是什么框架。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;参考文献&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;1.Krizhevsky, Alex, Ilya Sutskever, and Geoffrey E. Hinton.「ImageNet classification with deep convolutional neural networks.」Advances in neural information processing systems. 2012.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;2.Jozefowicz, Rafal, et al.「Exploring the limits of language modeling.」arXiv preprint arXiv:1602.02410 (2016).&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;3.Amodei, Dario, et al.「Deep speech 2: End-to-end speech recognition in english and mandarin.」arXiv preprint arXiv:1512.02595 (2015).&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;4.Patarasuk, Pitch, and Xin Yuan.「Bandwidth optimal all-reduce algorithms for clusters of workstations.」Journal of Parallel and Distributed Computing 69.2 (2009): 117-124.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;5.Hannun, Awni, et al.「Deep speech: Scaling up end-to-end speech recognition.」arXiv preprint arXiv:1412.5567 (2014).&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;February 21st, 2017&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文链接：&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;a style="font-size: 12px; color: rgb(136, 136, 136); text-decoration: none;"&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;http://research.baidu.com/bringing-hpc-techniques-deep-learning/&lt;/span&gt;&lt;/em&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Wed, 22 Feb 2017 12:55:17 +0800</pubDate>
    </item>
    <item>
      <title>Science | 量子计算机的首次性能测评，IBM成绩落后</title>
      <link>http://www.iwgc.cn/link/</link>
      <description>
&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自Science&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;strong&gt;作者：Gabriel Popkin&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李泽南、蒋思源&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote style="color: rgb(62, 62, 62); font-size: 16px; white-space: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/blockquote&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;在一项新研究中，两种使用完全不同技术的量子计算机在同一个算法任务中进行了对决。结果显示，其中一种更加可靠，而另一种运算速度更快。但科学家们认为，这项研究最重要的意义在于：第一次有人在完全相同的任务场景中对不同种类的量子计算机进行了比较。读者可点击阅读原文下载此论文。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「量子计算机技术一直没有发展成熟。长久以来，我们一直不能真正地把两个只含有五个量子比特的原型机拿来进行性能对比，」牛津大学的物理学家 Simon Benjamin 说道。「最近这一研究的出现证明了量子计算技术又前进了一步。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这项研究中，其中一台计算机来自马里兰大学的 Chris Monroe 团队（ionQ），该机器使用五个镱离子，以电磁阱和激光进行操纵。另一台计算机来自于 IBM，它的核心是五个超导金属环路，通过微波信号操控。IBM 的计算机也是目前世界上唯一一种可以由普通用户进行在线编程的量子计算机。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这两种计算机都不具备堪比普通架构计算机的运算性能，但它们都证明了量子计算的思路具有可行性。量子计算机的基本位&amp;mdash;&amp;mdash;量子比特的表示不像普通计算机只有 0 或 1，它多出了一种「叠加态」，可以同时是 0 和 1。在 Monroe 的量子计算机里，每个量子比特都由一个离子代表，其中电子的能级可以用来表示 0、1 或「叠加态」三种状态。而在 IBM 的超导环路中，电流可以以两种不同的强度循环，或同时在两种强度上循环&amp;mdash;&amp;mdash;这也构成了量子计算的三种状态。在目前的基础上，量子计算机可以叠加更多的量子比特，由于原理上的先进性，量子计算机具有超越普通架构的潜力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但量子位的状态是脆弱的，来自外界的扰动可以轻易地让叠加态坍缩回 0 或 1。因此在运行时，量子计算机必须能够小心地保证叠加态能够存在一段时间。在研究人员的测试中，这两台量子计算机都具有大约 97% 的双量子比特「门精度」&amp;mdash;&amp;mdash;成功计算双量子比特逻辑运算的概率，这意味着它们仍然难以用于执行现实世界的任务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/40756199c8246b168ce0415fd4c3c2519d09e7e2"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;（a）：IBM 的超导环路系统；（b）：马里兰大学的镱离子系统。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了测试设备的性能，Monroe 研究团队在每个设备上运行一组标准化算法，并对比其输出结果。离子计算机（The ion computer）在每一个测试中都能得到更正确的答案。而对于特定训练，对比非常具有戏剧性：离子计算机能达到 77.1% 的成功率，而超导计算机（the superconducting computer）的成功率仅仅只有 35.1%。科学家上一周在 arXiv 上发表了对比结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Monroe 认为，这种性能差异并不是从量子比特本身而引发的，这些差异是从连接量子比特的方法而来。在 Monroe 的架构中，每一个离子都能和其他任何一个离子产生交互，所以很多任务所需要的操作次数大大降低了，且叠加态（superposition）崩溃的机会也会相应降低。相比之下，IBM 计算机每四个超导回路连接一个中枢，所以超导计算机需要额外的操作在回路之间交换信息。因为没有任何操作是 100% 可靠的，所以整体的成功率就随着操作次数的增加而降低。「连通性是关键，」Monroe 说道。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;物理学家 Jerry Chow 领导着 IBM 的量子计算研究团队，他们的实验室位于纽约公司的 Yorktown Heights。他认同 Monroe 对于连接性的看法。但是他认为 IBM 计算机的量子比特叠加态会持续更长时间且更加「连贯」，这也就意味着从长远角度来看，计算机较低的连接性不一定会拖累它的整体的可靠性。他指出「如果有足够的连贯性，那么算法全部操作的时间就变得不那么重要了。」他还指出 IBM 的在线计算机现在比 Monroe 团队测试时拥有更多的量子比特连接，这将使得超导计算机的性能很可能至少是接近于离子计算机的。目前，上述两个实验室正在开发更可靠、拥有更多量子比特的下一代设备。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Benjamin 认为，该研究对比了两种通向量子计算这一「超前」方法的「原始形式」。由超导环路或离子构成的实用型量子计算机需要成千上万的量子位，并且这些量子位之间的互联网络会变得更加复杂。他认为，即使离子计算机目前拥有更高的可靠性，超导计算机理论上还是运行地更快。IBM 量子计算机在 250 到 450 纳秒内就能完成一个双量子比特的操作，这比离子计算机快了 1000 倍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该研究同样为量子软件开发者（如微软研究员 Krysta Svore）提供了新思路。理解量子计算机的特定架构如何影响未来优化算法的性能是很重要的，这将是开启实用量子计算的第一步。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;论文：Experimental Comparison of Two Quantum Computing Architectures&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/f26955de619093e7e2c735fe77c95d942c0030da"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：&lt;/span&gt;&lt;span&gt;我们在两个目前最先进，但架构不同的 5 量子比特的计算机上运行了一系列算法。一种是具有有限连接性的超导转导装置&amp;mdash;&amp;mdash;它可以被公众接触（IBM），另一种是完全连接的离子阱系统（ionQ）。即使两种系统的量子交互方式不同，但它们仍可以在对底层硬件不知情的情况下进行编程，这允许了我们对不同的物理系统进行相同的量子算法硬件性能对比。我们的实验表明，更具连通性的量子比特系统显然能使算法运算速度更快。虽然目前的量子系统还不够强大，无法匹敌常规架构的计算机，但本实验揭示了量子计算机未来发展需要解决的重要问题，如量子比特连通性与门表达性。此外，我们的实验结果也显示，为特定的硬件架构设计专有优化的量子应用是未来量子计算机成功的最重要因素。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文链接：http://www.sciencemag.org/news/2017/02/split-decision-first-ever-quantum-computer-faceoff&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Wed, 22 Feb 2017 12:55:17 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 谷歌结合机器学习技术「摘掉」VR 头盔，让共享体验更真实</title>
      <link>http://www.iwgc.cn/link/</link>
      <description>
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自Google blog&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;strong&gt;作者：Vivek Kwatra、Christian Frueh、Avneesh Sud&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：微胖、曹瑞&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;iframe allowfullscreen="" class="video_iframe" data-vidtype="1" frameborder="0" height="417" src="https://v.qq.com/iframe/preview.html?vid=g0377jl9k9u&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0" width="556"&gt;&lt;/iframe&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虚拟现实能带来很赞的沉浸式体验，提供全新看待世界的方式，还能帮助我们探索新奇的环境，无论它是现实的抑或想象的。不过，与物理现实相比，与他人共享这些体验却很难，因为虚拟现实头盔很难让用户看清共享对方的完整面部。&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;混合现实（Mixed Reality）可以减轻一些不连贯，因为它可以在一个二维视频格式中实现 VR 用户虚拟文本的共享，其他用户可以感受到该用户的虚拟体验。即使混合现实能让共享变得容易，但是，头盔仍然盖住了面部表情和目光注视，这严重妨碍了完整的沉浸体验，也没办法在虚拟现实中看到整个人。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌 Machine Perception 研究人员与 Daydream Labs 以及 Youtube Spaces 合作，看看怎么解决这个问题，能否通过虚拟地「揭开」头盔，看到用户的脸，进而创造出一种现实般的看穿效果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/7680bfa8b9b7d0d6e50c66dac3e91099680bb36d"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;一个绿色屏幕前的虚拟现实用户与虚拟背景融合起来，生成一种混合现实：传统的混合现实输出会挡到用户面部，但是我们的输入会让你看到脸。注意，如何用标记修改头盔，方便追踪。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们的办法结合了 3D 视觉、机器学习以及图形技术，最好在增强 MR 视频中加以说明（我们在 Google-VR blog 中也讨论过）。有三个部分：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;动态面部模型捕捉&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们技术的核心思想是，将一个用户面部的 3D 模型作为被隐藏面部的代理。这个代理被用来合成 MR 视频中的面部，因此，可以创造摘掉头盔后的效果。首先，我们使用所谓的注视依赖动态外观（gaze-dependent daynamic appearance）技术，捕捉到一个用户的个性化 3D 面部模型。初次校准需要用户做在一个色彩+深度摄像头（a color+depth camera）和一个监视器前面，然后，眼睛追踪监视器上的标记。我们使用这种一次校准程序（one-time calibration procedure）&amp;mdash;&amp;mdash;通常耗时不到一分钟&amp;mdash;&amp;mdash;来获取用户的 3D 面部模型，还要学习一套将外观图像（或文理质地）映射到不同注视方向和眨眼状态上的数据集。这个目光注视数据集（gaze database）能让我们在合成任何想要的注视状态时，显著改善面部外观，让合成表情更加自然生动。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/ad250d9384210ae1d44227b6cb57156333ac334b"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;左边，当她用眼睛跟踪显示器上的标记时，摄像头捕捉到了用户面部。右边，我们展示了重新建构 3D 面部模型的动态性质：移动或点击鼠标，我们就能模拟注视和眨眼状态。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;校准和对齐&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;创造混合现实视频需要一个专门的装备，包括一个外部摄像头，可校准并与头盔同步。这个摄像头用来捕捉绿色屏幕前虚拟现实用户的视频流，然后将用户剪影与虚拟世界混合起来，生成最终的混合虚拟现实视频。其中，很重要的一个环节就是准确估计测摄像头和头盔的对齐系统之间的校准（固定的 3D 转换，fixed 3D transformation）。这些校准技术通常包括显著的人工干扰，完成需要多个步骤。通过给头盔前端加上一个物理标记并在 3D 中进行虚拟跟踪，我们可以简化整个过程，因为这可以实现自动优化校准参数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因为「摘掉」了头盔，所以，我们需要将 3D 面部模型和摄像头流中的面部可见部分对齐，实现无缝对接。这一对齐的合理代理就是将面部模型放到头盔后面。上面描述的校准，连同虚拟现实头盔跟踪，能提供充足的信息来决定如何放置，这样，我们就能通过提供虚拟面部，修改摄像头流（camera stream）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;合成和渲染&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在处理完对齐之后，最后一步涉及到生成 3D 脸部模型适当渲染，要与摄像头流中的内容保持一致。通过将我们的动态注视数据库和 HTC Vive 头戴式设备结合，重现用户真正的眼睛注视（eye gaze），HTC Vive 的眼球追踪技术是由 SMI 公司提供。眼球追踪器产生的图像缺乏充分细节来直接再生被挡面部区域，但是，非常适合提供细致的注视信息。使用追踪器实时注视数据，我们合成了一个能够精确代表用户注意力和眨眼的面部代理。在运行过程中，会搜索预处理步骤时捕捉到的注视数据库，找寻最符合查询注视状态的面部图像，同时也兼顾了美学，例如时空光滑度（temporal smoothness）。另外，为了解决已获取的注视数据组与运行过程时面部之间的亮度变化不同，我们使用了色彩校正和羽化，让合成面部区域与其他面部区域匹配。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人们对面部的失真成分高度敏感，即使是被遮挡面部上非常小的瑕疵，也会让人感觉不自然，分散人的注意力。这种现象就是恐怖谷（Uncanny Valley）理论。为了减轻这一问题，我们不会完全移除头戴式设备，我们已经选择了一种用户体验，通过合成色彩校正过的面部代理与透明头盔，这种体验类似「潜水镜效应」。提醒体验者头盔的在场有助于人们避免恐怖谷体验，也能让我们的算法稳健，不受对齐和色彩校正中一些小误差的干扰。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种修正后的摄像头流，源自潜水镜般透明头盔，由于用户面部可见，还再造了真实的注视状态，因此，接下来可以与虚拟环境融合起来，生成最终的虚拟现实影像。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;结果和扩展&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们已经使用头戴设备去除技术来增强混合现实，这让媒介不仅将 VR 用户的互动传递给虚拟的环境，还能够以一种自然有力的方式展示他们的面部。下面的例子就展示了一位艺术家对我们这项科技的应用，她使用谷歌 Tilt Brush 在虚拟环境中进行创作：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/2ca7058c36dd8e184bbb48fd9d15531a5a763b35"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;一位艺术家运用谷歌的 Tilt Brush 在 3D 环境中进行创作，在混合现实中展示。上面是传统的混合现实结果，图中的人脸被隐藏在头戴式设备之后。下方的是我们的结果，在这张图中，整个脸部和眼睛都可以看到，这种体验更加的自然有趣。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们已经展示了该技术的潜力，它的应用已经延伸到了混合现实之外。头戴式设备去除技术将会增强虚拟现实本身的交流和社会互动，会产生很多多样的应用，例如虚拟现实视频会议、多人虚拟现实游戏、和朋友家人一起探索等。在照相写实主义（Photographic Realism）的鼓舞下，从完全空白的头戴式设备，到可以看见 VR 用户的面部是虚拟现实世界中一个重大的转折，我们非常高兴成为这一转折中的一部分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;原文链接：&lt;/span&gt;&lt;/em&gt;&lt;em&gt;&lt;span&gt;https://research.googleblog.com/2017/02/headset-removal-for-virtual-and-mixed.html&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Wed, 22 Feb 2017 12:55:17 +0800</pubDate>
    </item>
    <item>
      <title>学界 | 不同硬件不同网络，横向对比五大深度学习框架（附论文第七版）</title>
      <link>http://www.iwgc.cn/link/</link>
      <description>
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自arXiv.org&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote style="color: rgb(62, 62, 62); font-size: 16px; white-space: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/blockquote&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;2016 年 8 月，香港浸会大学褚晓文团队的研究者发表了一篇论文，对业界主流深度学习工具进行了基准评测 ，之前机器之心也报道了&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722774&amp;amp;idx=4&amp;amp;sn=e38ed07e2a47b60c37d4679d66710410&amp;amp;chksm=871b15a8b06c9cbee0d1daa51d3e4a003a3a8d363da3b8a935c59fab87acb36d0812ae63bf25&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722774&amp;amp;idx=4&amp;amp;sn=e38ed07e2a47b60c37d4679d66710410&amp;amp;chksm=871b15a8b06c9cbee0d1daa51d3e4a003a3a8d363da3b8a935c59fab87acb36d0812ae63bf25&amp;amp;scene=21#wechat_redirect" target="_blank"&gt;该论文的第六版更新&lt;/a&gt;（把 MXNet 加入了评估对象内）。近日，该论文又放出了第七版更新，此次更新修正了 MXNet 中的 ResNet-50 配置；增加了在 TensorFlow 中多 GPU 更快速的实现 ResNet-56。读者可点击阅读原文下载此论文。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;摘要&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深度学习已被证明是一种可成功用于许多任务的机器学习方法，而且它的广泛流行也将很多开源的深度学习软件工具开放给了公众。训练一个深度网络往往是一个非常耗时的过程。为了解决深度学习中巨大的计算难题，许多工具利用了多核 CPU 和超多核 GPU 这样的硬件特性来缩短训练时间。但是，在不同的硬件平台上训练不同类型的深度网络时，不同的工具会有不同的特性和运行性能，这让终端用户难以选择出合适的软件和硬件搭配。在这篇论文中，我们的目标是对当前最先进的 GPU 加速的深度学习软件工具（包括：Caffe、CNTK、MXNet、TensorFlow 和 Torch）进行比较研究。我们在两种 CPU 平台和三种 GPU 平台上使用三种流行的神经网络来评测了这些工具的运行性能。我们做出了两方面的贡献。第一，对于深度学习终端用户，我们的基准评测结果可用于指导合适的软件工具和硬件平台的选择。第二，对于深度学习软件开发者，我们的深度分析为进一步优化训练的性能指出了可能的方向。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;实验数据展示地址：http://dlbench.comp.hkbu.edu.hk/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;项目开源地址：https://github.com/hclhkbu/dlbench&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1 评测软件版本&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/d814e6f4c87d331f6f857d33ab2039c2c40362bd"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2 评测中的神经网络设置&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/a537270b8b0cc3e3c8c2fad96a57aac698e9777c"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;全连接网络&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;卷积神经网络: AlexNet、ResNet&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;循环神经网络&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3 评测硬件配置&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/64be6e7f449b9943ac4a4e858159a956c59ba786"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;评测硬件配置&amp;mdash;&amp;mdash;并行数据&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/909426890de87d7610cc19141202ebb68d861d93"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4 实验概览及结果&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下表给出了不同的网络、框架和硬件组合下进行的实验：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/7686fc18191e98abfab909791f6ae2d09474c73d"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;实验结果概览&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下表给出了实验结果比较数据，更清晰的结果可在上文给出的地址查看。这里给出的数据是实验的速度比较，比较了每个 mini-batch 处理所需的时间（单位：秒）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/4ddec7f84bb17492e2f64ceb53a493bdbc3cfed9"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下表给出了在单个 GPU 和多个 GPU 上的实验比较数据，比较了每个 mini-batch 处理所需的时间（单位：秒）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/a6be5dd27b436a25d7da3a94a52d6572d345e3d4"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4.1. CPU 评测结果&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;根据我们之前的研究 [31]，在 CPU 平台上测试特定的 mini-batch 大小 d 的实验能够获得最好的运行时间表现。不同网络使用的 mini-batch 的大小在表 9 中有展示：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/329126776356b1d31a46f6f1c9d0df01955d9d19"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/f444cc25358d7e18baa40c3c31a6a42c8ffd0645"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 2：FCN-S 在 mini-batch 大小为 64 时在 CPU 平台上的表现的比较（越低越好）&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/ee0d6e24be16a3944f75f218d941234ee78c092a"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 3：AlexNet-S 在 mini-batch 大小为 16 时在 CPU 平台上的表现的比较（越低越好）&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/55d86bd8d9617fabb296c50f2dfacc6c62372d4e"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 4：ResNet-50 在 mini-batch 大小为 16 时在 CPU 平台上的表现的比较（越低越好）&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/a3ae1acccb29301b2f3dac76407b644c405a508c"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 5：FCN-R 在 mini-batch 大小为 1024 时在 CPU 平台上的表现的比较（越低越好）&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/f4b9e97c91180c61390f00168365cf6a42cdd1e6"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 6：AlexNet-R 在 mini-batch 大小为 1024 时在 CPU 平台上的表现的比较（越低越好）&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/7c4af7235ae17d724bed1c987ad8d23edb02ef39"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 7：ResNet-R 在 mini-batch 大小为 128 时在 CPU 平台上的表现的比较（越低越好）&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/0c7e104c62560cd5f406e4a4aa9f0ea06b8f4b40"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 8：LSTM 在 mini-batch 大小为 256 时在 CPU 平台上的表现的比较（越低越好）&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4.2. 单 GPU 卡评测结果&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在单 GPU 卡的对比上，我们也展示了不同 mini-batch 大小的结果，从而演示 mini-batch 大小对表现的影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4.2.1. 合成数据（Synthetic Data）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/c0103a16797b848f2444a0d5604b42b5aa1d1351"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 9：在不同 GPU 平台运行 FCN-S 时，不同框架的表现对比&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/6f6ed9592396c0e164058293ba8153e72a0a930e"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 10 ：在不同 GPU 平台运行 AlexNet-S 时，不同框架的表现对比&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/b80e5056a50de172a2b12dc486d3e7f67af7c61e"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 11：在不同 GPU 平台运行 ResNet-50 时，不同框架的表现对比&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4.2.2. 真实数据（Real Data）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/ab65c678d9616527d75126e2216613db45a9ad50"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 12:在不同 GPU 平台运行 FCN-R 时，不同框架的表现对比&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/7f82142aafa51eeab743c86e76c6a89448ebb1f9"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 13：在不同 GPU 平台运行 AlexNet-R 时，不同框架的表现对比&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/4c44828d8d86833daddfbc523e5f8bc9c2d50111"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 14：在不同 GPU 平台运行 ResNet-56 时，不同框架的表现对比&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/1967fe434598c029324080914fe386edd35bd485"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 15：在不同 GPU 平台运行 LSTM 时，不同框架的表现对比&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4.3. 多 GPU 卡评测结果&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;FCN-R：在我们的测试中，mini-batch 的大小设置为 4096，结果如图 16 所示。在图 16(a) 中，我们可以看到 Caffe、CNTK 和 MXNet 的速度非常接近单 GPU 的情况；而在 TensorFlow 和 Torch 上的表现则相对好一点。当 GPU 数量翻倍时，CNTK 和 MXNet 的可扩展性最好，均实现了约 35% 的提速，Caffe 实现了大约 28% 的提速，而 Torch 和 TensorFlow 较差，只有约 10%。当我们把 GPU 数量从 2 个增加到 4 个时，TensorFlow 和 Torch 没有实现进一步的提速。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/09e0b44088bf0447fc393dd896d89310bdb87ef0"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 16：(a) FCN-R 在多 GPU 平台上的性能比较，(b) 在多 GPU 平台上的收敛速度&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/4e69dd13685fa466a93b522395275058e7c7bc4a"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 17：(a)AlexNet-R 在多 GPU 平台上的性能比较，(b) 在多 GPU 平台上的收敛速度&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/e1e017223f42de5b79529d61b8355b38701e5bc2"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 18：(a)ResNet-56 在多 GPU 平台上的性能比较，(b) 在多 GPU 平台上的收敛速度&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;结论&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本研究旨在对比现代深度学习软件工具的运行性能，测试它们在不同类型的神经网络和不同的硬件平台上的执行效率。我们的实验结果表明，目前所有经过测试的工具都可以很好地利用 GPU，和使用 CPU 相比有着很大优势。然而，没有任何一个工具可以在所有方面胜过其他软件工具，这意味着也许存在进一步优化性能的方向。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在未来的研究中，首先，我们会将更多的深度学习软件工具（如百度的 Paddle）和硬件平台（如 AMD 的 GPU 和英特尔 Xeon Phi）纳入这项基准研究。其次，我们计划评估在高性能 GPU 集群上这些工具的可扩展性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Wed, 22 Feb 2017 12:55:17 +0800</pubDate>
    </item>
    <item>
      <title>公告｜机器之心完成 Pre A 轮融资，今日头条领投，源码、讯产投及晨兴跟投</title>
      <link>http://www.iwgc.cn/link/</link>
      <description>
&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/d115a6434e65917d44a1f8fe1e201f5c646b8e01"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;近日，机器之心完成 Pre A 轮融资，本轮融资由今日头条领投，源码资本、讯产投和晨兴资本跟投。接下来，机器之心将与这四家战略投资者以及此前的天使投资方联想之星 Comet Labs 一起，在全球人工智能领域的内容、投资、产业服务、项目孵化和技术研究等方面展开深入合作，具体合作事宜将会阶段性公布。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器之心是国内首家系统性关注人工智能的科技媒体，在过去三年时间里，机器之心一直恪守正确的内容价值观和原则，坚持提供高质量内容，使人工智能从业者及爱好者能够真正获取有价值的信息及学习知识，我们希望借助优质内容的力量来正确引导甚至影响人工智能行业的发展，而非刻意炒作 AI 概念或者进行不负责任的内容输出。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;也正因如此，机器之心得到了国内外众多技术专家、科技公司高管和人工智能从业者的高度认可，机器之心也积累了广泛的影响力和知名度，形成了富有特色的自我品牌。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器之心对邓力、吴恩达、Richard Sutton、杨强、黄学东、MXNet 团队、Greg Corrado、Lawrence Carin、 Jack Gallant、Randy Schekman、洪小文、王永东、俞栋、刘庆峰、胡郁、林元庆、戴文渊、孙剑、李磊等人工智能专家做过深度专访，对 NIPS 2016 、CDLM 2016 等进行了现场深度报道。也获得了「微软中国 2016 年度媒体奖」、今日头条 2016「年度科技头条号」、「虎嗅 2015 年度十佳作者」和「今日头条 2015 年度最佳自媒体」等荣誉，与 O'Reilly 一起成为 AI Frontiers 合作媒体，也是唯一一家受邀参加神经科学顶级大会 Brain Froum 2016 的中文媒体。同时，机器之心也是中国人工智能学会「吴文俊人工智能科学技术奖」战略合作伙伴。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前机器之心在各平台拥有共计 50 万高质量用户，微信端日均 PV 5 万，活跃用户 6 万人。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在活动方面，机器之心举办了「北美七大城市人工智能系列活动」、「CVPR 2016 华人学者聚会」等活动，覆盖了近千名优秀海外人工智能人才。在国内打造了人工智能精品线下活动「Interface」，协办了「BOT 数据应用竞赛」、「中国人工智能产业大会暨吴文俊奖颁奖典礼」等多场重要活动。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在媒体业务之外，机器之心一直深耕人工智能领域的产业服务，为各类参与者提供包括投融资对接、产业上下游需求匹配、人才招聘和国际合作等多项服务，并积累了多个成功案例。同时，已经完成了孵化器、基金和数据开放平台的筹备工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前，机器之心拥有完善且专业的国际化团队，建立了覆盖全球所有人工智能核心区域和华人技术人才的渠道和网络，与世界范围内上百家科技巨头、实验室、研究机构、孵化器和创业公司都建立了紧密合作关系，这将使我们源源不断的获取优质内容、创业项目、人才和合作机会等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器之心深知自己的定位和使命，并坚守自己的原则、品味和价值观，媒体业务将一如既往的生产更多高质量内容，并推出视频和行业报告等新型内容产品，永远朝着「经济学人」、「彭博」和「纽约客」这样的业界榜样而努力，希望真正成为一家国际化的严肃科技媒体；在产业方面，机器之心将一直定位于「服务者」，通过自身踏实的积累和具体落地的业务，审慎谦卑的为各类人工智能参与者提供服务，以帮助他们解决实际问题，而不会去做（也不可能做到）一个所谓的「AI 平台」或「AI 生态」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;领投方今日头条表示，今日头条一直致力于大规模运用人工智能技术，根据用户兴趣为用户个性化匹配推荐内容，在信息分发效率上不断寻求优化和提升。我们相信未来 AI 将更为深远地影响各行各业，给人们的生活带来更大的便利。机器之心作为人工智能领域的重要产业媒体，创造生产了大量 AI 领域的优质内容，在产业界、学界和社会发挥着重要的连接作用。未来希望今日头条能携手机器之心，通过深度合作，更广泛地促进人工智能领域信息、资源、资本和人才方面的交流合作，进一步助推人工智能产业整体更好的发展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;源码资本一直关注人工智能结合实际应用的多个领域做投资布局，具体而言：在信息领域，如今日头条，就在利用 AI 做信息分发；金融领域，如趣店、用钱宝，基于人工智能做个人信贷；医疗领域，机器人医生的辅助诊断等。对于本次投资，源码资本认为，「智能+」在不断的改造这个社会，从长期看，技术会渗透到人类生活、生产的各个方面，趋势不可阻挡。相信机器之心的专业报道和产业服务有助于提升产业内信息、人才、资金、资源的流动速度和效率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;晨兴资本认为，机器之心深耕 AI 领域，在产业和学术两方面都具有极高的敏感度，未来将会在汇集行业人才、资讯、资本上有更深入的发展。晨兴一直致力于携手优秀的创业者创建伟大的科技企业，AI 是晨兴长期关注的重点领域，先后在早期投资了地平线机器人、图普科技、追一科技和康夫子等项目。晨兴一直寻求在数据和商业两方面都有闭环能力、由算法驱动的新创业机会。未来晨兴资本将携手机器之心，共同探索 AI 底层技术驱动下的新产品、新市场。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，讯产投代表胡郁表示：「伴随着中国乃至世界人工智能的不断发展，机器之心在过去的几年当中深入到科技与产业的核心，已经成为连接中国人工智能科技产业界与世界前沿的桥梁。科大讯飞在创业以来的十八年中以『在中国用人工智能改变世界』为自己的座右铭，与机器之心在核心价值观方面高度一致。我们期待携手机器之心在将来中国人工智能引领世界的路程中一同努力，共创辉煌！」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器之心正朝着正确的方向狂奔，我们期待更多国内外的优秀人才加入，详细请查看机器之心「&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722163&amp;amp;idx=5&amp;amp;sn=ffdda8d22220932d4227df95d5c9731e&amp;amp;chksm=871b0b0db06c821bd2d86b40d2a38c9d881f814ca0cc0b887eb892382a5cb3ad9e560ade759f&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722163&amp;amp;idx=5&amp;amp;sn=ffdda8d22220932d4227df95d5c9731e&amp;amp;chksm=871b0b0db06c821bd2d86b40d2a38c9d881f814ca0cc0b887eb892382a5cb3ad9e560ade759f&amp;amp;scene=21#wechat_redirect" target="_blank"&gt;全球人才招聘&lt;/a&gt;」。&lt;/span&gt;&lt;/p&gt;
</description>
      <pubDate>Wed, 22 Feb 2017 12:55:17 +0800</pubDate>
    </item>
  </channel>
</rss>
