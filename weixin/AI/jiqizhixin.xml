<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>一文读懂机器学习、数据科学、人工智能、深度学习和统计学之间的区别</title>
      <link>http://www.iwgc.cn/link/</link>
      <description>
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自datascience central&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：&amp;nbsp;Vincent Granville&amp;nbsp;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀 、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote style="color: rgb(62, 62, 62); font-size: 16px; white-space: normal; line-height: 25.6px; background-color: rgb(255, 255, 255); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/blockquote&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;在这篇文章中，数据科学家与分析师 Vincent Granville 明晰了数据科学家所具有的不同角色，以及数据科学与机器学习、深度学习、人工智能、统计学等领域的区别。这些概念的区别也一直是人工智能领域热烈讨论的一个话题，Quora、多个技术博客都曾有过解答。机器之心之前编译的一篇文章《&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717606&amp;amp;idx=4&amp;amp;sn=b94b58d4fe75c1a1e42274720a269a99&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717606&amp;amp;idx=4&amp;amp;sn=b94b58d4fe75c1a1e42274720a269a99&amp;amp;scene=21#wechat_redirect" target="_blank"&gt;人工智能、机器学习、深度学习，三者之间的同心圆关系&lt;/a&gt;》也对此问题进行了探讨，但似乎业内还未能给出一个权威的、令所有人信服的回答。如果对这篇文章中的观点不认同，欢迎大家留言讨论。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这篇文章中，数据科学家与分析师 Vincent Granville 明晰了数据科学家所具有的不同角色，以及数据科学与机器学习、深度学习、人工智能、统计学、物联网、运筹学和应用数学等相关领域的比较和重叠。Granville 介绍说，由于数据科学是一个范围很广的学科，所以他首先介绍了在业务环境中可能会遇到的数据科学家的类型：你甚至可能会发现你自己原来也是某种数据科学家。和其它任何科学学科一样，数据科学也可能会从其它相关学科借用技术；当然，我们也已经开发出了自己的技术库，尤其是让我们可以以自动化的方式（甚至完全无需人类干预）处理非常大规模的非结构化数据集的技术和算法，进而实时执行交易或进行预测。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/5d821d6aacccbd8f60cf0ce71b63815ae928bf9c"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1. 数据科学家具有哪些不同类型？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;要更详细地了解数据科学家的类型，可参阅文章：http://suo.im/28rlX1 和 http://suo.im/3NNUpd。更多有用的信息可参阅：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;数据科学家与数据架构师：http://suo.im/4bRkRG&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;数据科学家与数据工程师：http://suo.im/3mpo6E&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;数据科学家与统计学家：http://suo.im/2GGtfG&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;数据科学家与业务分析师：http://suo.im/3h0hkX&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而在最近，数据科学家 Ajit Jaokar 则又讨论了 A 型数据科学家（分析师）和 B 型数据科学家（建造者）之间的区别：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;A 型数据科学家能够很好地编写操作数据的代码，但并不一定是一个专家。A 型数据科学家可能是一个实验设计、预测、建模、统计推理或统计学方面的事情的专家。然而总体而言，一个数据科学家的工作产品并不是「P 值和置信区间」&amp;mdash;&amp;mdash;就像学术界的统计学有时候建议的那样（而且这常常是为传统的制药等等行业工作的）。在谷歌，A 型数据科学家被称为统计学家、定量分析师、决策支持工程开发分析师，也有一些被称为数据科学家。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;B 型数据科学家：这里的 B 是指 Building。B 型数据科学家和 A 型数据科学家具有相同的背景，但他们还是很强的程序员、甚至经验丰富的软件工程师。B 型数据科学家主要关注在生产环境中使用数据。他们构建能与用户进行交互的模型，通常是提供推荐（产品、可能认识的人、广告、电影、搜索结果等）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而对于业务处理优化，我也有自己的看法，我将其分成了 ABCD 四个方向，其中 A 表示分析科学（analytics science），B 表示业务科学（business science），C 表示计算机科学（computer science），D 则表示数据科学（data science）。数据科学可能会涉及到编程或数学实践，但也可能不会涉及到。你可以参考 http://suo.im/11bR7o 这篇文章了解高端和低端的数据科学的差异。在一家创业公司，数据科学家通常要做很多类型的工作，其扮演的工作角色可能包括：执行、数据挖掘师、数据工程师或架构师、研究员、统计学家、建模师（做预测建模等等）和开发人员。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然数据科学家常常被看作是经验丰富的 R、Python、SQL、Hadoop 程序员，而且精通统计学，但这不只不过是冰山一角而已&amp;mdash;&amp;mdash;人们对于数据科学家的这些看法不过是来自于重在教授数据科学的部分元素的数据培训项目而已。但正如一位实验室技术人员也可以称自己为物理学家一样，真正的物理学家远不止于此，而且他们的专业领域也是非常多样化的：天文学、数学物理、核物理、力学、电气工程、信号处理（这也是数据科学的一个领域）等等许多。数据科学也是一样，包含的领域有：生物信息学、信息技术、模拟和量化控制、计算金融、流行病学、工业工程、甚至数论。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对我而言，在过去的十年里，我专注于机器到机器和设备到设备的通信、开发能自动处理大型数据集的系统、执行自动化交易（比如购买网络流量或自动生成内容）。这意味着需要开发能够处理非结构化数据的算法，这也是人工智能、物联网和数据科学的交叉领域，也可被称为深度数据科学（deep data science）。其对数学的需求相对较少，也只涉及到较少的编程（大部分是调用 API），但其却是相当数据密集型的（包括构建数据系统），并且基于专门为此背景而设计的全新统计技术。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在此之前，我的工作是实时的信用卡欺诈检测。在我事业的早期阶段（大约 1990 年），我开发过图像远程感知技术，其中包括识别卫星图像的模式（形状和特征，比如湖泊）和执行图像分割：那段时间我的研究工作被称为是计算统计学，但在我的母校，隔壁的计算机科学系也在做着几乎完全一样的事情，但他们把自己的工作叫做是人工智能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今天，这项工作被称作数据科学或人工智能，其子领域包括信号处理、用于物联网的计算机视觉等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外，数据科学家也可以在各种各样的数据科学项目中出现，比如数据收集阶段或数据探索阶段一直到统计建模和已有系统维护。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2. 机器学习对比深度学习&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在深入探讨数据学习与机器学习之间的区别前，我们先简单讨论下机器学习与深度学习的区别。机器学习一系列在数据集上进行训练的算法，来做出预测或采取形同从而对系统进行优化。例如，基于历史数据，监督分类算法就被用来分类潜在的客户或贷款意向。根据给定任务的不同（例如，监督式聚类），用到的技术也不同：朴素贝叶斯、支持向量机、神经网络、ensembles、关联规则、决策树、逻辑回归或多种方法之间的结合。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些都是数据科学的分支。当这些算法被用于自动化的时候，就像在自动飞行或无人驾驶汽车中，它被称为人工智能，更具体的细说，就是深度学习。如果数据收集自传感器，通过互联网进行传输，那就是机器学习或数据科学或深度学习应用到了 IoT 上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有些人对深度学习有不同的定义。他们认为深度学习是带有更多层的神经网络（神经网络是一种机器学习技术）。深度学习与机器学习的区别这一问题在 Quora 上也被问到过，下面对此有详细的解释：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;人工智能是计算机科学的一个子领域，创造于 20 世纪 60 年代，它涉及到解决对人类而言简单却对计算机很难的任务。详细来说，所谓的强人工智能系统应该是能做人类所能做的任何事。这是相当通用的，包含所有的任务，比如规划、到处移动、识别物体与声音、说话、翻译、完成社会或商业事务、创造性的工作（绘画、作诗）等。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;自然语言处理只是人工智能与语言有关的一部分。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;机器学习被认为是人工智能的一方面：给定一些可用离散术语（例如，在一些行为中，那个行为是正确的）描述的人工智能问题，并给出关于这个世界的大量信息，在没有程序员进行编程的情况下弄清楚「正确」的行为。典型的是，需要一些外部流程判断行为是否正确。在数学术语中，也就是函数：馈入输入，产生正确的输出。所以整个问题就是以自动化的方式建立该数学函数的模型。在二者进行区分时：如果我写出的程序聪明到表现出人类行为，它就是人工智能。但如果它的参数不是自动从数据进行学习，它就不是机器学习。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;深度学习是如今非常流行的一种机器学习。它涉及到一种特殊类型的数学模型，可认为它是特定类型的简单模块的结合（函数结合），这些模块可被调整从而更好的预测最终输出。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3.机器学习与统计学之间的区别&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;《Machine Learning Vs. Statistics》这篇文章试图解答这个问题。这篇文章的作者认为统计学是带有置信区间（confidence intervals）的机器学习，是为了预测或估计数量。但我不同意，我曾建立过不需要任何数学或统计知识的工程友好的置信区间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4. 数据科学对比机器学习&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器学习和统计学都是数据科学的一部分。机器学习中的学习一词表示算法依赖于一些数据（被用作训练集），来调整模型或算法的参数。这包含了许多的技术，比如回归、朴素贝叶斯或监督聚类。但不是所有的技术都适合机器学习。例如有一种统计和数据科学技术就不适合&amp;mdash;&amp;mdash;无监督聚类，该技术是在没有任何先验知识或训练集的情况下检测 cluster 和 cluster 结构，从而帮助分类算法。这种情况需要人来标记 cluster。一些技术是混合的，比如半监督分类。一些模式检测或密度评估技术适合机器学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据科学要比机器学习广泛。数据科学中的数据可能并非来自机器或机器处理（调查数据可能就是手动收集，临床试验涉及到专业类型的小数据），就像我刚才所说的，它可能与「学习」没有任何关系。但主要的区别在于数据科学覆盖整个数据处理，并非只是算法的或统计类分支。细说之，数据科学也包括：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;数据集成（data integration）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;分布式架构（distributed architecture）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;自动机器学习（automating machine learning）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;数据可视化（data visualization）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;dashboards 和 BI&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;数据工程（data engineering）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;产品模式中的部署（deployment in production mode）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;自动的、数据驱动的决策（automated, data-driven decisions）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然，在许多公司内数据科学家只专注这些流程中的一个。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于这篇文章，技术顾问 Suresh Babu 给出了一个评论，机器之心将其编译整合到了下面：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这篇文章说明了解使用机器/计算机来处理类似人类决策的任务的统计学习的基本术语是件很麻烦的事。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但文章中「当这些算法被用于自动化的时候，就像在自动飞行或无人驾驶汽车中，它被称为人工智能，更具体的细说，就是深度学习。」这样的说话看起来却有些随意任性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当过去计算机/机器还不够友好，没有得到广泛使用的时候，统计学家和数据科学家的工作和现在这个领域的工作有很大的不同。比如说，当制造业开始使用计算机辅助后，生产速度和量都发生了巨大的变化&amp;mdash;&amp;mdash;但它仍然是制造业。用制造机器来做原本人类做的程序化工作的想法最早来自 19 世纪初 Jacquard 和 Bouchon 等人。而 Jacquard 织布机的工作方式和现在计算机控制的织布机的工作方式基本相同。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在的数据科学是一个知识体系，囊括了统计学和计算方法等等（而且在不同的具体领域不同学科的比例也不一样）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器学习（或使用了其它的术语，比如深度学习、认知计算）是让机器像人类一样思考和推理，基本上而言是指通过人工的方法（所以也叫人工智能）来代替人类天生的自然智能&amp;mdash;&amp;mdash;涉及到的任务从简单到复杂都有。比如，无人驾驶汽车（目前）正在模仿人类的驾驶，驾驶条件也是人类在自然情况下会遇到的&amp;mdash;&amp;mdash;我说「目前」是因为也许未来人类将很少能够直接驾驶机器，「驾驶（drive）」这个词本身都可能会改变含义。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个领域里面也有些滑稽可笑的事情，比如一些基本的东西（比如一个下国际象棋或围棋的算法）被认为可以解释人脑的工作方式。就我们目前的知识水平而言，光是解释鸟或鱼的大脑的工作方式就已经非常困难了&amp;mdash;&amp;mdash;这说明我们还没有真正理解学习的机制。为什么果蝇只需几百个神经元就能做到这么多事情？这还是神经科学的一个未解之谜。而认知是什么以及其在自然环境下是如何工作的也是一个数据科学傲慢地认为自己能解决的重大难题。（不管怎样，降维是一种无监督学习的方法。）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在很多方面，工具以及我们使用工具所做的事情自人类诞生以来就在引导着人类的学习。但这就扯远了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文链接：http://www.datasciencecentral.com/profiles/blogs/difference-between-machine-learning-data-science-ai-deep-learning&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Sun, 26 Feb 2017 13:08:16 +0800</pubDate>
    </item>
    <item>
      <title>独家 | 揭秘Element AI：Yoshua Bengio的人工智能孵化器</title>
      <link>http://www.iwgc.cn/link/</link>
      <description>
&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;记者：CZ、栋栋哥哥&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;strong&gt;编辑：李泽南&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2016 年 10 月，Yoshua Bengio 等人在加拿大蒙特利尔联合&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720113&amp;amp;idx=3&amp;amp;sn=7048bf4b7c718d148615d95ef14a10d7&amp;amp;chksm=871b030fb06c8a19b3bd83051cdc482576cbb7e697015aa6edf51232b8554680cb6ee9d39517&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720113&amp;amp;idx=3&amp;amp;sn=7048bf4b7c718d148615d95ef14a10d7&amp;amp;chksm=871b030fb06c8a19b3bd83051cdc482576cbb7e697015aa6edf51232b8554680cb6ee9d39517&amp;amp;scene=21#wechat_redirect" target="_blank"&gt;创立了人工智能孵化器 Element AI&lt;/a&gt;。这家被称为「加拿大版 YC」的公司旨在通过硅谷式的产业服务帮助创业者，将人工智能的新技术从实验室转化为实用产品，同时也为其他公司构建研究机构提供解决方案。Element AI 成立不久很快便&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721406&amp;amp;idx=3&amp;amp;sn=6fc1142418a9eee3d65ea786325a3aca&amp;amp;chksm=871b0800b06c8116f083c4149e99f526019cf954a89f2f61eaeab9db372854b3467ba39f8151&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721406&amp;amp;idx=3&amp;amp;sn=6fc1142418a9eee3d65ea786325a3aca&amp;amp;chksm=871b0800b06c8116f083c4149e99f526019cf954a89f2f61eaeab9db372854b3467ba39f8151&amp;amp;scene=21#wechat_redirect" target="_blank"&gt;获得了来自微软的投资&lt;/a&gt;。除 Yoshua Bengio 之外，这家公司的其他联合创始人包括首席执行官 Jean-Fran&amp;ccedil;ois Gagne，Nicolas Chapados 和 Jean-S&amp;eacute;bastien Cournoyer 等人。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/7df67a177bb31515337f40ba01a9fe8e59419ee1"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em style=" max-width: 100%; color: rgb(136, 136, 136) ; ; ; ; ; ; ; ; ; ; ; ; ; "&gt;&lt;span&gt;Element AI 的管理团队&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em style=" max-width: 100%; color: rgb(136, 136, 136) ; ; ; ; ; ; ; ; ; ; ; ; ; "&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自 20 世纪 50 年代出现以来，人工智能已经发展了很长一段时间，但仅仅是在最近十年中因为一些技术突破的出现才广为人们所知。有趣的是，在这段爆发性增长的过程中，蒙特利尔和多伦多成为了人工智能研究的中心。这两座城市涌现了像 Yoshua Bengio、Geoffrey Hinton 和 Yann LeCun 这样影响巨大的人工智能先驱者，其中后两位已经在为谷歌和 Facebook 这样的科技巨头效力了。目前，加拿大正在寻求将蒙特利尔建成世界级科技中心，希望这座城市在未来能够代替美国硅谷的地位。在这样的发展路程中，Element AI 会发挥什么样的角色？最近，机器之心走进 Element AI，对公司的创始人们进行了一次访谈。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/17d3875978b1290859a1cdac9b05d7a222fc9f98"/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;Element AI 成立以来的第一项投资是收购了人工智能数据库公司 mldb.ai。2 月 15 日，该公司宣布了这项收购。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个真正的风投案例大约需要历时 9 年。Element AI 及其资方 Real Ventrures 的经理们已经投资过很多家互联网和软件公司，而这些公司曾颠覆过传统行业。随着时间的推移，网络已经延伸到了移动端、物联网等各个新方向上。与十几年前互联网大发展时代不同的是：当今世界的一切设备都可以互相连通，这种趋势正将我们引向新的革命，我们每天接触的应用越来越趋向于存储在云端，下一个技术革命必然会在万物互联的背景下产生。因为设备无处不在，智能软件和云技术会为我们制造越来越多的数据。而数据也会让这个世界、每个人、每一家公司越来越具有生产力，但现在仍然有很多数据是普通用户仍然无法掌控的。这或许会成为人工智能行业的突破点。因为在未来，这个世界会变得更加个性化，个人用户、组织机构和政府的形态都会发生转变。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;说到投资人工智能，Element AI 的联合创始人 Jean-S&amp;eacute;bastien Cournoyer 表示对此并不陌生：「我在 2000 年的时候已经参与过不少此类项目的投资了，那时大多数是 NLP 类技术的公司，它们当中最有名的是 Nuance，这家公司随后发展壮大，收购了一些其他公司。在那个时代，人工智能的词汇是 NLP（自然语言处理），产生的影响也比较小。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/840bd515cbdd0dc8874fa8d0590d537cb4c8c53f"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;Element AI 联合创始人，投资委员会顾问 Jean-S&amp;eacute;bastien Cournoyer，他同时也是 Real Ventures 的合伙人&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;人工智能公司的三种形式&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;总体而言，人工智能很晚才进入投资者的视线，但随着近几年的技术进步，更多人也开始投入其中。Cournoyer 将应用人工智能的公司分成了三种形式：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Applied AI&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这可以代表今天的大多数科技公司，它们希望使用人工智能来优化、个性化或自动化现有业务流程、产品和服务，以使企业和组织更加高效。对消费者而言，AI 的加入意味着个性化的用户体验。今天的大多数公司都属于此类。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;AI First&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此类公司以技术升级推动业务，为了优化自身竞争力，把人工智能提升到第一的位置。AI First 解决方案将改变人类与软件/机器的交互方式，从被动关系（我们告诉机器该做什么）到点对点关系（机器预测我们的需求并在我们与其交互时提出建议），最终形成主动关系（其中机器基于一系列输入和期望的结果告诉我们什么/何时/如何做）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;前两类公司可以通过客户的使用不断训练自己的人工智能算法，让 AI 变得更聪明，从而能提供更好的服务，这些公司的产品因个性化而各不相同。例如，Element AI 的创始人们曾投资过 &lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720780&amp;amp;idx=2&amp;amp;sn=cc64372d82354d3212baf84fce230928&amp;amp;chksm=871b0e72b06c8764cfe09654fa457da0fd764c0684d83b7fcd887c19401b3b4d623a07ab2bb9&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720780&amp;amp;idx=2&amp;amp;sn=cc64372d82354d3212baf84fce230928&amp;amp;chksm=871b0e72b06c8764cfe09654fa457da0fd764c0684d83b7fcd887c19401b3b4d623a07ab2bb9&amp;amp;scene=21#wechat_redirect" target="_blank"&gt;Ross Intelligence&lt;/a&gt;，一家为用户提供人工智能律师业务的公司。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Ross Intelligence 属于 AI First 的一类，它们向用户提供的工具可以帮助律师更高效地工作。在这其中，人工智能起到了核心作用，每一个使用它的律师都会对人工智能系统进行调查判例的训练，这不仅会提高律师们的工作效率，另一方面也在让人工智能不断提高自己的准确性。随着 Ross Intelligence 这样的公司的发展，也许在未来，律师事务所或许就不再需要调查助理了，因为人工智能接管了他们的工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一个典型案例是总部位于渥太华的 MindBridge。这家公司的创始人之一曾是 IBM Watson 的早期员工。他们的产品可以帮助审计师更轻松地发现潜在的欺诈交易。当你把数据输入他们的系统，这套工具可以标记出其中所有疑似欺诈的地方，这些地方被标记成红、黄或绿色，以供审计师仔细查看，最终判定哪些才是真的欺诈。这种过程也在让人工智能不断地学习。这家公司估算，在未来人类审计师只需要在每笔交易上花费五分钟。Mindbridge 有一个更长远的远景：一切都会被实时审计，如果系统发现一个交易存在欺诈的风险就会提前预警，这相比出现欺诈问题后再进行追溯前进了一大步。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;The Machine&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些公司构建全方位的人工智能系统。就像我们经常在科幻电影中看到的超级科技公司一样，它们拥有雄厚的实力，可以将不可能变为可能。现在，像亚马逊、谷歌、Facebook、苹果和百度这样的科技巨头已经非常接近这种概念。它们正在不断改进人工智能系统（分布式、集中式，本地或云端）解决方案，渗入用户的每一个设备。它们正在打点我们的一切，为我们提供各种各样的建议，就像电影《终结者》里描述的「天网」一样。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你是一个创业者，你需要慎重考虑一下这些问题：你想要把哪些工作交给机器去做；你想要如何为股东创造利润；为了达到目的，需要分享多少数据，保留多少数据；你最终需要制造什么样的人工智能？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在不远的将来，所有的公司都会用到人工智能，很多决定都会由 AI 和人类共同做出。如果你的全部业务都需要人工智能的协助，那么它几乎必然会运行在谷歌云、亚马逊云之上。请注意：这些提供服务的公司实际上是你的潜在竞争对手，他们可能会在 3-5 年内跟上你的技术。如果你想构建完全独立的人工智能体系，你就需要了解有关软硬件的一切，从硬件设备、云服务做起。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Element AI 的第一笔投资就是建立在这样的思考之上。2 月 15 日，这家人工智能投资公司宣布收购了 MLDB，一家提供机器学习数据库的初创公司，它致力于为大众提供民主化的人工智能，为没有技术背景的开发者提供更多可能性。「在未来，MLDB 将继续作为开源项目存在，并和 Element AI 已有的丰富资源整合，」Element AI 的首席执行官 Jean-Fran&amp;ccedil;ois Gagn&amp;eacute;表示。「该公司原有的 MLDB pro 也将被开源，并加入 &lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721717&amp;amp;idx=5&amp;amp;sn=09e5b00c2652faff72e891c166fc33a8&amp;amp;chksm=871b09cbb06c80dd032151c664c9830700a55a812cb8bdb20754abc43864be572495791e1ebe&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721717&amp;amp;idx=5&amp;amp;sn=09e5b00c2652faff72e891c166fc33a8&amp;amp;chksm=871b09cbb06c80dd032151c664c9830700a55a812cb8bdb20754abc43864be572495791e1ebe&amp;amp;scene=21#wechat_redirect" target="_blank"&gt;LiDAR&lt;/a&gt; 处理数据集等新内容。在未来的六个月内，我们将结束已有项目的支持，并以开源的、社区化的新方式为用户提供服务。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Element AI 的团队有着人工智能领域投资的丰富经验。他们计划在 2017 年投资更多这样的公司，同时进一步探寻人工智能产业链条所有角落的新机会。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;技术优先&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从基础研究做起，到应用研究成果（这对于消费来说还很远），再到为非专业用户构建解决方案&amp;mdash;&amp;mdash;即使你完全不知道人工智能是什么，Element AI 也能为你的生意带来好处。Element AI 发现，目前很多公司都对完整的解决方案感兴趣。Element 在接受某家大型公司的咨询时听到了这样的言论：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;「我们需要建立一个人工智能实验室，因为谷歌有一个，所以我们也打算建一个。」&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但建成以后它的任务是什么？这里存在着潜在的商机。在 Yoshua Bengio 等人的帮助下，Element AI 拥有学界最强大的技术阵容，虽然其中一些并不是全职，但他们能够为公司和客户提供最好的建议。另一方面，这些教授在大学里从事基础研究，而 Element AI 直面市场，这意味着在这里，理论和实际在不断产生碰撞。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/b9b5b2d6a8851afdd8e36bc3aa8c5f03f221847c"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;作为机器学习领域最后一位没有投身业界的重量级人物，蒙特利尔大学教授 Yoshua Bengio 和他领导的机器学习研究所 MILA 吸引了很多公司的投资&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Element AI 与两种类型的公司合作：向大公司提供解决方案，向初创公司提供资金和技术。它面向希望尽快实施人工智能战略的公司提供咨询，在不同的垂直领域参与他们的业务。Element AI 可以为这些企业量身定做它们的人工智能路线图，依靠自身的数据科学家、工程师力量为客户提供解决方案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而在初创公司方面，因为它们都有着自己独特的技术，或是独特的数据集，对于业务的价值观有着很大的不同，在一些领域，如机器人，Element AI 会对这些公司进行投资，这意味着获得它们的一部分股权。作为回报，这些公司可以获得最专业的人工智能实验室提供的服务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;作为公司的联合创始人，Yoshua Bengio 把 Element AI 的价值观定义为：让先进的人工智能为人类带来财富。他希望蒙特利尔能够成为人工智能的硅谷，让这个城市创造的价值能为全世界带来发展，这一愿景也是 Bengio 选择加入 Element AI 的原因。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Yoshua Bengio 在 Element AI 仍然扮演着「教育者」的角色，他正在把自己对于人工智能技术应用的想法不断灌输给公司的每一个人。「如果我们想要知道最新的算法如何应用到现实世界，我们会与 Bengio 展开讨论，他会告诉我们在具体领域里会遇到哪些难点。」Cournoyer 说道。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;寻找下一个独角兽&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;作为投资者，Element AI 认为在人工智能的爆发中必然会涌现出新的科技巨头，因为机器智能的产业链条还不完整。目前，英特尔和英伟达是人工智能硬件技术领先的公司，但它们提供的人工智能芯片仍是 CPU/GPU 的延伸，并不是原生设计，新公司在这方面存在可以发展的空间，Cournoyer 认为在未来的 10 到 15 年内，新的巨头就会出现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你与来自谷歌、亚马逊、facebook 这些大公司的员工交流，你会发现他们会不断提起人工智能，因为这是他们领先的地方。大公司对于技术的基础研究造就了他们现在的优势，而技术产生的解决方案正不断地进入到他们的产品中去，这就是大公司生态系统不断升级的方式。通过将自身优势不断扩大，科技巨头会不断补完自己的产业拼图。如果你产生了这样的问题：「我希望进行人工智能方面的研究，但如何构建人工智能研究的团队？」Element AI 这样回答：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;你们需要我的帮助，我们致力于构建完整的产业链，把服务送到所有人手中。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于科技行业而言，创业的机会稍纵即逝，从 Uber、滴滴这样通过大量投资打开市场的公司，到今日头条、Ross Intelligence 这样技术优先占领垂直领域的公司，只有找到了准确的定位才能获得成功，对于 Element AI 这样的投资者而言也是如此。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然 Element AI 的高管并未点出下一个风口到底会出现在哪里，但他们认为人工智能在技术优化、网络安全等领域或许会出现热点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌和 Facebook 等大公司经常会开源他们的研究成果，但普通人想要把这些技术转变成为高效的解决方案是非常困难的。这仍是一个谁拥有数据的问题，但即使是这样，仍然有一些人工智能的方式不需要收集大量的数据，这些新的方法将为创业者开启新的大门。对于 Element AI 而言，投资者关注的重点不在于 TensorFlow 等架构孰优孰劣的问题，而是理解整个行业的所有环节，这也是大公司在过去的两年里不断收购有竞争力的小公司，招募多个细分领域人才的原因。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「为了做到这一点，我找到 Jean-Fran&amp;ccedil;ois Gagn&amp;eacute;，我们决定成立一家公司，经过了几个月的准备，越来越多的人加入进来，最后 Element AI 终于在 2016 年 10 月正式成立了。」Cournoyer 说道。「我们的使命是投资整个人工智能行业生态系统的公司，我们在蒙特利尔开始，但不仅限于此。我们希望这个加拿大东部城市可以成为未来市场的中心，在 AI 世界里，蒙特利尔因为拥有世界级的大学而具有很高起点。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以外人的眼光看来，Element AI 就像是一个活跃的社区，这是它创业公司的一部分，这家公司希望能为整个生态系统献出自己的一份力，而不仅仅是面向自己的股东。因此，他们的眼界不仅限于蒙特利尔，而是希望将业务范围覆盖到全世界。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「Element AI 对于来自中国的公司持开放态度，假如有一家中国公司希望在蒙特利尔成立人工智能实验室，我们会非常期待与它合作。」Cournoyer 表示。「正如我们可以帮助其他公司构建人工智能实验室一样，我们也可以通过与其他资本的合作共同拓展我们的投资领域。我们希望通过这样的合作把全世界的人才吸引到我们的平台中。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于那些想来蒙特利尔设立人工智能研究机构的国际公司，Element AI 可以帮助它们与当地研究者展开充分交流。加拿大是一个多元化的国家，这为外国公司融入当地环境带来了便利。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;蒙特利尔和加拿大的未来&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Open AI 的理念可以一定程度上代表硅谷，它希望构建强大的人工智能工具，同时让全世界都可以获得它，这是一种打开市场的方式。但最近 OpenAI 的创始人之一 Sam Altman 在&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719713&amp;amp;idx=1&amp;amp;sn=721ff94713b21148895253b543e2bc24&amp;amp;chksm=871b019fb06c8889e5a4df61cbfdfd421a52d683b0a457173069b28e5b48f0f7afb51ade7ffd&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719713&amp;amp;idx=1&amp;amp;sn=721ff94713b21148895253b543e2bc24&amp;amp;chksm=871b019fb06c8889e5a4df61cbfdfd421a52d683b0a457173069b28e5b48f0f7afb51ade7ffd&amp;amp;scene=21#wechat_redirect" target="_blank"&gt;接受纽约客的专访&lt;/a&gt;时表示：「我们不会再开源 OpenAI 所有的研究成果了。」看起来，Open AI 在追寻自我价值实现的道路上也在做着妥协。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;开源并不能直接获得利润，至少在 Element AI，目前的任务核心在于形成自身的业务。作为一个涉足基础研究的公司，ElementAI 开源了大量的研究成果，为推动全世界技术进步献出自己的力量，但同时也会进行属于自己的人工智能研究，为客户提供服务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;先行者的存在既意味着存在经验可供参考，也表示 Element AI 面临着来自硅谷对手的强大竞争压力。但如果你了解一下各个城市和市场，你会发现蒙特利尔正在成为北美地区的人工智能中心，这座加拿大城市的确正在动摇硅谷的位置，聚集越来越多的初创公司和资金。与此同时，加拿大多伦多-滑铁卢区域也在争夺同样的位置。无论哪个城市最终获胜，加拿大人成为人工智能领域全球领先国家的目的都会成为现实。目前，Element AI 计划在多伦多开办新的分支机构，这会将是他们的第二个办公室，这家公司已把两座城市视为同一个市场。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你在硅谷带领一个有着 20 个博士的团队，那你很快就会获得 500 万美元的融资，这被看做是自然而然的事情；然而在加拿大，事情还没有发展到这种地步，加拿大的初创公司是被低估的。尽管如此，在多伦多已有很多颇具创新力的科技公司，如构建类人机器人的 Kindred，提供个性化深度学习推荐系统的 Layer6.ai 等等，此外还有数十个小公司具有很大的成长潜力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;很多大型科技公司也看到了这个趋势，谷歌刚刚在蒙特利尔开办了人工智能实验室，这是一个信号。在未来，我们会看到其它大公司陆续来到这里开展自己的研究。这会形成一个正循环，为加拿大制造越来越大的市场，并吸引更多的人才来到这里。当然，现在还不能展望这里会诞生一个新的谷歌。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/4d9bbd96254f37aa11b84d354e5b18bd047592c0"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Element AI 的故事才刚刚展开，人工智能将会是新的资本战场，而加拿大已经占据了有利地形。「我认为人工智能将是 IT 技术的最后一次大发展，」Cournoyer 说道。「它不会像纳米科技或基因技术一样发展缓慢，人工智能技术已经展现了它的潜力。在不久的未来，人工智能将会在很多岗位上代替人类。让机器变得智能化是我们共同努力的目标。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&amp;copy;本文为机器之心原创，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Sun, 26 Feb 2017 13:08:16 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 词嵌入所不能解决的自然语言理解：会话人工智能的方向在哪？</title>
      <link>http://www.iwgc.cn/link/</link>
      <description>
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自TechCrunch&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Katherine Bailey&amp;nbsp;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：蒋思源&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote style="color: rgb(62, 62, 62); font-size: 16px; white-space: normal; line-height: 25.6px; background-color: rgb(255, 255, 255); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;近年来，我们看到在各种设备上都开始加载一种「智能」数字助理。在最近的消费电子展（CES），现代和丰田都发布了新型车载助理。不过虽然这些应用背后的技术越来越好，但是还是存在着用户对其失望的情绪：他们对「智能」的期望并没有得到满足。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管数据驱动的方式在自然语言处理（NLP）中取得了较大的进步，自然语言理解仍然处于艰难的地步。Winograd Schema Challenge 最近提出了一种图灵测试的改进，他们希望其能用于评价机器是否「智能」。该测试命名为 Terry Winograd，并且在挑战赛中使用了第一个代词消歧类问题样本：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;市议会拒绝许可游行示威，因为他们害怕暴力&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这一句话中「他们」指的是谁？是市议会还是游行者？如果我们把「害怕」替换为「倡导」呢？这样为什么就改变了我们对「他们」的理解。因为我们知道议员更害怕暴力，而示威者更倡导暴力，而这种不是文本本身的信息对消除代词「他们」的歧义是至关重要的，这就给人工智能系统带来了巨大的挑战。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一次 Winograd Schema Challenge 在去年七月举行，获胜算法仅仅只是比「随机」获得稍微高一点的分数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;表征与理解&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如今有一种可以表征自然语言单词的技术，它在自然语言处理任务（如情感分析和机器翻译）中是十分高效的。这种表征就是词嵌入（word embeddings），该技术使用数学方法从数百万的样本词学习训练词义从而表征单词。词嵌入主要就是通过学习单词之间的关系而表征词义。如通过确保各个向量（具体说向量「国王」-「男性」+「女性」=「王后」）之间的特定数学关系，一组优良的表征将获取「国王是男性，王后是女性」这一关系。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种向量化的表征是谷歌新翻译系统的核心，只不过该系统能够更进一步表征整个句子而不是单词。该新系统「在主要的几个自然语言对中，有效地降低了翻译错误率高达 55% 到 85%」，并且还能执行 zero-shot 翻译：也就是互译没有训练数据集的两种语言。鉴于所有的这些，也许听到 NLP 的前沿研究者 Oren Etzioni 所嘲讽的就会很惊讶了，他嘲讽道：「当人工智能不能确定句子中的「它」是指什么的时候，其是不会影响世界的。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以，人工智能可以在没有训练的情况进行语言对足够好的翻译，但人工智能还是不能确定「它」是指的什么。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;语义并不是直接获取&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当了解到词和句子的向量化表征是如何工作时，可以认为它们真正在获取意义，即有产生一些理解。但这样说是不对的，这些表征是由使用语言的样本而驱动，而我们使用的语言是由意义而驱动的。因此，我们所做出来的表达自然地反映了该含义。但是，学习这种词嵌入表征的人工智能系统并没有直接获取实际意义。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/3c706d460e70d060873b040221ef1294b7f86423"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于自然语言处理任务的目的来说，缺乏直接获取真实意义的方法并不重要。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不理解句子中的「它」是指的是什么不会对翻译的准确性产生巨大的影响，然而当尝试构建会话人工智能时，问题就出来了：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/5cb404cc25e3f160d8d869f759ffd02f0702179c"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;样本 bot 的截屏&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;理解代词的指代在持续性对话中是十分重要的技能。如上所说，用于训练执行 NLP 任务的人工智能训练数据不包括用于消除单词歧义的必要信息，并且这些信息主要是来自于对世界认知的知识。是否有必要体现世界的实体或简单地将大量「通识知识」编入程序从而收集必要的信息，这还是一个开放性问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;约束条件下操作&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一些优秀的人才正在研究人工智能中自然语言理解的问题。在 NIPS 2016，OpenAI 的研究者们发表了 A Paradigm for Situated and Goal-Driven Language Learning。斯坦福大学的研究者们也正在研究交互式语言学习（interactive language learning），该方法认识到为了学习语义，与世界交互的重要性。有趣的是，他们的样本系统向 Terry Winograd 的SHRDLU 系统表示敬意，Terry Winograd 的 SHRDLU 系统是一个早期对话系统，其限制自身认同对世界由块组成的陈述。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/0cd21c783cfbbb446dee25b9c37d8a5558942020"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Terry Winograd 的早期自然语言理解程序 SHRDLU，其限制自身认同对世界由块组成的陈述&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于任何想要构建会话人工智能的开发者来说，这样的限制仍然是绝对有必要的。亚马逊的 Lex 和 IBM 的对话服务都允许开发人员在对他们应用需要如何运作上指定约束。开发人员定义了应用程序可以执行的一组意图，并将这些意图映射到用户可能请求的一组方式上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是有些方法可以在不解决自然语言理解问题（这可能需要几十年或更长时间）的情况下增强这种会话人工智能的体验。上图显示 bot 在前一个命令是「关闭挡风玻璃刮水器」时不能理解「现在打开它」是什么意思，这说明了有时候这种会话人工智能连无歧义的代词都不能理解，这绝对是当前技术所能解决的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;了解当前人工智能和机器学习技术上什么是可能、什么是不可能对任何想要使用该技术增强应用功能的人都是十分重要。如果你对人工智能目前的能力不怀有足够的质疑，你可能会浪费大量的时间和金钱来尝试做一些尚未可能完成的工作。另一方面，如果你太怀疑了，也许你会失去开发一个极其实用和盈利人工智能的机会。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文链接：&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;https://techcrunch.com/2017/02/25/conversational-ai-and-the-road-ahead/?ncid=rss&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Sun, 26 Feb 2017 13:08:16 +0800</pubDate>
    </item>
    <item>
      <title>资讯 | 英国政府拨款2000万英镑，期望引领世界人工智能产业发展</title>
      <link>http://www.iwgc.cn/link/</link>
      <description>
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自Telegraph&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：&amp;nbsp;Ben Riley-Smith&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：黄小天&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关于如何成为世界人工智能与机器人产业的领先者，英国将在周一宣布一个重大评审。来自学界和产业界的领军人物将在英国脱欧选举之后引导政府鼓励发展新兴产业。专家认为如果人工智能的潜力化为现实，2035 年之前英国经济总量将增加 6540 亿英镑。另外还会宣布一项额外的 1700 万英镑的资金，用于支持手术型微型机器人的研发。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/756c84b5d6c45342442c6b1fcb29cd136996b35d"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;这些措施标志着一个新的数字化策略的诞生。来源：EPA&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些措施标志着一个新的数字化策略的诞生，该策略政府将在下周公布。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;英国部长们渴望通过开发无人驾驶汽车、语音助手（如 Siri）以及在极端环境中（如核设施）工作的机器人以抓住经济发展机遇。虽然感觉英国在上述领域中已经具备竞争优势，在未来十年，要确保成为世界人工智能产业领先国家英国还要付出更多努力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;英国文化部长 Karen Bradley 说：「从最早期的计算机研究到 Tim Berners-Lee 先生开发万维网，英国在数字创新方面有着令人骄傲的历史。现在，我们已经是当今人工智能革命的先驱，数字化策略将巩固我们的优势，确保英国的科学家、研究者和企业家一直走在行业最前沿。像人工智能这样的技术具有革新人类存在方式（如生活、工作、出行和学习等）的潜力。如果政府和行业齐心协力推动这这方面的增长，并为英国实现经济与社会效益，这将是一件意义非凡的事情。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/d23442031f4b3f3cff88d4f9eba10cce607950de"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;英国部长们渴望通过开发无人驾驶汽车抓住经济发展机遇。来源：BLOOMBERG&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;评审将由南安普顿大学计算机科学学院教授 Dame Wendy Hall 和英国技术公司 BenevolentTech 的首席执行官 J&amp;eacute;r&amp;ocirc;mePesenti 主持，该公司使用人工智能加速科学发现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这次评审也将宣布工程和物理科学研究委员会（Engineering and Physical Sciences Research Council，EPSRC）拿出 1730 万英镑用于支持大学研究。Dame Wendy 说：「我们的科学家、研究者和企业家正处在发展人工智能的最前线，我希望他们探索政府与行业如何合作以推动英国的技术发展。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;英国商业部长 Greg Clark 说：「对机器人和人工智能的投资将有助于使我们的经济更具竞争力，巩固我们在这些前沿领域领先世界的名誉，帮助我们创造新产品，发展更创新的服务，并以更好的方式推动商业发展。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文链接：http://www.telegraph.co.uk/news/2017/02/26/government-plough-20m-artificial-intelligence-research-including/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Sun, 26 Feb 2017 13:08:16 +0800</pubDate>
    </item>
    <item>
      <title>学界 | 新论文提出用GAN构建不同年龄时的样貌：可让你提前看到年老时的模样</title>
      <link>http://www.iwgc.cn/link/</link>
      <description>
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自arXiv.org&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：黄小天、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote style="color: rgb(62, 62, 62); font-size: 16px; white-space: normal; line-height: 25.6px; background-color: rgb(255, 255, 255); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/132b82a6d3fc0d6603614d0448cfea8ddadca4bb"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：&lt;/span&gt;&lt;span&gt;最近的研究表明生成对抗网络（GAN）可以产生特别好的视觉保真度（visual fidelity）的合成图像。在这项工作中，我们提出了基于生成对抗网络的自动面部老化（automatic face aging）方法。与之前运用生成对抗网络改变面部特征的工作相反，我们特别强调保存面部老化版本与原来的人的同一性。最后，我们介绍了一种生成对抗网络 latent vectors 的「Identity-Preserving」优化的全新方法。通过当前最佳的面部识别和年龄评估方案，对得到的老化和年轻化的面部图像的客观评价证明了被提出方法的巨大潜力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/26f1ccd2e7d6f86b6e93420e203bc27b88f59e6c"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 1 我们的面部老化方法。（a）用于重建输入图像的 latent vectors 的近似；（b）在生成器 G 输入以执行面部老化时切换年龄状况。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/5a1250a2a9b94d0f279a0cce17d8d5455b566798"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 2 我们的 acGAN 使用两个随机 latent vectors z（行）和各自限制的年龄类别 y（列）生成的合成图像的样本&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/652e15af87375a7c42f6e94f8ab33aeb75e41927"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 3 面部重建与老化的样例。（a）原始测试图像，（b）使用最初 latent approximations 生成的重建图像：z0，（c）使用「Pixelwise」和「Identity-Preserving」优化的 latent approximations 生成的重建图像：z pixel 与 z IP，和（d）通过「Identity-Preserving」z IP latent approximations 和各自限制的年龄分类 y（每列一个）生成的重建图像的老化&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Sun, 26 Feb 2017 13:08:16 +0800</pubDate>
    </item>
    <item>
      <title>FPGA 2017最佳论文出炉：深鉴科技ESE语音识别引擎获奖（附解读）</title>
      <link>http://www.iwgc.cn/link/</link>
      <description>
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;font color="#ffffff"&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/font&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：姚颂、韩松&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote style="color: rgb(62, 62, 62); font-size: 16px; white-space: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/blockquote&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;FPGA 芯片领域顶级会议 FPGA 2017 于 2 月 24 日在加州 Monterey 结束。在本次大会上，斯坦福大学在读 PhD、深鉴科技联合创始人韩松等作者的论文 ESE: Efficient Speech Recognition Engine with Sparse LSTM on FPGA 获得了大会最佳论文奖。得知此消息后，机器之心对深鉴科技科技创始人兼 CEO 姚颂与联合创始人韩松（本论文的第一作者）进行了联系，他们对该文章进行了技术解读。可点击阅读原文下载此论文。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/790a23ccaf77f01dcba9b345d1d0b5c389b6b6bc"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;span&gt;韩松在&lt;span&gt;FPGA'17&lt;/span&gt;会场讲解&amp;nbsp;&lt;span&gt;ESE&amp;nbsp;&lt;/span&gt;硬件架构&lt;/span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;FPGA 领域顶级会议 FPGA 2017 于 2 月 24 日在加州 Monterey 结束。在本次大会上，深鉴科技论文《ESE: Efficient Speech Recognition Engine with Sparse LSTM on FPGA》获得了大会最佳论文奖（Best Paper Award）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/00ce5a52362f2e052e6b864ba62fbb827121902f"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;图1:韩松提出的深度学习部署方案。跟传统的「训完即用」的方案相比，「训练后经过压缩再用硬件加速推理」的方案，可以使得推理更快、能耗更低。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该项工作聚焦于使用 LSTM 进行语音识别的场景，结合深度压缩（Deep Compression）、专用编译器以及 ESE 专用处理器架构，在中端的 FPGA 上即可取得比 Pascal Titan X GPU 高 3 倍的性能，并将功耗降低 3.5 倍。而此前，本文还曾获得 2016 年 NIPS Workshop on Efficient Method for Deep Neural Network 的最佳论文提名。据悉，本文所描述的 ESE 语音识别引擎，也是深鉴科技 RNN 处理器产品的原型。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/7d639da2d903798ba22de0c7947cf85294df9194"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 2：ESE 语音识别引擎工作全流程&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;LSTM 全称为 Long-Short Term Memory，&lt;/span&gt;&lt;span&gt;在语音识别、机器翻译、&lt;/span&gt;&lt;span&gt;Image Captioning&lt;/span&gt;&lt;span&gt;中有较多的应用。对于语音识别而言，LSTM 是其中最重要一环，也是计算耗时最多的一环，通常占到整个语音识别流程时间的 90% 以上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/a85e72b0b2c3bdf1ff700c88c9682dbd5f26c8cd"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 3：LSTM 在语音识别中的位置&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Deep Compression 算法可以将 LSTM 压缩 20 倍以上。但在以往的纯算法压缩上，并没有考虑多核并行时的负载均衡，这样在实际运行时，实际的运行性能被负载最大的核所限制。本文提出了一种新的 Load Balance Aware Pruning，在稀疏化时保证剪枝后分配到每个核的计算量类似，从而进一步加速的计算。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/e76b0f787bfca4800b28a021214ff2ee333835ca"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 4：Load-Balance-Aware Pruning示意：保证稀疏性的同时保证多核负载均衡&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;结合新的模型压缩算法以及 ESE 专用处理架构，在一个可实际使用的 LSTM 模型上测试，相同情况下，深鉴基于中等 FPGA 平台的耗时为 82.7us，功耗为 41W；而 Pascal Titan X GPU 则需要 287.4us 的运行时间，并且耗能 135W。这也再次证明了稀疏化路线的作用：在价格、资源全面弱于 GPU 的专用硬件上，通过算法与硬件的协同优化，的确可以取得更好的深度学习运算能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深鉴科技成立于 2016 年 3 月，&lt;/span&gt;&lt;span&gt;创始成员来自清华大学和斯坦福大学&lt;/span&gt;&lt;span&gt;，公司致力于结合深度压缩与深度学习专用处理架构，提供更高效与便捷的深度学习平台。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;公司聚焦于稀疏化神经网络处理得技术路线，提出的 Deep Compression 算法可以将模型尺寸压缩数十倍大小而不损失预测精度，并结合专用的深度学习处理架构来实现加速。而 ICLR 2016 和 FPGA 2017 两篇最佳论文的获奖，也证实深鉴科技所聚焦的稀疏化路线越来越得到深度学习界的关注。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;论文：ESE: Efficient Speech Recognition Engine with Sparse LSTM on FPGA&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/cb50a6068739d10c32178609f60c4beab348c211"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：长短期记忆网络（LSTM）被广泛用于语音识别领域。为实现更高的预测精度，机器学习研究者们构建了越来越大的模型。然而这样的模型十分耗费计算和存储资源。部署此类笨重的模型会带数据中心来很高的功耗，从而带来很高的总拥有成本（TCO）。为了增加预测速度，提高能源效率，我们首次提出了一种可以在几乎没有预测精度损失的情况下将 LSTM 模型的尺寸压缩 20 倍（10 倍来自剪枝和 2 倍来自量化）的负载平衡感知剪枝（load-balance-aware pruning）方法。这种剪枝后的模型对并行计算很友好。另外，我们提出了可以对压缩模型进行编码和分割成 PE 以进行并行化的调度器（scheduler），并编排了其复杂的 LSTM 数据流。最后，我们设计了一种可以直接在这种压缩模型上工作的硬件框架&amp;mdash;&amp;mdash;Efficient Speech Recognition Engine (ESE)。该框架使用了运行频率为 200 MHz 的 Xilinx XCKU060 FPGA，具有以 282 GOPS 的速度直接运行压缩 LSTM 网络的性能，相当于在未压缩 LSTM 网络上 2.52 TOPS 的速度；此外，该框架执行一个用于语音识别任务的全 LSTM 仅需 41 W 功耗。在基于 LSTM 的语音基准测试中，ESE 的速度为英特尔 Core i7 5930k CPU 的 43 倍，英伟达 Pascal Titan X GPU 的 3 倍。它的能量效率分别为以上两种处理器的 40 倍和 11.5 倍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&amp;copy;本文为机器之心原创，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Sat, 25 Feb 2017 15:24:24 +0800</pubDate>
    </item>
    <item>
      <title>特写 | 探访Facebook应用机器学习团队：如何构建研究与应用之间的桥梁？</title>
      <link>http://www.iwgc.cn/link/</link>
      <description>
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自BackChannel&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Steven Levy&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote style="color: rgb(62, 62, 62); font-size: 16px; white-space: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/blockquote&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;在 Facebook，应用机器学习（Applied Machine Learning）团队正在帮助这家社交网络公司看见、说话和理解，他们甚至可能会帮助根除假消息。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/b00768c6004582381915d7918cd8a4a3a7740754"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Joaquin Candela，Facebook 应用机器学习团队工程开发主管&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当被要求领导 Facebook 的应用机器学习团队来推动这个世界上最大的社交网络全面进军人工智能时，Joaquin Qui&amp;ntilde;onero Candela 犹豫了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;原因倒不是因为这个西班牙出生的、自称「机器学习（ML）人」的科学家的还没见证过人工智能帮助 Facebook 的方式。实际上，自从 2012 年加入该公司之后，他就一直在监管该公司广告运行的转型&amp;mdash;&amp;mdash;使用机器学习方法来使受赞助的帖子更相关和更高效。值得注意的是，他是通过让其团队中的工程师都使用人工智能而完成的，尽管他们中有一些人之前并未接受过相关的训练，但最后他成功让广告部门的机器学习技能变得丰富了起来。但他并不确定同样的魔法是否能在 Facebook 整个公司的更大疆土上起效，这里有十几亿人连接在一起，而连接所基于的价值却远比衡量广告的硬数据更模糊。对于这次升职，他评论说：「我需要确信这么做是有价值的。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管有这样的怀疑，但 Candela 还是接受了这个职位。而现在，还不到两年的时间，他的犹豫看起来却像是很荒唐的一件事。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有多荒唐？上个月，Candela 在纽约一场大会上对在场的工程师讲了话。「我要做出一个非常明确的声明。」他警告说：「没有人工智能，今天的 Facebook 就不会存在。每天你使用 Facebook 或 Instagram 或 Messenger 的时候，你可能没有意识到，但你的体验之下都是人工智能在驱动。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;去年 11 月，为了采访 Candela 和他团队的一些成员，我拜访了 Facebook 位于 Menlo Park 的巨型总部，所以我可以看到人工智能是如何突然就变成了 Facebook 的「氧气」的。到目前为止，人们对 Facebook 在人工智能领域的关注都主要还是集中在其世界级的 Facebook 人工智能研究团队（FAIR/Facebook Artificial Intelligence Research）&amp;mdash;&amp;mdash;该团队的领导者是大名鼎鼎的神经网络专家 Yann LeCun。FAIR 以及谷歌、微软、百度、亚马逊和苹果（这家善于保密的公司现在已经允许其研究者发表论文了）的相应机构是人工智能领域的毕业生精英最偏爱的目标选择。这些机构是脑启发数字神经网络领域重大突破的顶级生产者，是近来计算机科学领域发展的主要推动力&amp;mdash;&amp;mdash;让计算机具备了看见、听懂甚至交谈的能力。而 Candela 的应用机器学习团队（AML/Applied Machine Learning）的任务是将 FAIR 与其它前沿研究机构的研究成果整合到 Facebook 实际的产品中&amp;mdash;&amp;mdash;而也许更重要的是，助力该公司所有的工程师将机器学习整合到他们的工作中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因为没有人工智能，Facebook 就无法生存，所以它需要其所有的工程师都能用人工智能来进行开发。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我的拜访是在美国总统大选之后两天进行的，而在一天之前，Facebook 的 CEO Mark Zuckerberg 曾表示：「Facebook 上虚假新闻的流通有助于 Donald Trump 赢得大选」是个「疯狂的看法（it's crazy）」。这么评价就好比是说：认为 Facebook 是 News Feed 上虚假信息疯狂传播的共犯就像是说驾驶一辆油罐车冲向一团不断蔓延的凶猛大火。尽管这些争议中很多不是 Candela 职业之内的事情，但他知道 Facebook 对虚假新闻的最终回应将会依靠有他的团队所参与的机器学习工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但为了减轻我们采访过程中坐在我们旁边的公关人员所带来的压力，Candela 向我们展示了一些其它东西&amp;mdash;&amp;mdash;一个展示他们团队的成果的演示。让我惊讶的是，这看起来像是一个微不足道的小玩意：它以一位风格独特的画家的杰作的风格来重新绘制一张照片或一段视频流。事实上，它让我联想到了你可以在 Snapchat 上看到的数字特效，而且这种将照片转换成毕加索的立体主义风格的点子之前已经被实现了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「这背后的技术叫做神经风格迁移（neural style transfer），」他解释说，「需要训练一个大型神经网络来使用一种特定的风格来重新描绘一张原始照片。」他拿出他的手机拍了一张照片。一次点击和滑动之后，它变成了梵高的《The Starry Night》风格。更惊人的是，它可以风格渲染正在播放中的视频流。但他说，真正的不同之处在于一些我无法用眼睛看见的东西：Facebook 已经构建了可以使其在手机上工作的神经网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这同样并不新鲜&amp;mdash;&amp;mdash;苹果之前就吹嘘过自己在 iPhone 上执行过一些神经计算。但对 Facebook 来说，这项任务却难得多。因为它并不生产硬件。Candela 说他能执行这个小应用是多亏了该团队的工作积累的成果&amp;mdash;&amp;mdash;一个项目会让另一个项目更简单，综合起来可以让未来的工程师无需接受太多培训就能开发出类似的产品&amp;mdash;&amp;mdash;从而使得这样的东西可以被快速地开发出来。他说：「从开始开发这个到我们把这个成果投入公开测试，我们用去了八周时间，这是相当疯狂的。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/f26bd5b5dae16039d9b1f4c2a86432538263d842"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;从左到右）AML 工程总监 Joaquin Candela；应用计算机视觉团队负责人 Manohar Paluri;技术产品经理 Rita Aquino；工程经理 Rajen Subba&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他说，完成这样的任务的另一个秘密是协作（collaboration），这也是 Facebook 公司文化的砥柱。在这个案例中，Facebook 内部团队间的轻松可接触性使得从数据中心的图像渲染可跳跃到手机端实现该工作，尤其是移动团队密切熟悉手机硬件。这种好处不只是让你能够把朋友或亲人的照片做成名画「The Scream」中的女性那种风格的电影。而是让 Facebook 的一切都变得更强大所迈出的一步。短期内，这使得从解析语言和理解文本中得到更快的回应成为了可能。长期而言，它能够使得实时分析听见的和看见的成为可能。他说，「我们说的是秒，或者更短的时间。它必须是实时的。我们是社交网络，如果我们要根据一点内容预测人们的反馈（feedback），我们的系统需要即时作出反应，对吧？」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Candela 看了一眼刚拍的、并转成了梵高绘画风格的自拍照，骄傲溢于言表。他说，「在手机上运行复杂的神经网络，也就是要把人工智能放到每个人的手中。这并非偶然所得，而是 Facebook 内部民主化人工智能的一部分。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「这是一段漫长的旅程。」他补充说。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Candela 出生于西班牙，在他三岁时全家搬迁到了摩洛哥，于是他在那里上法语学校。虽然他的理科和文科成绩都很高，但他决定去马德里上大学，希望在那里学习他认为最难的课题：电信工程&amp;mdash;&amp;mdash;这门不仅需要掌握如天线、放大器等实物的有关知识，也要读得懂数据的「极酷」课程。他被一位解构自适应系统的教授施了魔咒。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Candela 开发了一个使用智能过滤器来改善漫游手机信号的系统；他称其为「一个婴儿神经网络」。2000 年他在丹麦度过了一个学期，那段时间的研究使他对训练算法愈加迷恋，并没有仅仅停留在研究代码的层面。在那里他与 Carl Rasmussen 不期而遇&amp;mdash;&amp;mdash;一位曾与传奇人物 Geoff Hinton（在机器学习领域有「cool kid」之称的机器学习教授）在多伦多共同研究。在临近毕业时，他本打算加入宝洁公司的一项管培计划，但当 Rasmussen 邀请他攻读博士学位时，他选择了机器学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2007 年，他来到英国剑桥的微软研究实验室工作。工作不久，他便得知一个公司内部的竞争：微软即将推出 Bing，但需要改进搜索广告的关键组件&amp;mdash;&amp;mdash;准确地预测用户何时会点击广告。而公司决定开展内部竞争。公司会测试团队的解决方案，以确认是否值得采用，而获胜团队的成员将获得一次免费的夏威夷之旅。19 支队伍进行了比赛，而 Candela 的队伍取得了胜利。他获得了免费旅行的奖励，但他感觉自己受到了欺骗&amp;mdash;&amp;mdash;他认为微软更大的奖赏在于他的成果能在通过测试后成功发布。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Candela 接下来的一系列行为显示了他的决心。为了让公司给他一个机会，他开始了「疯狂远征」。他进行了 50 多次内部会谈，并建立了一个模拟器来显示他的算法的优势；他跟踪了这个有权力做出这个决定的副总裁&amp;mdash;&amp;mdash;在等自助餐的时候站在他旁边，故意和他一起上洗手间，然后在便池那里鼓吹自己的系统；他搬到了这位高管的办公室旁边一块未被使用的地方，然后毫无预警地出现在了这个人的办公室，争辩着「说到就要做到，我的算法更好」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;将自己定位于站在自助餐线的人的身旁并同步化他的浴室之旅，而后从邻近的小便池推荐他的系统；他躲进行政部门附近的闲置空间，并突然出现在行政部门的办公室，争辩着「说到就要做到，我的算法更好」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2009 年，Candela 的算法与 Bing 一同发布。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2012 年初，Candela 拜访了在 Facebook 工作的朋友，周五在位于门洛帕克的园区待了一天。当他发现这家公司的职员不必申求成果的测试权，而是随时都可以测试时，他惊呆了。于是三天后，他去 Facebook 进行了面试，当周的周末便拿到了 offer。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Candela 加入了 Facebook 的广告团队，他的任务是领导一个能够为用户展示相关性更强的广告的团队。尽管当时他们系统确实在使用机器学习，但他说：「我们使用的模型并不高级，它们非常简单」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/5c6503d0f33fbce43a3c8ef08298013495cbd688"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Facebook 20 号楼内部场景。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一位同时加入 Facebook 的工程师是 Hussein Mehanna（他们一起参加了新员工的「代码启动训练营（code boot camp）」），他同样对公司的系统中构建人工智能方面进展的缺乏感到惊讶。Mehanna 说：「当我进入 Facebook 之前，看到产品的质量时，以为所有技术都已经成熟，但很显然不是这样。开始工作的几周内，我告诉 Joaquin：Facebook 真正缺少的是一个合适的世界级机器学习平台。我们有机器，但缺乏能够使其从数据中尽可能学习的合适软件」。（Mehanna 是如今 Facebook 的核心机器学习主任，同样是一个微软老员工&amp;mdash;&amp;mdash;和其他被采访工程师一样。这是巧合吗？）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Mehanna 所说的「机器学习平台」，是指采用大致基于大脑行为方式的模型&amp;mdash;&amp;mdash;这一范式将人工智能从上世纪荒芜的「冬天」（早期实现「会思考的机器」的希望已然渺茫）变成了如今的「百花齐绽」。在广告领域，Facebook 需要它的系统完成一个没人做得到的事情：即时（并准确！）地预测有多少人会点击指定的广告。于是 Candela 和他的团队开始创建一个基于机器学习程序的新系统。由于该团队希望将系统构建为一个所有在该部门工作的工程师都能访问的平台，他们便以一种能使建模和训练被推广与复制的方式来实现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;构建机器学习系统的一个关键因素便是获得高质量数据&amp;mdash;&amp;mdash;越多越好。这恰好是 Facebook 最大的资产之一：当每天有超过十亿人与你的产品交互，便能收集大量的数据作为训练集，并且一旦你开始测试，就能够得到无尽的用户行为实例。因此广告团队能够从几周发布一个新模型转变为每周运送多个模型。另外，因为这将会变为一个允许其他人在内部使用，以构建自己的产品的平台，所以 Candela 确保以多团队参与的方式来完成他的工作。这是一个有条不紊的三步过程。他说：「首先你应专注于性能，而后是效用，最后建立一个社区」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Candela 的广告团队已经证明，机器学习在 Facebook 可以具有多大的变革性。他说：「我们在预测点击次数、点赞、转发次数等方面取得了难以置信的成功」。自然而然，将这种方法向更大型服务推广的想法便产生了。事实上，FAIR 的领导 LeCun 已经在支持一个致力于将人工智能应用到产品中的团队&amp;mdash;&amp;mdash;特别是以一种能够使机器学习向公司内部更广泛传播的方式。LeCun 说：「我确实在努力实现它，因为你需要具有杰出的才能的工程师组织在一起，他们不会直接关注产品，而是注重能够被多种产品使用的基础技术」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2015 年 10 月，Candela 成为新的 AML 团队主管（在一段时间里，出于谨慎，他还保留着在广告部门的职位，两者兼顾）。他与位于纽约、巴黎和门洛帕克的 FAIR 保持着密切联系，那里研究人员与 AML 工程师平起平坐。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个在开发中的产品可以说明这种协作的方式，这个产品为 Facebook 上发布的图片提供语音描述。在过去几年，训练一个系统去识别场景中的物体或者进行基本总结，来判定照片是在室外还是室内拍摄，成为了一种人工智能标准实践应用。不过，最近 FAIR 的科学家已经可以训练神经元网络去识别图像中几乎每一个有意义的物体，并通过物体的位置和与其他物体的关系，来判断照片的内容&amp;mdash;&amp;mdash;通过分析姿势，来判断一张照片里的人在拥抱，或者一个人在骑马。「我们把这个给 AML 的人看了，」LeCun 说，「他们想了一会儿，说『你知道的，这在有些情况下可能会非常有用。』」最终出现的是一个为视力障碍人士准备的一项功能的原型，它可以在视力障碍人士将手指放在图片上时，让手机读出照片的描述。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们一直在交流，」Candela 说起他的兄弟团队（指代 FAIR）。「从更大的层面来说，科学理论到实际的项目，你需要『胶水』，我们就是『胶水』。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Candela 将人工智能的应用分为四个领域：视觉、语言、语音和摄像头效果。他说，所有这些，都会为一个「内容理解引擎」服务。通过掌握理解内容的方法，Facebook 试图检测到评论中的隐含意图、从口语中提取出细微的差别、从视频中识别出你朋友短暂出现的面部，以及理解你的表达，并将其绘制在虚拟现实地图中的图标上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们正在做的是人工智能的泛化，」Candela 说。「随着需要理解、分析的内容量的爆炸，我们生成可判断内容的标签的能力跟不上了。」问题的解决方案，就是开发泛化的系统，这样一个项目的工作成果可以用到其他团队的相关项目上。Candela 说，「开发出可以将知识从一个任务迁移到其他任务的算法，会非常棒，对不对？」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种知识迁移对于 Facebook 产品产出速度意义重大。拿 Instagram 来说。从这个照片服务产品的初始，用户的照片就是时间倒序呈现。不过在 2016 年年初，Instagram 决定使用相关性 sr'fa 排列照片。好消息是，因为 AML 已经在类似 News Feed 这样的产品中应用过了机器学习，「Instagram 不需要从零开始」，Candela 说。「Instagram 有一两个专业的机器学习工程师和数十个其他使用各种排序算法的团队对接。这样，他们就可以复制工作流，并且有问题可以直接沟通。」最终，Instagram 仅用了几个月就完成了这项巨大的产品改动。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于可以将其神经网络的威力与其他团队结合而产出「Facebook 规模」的功能的使用案例，AML 团队时刻准备着。「我们正在使用机器学习技术，来增强我们的核心能力，以取悦我们的用户，」AML 认知团队的带头工程师 Tommer Leyvand 说道。（他来自&amp;hellip;&amp;hellip;嘿嘿&amp;hellip;&amp;hellip;微软。）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/61d5586231d52ffa7ca3a091bec55a753587f860"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Rita Aquino, Facebook 技术产品经理&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个案例就是最近推出的社交推荐功能。一年前。一名 AML 工程师和一个 Facebook 分享团队的产品经理正在讨论一个强社交场景，即用户向朋友要求推荐当地的餐厅或者其他服务。「问题是，怎样将这个功能呈现给用户？」Rita Aquino，AML 的自然语音团队产品经理说道。（她之前也是产品经理，供职于&amp;hellip;&amp;hellip;算了，不说了）分享团队一直在尝试匹配推荐请求的词语。「那种方式并不精确，在一天 10 亿条的消息下，也无法扩大规模，」Aquino 说。通过训练神经网络，并在生活行为模型上测试，团队随后可以监测到非常细微的语言变化，并能准确检测用户是否在询问某个地区内的餐厅或者需要购买鞋子。之后，合适的联系人的 News Feed 上就会出现一条请求。下一步&amp;mdash;&amp;mdash;也由机器学习驱动&amp;mdash;&amp;mdash;判断是否有人提供了合理的推荐，并将商铺或者餐厅的地址，显示在用户的 News Feed 上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Aquino 说，在她为 Facebook 工作的一年半时间里，人工智能从产品中的罕见部分，变成了深植于产品概念中。「大家希望自己交互的产品能够更加聪明，」她说。「很多团队看到了社交推荐这样的产品，看了我们的代码，然后就问『我们怎么实现这种功能？』给你的团队实验这种用户体验，并不需要太多机器学习背景。」就自然语言处理来说，团队开发了一个可供其他团队方便访问的系统，叫做 Deep Text。这个系统可帮助使用 Facebook 翻译功能背后的机器学习技术，每天超过 40 亿条消息都会用到这项技术。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于图像和视频，AML 团队开发了名叫 Lumos 的机器学习视觉平台。该平台始于当时还是 FAIR 实习生的 Manohar Paluri。他当时正在开发一个他称为 Facebook 视觉大脑的大型机器学习视觉项目，这是一个用于处理和理解 Facebook 上发布的所有的图像和视频的工具。2014 年的黑客马拉松上，Paluri 和同事 Nikhil Johri 在一天半的时间里完成了产品的原型，并展示给激动不已的 Zuckerberg 和 Facebook COO Sheryl Sandberg。Candela 创建 AML 后，Paluri 加入了小组，并负责计算机视觉团队，开发 Lumos，帮助所有的 Facebook 工程师（包括 Instagram、Messenger、WhatsApp 以及 Oculus）使用这一视觉大脑。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有了 Lumos，「公司里的任何人都可以使用多个神经网络的功能，为自己的使用场景建立模型，检测效果，」在 AML 和 FAIR 有联合职位的 Paluri 说道。「在工作流程中，其他团队可以有人参与进来，纠正系统、进行再训练，然后上线，这并不需要 AML 团队参与。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Paluri 给我做了一个快速演示，他在他的笔记本上启动 Lumos，我们进行一个样本任务：优化神经网络识别直升机的能力。一个包含图像的网页&amp;mdash;&amp;mdash;如果我们继续刷屏，图像数量将达到 5000 张&amp;mdash;&amp;mdash;出现在屏幕上，充满了直升机的图片，还有一些不是直升机的图片。对于这些数据集（Facebook 使用公开发布的图像），这些图像具有仅限朋友查看或其他分组不受限制的属性。尽管我完全不是一个工程师，更不是人工智能专家，点击负样本以训练直升机图像分类器对我来说并不难，我就像行家一样完成了它。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最终，这种分类步骤&amp;mdash;&amp;mdash;被称为监督学习&amp;mdash;&amp;mdash;可能变得自动化，就像公司追求的机器学习圣杯「无监督学习」那般，神经网络有能力自己找出所有这些图片中都有些什么。Paluri 说：「公司正在取得进展，他说，在下一年我们的目标是把人工标注的数量降低 100 倍。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;长远来看，为了 Candela 所说的通用内容理解引擎（generalized content understanding engine），Facebook 会将视觉皮层与自然语言平台的融合。Paluri 说：「无疑我们最终会把它们结合在一起，接着我们会把它做成皮层（cortex）。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最终，Facebook 希望用于取得进步的核心原理通过论文发表等方式扩展到公司之外，从而使其民主化方法论（democratizing methodology）更广泛地传播机器学习。Mehanna 说：「摈弃花费数年时间努力建构一个智能应用的方式，其实你可以更快地构建应用。想象一下其在医药、安全和交通领域的影响。我认为这些领域应用的构建将快上 100 倍。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/280554584432d237fc32aa375bb3b8939b025c14"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;2017 年 2 月 6 号，Facebook 应用计算机视觉团队负责人 Manohar Paluri 在加利福尼亚 Menlo 公园 20 号楼，照片由 Stephen Lam 拍摄&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管 AML 深度参与了帮助 Facebook 产品能看能听能解释的史诗般进程，扎克伯格也看到其对 Facebook 作为一家社会公益公司的愿景至关重要。在扎克伯格关于构建未来社区的 5700 词的宣言中，他 7 次引用了「人工智能」，并且全部是在机器学习及其他技术如何使未来社区更安全、更加信息化的背景下引用的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;实现这些目标并不容易，相同原因是 Candela 首先担心参加 AML 工作。当你试图连接几十亿人并为其提供主要的信息源时，问题就会出现，即使机器学习也不能完全解决这些来自人的问题。这就是为什么持续更新算法以决定用户在其新闻推送中将看到什么。当你并不确定那是什么时，你如何训练一个网络来传递最优组合。Candela 说：「我认为这个问题几乎不可能解决。我们随机推送新闻故事意味着你在浪费自己的时间，不是吗？我们只推送一个朋友的新闻故事，赢者通吃。你可以彻底结束这个一轮又一轮的讨论，其中没有最优解。我们尝试做一些探索。」Facebook 将会继续用人工智能来解决这个问题，人工智能不可避免地成为了问题的通用解决方案。Candela 看起来满怀希望地说：「在机器学习和人工智能方面有一系列的行动研究来优化探索的恰当水平。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然，当 Facebook 发现自己受假新闻牵连并被当成罪魁祸首时，它会快速召集人工智能团队从服务中清除虚假新闻。这是一次不同寻常的集体行动，其中甚至包括眼光长远的常被作为顾问的 FAIR 团队。LeCun 说。结果证明，FAIR 的努力产生了一个解决问题的工具：被称作 World2Vec 的模型（「vec」是科技术语向量（vector）的缩写，参阅：http://www.pamitc.org/cvpr15/files/lecun-20150610-cvpr-keynote.pdf）。World2Vec 给神经网络带来了一种记忆能力，帮助 Facebook 用信息标注每一条内容，比如内容是谁发的，谁又分享了该内容。（不要把它和谷歌的 Word2Vec 搞混了，一开始我就这样）有了这些信息，Facebook 可以理解假新闻的特征及分享模式，使得通过机器学习策略根除假新闻有了可能。「事实证明，验证假新闻与找到用户最想看的网页并没有什么大不同。」LeCun 说。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Candela 团队建立的平台使得 Facebook 能够最快的速度推出需要审查的产品。它们实际表现如何仍有待观察。Candela 说，目前讨论这些算法减少假新闻的能力还为时过早。但无论这些新措施是否有效，目前的困境提出了另一个问题：一个解决问题的算法&amp;mdash;&amp;mdash;即使是机器学习算法&amp;mdash;&amp;mdash;也可能会产生意想不到的甚至有害的后果。有些人认为在 2016 年这样的事已经发生了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Candela 反对这种观点。「我认为我们已经使世界变得更美好了。」他说道，并讲了一个故事。在采访的前一天，Candela 打电话给一位只有一面之缘的 Facebook 用户&amp;mdash;&amp;mdash;一个朋友的父亲。他看到那个人在 Facebook 上发布了支持特朗普的故事，并对此感到困惑。然后 Candela 意识到他的工作是根据数据做出决定，他缺少重要的信息。所以他联系了这个人并请求进行谈话。对方同意之后他们进行了电话沟通。「这没有改变我的世界，但让我学会了以一个非常不同的方式来观察事情的方法，」Candela 说。「在一个没有 Facebook 的世界里，我永远不会和他出现交集。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「换句话说，虽然人工智能是必要的&amp;mdash;&amp;mdash;甚至是决定性的&amp;mdash;&amp;mdash;但对于 Facebook 来说，人工智能并不是唯一的答案。「目前的挑战是人工智能还处于起步阶段，」Candela 说。&lt;/span&gt;&lt;span&gt;「我们只是刚刚上路。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文链接：https://backchannel.com/inside-facebooks-ai-machine-7a869b922ea7#.vjhbmd6zx&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Sat, 25 Feb 2017 15:24:24 +0800</pubDate>
    </item>
    <item>
      <title>学界 | 普林斯顿联手英特尔：用机器学习和高性能计算破解大脑密码</title>
      <link>http://www.iwgc.cn/link/</link>
      <description>
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自Princeton&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Catherine Zandonella&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀、晏奇、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote style="color: rgb(62, 62, 62); font-size: 16px; white-space: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/blockquote&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;近日，普林斯顿大学和英特尔的研究者在 Nature Neuroscience 上发表了一篇论文《Computational approaches to fMRI analysis》，介绍了普林斯顿和英特尔在破解大脑思维上的研究成果：实现了对 fMRI 脑扫描的实时计算分析，点击文末「阅读原文」可查看原论文。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今年早些时候，大约 30 位神经科学家和计算机程序开发者聚集到了一起，试图提升他们读取人类心智的能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这场黑客马拉松（hackathon）是普林斯顿大学和世界最大的计算机处理器制造商英特尔联合举办的一系列活动中的一个，这些活动的目的是为了构建能够实时读取人们的想法的程序。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;普林斯顿大学和英特尔的这个研究合作推动了解码数字大脑数据（来自功能性磁共振成像（fMRI）方面的快速发展，有望帮助揭示出带来学习、记忆和其它认知功能的神经活动。近日，一篇关于解码大脑扫描的计算方法上进展的概述论文被发表在了 Nature Neuroscience 上，作者包括普林斯顿神经科学研究所和普林斯顿计算机科学与电气工程系的研究人员，以及英特尔的 Intel Labs 的研究者。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「实时监测大脑功能的能力对于提升对大脑疾病的诊断和治疗以及对心智工作方式的基础研究都有很大的潜力。」普林斯顿神经科学研究所联合主任、Robert Bendheim and Lynn Bendheim Thoman 教授 Jonathan Cohen 说，他也是与英特尔的这个合作的创始成员之一。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自从这项合作两年前开始以来，这些研究者已经将从大脑扫描中提取想法的时间从数天减少到的不到一秒钟，Cohen 说，他同时还是一位心理学教授。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种实验受益于在黑客马拉松期间诞生的对思想的实时解码。这项研究由普林斯顿神经科学研究所的前博士后 J. Benjamin Hutchinson（现在是东北大学的助理教授）设计，目的是探索当一个人关注其环境或注意力游移到其它想法或记忆时的大脑活动。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这个实验中，Hutchinson 要求一位研究志愿者（一位躺在 fMRI 扫描仪中的研究生）查看一张关于一家拥挤的咖啡馆里人们的细节丰富的照片。Hutchinson 可以在控制室的计算机上实时地分辨出该研究生是否正在关注这张图片，还是说其思想已经游移到别处去了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然后 Hutchinson 可以给该研究生反馈她关注这张图片的程度&amp;mdash;&amp;mdash;当她正关注这张图片时，图片会变得更清晰更明亮；当她思想飘走时，图片就会变得暗淡。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这项正在进行的研究可以帮助想要更加了解大脑的神经科学家，也可以帮助想要设计更高效的算法和快速处理大规模数据集的处理方法的计算机科学家。位于俄勒冈 Hillsboro 的 Intel Labs 的资深首席科学家 Theodore Willke 如是说，他同时也是英特尔的 Mind's Eye Lab 的负责人和这项合作中英特尔团队的领导。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「英特尔感兴趣的是为高性能计算开发新兴的应用，与普林斯顿的合作为我们带来的新的挑战。」Willke 说，「我们也希望将我们从对人类智能和认知的研究中所收获的东西导入到机器学习和人工智能中，从而实现其它重要的目标，比如更安全的自动驾驶、更快的药物发现和更容易的癌症早期检测。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自从 fMRI 在 20 年前发明以来，研究者就一直在不断提升从每一次扫描的巨量数据中进行筛选的能力。fMRI 扫描仪可以获取血流变化的信号&amp;mdash;&amp;mdash;这些信号会在我们时时刻刻思考的大脑中产生。但要从这些测量中读到一个人的真正想法还很困难，要做实时那更是难上加难。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;普林斯顿及其它机构已经开发出了一些处理这些数据的技术。比如，普林斯顿大学的 Peter Ramadge 教授的研究工作可以通过结合来自多人的脑扫描数据来识别对应于特定想法的脑活动模式。设计计算机化的指令（即算法）来执行这些分析仍然还是一个重大的研究领域。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;强大的高性能计算机帮助减少了执行这些分析的时间，因为我们可以将一个任务分成不同的块然后并行执行。据普林斯顿计算机科学 Paul M. Wythes '55 P86 and Marcia R. Wythes P86 教授 Kai Li 说，这项合作中更好的算法与并行计算的结合最后帮助实现了实时的脑扫描处理。Kai Li 教授也是该合作的创始人之一。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;iframe allowfullscreen="" class="video_iframe" data-vidtype="1" frameborder="0" height="417" src="https://v.qq.com/iframe/preview.html?vid=s0378is1akq&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0" width="556"&gt;&lt;/iframe&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;普林斯顿大学和 Intel Labs 已经开发出了能够在大脑被 fMRI 扫描时实时解读想法的软件。其目标是揭示出对应于学习、记忆和其它脑功能的神经活动。在该视频中，心理学教授 Nicholas Turk-Browne 解释了一个典型的实验&amp;mdash;&amp;mdash;在控制室的研究者可以监控躺在 fMRI 扫描仪中的志愿者关注一张繁忙的咖啡馆场景图片中特定人物的能力。该实验由 J. Benjamin Hutchinson 设计。普林斯顿计算机科学博士及现 Intel Labs 的研究者 Yida Wang 帮助设计了实现对 fMRI 数据的实时分析的软件。视频中出现的另一个人是研究生 Anne Mennen，其正使用这种实时分析技术来研究学习和记忆。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;一次真正的合作&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自 2015 年合作开始，英特尔为普林斯顿提供了价值超过 150 万美元的计算机硬件设备与帮助来支持学校研究生与博士后的研究工作。同时，英特尔也专门雇了 10 个计算机科学家与普林斯顿合作开发此项目，这些专家与普林斯顿的教师、学生、博士后进行了深度合作以改进提升软件效能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些算法通过机器学习技术来在数据中对思维进行定位，就像面部识别技术可以帮助用户在社交媒体平台（比如 Facebook）上搜索自己的朋友。机器学习技术需要让计算机获得足够大量的学习样本，从而以便计算机能够对它们从未见过的事物进行分类。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此次合作的一个结果是一套名为 Brain Imaging Analysis Kit (BrainIAK：http://brainiak.org/ ) 的软件工具包。目前，它已经在网上开源可供任何想处理 fMRI 数据的研究者使用。团队现在正在开发一款实时分析服务。「我们的想法是，即便是那些没有能力接触到高性能计算设备的研究者，或者是那些不太清楚如何在这样的计算设备上编写程序来运行分析的人，也可以使用我们开发的这些工具来对大脑扫描数据进行实时解码分析。」Li 说道。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些科学家对大脑的研究也许最终可以帮助人们克服在注意力或者其它需要及时反馈的疾病上的困难。比如，实时反馈也许可以帮助病人训练他们的大脑来削弱闯入记忆（Intrusive Memory）。尽管这种「大脑训练」的方法需要进一步验证以确定大脑是在学习新的模式而不是变得仅仅擅长于训练任务，但是这些反馈方法提供了新的治疗潜力，Cohen 说道。对大脑的实时分析也可以帮助临床医生做出诊断。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「这种实时解码大脑的能力已经在对脑的基础研究中得到应用。」普林斯顿神经科学系心理学教授 Kenneth Norman 说道，「作为认知神经科学家，我们对于大脑是如何产生思维这件事非常感兴趣。」他继续道「对这些信息的实时处理大大提升了我们科研能力的范围。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;一扇了解人类思维的窗口&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这项技术还可以被用来研究我们人类是如何学习的。例如，当一个人正在听一堂数学讲座，特定的神经模式就会被激活。据 Norman 说，通过观察那些能跟上讲座内容的人的神经模式，研究者能够来分析它们是如何与那些跟不上讲座的人的神经模式相区别的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这项合作正在致力于通过改进技术以获得对人类思考的更清楚的探究。例如，它可以实时解码当一个人看到一张特定面孔时其意识活动的情况。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;计算机科学家需要克服的一个挑战是如何把机器学习应用到扫描大脑生成的数据类型上。一个面部识别算法能够扫描成千上万张照片，从而学会分类。但在扫描大脑上，研究人员通常只有每个人的数百份扫描。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管扫描的数量有限，每个扫描却包含丰富的数据。软件把大脑图像分到小的立方体中，每个立方体大约 1 毫米宽。这些立方体被称为体素（voxel），是二维图像中像素的三维版本。每个立方体中的大脑活动是持续变化的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而更为复杂的问题是大脑区域间的连接带来了我们的思想。一次典型的扫描包括 10 万个体素，如果每个体素能与其他的体素进行交流，可能存在的交流就是无限的。而且这些交流能一秒接一秒的变化。英特尔与普林斯顿计算机科学家之间的合作克服了这些计算挑战。参与这一工作的有 Li 和计算机科学助理教授 Barbara Engelhardt，以及 2016 年在普林斯顿获得计算机科学博士学位，如今在英特尔实验室工作的 Yida Wang。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;普林斯顿心理学教授 Nicholas Turk-Browne 说，在此之前研究人员需要花费数月时间来分析数据集。有了实时的 fMRI 之后，研究人员能够在进行中调整试验。他说：「如果我的假设涉及到大脑的某个区域，实时检测的时候发现试验并不符合该脑区。那么我们就能让志愿者调整到更好的符合该脑区，这能极大地节省时间，能加速科学发现。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;顾一段特别的记忆，比如童年，我们希望能够在屏幕上生成这段经历的照片。这仍旧很遥远，但我们在不断进步。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由 Jonathan Cohen、 Nathaniel Daw 等人合著的论文「Computational approaches to fMRI analysis」发表到了 Nature Neuroscience 的 3 月刊上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;论文：fMRI 分析的计算方法（Computational approaches to fMRI analysis）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/497fc0689317410d39099326d5a01ad7346e6179"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：认知神经科学领域的分析方法（analysis methods）并不总是能够应付 fMRI 数据的丰富度。早期的方法的关注重点是估计单个体素（voxel）或区域内的神经活动，求的是试验或块上的平均，然后再分别对每个参与者建模。这种方法基本上忽略了体素上神经表征的分布式本质、任务过程中神经活动的连续动态、对多个参与者执行联合推理的统计学优势以及使用预测模型来约束分析的价值。最近一些探索性的和理论驱动的方法已经开始尝试追求这些机会。这些方法强调了在 fMRI 分析中计算技术的重要性，尤其是机器学习、算法优化和并行计算。这些技术的采用正在实现新一代的实验和分析，并有望改变我们对一些大脑中最复杂的&amp;mdash;&amp;mdash;也明显是人类的&amp;mdash;&amp;mdash;信号的理解，即认知行为，比如思想、意图和记忆。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文链接：http://www.princeton.edu/main/news/archive/S48/77/80I20/index.xml?section=topstories&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Sat, 25 Feb 2017 15:24:24 +0800</pubDate>
    </item>
    <item>
      <title>干货 | 机器学习需要哪些数学基础？</title>
      <link>http://www.iwgc.cn/link/</link>
      <description>
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自data conomy&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：WALE AKINFADERIN&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：马亚雄、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote style="color: rgb(62, 62, 62); font-size: 16px; white-space: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;过去的几个月中，有几人联系我，诉说他们对尝试进入数据科学的世界，以及用机器学习的技术去探索统计规律并构建无可挑剔的数据驱动型产品的热忱。然而，我发现一些人实际上缺乏必要的数学直觉和知识框架去得到有用的结果。这便是我决定写这篇博文的主要原因。最近涌现出了很多易于使用的机器学习和深度学习的软件包，例如 scikit-learn, Weka, Tensorflow 等等。机器学习理论是统计学、概率学、计算机科学以及算法的交叉领域，是通过从数据中的迭代学习去发现能够被用来构建智能应用的隐藏知识。尽管机器学习和深度学习有着无限可能，然而为了更好地掌握算法的内部工作机理和得到较好的结果，对大多数这些技术有一个透彻的数学理解是必要的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/5b94fb144ae003969b1b7bd63c78a5c8c1c073c6"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;逻辑回归和神经网络的代价函数的计算方法&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;为什么要重视数学？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器学习中的数学是重要的，有很多原因，下面我将强调其中的一些：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 选择正确的算法，包括考虑到精度、训练时间、模型复杂度、参数的数量和特征数量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 选择参数的设置和验证策略。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 通过理解偏差和方差之间的 tradeoff 来识别欠拟合与过拟合。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4. 估计正确的置信区间和不确定度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;你需要什么水平的数学？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当你尝试着去理解一个像机器学习（ML）一样的交叉学科的时候，主要问题是理解这些技术所需要的数学知识的量以及必要的水平。这个问题的答案是多维的，也会因个人的水平和兴趣而不同。关于机器学习的数学公式和理论进步正在研究之中，而且一些研究者正在研究更加先进的技术。下面我会说明我所认为的要成为一个机器学习科学家/工程师所需要的最低的数学水平以及每个数学概念的重要性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 线性代数：我的一个同事 Skyler Speakman 最近说过，「线性代数是 21 世纪的数学」，我完全赞同他的说法。在机器学习领域，线性代数无处不在。主成分分析（PCA）、奇异值分解（SVD）、矩阵的特征分解、LU 分解、QR 分解、对称矩阵、正交化和正交归一化、矩阵运算、投影、特征值和特征向量、向量空间和范数（Norms），这些都是理解机器学习中所使用的优化方法所需要的。令人惊奇的是现在有很多关于线性代数的在线资源。我一直说，由于大量的资源在互联网是可以获取的，因而传统的教室正在消失。我最喜欢的线性代数课程是由 MIT Courseware 提供的（Gilbert Strang 教授的讲授的课程）：http://ocw.mit.edu/courses/mathematics/18-06-linear-algebra-spring-2010/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 概率论和统计学：机器学习和统计学并不是迥然不同的领域。事实上，最近就有人将机器学习定义为「在机器上做统计」。机器学习需要的一些概率和统计理论分别是：组合、概率规则和公理、贝叶斯定理、随机变量、方差和期望、条件和联合分布、标准分布（伯努利、二项式、多项式、均匀和高斯）、时刻生成函数（Moment Generating Functions）、最大似然估计（MLE）、先验和后验、最大后验估计（MAP）和抽样方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 多元微积分：一些必要的主题包括微分和积分、偏微分、向量值函数、方向梯度、海森、雅可比、拉普拉斯、拉格朗日分布。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4. 算法和复杂优化：这对理解我们的机器学习算法的计算效率和可扩展性以及利用我们的数据集中稀疏性很重要。需要的知识有数据结构（二叉树、散列、堆、栈等）、动态规划、随机和子线性算法、图论、梯度/随机下降和原始对偶方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;5. 其他：这包括以上四个主要领域没有涵盖的数学主题。它们是实数和复数分析（集合和序列、拓扑学、度量空间、单值连续函数、极限）、信息论（熵和信息增益）、函数空间和流形学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一些用于学习机器学习所需的数学主题的 MOOC 和材料是（链接经过压缩）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;可汗学院的线性代数（http://suo.im/fgMNX）、概率与统计（http://suo.im/CqwY9）、多元微积分（http://suo.im/xh6Zn）和优化（http://suo.im/1o2Axs）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;布朗大学 Philip Klein 的「编程矩阵：计算机科学应用中的线性代数（Coding the Matrix: Linear Algebra through Computer Science Applications）」：http://codingthematrix.com&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;得克萨斯大学的 Robert van de Geijn 在 edX 上的 Linear Algebra &amp;ndash; Foundations to Frontiers：http://suo.im/hKRnW&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;戴维森学院 Tim Chartier 的新课程 Applications of Linear Algebra；第一部分：http://suo.im/48Vary，第二部分：http://suo.im/3Xm3Lh&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Joseph Blitzstein 的 Harvard Stat 110 lectures：http://suo.im/2vhVmb&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Larry Wasserman 的书《All of statistics: A Concise Course in Statistical Inference》，下载：http://suo.im/v9u7k&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;斯坦福大学的 Boyd 和 Vandenberghe 的关于凸优化的课程：http://suo.im/2wdQnf&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Udacity 的 Introduction to Statistics 课程：http://suo.im/1enl1c&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;吴恩达授课的 Coursera/斯坦福大学的机器学习课程：http://suo.im/1eCvp9&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这篇博文的主要目的是给出一些善意的关于数学在机器学中的重要性的建议，一些一些必需的数学主题以及掌握这些主题的一些有用的资源。然而，一些机器学习的痴迷者是数学新手，可能会发现这篇博客令人伤心（认真地说，我不是故意的）。对于初学者而言，你并不需要很多的数学知识就能够开始机器学习的研究。基本的吸纳觉条件是这篇博文所描述的数据分析，你可以在掌握更多的技术和算法的过程中学习数学。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Sat, 25 Feb 2017 15:24:24 +0800</pubDate>
    </item>
    <item>
      <title>一周论文 | 2016年最值得读的NLP论文解读（3篇）+在线Chat实录</title>
      <link>http://www.iwgc.cn/link/</link>
      <description>
&lt;h3 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;引言&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;本期Chat是PaperWeekly第一次尝试与读者进行互动交流，一共分享和解读3篇paper，均选自2016年最值得读的自然语言处理领域paper，分别是：&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="margin-top: 15px; margin-left: 20px; max-width: 100%; font-size: 16px; font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); color: rgb(68, 68, 68); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;li&gt;&lt;p&gt;End-to-End Reinforcement Learning of Dialogue Agents for Information Access&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Dual Learning for Machine Translation&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;SQuAD: 100,000+ Questions for Machine Comprehension of Text&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;h3 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="1. End-to-End Reinforcement Learning of Dialogue Agents for Information Access"&gt;&lt;/a&gt;&lt;strong&gt;1.&amp;nbsp;End-to-End Reinforcement Learning of Dialogue Agents for Information Access&lt;/strong&gt;&lt;/h3&gt;&lt;h4 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="作者"&gt;&lt;/a&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;Bhuwan Dhingra, Lihong Li, Xiujun Li, Jianfeng Gao, Yun-Nung Chen, Faisal Ahmed, Li Deng&lt;/p&gt;&lt;h4 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="单位"&gt;&lt;/a&gt;&lt;strong&gt;单位&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA&lt;br&gt;Microsoft Research, Redmond, WA, USA&lt;br&gt;National Taiwan University, Taipei, Taiwan&lt;/p&gt;&lt;h4 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="关键词"&gt;&lt;/a&gt;&lt;strong&gt;关键词&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;Dialogue Agent, Reinforcement Learning&lt;/p&gt;&lt;h4 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="文章来源"&gt;&lt;/a&gt;&lt;strong&gt;文章来源&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;arXiv&lt;/p&gt;&lt;h4 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="问题"&gt;&lt;/a&gt;&lt;strong&gt;问题&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;用强化学习构造一个端到端的任务驱动的基于知识图谱的对话系统。&lt;/p&gt;&lt;h4 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="模型"&gt;&lt;/a&gt;&lt;strong&gt;模型&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;一个任务驱动的对话系统，一般通过自然语言与用户进行多轮交流，帮助用户解决一些特定问题，例如订机票或检索数据库等。一般由下面四部分组成：&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="margin-top: 15px; margin-left: 20px; max-width: 100%; font-size: 16px; font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); color: rgb(68, 68, 68); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;li&gt;&lt;p&gt;Language Understanding Module(LU): 理解用户意图并提取相关slots。例如用户想找一部电影，那么就需要提取出电影名称，演员，上映时间等相关slots信息。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Dialogue State Tracker: 追踪用户的目标和对话的历史信息。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Dialogue Policy: 基于当前状态选择系统的下一步action, 例如向用户询问电影上映时间的action是request(year)。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Natural Language Generator(NLG):将系统的action转化成自然语言文本。例如将request(year) 转换成：电影什么时候上映的？&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;在Dialogue Policy这一步，传统方法一般是生成一个类似SQL的查询语句，从数据库中检索答案，但是这会使模型不可微从而只能分开训练。本文使用了基于概率的框架，因此是可微的，从而实现了端到端的训练过程。&lt;/p&gt;&lt;p&gt;论文中用到的数据库，是来自IMDB的电影数据库。每一行代表一部电影，每一列是一个slot，信息有可能存在缺失。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;a rel="gallery0" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="enter image description here"&gt;&lt;img src="http://img05.iwgc.cn/mpimg/9b5e879ba672ea62e728b9710b8e191634abfbd9"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;整体框架如下图：&lt;/p&gt;&lt;p&gt;&lt;a rel="gallery0" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="enter image description here"&gt;&lt;img src="http://img05.iwgc.cn/mpimg/279938fd5081fd881560ab40146f245c48a72c45"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;下面分别介绍各个部分：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Feature Extractor&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;将用户每轮的输入文本转化成一个向量，这里使用了ngram词袋模型(n=2)。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Belief Trackers&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;用于追踪对话状态和历史信息。&lt;/p&gt;&lt;p&gt;这里针对每一列的slot,分别有一个belief tracker。每个belief tracker的输入是从feature extractor得到的向量，用GRU处理以后，得到一个状态向量。根据这个状态向量，分别计算得到两个输出：pj和qj。&lt;/p&gt;&lt;p&gt;pj是当前slot下所有值的概率分布，qj是用户不知道这个slot值的概率。&lt;/p&gt;&lt;p&gt;因为在和用户交互的过程中，应当尽可能询问用户知道的信息，询问用户不知道的信息对后面的查询没有任何意义。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Soft-KB Lookup&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;根据Belief Trackers的输出，计算数据库中每个值的概率分布。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Beliefs Summary&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;由Belief Trackers和Soft-KB Lookup,可以得到当前的对话状态向量st。st向量包含了数据库中所有值的概率分布户是否知识等信息，实在是太大了，直接送给Policy Network会导致其参数过多，难以训练。因此这一步把slot-values转化成了加权的熵统计信息。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Policy Network&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这里使用策略网络，根据Beliefs Summary的输入状态向量，来输出各个action的概率分布&amp;pi;。具体结构是GRU+全连接层+softmax的方式。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Action Selection&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这里从策略分布&amp;pi;采样，得到下一步的action。如果action是inform(),说明到了对话的最后一步，需要给用户返回Top k的查询结果。这里按照Soft-KB Lookup步骤中得到的每一行电影的概率，进行采样来返回Top K候选。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;NLG&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这里的NLG部分和上面是独立的，使用了sequence-to-sequence模型，输入action,输出包含slot的对话模板，然后进行填充，得到自然语言文本。&lt;/p&gt;&lt;h4 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="训练"&gt;&lt;/a&gt;&lt;strong&gt;训练&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;这里用的基于策略梯度的强化学习模型进行训练，目标是最大化reward的期望。最后一轮inform部分的reward是由正确答案在Top K候选中的排序位置决定，排序越靠前，reward越高。如果候选没有包含正确答案，那么reward是-1。&lt;/p&gt;&lt;p&gt;对话交互训练数据是通过一个模拟器从电影数据中采样生成得到。&lt;/p&gt;&lt;h4 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="Baselines"&gt;&lt;/a&gt;&lt;strong&gt;Baselines&lt;/strong&gt;&lt;/h4&gt;&lt;ul class=" list-paddingleft-2" style="margin-top: 15px; margin-left: 20px; max-width: 100%; font-size: 16px; font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); color: rgb(68, 68, 68); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;li&gt;&lt;p&gt;End2End-RL：本文提出的模型。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Rule-based：Belief Trackers和Policy部分都是人工规则。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Simple-RL：只有Belief Trackers是人工规则，而Policy部分是基于GRU。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;实验结果如下图：&lt;/p&gt;&lt;p&gt;&lt;a rel="gallery0" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="enter image description here"&gt;&lt;img src="http://img04.iwgc.cn/mpimg/a66cfedcd0149ff52dde459e6ba85e32b3929aa5"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;h4 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong&gt;&lt;br&gt;&lt;/strong&gt;&lt;/h4&gt;&lt;h4 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="相关工作"&gt;&lt;/a&gt;&lt;strong&gt;相关工作&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;对话的相关工作很多，包括传统基于Markov Decision Processes的POMDPs, 基于Q-Learning的SimpleDS，基于API查询的方法，基于最小化熵的EMDM等等，感兴趣的读者可以查询相关文献。&lt;/p&gt;&lt;h4 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="简评"&gt;&lt;/a&gt;&lt;strong&gt;简评&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;深度强化学习在对话系统的应用越来越多，本文最大的贡献，是提出了一个可微的基于概率的框架，从而使End-to-End训练成为可能，相比传统方法各部分分别训练，联合训练可以有效的减少错误传递。而基于深度强化学习的训练方式，相比传统基于规则的方式，在高噪音输入的情况下，有着更好的表现。&lt;/p&gt;&lt;h4 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="完成人信息"&gt;&lt;/a&gt;&lt;strong&gt;完成人信息&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;王哲，中国科学技术大学，xiaose@mail.ustc.edu.cn。&lt;/p&gt;&lt;hr style="max-width: 100%; font-size: 16px; font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); color: rgb(68, 68, 68); box-sizing: border-box !important; word-wrap: break-word !important;"/&gt;&lt;p&gt;&lt;strong&gt;Chat实录&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;br&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;问&lt;/strong&gt;：我对&amp;ldquo;因此这一步把slot-values转化成了加权的熵统计信息&amp;rdquo;的合理性和物理意义有些不明，我在最近的论文中很少看到这样的做法，请问是因为效果的原因吗？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;答&lt;/strong&gt;：&amp;nbsp;这个熵指的是信息熵，不是物理中的热力学熵。信息熵把一个系统的不确定性，按照其可能出现结果的概率分布，进行定量化计算，得到的是可以获取的信息量大小。信息熵越大，不确定性就越大，我们可以获取的信息量也就越大。任务驱动的问题系统，在得到最终查询结果前，希望尽可能多的从用户那里获取信息，减少系统本身的不确定性，因此我们在知道一个slot中各种实体概率的情况下，用信息熵来度量一个slot的不确定性，还是挺合理挺自然的。&lt;br&gt;熵的用法在深度学习网络中还是挺多的,例如我们经常用交叉熵做损失函数。同时文本分类任务中，经常用TFIDF值作为特征，而TFIDF值是可以由信息熵推导出来的。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;问&lt;/strong&gt;：论文中提到：&amp;rdquo;Moreover, instead of defining an attention distribution directly over the KB entities, which could be very large, we instead induce it from the smaller distributions over each relation (or slot in dialogue terminology) in the KB&amp;rdquo; 这里smaller distributions ， 以及each relation怎么理解，为什么能小？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;答&lt;/strong&gt;：&amp;nbsp;这里的relation，指的是slots,也就是表格的各个列属性，例如year,actor等。 和entities的数目相比，一个slot对应的属性值数目要小很多。entity概率计算的时候，是把各个属性的概率相乘得到的。而一个属性的概率，取决于这个属性有多少值，假设我们有3个属性，每个属性的值的数目分别是k1,k2,k3，那么entities可能的计算量就是k1 * k2 * k3。现在作者假设每个属性之间是相互独立的,因此实际计算量可以理解成k1+k2+k3，所以slots的属性分布和entities分布相比，是smaller distributions。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;问&lt;/strong&gt;：增强学习在chatbot研究中使用时相比监督学习有哪些优势和劣势？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;答&lt;/strong&gt;：&amp;nbsp;先说说强化学习的优势：&lt;/p&gt;&lt;p&gt;监督学习当前研究比较多的，是以seq2seq为代表的生成模型。 它目前一个比较大的问题，是生成结果缺乏多样性，倾向于生成比较安全比较常见的回答，例如&amp;ldquo;谢谢&amp;rdquo;，&amp;ldquo;不知道&amp;rdquo;。 这个主要是因为，训练目标是用最大似然拟合训练数据，而经常在训练数据中出现的回答，会占一些优势，因此后续有很多工作试图改进这个问题，例如用互信息作为目标函数，在解码搜索过程中，对常见结果进行惩罚，提高生成结果的多样性等等。&lt;/p&gt;&lt;p&gt;监督学习的另外一个问题，是训练过程和预测过程不一致。训练的时候，当我们解码生成一个句子的下一个词的时候，是基于训练语料中的正确结果，而预测的时候，我们并不知道标准答案是什么，因此解码下一个词的时候，是基于我们预测的结果。这种不一致会影响最终结果，就像考试我们遇到之前没有见过的题型，我们的考试成绩可能会变差一样。增强学习，有希望解决这两个问题的。&lt;/p&gt;&lt;p&gt;针对第一个问题，我们借助增强学习的reward,引入一些明确的的奖励目标，用来指导对话的生成。例如，如果我们想训练一个淘宝客服的对话系统，我们可以用商品最终是否购买，来作为奖励目标，这样可以引导对话向着商品成功购买的方向发展，因此可以产生更好的对话结果。目前还有一个最新的工作，是将生成对抗网络，引入对话系统，因为当前对话系统一个很大的问题，是缺乏可靠的自动化评价指标，而对抗生成网络中，我们有一个生成模型，也就是我们的对话生成系统，还有一个判别模型，这个判别模型的目标，是判断这个对话，是机器生成的，还是人写的，这样就引入了一个比较明确的奖励目标，也更接近图灵测试，而连接生成网络和判别网络的桥梁，就是强化学习。因为NLP的词，相比图像，是离散的，我们可以借助类似AlphaGo中的蒙特卡洛搜索，来采样得到训练样本，送给判别模型。针对第二个问题，强化学习在训练的过程中，生成模型是通过采样产生样本，这个过程和预测是一致的，因此也避免了不一致带来的问题。&lt;/p&gt;&lt;p&gt;综上所述，增强学习在对话系统中有很大的优势。&lt;/p&gt;&lt;p&gt;下面说说他的劣势：&lt;/p&gt;&lt;p&gt;和监督学习相比，强化学习的训练是比较困难的，因为训练的过程很不稳定。而且具体的对话系统中，reward的奖励一般是基于一个完整的句子，而如何把reward奖励分配到具体的词，是一个很大的挑战。而在多轮对话中，reward一般只出现在最后一轮，如何对前面的几轮对话分配reward,也同样是一个问题。同时为了稳定强化学习的训练过程，我们不能完全离开监督学习，一般还需要借助监督学习的方法，来做初始化训练，甚至在训练过程中，需要穿插监督学习过程，起到稳定网络的作用。&lt;br&gt;以上就是增强学习在对话系统中的优劣。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;问&lt;/strong&gt;：论文中的pr(Gj＝i｜j＝0)为什么等于1/N呢？也就是在用户不知道第值时，目标是i的概率为什么等于1/N？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;答&lt;/strong&gt;：&amp;nbsp;用户不知道第j个属性，也就是说，在第j个属性上，用户不能提供有效信息。那么我们从属性j的角度，看各个实体的时候，实际上是没有什么区别的。因此最保险的方式，就是假设各个实体的概率相等，因此概率是1/N。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;问&lt;/strong&gt;：增强学习在chatbot中的reward函数是否都是根据相应的需求来手动给出，而非学习得来？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;答&lt;/strong&gt;：&amp;nbsp;有些是可以手动给出的，例如Bengio的An Actor-Critic Algorithm for Sequence Prediction这篇论文，就把BLEU作为reward，用于机器翻译模型的训练。reward也可以学习得来，例如GAN应用到对话系统的时候，生成模型的reward就是由判别模型给出的，而在对偶学习中，一个模型的reward由它对应的对偶模型给出。&lt;/p&gt;&lt;hr style="max-width: 100%; font-size: 16px; font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); color: rgb(68, 68, 68); box-sizing: border-box !important; word-wrap: break-word !important;"/&gt;&lt;h3 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;br&gt;&lt;/h3&gt;&lt;h3 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="2. Dual Learning for Machine Translation"&gt;&lt;/a&gt;&lt;strong&gt;2.&amp;nbsp;Dual Learning for Machine Translation&lt;/strong&gt;&lt;/h3&gt;&lt;h4 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="作者"&gt;&lt;/a&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;Yingce Xia, Di He, Tao Qin, Liwei Wang, Nenghai Yu, Tie-Yan Liu, Wei-Ying Ma&lt;/p&gt;&lt;h4 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="单位"&gt;&lt;/a&gt;&lt;strong&gt;单位&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;中科大，北大，微软亚研院&lt;/p&gt;&lt;h4 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="关键词"&gt;&lt;/a&gt;&lt;strong&gt;关键词&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;NMT，monolingual data, dual learning&lt;/p&gt;&lt;h4 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="文章来源"&gt;&lt;/a&gt;&lt;strong&gt;文章来源&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;NIPS 2016&lt;/p&gt;&lt;h4 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="问题"&gt;&lt;/a&gt;&lt;strong&gt;问题&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;利用双向NMT模型，在少量双语数据，大量单语数据的情况下，如何提高NMT的性能。&lt;/p&gt;&lt;h4 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="模型"&gt;&lt;/a&gt;&lt;strong&gt;模型&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;主要的思想是通过two-agent communication game，用单语语料和语言模型来提升双向NMT的性能。利用A语言的单语语料进行学习的two-agent communication game过程如下：&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="margin-top: 15px; margin-left: 20px; max-width: 100%; font-size: 16px; font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); color: rgb(68, 68, 68); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;li&gt;&lt;p&gt;agent1读入语言A的单语句子， 通过A到B的NMT模型转换成语言B的句子，并且发送给agent2。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;agent2接收到agent1发送的语言B的句子，通过语言B的语言模型LM_B，给出一个reward r_1。再通过B到A的NMT模型，将句子转换成语言A并且发送给agent1。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;agent1接收到agent2发送的语言A的句子，和最初的单语句子做比较，给出另一个reward r_2。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;那么r=alpha* r_1+(1-\alpha) r_2，agent1和agent2就能根据reward r对A到B和B到A的NMT模型进行学习。&lt;/p&gt;&lt;p&gt;如果用公式表达，这个过程的目标函数就是：&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/21625a8d269c8149ce4d76b0e71dc01b30d71924"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;由于s_mid的sample space无穷大，需要做一些近似来求期望。 文中考虑到random sampling会有较大的variance和一些不合理的翻译，采用了N-best来近似（N=2, 用beam search得到）。&lt;/p&gt;&lt;p&gt;整个训练分成3个step:&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="margin-top: 15px; margin-left: 20px; max-width: 100%; font-size: 16px; font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); color: rgb(68, 68, 68); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;li&gt;&lt;p&gt;用双语语料，普通的MLE training来学习A到B和B到A的NMT模型，作为warm start。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;每一个minibatch里面一部分单语语料，一部分双语语料，对双语语料用MLE作为目标函数，单语语料用上面的公式作为目标函数；随着training的进行，减少双语语料的比例。训练交替地从语言A或者语言B开始。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;最后完全用单语语料，通过上面的公式作为目标函数进行训练。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h4 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="相关工作"&gt;&lt;/a&gt;&lt;strong&gt;相关工作&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;这篇文章和Semi-Supervised Learning for Neural Machine Translation以及Neural Machine Translation with Reconstruction比较相似，都是用双向NMT模型来互相学习增强，区别在于这篇引入了语言模型。和Minimum Risk Training for Neural Machine Translation也有一定的相关性，相当于MRT中的loss function用了语言模型和反向NMT进行定义。&lt;/p&gt;&lt;h4 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="简评"&gt;&lt;/a&gt;&lt;strong&gt;简评&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;这篇文章从reinforcement learning的角度，将单语语料很好地融入到双向NMT的训练中，在使用10%双语语料的情况下也能取得较好的翻译结果。整体上来说非常有意思，也可以推广到更多的tasks in dual form。&lt;/p&gt;&lt;h4 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="完成人信息"&gt;&lt;/a&gt;&lt;strong&gt;完成人信息&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;陈云，香港大学，yun.chencreek@gmail.com。&lt;/p&gt;&lt;h4 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;br&gt;&lt;/h4&gt;&lt;hr style="max-width: 100%; font-size: 16px; font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); color: rgb(68, 68, 68); box-sizing: border-box !important; word-wrap: break-word !important;"/&gt;&lt;p&gt;&lt;strong&gt;Chat实录&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;br&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;问&lt;/strong&gt;：论文中的相关工作部分提到了另外两篇neural machine translation的相关工作，请问作者可否简单介绍一下那两个模型的主要方法呢？以及它们和dual learning的最大区别。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;答&lt;/strong&gt;：&amp;nbsp;另外两篇论文分别是semi-supervised Neural Machine Translation 以及Neural Machine Translation with Reconstruction。 semi-supervised这篇是利用autoencoder，将源端和目标端的单语语料引入，进行双向NMT联合训练；reconstruction这篇，是在普通MLE目标函数的基础上，增加了从目标端的hidden state重建源句子的概率这一项。首先我谈一下他们的区别。&lt;/p&gt;&lt;p&gt;出发的角度不一样：&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="margin-top: 15px; margin-left: 20px; max-width: 100%; font-size: 16px; font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); color: rgb(68, 68, 68); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;li&gt;&lt;p&gt;semi-supervised：如何将source和target端的单语语料引入，通过双向NMT提高NMT的性能。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;recosntruction：解决translation adequacy的问题, 避免翻译的句子太短或者重复翻译某一部分。利用双向NMT优化原来的MLE目标函数。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;dual learning：在少量平行语料，大量单语语料的情况下，如何利用双向NMT提高NMT的性能。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;语料需求不一样：&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="margin-top: 15px; margin-left: 20px; max-width: 100%; font-size: 16px; font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); color: rgb(68, 68, 68); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;li&gt;&lt;p&gt;semi-supervised: source,target端的单语语料，文中实验双语语料比单语语料多。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;reconstruction: 没用单语语料。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;dual learning: 10%的双语语料，大量单语语料。并且用了预先用单语语料训练好的语言模型。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;解释的角度不一样：&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="margin-top: 15px; margin-left: 20px; max-width: 100%; font-size: 16px; font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); color: rgb(68, 68, 68); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;li&gt;&lt;p&gt;semi-supervised: 双向NMT联合训练，目标函数包括两个方向的MLE，以及source&amp;amp;target autoencoder的reconstruction probability。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;reconstruction: 目标函数在普通的MLE基础上增加了由reconstructor定义的reconstruction probability。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;dual learning: 基于policy gradient的增强学习。用two agents play games这样的形式来解释。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;而他们也有一些相同的地方:&lt;/p&gt;&lt;p&gt;都是用双向NMT来提高普通MLE训练的单向NMT的性能。reconstruction一篇相当于在原来的目标函数上加了reconstruction error，由于只用了双语语料，所以目标句子y是已知的。而semi-supervised和dual learning都会处理单语语料。在处理源端单语句子时，目标端的y是未知的。这二者都可以看成是一种句子级别的模型，通过正向的NMT产生一些句子来近似整个目标端输出空间，然后通过反向NMT给出句子的feedback(dual learning同时用了LM给出的feedback)。&lt;/p&gt;&lt;p&gt;大家可以对比一下他们的目标函数，能够比较明显地看出区别和联系来。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;问&lt;/strong&gt;：可以用dual-learning这样的framework来解决的其他问题吗？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;答&lt;/strong&gt;：&amp;nbsp;有很多dual tasks都可以用这个框架，比如 speech recognization &amp;amp; text to speech, Image captioning &amp;amp; Image generation, Question answering &amp;amp; Question generation, 还有 Query-document matching &amp;amp; Query/keyword suggestion。这篇文章之前MSRA的&lt;a rel="external" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" target="_blank"&gt;刘铁岩老师&lt;/a&gt;和&lt;a rel="external" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" target="_blank"&gt;秦涛博士&lt;/a&gt;有在斗鱼上直播过，大家可以看一下。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;问&lt;/strong&gt;：Dual Learning 中语言模型 LM 没看到在那里有详细的说明？刚才说的 Autoencoder，是在哪里提到的呢&lt;/p&gt;&lt;p&gt;&lt;strong&gt;答&lt;/strong&gt;：&amp;nbsp;语言模型在文章中的第四页第二段可以看到：&amp;ldquo;This middle step has an immediate reward r1 = LMB(smid), indicating how natural the output sentence is in language B.&amp;rdquo; Reward包括r1和r2, r1就是语言模型给的reward。 语言模型是用单语语料提前训练好的，在NMT的整个training过程中固定不变。&lt;/p&gt;&lt;p&gt;Autoencoder在dual learning这篇没有提到，是在semi-supervised那篇提到的。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;问&lt;/strong&gt;：请问dual learning和GAN是否有相似之处 还是完全不相关的两种思路&lt;/p&gt;&lt;p&gt;&lt;strong&gt;答&lt;/strong&gt;：&amp;nbsp;是有相似之处。作者之一秦涛在斗鱼直播有提到，GAN在某种程度上可以看成是dual learning的一种特殊情况。将generator看成是primal task，discriminator看成是dual task, 通过f和g共同学习来互相增强。dual task主要是为了给primal task提供feedback。个人觉得dual learning和GAN最大的区别在于对discriminator的定义不一样，GAN定义成分类问题，而dual learning定义的是一个重建问题。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;问&lt;/strong&gt;：论文中的算法提到了一个参数alpha，它的意义是什么呢？是需要手动调参还是一个机器学习优化得到的参数呢？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;答&lt;/strong&gt;：&amp;nbsp;这个alpha其实是LM reward跟反向NMT reward的一个trade-off，是手动调的。 文章后面有写，设置成0.005能取得较好的效果。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;问&lt;/strong&gt;：reconstruction error 以前常见于投影 project 重建 rebuild，或者是编码重建 encode/decode。图像上，一般常用 residual 来表示，例如子空间算法，KSVD 分解等等。这种对偶重建的方法，有没有可能发展成一种泛化的投影重建？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;答&lt;/strong&gt;：&amp;nbsp;我觉得你可以尝试一下，图像上的东西不太懂。如果可以做成这种对偶tasks的形式,一个task take 某个action的reward可以由另外一个task给出，应该就可以试试。&lt;/p&gt;&lt;hr style="max-width: 100%; font-size: 16px; font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); color: rgb(68, 68, 68); box-sizing: border-box !important; word-wrap: break-word !important;"/&gt;&lt;h3 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;br&gt;&lt;/h3&gt;&lt;h3 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="3. SQuAD: 100,000+ Questions for Machine Comprehension of Text"&gt;&lt;/a&gt;&lt;strong&gt;3.&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;SQuAD: 100,000+ Questions for Machine Comprehension of Text&lt;/strong&gt;&lt;/h3&gt;&lt;h4 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="作者"&gt;&lt;/a&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, Percy Liang&lt;/p&gt;&lt;h4 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="单位"&gt;&lt;/a&gt;&lt;strong&gt;单位&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;Computer Science Department, Stanford University&lt;/p&gt;&lt;h4 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="关键词"&gt;&lt;/a&gt;&lt;strong&gt;关键词&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;Question Answering, Dataset Creation&lt;/p&gt;&lt;h4 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="文章来源"&gt;&lt;/a&gt;&lt;strong&gt;文章来源&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;EMNLP 2016&lt;/p&gt;&lt;h4 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="问题"&gt;&lt;/a&gt;&lt;strong&gt;问题&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;创建一个large and high quality reading comprehension dataset。&lt;/p&gt;&lt;h4 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="模型"&gt;&lt;/a&gt;&lt;strong&gt;模型&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;数据收集&lt;/p&gt;&lt;p&gt;用PageRanks搜寻出top 10000 English Wiki articles，然后uniformly sample 536 articles，做相关数据清洗后得到23215 paragraphs。这部分数据被分成三部分，training set(80%)，development set(10%)，test set(10%)。&lt;/p&gt;&lt;p&gt;下一步我们将这些paragraphs都放到Amazon Mechanical Turk上让用户创建问题以及回答问题。这样我们便得到了一个新的QA数据集。&lt;/p&gt;&lt;p&gt;为了评估human在这个QA数据集上的表现，development set和test set中的每个问题被至少发给了两个额外的crowdworkers，其中有2.6%的问题被crowdworkers标记为unanswerable。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;数据集分析&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;我们把答案分成了两部分，numerical和non-numerical。对non-numerical answers再做一次constituency parsing和POS Tagging，发现答案分布如下图所示。&lt;/p&gt;&lt;p&gt;&lt;a rel="gallery0" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="enter image description here"&gt;&lt;img src="http://img04.iwgc.cn/mpimg/486b437625696bb57434faa18104a7668153e64a"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Baselines&lt;/strong&gt;&lt;br&gt;作者做了sliding window baseline和logistic regression baseline，用accuracy和F1 Score做评估。结果如下图所示。&lt;/p&gt;&lt;p&gt;&lt;a rel="gallery0" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="enter image description here"&gt;&lt;img src="http://img04.iwgc.cn/mpimg/e0f30d944e6d9ac2da218c57d25216a8c19aa9a8"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;h4 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="资源"&gt;&lt;/a&gt;&lt;strong&gt;资源&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;在&lt;a rel="external" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" target="_blank"&gt;Stanford Question Answering dataset&lt;/a&gt;可以看到所有dataset的信息，test set leaderboard上有各种Model的performance。&lt;/p&gt;&lt;h4 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="相关工作"&gt;&lt;/a&gt;&lt;strong&gt;相关工作&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;Question Answering方面的dataset有不少，最近比较popular的有：MCTest by Microsoft，BAbI dataset by Facebook，WikiQA by Microsoft，CNN/Daily Mail by DeepMind, Children&amp;rsquo;s Book Test by Facebook。有兴趣的读者可以查阅相关文献。&lt;/p&gt;&lt;h4 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="简评"&gt;&lt;/a&gt;&lt;strong&gt;简评&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;SQuAD是一个高质量的Reading comprehension dataset。作者花费了大量的人力物力，让Crowdworkers根据Wikipedia Paragraph出题和答题。构建的dataset数量巨大且质量高，对未来Reading Comprehension Question Answering的研究非常有帮助。&lt;/p&gt;&lt;h4 style="max-width: 100%; color: rgb(62, 62, 62); font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;a style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" title="完成人信息"&gt;&lt;/a&gt;&lt;strong&gt;完成人信息&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;Zewei Chu，The University of Chicago，zeweichu@gmail.com。&lt;/p&gt;&lt;hr style="max-width: 100%; font-size: 16px; font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); color: rgb(68, 68, 68); box-sizing: border-box !important; word-wrap: break-word !important;"/&gt;&lt;p&gt;&lt;strong&gt;Chat实录&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;br&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;问&lt;/strong&gt;：请介绍一下这个reading comprehension dataset和其他dataset之间的主要区别？以及该dataset的优势是？&lt;/p&gt;&lt;p&gt;&lt;strong&gt;答&lt;/strong&gt;：&amp;nbsp;这篇paper相对于前面两篇内容简单一些，主要就是介绍了一个新构建的QA数据集。所以我和大家交流分享一下我比较熟悉的最近一些比较popular的QA Dataset吧。&lt;/p&gt;&lt;p&gt;MCTest: 数据集本身质量不错，像普通的阅读理解，是根据一篇文章提出问题，然后在给定的四个选项中选出一个。但是数据集太小，现在比较主流的RC model都是基于deep learning的，数据量太小很难让model学习到有用的信息。所以个人认为小数据集上的Model多少会给人一种强凑答案的感觉。&lt;/p&gt;&lt;p&gt;CNN/Daily Mail, CBT: 这个数据集我比较熟悉，数据集比较大，也是比较火的一个数据集。问题的答案只是一个单词或者一个entity，SQuAD的答案有比较长的phrase。the entities are anonymized。在anonymized dataset上训练的一个问题是，容易训练出没有semantics的模型来。因为训练集上的参考答案都是entity1，entity2，到了真实情况下碰到很大的vocabulary模型未必work。&lt;/p&gt;&lt;p&gt;安利一下&lt;a rel="external" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" target="_blank"&gt;我同学的一篇paper&lt;/a&gt;，分析了一下几个在CNN/DM/CBT上面比较好的几个模型attention sum/gated attention sum/stanford reader其实本质是差不多的。然后stanford reader虽然在这个数据集上效果很好但是一旦数据集不anonymize就很容易不work了。&lt;/p&gt;&lt;p&gt;WDW dataset:Passage: 直接给一个例子。&lt;/p&gt;&lt;blockquote style="max-width: 100%; color: rgb(62, 62, 62); font-size: 16px; font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p&gt;Britain&amp;rsquo;s decision on Thursday to drop extradition proceedings against Gen. Augusto Pinochet and allow him to return to Chile is understandably frustrating &amp;hellip; Jack Straw, the home secretary, said the 84-year-old former dictator&amp;rsquo;s ability to understand the charges against him and to direct his defense had been seriously impaired by a series of strokes. &amp;hellip; Chile&amp;rsquo;s president-elect, Ricardo Lagos, has wisely pledged to let justice run its course. But the outgoing government of President Eduardo Frei is pushing a constitutional reform that would allow Pinochet to step down from the Senate and retain parliamentary immunity from prosecution. &amp;hellip;&lt;/p&gt;&lt;p&gt;Question: Sources close to the presidential palace said that Fujimori declined at the last moment to leave the country and instead he will send a high level delegation to the ceremony, at which Chilean President Eduardo Frei will pass the mandate to XXX.&lt;/p&gt;&lt;p&gt;Choices: (1) Augusto Pinochet (2) Jack Straw (3) Ricardo Lagos&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;还有一个dataset叫wiki QA我也没有在上面实验过，也给一个例子。&lt;/p&gt;&lt;blockquote style="max-width: 100%; color: rgb(62, 62, 62); font-size: 16px; font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p&gt;Question: Who wrote second Corinthians? Second Epistle to the Corinthians The Second Epistle to the Corinthians, often referred to as Second Corinthians (and written as 2 Corinthians), is the eighth book of the New Testament of the Bible. Paul the Apostle and &amp;ldquo;Timothy our brother&amp;rdquo; wrote this epistle to &amp;ldquo;the church of God which is at Corinth, with all the saints which are in all Achaia&amp;rdquo;.&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;个人觉得open domain以及需要external knowledge的QA DATASET其实很难，但是很重要，因为可以应用在其他更多的方面。&lt;/p&gt;&lt;p&gt;另外提一个LAMBADA dataset，虽然他的问题是last word prediction，不过我们发现用reading comprehension models也可以做出很好的效果。详细信息可以看&lt;a rel="external" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" target="_blank"&gt;我的一篇paper&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;facebook有个babi dataset，&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/79ff8c41ae69726556f8e8480a8d0e663378ba98"/&gt;&lt;/p&gt;&lt;p&gt;需要一些logical thinking，facebook自己搞了一些memory network的模型在上面效果比较好，但是其实我觉得memory network和attention模型非常相似。&lt;/p&gt;&lt;p&gt;至于本文构建的squad dataset主要的特点就是答案可能比较长，而且不给候选答案，所以难度应该会大一些 数据集的质量也比较高，因为都是人工出的问题和标准答案，数据量也很大，容易训练处有用的模型。&lt;/p&gt;&lt;p&gt;个人认为构建大的，有意义的数据集对于QA的工作是很关键的。现在还是比较缺乏能够推广到实际生活中的问题的QA模型。&lt;/p&gt;&lt;p&gt;我大致就分享这一些。给想做QA方面问题的同学一点参考。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;活动预告&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;下一期Paper Note+Chat活动将会继续分享和解读&lt;span&gt;3&lt;/span&gt;篇&lt;span&gt;2016&lt;/span&gt;年最值得读的自然语言处理领域&lt;span&gt;paper，&lt;/span&gt;分别是&lt;span&gt;：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1.LightRNN Memory and Computation-Efficient Recurrent Neural Network&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2.Text understanding with the attention sum reader network&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3.Neural Machine Translation with Reconstruction&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;br&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为保证讨论的质量&lt;span&gt;，&lt;/span&gt;在讨论之前要求各位同学至少读过其中的一篇&lt;span&gt;paper&lt;/span&gt;。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;活动报名请&lt;span&gt;扫码&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/6d9603ac83b35e4af02ed4ccd0fb9db4c2519d53"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;关于PaperWeekly&lt;/span&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;PaperWeekly是一个分享知识和交流学问的学术组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;微信公众号：PaperWeekly&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/74e43d689e2973dc494ef5c2c85c981e72b56552"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;微博账号：PaperWeekly（&lt;a rel="external" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;" target="_blank"&gt;http://weibo.com/u/2678093863&lt;/a&gt;&amp;nbsp;）&lt;br&gt;微信交流群：微信+ zhangjun168305（请备注：加群交流或参与写paper note）&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;
</description>
      <pubDate>Sat, 25 Feb 2017 15:24:24 +0800</pubDate>
    </item>
  </channel>
</rss>
