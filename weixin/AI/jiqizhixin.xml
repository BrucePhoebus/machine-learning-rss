<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>深度 | 马克·扎克伯格展示个人助理Jarvis：又一个走出电影银幕的科幻作品</title>
      <link>http://www.iwgc.cn/link/3990737</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自FastCompany&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;作者：DANIEL TERDIMAN&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：微胖、李泽南、蒋思源、杜夏德&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8VWKQofaVnqvnBPXGupytYy276aktHNdWQfY46evkhBsqxMAY5viaOcomqQYVFicjI6Mgef5yN0mhg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;每当新工程师加入 Facebook——无论他/她刚刚离开大学还是已经身经百战——所有人都需要在 Bootcamp 度过六周时间。这是一个入职培养计划，旨在帮助新员工了解公司庞大的代码库，然他们能够尽快使用编程工具不断进行新的开发。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;马克·扎克伯格是 Facebook 的第一位工程师，在公司成立早期贡献了数量庞大的代码。但是这位现年 32 岁的创始人和 CEO 从来没有参加过 Bootcamp 计划，该计划是他在哈佛大学的宿舍创办公司两年以后于 2006 年推出的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;去年 1 月，扎克伯格曾经宣布，他计划建立一个人工智能系统，通过 Facebook 工具操纵所有智能家居，这是扎克伯格每年为自己制定的最大挑战中最新的一条。这需要在最先机的人工智能技术之上不断探索，虽然 Facebook 已经在人工智能领域具有强大实力，但该项目仍然迫使他重新整合了公司内的系统和架构，而这些努力让这位年轻的 CEO 重新与公司中的数千名工程师紧紧联系在一起。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是作为 Facebook 的首席执行官，他再也无法花六个星期全身心地投入到员工再教育活动中去了。「我之前从未经历过一次正式的 Bootcamp，」扎克伯格上周在他位于 Palo Alto 有着 113 年历史的木质别墅客厅里告诉我。我受邀观摩他的 Jarvis 演示，这是他今年最大挑战第一次被公之于众。「当我在课上向大家提问时，你可以想象他们的反应是有多快。」&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_gif/KmXPKA19gW8VWKQofaVnqvnBPXGupytYoegLUNibQWAlBFVlycfAwj31sVqsEDgmjoaPib73G55VryJAXA8p0WYg/0?wx_fmt=gif"/&gt;&lt;br/&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;马克·扎克伯格命令 Jarvis——他的人工智能助理关灯&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;扎克伯格非常喜欢工程学「具有确定性」的特质——它让工程师能够安心构建完全符合自己期望的东西。对于他所期待的一切而言，他正领导着一家有着一万五千名员工和数以十亿计用户的科技公司，这些用户横跨 Messenger、WhatsApp、Instagram 和 Facebook，确定性是一件奢侈的事物。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这也就是为什么扎克伯格喜欢在为数不多的业余时间里捣鼓一些新奇的小项目，这也就是为什么他在 2012 年的个人挑战内容是每天写一段代码。他多年来一直在参与多个公司的黑客挑战赛，这是他的修行方式，作为练习，他曾编写过一个系统，用于配组 Facebook 的组织图和内部社交图，以查看公司内部的哪些团体的社交关系最为密切。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「通常来说，写代码去做一件事很像我当年学中文的感觉（那是我 2010 年的年度挑战）。我感觉整个大脑都被激活了。」扎克伯格对我说。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Facebook 的工程师文化要求员工在发现问题时，必须停下目前的工作立即寻找解决方案。这个设定对于全球飞奔的 CEO 而言显得有些不合适。「我要么必须从会议中起身，要么只能去找别人来帮我解决代码上的问题，不管哪种方式，都太糟糕了，」扎克伯格说道。所以很长一段时间里，他都没有放弃在任何时候写代码的习惯。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在过去的一年中，扎克伯格花费了 100-150 小时用于他的家庭助理项目。他把这个项目命名为 Jarvis——电影《钢铁侠》中托尼·史塔克的人工智能助理，在电影中，它有点像是一个自制的，非常个人化的亚马逊 Alexa。现在，扎克伯格的 Jarvis 已经可以用来帮助和他的妻子 Priscilla Chen 使用自定义 iPhone 应用程序，或唤醒 Facebook Messenger 机器人开灯关灯，根据个人喜好播放音乐，为来访的朋友开门，烤面包，甚至唤醒他们的一岁女儿 Max 准备上中文课。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;iframe class="video_iframe" data-vidtype="1" style="   z-index:1; " height="375" width="500" frameborder="0" data-src="https://v.qq.com/iframe/preview.html?width=500&amp;amp;height=375&amp;amp;auto=0&amp;amp;vid=h0357vz13tu" allowfullscreen=""&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;闲暇时间的体验&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你有幸造访马克·扎克伯格的别墅，你会体验到硅谷最棒的社区中 1600 平米的宁静。Jarvis 认出了你，自动向主人提醒你的到来。但和电影中情况不同的是——当你穿过一扇木门，沿着两旁种满柑橘和枫树的小道探寻——扎克伯格会亲自出来迎接你。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;还好，这不是特别奇怪，他有着棕色卷发，穿着灰色 T 恤和牛仔裤，这个形象曾出现在无数照片和视频中。需要确定的一点是这不是什么全息影像正在引你进屋。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最近几周对于扎克伯格来说格外忙碌，他需要应对三个不同的争议：Facebook 的假新闻是否影响了最近一次美国总统选举；考虑投资者（也是董事会董事）Marc Andressen 在出售 Facebook 股票以后在公司管理层中的地位；以及 Facebook 广告推送的各种错误问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相比之下，Jarvis 是一个轻松的话题。我们在客厅的深绿色沙发上坐着，一只匈牙利牧羊犬就在身边，扎克伯格看起来非常放松。他开始讲述过去一年里开发 Jarvis 的点点滴滴。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;iframe class="video_iframe" data-vidtype="1" style="   z-index:1; " height="375" width="500" frameborder="0" data-src="https://v.qq.com/iframe/preview.html?width=500&amp;amp;height=375&amp;amp;auto=0&amp;amp;vid=l0357e3nvao" allowfullscreen=""&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在今年 1 月份，扎克伯格宣布了 Jarvis 计划，他曾表示，自己将用一年时间构建一个智能系统，控制家中所有的电子设备，包括音乐播放器，灯和空调。他同时希望 Jarvis 可以通过面部识别到访的好友，为他们自动打开房门，同时监控小女儿 Max 的一举一动。扎克伯格希望这个系统可以「通过 VR 影像中的可视化数据帮助我构建更加有效地服务，让 Facebook 运行得更加高效。」&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今年 12 月，他已经实现了所有这一切。然而，当他亲自向我展示这个系统时，我得知它有时还是有点小毛病。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;扎克伯格开始演示作为系统前端构建的 Messenger bot，他用 iPhone 完成了简单的命令，关闭和打开灯。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他通过自定义的 iOS 应用程序建立了系统来响应语音命令，不过系统反馈不是很好。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他说：「这是他从未有过最失败的作品」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他说：「播放我们一些音乐」，几秒钟后，David Guetta 的「Would I Lie to You」开始在客厅的扬声器非常安静地开始播放。他说了两次「音调大」，系统真的就调大音量了。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;扎克伯格最骄傲 Jarvis 的一个功能是它能够学习他和 Priscilla 的音乐品味，它能选择一些是 Priscilla 偏好的歌曲而不是扎克伯格的。同时他设计这个系统还能响应一些特定风格的音乐，如轻音乐或某个艺术家风格的音乐。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;扎克伯格告诉 Jarvis，「放些 Red Hot Chili Peppers 风格的歌曲」，然后它就播放了 Nirvana 的 Smells Like Teen Spirit。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;扎克伯格也希望 Jarvis 能够理解一定程度的语言差异。他说：「当你在想音乐时，如果你告诉它放点什么，这些东西可以是一首歌、一组歌曲、一个艺术家或 一张专辑。」&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8VWKQofaVnqvnBPXGupytYjb5BydKlQElpSiaTyAQZ2E10kDHM9YN6a7EwywZQlbnWSKxoPfjn1sw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Jarvis 给音乐回放装上了声音控制&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他发现具有挑战性的任务是让 Jarvis 解析非常相似的短语。Adele 就提供了这样一个案例，如果说播放「Someone Like You」，代表播放特定的歌曲，那么对它说「play someone like Adele」就代表着需要一些 Adele 类型歌手的音乐。如果说播放「some Adele」，就代表着播放些她的音乐。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那些「Someone like you、someone like Adele、some Adele」短语很相似，但意思又完全不同。所以在一定范围内短语能够做很多不同的事情，它不仅仅只是开关 灯光，它能够通过获得反馈来辨别短语的差异。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;「A GOOD WAY TO MAKE YOUR WIFE MAD AT YOU」&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;正确播放音乐是一回事。确保 Jarvis 不会讨厌又是另外一回事了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果不确定应该在哪该做什么的话，即使只要求系统开关灯光或播放音乐也可能会带来惊人的模糊性。如扎克伯格和他的妻子有时会使用不同的短语来表示客厅，所以 Jarvis 需要理解同义词。但扎克不想只对不同的短语进行编程设置，教导 Jarvis 学习它们和其他细微差别的语境是一个更有趣的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8VWKQofaVnqvnBPXGupytYeRg0U3Via5p7yM3tD1vonR80ja6iczIiazibsPduiaubHgLtluLSzB2qCEw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;它应该达到这种效果，如果我进门说：「把房间的灯打开」，然后也许灯太亮了，Priscilla 说：「调暗一些」，系统就能自动把她所在房间的灯调暗一些。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「如果这些发生时，Max 碰巧在睡觉，会怎么样？「会很麻烦。这也是让你妻子对你抓狂的好办法。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果 Max 碰？「这个很麻烦，也是让你太太对你抓狂的好办法。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一个关于位置重要性的例子：创造舒适的电视观看体验，Javis 要会关灯。「挨着看电视的房间中，有一间是...Priscilla 的办公室。」扎克伯格说，「所以，我将它安排在看电视的地方，这样它就可以关掉楼下的灯。如果 Priscilla 在努力工作，她就会抓狂，『马克！』」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;比预期容易，但是...&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然扎克伯格通常只会挑选一件事作为一年的挑战，但在 2016 年，他选择了两个。第二个是跑上 365 英里（约 573 公里），以防止他在打造 Jarvis 时久坐不起。而 2015 年他给自己设下的挑战是两周读完一本书。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;连上互联网的冰箱并不自带 Facebook 安全证书。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;严格来说，扎克伯格的家庭网络是 Facebook 公司设施的一部分。保护它就需要让任何与家庭系统相连的东西都要带上 Facebook 安全证书——基本上就是一个数字认证密钥，保证某个特定设备是安全的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种安全证书会限制他的控制。比如，接入互联网的冰箱不带 Facebook 安全证书。对大多数人来说，这不是个问题，但是扎克伯格不是大多数人。确保家中的安全是他首要考虑的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前扎克伯格通过互联网连接的转换开关来实现对家中某些电器的远程控制。他想要让 Jarvis 能自己拿出面包片做早餐烤面包。但是，现在还没有一种现代烤面包机能在关掉时让你把面包推下去，这是出于安全考虑。所以他只好买了一台上世纪 50 年代就有的低科技面包机凑活着用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而事实上，他在 Jarvis 上花的时间要少于跑步，这很大程度上要感谢 Facebook 的各种工具包，他利用这些工具包做了很多任务，比如图像和声音识别。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是扎克伯格不希望看到的是，这个项目的大部分工作要研究如何将 Jarvis 与他家里的各种系统连接起来，这些系统囊括了照明、门、温度的快思聪家庭自动化系统；三星电视；SONOS 流箱和 Spotify 的音乐系统。但是扎克伯格想把这些东西都控制起来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最终他想让每样东西都相连的方法需要花很多时间去解决软件的逆向工程问题，这些问题来自于他采用的产品和服务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8VWKQofaVnqvnBPXGupytYqibR9kmJMAOhwmQVvPmI7KUic9fW3TG2QPibKNDxjVJutImibsGaChI8icQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图：扎克伯格收到一条短信，当他控制他的 Sonos 音乐系统时，Jarvis 为他打开了大门&amp;nbsp;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管 Jarvis 在记者面前表现并不完美，但是，扎克伯格却对自己的成就很自豪。他愿意将这个作品和任何人购买的系统（比如 Echo）做个比较。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他强调，这还不是一个可以走进千家万户的产品系统，但是，如果我搭建的系统连 Echo 等系统能做到的事情都完不成，我会很失望。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他补充说，搭建类似亚马逊和谷歌那样的系统，设计成让数以百计的用户可以控制大量设备的样子，要比仅打造单个家庭的人工智能管家要难得多。他也无意贬低那些公司的成就，也没有计划量产自己的作品。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不过，他说，如果我没能将人工智能的能力延展到音乐推荐或者面部识别（以不同的方式来实现）或者理解屋内环境，那么，我会觉得自己并没有真正推动这一研究。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_gif/KmXPKA19gW8VWKQofaVnqvnBPXGupytY26UOicAsKS5Wl17ddRT10wD4deElpyzlDUfFczYx0X0ALZ8RWaAzsew/0?wx_fmt=gif"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;实际上，他计划总结自己这方面的工作并发布出来，如果他的某些结论最终能融入市场产品系统，他会非常开心。那也反映出脸书的一般哲学：开源，特别是人工智能方面的研究。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种学习与我们与文本和声音的互动有关。对 Jarvis 说话并让他能够回答，对于播放音乐来说，是有意义的，不过，扎克伯格发现，在许多其他情况下，文本更加好，特别是当有其他人在身边的时候。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果我在门口让某人进来，而这又与我身边的其他人无关，我更愿意输入文本发出指令。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;即使是发出命令，他也想让 Jarvis 能够通过文本的方式回复他，或者说，与其大声回复不如以文本的方式显示出来。因为它说话时会有点烦人。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;扎克伯格说，也就是说，语音功能在固定的时间发挥作用。你对他说话，他会回应你——我不想说它是我们家的一部分，这样有点过了——但是，确实感觉它有点具身化，所以 Max 很喜欢它。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;扎克伯格并不幻想只用不到 150 个小时的时间就可以打造出媲美公司专业人工智能人士花费数千小时（一个项目，一位工程师可能要花一年时间来完成）的成果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;让世人好奇了整年后，他将 Jarvis 带到了人们面前。他一直在修改着这个管家，因为他每天都在使用，总会做些修补或者增添一些新的功能。不过，他很高兴他和整个家庭都在 Jarvis 的打理下。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;扎克伯克可以通过界面输入所要完成的任务，比如晚上关灯。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他说，早上唤醒，说声早安，或者醒来后唤醒整个家，很简便。类似地，晚上不用在上床前关闭各种电器，说一声晚安就搞定一切并确认门也锁好了，非常方便。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Jarvis 这个项目最棒的事情之一就是刷新了扎克伯格的 Facebook 工程体验。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他说，因为自己花了很多时间用公司工具写代码，这并不是公司 CEO 通常会做的事情，因此，他能体会到一个新入职脸书的工程师的感受。他直接体验了一把公司所有这些内部工具，而且非常赞赏他们自己建造的这些工具，它们也是脸书文化的一部分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文链接：https://www.fastcompany.com/3066478/mind-and-machine/mark-zuckerberg-jarvis&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 20 Dec 2016 12:04:18 +0800</pubDate>
    </item>
    <item>
      <title>学界 | Andrej Karpathy：你为什么应该理解反向传播</title>
      <link>http://www.iwgc.cn/link/3990738</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Medium&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;作者：&amp;nbsp;Andrej Karpathy&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀、李亚洲、杜夏德&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当我们在斯坦福提供 CS231n（深度学习课程）时，我们有意设计编程任务来将涉及最底层的反向传播的明确的计算包括进来。这些学生必须在原始的 numpy 的每一层中实现前向和反向传播。然而，一些学生在黑板上留下这些抱怨。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;「在现实世界中，框架（比如 TensorFlow）会自动计算反向传播，为什么我们还一定要写它们？」&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这看起来非常合理，如果课程结束后你永远不会写反向传播，为什么还要练习呢？难道是因为我们自己的兴趣而折磨学生吗？有一个简单的回答可能是「在求知欲下值得我们知道反向传播」，也有回答是「之后你可能想要改进里面的核心算法」，但还有一个更有力、更实际的理由，我会在此文章中展现：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;反向传播的问题在于它是一个抽象泄漏（leaky abstraction）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;换言之，你会很容易将学习过程抽象掉——认为自己能非常容易地将任意层堆叠到一起，然后反向传播就会在你的数据上「神奇发挥功效」。所以，让我们来看一些非常清楚的例子，这是一种相当直观的方式。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8VWKQofaVnqvnBPXGupytYoGBSMEQ4kYVfuuEgkHVHXjicooJvJqSFiafyyRNibT3NWhmW0hZAs3icWg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;带有前向传播（黑色）和反向传播（红色）的 Batch Norm 层的计算图&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;在 S 型函数上的梯度消失&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从这里开始会很简单。以前某段时间，在全连接层中使用 S 型函数（或双曲正切函数 tanh）的非线性（non-linearities）非常流行。当时有一个难点是直到人们想出了反向传播才意识到的：如果不注意权重初始化或数据预处理，这些非线性会「饱和」并完全停止学习——你的训练损失将会趋于平坦，难以下降。例如，带有 S 型非线性的全连接层计算（使用 raw numpy）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8VWKQofaVnqvnBPXGupytYLQEhpkAwWwhB7gdzD5f7PyzKrYZQPcCKibpPia4QuUTdYQ3QBhlcicv8Q/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果权重矩阵 W 初始化过大，矩阵相乘的输出范围会非常大（例如 -400 到 400 之间的数值），这会使得向量 z 上的所有输出几乎是二元的：0 或 1。但如果是这样，S 型非线性函数的局部梯度 z*(1-z) 在两种情况下都会是 0（梯度消失），使得 x 和 W 的梯度都是 0。在链式反应下，之后的反向传播相乘之后得到的都会是 0。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8VWKQofaVnqvnBPXGupytYBqSGqzyJ5EL8PaGOgMias8ebJL8535m0N0tXsLxbYQaQp3f8gBicKt0A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一个关于 S 型的不太明显的有趣事实是当 z=0.5 时，它的局部梯度 z*(1-z) 的会达到最小值 0.25。那就意味着这个梯度信号每次通过一个 S 型函数门时，它的大小总会减少四分之一（或更多）。如果你正在使用基本的随机梯度下降法（SGD），这会使某个网络中较低层的训练比较高层慢得多。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;注：如果你正在你的网络中使用 S 型或双曲正切非线性并且你理解反向传播，你就总会为确保初始化不会使它们完全饱和而感到紧张。更多解释请参阅这个 CS231 讲座视频（CS231n Winter 2016: Lecture 5: Neural Networks Part 2）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;垂死的 ReLU&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一个有趣的非线性是 ReLU，其神经元的阈值范围是 0 以下。对于一个使用了 ReLU 的全连接层，其前向和反向通过需要在其核心包含：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8VWKQofaVnqvnBPXGupytY5qiar5KEYAhaiaAH8N7bjlYMfKFbKhcajy0NTiavhxicRK3wTfUSFur8dg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你研究一下这段代码，你会发现如果一个神经元在前向通过中被嵌位到 0（即 z=0，它不会「fire」），那么它的权重将会得到 0 梯度（zero gradient）。这会导致所谓的「死亡的 ReLU（dead ReLU）」问题，即如果一个 ReLU 神经元不幸被初始化为其永远无法 fire，即如果一个神经元的权重在训练进入这一范围期间被使用一次大更新敲除，那么这个神经元就将永久死亡。这就像是永久的、不可恢复的脑损伤。有时候当你使其整个训练集前向穿过一个训练好的网络，你可能会发现你的神经元中很大一部分（比如 40%）在所有时间都是 0.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8VWKQofaVnqvnBPXGupytYgjQMIiaEv3hvYOLkUNR3tRB0JFn6rnQ2ib9q2eOsDw7JzUiaYuYKyL8Sw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;注：如果你了解反向传播并且你的网络有 ReLU，那么你会常常为死亡的 ReLU 感到焦虑。对于你整个训练集中的任何样本，这些神经元都不会开启，而且会一直保持死亡状态。神经元在训练过程中也会死去，通常是由于激进的学习率所造成的。更详细的解释请参看 CS231n 教学视频：https://youtu.be/gYpoJMlgyXA?t=20m54s&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;RNN 中的梯度爆炸&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Vanilla RNN 是反向传播的非直观效应的另一个好例子。我从 CS231n 复制了一张幻灯片，上面有一份简化的 RNN，其没有采用任何的输入 x，只在隐态（相当于输入 x 一直是 0）上计算循环（recurrence）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8VWKQofaVnqvnBPXGupytYGp5leSAsO9XYsCdXgwJ9Iv3vj7pdTM7bQGeAibjSYmfGVeazicf6SrNg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个 RNN 通过 T 时间步展开。当你盯着反向传递在做什么时，你会看到在所有隐藏状态下会及时反向传播的梯度信号总是被同一矩阵（循环矩阵 Whh）相乘，中间穿插着非线性反向传播。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当你拿到某个数字 a 并开始将它与另一个数字 b（例如，a*b*b*b*b...）相乘时会发生什么？|b|&amp;lt;1 时，这个序列会趋近于 0；当|b|&amp;gt;1 时，这个序列会「爆炸」成无限。在某个 RNN 的反向传递中会发生同样的事情，除非 b 是一个矩阵，而不仅仅是一个数，所以我们必须推理出它的最大特征值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;注：如果你理解了反向传播并且你正在使用 RNN，你就总是会为一定要做梯度裁剪而感到焦虑，要不然你就去使用 LSTM。详细解释可以看看这个视频：CS231n Winter 2016: Lecture 10: Recurrent Neural Networks, Image Captioning, LSTM（https://www.youtube.com/watch?v=yCC09vCHzF8）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;自己的发现：DQN Clipping&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;让我们再看一个，也是它启发我写出了这篇文章。昨天，我正在浏览 Deep Q Learning 在 TensorFlow 上的实现（看看别人是怎么处理等同于 numpy 的 Q [:, a] 的计算，其中的 a 是个整数向量——发现 TensorFlow 并不支持该繁琐的操作。）总之，我搜索了一下「dqn tensorflow」，点开第一条搜索连接，发现了它的核心代码，下面是引用：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8VWKQofaVnqvnBPXGupytYzVT2eo7tLfcZKpIvbJvVyiabkicG65995dvAS5loon6nso1BFuHCyicQw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你熟悉 DQN，你可以看到有一个 target_q_t，也就是 [reward * \gamma \argmax_a Q(s』,a)]，然后有一个 q_acted，也就是采用的该 action 的 Q(s,a)。作者在这里将上面这两个简化到了变量间隔（variable delta），然后他们想要把 295 行的代码中的 L2 loss 用 tf.reduce_mean(tf.square()) 替换掉从而进行缩减，到这里还好。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但问题出在第 291 行。作者想要保持对异常值（outlier）的稳健性，所以如果间隔（delta）过大，它们就使用 tf.clip_by_value 修剪它。意图很好，而且从前向传播的角度来看也是合理的，但如果你考虑一下就会发现它引入了一个大漏洞。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个 clip_by_value 函数在 min_delta 到 max_delta 的范围之外还有一个 0 的局部梯度，所以无论何时，该 delta 都在 min/max_delta 之上，该梯度会在反向传播过程中变成确定的 0。当作者为了额外增加稳健性而很可能尝试修剪梯度时，他们修剪了原始的 Q delta。在那个案例中，正确的做法是在 tf.square 的位置使用 Huber loss：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8VWKQofaVnqvnBPXGupytYPiaWfMEk6iaFxfF76uUUIdS5kfmX0A4sv0b4qpaXfG4wpJGxgicTetWhg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 TensorFlow 中，这有点难办；因为如果梯度超过了一个阈值，我们想做的只是修剪该梯度，但是因为我们不能直接干预梯度，所以我们必须通过定义 Huber loss 这种迂回的方式来做这件事。在 Torch 中，这会简单得多。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我在 DQN repo 中提交了一个问题（https://github.com/devsisters/DQN-tensorflow/issues/16），这已经被及时修复了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;总结&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;反向传播是一个 leaky abstraction；它是一个有着非琐细后果的信用分配机制。如果你试着忽视引擎下面的工作原理，因为「TensorFlow 会自动让我的网络学习」，那么，你就无法应对它会带来的危险，而且在搭建和调试神经网络时，会低效很多。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;值得庆幸的是，如果呈现方式合适，反向传播不难理解。我对此深有体会，因为在我看来，95% 的反向传播材料都错误地呈现了反向传播，通篇都是机械化的数学。我不会这么做，在 CS231n 的课堂讲解里，反向传播将会以更加直观的方式展开。如果你愿意花时间完成 CS231n 的课后作业，作为奖励，手动编写反向传播会巩固你的理解。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前只有这么多。我希望你对反向传播向前（going forward）更加充满疑问了，而且，仔细思考向后传递是在做什么。我也留意到，在这篇 post 里给 CS231n 打了好几次广告（不是故意的！），对此表示歉意：）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文链接：https://medium.com/@karpathy/yes-you-should-understand-backprop-e2f06eab496b#.t84o4shhe&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 20 Dec 2016 12:04:18 +0800</pubDate>
    </item>
    <item>
      <title>开源 | 哈佛大学NLP组开源神经机器翻译工具包OpenNMT：已达到生产可用水平</title>
      <link>http://www.iwgc.cn/link/3990739</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自OpenNMT&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;神经机器翻译是近段时间以来推动机器翻译发展的主要推动力。今天，哈佛大学自然语言处理研究组（Harvard NLP）宣布开源了其研发的神经机器翻译系统 OpenNMT，该系统使用了 Torch 数学工具包。该研究组在官网上表示该系统已经达到生产可用的水平（industrial-strength）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;官网：&lt;span&gt;http://opennmt.net&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;代码：&lt;span&gt;https://github.com/opennmt/opennmt&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;演示：&lt;span&gt;https://demo-pnmt.systran.net&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Docker 容器：&lt;span&gt;https://hub.docker.com/r/harvardnlp/opennmt&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8VWKQofaVnqvnBPXGupytYbdzlIASJ0iaNqxQiaNrgPKvabwNN2gSXHnmpNLPMBH6ibkvWGyRBj2TKQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;OpenNMT 可以像主要的翻译服务提供商的已投入生产的系统那样使用。该系统简单易用，易于扩展，同时也能维持效率和当前最佳的翻译准确度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其特性包括：&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;简单的通用型接口，仅需要源文件和目标文件；&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;为高性能 GPU 训练进行了速度和内存优化；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;可以提升翻译性能的最新研究的特性；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;有多个语言对的预训练好的模型（即将到来）；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;允许其它序列生成任务的扩展，比如归纳总结和图像到文本生成。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;安装&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;OpenNMT 仅需要一次 vanilla torch/cutorch 安装。它要使用 nn、nngraph 和 cunn。有（CUDA）Docker 容器可选。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;快速启动&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;OpenNMT 包含三条指令：&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1）预处理数据&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;th preprocess.lua -train_src data/src-train.txt -train_tgt data/tgt-train.txt -valid_src data/src-val.txt -valid_tgt data/tgt-val.txt -save_data data/demo&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2）训练模型&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;th train.lua -data data/demo-train.t7 -save_model model&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3）翻译句子&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;th translate.lua -model model_final.t7 -src data/src-test.txt -output pred.txt&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;查看指南了解更多：http://opennmt.github.io/Guide&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;研究&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中主要的模型基于论文 Neural Machine Translation by Jointly Learning to Align and Translate Bahdanau et al. ICLR 2015 和 Effective Approaches to Attention-based Neural Machine Translation, Luong et al. EMNLP 2015。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在基本模型上，还有大量可选项，这都要感谢 SYSTRAN（http://www.systransoft.com/）的出色工作。特别地，下面是一些实现的功能：&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Effective Approaches to Attention-based Neural Machine Translation . Luong et al., EMNLP 2015.&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Character-based Neural Machine Translation. Costa-Jussa and Fonollosa, ACL 2016.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Compression of Neural Machine Translation Models via Pruning . See et al., COLING 2016.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Sequence-Level Knowledge Distillation . Kim and Rush., EMNLP 2016.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Deep Recurrent Models with Fast Forward Connections for Neural Machine Translation . Zhou et al, TACL 2016.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Guided Alignment Training for Topic-Aware Neural Machine Translation . Chen et al., arXiv:1607.01628.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Linguistic Input Features Improve Neural Machine Translation . Senrich et al., arXiv:1606.02892&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;声明&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;OpenNMT 的实现使用了以下项目的代码：&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Andrej Karpathy 的 char-rnn：&lt;span&gt;https://github.com/karpathy/char-rnn&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Wojciech Zaremba 的 LSTM：&lt;span&gt;https://github.com/wojzaremba/lstm&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Element RNN 库：&lt;span&gt;https://github.com/Element-Research/rnn&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;证书&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;MIT&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 20 Dec 2016 12:04:18 +0800</pubDate>
    </item>
    <item>
      <title>学界 | 英特尔新论文提出事件驱动的随机反向传播：能实现神经形态深度学习</title>
      <link>http://www.iwgc.cn/link/3990740</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自arXiv.org&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;论文：事件驱动的随机反向传播：能实现神经形态深度学习（Event-driven Random Backpropagation: Enabling Neuromorphic Deep Learning）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBIswl5ypwwstyBG2FGM6hNibehAxHlLn1cfGgwCvIQnEAnDiaWFW4icl5w/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;神经形态计算（neuromorphic computing）领域内一个一直以来持续存在的挑战是设计兼容大脑的时间和空间约束（spatial and temporal constraints）的通用的且计算高效的推理和学习模型。梯度下降反向传播规则（gradient descent backpropagation rule）是一种强大的算法，现在已经在深度学习领域无处不在，但这种算法依赖于使用高精度记忆存储的整个网络那么宽的信息的即时可用性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是，近来的研究成果表明：准确的反向传播的权重对学习深度表征而言并不是必需的。随机反向传播（random backpropagation）使用了随机的权重来替换反馈的权重并鼓励（encourage）该网络调整其前馈权重，从而学习该（随机）反馈权重的伪逆（pseudo-inverses）。在这里，我们提出了事件驱动的随机反向传播（event-driven random backpropagation，简称 eRBP）规则，其使用了一种误差调制的突触可塑性（error-modulated synaptic plasticity），可用于在神经形态计算硬件中学习深度表征。对于使用了 two-compartment leaky integrate &amp;amp; fire neuron 和膜电压调制的、尖峰驱动的可塑性规则（membrane-voltage modulated, spike-driven plasticity rule）的神经形态硬件，我们提出的这个规则非常适合于其中的实现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们的结果表明：使用 eRBP，无需使用反向传播的梯度就能快速学习到深度表征，并能实现可与在 GPU 上的人工神经网络模拟相媲美的分类准确度，同时也对学习过程中的神经和突触状态量化（neural and synaptic state quantizations）是稳健的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFB2SDFaTibIUnWUgZOxybRYiboJTQnbqLgp3CspBAtglh2MerGBlGJHHTw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图 1：用于事件驱动的随机反向传播（eRBP）的网络架构和训练过程中的尖峰活动示例。该网络包含用于预测的前馈层和用于有标签（目标）L 的监督训练的反馈层。实线箭头表示突触连接，虚线箭头表示突触可塑性调制（synaptic plasticity modulation）。在这个示例中，数字 7,2,1,0,4 被以序列的形式提供给该网络。这些数字像素值被使用尖峰响应模型（Spike Response Model）转换成了尖峰串（spike trains）。该网络中的所有其它神经元都实现了 two-compartment leaky I&amp;amp;F neuron。这个误差是标签（L）和预测（P）之间的差，其中偏移设置为 500 Hz。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;点击阅读原文查看论文&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 20 Dec 2016 12:04:18 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 谷歌自动驾驶公司Waymo展示新车型，计划明年上路</title>
      <link>http://www.iwgc.cn/link/3990741</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自TheVerge&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Jordan Golson&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：微胖&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8VWKQofaVnqvnBPXGupytYIMwsVYTMNfmQiatLGdoagaB8Yia7zuNl1UNUibT1d3PLbWlocCicqLOv4g/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;克莱斯勒已经完成了 100 辆 Pacifica 小型休旅车，这些车将于 2017 年加入 Waymo 车队。这些车是插电混合动力型车的变种，带有 Waymo 自动驾驶硬件和内置软件，也是菲亚特·克莱斯勒和 Waymo 今年早些时候宣布合作的一部分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721418&amp;amp;idx=3&amp;amp;sn=bc21aa884bd56d3cf123d66bfa19a31f&amp;amp;chksm=871b08f4b06c81e2502bfe1c69ea291e7be740d7d4d42948e441cfbbf118f3289f661efb1bfd&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721418&amp;amp;idx=3&amp;amp;sn=bc21aa884bd56d3cf123d66bfa19a31f&amp;amp;chksm=871b08f4b06c81e2502bfe1c69ea291e7be740d7d4d42948e441cfbbf118f3289f661efb1bfd&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;Waymo CEO John Krafcik 上礼拜曾说&lt;/span&gt;&lt;/a&gt;&lt;span&gt;，公司的兴趣不在于打造更好的车，而是更好的司机。这也是 Waymo 与 FCA 合作的原因，后者并不像福特和通用这些汽车制造商一样，积极炫耀自己的自动驾驶秘笈。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;Krafcik 说，「这些新的小型休旅车在测试市场上路后，我们就能从中获知各年龄、身形以及群体规模的人如何体验我们的全自动驾驶技术。公司已经在测试很多原型车，不过，这些车辆显然比其他原型车更紧密地与 Waymo 的自动驾驶硬件融合在一起。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;菲亚特·克莱斯勒发言人 Berj Alexanian 说，两家公司的合作见证了两家工程师之间的亲密合作，他们迅速并稳健地将车辆电子控制系统与全自动驾驶系统结合起来。Waymo 两百万英里的自动驾驶测试几乎都用的是带有谷歌自动驾驶硬件的雷克萨斯 SUV。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;FCA 和 Waymo 工程师修改了 Pacifica 的电子动力系统以及结构系统，让小型休旅车适于 Waymo 的自动驾驶技术。两家公司已经在位于密歇根和亚利桑那的切尔西测试场地以及位于加州的 Waymo 设施场地测试了 Pacifica 的原型，包括 200 小时极端天气下的测试。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Berj Alexanian 说，「Waymo 直接学习一家汽车制造商的车辆研发过程中所需要的一手材料，比如优化重力分布以确保舒服的驾驶体验以及在极端天气条件下的持久性测试。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;据彭博报道，两家公司或许会在自动拼车服务方面展开合作，可能会在 2017 年末展开，而这些自动驾驶休旅车就是合作的核心部分。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自动 Pacificas 会于明年早些时候上路，可能是公司现有的位于加州、华盛顿、亚利桑那以及德克萨斯的测试市场。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8VWKQofaVnqvnBPXGupytYH6ia2IllSdHhM09fVNUXibWsfOQpKyMm2JFl1X8EZiaZkAMC1w67AeAicw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8VWKQofaVnqvnBPXGupytYfpM7eSpf0GNfK3HhZjuiaXV7Ftia4Uqy9treljKygxIPZHwkqZmWtk1A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8VWKQofaVnqvnBPXGupytYibUMKkvewcNSu28NwpzXIkIsGdtsfrIQqCgqrJy0buqyEULdTbqTATQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文链接：http://www.theverge.com/2016/12/19/14003642/waymo-google-autonomous-chrysler-pacifica-minivan-photos&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 20 Dec 2016 12:04:18 +0800</pubDate>
    </item>
    <item>
      <title>腾讯大数据将开源高性能计算平台 Angel，机器之心专访开发团队</title>
      <link>http://www.iwgc.cn/link/3984747</link>
      <description>&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：吴攀、微胖&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随着近年来深度学习技术的发展，各种机器学习平台也纷纷涌现或从专用走向了开源。到现在，一家科技巨头没有一个主导的机器学习平台都不好意思跟人打招呼。比如谷歌有 TensorFlow、微软有 CNTK、Facebook 是 Torch 的坚定支持者、IBM 强推 Spark、百度开源了 PaddlePaddle、亚马逊也在前段时间高调宣布了对 MXNet 的支持。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在，腾讯也加入了这一浪潮。在 12 月 18 日于深圳举办的腾讯大数据技术峰会暨 KDD China 技术峰会上，腾讯大数据宣布推出了面向机器学习的「第三代高性能计算平台」——Angel，并表示将于 2017 年一季度开放其源代码。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBgEMocn7wnIb6FxeuQ6Qqsiar31NkpYWA0VS3K5LiajBSazicuzZbrNDiag/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;腾讯副总裁姚星在大会发言中说道：「人工智能的发展在过去 60 年中几经沉浮，今年终于发出了璀璨光芒，很大的原因就是跟云计算和大数据有关，这是一种演进发展的必然结果。如何处理好大数据，如何在有限的计算资源上对这些大数据进行深入挖掘和分析，这是未来整个产业发展和升级的一个大课题。我相信大数据将成为这次产业升级的基础，核心算法将成为这次产业升级的灵魂。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这次会议上，腾讯数据平台部总经理、首席数据专家蒋杰详细分享了腾讯大数据的发展之路以及 Angel 系统构建的生态圈层。据介绍，Angel 是腾讯大数据部门发布的第三代计算平台，使用 Java 和 Scala 语言开发的面向机器学习的高性能分布式计算框架，由腾讯大数据与香港科技大学、北京大学联合研发。它采用参数服务器架构，解决了上一代框架的扩展性问题，支持数据并行及模型并行的计算模式，能支持十亿级别维度的模型训练。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不仅如此，Angel 还采用了多种业界最新技术和腾讯自主研发技术，性能更高、系统更具易用性。自今年年初在腾讯内部上线以来，Angel 已应用于腾讯视频、腾讯社交广告及用户画像挖掘等精准推荐业务。Angel 更是腾讯大数据下一代的核心计算平台。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBeN5CkS7Kf4zbic7ZTZdl2nhUsicOtjKM2zkUGrKAm55URS2RLiaIzasvg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;近期，机器之心对腾讯数据平台部总经理、首席数据专家蒋杰进行了一次专访，请他详细谈了谈 Angel 的开发和开放背后的故事。（注：后文还附有蒋杰在本次会议上的演讲）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;一、Angel 特点与优势&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;为什么会选择在这个时间点开源 Angel？你怎么看待目前市面上开源的机器学习平台？相比于其他平台，Angel 的优势是什么？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;并不是我们刻意选择一个时间，而是水到渠成的过程。Angel 已在腾讯内部使用了一段时间，系统稳定性和性能经过了腾讯业务的检验，系统达到了一定成熟度，因此现在到了开放给所有用户的时候，希望能激发更多开放创意，让这个好平台逐步转化成有价值的生态系统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前的一些主要机器学习平台：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1）Spark(MLlib): 采用 MapReduce 的计算模型进行分布式机器学习的计算，通用性较好，但不是很适应大规模的模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2）Petuum: Petuum 验证了 SSP 的可行性，这是它带来的最大的贡献，功能方面也比较完备，不过在一定程度来说，更像是一个实验室的产品，离工业界的应用还有一段距离。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3）TensorFlow: Google 开源的机器学习系统，用来替代 DistBelief。提供了 Tensor 流编程模型，主要的优势在于为深度学习提供了通用的算子和 GPU 并行计算，目前 TensorFlow 开源的版本比较适用于单机多卡的环境，在多机多卡上性能有瓶颈。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;Angel 的哪一项特性最能吸引开发者？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;更高性能、更易用，并且在腾讯内部经历过十亿级别的大规模应用的考验，适合工业界使用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;根据这个数据（下图），Angel 的迭代时间显著优于 Spark，尤其是在模型较大的时候差距更是明显，达到这种效果的主要技术进步是什么？请通俗地解释一下。&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBpV7EpibAVN9Krw9I6YJBDhFrYyLX6Lk2HszsMdiaInwd94MWIwUra28g/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Angel 的模型，是分布式存放于多台高性能 Parameter Server 之上的，并且对模型的 pull &amp;amp; push 都做了专门的优化，对于大部分的机器学习算法，在模型越大的情况下，比起 Spark 的单点模型广播方式，性能自然越好。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;请对比一下 Angel 与 Spark、Petuum、GraphLab（Turi 底层技术，被 Apple 收购）等平台。&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Spark 的通用性很好，但架构上不适应大规模参数交换，因此我们才研发了 Angel。Petuum 验证了 SSP 的可行性，这是它带来的最大的贡献，功能方面也比较完备，不过在一定程度来说，更像是一个实验室的产品，离工业界的应用还有一段距离。GraphLab 图方面很强，但是很多机器学习算法不适合抽象为图模型，因此通用性方面不够好，另外，容错性一般。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;至于 Angel，我们主要融合了 Spark 和 Petuum 的优点，避免它们的一些短板，我们在性能、易用性、可靠性方面做了很大的加强。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;为什么考虑用 Java &amp;amp; Scala 来开发这个系统？而不是通常的 C/C++？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;主要是一个延续性的考虑，腾讯大数据平台起源于 Hadoop 和 Spark，都是基于 Java，考虑到用户的习惯，所以使用相同的语言，对于他们来说接受成本更低。另外，Scala 在接口更加的丰富和有表现力，也会对用户更加友好。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外是部署和升级的简单性，之前公司的分布式平台用的是 Java 架构为主，在这些机器上进行 Angel 运行资源的申请，都是透明的，迁移代价很低。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;目前我们了解到 Angel 在模型方面已经支持了 Latent DirichletAllocation (LDA)、MatrixFactorization (MF)、LogisticRegression (LR) 、Support Vector Machine(SVM)，而这些模型都离不开矩阵运算。可否谈谈 Angel 在矩阵运算上做了哪些优化？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前提供 Vector, Matrix 库，支持各种表达形式（稀疏或稠密）和常见存储格式（CSR，COO 等），支持常用数据类型和线性代数计算。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;你们在参数服务器上做了哪些优化？和 DistBeilef 相比，又有哪些不同？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Angel 是基于参数服务器的一个架构，与其他平台相比，我们做了很多优化。首先，我们能支持 BSP、SSP、ASP 三种不同计算和参数更新模式，其次，我们支持模型并行，参数模型可以比较灵活进行切分。第三，我们有个服务补偿的机制，参数服务器优先服务较慢的节点，根据我们的测试结果，当模型较大时，能明显降低等待时间，任务总体耗时下降 5%~15%。最后，我们在参数更新的性能方面，做了很多优化，比如对稀疏矩阵的 0 参数以及已收敛参数进行过滤，我们根据参数的不同数值类型进行不同算法的压缩，最大限度减少网络负载，我们还优化了参与获取与计算的顺序，边获取参数变计算，这样就能节省 20-40% 的计算时间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关于 DistBeilef，我们阅读过跟它相关的一些论文和资料，原理上有一定类似，但因为它没有开源，因此没有办法进行具体细节上的比较，但目前谷歌也用 TensorFlow 来替换它了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;能够支持数亿甚至数十亿的特征维度需要对系统基础架构和算法本身进行多方面的改进，特别是在算法方面，需要对每个算法进行特别的优化。Angel 在基础架构（infrastructure）和算法方面都做了哪些主要优化？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;正如刚才所说，Angel 是基于分布式参数服务器的一个架构，它解决了 Spark 上做参数更新的网络及计算的瓶颈，同时，我们在参数更新、网络调度、降低网络负载等等做了很多架构上面的优化，可以支持数据并行和模型并行，这样才能支持更大的模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在算法方面，其实算法种类繁多，每种都有自己特定的优化方法，但有框架上，会有一些通用的优化方法：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;对传输的算法模型进行低精度压缩，用较少的字节传输浮点数，减少网络流量，加快系统速度；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;每个计算节点建立索引，只向 PS 获取本节点需要的模型子集；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;过滤掉对模型影响较小的更新值，降低网络传输数据量等。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除了这些通用的方式，Angel 针对每种算法也做了大量有针对性的优化，例如 GBDT、LDA 等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GBDT：在 PS 端提供自定义的 Pull 函数，在 server 端完成树节点的分裂，避免将整个梯度直方图发送到计算节点，极大减少网络流量。计算节点向 PS 端 Push 本地的梯度直方图时，使用低精度压缩。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;LDA：Angel 实现了各种 LDA 的 sampler，可以根据具体应用场景选取最合适的 sampler；充分利用了数据稀疏的特点和非均匀分布的特点，提供高效的压缩方式，降低传输数据量；根据数据的分布情况来进行矩阵的划分策略，从而达到 ps 的负载均衡；对不同的词做了细粒度的调度，可以根据词-话题矩阵和文档-话题矩阵的大小来选择是在 worker 上做计算还是在 server 上做计算，从而减少网络开销。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;Angel 和 Spark 一样属于 in-memory 计算吗 in-memory 计算的一个难点在于资源配置和内存管理。在腾讯内部，Angel-as-a-service 是如何做到能够处理不同规模、频率、算法、时间需求的工作量的？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;是的，Angel 也属于 in-memory 计算，但是，Angel 占用的内存会比 Spark 小很多，因为 Angel 主要针对机器学习，专门进行了优化。另外，Angel 并不是一个常驻服务，每个计算任务独立，它的生命周期和计算任务一致，不长期占用。我们可以通过参数来设置 Angel 占用的资源量，也可以通过训练数据量和模型计算一个默认的资源占用量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;二、Angel 与深度学习&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;Angel 对深度学习和强化学习的支持怎么样？支持 GPU 吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Angel 支持基于 GPU 的深度学习，它支持 DL4J，另外，目前 Angel 还能支持如 Caffe、Torch 和 TensorFlow 等业界主流的机器学习框架，提供计算加速。两年前我们就开始在效果广告领域尝试使用深度学习，深度学习+在线学习在我们的效果广告取得很好的效果。我们也在广告领域开始强化学习的应用实验，并探索深度学习+强化学习的融合。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;在 TensorFlow、MXNet 等其它架构上已经实现的模型迁移到 Angel 上的难度有多大？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们在整体架构层面有兼容不同计算框架的设计考虑，同时我们建设了很多相对应配套的工具来降低迁移成本，因此，整体迁移难度很低。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;三、安全和隐私&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;随着信息安全和数据保密需求的日益增加，腾讯的基于云的大数据分析服务面临哪些信息安全和数据隐私的要求？这些要求如何影响了像 Angel 一样的系统的设计和实现？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据安全一直是腾讯首要关注的，我们在数据安全方面有很多规范，技术方面也会要求各层的平台进行全力安全保障。具体到 Angel，它有完善的用户认证和权限控制体系，确保非法用户无法登陆系统，合法的用户也只能看到自己的数据；其次，Angel 的数据存储在具有高容错性和可用性的分布式存储系统上，数据不会丢失，同时数据是分片的，同时也有独特加密格式，此外不同业务之间的数据是隔离的；最后，Angel 拥有完善的监控体系和日志审计，非法访问会被及时发现和处理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;四、背景与展望&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;在 Sort Benchmark 大赛中腾讯团队获得了 GraySort 和 MinuteSort 两项的冠军，速度大幅提升背后应用的技术是怎样的？为何能获得如此大的速度提升？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;比赛冠军，可以说是腾讯大数据平台的厚积薄发，我们的平台发展了 7 年，历经了三代的演进，经历了离线计算、实时计算、机器学习的三大阶段的发展，我们的平台每天都在经受着腾讯数以万亿计的业务量的考验，腾讯的业务量大并行业务类型复杂，迫使我们在高性能计算及资源调度方面必须适应业务的要求，必须灵活、性能高，并要有很好的灵活性。正式有了这些积累，才让我们在比去年更低的成本的条件下取得比去年提升几倍的成绩。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;腾讯内部已经用到了哪些基于 Angel 的产品？在推广中有哪些问题吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Angel 定位于大规模机器学习的计算，自今年初上线以来，已应用于腾讯视频、腾讯社交广告、用户画像挖掘等精准推荐业务，效果非常明显。目前基本上所有的 BG 都有业务在使用并且用户越来越多。推广过程中问题不少，主要是用户对一个新事物的接受需要一个逐步的适应过程，有一定的学习和业务迁移成本，所以，我们在易用性方面以及业务迁移方面做很多工作，降低用户的使用的门槛。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;开发这个框架投入了多少资源？开发团队有多少人？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Angel 项目在 2014 年开始准备，2015 年初正式启动，刚启动只有 4 个人，后来逐步壮大。项目跟北京大学和香港科技大学合作，一共有 6 个博士生加入到我们的开发团队。目前在系统、算法、配套生态等方面开发的人员，测试和运维，以及产品策划及运维，团队超过 30 人。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;Angel 已经支持了 SGD、ADMM 优化算法，后续还将支持哪些算法？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;主要看用户需求，应用有需要的，我们就会支持。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;能谈一下 Angel 此次开源的原因和意义吗？Angel 后续的短期计划和长期计划是什么？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;腾讯大数据平台来自于开源社区、受益于开源社区，所以我们自然而然地希望回馈社区。开源，让开放者和开发者都能受益，创造一个共建共赢的生态圈。在这里，开发者能节约学习和操作的时间，提升开发效率，去花时间想更好的创意，而开放者能受益于社区的力量，更快完善项目，构建一个更好的生态圈。我们一直都在回馈社区，开放了很多源代码，培养了几个项目的 committer，这种开放的脚步不会停止。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;开源只是个开头，后续我们会努力做好社区建设，我们会投入比较多的资源来响应社区的需求，我们会为 Angel 建设更多更好的配套生态来支持更多的业务场景。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;目前国内外几大科技巨头都在主推一个开源平台，腾讯此次开源后，如果看待这种竞争格局，以及腾讯在这方面的竞争优势？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;竞争一直都会存在，竞争促使进步，会让整个行业发展更快，所有从业人员和用户都是好事。至于各企业的平台，每家都有自己的优势，也有不足，开源能促使短板被优化。让竞争来的更猛烈些吧。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;为什么命名 Angel？开发中有什么有趣的故事吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们开发的初衷是一个可以计算更大模型，速度快到飞起来，像插上翅膀一样的平台，也希望它对用户足够友好，门槛低，易用性高，会是一个友好善良的平台形象。另外，这个项目对我们几个开发人员来说非常重要，心里很宝贝这个项目，所以自然而然想到了 Angel。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;以下是腾讯数据平台部总经理、首席数据专家蒋杰在本次会议上的演讲整理：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;很多人已经知道腾讯获得了今年的 Sort Benchmark 的排序的 4 项冠军，很多朋友来问我：腾讯是怎么做到的，背后支撑的究竟是什么样的技术？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今天，我借这个机会，跟大伙来讲讲背后的一些故事。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBUdqSRY7jmLiatHexAdB0XIHkYqRicaBC4miaFvhdIy5t2gk20b32BPqwA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相信很多人看过我们在很多城市机场投放的这个广告，这个广告里面画的是一个赛跑的选手。排序比赛就跟奥运会的百米赛跑一样，都要很快。但我想说的是：其实我们更像一个长跑选手，我们在跑马拉松。这场马拉松，我们跑了 7 年。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFB0tLgc2BaYhru5J62ia1LqSzqVxKOxNvjriciaqwnbwXFVElpFssibqSljQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;回顾过去几年的比赛成绩，几年前冠军都是被美国企业垄断的，最近三年则是 BAT 拿了冠军。应该说，这几年，国内互联网的发展速度不比美国慢，与此同时，以 BAT 为代表的国内互联网企业的计算能力也不落后于美国。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;过去几年，获得冠军的团队用的基本上都是 Hadoop 和 Spark。其实腾讯的大数据平台，也是始于 Hadoop。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBxHorg5T4NaWyWIOaIuCSC7SM64miarMzS5FWN4D38iahCfxGeqLvna0Q/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们之所以能获得四项的冠军，是我们经历了几年的打磨，追求极致，我们希望最大限度地压榨机器的性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先，从成本的角度，只有把硬件压榨到极致，成本才会低。我们采用的是 OpenPower 架构的机器，按节点数计算，我们规模只有去年冠军的六分之一。按照今年的硬件价格，我们总 TCO 成本远低于去年的冠军。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在调度层面，我们对调度算法做了深度优化，使得每台机器的 CPU、内存、网络、磁盘 IO 等每个环节都能发挥到极致。本次比赛的其中两项为 MinuteSort，比拼的就是一分钟内的排序数据量。在这里，时间调度的效率就变得非常重要，而在这两项比赛上我们比去年提升了 5 倍——是提升幅度最高的；这也从另一个方面说明了我们在调度效率上的领先性。总结为一句话就是：最大限度地压榨了硬件的性能，才让我们取得了这个成绩。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前我们用于比赛的这个集群，已经在我们的现网中用起来了，在高性能计算、图计算、深度学习等领域支撑着腾讯的现网应用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;回顾我们走过的 7 年，我们是 2009 年 1 月开始基于 Hadoop 来开发我们的大数据平台，七年的征程，我们历经了 3 代平台的发展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBxnQSicYV0HKDuduBhRPGYsoqkw4XmBiaGFVeGPBiaInWp8gNZj0lyPbRQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2009-2011 年是我们的第一代平台。我们的第一代平台只支持批量计算的场景，主要就是报表。在这个过程中我们重点发展了平台的可扩展性。我们不断增大集群的规模——从 09 年的几十台发展到了现在总规模接近 3 万台。总结起来：第一代就是「规模化」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二代用三个字总结就是「实时化」。这是 2012 年到 2014 年，主要支持在线分析和实时计算的场景，比如实时报表、实时查询、实时监控等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第三代是去年到现在，主要是建设机器学习平台来支持腾讯各业务数据挖掘的需求。这是从数据分析到数据挖掘的转变，三个字总结就是「智能化」。、&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFB2ZC7FmWe8ibMRN0o1nf4nj5G2iak6AqCJc8EfmSEhIOERNT29h6wM9gQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一代是离线计算的架构，是基于 Hadoop 开发的，我们起名叫 TDW——腾讯分布式数据仓库（Tencent distributed Data Warehouse）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;社区的 Hadoop 迭代慢，单一集群规模小，稳定性和易用性都很差，不能达到腾讯的要求，因此我们按腾讯的业务运营标准，做了深度定制开发，我们着重发展集群的规模，解决 Master 单点瓶颈不能扩展的问题，我们优化了调度策略来提高 Job 的并发性，也加强了 HA 容灾建设；还有很关键的一点的是，我们丰富了 Hadoop 的周边生态，建设了配套的工具和产品来降低用户的使用门槛。语法上，我们兼容 Oracle 的语法，方便腾讯各产品部门做程序的迁移。Hadoop 大数据的性能很强，但是小数据分析的效率很差，我们就集成了 PostgreSQL 来提升小数据的分析性能，从而打通 Hadoop 和 PG 的访问界限。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;就这样，我们从最开始的几十台、到几百台、到几千台。几年以后，在 2013 年单一集群达到了 4400 台，2014 年单一集群突破了 8800 台，处于业界领先的水平。目前我们的总规模接近 3 万台。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;TDW 的建成解决了我们内部三大业务痛点：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFB95v0gOOhqJia1zAfIYCtTib9sTicPlW25EFxFib3FydPMENsr8j3zWKcxw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一，它使我们具备了 T/P 级的数据处理能力，几十亿、百亿级的数据量，基本上 30 分钟就能算出来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二，它的成本很低，我们可以使用很普通的 PC Server，就能达到以前小型机一样的效果；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第三，容灾方面，原来只要有机器宕机，业务的数据肯定就有影响，各种报表、数据查询都出不来。现在 TDW 的机器宕机，业务完全无感知，系统会自动做切换、数据备份等等的事情。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;正是解决了业务的这些痛点，业务部门都愿意把计算迁移到 TDW。到 2012 年底，我们把所有原来在 Oracle 和 MySQL 上跑的报表都切换到 TDW。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;TDW 的建成，让我们具备了融合所有产品平台的数据的能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以前的各产品的数据都是分散在各自的数据库里面的，是一个个数据孤岛，现在，我们以用户为中心，建成了十亿用户量级、每个用户万维特征的用户画像体系。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBCytWye3ibBuxcNgLaibOjxfkdzWOu5U4nyg5k87G39zwHiafY8je4kwNg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以前的用户画像，只有十几个维度——主要就是用户的一些基础属性，比如年龄、性别、地域等。以前构建一次要耗费很多天，数据都是按月更新，有了 TDW，我们每天更新一次。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个用户画像已经应用在腾讯所有跟精准推荐相关的产品里面。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBtxH3ZZbzbND45diaoXr3iarosvmTH9wqN4AgiaAAoMVDVZf74oibicicbWcA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;推荐相信大家现在都耳熟能详，但是放在 6 年前，这还是一个刚刚新兴起的应用；TDW 为我们提供了一个快速切入快速支撑的能力。通过 MapReduce 的编程范式，基于 TDW 的平台，我们可以专注于各种推荐算法逻辑本身的实现，比如大家常见的 CF、MF、LR 这些算法、以及各种 hash 聚类算法；这个时候的推荐技术，面对海量的用户群体访问，更多还是基于一种实时查询的服务方式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一代平台解决了量大的痛点，但是在速度方面还有问题——数据是离线的，任务计算是离线的，实时性差。所以，我们建设了第二代大数据平台。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在第一代基础上，集成了 Hadoop 的第二代——Spark，同时，还融合了 Storm 流式计算的框架。这一代平台的集成，让我们的计算速度从原来的小时，发展到分钟，直至秒级。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFB80GHiau8xaHRBF6kMloz4Kib3SGK1j6xL3l4UZBlYoPQicX4AibUcaKMzQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据采集方面，我们构建了 TDBank，让原来通过接口机传文件的方式，T+1 的粒度，变成了毫秒级的实时采集。在这个采集平台里面，我们自研的消息中间件每天采集的消息条数超过 6.5 万亿，可以说是世界上消息量最大的消息中间件。同时，我们还有高可靠版本的消息中间件，能支持像金融、计费等高一致性的需求，保证消息不丢。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在资源调度层面，我们基于 Yarn，发展了我们的 Gaia 调度平台，Yarn 只支持 CPU 和内存的维度，而我们的 Gaia 还支持网络以及磁盘 IO 的维度，Yarn 只支撑离线计算，Gaia 能支持在线的场景，另外，我们还支持 Docker，我们平台现在每天有 1.5 亿 container。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBKeHic8dNPaYGib3sHDDwOeYs4gSF2PdX7zXuZDaP0ggrBz9VCiahI1Nsw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;再拿刚才提到的推荐例子，基于第一代平台的推荐应用会碰到 2 个问题，一个是随着用户量和访问量的增多，产生的数据会越来越多，多到在有限的时间根本不可能批处理地计算完，还有一点是用户的行为模式变化很快，需要更快地去更新各种维度的用户画像；数据的实时采集让用户行为实时画像的计算成为可能，这构成了流式计算的数据流。分布式的流式计算实时更新各个维度的统计量，进一步形成了推荐算法的实时训练数据，从而把上一代的 offline 的推荐系统变成了 online 的实时推荐系统。在广告的推荐应用上，我们可以看到每一次的实时加快，都带来了更大的点击率提升。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二代的平台，实时性和体量方面都能满足绝大多数业务需求。但随着我们的数据量越来越大，我们的瓶颈很快也出现了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBNib2LRPkysDvGSicHqZBjnBzTbiaw9wibefay3Om8JzgTNfey9BZiagOC7A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们在 Spark 上做数据训练的时候，每一轮的迭代，在更新数据的时候，都会遇到网络方面的瓶颈——因为更新数据的地方是一个单点，如果数据的维度很大，这套框架就无法支撑。在我们的实际应用中，千万级的维度都可以运行得不错，但是上了亿级，性能就非常低了，甚至跑不出来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以，我们必须要建设一个能支持超大规模数据集的一套系统，能满足 billion（十亿）级别的维度的数据训练；而且，这个系统必须能满足我们现网应用的工业级需求。它能解决 big data 和 big model 的需求，它既要能做数据并行，也要能做模型并行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBT6DTnr40mTNCgpoJPlrXy1hXjgGLWp9BApJEUE8qI9heWiaAKpLue4Q/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这个问题上，存在两种解决的思路：一个是基于第二代平台的基础上做演进，解决大规模参数交换的问题。另外一个，就是新建设一个高性能的计算框架。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们看了当时业内比较流行的几个产品：GraphLab（主要做图模型，容错差）；Google 的 Distbelief（还没开源）；还有 CMU Eric Xing 的 Petuum（当时很火，不过它更多是一个实验室的产品，易用性和稳定性达不到我们的要求）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;看了一圈，我们决定自研，走自研的路。我们前两代都是基于开源的，第三代则开始了自研的历程。其实在第二代，我们已经尝试自研，我们消息中间件——不论是高性能的，还是高可靠的版本——都是我们自研的。它们经历了腾讯亿万流量的考验，这也给了我们在自研方面很大的信心。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFB9E2MNLHuBia0IicVvuGJAiafVTWGVbarYjYibRwk7edg34Lq8OTFZ9T1Ow/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此，第三代整体的计算框架方面，我们也走了自研的道路。第三代的平台，核心是一个叫 Angel 的高性能计算平台。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们聚焦在高性能的计算框架方面，同时，也是我们往机器学习、深度学习演进的一个路线。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相比第二代，第三代的计算框架，可以支持 10 亿级维度的算法训练，由以前的数据并行，到可以支持模型并行。同时，我们第三代的平台，还支持 GPU 深度学习，支持文本、语音、图像等非结构化的数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBy1zEXmbkiapAmfCsWTWYzibhsj5O81Wf8mGatN4HU3TyicxrxEL8sZjOA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Angel 是基于参数服务器的一个架构，它跑在我们的 Gaia 平台上面的。它支持 BSP、SSP、ASP 三种计算模式；支持数据并行以及工业界更看重的模型并行（因为我们主要碰到的还是模型大的问题）；另外，在网络上我们有个原创的尝试，我们用了港科大杨老师的团队做的诸葛弩来做网络调度；Parameter Server 优先服务较慢的 Worker，当模型较大时，能明显降低等待时间，任务总体耗时下降 5%~15%。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFB65OwksSVbVEPLsfv1cLgSmk225OuTQcWXpmJwAdjc7OHytlrNKDJIQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Angel 提供很丰富的算法，支持 LR、SVM、LDA、GBDT 等等，并且集成了非常丰富的数学函数库，另外，还提供非常友好的编程界面，能跟 Spark、MR 对接，你能像用 MR、Spark 一样编程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Angel 跟其他平台（比如 Petuum 和 Spark 等）相比，就我们的测试结果，在同等量级下，Angel 的性能要优于其他平台。比如我们用 Netflix 的数据跑的 SGD 算法，大家看一下这个图的对比：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBbkuncTubQS9tGOhGqHJfhLlE08nr6EJMY7EhjLL0z1gAJotnfFuQaA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;同时，Angel 更适合超大规模的数据训练。目前 Angel 支持了很多腾讯内部的现网业务。这里举两个例子，比如，在构建用户画像方面，以前都是基于 Hadoop 和 Spark 来做，跑一次模型要 1 天甚至几天，话题只有 1k；而在 Angel 上，200 多亿文档、几百万个词、3000 亿的 token，1 个小时就跑完了。以前 Spark 能跑的，现在 Angel 快几十倍；以前 Spark 跑不了的，Angel 也能轻松跑出来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;再看一个案例。视频的点击预测，同等数据量下，Angel 的性能是 Spark 的 44 倍以上。用了 Angel 以后，我们维度从千万扩展到亿，训练时间从天缩短到半小时，而准确度也有不小的提升。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBtjANfkVY6dCFnguYRRl2lPl0R5ceAHOD7paHicMVOultuAQoc1ewF9Q/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Angel 不仅仅是一个只做并行计算的平台，它更是一个生态，我们围绕 Angel，建立了一个小生态圈，它支持 Spark 之上的 MLLib，支持上亿的维度的训练；我们也支持更复杂的图计算模型；同时支持 Caffe、TensorFlow、Torch 等深度学习框架，实现这些框架的多机多卡的应用场景。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;各位，临近尾声了，我想总结一下腾讯大数据平台发展的三个阶段：我们从离线计算起步，经过实时计算阶段，进入了机器学习的时代。我们从跟随开源，发展到自研，我们的发展历经了规模化、实时化，以及智能化的变迁。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，我要借这个机会跟大家公布一个消息，那就是：我们的大数据平台将全面开源。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们会在明年上半年把 Angel 以及 Angel 周边的系统进行开源。我们平台源自开源，我们的发展离不开开源，所以我们会以最大的力度拥抱开源。其实在开源的道路上，我们一直都在参与：我们第一代平台的核心 TDW-Hive 在 2014 年就开源了；我们还在很多社区项目贡献了很多核心代码，培养了好几个 committer。而未来，我们的开源力度只会越来越大。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谢谢大家。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心原创文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 19 Dec 2016 21:08:36 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 麦肯锡报告：机器的崛起，中国高管眼中的人工智能</title>
      <link>http://www.iwgc.cn/link/3984749</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;转自麦肯锡咨询公司&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;作者：&lt;span&gt;Christopher Thomas，梁刚&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自 20 世纪 50 年代「有思想的机器」诞生以来，软件开发人员一直在试图教会计算机如何像人类一样思考。然而，在接下来的几十年里，人工智能（AI）的发展速度并没有快速增长。相关技术的研究也通常伴随着停滞和挫折，因为开发成本过高，也缺乏足够的数据量来支持人工智能算法。&lt;/span&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而，在过去十年中，计算能力大幅提升，深度学习算法不断提高，机器学习变得更加强大，与此同时数据量的急剧增长也大大推动了这些算法的发展，人工智能从此进入了加速增长的新阶段。经过了 60 多年，人工智能的发展已接近临界点，完全具备实现大规模商用的潜力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在中国，人工智能也插上了腾飞的翅膀。「百度大脑」就是其中一个推动因素。这是一家百度建立的研发平台供第三方来开发人工智能应用，投资于无人驾驶汽车的研究，以及提供给蓬勃兴起关注于机器学习应用及相关商业模式创业公司的利用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而，我们最新的一项研究表明，人工智能的迅速发展可能更有利于科技板块，因为这一行业具有相关的人才、技术和资金，更易于推动人工智能的发展和普及。相比之下，中国的传统行业还没准备好利用人工智能技术，大多还没把其视作战略重点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;关键术语&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能是有关计算机系统的理论和发展，这类计算机系统能够代替人类智能执行一般由后者执行的任务，比如视觉感知、语音识别、决策和语言转换。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器学习也是一种人工智能，可以不通过明确的编程就能让计算机获得学习的能力。机器学习专注于开发能自学的计算机程序，遇到新数据时，这些程序能够自我成长并做出改变。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深度学习是人工智能的一项功能，主要通过模仿人脑的工作模式进行数据处理并生成供决策用的模式。深度学习是人工智能中机器学习的一个子集。深度学习具备的网络能够向无结构或无标签的数据学习，而无需任何监督。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了更好地了解人工智能对中国传统行业的潜在影响，我们最近对 80 家公司展开了一项调查。其中，60 家处于传统行业，如零售、重工业和建筑业。另外，调查对象还包括 20 位人工智能专家，他们来自中国领先的互联网公司，其中包括几家初创公司。调查对象覆盖各行各业，具有一定代表性，包括金融、医疗保健、零售、消费品、科技、媒体和电信。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有一点大部分受访者都认同，那就是人工智能会成为其所在行业的一股颠覆性力量。尽管变化的步伐可能因行业不同而有所差别，但 90％的受访者都认为，人工智能会从根本上改变自己的行业。在问到人工智能会怎样产生影响时，受访者提出了 100 多种潜在方式，从提高运营效率的应用程序开发，到全新的产品和服务开发，不一而足。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管人工智能带来了一线曙光，但我们的研究表明，传统行业公司仍在挣扎，犹豫该如何对这一技术进行投资。超过 40％的调查受访者表示，所在公司的 CEO 并没有将人工智能作为战略重点，60％以上的人认为，所在公司在过去一年中，人工智能战略并没有取得令人满意的进展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBMEejShrOgdQ1NwPBD9fFZicdPnuiaGKMqk8f4lwX0tMzk3nMbcHnMEDw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在调查中，大多数高管指出，人才匮乏是制定具体人工智能战略的主要障碍。事实上，中国只有不到 25％的人工智能从业者拥有超过 10 年的行业经验，而在美国这一比例也只有 50％。一名首席技术官表示，开设机器学习相关专业的中国高等院校屈指可数。即便是有此专业，大多数学生也开发不出现实生活中能真正运用的应用程序。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;鉴于以上种种挑战，传统行业的受访者认为，要在这一领域取得成功，前景不容乐观：84％的受访者表示，人工智能最大的赢家可能是互联网公司和创业公司，而不是现在的行业领军者。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBbB3wrVDBGlyjhk8yEDGQMdzg1eFV1gavoUsInw5NUhUXfvz7hxcckg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;人工智能到了爆发的临界点&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在技术突破和应用机会不断扩展的双重推动下，人工智能走到了大规模应用的临界&lt;/span&gt;&lt;span&gt;点。四大趋势表明，人工智能将给各行各业带来颠覆性的变革：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBIiaJ4UZn6SriafVdHo7wxCpicbu2DceN3iagLibst1teHeqhVqib7rsfo1UA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 领先的半导体厂商及 CPU 和 GPU 企业均将人工智能视作核心目标，斥巨资投入大&lt;/span&gt;&lt;span&gt;量处理技术，为人工智能及机器学习打下基础。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 开源人工智能平台的数量及规模持续激增，开发人员可以自由利用编程界面，使&lt;/span&gt;&lt;span&gt;用各类工具、算法以及训练数据，建立人工智能功能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 数据资源的规模及种类也大幅增加，意味着可以对机器进行训练，从而使其做出&lt;/span&gt;&lt;span&gt;更快更好地决策。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4. 高科技巨头以及风投机构对致力于「人工智能跨行业创新应用」的初创公司趋之&lt;/span&gt;&lt;span&gt;若鹜。从 2010 年到 2014 年，人工智能初创公司的风险投资额增加了 20 倍以上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBIbMuMb8urXLt56Z94uk3TgMPwLiazwdysviayp2A1KyY7d3tOOKkvRLQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们对这种历史性转折并不陌生。当技术创新与市场力量汇聚在一起时，便会创造&lt;/span&gt;&lt;span&gt;出足以扭转整个行业局势的产品。2007 年苹果手机 iPhone 的发布就是这样一个历史&lt;/span&gt;&lt;span&gt;时刻。当触摸屏的成熟技术与移动电话的日益普及交织在一起时，便产生了足以改变&lt;/span&gt;&lt;span&gt;整个行业领域的新产品。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然确切的时间仍无法预测，但人工智能似乎已走到了类似的爆发性历史转折点。&lt;/span&gt;&lt;span&gt;人工智能的重大技术进步创造了大量机会，将催生出改变游戏规则的产品和服务。&lt;/span&gt;&lt;span&gt;其中一项关键的应用便是语音识别。自然语言处理的成功率已接近 99％（技术临界点），全球和中国的大型科技企业正在努力推出相应的家用网络设备，如具备语音&lt;/span&gt;&lt;span&gt;输入技术的路由器。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在无人驾驶领域，关键技术也已接近临界点：比如目标跟踪算法，即用于识别车辆&lt;/span&gt;&lt;span&gt;附近目标的算法，已达到 90％的准确率。再比如，固态激光雷达也已面市（类似于雷&lt;/span&gt;&lt;span&gt;达，但以激光为工作光束），可用于收集车辆周围环境的高频数据。由于这些技术迅&lt;/span&gt;&lt;span&gt;速进入成熟可行阶段，各类大型科技公司，如谷歌、英伟达、英特尔和宝马都在快马&lt;/span&gt;&lt;span&gt;加鞭，努力开发自动驾驶汽车。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBI6V3UdutrC9DVEg629iaUjQjLnWN3CYibHNN6LlSK9wbeicBB7T8lgpsQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;中国将引领行业趋势&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管人工智能的发展主要受全球高科技企业的推动，中国企业也致力于在这一新兴&lt;/span&gt;&lt;span&gt;领域成为领导者。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;例如，中国对本土半导体行业的打造主要强调发展机器学习所依赖的 CPU 和 GPU&lt;/span&gt;&lt;span&gt;技术。百度以 96% 的准确率成为语音识别市场的领先企业，追上甚至赶超了谷歌、&lt;/span&gt;&lt;span&gt;微软及亚马逊等竞争对手。预计中国的人工智能应用市场将以 50% 的增速逐年增&lt;/span&gt;&lt;span&gt;长，远远超过全球市场 20% 的复合年增长率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;中国政府已经认定，人工智能是经济发展新的引擎，因而投入资金开展学术研究，&lt;/span&gt;&lt;span&gt;并为人工智能企业提供经济奖励。中国的互联网巨头将人工智能视为重点，而初创&lt;/span&gt;&lt;span&gt;公司不断开发各种人类智能应用，包括机器人、医疗卫生、以及无人机领域。部分中&lt;/span&gt;&lt;span&gt;国公司（比如 NIST 的科大讯飞和 Imagenet 的海康威视）在人工智能技术领域甚至&lt;/span&gt;&lt;span&gt;超过了全球知名的竞争对手。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;对传统企业的挑战: 成为行业的领导者还是落后于人&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;中国积极推进引领人工智能革命，为国内非高科技类企业带来一定难题，因为后者将&lt;/span&gt;&lt;span&gt;不得不开始采用人工智能技术。很多这类传统企业开始与互联网公司在人工智能&lt;/span&gt;&lt;span&gt;应用领域开展合作，以增加自身的成功几率。在这合作过程中，他们为今后可能颠覆&lt;/span&gt;&lt;span&gt;自己的对手提供珍贵的专有数据以及行业经验。与可能摧毁自己的公司合作，就像&lt;/span&gt;&lt;span&gt;他们冲击银行、商业及其他行业一样，真的能够帮助传统企业取得成功吗？高科技&lt;/span&gt;&lt;span&gt;企业是否成为中国人工智能繁盛时期的唯一赢家？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于传统企业而言，如果不开展合作，其他可采用的策略为：投入资金，加入人工智&lt;/span&gt;&lt;span&gt;能技术和能力的竞赛。然而，鉴于我们预测人工智能业未来的发展带有很多不确定&lt;/span&gt;&lt;span&gt;性，因此，仅靠预测采取上述举措可能是很不明智的。中国在人工智能领域发展的&lt;/span&gt;&lt;span&gt;这一优势能否被国内传统企业所充分利用？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;CEO 们需回答九个关于人工智能战略的问题&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于人工智能，中国传统企业大多不会战略性地采取「放任不管」的态度。中国企业&lt;/span&gt;&lt;span&gt;的 CEO 们必须积极思考这一问题，做出审慎的战略决策：是「发展壮大」、「建立合&lt;/span&gt;&lt;span&gt;作」、还是仅仅采取「观望」的态度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以下是企业领导人在制定人工智能战略时需回答的九大问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFB3QBkrS09YlqicTT6EzrPjOXzobRrVMrTr4BBbvbMuEA9mYo6ibQQyyxw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们现在处于怎样的阶段？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1) 我们所处的行业在采用人工智能技术方面处于怎样的阶段？我们现在正在使用&lt;/span&gt;&lt;span&gt;以人工智能为主的应用吗？还是正处于将人工智能运用到业务当中的最初阶段？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2) 我们所处的行业之中，谁正在引领使用人工智能技术？我们的公司是引领者、还&lt;/span&gt;&lt;span&gt;是追随者？有哪些最佳做法是我们的公司可以学习和借鉴的？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3) 我们的组织是否已经做好准备，制定并采纳人工智能战略？在公司内全面采用人&lt;/span&gt;&lt;span&gt;工智能技术需要具备哪些基础？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;未来我们的目标竞争领域是什么？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4) 在我公司所处的行业里，有哪些可行的人工智能应用案例？有哪些关键技术？哪&lt;/span&gt;&lt;span&gt;些企业可以进入我们所处的行业？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;5) 从近期和长期看，人工智能可取得哪些业务成效？在人工智能领域的投资预计&lt;/span&gt;&lt;span&gt;多久可以回报？在决定投资时机时预计会有哪些取舍？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;6) 我们应如何利用人工智能进入或打造新的领域？人工智能应用所提供的能力远&lt;/span&gt;&lt;span&gt;远超越了当前的规范，可能促使企业将当前重点扩大到其他领域。人工智能将如何&lt;/span&gt;&lt;span&gt;改变竞争规则，以及我公司所处的竞争格局？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们需要哪些人工智能能力？如何获得这些能力？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;7) 我们应利用哪些人工智能的能力？根据我们对潜在案例的分析，以及人工智能的&lt;/span&gt;&lt;span&gt;竞争影响，我们具体需要哪些技术和商业人才来实施我们的目的？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;8) 我们怎样才能获得上述能力？是外购、合作、还是自建？每项选择都有潜在的优&lt;/span&gt;&lt;span&gt;势和劣势。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;9) 我们应如何利用上述能力打造持续的创新流程？企业必须能预测上述能力将如&lt;/span&gt;&lt;span&gt;何推动企业在未来持续增长，才能够最大程度地利用人工智能的投资&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于传统行业的企业，问题不在于他们是否应该考虑在自身的业务及战略流程中采&lt;/span&gt;&lt;span&gt;用人工智能应用—而是他们应该制定怎样的人工智能战略，以及如何去实施这一&lt;/span&gt;&lt;span&gt;战略。中国的非高科技企业或者可以向国内高技术企业学习，或者眼睁睁看着对方&lt;/span&gt;&lt;span&gt;在技术行业独占鳌头。为避免落后或更糟的局面，CEO 们必须积极考虑人工智能在&lt;/span&gt;&lt;span&gt;其所在行业的现状以及潜在的未来，明确未来目标的重点，建立发现并捕捉人工智&lt;/span&gt;&lt;span&gt;能在本行业推广效益的引擎。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;获取报告 PDF 全文 (2MB)，请点击「阅读原文」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;作者诚挚感谢魏海, 朱虹, 韩赟儒和戈弋对本报告的贡献。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Christopher Thomas 为麦肯锡全球董事合伙人, 常驻北京分公司；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;梁刚为麦肯锡资深专家, 常驻台北分公司。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 19 Dec 2016 21:08:36 +0800</pubDate>
    </item>
    <item>
      <title>资源 | 贝叶斯神经网络简史</title>
      <link>http://www.iwgc.cn/link/3984751</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自NIPS2016&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：杜夏德、曹瑞&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;在刚刚过去的 NIPS 2016 会议上，剑桥大学信息工程学教授 Zoubin Ghahramani 为我们讲述了贝叶斯神经网络的发展历程。本文从研究背景和问题应用切入，介绍了贝叶斯神经网络的起源、黄金时期以及后来的复兴，并介绍了每个发展阶段的几篇关键研究，是一份简明扼要的学习资料，能够帮你快速深入理解贝叶斯神经网络。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBbH7aabjuhy57WmOezDAWxnHqkfZvCXpC2myx9NITLF3ribsYruLJ6qg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBHZDMVNMlAZHiaG1zc6IGDJibcibz406Da4krPjTs84G2Dibia6bDThFjwMA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P4：上世纪八十年代的研究背景&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;《玻尔兹曼机》于 1985 年出版，1986 年反向传播网络论文发表，接着 1987 年 PDP 大量出现。这一领域过去也被称为连接机制，NIPS 是该领域的主要学术会议。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P5-P7：神经网络与深度学习简介&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;神经网络与深度学习系统在很多基准任务的表现优异，但是它也有以下缺陷：&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;需要大量数据（常常是数百万样本）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;训练与部署的计算量大（云 GPU 资源）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;不确定性表征得不太好&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;常常被对抗样本欺骗&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;对于优化很挑剔：非凸+架构选择，学习程序（procedure），初始化等等，还需要专家知识（expert knowledge）和实验&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;过程黑箱，无法解释，缺少透明性，很难信任其结果。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBh5JyUWHWjfHVgH9Cr58sdZlA0RiaASq5u2XpBfuSzqGptSFsMD3Ec9g/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P8 -12：贝叶斯在这里有什么帮助&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;处理参数不确定性的所有来源&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;具备处理结构不确定性的能力&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;贝叶斯定理告诉我们要从数据（可衡量的量）当中做一些关于假设（不确定的量）的推理。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;学习和预测都可以看作是推理的形式。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;校正模型与预测不确定性：让系统知道它们何时不知道。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;自动模型复杂性控制与结构学习（(Bayesian Occam's Razor)）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;要清楚的一点是「贝叶斯」属于算法范畴，不是模型类。任何定义好的模型都可以用贝叶斯方法.&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBZiaeJyDAUqPlurOdQiczKJsEmEmy7qfHEFdqWB4oe9zyP60KkIErQiaUA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P13：贝叶斯神经网络&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P14-16：贝叶斯神经网络的早期历史&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;贝叶斯神经网络的早期历史可以从以下几篇论文中了解：&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;John Denker, Daniel Schwartz, Ben Wittner, Sara Solla, RichardHoward, Lawrence Jackel, and John Hopfield. Large automaticlearning, rule extraction, and generalization. Complex Systems,1(5):877-922, 1987.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Nafitali Tishby，Esther Levin，and Sara A Solla. Consistent inference of probabilities in layered networks: Prediction and generalization. In IJCNN,1989.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;......&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBa8icRhu7OMuWicnI5BsmaI81H9ib89N1GhfviaX75ABPBiaslRGXNDtwoaw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P17- 20 贝叶斯神经网络的黄金时期&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;David JC Mackay 发表在神经计算（Neural Computation）上的一篇文章：A Pratical Bayesian Framework For Backpropagation Networks 揭开了这一时期的序幕。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Neal, R.M. 1995 年在多伦多大学的博士论文：Bayesian learning for neural networks. 这篇论文也奠定了贝叶斯神经网络 (BNN) 和高斯过程（Gaussian processes）以及自动相关决策机制（automatic relevance determination ,ARD）之间的关系。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBkh41AAnibxr1QNc42Kg4xZw2gXgMc4kxN0bFM4WTVQtbGSHdnsBQneg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P21-24 高斯过程与贝叶斯神经网络&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;高斯过程可被用于回归、分类、排名等。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;将郎格文动力学（Langevin dynamics，一种 MCMC 的形式）与随机梯度下降（SGD）结合起来得到一个基于 minibatch SGD 的高度可扩展的近似 MCMC 算法。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;这样一来，贝叶斯推断就能像运行嘈杂的 SGD 那样简单。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;一个带有一层隐藏层和无数隐藏单元的神经网络和权重高斯先验&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;MacKay 和 Neal 的贡献将特征与架构选择与高斯过程联系起来&amp;nbsp;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P25- 28 贝叶斯神经网络中的变分学习（variational learning）&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Hinton 的一篇论文推导出一个贝叶斯网络权重的对角高斯变分近似，但是用最小描述长度信息理论语言进行描述。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBP69MrPBE9g5OKoaSk8qibRsGKAgYuN2ptDpqG13qPzeXzeRJrlzFGtQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P29 随机梯度朗格文动力学（Langevin Dynamics）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFB9wFiaCvr6zpicuuj2hJRTbbHqcbD28hMgknPykb3ON6kALNDfZ35JI9g/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P30：贝叶斯神经网络的复兴&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P31-32 概率方法什么时候变得非常重要？&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;学习的很多方面都非常依赖于不确定性的细致表征&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P33 结论&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;概率模型为建立能从数据中学习的系统提供了通用框架&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;贝叶斯神经网络有很长的历史并且正在经历着复兴的浪潮&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBKqkGJfqib9LvHHf0ompuzGJGmlr1PGQqpURbG81odVkRibGQv525qLew/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBcsicfEjQCt8QhUqBAFwjyrpGTKBpYdVoS3ibegJmrYpc3uItr5JTQIiaQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P35-36 模型比较及学习模型结构&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBNHoP2GSwrP6X3nrN4vMxHcJ2ibU8Xrxibrq5p81ZOUSaj1Yibf0gibZ2jQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P37-39 贝叶斯奥卡姆剃刀（Bayesian Occam's Razor）&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;模型类别太过简单就可能无法生成数据集。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;模型类别较复杂可以生成很多可能的数据集，所以它们也不太可能随机生成某个特定的数据集。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBibNHc0dibXTNicT14FTZHJPZOxWsjB1AP7Y0lib3ibZdxqP0iatMBLS9iahwg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P40 模型比较和奥卡姆剃刀&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBibdcPqhQaxzsSFa7oicSUl02ZrtnvvUQYr836w2YegAR7APm4GyCE0nQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P41-42 边缘似然 (marginal likelihood) 和后验（posteriors）的近似方法（Approximation Methods）&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;拉普拉斯近似（Laplace Approximation）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;贝叶斯信息准则（Bayesian Information Criterion，BIC）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;变分近似（Variational approximations）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;期望传播 (Expectation Propagation，EP)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;马尔科夫蒙特卡洛方法（Markov chain Monte Carlo methods，MCMC）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;序列蒙特卡洛方法（Sequential Monte Carlo，SMC）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;精确抽样（Exact Sampling）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;……&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;点击阅读原文即可阅读完整PPT&lt;/span&gt;&lt;/strong&gt; &lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 19 Dec 2016 21:08:36 +0800</pubDate>
    </item>
    <item>
      <title>开源 | OpenAI 的 PixelCNN++实现：基于 Python3 和 TensorFlow</title>
      <link>http://www.iwgc.cn/link/3984753</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Github&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：朱思颖、蒋思源&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBrmb8RFIicuMuCu9PKM04QgDTsgotCkAN0GXWQ5wIQY7MickOKegNiaaMA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今年 6 月 DeepMind 的一条官方推文里，公布了他们当时运用 PixelCNN 所生成的条件自然场景合成图，并称这种方法将艺术生成模型提升到一个新的水准。DeepMind 运用 PixelCNN 实现条件图像生成的论文也被今年的 NIPS 所收录（见文末附录）。6 个月之后，近日，OpenAI 在 GitHub 公开了 TensorFlow 框架里用 Python3 实现的 PixelCNN 优化版——PixelCNN++的源码，其论文已被 ICLR 2017 接收。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所公开的源码是 PixelCNN++的具体代码实现，是在 TensorFlow 框架里用 Python3 编写的。PixelCNN++的具体阐述在以下论文：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;PixelCNN++：A PixelCNN Implementation with Discretized Logistic Mixture Likelihood and Other Modifications, by Tim Salimans, Andrej Karpathy, Xi Chen, Diederik P. Kingma, and Yaroslav Bulatov.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们的研究是建立在 van der Oord 等人今年 6 月份最初提出来的 PixelCNN（所附论文一）上。PixelCNN 是一类强大的生成模型，它有易处理似然性（tractable likelihood）从而容易进行抽样。其核心的卷积神经网络计算在一个像素值上的概率分布，且受左侧和上侧的像素值约束。下面是在 CIFAR-10 上训练的模型里面的示例样本，其实现了每维度 2.92 bits（van der Oord 等人的 PixelCNN 是 3.03 bits）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;来自模型（左）的样品和来自以 CIFAR-10 类标签为约束的模型的样本（右）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBvRPXMujfQYj3gT6nnYibOibrkW6jlCKdU3UFGoszbYe4icbRero76M02g/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此代码支持将我们改进的 PixelCNN 在 CIFAR-10 和 Small ImageNet 上进行多 GPU 训练，并很容易适应额外的数据集。在具有 8 个 Maxwell TITAN X GPU 的机器上进行训练在大约 10 小时内能实现每个维度 3.0 bits，并且需要大约 5 天才能收敛到 2.92 bits。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;开源地址：&lt;em&gt;https://github.com/openai/pixel-cnn&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;设置&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你需要以下环境运行该代码:&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: circle;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;多 GPU 计算机&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Python3&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Numpy, TensorFlow&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;训练模型&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使用 train.py 脚本进行模型的训练，在 CIFAR-10 上训练默认模型只需要简单键入：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;python3 train.py&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你可能希望至少可更改 --data_dir 和 --save_dir，它们指向系统下载数据的路径（如果是无效的）和保存点的位置。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我想使用更少的 GPU 进行训练。为了在更少的 GPU 上训练，我们建议使用 CUDA_VISIBLE_DEVICES 缩小 GPU 可用（the visibility of GPUs）数量，然后再运行脚本。不要忘记相应地调制 flag： --nr_gpu。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我想训练自己的数据集。看看 data/ 文件夹中的 DataLoader 类，必须为你自己的数据集写一个类似的数据迭代器，然后代码才能从那边正常运行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;预训练模型检查点（checkpoint）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你可以下载（http://alpha.openai.com/pxpp.zip）(http://alpha.openai.com/pxpp.zip%EF%BC%89) 中我们已训练的模型（TensorFlow），它在 CIFAR-10 上实现了 2.92bpd。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;引用&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你发现代码很有用，请在你的研究中引用我们：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;@inproceedings{Salimans2016PixeCNN,&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;title={PixelCNN++: A PixelCNN Implementation with Discretized Logistic Mixture Likelihood and Other Modifications},&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;author={Tim Salimans and Andrej Karpathy and Xi Chen and Diederik P. Kingma and Yaroslav Bulatov},&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;booktitle={Submitted to ICLR 2017},&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;year={2016}&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;}&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;附录：&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;论文：Conditional Image Generation with PixelCNN Decoders&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBSqSLkEUFbkibaawwJhobnI8YxjgMLRUn1R0zkNgYwxpctOqImxrSE2g/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本研究探索了使用条件图像生成与基于 PixelCNN 架构的新的图像密度模型。该模型可以以任何矢量为条件，包括描述性标签或标签，或由其他网络创建的隐嵌入。当使用来自 ImageNet 数据库的类标签时，该模型能够生成表示不同动物，对象，风景和结构的多样化、形象逼真的场景。当对由未知的面部的单个图像给出的卷积网络产生的嵌入进行调节时，它可以生成不同面部表情，姿势和光照条件下同一个人的各种新肖像。我们还展示了条件 PixelCNN 可以作为图像自动编码器中的强大的解码器。此外，提出的模型中的门控卷积层提高了 PixelCNN 的对数似然度，以匹配 ImageNet 上的 PixelRNN 的最新性能，大大降低了计算成本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;论文：PIXELCNN++: A PIXELCNN IMPLEMENTATION WITH DISCRETIZED LOGISTIC MIXTURE LIKELIHOOD AND OTHER MODIFICATIONS&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBqauqJZM45yZgmD77Hib4cFbOczGOEhpfDNyTxFxNhnicibSnOocaF9ib6Q/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;PixelCNN 是最近提出的一类具有易处理似然性（tractable likelihood）的强大生成模型。本文将讨论我们怎样实现 PixelCNN，同时在 Github 上开源。我们的实现方法包含对原始模型的多个修改，不仅精简了结构，还提高了性能。主要从以下几个角度完成：1. 我们使用像素上的离散逻辑混合似然（discretized logistic mixture likelihood），而不是 256 阶的 softmax 回归（256-way softmax），这能大大加快训练。2. 我们对整个像素而不是 R/G/B 子像素进行约束，从而简化模型结构。3. 我们使用下采样（downsampling）有效地捕获多种分辨率结构。4. 我们引入额外的快捷连接，以进一步加速优化。5. 我们使用 dropout 对模型进行正则化。最后，我们在 CIFAR-10 上呈现最先进的对数似然（log likelihood）结果，以证明这些改进的有用性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 19 Dec 2016 21:08:36 +0800</pubDate>
    </item>
    <item>
      <title>机器之心独家对话吴恩达：很多技术其实是中国最先开始应用的</title>
      <link>http://www.iwgc.cn/link/3966674</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;吴恩达，百度首席科学家、百度大脑项目负责人。在最近的百度语音开放平台三周年主题活动上，机器之心对这位与 Geoffrey Hinton、Yoshua Bengio、Yann LeCun 齐名的人工智能专家进行了专访，深度了解了百度的人工智能研究、吴恩达的人工智能之路，以及更多的有关人工智能技术的话题。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;一、在百度的人工智能研究&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2014 年 5 月 16 日，百度官方宣布建立硅谷实验室并任命吴恩达作为首席科学家，领头百度北京与硅谷的实验室。当时，百度投入了 3 亿美元在硅谷建起专注人工智能的实验室。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但吴恩达来到百度，并非重头开始建立深度学习。在 2013 年，百度就已建立深度学习研究院（IDL），并在图像识别、基于图像的搜索、语音识别、自然语言处理与语义智能、机器翻译等领域做出重大进展。当时，IDL 由余凯（2012 年加入百度，2015 年离职）组建，百度 CEO 李彦宏任院长，余凯任常务副院长。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;加入百度之后，吴恩达做了一件事。「他订购了 1000 个 GPU，并在 24 小时内得到。而在谷歌，他可能几周或几个月才能得到。」当时深度学习创业公司 SkyMind 的联合创始人 Adam Gibson 在一次采访中曾这么说道。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;百度之前从未买过这样的硬件。在这样的支持下，吴恩达在百度建立了一个进行深度学习的 GPU 集群，使得百度成为了世界上第一个建立深度学习 GPU 集群的公司。几年来，百度不断在 GPU 和超级计算机方向做投入，加大深度学习的研究。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在加入百度之后，曾帮助谷歌建立 Google Brain 的吴恩达也在百度建起了「大脑」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW97Eu3kQ28xCXnW6b2iagC06aJ5JbdzicYLg8nIsUXIQRMFuF31tw1kj7kcVXsPwpwENvL2LFAvp0QA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图片：百度大脑官网&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从百度大脑的官网，我们就可以明晰的看到吴恩达在百度的人工智能研究：机器学习、语音技术、图像、自然语言处理、用户画像。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;机器学习&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今年 9 月份，吴恩达在百度世界大会上宣布开源深度学习平台 PaddlePaddle。PaddlePaddle 的前身是百度于 2013 年自主研发的深度学习平台 Paddle（Parallel Distributed Deep Learning，并行分布式深度学习），一直为百度内部工程师研发使用，并且已经做出了一些实际的产品，较为成熟。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;据介绍，PaddlePaddle 是一个云端托管的分布式深度学习平台，支持 GPU 运算，支持数据并行和模型并行。对于序列输入、稀疏输入和大规模数据的模型训练有着良好的支持，仅需少量代码就能训练深度学习模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是在谷歌宣布开源 TensorFlow 之后，又一科技巨头开源的深度学习平台。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不到一个月，百度再次宣布开源基准工具 DeepBench，可对硬件平台的深度学习性能进行评估，帮助硬件开发人员优化深度学习硬件，从而加快深度学习研究。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW97Eu3kQ28xCXnW6b2iagC06hiaY6xxibqE9fllXc5YlWVML3MwtJr9GhFjEGtBETb1mMr5queCuCPiaQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;语音技术&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「百度大脑已经有好几种不同的人工智能技术，其中比较成熟的就是我们的语音技术。」吴恩达在百度语音开放平台三周年的主题活动上说。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW97Eu3kQ28xCXnW6b2iagC06Gwpq19nK1qqaLcT1jKPV8icR0UlhuhbKyefHqtMON0J0FcWCI4CYgzw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;长久以来，人与机器交谈一直是人机交互领域内的一个梦想。最近几年来，随着深度神经网络的应用，计算机理解自然语音的能力也有了彻底革新。但人机的自然交互，涉及到语音方面的多项技术。在此次主题活动上，吴恩达谈到了百度在语音识别、语音合成、语音输入方面的研究。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「这几年来，我们的团队在不断地优化语音识别系统，在 2012 年开始使用 DNN 模型，后来有比较好的特征，之后开始用 Sequence Discriminative Training，也开始使用 LSTM 模型，加上 CTC，今年我们的团队开发了 Deep CNN 模型，效果在不断进步，这就是我们的语音识别系统。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;百度于 2015 年 11 月发布的 Deep Speech 2 已经能够达到 97% 的准确率，并被麻省理工科技评论评为 2016 年十大技术突破之一。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;语音识别的记录不断在被刷新，今年微软在英语语识别上准确率的突破也几乎媲美人类。但是，使用计算机生成语音——这个过程通常被称为语音合成（speech synthesis）或文本转语音（TTS）——仍在很大程度上基于所谓的拼接 TTS（concatenative TTS），其中有一个由单个人录制的大量短语音片段构成的非常大的数据库，然后再将这些短语音组合起来构成完整的话语。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今年 9 月份的时候，谷歌 DeepMind 爆出在语音合成上的突破性研究——WaveNet，将机器语音合成的表现与人类之间水平的差距至少缩减了 50%。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们的语音合成模型也变得越来越好。这几年来我们在好几个技术方面有比较大的突破，语音合成效果变得越来越好。现在百度在中国语音合成的能力达到业界领先的水平。」据百度讲，百度情感合成技术主要聚焦在为合成语音「加入情感」，目前可达到接近真人发声效果。它们在今年早些时候曾利用此技术，复原已逝明星张国荣的声音。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2016 年，我们也看到了深度学习在图像（识别准确率、风格迁移）、自然语言处理、机器翻译（谷歌神经机器翻译系统）等其他领域取得的最新进展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;比如在自然语言处理任务上，序列到序列模型的注意实现了很大的进展。在后续的专访中，吴恩达表达了自己的看法，「从研究者的角度来看，未来几年有非常多有可能带来突破的思想，它们有可能能够以全新的方式创造出更好的自然语言处理系统。比如说，在词嵌入（word embedding）上，我们可以看到仍有很大的进展。在跨模型学习上，也有一些研究成果。当你同时学习计算机视觉和自然语言处理的时候，那是非常激动人心的。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在研究上，吴恩达认为迁移学习和多任务学习是很好的研究方向。他拿百度的 NLP 团队在 2015 年研究举例说，「如果同时学习多个语言对之间的翻译，效果会比同时学习一个语言对的效果好。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当时，谷歌的神经机器翻译的出现引起了业内的极大关注。但在机器之心之前对百度 NLP 团队的专访中，我们了解到百度的在线翻译系统一年前就应用了基于神经网络的翻译方法。去年百度在 ACL 会议上发表论文《Multi-Task Learning for Multiple Language Translation》，探讨用 NMT 技术解决多语言翻译及语料稀疏的问题，这也就是吴恩达上面所说的多任务学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;说到谷歌的神经机器翻译，我们依此为例向吴恩达追问技术到产品的部署问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;吴恩达回应说，「中国、美国和其它地方的公司在实现先进人工智能的产品部署上都动作很快。但很多人并不知道很多部署实际上是中国的公司最先开始的，虽然不是全部，但也不少。就拿使用神经网络来为机器翻译进行序列学习的特定例子来说吧。实际上，百度比谷歌更早搞明白如何开发和部署它。除此之外，我们还能找到很多首先在中国被开发出来或产品化的技术。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他还提到，「中国科技行业的发展速度是激动人心的。然而现在却有一个令人吃惊的事实摆在我们面前：很多东西是最先在中国实现的，可能一年之后才传入美国，但人们首先想到的还是美国的例子，而不是中国的。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;也许这是对中国人工智能研究实力的一次很好回应。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今年 10 月份的时候，白宫发布的《国家人工智能研究与发展策略规划》报告中称中国的人工智能研究已经走在了美国前面。在提及「深度学习」或「深度神经网络」的期刊论文数量上，中国在 2013 年就超越了美国。而且有媒体称，中国的相关论文不仅数量上远超其他国家，质量上的表现也毫不逊色。这一消息受到了业内许多人士的质疑，认为数量不谈，质量上肯定还有很大差距。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;众说纷纭，难以有一基准评出高低。但高盛近期的一份调查报告认为，人工智能前沿的参与者可能会继续来自美国和中国。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;人工智能之路&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1976 年初生，吴恩达今年刚好 40 岁，不惑之年。他与 Geoffrey Hinton、Yoshua Bengio、Yann LeCun 合称为深度学习「四大天王」，但有人曾质疑吴的人气为何这么高？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 VB 较早的一篇专访中是这样评论吴恩达的，「Bengio 在训练神经网络上取得很大进展，LeCun 开发了卷积神经网络，Hinton 普及了受限玻尔兹曼机。而吴采用最好的，并进行部署与改进。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谈起吴恩达，我们会想到他做过哪些事？取得过哪些成就？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;吴恩达出生于伦敦，父亲是一位香港医生。吴恩达年轻时候是在香港和新加坡度过的，父亲对人工智能在医疗领域的应用的兴趣影响到了他。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他告诉我们，「当时我还在新加坡，我的父亲是一位医生，他对人工智能在医疗领域的应用很感兴趣。所以当时我就很幸运地有些人工智能方面的书。我很小就开始学习人工智能，确切地说，是我 12 岁的时候。我 16 岁时，很幸运地进入新加坡国立大学做实习。在那里，我开始研究神经网络，甚至和教授一起写了一篇小的研究论文。那篇论文今天看来不怎么样，所以我也就不推荐你们读了。不过打那时起，我就对神经网络以及它们从数据中学习的能力，非常着迷。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;21 岁时，吴恩达获得了卡内基梅隆大学的计算机科学学士学位。之后他在 1998 年获得了麻省理工学院的硕士学位，并于 2002 年获得了加州大学伯克利分校的博士学位，导师是 Michael I. Jordan。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在拿到博士学位后，吴恩达开始了在斯坦福大学的工作。后来，他成为了斯坦福大学计算机科学系和电子工程系副教授，人工智能实验室主任。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2010 年，时任斯坦福大学教授的吴恩达加入谷歌开发团队 X Lab，作为顾问。他是较早从学界加入产业界的研究人员之一。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从 2010 年到今年，随着人工智能、深度学习的兴起，越来越多优秀的学术界人才被企业所拉拢——Geoffrey Hinton、Russ Salakhutdinov、李飞飞。这一现象的加剧引起了业内的一阵恐慌，害怕优秀学者的流失会影响人工智能人才的造血。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谈到这一现象吴恩达观察到了不一样的角度，他认为近期的另一个变化就是公司也在创造人工智能人才，可能创造人才的规模要比学校更大：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「因为极大的缺乏人才，所以百度这样的公司的招聘部门都投入很大。这也是为什么百度里有无数关于深度学习、计算机视觉、自然语言处理、语音识别的课程，我们会常规性的训练职员，从而让他们更有所长。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;事实上，百度硅谷办公室已经有了这样的荣誉：硅谷学习人工智能的地方。所以，我认为除了大学之外公司成为创造更多人工智能人才的地方来帮助我们做激动人心的工作，这是一个非常有前景的发展，这就是我们所面临的。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;教学课程，是吴恩达的另一荣誉。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2008 年，吴恩达发起了「Stanford Engineering Everywhere」（SEE）项目，把斯坦福的许多课程放到网上，供免费学习。他自己也教了一些课程，如机器学习课程，包含了他录制的视频讲座和斯坦福 CS299 课程的学生材料。2011 年 8 月时，Coursera 作为一家公益创业公司正式成立，并逐渐成为了世界上最大的 MOOC 平台之一。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;同样是 2011 年，吴恩达与 Jeff Dean、Greg Corrado 联合创立了谷歌大脑。当时，吴恩达向谷歌 Jeff Dean 提及了自己在 X 内部实验的项目 Project Marvin，然后他们用自己的空余时间催生出了谷歌大脑（后来拉来了有神经科学背景的 Greg Corrado）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在谷歌大脑期间，最出名的案例就是他们所开发的人工神经网络通过观看 YouTube 视频，自主学会识别哪些是关于猫的视频。这个案例为人工智能领域翻开崭新一页。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从2002年博士毕业任教到现在成为百度首席科学家，吴恩达 14 年中在谷歌、斯坦福、百度都带领、扶持过一些成功的人工智能团队。基于这些经验，他近期曾在哈佛商业评论上撰文呼吁大部分有数据但缺乏深度人工智能知识的公司来&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720432&amp;amp;idx=2&amp;amp;sn=83ae4ce687079fe40c273abad7a34603&amp;amp;chksm=871b0cceb06c85d8d48047e61a3782dbea3e926a4282e50986cb2fb3014e4dc23cb7ec031d0c&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720432&amp;amp;idx=2&amp;amp;sn=83ae4ce687079fe40c273abad7a34603&amp;amp;chksm=871b0cceb06c85d8d48047e61a3782dbea3e926a4282e50986cb2fb3014e4dc23cb7ec031d0c&amp;amp;scene=21#wechat_redirect"&gt;设立首席人工智能官&lt;/a&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他对我们解释说，「我们都知道人工智能意味着什么，在目前的发展环境下，公司需要重新考虑自身业务如何与新技术相结合以获得竞争优势。越来越多的公司雇佣了熟悉人工智能的高管，我认为这很快就会形成一个特定的职位。我认为有专人来从事这一工作会使公司的运转效率更高，这个人需要拥有足够的技术知识，对人工智能的发展有独到的见解。所以首席人工智能官需要通晓人工智能的运行方式，而不仅仅是具有技术知识，它需要有开阔的眼界，明白如何将技术用于促进商业发展，为公司带来效益。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心原创文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 18 Dec 2016 10:36:44 +0800</pubDate>
    </item>
  </channel>
</rss>
