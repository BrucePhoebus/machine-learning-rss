<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>PyTorch和TensorFlow到底哪个更好？看看一线开发者怎么说</title>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650723769&amp;idx=1&amp;sn=17565e650771699ceddabb214d485626&amp;chksm=871b11c7b06c98d1c76623f7c90120e363cc43462b74f22c27038e324c2975ec4d0db5b483c1&amp;scene=0#rd</link>
      <description>
&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自Reddit&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：王宇欣、Jane W、侯韵楚、李泽南&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Theano、TensorFlow、Torch、MXNet 再到近日比较热门的 PyTorch 等等，深度学习框架之间的比较一直以来都是非常受人关注的热点话题。机器之心也曾发表过多篇相关的介绍和对比文章，如&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719118&amp;amp;idx=2&amp;amp;sn=fad8b7cad70cc6a227f88ae07a89db66&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719118&amp;amp;idx=2&amp;amp;sn=fad8b7cad70cc6a227f88ae07a89db66&amp;amp;scene=21#wechat_redirect" target="_blank"&gt;《主流深度学习框架对比：看你最适合哪一款？》&lt;/a&gt;、&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718160&amp;amp;idx=3&amp;amp;sn=a2114e3324f28740d2603da26fbbdfb4&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718160&amp;amp;idx=3&amp;amp;sn=a2114e3324f28740d2603da26fbbdfb4&amp;amp;scene=21#wechat_redirect" target="_blank"&gt;《五大主流深度学习框架比较分析：MXNET 是最好选择》&lt;/a&gt;、&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721938&amp;amp;idx=1&amp;amp;sn=a7568453296f8b34f1bbb6287cb994d0&amp;amp;chksm=871b0aecb06c83fad3b111c2f48206b26c85762e2b9834a07dddd7a282b60a5df2f78c104de5&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721938&amp;amp;idx=1&amp;amp;sn=a7568453296f8b34f1bbb6287cb994d0&amp;amp;chksm=871b0aecb06c83fad3b111c2f48206b26c85762e2b9834a07dddd7a282b60a5df2f78c104de5&amp;amp;scene=21#wechat_redirect" target="_blank"&gt;《对比深度学习十大框架：TensorFlow 最流行但并不是最好》&lt;/a&gt;和&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650723269&amp;amp;idx=1&amp;amp;sn=959bfccb95502778aadeb1c906044b0d&amp;amp;chksm=871b17bbb06c9ead069be0bca912814ae8b1c10533f90f64cfd46b70a68c89c3df6492139dfc&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650723269&amp;amp;idx=1&amp;amp;sn=959bfccb95502778aadeb1c906044b0d&amp;amp;chksm=871b17bbb06c9ead069be0bca912814ae8b1c10533f90f64cfd46b70a68c89c3df6492139dfc&amp;amp;scene=21#wechat_redirect" target="_blank"&gt;《从 TensorFlow 到 Theano：横向对比七大深度学习框架》&lt;/a&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不过你知道用户实际用起来的感觉怎么样吗？近日，Reddit 用户 cjmcmurtrie 发了一个主题为「PyTorch vs. TensorFlow」的讨论帖，想要了解这两大流行的框架之间各自有什么优势。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;原帖地址：https://redd.it/5w3q74&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;帖子一楼写道：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;我还没有从 Torch7 迁移到 TensorFlow。我玩过 TensorFlow，但我发现 Torch7 更加直观（也许是我玩得不够？）。我也尝试了一点 PyTorch，所以我决定先看看效果。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;使用了几周 PyTorch 之后，我认为我现在还不必迁移到 TensorFlow，至少在我感兴趣的项目上还不需要。用 PyTorch 写自定义模块真是简单至极。而且其动态图构建（dynamic graph construction）给我之前需要熬夜实现（或等待列表上）的东西带来了很多新想法。我认为对机器学习开发者来说，PyTorch 是一个了不起的工具集。我也知道 TensorFlow 的社区资源要强大得多，但如果要开发全新的项目（而不是为已有的架构重新写代码或阅读教程），社区也不一定能有很大的帮助。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个 Reddit 帖子发出后得到了很多机器学习研究者和开发者的关注，他们纷纷跟贴谈论自己的想法和经验（不只是关于 PyTorch 和 TensorFlow，讨论中还涉及到更多工具）。机器之心在这里选择其中一些我们认为有价值的评论，希望能够给你的学习和研究带来帮助。以下按赞成数量排序。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;ajmooch的回复：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我一直在做一个 TensorFlow 的项目，所以我可以公正地在 Theano+Lasagne, PyTorch 和 Tensorflow 三者之间做一个比较。但对于前两者，我可以给出一些漫漫的看法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;背景：大概在一年前我开始接触 Theano+Lasagne，并在我的两篇论文中使用了它。我上周改换到 PyTorch，并重新建了两个我以前用 Theano 实现的关键项目。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;API：Theano 的图形构建和编译工作方式让我学习起来很费劲，但一旦我找到了它的窍门，一切都迎刃而解（这也许会花费两个月，但是我仍旧在学习 Python 和基本的神经网络方面的东西，所以对这一速度的参考价值持保留态度）。Lasagne 的 API，对我来说，就像是优雅的凯瑟琳女皇骑着逆戟鲸展开了战斗，也就是说我爱死它了。如果我提前知道我有多想要一个 Theano 的程式库去工作，我一定会写一个程式库，这大大地减轻了繁重的劳动。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;PyTorch 的 API，另一方面来说感觉有些粗糙，但对它有一些限定词，这个稍后再谈。如果你只是做一些标准的任务（实现 ResNet 或者 VGG）我认为你不会有问题，但我一直都有一些分歧因为我所做的一切都有些奇怪。举个例子，在我当前的项目中，因为 strided 张量索引（tensor indexing）还未实现，我必须使用几个 hacky 解决方法，虽然当前的索引技术非常灵活，比起直接使用 numpy 风格的索引，它们少了很多直观性。中心的限定条件是，它们确实只是释放 friggin 的框架，当然并不是一切都实现，还有一些待解决的问题。Theano 发展时间长且已经成熟，我并没有观察到它或者 Lasagne 在这个过程中遇到过困难。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除此之外，对于 PyTorch 我最大的「抱怨」基本上是在神经网络 API 方面「事情并未按照我让他们组合的方式进行放置」。具体来说，我非常喜欢 Lasagne 的「层次（layers）」范式&amp;mdash;但是一点点批判性的思维就会让你得出这个结论，这个范式尤其不适合动态图框架。我完全习惯于考虑并且优化我关于静态图形定义的思考过程，所以转换 API 方法是一个小的痛点。这非常重要-我花了很长时间思考「好吧，既然我不能使用自己的标准流控制写出一个常规的程序一样，写出这个图的 Theano，那么我该如何定义它呢，」这让我在思维的道路上变得越来越强大。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而，动态图需要一个与「定义+运行」基本不同的 API，虽然我个人认为它并不直观，就在上周其单独执行定义的方法，正如 CJ 所说，打开了我的思路并给了我几十个项目的想法，这在以前是不可能的。我还想象，如果你在任何你想的地方使用 RNNs 做任何事情，比如，在没有消耗计算的前提下实现动态计算，接口的命令性质将会使它更容易这样做。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;速度：所以我没有做广泛的基准测试，但是我惊讶的发现，PyTorch 是可以立即使用的，在我当前的项目的单 GPU 的训练时间比 theano+lasagne 快 100%。我已经在 Geforce gtx 980 和 Titan X 上测试了它，并实现了已经确认相同且在合理的误差范围内的网络。100% 逐字地在 CIFAR100 上从（在最简单的情况下）5 分/历元到 2.5 分/历元，并且在某些情况下降到 2 分钟/历元（即，快两倍）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是相同的模板代码，使用了相同的数据提取程序（我不得不讽刺地说「fetcher」没有思考「去死吧，FETCHER（DIE, FETCHER!）」），除了实际的代码，训练和运行网络，一切都相同。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这让我感到惊讶，因为我的印象是，Theano 的广泛和积极的内存优化（在这种情况下，当你开始训练，只需花费几分钟进行编译）意味着它在单 GPU 下的速度非常快。我不知道什么导致了速度的提升，或者，因为他们同样都使用了 cuDNN 的最新版本（我仔细地检查了一遍以确保的确是这样），所以这一切的收获一定在天空的某一个地方，但我并不知道会在哪里。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相关地，使用 Theano 工作时，我从来没有能够得到多 GPU 或者半精度浮点数。我花了好几天的时间试图让 libgpuarray 工作，并使用 platoon 试图进行修复，但每次我都会精疲力尽（想象一下即使我可以得到编译的资源也不会如此困难，这已经是一个痛点了）。然而，立即使用的 PyTorch 的数据并行性（单节点，4 GPU）和半精度（用于卷积的 pseudo-FP16，这意味它不会变快但是会使用更少的内存）问题就解决了。当时就是这样。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;开发团队交互：我与两个框架的核心开发团队一直交流的非常愉快。对于 Lasagne 和 Theano，我遇到了一些困难，很多奇怪的问题。很多次，他们总是快速且简洁地帮我弄清楚什么错了（我通常不明白）。PyTorch 团队同样有帮助&amp;mdash;我一直在提出我遇到的错误或问题，并得到及时的反映，通常会在当天修复，或者得到解决方法或得到问题跟踪。我并没有在 Keras 或者 Tensorflow 上工作，但是我看过他们的「问题」日志和一些用户组，只是因为大量的用户，这些框架看起来并不会得到这种个人的关注 - 就像是我去 Cal Poly（加州理工州立大学）一样，在这个地方，教授/学生的比例很高，你很少看到一个班中有超过 20 个学生，然而在 Berkeley 你能看到 1000 人的演讲厅。这并非批评 Cal 的孩子或者暗示 berkeley 盲目扩招，但如果你是一个像我一样开发非标准神经网络的人（我并不是在说 Chuck Tingle weird），然而从一个实际构建框架的人那里得到快速的反馈，这是非常宝贵的能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Misc：我担心一个特别的问题（为什么我打算几年拾起 TensorFlow 并将它作为主要框架），Theano 和 PyTorch 都没有为部署设计，开发团队它看上去并没有把重心放在 PyTorch 上（虽然在这方面，我可能看错了，我模糊的记得我在论坛的帖子上看到过这个）。我想要练习将一些东西放置在网站或者 droid app 上（主要是为了娱乐，但我一直都非常专注于研究并认为这是一个真正有用的技能，可以实际获得我在设备上所做的东西），我不确定其他的框架能很好地支持这种方式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相关地，PyTorch 的分布式框架仍然是实验性的，最近我听说 TensorFlow 在设计时就考虑到了分布式，所以如果你需要运行真正的大规模项目，TensorFlow 多半是最好的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;TL；DR：我并不是试图推荐哪个框架比较好；我至死都爱 Lasagne（可能更多），但我已经发现动态图的灵活性和其快速地、难以理解的增益的速度。我在上个星期安装了 PyTorch 并且只用了非常少的时间就上手了，我想我不太可能回头了。我并不是很了解 TensorFlow。但能从 PyTorch 开发者那里得到及时反馈对我来说是很重要的一点，因为我正在做一些看来有点奇怪的研究，但在未来我也可能为一些项目重新使用 TensorFlow。这个讨论帖非常棒，但我希望在你阅读过后的印象是：这是他们的主观经验，而不是一个刻板的印象如：「就是这样，你绝对会感到同样的方式」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;taion的回复：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们最近从 Theano+Lasagne 转到了 TensorFlow。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我还没有尝试过任何分布式的架构，但总体上用过 Theano 之后再用 TensorFlow 感觉非常熟悉&amp;mdash;&amp;mdash;甚至更好。对你提到的几点，回复如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;等效的图形编译（graph compilation）要快得多；我们用了几秒而不是几分钟。但是它仍然不够快，如果我们想要将它的大部分添加到我们的 CI 套件（CI suite），但我们不需要等待很长时间来开始训练。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从 Lasagne 转到 TensorFlow 之后，我喜欢 tf.layers 和 tf.contrib.layers 中更高层次的功能；它们为接受张量（tensor）并返回张量的功能性 API，因此更容易与「原始」的 TensorFlow 集成。我们可以做普通的张量操作，而不用写一个层那么麻烦。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在我们使用的模型上，TensorFlow 的速度稍稍快于 Theano（20％-30％）。当第一次使用时，我们看到大致相同的性能，并认为这可以接受，但然后我们阅读 TensorFlow 的性能指南（https://www.tensorflow.org/performance/performance_guide），并切换到 NCHW 并融入批处理规范（batch norm），然后一切运行得更快了。我猜 Theano 本身就不是很快&amp;hellip;&amp;hellip;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关于开发人员的反馈速度：我曾在 TF 的问题区提出了一些微不足道的问题，但 TF 开发人员通常在一两天内就回复我了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此外，工具是相当好的。TensorBoard 绝对好用，用来表示的时间线（timeline）/跟踪（trace）的工具也一样好用。但是我还没有尝试新加入的 tfdbg。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;TensorFlow 当然也有几个缺点，例如在实践中部署到 iOS，但这说来话长。使用 TensorFlow 不是没有痛苦，但与需要 Python runtime 的 Theano 相比，这还算什么事情吗？这是相当大的进步。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你使用 TensorFlow，我强烈建议你看看 tf.layers 或 TF-Slim。具体的说，tf.layers 本质上嵌入了 Keras API。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管我不指望任何有意义的性能差异；本帖讨论的操作最终定义了一个静态计算图形（computation graph），所以使用像 Keras 这样的包装器本身并不增加资源消耗，除了在图形定义时最小的资源占用，但是如果你原来使用 Theano，你会感到 TensorFlow 的启动时间快得多（以秒计而不是以分钟计的编译速度）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;遵循 TensorFlow 性能指南（TensorFlow performance guide）非常有用。在 DenseNet（L = 40，k = 12）模型上，从默认的 NHWC 和未融入批处理规范切换到 NCHW 和融入批处理规范后，我们的每个 epoch 时间都下降了超过 30％。在 WRN-16-4 模型上，我们看到 epoch 时间下降了超过 20％。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;badmephisto的回复：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我认为在深度神经网络库的设计方面，PyTorch 目前已然接近启发的高度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;它属于轻量级；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;它目前位于 Python 中；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;它使你能够明确地控制计算。没有编译器能自己妄图变聪明来「帮助你」，或是将你的代码加速；事实上大多编译器在调试中会产生大量麻烦；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;它使 GPU 内核调用之上仅有少量（可解释的）抽象层，而这恰恰是高性能的保证；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;也许这是个人偏好，但我得到了与抽象有关的特定 OCD。每当我要做艰巨的工作时都会很紧张，因为一旦我的未来被泄漏，我便能感觉到它那些无法摆脱且难以忍受的痛苦。相对简单的事情理应在引擎盖之下发生的大多数情况下，这种感觉尤为强烈；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;调试更容易，因为特定代码中会是特定行（而不是在距离使用大型或生成的 Graph 对象的 sess.run（）很远的地方）失败。你的堆栈跟踪不会填满三个屏幕来让你玩「找找错误在哪里！」的竖版卷轴游戏；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;不存在编译时间。我无法理解 Theano 用户是如何处理的，他们一定更有耐心；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;你可以直接操作渐变，显然，做一些事情时可以更容易，也更自然（如在反向传播过程中的渐变剪辑，或各种「破碎的反向传播」的有关想法，就像最近的 Shake Shake reg 命令一样；的确，我认为你可以用 stop_gradient 破解一个解决方案）；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;它对动态图的支持从一开始就是自上而下的设计原则，而非随之而至的事后想法。并且我们会看到更多的动态图表，如做成一大块 NLP，或是神经模块网 ；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;它没有缩进或膨胀你的代码的显式会话对象；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;它获得的抽象是正确的：raw numpy - &amp;gt; Tensors（但 GPU 上的 raw numpy 可能对深度学习一无所知！）- &amp;gt;变量（它们了解深度学习），并且 Modules 或 Optim 等等会稍有益处。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;到目前为止，我与 TF 的有关经验有些膨胀，所以即便是像数据驱动初始化这样理应很简单的事情，也会用到一些 tricks。当然，TF 的开发者有他们的一套解决方案，但往往涉及你从未听说过的 5 个 TensorFlow 函数的组合。我不记得曾用 Torch 做过这些，又或许我现在做的事情更复杂。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;免责声明：我仍行进于对 PyTorch 进行尝试的漫漫征途中；所以我的经验是基于在 TensorFlow 做了很多复杂事情，而在 PyTorch 上才刚刚开始的背景上得到的。让我们看看未来会发生什么。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;jeremyhoward的回复：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于 http://course.fast.ai 的第 2 部分，我们从 keras + theano（第 1 部分）切换到 Keras、TensorFlow 和 PyTorch 合用的状态。一般而言，使用 PyTorch 总是令人愉快的，主要是因为：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;动态计算使很多事情更加容易，如 seq2seq + attention 的神经翻译很难通过 keras + tf 来实现，但使用 PyTorch 便会很容易；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;更容易调试，因为你可以只使用标准的 PyThon 工具；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;PyTorch 让自定义的实现更加容易，所以你得以将更多时间专注于算法中，这样往往能够改进主要性能；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;使 Multi-gpu 简单易懂；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Torch-vision 使加载和变换图像变得容易。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;TensorFlow 的 API 非常荒谬，它在每个阶段都会重新发明轮子，并且要求开发者学习很多本不必要的新概念。然而，开发者峰会表示这一境况正在改善&amp;mdash;&amp;mdash;而且同时使用 TensorFlow Servin 和 Cloud ML 会提高你的生产力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;Powlerbare的回复：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我大约在半年前使用 TensorFlow 实现了一些 seq2seq 模型，并意识到为何 TensorFlow 很好用：它的内置组件很棒，让研究变得就像有老师在推动着你一样容易，而注意与损失函数就如同噪声对比估测，等等。倘若我收集基线或修改函数，一切都会变容易。我已经习惯于搜索代码库，并确定究竟哪种函数在运作（如果不小心，某些可选的函数默认值便会得到不好的结果）&amp;mdash;&amp;mdash;并且我对基于这些实现的大部分报告结果非常有信心。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面是几点与我所爱的 PyTorch 有关，而 TensorFlow 却不会提供的事项：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1）PyTorch 提供了一个强化功能，我很喜欢它。增强功能基本上不会在实现中产生过多资源消耗，能有一些内置函数来调用 RL 的感觉真棒。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2）我并未大量使用 autograd，因为那时它速度很慢，但人们感觉用它来做一些没谱的事情很有趣。我是这个范例的死忠粉，因为我没来由地钟爱在 numpy 上编写网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;span&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Wed, 01 Mar 2017 13:47:20 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 英伟达正式发布GeForce GTX 1080Ti：性能提升35%</title>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650723769&amp;idx=2&amp;sn=75829f24b6c78ae2a80d9399fe2fbd25&amp;chksm=871b11c7b06c98d1d231ae02b6a5edc81cd28c1d0bf363ff172f00980c4a4d41ce99a8fb0673&amp;scene=0#rd</link>
      <description>
&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;机器之心报道&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;编辑：李泽南、李亚洲、黄小天&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;今天，英伟达正式发布了 GeForce GTX 1080TI 显卡，其 Pascal 架构产品线又增添了一个新成员。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/48c40b01022fc34c32f2af9bab31db27d283495a"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在发布会上，英伟达 CEO 黄仁勋激动之情溢于言表：「今天，我们发布的这块显卡非常、非常重要。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 AMD 刚刚发布 RyZen 架构 CPU，真正击败了英特尔 Core i7，并计划在今年上半年推出 Vega 架构新显卡的时间段上，英伟达正面临着空前的压力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本次发布的 GeForce GTX 1080 Ti 拥有 120 亿个晶体管，3584 个 CUDA（统一计算设备架构）核心，这让它步入目前英伟达最强显卡之列。同时在发布会上，英伟达宣称这一高性能 GPU 可以从 1.6GHz 超频至 2GHz，这意味着它的频率超过了目前的 Titan X 的速度（未超频1.5GHz）。英伟达宣称 GTX 1080 Ti 的性能相对普通 GTX 1080 的提升为 35%，这使得它成为了史上性能提升最大的「Ti 标志」显卡。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/23c5b581acaaab3ab2359038c204f935306844d9"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;GeForce GTX 1080 Ti 采用了一个带有 7 阶双场效应晶体管和 14 dual-FETs 架构的全新供电设计。结合蒸汽室和双倍的冷却面积，该显卡在全速运行时的温度相比 GTX 1080 要低 5 摄氏度，安静 2.5 倍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/00f728777cee10e9e5be8762920321c1984235ab"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;正如之前英伟达对于新 GPU 处理方式, 微星、华硕及其他厂商将通过供应商模式首先推出 GTX 1080 Ti Founders Edition。英伟达 GTX 1080 Ti 将在下周以 699 美元的价格正式发售。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该显卡具有 GDDR5X 11GB/s 内存，将从 3 月 10 号开始面向全球发售，售价为 699 美元。同时，在发布会上英伟达宣布将 GTX 1080 公版的价格从 599 美元降至 499 美元。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;英伟达表示并不会停止对于旧型号的技术升级，并宣布会在未来发布配备 11Gbps G5X 内存的 GeForce GTX 1080 和带有 VRAM 的 GeForce GTX 1060 的超频版本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;英伟达今天也宣布了 GameWorks DX12，这是面向游戏开发者的资源集，能够在使用 DirectX12 进行设计中增加现实感、减少产品开发周期。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/3d9494c2e2e15b2c3db143297fb4c9be30d0839b"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;参考资料：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;http://venturebeat.com/2017/02/28/nvidia-unveils-new-geforce-gtx-1080-ti-graphics-chip/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;http://www.techradar.com/news/the-nvidia-gtx-1080-ti-turns-the-dial-to-11：&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&amp;copy;本文为机器之心报道，&lt;strong&gt;&lt;span&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Wed, 01 Mar 2017 13:47:20 +0800</pubDate>
    </item>
    <item>
      <title>深度 | 人工智能将如何改变公司组织形式？这份最新德勤报告能告诉你答案（附144页报告下载）</title>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650723769&amp;idx=3&amp;sn=0c69962999575349a5b2ef9d6b2378a7&amp;chksm=871b11c7b06c98d1333d4e8200ca89473e6daba8128ba50b3570c86d8c9aa482a7a70ec3fec9&amp;scene=0#rd</link>
      <description>
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自Deloitte、Fast Company&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：微胖、曹瑞&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;人工智能对公司企业的渗透，才刚刚开始，但是，这已经引发企业领导人反思企业的运行方式。德勤近期发布了 2017 年全球人力资源趋势报告（2017 Global Human Capital Trends）对人工智能技术给全球企业人力管理带来的影响进行了深刻分析，以下是对这份长达 144 页报告的简单导读。点击文末「阅读原文」，下载报告全文 PDF。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽说人工智能仍在婴儿期，但是，已经迫使全世界的领导者们重新思考企业的核心框架。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/da817a6ab9b94c2a3445103c2cff0a5b7419990b"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;技术的进步正在让公司重构组织形式，变革人力资源部门，开发新的训练模型，重新评估他们的招聘工作。2017 年德勤人力资源趋势报告（2017 Global Human Capital Trends）对 140 个国家 1 万多名人力资源以及业务负责人进行了调查。调查发现，很这些变化中的很大一部分，都是集簇人工智能软件早期入侵导致的，这也是为组织成熟后会出现的需求做好准备。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/57bbf7acb19c0215151d432cf64cd0e3db2af4ba"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们的结论是，人工智能肯定不是在消除工作岗位，而是消除工作中的苦差事（tasks of jobs）, 并创造新的工作，而且这些新的工作更多的是依赖人类特点的岗位，」Bersin 的创始人 Josh Bersin 说。他所谓的「更多依赖人类特点的岗位」，是指依赖机器尚不具备的人类特点的工作，比如，同情心，交流以及跨界解决问题。他补充说，「更多的是从事苦差事岗位上的员工不得不接受再培训，或者转移到新的岗位。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/cbeb0d6853e16e6d23158b9cd2ff920fe7f833e7"/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/5c94e5787dba05f160111e14ee742a357dad4a26"/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/455d30876d437533d56c5227cdd48f431962d9de"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;调查发现，41% 的受访者在全体员工中，完全采用了人工智能技术，或者在采纳这一技术上取得了显著进展。但是，只有 15% 管理人员认为，他们准备好了管理一支人类、机器人以及人工智能并肩作战的员工队伍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/f2c25877afb4bd20aa3f366a93b29ab50a701c07"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此，早期人工智能技术以及正在迫近的人工智能革命正在迫使组织重新评估大量既有战略。许多公司没有雇佣最适合某个特定差事的人，如今，他们更强调文化契合和适应性，因为他们知道个体角色将必然随着人工智能的采用而与时俱进。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随着不断采纳新的技术，为了将人类转移到新的岗位上，在岗培训就变得特别重要了，而且人力资源的功能也在迅速转变，过去是评估和招募&amp;mdash;&amp;mdash;如今，有了大数据和人工智能软件，这些工作处理起来会更加高效&amp;mdash;&amp;mdash;现在，人力资源更关注的是改善员工在一个越来越多变的团队中的工作体验。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;德勤调查还发现，56% 的受访者已经重新设计的人力资源项目，目的在于充分利用数字化和移动工具，而且 33% 的受访者正在利用一些人工智能技术实现人力资源功能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/12bb015ad349e22c50eea288dad42eb069ed6cb2"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;融入早期人工智能工具，让组织变得更加有合作精神，更以团队为导向，这与传统自上而下的等级结构截然不同。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数字簿记（bookkeeping）服务提供商 Bench 的联合创始人兼 CEO Ian Crosby 说，「想要融入人工智能，你必须要有一个专业的产品人员和工程师内部团队，这些人能够明白要将人工智能运用到哪里，并且还能和提供服务的前线团队紧密合作。」「当我们将人工智能应用到我们的第一线服务中时，我们并没有甩手掌柜，然后一年后就有了好成绩。我们每天与第一线保管员一起工作。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了能够合理地适应不断变化的科技，组织正在脱离自上而下的结构，并且向跨学科的团队发展。事实上，32% 的调查对象都表示，他们正在重新设计组织形式，让其更加团队取向化，为迎接技术变革而优化组织的适应性和学习能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而，找到一个平衡的团队结构并不是一蹴而就的，Crosby 解释说。「通常情况下，如果有一个大型组织，那么最好从一个小团队开始，让小团队自然演进并不断扩大规模，而不要一开始就试着引入整个公司。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Crosby 补充说，Bench 想要融入新科技的迫切希望，也影响到公司对人才所应具备技能的要求。除了检查是不是符合工作的技术性要求之外，公司还在寻找那些已经准备好适应即将到来的变革的人才。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「当你和人工智能在一起工作的时候，你正在创造从未有过的事物，也没有人知道你创建的东西会是什么样的。」他说，「如果他们对完全错误不能保持开放态度，并且谦虚地说他们错了。那我们就会重新评估他们。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随着人工智能变得越来越复杂，领导最终需要决定将人类雇员安置到什么地方，什么样的任务是最适合机器来做的，什么样的任务交给两者最高效。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在线聊天软件提供商 LivePerson 的全球研究与沟通负责人 Rurik Bradbury 说：「距离我们拥有真正的人工智能还需要几年的时间，可这已经越来越近了，但是，人工智能在理解人类意图的方面还是存在着很大的问题。」随着越来越多的人工智能软件变得可用，他建议组织要「考虑三种不同的员工类别&amp;mdash;&amp;mdash;人类、机器或半机器人，然后决定要雇佣谁来做这份工作。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然人工智能科技仍然处在萌芽阶段，但在不久之后，为了保持竞争力，每一个组织都必须在人工智能的浪潮中提出自己的人工智能战略。那些拥有 HR 团队、训练项目、组织化架构以及适应力强的公司能为即将到来的变革做出最充分的准备。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;原文链接：https://www.fastcompany.com/3068492/the-future-of-work/how-ai-is-changing-the-way-companies-are-organized&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;span&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Wed, 01 Mar 2017 13:47:20 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 百度提出 Deep Voice：实时的神经语音合成系统</title>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650723769&amp;idx=4&amp;sn=7098361f7369fe813aed6b2d035394c8&amp;chksm=871b11c7b06c98d11ff77ed0f23ac56ad1c55ae34756b628f215912f7feb815f290207ab13a6&amp;scene=0#rd</link>
      <description>
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自Baidu Research&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李亚洲、蒋思源&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;百度研究部门最近提出了深度语音（Deep Voice）系统，该系统是一个完全由深度神经网络构建的高质量语音转文本系统。读者可点击阅读原文下载此论文。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;百度研究部门最近提出了深度语音（Deep Voice）系统，该系统是一个完全由深度神经网络构建的高质量语音转文本系统。而如今建立这样一个系统最大的障碍就是音频合成的速度，因为以前的方法需要花几分钟到几小时来生成仅仅几秒钟的语音。我们致力于解决该难题，并且已经做到了实时的语音合成，这相比以前的 WaveNet 推理的实现有 400 倍的加速。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从文本合成人工语音，也就是我们所熟知的文本转语音（TTS），在许多的应用中都是非常重要的组件，比如语音设备、导航系统和对视力障碍人群的辅助应用。从基础上，它使得人类在不需要视觉界面的情况下能与科技进行交互。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现代 TTS 系统主要基于复杂的、多阶段处理流程（pipeline)，每个都依赖人工调配的特征参数以及启发式规则。由于这种复杂性，开发新的 TTS 系统需要大量的人力，也非常的困难。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Deep Vioce 受启发于传统的文本转语音处理流程采用了同样的架构，但使用神经网络取代了所有组件且使用了更简单的特征。这使得我们的系统更适用于新数据集、语音和没有任何手动数据注释或其他特征调配的领域。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Deep Voice 为真正的端到端语音合成奠定了基础，这种端到端系统没有复杂的处理流程，也不依赖于人工调配（hand-engineered）的特征作为输入或进行预训练（pre-training）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们目前的流程并不&lt;/span&gt;&lt;span&gt;是端到端的，由音素模型（phoneme model）和语音合成组件所构成。下面的剪辑是通过整个流程由文本合成的语音。这里是一个随机选择的语音（每条微信文章只能添加一个音频，更多音频可点击原文链接查看）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;mpvoice class="res_iframe js_editor_audio audio_iframe" frameborder="0" high_size="9.64" low_size="5.54" name="%E7%99%BE%E5%BA%A61" play_length="3000" source_size="5.5" src="/cgi-bin/readtemplate?t=tmpl/audio_tmpl&amp;amp;name=%E7%99%BE%E5%BA%A61&amp;amp;play_length=00:03" voice_encode_fileid="MzA3MzI4MjgzM18yNjUwNzIzNzY4"&gt;&lt;/mpvoice&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个声音有机械的性质是因为整个流程的结构和音位模型，如果只是语音合成组件的话会生成更自然的语音。以下是仅仅使用语音合成组件的语音剪辑，其使用的特征直接来源于实际的语音而不是音位模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些样本听起来非常接近原始音频，这也表示我们的语音合成系统组件能很有效地生成人类语音。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深度学习变革了包括计算机视觉和语音识别在内的许多领域，我们相信语音合成如今也到了一个跳变点。我们期待看到深度学习社区能想到新的东西，并希望通过分享我们的文本转语音系统能加速此进程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;更多的细节，可查看我们的论文：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;论文：Deep Voice: Real-time Neural Text-to-Speech&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/ae0242a83a593982254f16af57c31a92a08a5d4c"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：&lt;/span&gt;&lt;span&gt;我们提出了一种高质量的、完全构建于深度神经网络的文本转语音系统 Deep Voice，它为真正的端到端神经语音合成奠定了基础。该系统包含 5 个重要基础：定位音素边界的分割模型、字母到音素（grapheme-to-phoneme) 的转换模型、音素时长预测模型、基础频率预测模型、音频合成模型。对分割模型，我们提出了一种使用深度神经网络完成音素边界检测的新方法，它使用了 CTC（connectionist temporal classification）损失函数。对音频合成模型，我们部署了 WaveNet 的变体，它要比原始的 WaveNet 需要更少的参数、训练速度更快。在每个组件上使用神经网络，我们系统要比传统的文本转语音系统更简单、更灵活（传统的组件需要费劲的人工调配以及大量的专业知识）。最后，我们演示了无论是 GPU 还是 CPU 上使用我们的系统进行推理，能够比实时的、说是最好的 WaveNet 推理核函数更快，比已有的实现快了 400 多倍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;原文链接：http://research.baidu.com/deep-voice-production-quality-text-speech-system-constructed-entirely-deep-neural-networks/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;span&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;
</description>
      <pubDate>Wed, 01 Mar 2017 13:47:20 +0800</pubDate>
    </item>
    <item>
      <title>波士顿动力正式发布「汽车人」Handle：具备双足轮动能力</title>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650723729&amp;idx=1&amp;sn=3d01459b5d24a064ee72698a573b740e&amp;chksm=871b11efb06c98f97a1d71b4f072bec414d7e89016b618bea1abd06194bf8bda38b7be7f7e7e&amp;scene=0#rd</link>
      <description>
&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自IEEE Spectrum&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Steve Crowe 等&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：微胖&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;昨天，波士顿动力官方发布了用于研究的机器人 Handle，它结合了轮子的高效与腿部的灵活。在上个月，曾有一个泄露出来的 Handle 机器人测试片段在网上传播，不过，这一次波士顿动力公布了这款机器人的新细节，还有才艺表演视频。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;iframe allowfullscreen="" class="video_iframe" data-vidtype="1" frameborder="0" height="417" src="https://v.qq.com/iframe/preview.html?vid=p0379yfdaoc&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0" width="556"&gt;&lt;/iframe&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「（Handle）约 6.5 英尺高，行进速度为每小时 9 英里，垂直跳跃高度为 4 英尺。电力运行电子和液压驱动器，一次充电的续航能力约为 15 英里。Hand 使用的许多动力学、平衡、移动控制原理，也是我们之前打造四足和双足机器人采用过的，只不过这款机器人只有 10 个驱动关节，很明显，比起之前的机器人，它没那么复杂。轮子可以在水平面上快速滑行，但是机器人可以使用腿部去任何地方，兼具轮子和腿部功能的 Handle 能博采两家之长。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;正如波士顿动力的其他机器人，Handle 目前也没有任何商业打算。目前严格用于研究，看看打造机器人时，将腿部和轮子结合起来主意会有多惊艳。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;波士顿动力的创始人 Marc Raibert 称呼 Handle 是「会让人做噩梦的机器人。」我们表示赞同，特别是如果 Handle 和我们一起在库房工作或者为我们送披萨。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以下是 IEEE Spectrum 对波士顿动力创始人 Marc Raibert 的简短采访：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;IEEE Spectrum：&lt;/span&gt;怎么会想到轮子的？打造这台机器人花了多长时间？&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Raibert：&lt;/span&gt;&lt;span&gt;将轮子和腿结合起来的想法早就有了，不过还没有机会加以研究。去年夏天，我们开始实现这个想法，大概花了六个月的时间。我们加快了项目进程，因为使用了原先为 Atlas 设计的能源、手臂以及上半身的设计。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;IEEE Spectrum：在腿式机器人中，你们成功使用了基于生物学启示的控制策略，可以将这一策略再次（或调整后）用到 Handle 身上吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;Raibert：&lt;/span&gt;Handle 所用到的控制，很多得益于之前四足和双足机器人的经验。不过软件不尽相同，但是，平衡、动力学控制原理都是很多共同之处，物理学根据是一样的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;IEEE Spectrum：&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;Handle 的上半身是不完全的 Atlas，还是一个全新设计？它是全电动的吗？使用了液压技术？&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;Raibert：&lt;/span&gt;是的。它用的是 Atlas 的上半身，手臂根据 Atlas 手臂做了轻微改动。电力（电池）驱动，不过，它有电力和液压驱动。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/271d6307e6f89a6b0caa85767d9d78a6481b2dcd"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;br&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;IEEE Spectrum：&lt;/strong&gt;&lt;/em&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;这么长的时间里，你们一直在研究设计腿式机器人，你和团队对轮子有何感受？&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;Raibert：&lt;/span&gt;轮子是伟大的发明（可参见吴军的《文明之光》里的介绍。&amp;mdash;&amp;mdash;编译者注）。但是，轮子只适合平坦的地面，腿可以抵达任何地方。因此，结合腿和轮子，Handle 就能博采两家之长。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;原文链接：http://spectrum.ieee.org/automaton/robotics/humanoids/boston-dynamics-handle-robot&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;span&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Tue, 28 Feb 2017 12:17:03 +0800</pubDate>
    </item>
    <item>
      <title>第四范式专栏 | 首席科学家杨强教授：人工智能的下一个技术风口与商业风口</title>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650723729&amp;idx=2&amp;sn=b3a77f31cf1767769e8c0f37886d0b13&amp;chksm=871b11efb06c98f99e1c2d557bf467f9bc03a6b457a1ee9691342917899d2e2394da3c2aa8ef&amp;scene=0#rd</link>
      <description>
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;第四范式专栏&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;演讲者：杨强&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote style="color: rgb(62, 62, 62); font-size: 16px; white-space: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;作为华人界首个国际人工智能协会AAAI Fellow、至今为止唯一的AAAI 华人执委，以及IEEE Fellow、AAAS Fellow、IAPR Fellow，杨强教授在专注学术研究的同时，也更关注如何让人工智能技术落地转化为生产力的问题。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;作为第四范式首席科学家、范式大学的导师，杨强教授近日在第四范式公司内部进行了一场主题为&amp;ldquo;人工智能的下一个三年&amp;rdquo;的培训，深入浅出地分享了自己在人工智能产业推广上的经验，并预判了人工智能即将爆发的技术风口与商业风口。此前，杨强教授与第四范式曾提出人工智能的五个必要条件，为人工智能行业提供了权威的准入标准。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以下内容根据杨强教授主题演讲编写，略微有所删减。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;一、AlphaGo为我们带来了什么&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大家记得在2016年3月，AlphaGo横空出世对战李世乭，这对于人工智能的社会影响非常大。这里，我们问一下：AlphaGo到底为我们带来了什么？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在AlphaGo的搜索中，Deepmind团队引入了一个新概念&amp;mdash;&amp;mdash;即用深度学习和强化学习的结合来做两种任务的判别，即来&lt;strong&gt;判别&lt;/strong&gt;现在所在的棋盘是好是坏，同时来&lt;strong&gt;预测&lt;/strong&gt;未来有利的走向。&lt;strong&gt;讲到这里大家应该能看出AlphaGo的算法和未来商业模式的关联，即：通过对大数据的分析，让我们对&amp;ldquo;现在状态&amp;rdquo;有了一个靠谱的理解；&lt;/strong&gt;这个状态可以是棋盘、可以是足球运动中两队交锋的状态，也可以是当前营销的一个状态。同时，下围棋中的一步，可以理解成对未来走向的预判，在商业活动中，这可以是营销活动中的下一步。这里很重要的一点，是区分我们商业行为中的两个任务，即对现实的判断和对商业未来走向的预估。这两个任务同样重要，也同样都需要大数据的支持。 因为围棋是一个封闭式的游戏（即没有外界因素的干扰），为了得到更多的数据，AlphaGo也引入了自我博弈。&lt;strong&gt;所谓自我博弈就是自己玩游戏，你会得到不断的反馈，然后来更新自己的策略&lt;/strong&gt;，经过无数次这样的比赛，最后会得到一个好的策略，你的最终输出是一个行为的策略。所以AlphaGo 也告诉我们，在一个封闭场景中，可以用自我博弈的模拟方法得到更多的数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;从AlphaGo到人工智能的应用流程&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们如果沿着下围棋的步骤走，就要面对这些问题：你的人工智能算法的目标是什么？有没有数据？数据在哪里？问题的边界是否清晰？什么叫合理的走法、什么叫犯规的走法？你的特征在哪里？又如何得到这些特征？是否可以得到一个持续的反馈？这样的一个流程是AlphaGo设计团队所走过的路。不妨把这些步骤记下来，变成一个workflow，看看其他的领域是不是可以重复AlphaGo的成功。 比如，如果用AlphaGo治疗癌症，如何治疗呢？治疗癌症一般是用放射性来杀掉癌细胞，而每一个癌症患者需要的剂量、角度、频次可能都不一样，如果能把所有的这些信息都记录下来，再记录治疗结果，因为结果不是马上就知道的，而是经过一段时间才知道，这样就有了数据、有了特征、有了问题持续的反馈，并且有了非常清楚的目标，即在副作用最小的情况下杀死癌细胞。并且这个workflow是可以重复的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/4e5015ebd19a4725fe1f8928c5a4f828cbd1e23a"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;AI&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;的发展历史还有前30年，这些年的积累也很有用&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;刚刚我们说了AlphaGo的一路历程，&lt;strong&gt;但我们对人工智能的理解不应该片面地认为人工智能就是机器学习。&lt;/strong&gt;人工智能的发展历史还有前30年，前30年是从50年代中一直发展到80年代中。这30年AI是在干什么呢？是在做人工输入的规则型的知识表达研究，以及基于这些规则的符号空间的推理和搜索。我认为，这个人工规则型的知识表达在AI的应用当中也是必不可少的，因为在众多领域当中还会碰到冷启动的问题，以及如何规范一个领域的边界的问题。这就是说，逻辑推理，逻辑知识表达，以及在符号空间的搜索的人工智能这个分支，在今后几年会和统计学习相结合，会大有发展。 这种发展会也涉及技术和商业两个层面。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;二、AI的技术风口在哪？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们大家会关心的一个问题， 是人工智能的技术在哪些方向可能会有大的突破。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;深度学习&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/2247f1c9a460251e3211e0c706153c607b2fae0e"/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;首先，是深度学习会继续发展。这里的发展不仅是在层次的增加，还包括深度学习的可解释性、以及对深度学习所获的的结论的自我因果表达。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;例如，如何把非结构化的数据作为原始数据，训练出一个统计模型，再把这个模型变成某种知识的表达&amp;mdash;&amp;mdash;这是一种表示学习。这种技术对于非结构化数据，尤其对于自然语言里面的知识学习，是很有帮助的。另外，深度学习模型的结构设计是深度学习的一个难点。这些结构在今天都是非常需要由人来设计的。还有一个研究问题是如何让逻辑推理和深度学习一起工作，这样也可以增加深度学习的可解释性。比如，建立一个贝叶斯模型需要有很多的设计者的经验，到现在为止，基本上是由人来设定的。如果我们能从深度学习的学习过程中衍生出一个贝叶斯模型，那么，学习、解释和推理就可以统一起来了。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;迁移学习&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;迁移学习也是我和戴文渊（第四范式创始人、首席执行官）一直在做的工作。给定一个深度学习的网络，比如一个encoder网络和一个decoder网络，我们可以看它学习和迁移的过程，作为新的数据来训练另外一个可解释的模型，也可以作为一个新的迁移学习算法的输出。即一个学生A在观察另外一个学生B学习，A的目的是学习B的学习方法，B就不断地在学新的领域，每换一个领域就为A提供一个新的数据样本，A利用这些新的样本就能学会在领域之间做迁移。所以这种过程叫做观察网络。有了这种一边学习、一边学习学习方法的算法，就可以在机器学习的过程中，学会迁移的方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;自然语言的表示学习与机器阅读&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;表示学习是当数据和任务没有直接相关时也可以学，一个重要的例子叫做self-taught learning，即我们通过很多supervise的数据、图像，可以学出一种最好的表达。用这个表达加上任务，就可以很快地学会这种知识表示。这时非结构化的数据就相当有用了。比如，给出一段话让机器去阅读，机器学习可以自动地发现一些值得关注的点。比如，给定一个文章中的实体和一个未知变量有这样的关系，然后用户可以问你这个未知变量是什么。能够达到这样的效果是因为深度模型已经具有了一种关注（&lt;span&gt;Attention）&lt;/span&gt;，这种关注是可以通过观众的学习来表达。&lt;strong&gt;其结果就好像我们一目了然地看了一本书，我们会把关键词和它们的关系抓取出来&lt;/strong&gt;。这实际上是利用类似人的一种直觉来进行学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;人机对话系统&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;应该说有一个领域已经发展到了临界点，就是人机对话系统领域。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;现在在这个领域，某些相对垂直的方面已经收取了足够多的数据，一个是客服，一个是汽车（车内的人车对话）；还有一种是特定场景的特定任务，像Amazon Echo，你可以跟它讲话，可以说&amp;ldquo;你给我放个歌吧&amp;rdquo;或者&amp;ldquo;你播一下新闻&amp;rdquo;，Amazon Echo里面是围了一圈的8个麦克风，这个阵列可以探测到人是否在和它说话，比如我和别人说话的时候，脸转过去，它就不会有反应。这种唤醒功能是非常准确的。它的另外一个功能是当你的双手没办法去控制手机的时候，可以用语音来控制，案例场景是客厅和厨房，在美国Amazon Echo特别受家庭主妇的欢迎，所以像这种特定的场景，如果收集了足够的数据，是可以训练出这样强大的对话系统来的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;强化迁移学习&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;我们可以想象，未来深度学习、强化学习和迁移学习的结合，可以实现以下几个突破&amp;mdash;&amp;mdash;反馈可以延迟、可以个性化，把一个通用模型施加到任何个体上面，这样一个复合模型可以叫做强化迁移学习模型&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;人工智能的可靠性模型&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;AI as Reliable Services&lt;/span&gt;&lt;span&gt;是AAAI 前主席Thomas Dietterich在AAAI 2016上给出的一个主题，人工智能只能作为一些例证证明能够做哪些事情，比如下棋，无人驾驶，但很多时候它还是不可靠的。它不像现在的一个商用软件一样，能让你放心地去使用，以保证它的错误率肯定不会超过很小的比例。相反，AI 在犯错的时候可能错得非常厉害，所以用平均值来代表一个准确率是不恰当的，相反，应该更多地要考虑它的置信区间。换言之，小白用户拿一些人工智能的模块来搭一个系统，这个系统就应该能被搭出来，而且它的效果应该是在一个固定的范围以内的，所以人工智能应该像软件工程一样做出来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;第四范式核心产品&amp;ldquo;先知平台&amp;rdquo;一直就在往这个方向发展，先知把人工智能的模块工程化、并在一定程度上保证了可靠性，从而让普通用户用来搭建自己的人工智能系统。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;三、AI的商业风口在哪？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;上面我们考虑了人工智能的技术发展。下面我们看看商业领域。我们刚才列举了AI 成功的5大必要条件：高质量的大数据、清晰的问题定义和领域边界、懂人工智能且擅长应用和算法的跨界人才、足够的计算资源、持续的外部反馈。满足这五个条件的领域，才有可能在未来出现人工智能的爆发。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;智能客服&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人机交互的智能客服，产生了很多外界公开的数据以及内部的数据、知识库等，都可以用来制造机器人。尤其是可以用客服过去的数据来做训练，这个数据量现在在垂直领域是逐渐在增加的。现在的对话系统也已经逐渐成为深度学习和强化学习的焦点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;新闻领域&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外一个比较看好的领域是新闻领域，新闻的分发和自动写作。有很多编辑、解说、自动校对、作家等，其实是数据量足够多的，有这么多的文本，而且外界反馈也越来越多了。给一篇文章，可以用机器学习来做自动摘要。 这样一个工作的外部反馈来自哪里呢？实际上我们写的那些paper就是一个外部反馈，因为每篇paper都有摘要，如果一篇paper被收了，就说明摘要写的还不错，所以外部反馈还是可以实现的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里分享一个有趣的实验，是香港科大同学做的&amp;ldquo;自动写小说&amp;rdquo;项目。主要有两个步骤，一步是让它读很多书，一步是这样训练出一个模型，这个模型再让它变成一个生成式的模型，这样就能用来写小说了。举个例子，我们提供《射雕英雄传》和《笑傲江湖》，把这两个结合起来，就可以写一部新的小说了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;特定任务的智能机器人&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;例如Amazon 的KIVA机器人，大家可能知道Amazon一个很大的优势就是所有的仓储都是由机器人来完成的，但是它也有工人，被雇来用手做抓取，因为现在机器人的抓取是非常难的，那么人和机器的优点就结合起来了。此外，医疗机器人也是非常专业的一个领域，它可以给人开刀缝线，但它不是自动的，而是通过远程控制的，但控制的精密度非常高，如果它收集到足够量的数据，是可以达到自动的效果的，以后我们可能开刀就由机器人来代劳了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;在医护领域，&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;无障碍辅助的应用领域痛点特别强烈，现在数据量可能还不是特别多，因为毕竟这一群体还是少数人，但是痛点很强，所以未来也许会有数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;AI+&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;有机食品&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们在香港曾去访问过一个有机食品工厂，这个实验室里的每一株菜，周边的所有环境全都记录起来，比如湿度、温度、光照，然后就可以收集这样的数据训练一个机器学习的模型，最后用这个模型来做蔬菜。所以得来的蔬菜滋味可以控制，要脆感还是要甜的，都可以通过模型学习出来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;FINTECH&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;智能投顾&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后来说一说金融，其实金融是一个非常好的领域，第四范式在金融领域也积累了很多成功案例。&lt;strong&gt;金融领域里的任务都是非常清楚的&lt;/strong&gt;，而且每个任务的数据都有痕迹、有数据足迹，数据的维度也是多维度的数据，有外界的、也有内界的，非结构数据比较多，例如文本和报告。数据也是形成了孤岛，链条也非常长，并且链条里面都有衔接。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在金融领域现在美国比较时髦的一个概念叫投研、投顾和投资。投研是说研究整个市场的基本面，就好像我们研究舆情分析一样，但舆情只是其中的一部分；投顾是说在美国的银行给很多客户做理财分析，然后做理财的配置，这些工作可以由机器人来做；投资是说机器人自己就是一个客户，它可以去投资。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;四、多年后的AI社会&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后说一下我认为多年后的AI社会是怎么样的。&lt;strong&gt;我觉得未来应该是几个人在运行一个公司，每一个人都能率领成千上万个机器人，这些机器人在做不同的事情，&lt;/strong&gt;也是它被训练得很擅长的事情。我们现在在一个传统行业里，往往是20%的人在做80%的工作，那么这20%的人就是未来的运营公司的人，剩下80%的人所做的工作将交由机器来完成。一个公司的自动化，智能化程度，也代表了这个公司在商业上的反应速度和竞争力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能给人类带来的变革是非常深远的，人工智能不仅仅是一场比赛、一个应用，而是整个社会真正地彻底地在改变。机器和人将成为一个共同的&amp;ldquo;军队&amp;rdquo;不断地攻克堡垒，推动人类进程向更好的方向发展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/cf1552389fe466eb546c6283d2e4b68a1dd39440"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&amp;copy;本文为机器之心经授权转载，&lt;strong&gt;&lt;span&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Tue, 28 Feb 2017 12:17:03 +0800</pubDate>
    </item>
    <item>
      <title>开源 | 为Go语言设计的机器学习库Gorgonia：对标TensorFlow与Theano</title>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650723729&amp;idx=3&amp;sn=240a0d5fc1133a1b520042128e9511cc&amp;chksm=871b11efb06c98f9240f82ce753301e896e9c4ba0cd320ebfb260c163f8c950ae46fa0aeb007&amp;scene=0#rd</link>
      <description>
&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自GitHub&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：侯韵楚、黄小天、蒋思源&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Gorgonia 是一个促进在 Go 中进行机器学习的库，旨在更容易地编写与评估涉及多维数组的数学方程。如果这听起来很像 Theano 或者 TensorFlow，原因是三者的想法非常相似。具体而言，Gorgonia 像 Theano 一样相当低级；但又像 Tensorflow 一样具有更高目标。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;项目地址：https://github.com/chewxy/gorgonia&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;项目介绍：https://blog.chewxy.com/2016/09/19/gorgonia/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;可执行自动微分&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;可执行符号微分&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;可执行梯度下降优化&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;可执行数值稳定&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;提供了许多便利功能，以助于创建神经网络&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;非常快（与 Theano 和 Tensorflow 的速度相当）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;支持 CUDA / GPGPU 计算（OpenCL 尚不支持，需发送拉取请求）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;将支持分布式计算&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;为何选择&amp;nbsp;Gorgonia？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Gorgonia 的使用主要方便了开发者。如果你使用 Go 广泛地堆栈，便可以在熟悉而舒适的环境中创建生产就绪的机器学习系统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器学习／人工智能通常笼统地分为两个阶段：（a）建立多种模型并测试、再测试的试验阶段，（b）以及模型在测试与试用之后被部署的部署阶段。这两个阶段不可或缺且作用各异，就像数据科学家和数据工程师之间的区别。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;原则上这两个阶段使用的工具也不同：实验阶段通常使用 Python / Lua（使用 Theano，Torch 等），而后这个模型会使用性能更高的语言来重新编写，如 C++（使用 dlib、mlpack 等）。当然，如今差距正在慢慢缩短，人们也经常会进行工具共享，比如 Tensorflow 便可用来填补差距。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而 Gorgonia 的目的，却是在 Go 环境中完成相同的事情。目前 Gorgonia 性能相当高，其速度与 Theano 和 Tensorflow 相当（由于目前 Gorgonia 存在 一个 CUDA 缺陷，所以还未完成官方基准测试；另外，因为实现可能会稍有不同，所以很难去比较一个精确的以牙还牙模型）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;安装&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;安装包是 go-get 的: go get -u github.com/chewxy/gorgonia.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Gorgonia 所使用的依赖很少且都很稳定，所以目前不需要代管工具。下表为 Gorgonia 所调用的外部软件包列表，并按照它所依赖的顺序进行了排列（已省略子软件包）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/a21b1d5b732d206c0c85a57d4cb5310d91793418"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;保持更新&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Gorgonia 的项目有一个邮件列表和 Twitter 帐户，官方更新和公告会发布到这两个网站：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;https://groups.google.com/forum/#!forum/gorgonia&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;https://twitter.com/gorgoniaML&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;用法&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Gorgonia 通过创建计算图来工作，而后将其执行。请把它当作一种仅限于数学函数方面的编程语言；事实上，这应当作为用户思考的主要实例。它创建的计算图是一个 AST。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微软 CNTK 的 BrainScript 可能是用来说明计算图的构建与运行并不相同的最佳实例，所以用户对于这二者，应当运用不同的思维模式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然 Gorgonia 的实现并不像 CNTK 的 BrainScript 那样强制性分离思维，但语法确实略有裨益。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此处举出一个实例&amp;mdash;&amp;mdash;若要定义一个数学表达式 z = x + y，应当这样做：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;package&lt;/span&gt; main&lt;span&gt;import&lt;/span&gt; ( &amp;nbsp; &amp;nbsp;&lt;span&gt;&lt;span&gt;"&lt;/span&gt;fmt&lt;span&gt;"&lt;/span&gt;&lt;/span&gt;
 &amp;nbsp; &amp;nbsp;&lt;span&gt;&lt;span&gt;"&lt;/span&gt;log&lt;span&gt;"&lt;/span&gt;&lt;/span&gt;

 &amp;nbsp; &amp;nbsp;. &lt;span&gt;&lt;span&gt;"&lt;/span&gt;github.com/chewxy/gorgonia&lt;span&gt;"&lt;/span&gt;&lt;/span&gt;)&lt;span&gt;func&lt;/span&gt; &lt;span&gt;main&lt;/span&gt;() { &amp;nbsp; &amp;nbsp;&lt;span&gt;g&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; &lt;span&gt;NewGraph&lt;/span&gt;() &amp;nbsp; &amp;nbsp;&lt;span&gt;var&lt;/span&gt; &lt;span&gt;x&lt;/span&gt;, &lt;span&gt;y&lt;/span&gt;, &lt;span&gt;z&lt;/span&gt; *Node &amp;nbsp; &amp;nbsp;&lt;span&gt;var&lt;/span&gt; &lt;span&gt;err&lt;/span&gt; &lt;span&gt;error&lt;/span&gt;

 &amp;nbsp; &amp;nbsp;&lt;span&gt;&lt;span&gt;//&lt;/span&gt; define the expression&lt;/span&gt;
 &amp;nbsp; &amp;nbsp;x = &lt;span&gt;NewScalar&lt;/span&gt;(g, Float64, &lt;span&gt;WithName&lt;/span&gt;(&lt;span&gt;&lt;span&gt;"&lt;/span&gt;x&lt;span&gt;"&lt;/span&gt;&lt;/span&gt;))
 &amp;nbsp; &amp;nbsp;y = &lt;span&gt;NewScalar&lt;/span&gt;(g, Float64, &lt;span&gt;WithName&lt;/span&gt;(&lt;span&gt;&lt;span&gt;"&lt;/span&gt;y&lt;span&gt;"&lt;/span&gt;&lt;/span&gt;))
 &amp;nbsp; &amp;nbsp;z, err = &lt;span&gt;Add&lt;/span&gt;(x, y) &amp;nbsp; &amp;nbsp;&lt;span&gt;if&lt;/span&gt; err != &lt;span&gt;nil&lt;/span&gt; {
 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;log.&lt;span&gt;Fatal&lt;/span&gt;(err)
 &amp;nbsp; &amp;nbsp;} &amp;nbsp; &amp;nbsp;&lt;span&gt;&lt;span&gt;//&lt;/span&gt; compile into a program&lt;/span&gt;
 &amp;nbsp; &amp;nbsp;&lt;span&gt;prog&lt;/span&gt;, &lt;span&gt;locMap&lt;/span&gt;, &lt;span&gt;err&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; &lt;span&gt;Compile&lt;/span&gt;(g) &amp;nbsp; &amp;nbsp;&lt;span&gt;if&lt;/span&gt; err != &lt;span&gt;nil&lt;/span&gt; {
 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;log.&lt;span&gt;Fatal&lt;/span&gt;(err)
 &amp;nbsp; &amp;nbsp;} &amp;nbsp; &amp;nbsp;&lt;span&gt;&lt;span&gt;//&lt;/span&gt; create a VM to run the program on&lt;/span&gt;
 &amp;nbsp; &amp;nbsp;&lt;span&gt;machine&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; &lt;span&gt;NewTapeMachine&lt;/span&gt;(prog, locMap) &amp;nbsp; &amp;nbsp;&lt;span&gt;&lt;span&gt;//&lt;/span&gt; set initial values then run&lt;/span&gt;
 &amp;nbsp; &amp;nbsp;&lt;span&gt;Let&lt;/span&gt;(x, &lt;span&gt;2.0&lt;/span&gt;) &amp;nbsp; &amp;nbsp;&lt;span&gt;Let&lt;/span&gt;(y, &lt;span&gt;2.5&lt;/span&gt;) &amp;nbsp; &amp;nbsp;&lt;span&gt;if&lt;/span&gt; machine.&lt;span&gt;RunAll&lt;/span&gt;() != &lt;span&gt;nil&lt;/span&gt; {
 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;log.&lt;span&gt;Fatal&lt;/span&gt;(err)
 &amp;nbsp; &amp;nbsp;}

 &amp;nbsp; &amp;nbsp;fmt.&lt;span&gt;Printf&lt;/span&gt;(&lt;span&gt;&lt;span&gt;"&lt;/span&gt;%v&lt;span&gt;"&lt;/span&gt;&lt;/span&gt;, z.&lt;span&gt;Value&lt;/span&gt;()) &amp;nbsp; &amp;nbsp;&lt;span&gt;&lt;span&gt;//&lt;/span&gt; Output: 4.5&lt;/span&gt;}&lt;/span&gt;&lt;/pre&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你可能会发现，它比其他类似的软件包更显冗长。如 Gorgonia 并未编译为可调用的函数，而是特地编译为需要TapeMachine 来运行的program；此外它还需要手动调用一个 Let（...）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;作者却认为这是好事&amp;mdash;&amp;mdash;能够将人的思维转变为机器的思维。它在我们想查清哪里出错的时候很有帮助。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;虚拟内存系统&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当前版本的 Gorgonia 有两个虚拟内存系统：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;TapeMachine&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;LispMachine&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;它们功能不同，采取的输入也不同。TapeMachine 通常更善于执行静态表达式（即计算图并不改变）；由于其静态特性，它适用于一次编写，多次运行的表达式（如线性回归，SVM 等）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;LispMachine 则是将图形设为输入，并直接在图形的节点上执行。如果图形有所改变，只需新创建一个轻量级 LispMachine 来执行便可。LispMachine 适于诸如创建大小不固定的循环神经网络这类的任务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 Gorgonia 发布之前存在第三个虚拟内存，它基于堆栈，且与 TapeMachine 相似，但能够更妥善地处理人工梯度。当作者解决了所有的问题后，它也许就能重见天日。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;微分&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Gorgonia 执行符号与自动微分，而这两个过程存在细微差别。作者认为这样理解是最合适的：自动微分是在运行时所做的微分，与图表的执行同时发生；符号微分是在编写阶段所做的微分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此处「运行时」当然是指表达式图的执行，而非程序的实际运行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过介绍这两个虚拟内存系统，便很容易理解 Gorgonia 如何执行符号与自动微分。使用与上文相同的示例，读者 能够发现此处并没有进行微分。这次用 LispMachine 做一次尝试吧：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;package&lt;/span&gt; main&lt;span&gt;import&lt;/span&gt; ( &amp;nbsp; &amp;nbsp;&lt;span&gt;&lt;span&gt;"&lt;/span&gt;fmt&lt;span&gt;"&lt;/span&gt;&lt;/span&gt;
 &amp;nbsp; &amp;nbsp;&lt;span&gt;&lt;span&gt;"&lt;/span&gt;log&lt;span&gt;"&lt;/span&gt;&lt;/span&gt;

 &amp;nbsp; &amp;nbsp;. &lt;span&gt;&lt;span&gt;"&lt;/span&gt;github.com/chewxy/gorgonia&lt;span&gt;"&lt;/span&gt;&lt;/span&gt;)&lt;span&gt;func&lt;/span&gt; &lt;span&gt;main&lt;/span&gt;() { &amp;nbsp; &amp;nbsp;&lt;span&gt;g&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; &lt;span&gt;NewGraph&lt;/span&gt;() &amp;nbsp; &amp;nbsp;&lt;span&gt;var&lt;/span&gt; &lt;span&gt;x&lt;/span&gt;, &lt;span&gt;y&lt;/span&gt;, &lt;span&gt;z&lt;/span&gt; *Node &amp;nbsp; &amp;nbsp;&lt;span&gt;var&lt;/span&gt; &lt;span&gt;err&lt;/span&gt; &lt;span&gt;error&lt;/span&gt;

 &amp;nbsp; &amp;nbsp;&lt;span&gt;&lt;span&gt;//&lt;/span&gt; define the expression&lt;/span&gt;
 &amp;nbsp; &amp;nbsp;x = &lt;span&gt;NewScalar&lt;/span&gt;(g, Float64, &lt;span&gt;WithName&lt;/span&gt;(&lt;span&gt;&lt;span&gt;"&lt;/span&gt;x&lt;span&gt;"&lt;/span&gt;&lt;/span&gt;))
 &amp;nbsp; &amp;nbsp;y = &lt;span&gt;NewScalar&lt;/span&gt;(g, Float64, &lt;span&gt;WithName&lt;/span&gt;(&lt;span&gt;&lt;span&gt;"&lt;/span&gt;y&lt;span&gt;"&lt;/span&gt;&lt;/span&gt;))
 &amp;nbsp; &amp;nbsp;z, err = &lt;span&gt;Add&lt;/span&gt;(x, y) &amp;nbsp; &amp;nbsp;&lt;span&gt;if&lt;/span&gt; err != &lt;span&gt;nil&lt;/span&gt; {
 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;log.&lt;span&gt;Fatal&lt;/span&gt;(err)
 &amp;nbsp; &amp;nbsp;} &amp;nbsp; &amp;nbsp;&lt;span&gt;&lt;span&gt;//&lt;/span&gt; set initial values then run&lt;/span&gt;
 &amp;nbsp; &amp;nbsp;&lt;span&gt;Let&lt;/span&gt;(x, &lt;span&gt;2.0&lt;/span&gt;) &amp;nbsp; &amp;nbsp;&lt;span&gt;Let&lt;/span&gt;(y, &lt;span&gt;2.5&lt;/span&gt;) &amp;nbsp; &amp;nbsp;&lt;span&gt;&lt;span&gt;//&lt;/span&gt; by default, LispMachine performs forward mode and backwards mode execution&lt;/span&gt;
 &amp;nbsp; &amp;nbsp;&lt;span&gt;m&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; &lt;span&gt;NewLispMachine&lt;/span&gt;(g) &amp;nbsp; &amp;nbsp;&lt;span&gt;if&lt;/span&gt; m.&lt;span&gt;RunAll&lt;/span&gt;() != &lt;span&gt;nil&lt;/span&gt; {
 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;log.&lt;span&gt;Fatal&lt;/span&gt;(err)
 &amp;nbsp; &amp;nbsp;}

 &amp;nbsp; &amp;nbsp;fmt.&lt;span&gt;Printf&lt;/span&gt;(&lt;span&gt;&lt;span&gt;"&lt;/span&gt;z: %v&lt;span&gt;\n"&lt;/span&gt;&lt;/span&gt;, z.&lt;span&gt;Value&lt;/span&gt;()) &amp;nbsp; &amp;nbsp;&lt;span&gt;xgrad&lt;/span&gt;, &lt;span&gt;err&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; x.&lt;span&gt;Grad&lt;/span&gt;() &amp;nbsp; &amp;nbsp;&lt;span&gt;if&lt;/span&gt; err != &lt;span&gt;nil&lt;/span&gt; {
 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;log.&lt;span&gt;Fatal&lt;/span&gt;(err)
 &amp;nbsp; &amp;nbsp;}
 &amp;nbsp; &amp;nbsp;fmt.&lt;span&gt;Printf&lt;/span&gt;(&lt;span&gt;&lt;span&gt;"&lt;/span&gt;dz/dx: %v&lt;span&gt;\n"&lt;/span&gt;&lt;/span&gt;, xgrad) &amp;nbsp; &amp;nbsp;&lt;span&gt;ygrad&lt;/span&gt;, &lt;span&gt;err&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; y.&lt;span&gt;Grad&lt;/span&gt;() &amp;nbsp; &amp;nbsp;&lt;span&gt;if&lt;/span&gt; err != &lt;span&gt;nil&lt;/span&gt; {
 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;log.&lt;span&gt;Fatal&lt;/span&gt;(err)
 &amp;nbsp; &amp;nbsp;}
 &amp;nbsp; &amp;nbsp;fmt.&lt;span&gt;Printf&lt;/span&gt;(&lt;span&gt;&lt;span&gt;"&lt;/span&gt;dz/dy: %v&lt;span&gt;\n"&lt;/span&gt;&lt;/span&gt;, ygrad) &amp;nbsp; &amp;nbsp;&lt;span&gt;&lt;span&gt;//&lt;/span&gt; Output:&lt;/span&gt;
 &amp;nbsp; &amp;nbsp;&lt;span&gt;&lt;span&gt;//&lt;/span&gt; z: 4.5&lt;/span&gt;
 &amp;nbsp; &amp;nbsp;&lt;span&gt;&lt;span&gt;//&lt;/span&gt; dz/dx: 1&lt;/span&gt;
 &amp;nbsp; &amp;nbsp;&lt;span&gt;&lt;span&gt;//&lt;/span&gt; dz/dy: 1&lt;/span&gt;}&lt;/span&gt;&lt;/pre&gt;&lt;p&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然，Gorgonia 同样支持更传统的的符号微分，比如在 Theano 中：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;package&lt;/span&gt; main&lt;span&gt;import&lt;/span&gt; ( &amp;nbsp; &amp;nbsp;&lt;span&gt;&lt;span&gt;"&lt;/span&gt;fmt&lt;span&gt;"&lt;/span&gt;&lt;/span&gt;
 &amp;nbsp; &amp;nbsp;&lt;span&gt;&lt;span&gt;"&lt;/span&gt;log&lt;span&gt;"&lt;/span&gt;&lt;/span&gt;

 &amp;nbsp; &amp;nbsp;. &lt;span&gt;&lt;span&gt;"&lt;/span&gt;github.com/chewxy/gorgonia&lt;span&gt;"&lt;/span&gt;&lt;/span&gt;)&lt;span&gt;func&lt;/span&gt; &lt;span&gt;main&lt;/span&gt;() { &amp;nbsp; &amp;nbsp;&lt;span&gt;g&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; &lt;span&gt;NewGraph&lt;/span&gt;() &amp;nbsp; &amp;nbsp;&lt;span&gt;var&lt;/span&gt; &lt;span&gt;x&lt;/span&gt;, &lt;span&gt;y&lt;/span&gt;, &lt;span&gt;z&lt;/span&gt; *Node &amp;nbsp; &amp;nbsp;&lt;span&gt;var&lt;/span&gt; &lt;span&gt;err&lt;/span&gt; &lt;span&gt;error&lt;/span&gt;

 &amp;nbsp; &amp;nbsp;&lt;span&gt;&lt;span&gt;//&lt;/span&gt; define the expression&lt;/span&gt;
 &amp;nbsp; &amp;nbsp;x = &lt;span&gt;NewScalar&lt;/span&gt;(g, Float64, &lt;span&gt;WithName&lt;/span&gt;(&lt;span&gt;&lt;span&gt;"&lt;/span&gt;x&lt;span&gt;"&lt;/span&gt;&lt;/span&gt;))
 &amp;nbsp; &amp;nbsp;y = &lt;span&gt;NewScalar&lt;/span&gt;(g, Float64, &lt;span&gt;WithName&lt;/span&gt;(&lt;span&gt;&lt;span&gt;"&lt;/span&gt;y&lt;span&gt;"&lt;/span&gt;&lt;/span&gt;))
 &amp;nbsp; &amp;nbsp;z, err = &lt;span&gt;Add&lt;/span&gt;(x, y) &amp;nbsp; &amp;nbsp;&lt;span&gt;if&lt;/span&gt; err != &lt;span&gt;nil&lt;/span&gt; {
 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;log.&lt;span&gt;Fatal&lt;/span&gt;(err)
 &amp;nbsp; &amp;nbsp;} &amp;nbsp; &amp;nbsp;&lt;span&gt;&lt;span&gt;//&lt;/span&gt; symbolically differentiate z with regards to x and y&lt;/span&gt;
 &amp;nbsp; &amp;nbsp;&lt;span&gt;&lt;span&gt;//&lt;/span&gt; this adds the gradient nodes to the graph g&lt;/span&gt;
 &amp;nbsp; &amp;nbsp;&lt;span&gt;var&lt;/span&gt; &lt;span&gt;grads&lt;/span&gt; Nodes
 &amp;nbsp; &amp;nbsp;grads, err = &lt;span&gt;Grad&lt;/span&gt;(z, x, y) &amp;nbsp; &amp;nbsp;&lt;span&gt;if&lt;/span&gt; err != &lt;span&gt;nil&lt;/span&gt; {
 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;log.&lt;span&gt;Fatal&lt;/span&gt;(err)
 &amp;nbsp; &amp;nbsp;} &amp;nbsp; &amp;nbsp;&lt;span&gt;&lt;span&gt;//&lt;/span&gt; compile into a program&lt;/span&gt;
 &amp;nbsp; &amp;nbsp;&lt;span&gt;prog&lt;/span&gt;, &lt;span&gt;locMap&lt;/span&gt;, &lt;span&gt;err&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; &lt;span&gt;Compile&lt;/span&gt;(g) &amp;nbsp; &amp;nbsp;&lt;span&gt;if&lt;/span&gt; err != &lt;span&gt;nil&lt;/span&gt; {
 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;log.&lt;span&gt;Fatal&lt;/span&gt;(err)
 &amp;nbsp; &amp;nbsp;} &amp;nbsp; &amp;nbsp;&lt;span&gt;&lt;span&gt;//&lt;/span&gt; create a VM to run the program on&lt;/span&gt;
 &amp;nbsp; &amp;nbsp;&lt;span&gt;machine&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; &lt;span&gt;NewTapeMachine&lt;/span&gt;(prog, locMap) &amp;nbsp; &amp;nbsp;&lt;span&gt;&lt;span&gt;//&lt;/span&gt; set initial values then run&lt;/span&gt;
 &amp;nbsp; &amp;nbsp;&lt;span&gt;Let&lt;/span&gt;(x, &lt;span&gt;2.0&lt;/span&gt;) &amp;nbsp; &amp;nbsp;&lt;span&gt;Let&lt;/span&gt;(y, &lt;span&gt;2.5&lt;/span&gt;) &amp;nbsp; &amp;nbsp;&lt;span&gt;if&lt;/span&gt; machine.&lt;span&gt;RunAll&lt;/span&gt;() != &lt;span&gt;nil&lt;/span&gt; {
 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;log.&lt;span&gt;Fatal&lt;/span&gt;(err)
 &amp;nbsp; &amp;nbsp;}

 &amp;nbsp; &amp;nbsp;fmt.&lt;span&gt;Printf&lt;/span&gt;(&lt;span&gt;&lt;span&gt;"&lt;/span&gt;z: %v&lt;span&gt;\n"&lt;/span&gt;&lt;/span&gt;, z.&lt;span&gt;Value&lt;/span&gt;()) &amp;nbsp; &amp;nbsp;&lt;span&gt;xgrad&lt;/span&gt;, &lt;span&gt;err&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; x.&lt;span&gt;Grad&lt;/span&gt;() &amp;nbsp; &amp;nbsp;&lt;span&gt;if&lt;/span&gt; err != &lt;span&gt;nil&lt;/span&gt; {
 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;log.&lt;span&gt;Fatal&lt;/span&gt;(err)
 &amp;nbsp; &amp;nbsp;}
 &amp;nbsp; &amp;nbsp;fmt.&lt;span&gt;Printf&lt;/span&gt;(&lt;span&gt;&lt;span&gt;"&lt;/span&gt;dz/dx: %v | %v&lt;span&gt;\n"&lt;/span&gt;&lt;/span&gt;, xgrad, grads[&lt;span&gt;0&lt;/span&gt;]) &amp;nbsp; &amp;nbsp;&lt;span&gt;ygrad&lt;/span&gt;, &lt;span&gt;err&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; y.&lt;span&gt;Grad&lt;/span&gt;() &amp;nbsp; &amp;nbsp;&lt;span&gt;if&lt;/span&gt; err != &lt;span&gt;nil&lt;/span&gt; {
 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;log.&lt;span&gt;Fatal&lt;/span&gt;(err)
 &amp;nbsp; &amp;nbsp;}
 &amp;nbsp; &amp;nbsp;fmt.&lt;span&gt;Printf&lt;/span&gt;(&lt;span&gt;&lt;span&gt;"&lt;/span&gt;dz/dy: %v | %v&lt;span&gt;\n"&lt;/span&gt;&lt;/span&gt;, ygrad, grads[&lt;span&gt;1&lt;/span&gt;]) &amp;nbsp; &amp;nbsp;&lt;span&gt;&lt;span&gt;//&lt;/span&gt; Output:&lt;/span&gt;
 &amp;nbsp; &amp;nbsp;&lt;span&gt;&lt;span&gt;//&lt;/span&gt; z: 4.5&lt;/span&gt;
 &amp;nbsp; &amp;nbsp;&lt;span&gt;&lt;span&gt;//&lt;/span&gt; dz/dx: 1 | 1&lt;/span&gt;
 &amp;nbsp; &amp;nbsp;&lt;span&gt;&lt;span&gt;//&lt;/span&gt; dz/dy: 1 | 1&lt;/span&gt;}&lt;/span&gt;&lt;/pre&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然人们在 Gorgonia 中，能嗅到支持 dualValue 存在条件下进行正向模式微分的旧版痕迹，但其目前仅执行反向模式自动微分（又名反向传播）。正向模式微分也许在将来能够回归。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;图表&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;确实存在许多计算图或表达式图的有关说法，但它究竟是什么？请将它想象成你想要的数学表达式的 AST。此处为上述示例的图形（但还有一个向量和一个标量加法）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/053df1295761cdbbcac2bfc656ec9c8995b945ac"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;顺便一提，Gorgonia 的图形打印能力很强。此处为方程式 y = x&amp;sup2; 及其导数的图形示例：&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/5e3ab4a15ed107d7ab6f792f262b6aa49c74ddba"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图形很容易阅读。表达式从下往上进行构建，而导数是由上向下构建的。因此每个节点的导数大致处于同一水平。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;红色轮廓的节点表示它们是根节点，而绿色轮廓则表示为叶节点，带有黄色背景的节点表示为输入节点，而虚线箭头则表示哪个节点是指向节点的梯度节点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;具体而言，比如 c42011e840 (dy/dx) 便表示输入 c42011e000（即 x）的梯度节点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;节点渲染&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;节点是这样渲染的：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/3c45d21ebbb2e3f64597a3b19bfdc9beb950dcb9"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;补充说明：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如果它是输入节点，则 Op 行不会显示。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如果没有绑定到节点的值，将显示为 NIL。但若有值和梯度存在，它将极尽所能显示绑定到节点的值。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;使用 CUDA&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此外，还存在附加要求：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 需要 CUDA toolkit 8.0。安装这个程序将会安装 nvcc 编译器，这是使用 CUDA 运行代码所必备的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. go install github.com/chewxy/gorgonia/cmd/cudagen。这是 cudagen 程序的安装网址。运行 cudagen 将生成与 Gorgonia 有关的 CUDA 相关代码。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 务必使用 UseCudaFor 选项，务必使代码中的 CUDA 操作能够手动启用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4. runtime.LockOSThread() 必须在虚拟内存正在运行的主函数中调用。CUDA 需要线程亲和性，因此必须锁定 OS 线程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;示例&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以，我们该如何使用 CUDA 呢？假设有一个文件 main.go：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;import&lt;/span&gt; ( &amp;nbsp; &amp;nbsp;&lt;span&gt;&lt;span&gt;"&lt;/span&gt;fmt&lt;span&gt;"&lt;/span&gt;&lt;/span&gt;
 &amp;nbsp; &amp;nbsp;&lt;span&gt;&lt;span&gt;"&lt;/span&gt;log&lt;span&gt;"&lt;/span&gt;&lt;/span&gt;
 &amp;nbsp; &amp;nbsp;&lt;span&gt;&lt;span&gt;"&lt;/span&gt;runtime&lt;span&gt;"&lt;/span&gt;&lt;/span&gt;

 &amp;nbsp; &amp;nbsp;&lt;span&gt;T&lt;/span&gt; &lt;span&gt;&lt;span&gt;"&lt;/span&gt;github.com/chewxy/gorgonia&lt;span&gt;"&lt;/span&gt;&lt;/span&gt;
 &amp;nbsp; &amp;nbsp;&lt;span&gt;&lt;span&gt;"&lt;/span&gt;github.com/chewxy/gorgonia/tensor&lt;span&gt;"&lt;/span&gt;&lt;/span&gt;)&lt;span&gt;func&lt;/span&gt; &lt;span&gt;main&lt;/span&gt;() { &amp;nbsp; &amp;nbsp;&lt;span&gt;g&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; T.&lt;span&gt;NewGraph&lt;/span&gt;() &amp;nbsp; &amp;nbsp;&lt;span&gt;x&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; T.&lt;span&gt;NewMatrix&lt;/span&gt;(g, T.&lt;span&gt;Float32&lt;/span&gt;, T.&lt;span&gt;WithName&lt;/span&gt;(&lt;span&gt;&lt;span&gt;"&lt;/span&gt;x&lt;span&gt;"&lt;/span&gt;&lt;/span&gt;), T.&lt;span&gt;WithShape&lt;/span&gt;(&lt;span&gt;100&lt;/span&gt;, &lt;span&gt;100&lt;/span&gt;)) &amp;nbsp; &amp;nbsp;&lt;span&gt;y&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; T.&lt;span&gt;NewMatrix&lt;/span&gt;(g, T.&lt;span&gt;Float32&lt;/span&gt;, T.&lt;span&gt;WithName&lt;/span&gt;(&lt;span&gt;&lt;span&gt;"&lt;/span&gt;y&lt;span&gt;"&lt;/span&gt;&lt;/span&gt;), T.&lt;span&gt;WithShape&lt;/span&gt;(&lt;span&gt;100&lt;/span&gt;, &lt;span&gt;100&lt;/span&gt;)) &amp;nbsp; &amp;nbsp;&lt;span&gt;xpy&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; T.&lt;span&gt;Must&lt;/span&gt;(T.&lt;span&gt;Add&lt;/span&gt;(x, y)) &amp;nbsp; &amp;nbsp;&lt;span&gt;xpy2&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; T.&lt;span&gt;Must&lt;/span&gt;(T.&lt;span&gt;Tanh&lt;/span&gt;(xpy)) &amp;nbsp; &amp;nbsp;&lt;span&gt;prog&lt;/span&gt;, &lt;span&gt;locMap&lt;/span&gt;, &lt;span&gt;_&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; T.&lt;span&gt;Compile&lt;/span&gt;(g) &amp;nbsp; &amp;nbsp;&lt;span&gt;m&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; T.&lt;span&gt;NewTapeMachine&lt;/span&gt;(prog, locMap, T.&lt;span&gt;UseCudaFor&lt;/span&gt;(&lt;span&gt;&lt;span&gt;"&lt;/span&gt;tanh&lt;span&gt;"&lt;/span&gt;&lt;/span&gt;))

 &amp;nbsp; &amp;nbsp;T.&lt;span&gt;Let&lt;/span&gt;(x, tensor.&lt;span&gt;New&lt;/span&gt;(tensor.&lt;span&gt;WithShape&lt;/span&gt;(&lt;span&gt;100&lt;/span&gt;, &lt;span&gt;100&lt;/span&gt;), tensor.&lt;span&gt;WithBacking&lt;/span&gt;(tensor.&lt;span&gt;Random&lt;/span&gt;(tensor.&lt;span&gt;Float32&lt;/span&gt;, &lt;span&gt;100&lt;/span&gt;*&lt;span&gt;100&lt;/span&gt;))))
 &amp;nbsp; &amp;nbsp;T.&lt;span&gt;Let&lt;/span&gt;(y, tensor.&lt;span&gt;New&lt;/span&gt;(tensor.&lt;span&gt;WithShape&lt;/span&gt;(&lt;span&gt;100&lt;/span&gt;, &lt;span&gt;100&lt;/span&gt;), tensor.&lt;span&gt;WithBacking&lt;/span&gt;(tensor.&lt;span&gt;Random&lt;/span&gt;(tensor.&lt;span&gt;Float32&lt;/span&gt;, &lt;span&gt;100&lt;/span&gt;*&lt;span&gt;100&lt;/span&gt;))))

 &amp;nbsp; &amp;nbsp;runtime.&lt;span&gt;LockOSThread&lt;/span&gt;() &amp;nbsp; &amp;nbsp;&lt;span&gt;for&lt;/span&gt; &lt;span&gt;i&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; &lt;span&gt;0&lt;/span&gt;; i &amp;lt; &lt;span&gt;1000&lt;/span&gt;; i++ { &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;span&gt;if&lt;/span&gt; &lt;span&gt;err&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; m.&lt;span&gt;RunAll&lt;/span&gt;(); err != &lt;span&gt;nil&lt;/span&gt; {
 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;log.&lt;span&gt;Fatalf&lt;/span&gt;(&lt;span&gt;&lt;span&gt;"&lt;/span&gt;iteration: %d. Err: %v&lt;span&gt;"&lt;/span&gt;&lt;/span&gt;, i, err)
 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;}
 &amp;nbsp; &amp;nbsp;}
 &amp;nbsp; &amp;nbsp;runtime.&lt;span&gt;UnlockOSThread&lt;/span&gt;()

 &amp;nbsp; &amp;nbsp;fmt.&lt;span&gt;Printf&lt;/span&gt;(&lt;span&gt;&lt;span&gt;"&lt;/span&gt;%1.1f&lt;span&gt;"&lt;/span&gt;&lt;/span&gt;, xpy2.&lt;span&gt;Value&lt;/span&gt;())
}&lt;/span&gt;&lt;/pre&gt;&lt;p&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果它正常运行：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;go run main.go&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;CUDA 不会被使用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果程序要使用 CUDA 运行，那么必须进行调用：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;go run -tags='cuda'&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;即便如此，也只有 tanh 函数使用 CUDA。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;解释&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使用 CUDA 的要求这么复杂，主要与其性能有关。正如 Dave Cheney 的名言：cgo 不是 Go。但不幸的是，使用 CUDA 必定需要 cgo；而若要使用 cgo，则需做出大量权衡。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此，解决方案是将 CUDA 相关代码嵌套于构建标记 cuda 中，以这样的方式默认未使用 cgo（好吧，只用了一点点，你仍然可以使用 cblas 或 blase）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;安装 CUDA toolkit 8.0 的原因是：存在许多 CUDA 计算能力，为它们生成代码将产生一个毫无益处的巨大二进制。相反，用户会倾向于为他们特定的计算能力编译。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，要求制定使用 CUDA 操作的明确规范，是由于 cgo 调用的成本问题。目前为了实现批量的 cgo 调用而在进行额外的努力，但是直到完成之前，该解决方案都会是特定操作的「升级」关键。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;CUDA 支持的操作&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;迄今为止，只有极基本的简单操作能够支持 CDUA：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;元素一元运算：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;abs&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;sin&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;cos&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;exp&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;ln&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;log2&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;neg&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;square&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;sqrt&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;inv (reciprocal of a number)（数字的倒数）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;cube&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;tanh&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;sigmoid&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;log1p&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;expm1&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;softplus&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;元素二进制操作&amp;mdash;&amp;mdash;只有算术运算支持 CUDA：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;add&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;sub&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;mul&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;div&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;pow&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;根据对作者个人项目的大量剖析，发现真正重要的是 tanh、sigmoid、expm1、exp 和 cube，即激活函数。其他使用 MKL + AVX 的操作正常运行，且并非造成神经网络缓慢的主因。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;CUDA 的改进&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在一项次要的基准测试中，CUDA 的谨慎使用（此情况通常调用 sigmoid）显示出非 CUDA 代码的大幅改进（考虑到 CUDA 内核十分朴素且未优化）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;code style=" box-sizing: border-box; ; ; ; ; ; ; ; ; ; ; ; ; ; "&gt;&lt;span&gt;BenchmarkOneMilCUDA-8 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;300 &amp;nbsp; &amp;nbsp; &amp;nbsp; 3348711 ns/op
BenchmarkOneMil-8 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 50 &amp;nbsp; &amp;nbsp; &amp;nbsp;33169036 ns/op&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;API 的稳定性&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Gorgonia 的 API 如今并不稳定，它将从 1.0 版本开始慢慢稳定。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1.0 版本是测试覆盖率达到 90％时所定义的，并且相关的 Tensor 方法已经完成。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;路线图&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是依照重要性排序所列出的 Gorgonia 的目标：&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: circle;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;80％以上的测试覆盖率。目前 Gorgonia 的覆盖率为 50％，tensor 为 80％。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;更高级的操作（如 einsum）。目前的 Tensor 操作符非常原始。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;软件包中的 TravisCI。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;软件包中的 Coveralls。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: circle;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;清除测试。测试是多年积累的结果，妥当地重构它们将大有裨益。若条件允许，使用表格驱动测试。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;提升性能，特别是应当重新分配，将系统类型的影响最小化。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;将 Op 界面从半输出公开／更改为全输出，以此提高 Op 的可扩展性（或者为扩展性创建一个 Compose 的 Op 类型）。这样每个人都可以制作自定义的 Op。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: circle;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;为了跟随 CUDA 的实现，重构 CuBLAS 以及 Blase 软件包。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;分布式计算。尝试多个机器上传播作业并彼此通信已至少 3 次，但无一成功。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;更好地记录做出某些决定的原因，并从宏观上对 Gorgonia 进行设计。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;高阶导数优化算法（LBFGS）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;无导数的优化算法&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;目标&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Gorgonia 的主要目标是成为一个基于机器学习/图形计算，能够跨多台机器进行扩展的高性能库。它应将 Go（简单的编译和部署过程）的呼吁带至机器学习领域。这条路还很漫长，然而我们已然迈出了第一步。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其次要目标是为非标准的深度学习和神经网络相关事物提供一个探索平台，其中包括 neo-hebbian 学习、角切割算法、进化算法等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;显然，由于你在 Github 上阅读的可能性最大，Github 将构建该软件包工作流程的主要部分以完善该软件包。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;参见：CONTRIBUTING.md&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;贡献者与重要贡献者&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们欢迎任何贡献。但还有一类新的贡献者，称为重要贡献者。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;重要贡献者是对库的运作方式和/或其周围环境有深刻理解的人。此处举出重大贡献者的例子：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;撰写了大量与特定功能／方法的原因／机制，及不同部分相互影响的方式的有关文档&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;编写代码，并对 Gorgonia 更复杂的连接的部分进行了测试&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;编写代码和测试，并且至少接受 5 个拉取请求&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;对软件包的某些部分提供专家分析（比如你可能是优化一个功能的浮点操作专家）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;至少回答了 10 个支持性问题&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;重要贡献者列表将每月更新一次（如果有人使用 Gorgonia）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;如何获得支持&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如今最好的支持方式，便是在 Github 上留言。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;常见问题&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为什么在测试中似乎出现了 runtime.GC() 的随机调用？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;答案非常简单：软件包的设计使其以特定的方式使用 CUDA：具体而言，一个 CUDA 设备及其景况会绑定一个虚拟内存，而不是软件包。这意味着对于每个创建的虚拟内存，其每一设备每一个虚拟内存都会创建不同的 CUDA 景况。因此在其他可能正在使用 CUDA 的应用程序中，所有操作都能够正常运行（然而这需要进行压力测试）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;CUDA 的景况只有在虚拟内存回收垃圾（经由终结器函数的帮助）时才会被销毁。在测试中大约会创建 100 个虚拟内存，并且大多数垃圾回收是随机的；当景况被使用过多时，会导致 GPU 内存耗尽。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此，在任何可能使用 GPU 的测试结束时，会调用 runtime.GC() 来强制垃圾回收，以释放 GPU 内存。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人们在生产过程中不太可能启动过多的虚拟内存，因此这并不是问题。若有问题，请在 Github 上留言，我们会想办法为虚拟内存添加一个 Finish() 方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;许可&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Gorgonia 根据 Apache 2.0 的变体授权。其所有意图与目的 Apache 2.0 的许可相同，除了重要贡献者（如软件包的商业支持者），其他人均不能直接从中获得商业利润。但从 Gorgonia 的衍生直接获利是可行的（如在产品中使用 Gorgonia 作为库）。所有人都可将 Gorgonia 用于商业目的（如用于业务软件）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;各类其他版权声明&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是在写 Gorgonia 的过程中有所启发和进行改编的软件包和库（使用的 Go 软件包已经在上文做出了声明）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/bf9708268494f15bb58125b7b38074bf4a45d9d6"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;span&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Tue, 28 Feb 2017 12:17:03 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 帮助视觉障碍者浏览社交网络，Facebook如何将用户反馈整合进人工智能系统？</title>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650723729&amp;idx=4&amp;sn=2d53dda8658809c4cb2a29a4a96ff9ca&amp;chksm=871b11efb06c98f945532dc5a77e89aca3f8122d25ff16dba52b4a84c479657dab6690ee05c8&amp;scene=0#rd</link>
      <description>
&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自research.facebook&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Julie Schiller 等&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀、微胖、曹瑞、黄小天&lt;br&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Automatic Alt-Text 服务让盲人可以更好地理解他们的动态消息（News Feeds）中的照片。用户通过采访、可用性测试和调查等研究而协助了对这一工具的开发。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你对这项成果感兴趣，可在本周在波特兰的 CSCW 2017 上与相关开发者联系讨论，本研究的主要作者、数据科学家 Shaomei Wu 将会在会上呈现相关的研究细节。此外，机器之心还曾编译过 Facebook 官方发布的另一篇相关的技术解读文章&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722844&amp;amp;idx=2&amp;amp;sn=b15ce8f19792e3ca2f7395a327cd1aae&amp;amp;chksm=871b1662b06c9f7409b2d5de918dc808a330e7f0135dd90240d8b8eace85e5cc54f18e432568&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722844&amp;amp;idx=2&amp;amp;sn=b15ce8f19792e3ca2f7395a327cd1aae&amp;amp;chksm=871b1662b06c9f7409b2d5de918dc808a330e7f0135dd90240d8b8eace85e5cc54f18e432568&amp;amp;scene=21#wechat_redirect" target="_blank"&gt;《深度 | 详解 Facebook 全新图像识别系统：无需依赖标记的自由搜索》&lt;/a&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;背景&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你也知道，你的 Facebook 动态消息常常排满了你的好友分享的图片和视频。手机上高品质相机越普及，人们分享的图片和视频就会越多。能够观看和讨论视觉媒体的内容一直是 Facebook 的一个关键组成。实际上，每天在 Facebook、Instagram、Messenger 和 WhatsApp 上分享的照片多达 20 亿张。听起来很赞吧？但并不是每个人都会这样想。对于那些有视觉障碍（比如：失明）的人来说，他们很难围绕一张图片来展开对话。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Facebook 的使命是创造一个更加开放和互联的世界，并赋予人们分享的能力。在整个世界，有大约 3900 万人是盲人，有超过 2.46 亿人有严重的视觉障碍。据报道，因为他们无法充分地参与到围绕图片和视频的对话中，他们会产生沮丧感和疏离感和被孤立排斥的感觉。为了让更多人参与到查看照片方面的社交活动中，Facebook 推出了 Automatic Alt-Text（AAT），让屏幕阅读器的用户也能够理解其动态消息中的大多数照片的内容（期待很快就能阅读所有照片）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/95ec7a0a2e3ce928a1e4f9a3ce0fa7d7fae543f1"/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;过去是什么，现在又怎样？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;应该从哪里开始来解决这个难题？对于这个计算机视觉模型之下 AAT 和 Lumos 技术的创造请参阅&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722844&amp;amp;idx=2&amp;amp;sn=b15ce8f19792e3ca2f7395a327cd1aae&amp;amp;chksm=871b1662b06c9f7409b2d5de918dc808a330e7f0135dd90240d8b8eace85e5cc54f18e432568&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722844&amp;amp;idx=2&amp;amp;sn=b15ce8f19792e3ca2f7395a327cd1aae&amp;amp;chksm=871b1662b06c9f7409b2d5de918dc808a330e7f0135dd90240d8b8eace85e5cc54f18e432568&amp;amp;scene=21#wechat_redirect" target="_blank"&gt;《深度 | 详解 Facebook 全新图像识别系统：无需依赖标记的自由搜索》&lt;/a&gt;。本文我们将关注我们如何通过与盲人用户合作来为他们创造出色的用户体验。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从之前的研究中我们了解到，一些服务会使用定制化的服务（或使用好朋友）来描述照片，用户需要为每一张想要了解的照片提出请求。不幸的是，这种方法存在一些问题：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;速度太慢&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;需要其他人在场，而且他愿意接受这个任务&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;会打断使用动态消息的流动性&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;可能最重要的：难以大规模应用&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而，这种方式也有好的一面。一位朋友或一位代表为你翻译照片的准确度是非常高的。朋友还能根据你们的关系给出额外的语境信息（比如，增加描述的色彩或说一个你们才懂的笑话）。但是这种解决方案能够在扩展的同时还能避免那些缺陷吗？我们的目标是创造一种新的 Facebook 功能，使其成为这类思想的下一代革命。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;AAT 项目的目标是以一种大规模、无延迟的方式来通过算法生成有用且准确的照片描述。我们以 image alt-text 的方式提供这些描述，这是一种为文本替代图像的内容管理而设计的 HTML 属性。因为 alt-text 是 W3C 可访问性标准的一部分，所以当人们将任何屏幕阅读器软件上的阅读光标移动到一张图像上时，该阅读器就可以抓取其 alt-text 然后将其朗读出来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;研究&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了构建一个可扩展的人工智能系统，我们用了 10 个月的时间完成了 2 种类型的研究。我们在 Shaomei Wu 设计的原型上进行了定性调查和可用性测试。这些定性环节有助于找出这种系统的关键问题，从而让我们可以进行一些修改，得到让人惊喜和感激的结果，而不是最终让人失望和困惑。我们用于确定我们的发现的另一个方法是推出一个实验性版本，告知人们我们会为他们发布一些实验性的功能，然后对他们进行一些和没有使用这些实验功能的用户（我们的对照组）一样的调查。这两组都来自于 VoiceOver Facebook iOS 用户。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;访谈 &amp;amp; 可用性测试&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;正如我们在这个过程中了解到的一样，最大的难题是在人们想要了解其消息流中关于图像的更多信息的愿望与这些信息的质量和社会智能之间找到平衡。对视觉内容的解读可能是非常主观的，而且可以也很依赖于语境。比如说，尽管人们基本上关心的是照片中有什么人以及他们在做什么事，但有时候关于这张照片的背景才是有意思的或重要的。对于我们最终组织读给人们听的句子方面，这是一个关键的发现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此外，让人来寻找一张照片中最有意思的地方是一个相当微不足道的任务，但对机器而言，即使最智能的人工智能也会感到相当困难。想让这项服务的体验优质，必须要了解照片的社会背景以及确定合适的反馈量，我们希望最终能达成这一目标！根据我们的访谈，我们发现比起丢下我们不确定的项不管，给出图片的错误信息实际上会更加糟糕。比如说，如果该服务说一张照片中有一个小孩，而实际上那却是一个个子很小的女子。我们也思考了其它公司的人工智能系统出现严重错误的地方，比如误将人类识别为动物，这可能会导致所有人都不愿看到的情况。如果该用户不知道该朋友没有孩子，那么他就可能会给出会导致难堪和社交尴尬的评论。在与开发团队的合作中，我们一直牢记这一点，并对我们要创造的系统有以下要求：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;能大规模地识别内容&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;能从照片中选取用户感兴趣的概念和事物&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;能为用户提供有意义的反馈&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;能提供无缝交互的感觉&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在定性环节，最后一个大的教训就是：在人工智能确定图片中的内容时，不要谈论把握有多大，这很重要。从参与者那里，我们得知这会让系统感觉起来像机器人或者不吉利。还会慢慢让用户不信任该系统。这里，我们做出了修改，让系统可以对图片中的内容达到极度确信状态（高于某个人工智能准确度阈值标准）。我们也很快去除了复述人工智能评级的确定性（用来确定每个图片中的内容）的机器人特性。尽管将准确性的指标抬得更高了，但是，在识别所有传到 Facebook 中的图片中的某个内容时，准确率也仅是超过 50%。这个数字会随着技术的不断改进而日趋增高。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;总之，在参与者们的非常有用的帮助下，关于如何采访那些想要分享一些定性研究小技巧的盲人，我们学习到了很多。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个简单的经验就是要有盲人参与者携带他们自己的设备。这会让他们在研究中感觉更加舒服自然（在对任何参与者来说这都是非常好的一个技巧），但同时也要允许他们对他们自己携带的辅助设备进行预配置。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一个技巧是让屏幕阅读器的使用者将语速调慢一点，这样你就能跟着进行出声思考。用很多的方式进行出声思考是参与者将屏幕阅读器中的读出的东西解释出来的方法。如果你跟不上这两者（参与者和阅读器的声音），就会丢失一半的数据。在你开始之前，就尝试使用屏幕阅读器，这样你才能成为一名更加高效的主持。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，一些研究人员表示，仅仅是招募屏幕阅读器用户就很难，因为很多 UX Recruiters 并不熟悉这一类人群。我们发现和宣传组织（advocacy groups，比如，Lighthouse）合作或者联系专门的招募单位寻找参与者是很有效的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;调查&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在深度定性理解的帮助下，我们为了描绘一个更全、更泛化的 AAT 使用反馈而转向了调查。我们调查了 550 名具有轻度视觉损害或全盲的参与者。如上所述，我们收到了来自控制组（通常是 Facebook）或 AAT（实验组）的更新版本的 Facebook 的反馈，总样本大约 9000。参与者填写了几乎相同的调查，调查涉及了很多问题，唯一区别是如果参与者来自实验组，有几个问题是专门为 AAT 准备的。参与者还有机会参加抽奖活动并获得一张价值 100 美元的亚马逊礼物卡。与任何调查书写一样，针对目标受访者创建最为简洁、易于理解的调查至关重要。我们就创建针对盲人用户的调查提出了一些实际的建议：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;避免使用横向单选按钮，以及拖／放问题。前者比垂直选项更难以分页，后者则对屏幕使用者来说根本不可能。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;避免使用矩阵和星级评分问题，前者不总是在 HTML 旁边被正确标记，使得在矩阵中识别应答者变的不可能；后者应该被替换为非图形 HTML 元素以使不同的屏幕阅读器可以更通用地访问。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;为屏幕阅读器用户提供返回功能，因为无意的错误会更频繁地发生。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;做一项关于屏幕阅读器的调查比调查一个视力正常的用户通过鼠标使用 OS 更费时一点。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如果屏幕阅读器用户响应你的调查对你来说很重要，那么让屏幕阅读器的用户首先进行导航，这可能很重要。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;与传统的优秀调查设计一样，尽量在每页之中仅包含少量问题，以避免出现认知复杂化和导航问题。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;使用间距，确保单选按钮和复选框与其标签清楚相关，以防止模糊和混乱。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;首字母缩略词和缩写在调查中很常见。然而并不是所有的受访者都会熟悉或记住它们，屏幕阅读器可能难以读出首字母缩略词和缩写。虽然「acronym」和「abbr」标签可以缓解这一点，并且「标题」属性可以在需要时提供进一步的信息。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;调查／试验发现：亮点&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;测试组中的人对该 AAT 功能评价不错。这是通过与没有开启这一功能的控制组的比较而得出的结论。总体而言，测试组的参与者更有可能做以下事情：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;给他们的动态消息中的照片点赞或回复&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;相对于非 AAT 用户，认为 Facebook 更关心辅助功能&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;相对于非 AAT 用户，认为总体而言 Facebook 更有用&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;最重要的是，可以更容易地明白照片中的内容&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;来自调查的样本问题：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们让 AAT 用户确认在动态消息中一旦点击了一张图片是否会听到一句话。如果他们确实听到了以「图片可能包含&amp;hellip;」开始的一句话，接着我们会问一些问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;问题：（如果在测试组）听到这个替换文本你有什么感受（检查所有使用）？&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;测试组中的受访者被展示了一个随机分类的词集帮助他们描述听到图片之中的替换文本的感受。我们还启用了其他方法帮助受访者写下他们的想法。根据调查结果，我们发现受访者更强调积极词汇：快乐（29%）、惊喜（26%）和印象深刻（25%）分别排在前三名。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;问题：回想一下动态消息中你还记得的最后几张照片，以回答这个页面上的问题。对于那些照片，描述照片关于什么的难／易程度是多少？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「还算容易」与「很难」的答案有很大不同，前者是 23% 与 2%，后者是 42% 与 73%。这表明 AAT 提供了额外价值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/509aeec899d2f2f51019314b05f77c9fe4d9792d"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;接下来呢？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这项研究还处在婴儿期，有关改善建议主要关注以下两类问题：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;从图片中识别和提取文本（29% 推荐这个功能）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;就图片中的人物提供更多的细节（26% 推荐这个功能）&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其它要求包括扩大该算法的词汇，增加既有标签的重新调用，可以在更多语言以及平台语境下用到 AAT 等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;原文链接：https://research.fb.com/accessibility-research-developing-automatic-alt-text-for-facebook-screen-reader-users/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;span&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Tue, 28 Feb 2017 12:17:03 +0800</pubDate>
    </item>
    <item>
      <title>学界 | 日本研究者提出新算法：让机器人通过多模态深度强化学习获得社会智能</title>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650723729&amp;idx=5&amp;sn=ab594ca1178aadd40f4dd5877e4c48d2&amp;chksm=871b11efb06c98f991e3b81a6c4d92564e7e658b4ea0a8f4d1e5b5f1106959c7d1489ed1c81f&amp;scene=0#rd</link>
      <description>
&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自arXiv.org&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们一直在期待机器人能在我们的日常生活中发挥重要的作用，而作为机器人强国的日本也一直是这一领域的领导者之一。近日，日本大阪大学和日本科学枝术振兴机构（JST）ERATO ISHIGURO 共生人机交互项目（Symbiotic Human-Robot Interaction Project）的研究者在 arXiv 提交了一篇论文，介绍了他们在机器人的社会智能上的研究成果。另外值得一提的是，他们的实验用到了著名的 Pepper 机器人。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/f5fd3ea78f63af4e7c8202052ad854e06028eed3"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;摘要&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;要让机器人与人类在类似我们社会那样的社会世界中共存，它们需要掌握类似人类的社交技能，这是很关键的。通过编程的方式来让机器人掌握这些技能是很艰难的。在这篇论文中，我们提出了一种多模态深度 Q 网络（MDQN：Multimodal Deep Q-Network），可以让机器人通过试错的方法来学习类似人类的交互技能。这篇论文的目标是开发能够在与人类的交互过程中收集数据并且能够使用端到端的强化学习从高维度传感信息中学习人类交互行为的机器人。本论文表明，机器人在经过了与人类的 14 天交互之后，可以成功学会基本的交互技能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/f4b9278736b46500fd1d28f02a2779a91a555759"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;图 1：机器人向人学习社交技能&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;算法介绍&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里提出的算法由两个独立工作的流组成：一个用于处理灰度帧（grayscale frame），另一个用于处理深度帧（depth frame）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面的 Algorithm 1 概述了这个算法。因为该模型有两个流，因为其参数 &amp;theta; 和 &amp;theta;- 是由两个网络的参数构成的。和 DQN [10] 不同，我们将数据生成阶段和训练阶段分开了。每一天的实验都对应于一个 episode，在这期间，算法要么执行数据生成阶段，要么执行训练阶段。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/8c773a67a1e0877c3b3c0f3bc908340fd201f4da"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;本研究所提出的算法的伪代码&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以下是这两个阶段的简述：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据生成阶段（data generation phase）：在数据生成阶段，系统使用 Q 网络 Q(s, a; &amp;theta;) 来与其环境进行交互。该系统会观察当前场景（由灰度帧和深度帧构成），并使用 &amp;epsilon;-greedy 策略来采取行动。该环境又会反过来提供标量的奖励（reward）（请参阅 5(2) 节了解奖励函数的定义）。交互经历是&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/d12e8a240b4e1553a494dee9a05f73a9bef8ea6c"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其被存储在重放记忆 M 中。重放记忆 M 会保存 N 个最近的经历，然后这些经历会在训练阶段被用于更新该网络的参数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;训练阶段（training phase）：在训练阶段，该系统会利用存储在重放记忆 M 中的数据来对网络进行训练。超参数 n 表示经历重放的数量。对于每一次经历重放，都会从有限大小的重放记忆 M 中随机采样出一个包含 2000 次交互经历的迷你缓存器 B。该模型会在从缓存器 B 中采样出的 mini batch 上进行训练，该网络的参数会在 bellman targets 的方向上迭代式地更新。这个对重放记忆的随机采样会打破样本之间的相关性，因为标准的强化学习方法假定样本是独立的且完全分布式的。将该算法分成两个阶段的原因是为了避免延迟&amp;mdash;&amp;mdash;如果该网络在交互期间同时进行训练就会产生这种延迟。该 DQN [16] 代理在一个循环中工作，其中它首先会与环境进行交互，然后会将这个转变存储到重放记忆中，然后其会从该重放记忆中采样出 mini batch，并在这个 mini batch 上训练该网络。这个循环会不断重复，直到终止。这个交互和训练的顺序过程在 HRI 之外的领域也许是可以接受的。在 HRI 领域，代理必须基于社会规范来和人类进行交互，因此机器人的任何停顿和延迟都是不可接受的。因此，我们将该算法分成了两个阶段：在第一个阶段，机器人通过与人类进行有限时间的交互来收集数据；在第二个阶段，其进入阶段。在这个休息阶段，训练阶段激活从而对该多模态深度 Q 网路（MDQN）进行训练。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;实现细节&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个模型由两个流（stream）构成，一个用于灰度信息，另一个用于深度信息。这两个流的结构是完全相同的，每个流都由 8 个层组成（包括输入层）。整体模型架构如图 2 所示。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/8d0458a9ec1b73461b9552d792889625632f720f"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;图 2：双流式卷积神经网络&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该多模态 Q 网络的 y 信道和 depth 信道的输入分别是灰度图像（198 &amp;times; 198 &amp;times; 8）和深度图像（198 &amp;times; 198 &amp;times; 8）。因为每个流都使用 8 帧输入，因此，来自对应相机的最新的 8 帧是被预处理后堆叠到一起，构成该网络的每个流的输入。因为这两个流是完全一样的，所以我们在这里只讨论一个流的结构即可。198 &amp;times; 198 &amp;times; 8 的输入图像首先被传递给第一个卷积层（C1），其以 3 的步幅卷积计算 9&amp;times;9 的 16 个滤波器，后面则跟着一个整流线性单元（ReLU）函数并得到每个大小为 64&amp;times;64 的 16 个特征图（我们将其记为 16@64&amp;times;64）。这个来自 C1 的输出然后会被送入下采样层 S1，其以 2&amp;times;2 的步幅应用 2&amp;times;2 的最大池化（max-pooling）。第二（C2）和第三（C3）个卷积层分别卷积计算 32 和 64 个滤波器，其大小为 5&amp;times;5，使用了 1 的步幅。C2 和 C3 的输出通过非线性 ReLU 函数，然后分别被送入下采样层 S2 和 S3。最后的隐藏层是带有 256 个整流单元的全连接层。输出层则是一个全连接的线性层，带有 4 个单元，每一个单元对应一个合法动作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/44c6d63111c4bc660edb45d67a6a12af08e3560d"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;图 3：成功和不成功的握手示例&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/902d1dd9f18ce558d1703cd2e645314610c72693"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;图 4：在经过了一系列的 episode 之后，MDQN 在测试数据集上的表现&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;论文链接：https://arxiv.org/abs/1702.07492&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;span&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Tue, 28 Feb 2017 12:17:03 +0800</pubDate>
    </item>
    <item>
      <title>经验之谈：如何为你的机器学习问题选择合适的算法？</title>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650723704&amp;idx=1&amp;sn=5e791710b46502661e25ff6f7528003b&amp;chksm=871b1106b06c98107174c81401c1f7017b35939ab20bc83b305ecae8b503690518fd32d75bbd&amp;scene=0#rd</link>
      <description>
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自askaswiss&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Michael Beyeler&amp;nbsp;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：王宇欣、吴攀 、邵明&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随着机器学习越来越流行，也出现了越来越多能很好地处理任务的算法。但是，你不可能预先知道哪个算法对你的问题是最优的。如果你有足够的时间，你可以尝试所有的算法来找出最优的算法。本文介绍了如何依靠已有的方法（模型选择和超参数调节）去指导你更好地去选择算法。本文作者为华盛顿大学 eScience Institute 和 Institute for Neuroengineering 的数据科学博士后 Michael Beyeler。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/82662eaa74cd42c11c4067f2cf98904b0f6dafbc"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;步骤 0：了解基本知识&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在我们深入学习之前，我们先重温基础知识。具体来说，我们应该知道机器学习里面三个主要类别：监督学习，无监督学习和强化学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/604ad1d707eb18fc658c47d3cf066fc5572c6992"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在监督学习（supervised learning）中，每个数据点都会获得标注，如类别标签或与数值相关的标签。一个类别标签的例子：将图片分类为「猫」或「狗」；数值标签的例子如：预测一辆二手车的售价。监督学习的目的是通过学习许多有标签的样本，然后对新的数据做出预测。例如，准确识别新照片上的动物（分类）或者预测二手车的售价（回归）。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在无监督性学习（unsupervised learning）中，数据点没有相关的标签。相反，无监督学习算法的目标是以某种方式组织数据，然后找出数据中存在的内在结构。这包括将数据进行聚类，或者找到更简单的方式处理复杂数据，使复杂数据看起来更简单。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在强化学习（reinforcement learning）中，算法会针对每个数据点来做出决策（下一步该做什么）。这种技术在机器人学中很常用。传感器一次从外界读取一个数据点，算法必须决定机器人下一步该做什么。强化学习也适合用于物联网应用。在这里，学习算法将收到奖励信号，表明所做决定的好坏，为了获得最高的奖励，算法必须修改相应的策略。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;步骤 1：对问题进行分类&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;接下来，我们要对问题进行分类，这包含两个过程：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;根据输入数据分类：如果我们的数据有标签，这就是一个监督学习问题；如果数据没有标签而且我们想找出数据的内在结构，那这就是无监督学习；如果我们想通过与环境交互来优化目标函数，这是强化学习。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;根据输出结果分类：如果模型输出结果是一个数值，这是回归问题；如果输出结果是一个类别，这是分类问题；如果输出结果是一组输入数据，那这是聚类问题。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;就是这么简单！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;更一般地说，我们可以询问我们自己：我们的算法要实现什么目标，然后以此来找到正确的算法类别。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/c3e65b5eccdce6391fee2a1d42ad6d874221d2d4"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;上面的描述包括了几个我们还没有提到的专业术语：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;分类（classification）：当使用数据来预测类别时，监督学习也被叫做分类。比如将含有「猫」或「狗」的图片识别出来，分类为「猫」或「狗」，这就是二分类问题（two-class or binomial classification）。当存在更多类别时（例如预测下一届诺贝尔物理学家的获得者是谁），这就是所谓的多分类问题（multi-class classification）。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;回归（regression）：当要预测数值时（比如预测股价），监督学习也被称为回归。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;聚类（clustering）：聚类或聚类分析（cluster analysis）是无监督学习中最常见的方法之一。聚类是将一组对象以某种方式分组，使得同一组中的数据比不同组的数据有更多的相似性。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;异常检测（Anomaly detection）：有时我们需要找出数据点中的异常点。例如，在欺诈检测中，任何极不寻常的信用卡消费都是可疑的；欺诈具有大量不同的形式，而训练样本又非常少，使得我们不可能完全了解欺诈活动应该是什么样。异常检测所采取的方法就是了解正常情况下的表现行为（使用非欺诈交易的历史数据），并识别出显著不同的表现行为。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;步骤 2：寻找可用的算法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在我们已经将问题进行了分类，我们就可以使用我们所掌握的工具来识别出适当且实用的算法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Microsoft Azure 创建了一个方便的算法列表，其展示了哪些算法可用于哪种类别的问题。虽然该表单是针对 Azure 软件定制的，但它具有普遍的适用性（该表单的 PDF 版本可查阅 http://suo.im/3Ss2zW )：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/8c6bcd4e8399e43604ea97ff7a8b3e9e5a255e82"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一些值得注意的算法如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: circle;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;分类：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;支持向量机（SVM）可用于找到尽可能宽的分类的边界。当两个分类不能被清楚地分开时，该算法会找到其所能找到的最佳边界。其真正的亮点在于处理特征密集的数据，比如文本或者基因组（特征数量&amp;gt; 100）。在这些情况下，除了仅需要适量的记忆外，支持向量机（SVM）能够比其它大多数算法更快且更少过拟合地进行分类。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;人工神经网络是涵盖二分类、多分类和回归问题的脑启发式学习算法。它们有无限的种类，包括感知器和深度学习。它们需要很长时间来训练，但已知其在多种应用领域都实现了当前最佳的表现。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;logistic 回归：即便名字中有着「回归」，但 logistic 回归实际上是一种可用于二分类和多分类问题的强大工具。它快速且简单。事实上，它使用「S」形曲线而非直线，所以它自然适合用于数据分组。logistic 回归可以给出线性分类边界，所以如果你要使用它，你一定要确保你能接受线性的近似。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;决策树和随机森林：决策森林（decision forests）（回归、二分类、多分类），决策丛林（decision jungles）（二分类和多分类）和提升决策树（boosted decision trees）（回归和二分类）都基于决策树。这是一个基本的机器学习概念。决策树有许多不同的变体，但它们都在做同样的事情&amp;mdash;将特征空间（feature space）细分为具有大致相同标签的区域。这些区域可以是一致的类别或者恒定值，具体取决于你进行的是分类还是回归。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: circle;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;回归：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;线性回归是将一条线（或平面、或超平面）拟合到一个数据集上。这是一种主要的工具，简单且快速，但对于一些问题而言，它可能过于简单。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;贝叶斯线性回归有着非常理想的特性：它可以避免过拟合。贝叶斯方法通过事先对答案的可能分布做出一些假设来做到这一点。这种方法的另一个副产品是它们具有非常少的参数。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;提升决策树回归（Boosted decision tree regression）：如上所述，提升决策树（回归和二分类）均基于决策树，并通过将特征空间细分为具有大致相同标签的区域发挥效用。提升决策树通过限制其可以细分的次数以及每个区域中所允许的最少数据点来避免过拟合。该算法会构造一个树的序列，其中每棵树都会学习弥补之前的树留下来的误差。这能得到一个会使用大量的内存的非常精确的学习器。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: circle;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;聚类：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;层次聚类（Hierarchical Clustering）的目标是构建聚类的层次结构，它有两种形式。聚集聚类（agglomerative clustering）是一种「自下而上」的方法，其中每个观察（observation）在其自己的聚类中开始，随着其在层次中向上移动，成对的聚类会进行融合。分裂聚类（divisive clustering）则是一种「自上而下」的方法，其中所有的观察都从一个聚类开始，并且会随观察向下的层次移动而递归式地分裂。整体而言，这里的融合和分裂是以一种激进的方式确定的。层次聚类的结果通常表示成树状图（dendrogram）的形式。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;k-均值聚类（k-means clustering）的目标是将 n 组观测值分为 k 个聚类，其中每个观测值都属于其接近的那个均值的聚类&amp;mdash;&amp;mdash;这些均值被用作这些聚类的原型。这会将数据空间分割成 Voronoi 单元。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: circle;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;异常检测：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;k 最近邻（k-nearest neighbors / k-NN）是用于分类和回归的非参数方法。在这两种情况下，输入都是由特征空间中与 k 最接近的训练样本组成的。在 k-NN 分类中，输出是一个类成员。对象通过其 k 最近邻的多数投票来分类，其中对象被分配给 k 最近邻中最常见的类（k 为一正整数，通常较小）。在 k-NN 回归中，输出为对象的属性值。该值为其 k 最近邻值的平均值。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;单类支持向量机（One-class SVM）：使用了非线性支持向量机的一个巧妙的扩展，单类支持向量机可以描绘一个严格概述整个数据集的边界。远在边界之外的任何新数据点都是非正常的，值得注意。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;步骤 3：实现所有适用的算法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于任何给定的问题，通常有多种候选算法可以完成这项工作。那么我们如何知道选择哪一个呢？通常，这个问题的答案并不简单，所以我们必须反复试验。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;原型开发最好分两步完成。在第一步中，我们希望通过最小量的特征工程快速且粗糙地实现一些算法。在这个阶段，我们主要的目标是大概了解哪个算法表现得更好。这个步骤有点像招聘：我们会尽可能地寻找可以缩短我们候选算法列表的理由。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一旦我们将列表减少至几个候选算法，真正的原型开发开始了。理想情况下，我们会建立一个机器学习流程，使用一组经过仔细选择的评估标准来比较每个算法在数据集上的表现。在这个阶段，我们只处理一小部分的算法，所以我们可以把注意力转到真正神奇的地方：特征工程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;步骤 4：特征工程&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;或许比选择算法更重要的是正确选择表示数据的特征。从上面的列表中选择合适的算法是相对简单直接的，然而特征工程却更像是一门艺术。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;主要问题在于我们试图分类的数据在特征空间的描述极少。利如，用像素的灰度值来预测图片通常是不佳的选择；相反，我们需要找到能提高信噪比的数据变换。如果没有这些数据转换，我们的任务可能无法解决。利如，在方向梯度直方图（HOG）出现之前，复杂的视觉任务（像行人检测或面部检测）都是很难做到的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然大多数特征的有效性需要靠实验来评估，但是了解常见的选取数据特征的方法是很有帮助的。这里有几个较好的方法：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;主成分分析（PCA）：一种线性降维方法，可以找出包含信息量较高的特征主成分，可以解释数据中的大多数方差。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;尺度不变特征变换（SIFT）：计算机视觉领域中的一种有专利的算法，用以检测和描述图片的局部特征。它有一个开源的替代方法 ORB（Oriented FAST and rotated BRIEF）。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;加速稳健特征（SURF）：SIFT 的更稳健版本，有专利。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;方向梯度直方图（HOG）：一种特征描述方法，在计算机视觉中用于计数一张图像中局部部分的梯度方向的 occurrence。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;更多算法请参考：https://en.wikipedia.org/wiki/Visual_descriptor&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然，你也可以想出你自己的特征描述方法。如果你有几个候选方法，你可以使用封装好的方法进行智能的特征选择。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: circle;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;前向搜索：&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;最开始不选取任何特征。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;然后选择最相关的特征，将这个特征加入到已有特征；计算模型的交叉验证误差，重复选取其它所有候选特征；最后，选取能使你交叉验证误差最小特征，并放入已选择的特征之中。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;重复，直到达到期望数量的特征为止！&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: circle;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;反向搜索：&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;从所有特征开始。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;先移除最不相关的特征，然后计算模型的交叉验证误差；对其它所有候选特征，重复这一过程；最后，移除使交叉验证误差最大的候选特征。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;重复，直到达到期望数量的特征为止！&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使用交叉验证的准则来移除和增加特征！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;步骤 5：超参数优化&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，你可能想优化算法的超参数。例如，主成分分析中的主成分个数，k 近邻算法的参数 k，或者是神经网络中的层数和学习速率。最好的方法是使用交叉验证来选择。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一旦你运用了上述所有方法，你将有很好的机会创造出强大的机器学习系统。但是，你可能也猜到了，成败在于细节，你可能不得不反复实验，最后才能走向成功。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文地址：http://www.askaswiss.com/2017/02/how-to-choose-right-algorithm-for-your-machine-learning-problem.html&lt;/span&gt;&lt;/em&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;
</description>
      <pubDate>Mon, 27 Feb 2017 12:07:15 +0800</pubDate>
    </item>
  </channel>
</rss>
