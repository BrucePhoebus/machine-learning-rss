<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>谷歌发布深度学习库TensorFlow Fold，支持动态计算图</title>
      <link>http://www.iwgc.cn/link/4615827</link>
      <description>&lt;div class="article-content"&gt;&lt;section style="white-space: normal; line-height: 28.4444px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="border: 0px currentcolor; font-family: 微软雅黑; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; border-style: solid none; font-family: inherit; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="font-size: 1em; margin-top: -1.2em; min-height: 1em; border: currentcolor; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color:#ffffff"&gt;&lt;span style="background-color: rgb(117, 117, 118);"&gt;选自Google Research&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="background-color: rgb(255, 255, 255); padding: 16px 16px 10px; font-family: inherit; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="color: rgb(62, 62, 62); font-size: 16px; margin-top: 5px; margin-bottom: 5px; min-height: 1em; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(127, 127, 127); font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;作者：Moshe Looks、Marcello Herreshoff、DeLesley Hutchins&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-top: 5px; margin-bottom: 5px; min-height: 1em; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color:#7f7f7f"&gt;&lt;span style="font-size: 12px;"&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="color: rgb(62, 62, 62); font-size: 16px; margin-top: 5px; margin-bottom: 5px; min-height: 1em; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(127, 127, 127); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important; font-size: 12px;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;参与：李亚洲、朱思颖&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style="min-height: 1em; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; text-align: justify; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;br style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;在大部分的机器学习过程中，用于训练 (training) 和推理 (inference) 的数据都需要进行数据的预处理，通过预处理将不同的输入数据（例如图像）规整至相同尺寸并进行批（batch）存储。这一步使高性能的深度学习库，例如 TensorFlow，可以并行的处理批存储中的所有输入，且以相同的计算图（computation graph）进行处理。批处理（Batching）利用现代 GPU 和多核 CPU 的单指令流多数据流（SIMD）性能来加速运算执行。但是，当输入数据的尺寸和结构变化时会产生诸多问题，例如在自然语言理解中的解析树（parse tree）、源代码中的抽象语法树（abstract syntax tree）、网页的文档树（DOM tree）等。在这些情况下，不同的输入数据需要不同的计算图，通常这些计算图不能够批存储在一起，导致处理器、存储器以及缓存利用率低。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;今天我们发布 TensorFlow Fold 来解决这些困难。TensorFlow Fold 使得处理不同数据尺寸和结构的深度学习模型更容易实现。不仅如此，TensorFlow Fold 将批处理的优势赋予这些模型，使得这些模型在 CPU 上的运行速度有超过 10 倍的提升，在 GPU 上的运行有超过 100 倍的提升（相比于其他实现方式）。这一提升来源于动态批存储（dynamic batching）技术，在我们的论文中有详细介绍（Deep Learning with Dynamic Computation Graphs）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1486528552FyXSki.gif"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;以上动图演示了动态批处理运行的递归神经网络。带有同样的颜色的运算聚成一批，这使得 TensorFlow 能够更快的运行它们。Embed 运算将单词转换为向量表征。完全连接（fully connected，FC）运算结合词向量，从而形成段落向量表征。网络的输出是一个完整语句的向量表征。尽管上图只演示了一个语句解析树，但在多种任意形状与大小的解析树上，这个网络同样也能运行并实现批处理运算。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;TensorFlow Fold 库首先会为每个输入建立一个独立的计算图。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;因为单独的输入可能有不同的大小和结构，计算图也可能是这样。动态批处理自动结合这些图，从而获取在输入内以及整个输入进行批处理机会的优势，并且插入额外的指令在批处理操作之间移动数据。（查看技术细节请参考论文）&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;想要了解更多，也可以查看我们的 github 网址：https://github.com/tensorflow/fold。我们希望 TensorFlow Fold 能够帮助研究人员与从业者在 TensorFlow 中部署动态计算的神经网络。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;论文：DEEP LEARNING WITH DYNAMIC COMPUTATION GRAPHS&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1486528553IB0Vnl.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;摘要：在包括自然语言处理（解析树）与化学信息学（分子图）在内的多个领域中，在图结构上进行计算的神经网络是解决问题的天然方式。然而，因为每个输入的计算图有不同的形状与大小，所以网络通常不能直接进行批训练或推断。它们也难以部署到流行的深度学习库中，因为这些库是基于静态数据流图的。我们引入了一种称之为动态批处理（Dynamic Batching) 的技术，它不仅能批处理不同输入图（形状也不类似）之间的运算，也能批处理单个输入图内的不同节点。该技术使得我们能够创造静态图、使用流行的库、模仿任意形状与大小的动态计算图。我们进一步展现了组成区块的高层次库，从而简化了创造动态图模型的过程。使用这一库，我们论证了文献中多种模型的简洁且明智的批处理并行实现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 12px;"&gt;原文链接：https://research.googleblog.com/2017/02/announcing-tensorflow-fold-deep.html&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="min-height: 1em; text-align: justify; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="line-height: 25.6px; font-family: 微软雅黑; font-size: 14px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; color: rgb(127, 127, 127); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="color: rgb(62, 62, 62); line-height: 25.6px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; color: rgb(127, 127, 127); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;©本文由机器之心编译，&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; font-size: 18px; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(127, 127, 127); line-height: 25.6px; font-family: 微软雅黑; text-align: justify; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(217, 33, 66); font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(217, 33, 66); line-height: 1.6; font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-size: 12px; color: rgb(217, 33, 66); line-height: 1.6; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-size: 12px; color: rgb(217, 33, 66); line-height: 1.6; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong style="color: rgb(136, 136, 136); font-family: &amp;#39;Helvetica Neue&amp;#39;; font-size: 14px; white-space: normal;"&gt;点击阅读原文下载论文&lt;/strong&gt;&lt;/p&gt;&lt;/div&gt;</description>
      <pubDate>Wed, 08 Feb 2017 12:09:17 +0800</pubDate>
    </item>
    <item>
      <title>深度 | Facebook官方详解：使用Apache Spark进行大型语言模型训练</title>
      <link>http://www.iwgc.cn/link/4615828</link>
      <description>&lt;div class="article-content"&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;section style="font-size: 16px; white-space: normal; line-height: 28.4444px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="border: 0px currentcolor; font-family: 微软雅黑; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; border-style: solid none; font-family: inherit; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-top: -1.2em; min-height: 1em; font-size: 1em; border: currentcolor; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color:#ffffff"&gt;&lt;span style="background-color: rgb(117, 117, 118);"&gt;选自 Facebook&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="color: rgb(62, 62, 62); background-color: rgb(255, 255, 255); padding: 16px 16px 10px; font-family: inherit; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-top: 5px; margin-bottom: 5px; min-height: 1em; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(127, 127, 127); font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;作者： Tejas Patil、Jing Zheng&amp;nbsp;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-top: 5px; margin-bottom: 5px; min-height: 1em; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(127, 127, 127); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important; font-size: 12px;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;参与：李泽南、高静宜&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style="min-height: 1em; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; text-align: justify; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;br style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/p&gt;&lt;blockquote style="color: rgb(62, 62, 62); font-size: 16px; white-space: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/blockquote&gt;&lt;blockquote&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 12px;"&gt;Apache Spark 是用于大规模数据处理的快速和通用引擎，它运行在 Hadoop，Mesos，可以离线或云端运行，具有高速、可扩展等特点。近年来，在 IBM 等大公司和众多社区贡献者的推动下，Spark 得到了越来越多的应用。今天，Facebook 团队也展示了他们使用 Apache Spark 进行大型语言模型训练的方法。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;如何处理大规模数据是 Facebook 基础设施团队面临的核心问题。随着软件技术的发展，我们面临着越来越高的硬件需求，为了满足需要，我们必须在开源架构上设计并构建新的系统。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;考虑到我们的需求，我们决定使用 Apache Spark，一个快速发展的开源数据处理平台，它可以自由扩展，支持用户自定义应用。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;几个月前，我们分享了一个支持 Spark 声明（SQL）的的例子。在本文中，我们将简要介绍如何使用 Spark 重新设计一个大型、复杂（100 余级）的管道，而这个管道最初是使用 HQL 在 Hive 上编写的。在此之中，我们会介绍如何控制数据分布，避免数据偏移，并实现对特定应用程序的优化，以构建高性能及可靠的数据管道。与原来的 HQL 查询集相比，这种新的基于 Spark 的管道是模块化的，高度可读且易于维护的。除了质量提升之外，我们还观察到它的资源使用和数据登录时间也有减少。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;使用案例：N-gram 语言模型训练&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;自然语言处理是涉及计算机和人类语言之间相互作用的人工智能领域。计算机可以对语言进行建模，此类模型可用于检测和纠正拼写错误。N-gram 语言模型是其中使用最广泛的语言建模方法。N-gram 通常以 N-x 方式呈现，其中前 N-1 个字作为历史，基于 N-1 的历史来预测下一个字。例如，「你能来这里吗（Can you please come here）」包含 5 个单词，是一个 5-gram。它的历史是「你能来吗（Can you please come）」基于这个历史，N-gram 语言模型可以计算出单词「这里。（here.）」的条件概率。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1486528555qiHD53.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;大规模、高阶的 N-gram 语言模型（例如 N = 5）已经被证明在许多应用中非常有效，例如自动语音识别和机器翻译。在 Facebook 中，它被用于为上传到时间线的视频自动生成字幕，探测可能低质量的地址标签（如「家，温暖的家」，「Apt#00，Fake lane，Foo City」）。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;用大数据集训练的语言模型与用较小数据集训练的语言模型相比，前者通常具有更高的准确性。覆盖罕见单词（或 N-gram）充分实例的可能性会随着数据集体量的增大而增加。对于具有较大数据集的训练任务，分布式计算框架（如 MapReduce）通常具有更好的可扩展性，可进行并行化模型训练。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;早期解决方案&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;我们最初开发了一个基于 Hive 的解决方案来生成 N-gram 语言模型。N-gram 计数由最后两个字的历史记录分割，使用基于 C ++的 TRANSFORM 来判断局部语言模型，并将它们保存在 Hive 中。单独的子模型建立在不同的数据源上，每个都由 Hive 查询触发。随后，每个子模型被插值算法计算权重，最后所有子模型被组合输出。以下是管道的概述：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1486528556nfEA10.jpg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&amp;nbsp;基于 Hive 的解决方案在构建语言模型中获得了一定程度的成功：当使用几百万 N-gram 训练时，我们能用它轻松地构建 5-gram 语言模型。然而一旦我们试图增加训练数据集的大小，运行管道的端到端时间就会达到不可接受的程度。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Hive 提供了一个基于 SQL 的引擎，可以轻松地编写查询，这些查询会自动转换为 MapReduce 作业。对于训练语言模型而言，将计算表示为 SQL 查询是不自然的，原因如下：&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;管道代码，包括每个子模型训练的几个 SQL 查询。这些查询大部分是相似的，只有细微的差别。为模型训练而编写新的管道会导致这些 SQL 查询重复。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;当越来越多的子句被添加到查询中时，系统会越来越难以理解查询的意图。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;更改查询的一部分需要重新运行整个管道，以确保不会导致回归。无法测试隔离变化使得开发周期变长。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;作为替代方法，编写 Hadoop 作业在表达计算方面为开发人员提供了更多的自由，但这也需要更多的时间，需要我们具有 Hadoop 的专业知识。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;基于 Spark 的解决方案&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Spark 自带特定领域语言（DSL），使得编写自定义应用程序比 SQL 查询作业更加容易。通过 DSL，你可以控制较低级别的操作（例如，当数据被洗牌时），并且可以访问中间数据。这有助于实现复杂的算法，达到更高的效率和稳定性。它还允许用户能以模块化的方式编写管道，而不是使用一个单一的 SQL 字符串，这提高了管道的可读性，可维护性和可测试性。所有这些优势吸引我们引入了 Spark。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;在 Scala 或 Java 中重现 C ++的逻辑——语言模型训练算法的实现——会是巨量的工作，因此我们决定不更改该部分。和 Hive 一样，Spark 支持运行自定义用户代码，这使得调用相同的 C ++二进制文件变得容易。它允许开发者平滑过渡，因此我们不必同时维护两个版本的 C ++逻辑，而且迁移对用户是透明的。我们使用 Spark 提供的 RDD 接口，没有使用 Spark SQL，因为前者可以控制中间数据的分区并直接管理分片生成。Spark 的 pipe（）运算符用于调用二进制文件。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;在更高层上，管道的设计保持不变。我们继续使用 Hive 表作为应用程序的初始输入和最终输出。中间输出被写入集群节点上的本地硬盘中。整个应用程序大约有 1,000 行的 Scala 代码，并且可以在 Spark 上执行时生成 100 多个阶段（这取决于训练数据源的数量）。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;可扩展性挑战&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;当我们使用更大的训练数据集来测试 Spark 方案时，我们遇到了可扩展性的挑战。在本节中，我们首先介绍数据分布要求（平滑和分割），然后是它带来的挑战和我们的解决方案。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;平滑&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;N-gram 模型是根据训练数据中的 N-gram 出现计数来估算的。由于在训练数据中有可能缺少 N-gram，这种方式可能很难推广到未见的数据中。为了解决这个问题，我们使用了许多平滑方法以减少观察到的 N-gram 计数以提升未见的 N-gram 概率，并使用较低阶模型来让较高阶模型平滑。由于平滑，对于具有历史 h 的 N-gram，需要具有相同历史的所有 N-gram 计数和具有作为 h 的后缀的历史的所有较低级 N-gram 来估算其概率。例如，对于三元组「how are you，」，其中「how are」是历史，「you」是要预测的词，为了估计 P（you|how are），我们需要「how are*」，「are*」和所有 unigram（单字 N-gram）的计数，其中*是表示词汇表中任何单词的通配符。经常会出现 N-gram（例如，「how are*」）导致处理时的数据发生偏移。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;分片&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;通过分布式计算框架，我们可以将 N-gram 计数分割成多片，以便由多个并行机器进行处理。基于 N-gram 历史的最后 k 个单词的分片方式可以保证比 k 更长的 N-gram 在所有片段之间被平衡。这需要在所有分片上共享所有长度为 k 的 N-gram 计数。我们把所有这些短 N-gram 放在一个叫做「0-shard」的特殊分片中。例如，如果 k 是 2，那么从训练数据中提取的所有单字母和双字母会被组合在同一个分片（0- shard）中，并且所有进行模型训练的服务器都可以访问。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;问题：数据扭曲（Data skew）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;在基于 Hive 的管道中，我们使用两个单词的历史分片（two word history sharding) 方式进行模型训练。两词历史分片意味着，共享相同集合的最高有效两词历史（最靠近正被预测的词）的所有 N-gram 计数会被分布到同一节点用于处理。与单字历史相比，两字分片通常具有更平衡的数据分布，除了所有节点必须共享存储在 0-shard 中的平滑算法所需的单字和双字统计。下图说明了具有单字和两字历史的分片分布之间的比较。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1486528556umLH87.jpg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;对于大型数据集而言，两字历史分割会生成巨大的 0-shard。必须向所有节点散布 0-shard 以缩短总计算时间。同时，这种情况还存在潜在的不稳定性，因为很难预测它的内存需求，一旦启动作业，它可能在运行中耗尽内存。虽然我们可以提前分配更多内存，但仍然不能保证 100％的稳定性，而且这会导致集群内存利用率降低，因为并不是所有实例都需要比历史均值更多的内存。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;当我们尝试使用 Spark 后，作业可以在低负载状况下运行。但是对于更大的数据集，我们观察到了以下几个问题：&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;由于执行器长时间没有接收到 heartbeat，驱动程序将执行器标记为「lost」&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;执行器 OOM&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;频繁的执行器 GC&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;随机服务 OOM&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Spark 的 block 存在 2GB 的限制&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;所有这些问题的根本原因可以归结于数据扭曲。我们想要实现分片的均衡分布，但是两词的历史分片和单词历史分片都不能带来均衡。因此，我们提出了一种混合方法：渐进式分片和动态调整分片大小。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;解决方案：渐进式分片（Progressive sharding）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;渐进式分片用迭代的方法来解决数据扭曲（skew）问题。在第一次迭代时，我们首先进行单个字的分片，在这一步的分片中只需要对所有分片（shard）的一元语言模型计数进行分割。一元语言模型计数远少于二元语言模型计数。通常情况下这种处理是可以完成预期作用的，但不包含分片极其大的情况。例如，对应于「how to ...」的分片将会被扭曲。为了解决这个问题，我们核查每个分片的尺寸然后仅处理小于某一阈值的分片。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1486528556a3snPs.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;在第二次迭代时，我们使用二个字的分割，即根据二个字的历史来完成对 N-gram 的分布。在这个阶段，我们只需要向二元语言模型（不包括已在第一次迭代中处理的二元语言模型）共享 N-gram 的计数。这些二元语言模型计数的数目远少于整个的二元语言模型计数数目，因此处理起来也更快。正如上面所说，我们依然核查每个分片的尺寸然后仅处理小于某一阈值的分片。所剩下的分片将会在下一次的迭代中通过三个字历史来处理。在大多数情况下，三次迭代已足以满足非常大数据集的需要。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1486528556mfEz1Z.jpg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;动态调整&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;分片尺&lt;/span&gt;&lt;span style="font-size: 14px;"&gt;寸&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;在第一次迭代里，我们用了一个足够大的预设数，从而使得大部分的生成分片尺寸很小。每一个分片是由单个 Spark 所完成。在这次迭代中 0-shard 的分片是非常小的尺寸，有很多小分片并不会影响处理效率。在后面的迭代中，分片的数目将由 N—gram 的未处理部分所自动产生。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;这些方案能够成功实现归功于 Spark DSL 的灵活性。通过 Hive，开发者们不需要支配这些低级别的运算。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;针对训练模型的通用库&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;根据不同应用环境，怎样使用语言模型呢？每一种应用可能需要不同的数据和配置，因此不同的管道也应运而生。在 Hive 解决方案中，管道的 SQL 部分应用之间是相似的，但在几个地方有不同的单元。相较于重复每一个管道的代码，我们开发了一种可以调用不同管道和不同数据源及配置的普适的 Spark 应用。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;基于 Spark 解决问题时，我们也可以自动地在输入配置的基础上，优化应用程序运行的工作流程中的步骤。比如说，如果用户没有明确指出使用熵修剪算法，那么应用程序将会跳过模型重新评估。如果用户在配置中明确指定了计数截止，那么应用程序将会瓦解许多低计数的 N-grams 并以通配符占位符来减少存储。这些优化组合节省了计算资源，同时可以在更短的时间内产生训练好的模型。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;Spark 管道与 Hive 管道性能的比较&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;我们利用以下性能指标比较 Spark 管道与 Hive 管道：&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;CPU 时间：这是从操作系统的角度衡量 CPU 的使用。比如，如果你在 32 核机上使用所有 CPU 的 50%，以每 10 秒处理一个进程，那么你的 CPU 时间将是 32*0.5*160CPU 秒。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;CPU 保留时间：这是从资源管理框架的角度衡量 CPU 的保留。举个例子，如果我们在 32 核机上保留 10 秒来运行一个任务，那么 CPU 的保存时间是 32*10=320CPU 秒。CPU 时间与 CPU 保留时间的比例反映出我们是如何实现在集群上保留 CPU 资源的。当精确度达到要求时，相较于 CPU 时间，在运行相同的工作负载的条件下，保存时间可以作为一个更好的测量尺度去比较引擎的执行。比如，如果一个运程需要 1CPU 秒去运行但是必须保存 100CPU 秒，那么在完成同样的工作量时，按照这种度量标准，它就比一个需要 10CPU 秒运行且保存 10CPU 秒的运程效率低。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;延迟/屏蔽时间：从结束到结束的工作时间&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;以下图表总结了 Spark 和 Hive 工作的性能比较结果。注意 Spark 的管道不是 Hive 管道 1:1 的转化。它有许多有助于实现更好的可测量性和执行的定制和优化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1486528557hazuWU.jpg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;基于 Spark 的管道可以不费力地多次处理输入数据，甚至输入数据量高于 Hive 的巅峰处理量。例如，我们训练一个较大的语言模型，它可以在几小时内生成一个包含 192 亿 N-grams 的语言模型。能够用更多的数据并更快地运行试验训练的能力可以促使产生更高质量的模型。正如我们在我们自己的试验中观察到的，大规模语言模型通常会在相关的应用中得到更好的结果。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;总结&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Spark 的灵活性可以从以下方面为我们提供帮助：&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;用模块化的方式表达应用逻辑，相较于整体的 SQL 字符串，拥有更强的可读性和可持续性。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;在计算的任何阶段都可以对数据实现自定义处理（例如，分区，重洗）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;高性能的计算机引擎可以节省计算资源和试验时间&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;拥有输入更大规模数据的扩展能力可以训练出高质量的语言模型&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;建立一个通用的应用，可以用于在不同的产品上生成语言模型。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;由于支持运行用户二进制文件（如 Hive's TRANSFORM）和与Hive数据交互的兼容性，我们可以从早期的解决方案实行改进。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Facebook 对加入 Spark 开源社区表示激动，并将共同协作致力于开发出 Spark 的全部潜能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="color: rgb(136, 136, 136); text-decoration: none;"&gt;&lt;em&gt;&lt;span style="color: rgb(136, 136, 136); text-decoration: none; font-size: 12px;"&gt;原文链接：&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;span style="font-size: 12px; color: rgb(136, 136, 136); text-decoration: none;"&gt;&lt;em&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;&lt;a style="font-size: 12px; color: rgb(136, 136, 136); text-decoration: none;"&gt;https://code.facebook.com/posts/678403995666478/using-apache-spark-for-large-scale-language-model-training&lt;/a&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="min-height: 1em; text-align: justify; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="line-height: 25.6px; font-family: 微软雅黑; font-size: 14px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; color: rgb(127, 127, 127); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="color: rgb(62, 62, 62); line-height: 25.6px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; color: rgb(127, 127, 127); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;©本文由机器之心编译，&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; font-size: 18px; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(127, 127, 127); line-height: 25.6px; font-family: 微软雅黑; text-align: justify; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(217, 33, 66); font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(217, 33, 66); line-height: 1.6; font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-size: 12px; color: rgb(217, 33, 66); line-height: 1.6; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/div&gt;</description>
      <pubDate>Wed, 08 Feb 2017 12:09:17 +0800</pubDate>
    </item>
    <item>
      <title>前沿 | MIT AAAI-17研究展示：为规划算法加入人类直觉</title>
      <link>http://www.iwgc.cn/link/4615829</link>
      <description>&lt;div class="article-content"&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;section style="white-space: normal; line-height: 28.4444px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="border: 0px currentcolor; font-family: 微软雅黑; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; border-style: solid none; font-family: inherit; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="font-size: 1em; margin-top: -1.2em; min-height: 1em; border: currentcolor; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(255, 255, 255); background-color: rgb(117, 117, 118);"&gt;选自MIT&lt;/span&gt;&lt;/p&gt;&lt;section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="background-color: rgb(255, 255, 255); padding: 16px 16px 10px; font-family: inherit; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="color: rgb(62, 62, 62); font-size: 16px; margin-top: 5px; margin-bottom: 5px; min-height: 1em; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(127, 127, 127); font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;作者： Larry Hardesty&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-top: 5px; margin-bottom: 5px; min-height: 1em; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(127, 127, 127); font-size: 12px;"&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="color: rgb(62, 62, 62); font-size: 16px; margin-top: 5px; margin-bottom: 5px; min-height: 1em; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(127, 127, 127); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important; font-size: 12px;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;整理：黄小天、蒋思源&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style="min-height: 1em; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; text-align: justify; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;每隔一年，自动规划与调度国际会议（International Conference on Automated Planning and Scheduling）会举行一次比赛，参会者设计的计算机系统试图找到规划问题的最佳解决方案，这些规划问题包含如安排航班或协调自主卫星组任务等。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;然而，除了最简单直接的问题外，即使最好的规划算法仍然不如具有特殊解决问题才能的人类有效，例如麻省理工学院的学生。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;麻省理工学院计算机科学与人工智能实验室的研究人员正通过给予自动化系统人类直觉的能力来提高系统的表现。通过以机器可读的形式编码杰出规划人员的策略，他们能够在一系列具有挑战性的问题上提高竞胜规划算法（competition-winning planning algorithms）10％至 15％的性能。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;研究人员本周在 AAAI（Association for the Advancement of Artificial Intelligence）2017 的会议上展示了他们的研究成果。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;MIT 航空航天学助理教授 Julie Shah 说：「在实验室和其他调查中，我们发现对于规划、调度和优化等任务，通常有一小部分人是真正杰出的人才，而我们是否可以从少数真正杰出人才那里获得洞察力和高层次策略等能力，并让一台机器利用这些杰出能力来解决问题，而不是直接通过普通大众的解决方法？」&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;会议论文（conference paper）的第一作者是 Joseph Kim，它是航天航空方向的研究生，且在 2016 年夏天本科时就在 Shah 的实验室担任研究实习生。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;strong&gt;寻找规划者&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;在自动规划比赛（国际规划竞赛/IPC）中会提供给输入算法不同难易程度的相关问题任务。最简单的问题就只要求满足一些严格的约束条件：如给定一定数量的机场、飞机和在各个机场有确定目的地的乘客，是否可以在所有乘客都到达指定目的地且没有飞机空飞的情况下规划航班路线。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;而更复杂的一类问题，即数值问题会增加一些灵活的数值参数：如你是否能找到一组飞行规划，它在满足原始问题的约束情况下，还能最小化飞机飞行的时间和燃油消耗。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;最后，最为复杂的问题就是时间问题，它在数值问题的基础上添加了时序约束：即如何在最小化飞行时间与燃油消耗的同时，确保飞机可以在不同时间抵达和离开。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;对于每个问题，算法有半个小时生成方案。方案的质量根据「成本函数」测量，例如将飞行总时间与燃油总消耗组合起来的方程式。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Shah、Kim 和 Banks 招募了 36 名麻省理工学院的本科生与研究生，并向他们每个人提出了两种不同比赛的规划问题，一个侧重于飞行线路，一个侧重于卫星定位。如同自动规划者，每个学生只有半个小时解决问题。Shah 说：「在这个世界上，麻省理工的学生基本是解决此类问题的专家，相信他们比绝大多数人做得更好。」&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;编码策略&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;当然，他们做得比自动规划者更好。在学生提交解决方案后，Kim 对他们用来解决问题的一般策略进行了采访。他们的答案大多是包含「飞机应该访问每个城市最多一次」和「对于每个卫星，在三次转向之内找到路线」之类的内容。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;研究人员发现，大多数学生的策略可以使用称为线性时序逻辑（linear temporal logic）的形式语言来描述，并可用于向问题规范添加约束。由于不同的策略可以相互抵消，研究人员分别使用已经赢得他们各自比赛的规划算法来测试每个学生的策略。结果仅轻微变化。关于数值问题，飞行规划和卫星定位问题的平均改进分别为 13％和 16％;对时间问题的改善为 12％和 10％。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Shah 说：「当自动规划员使用人类的高级策略时，它提出的规划看起来更像是由人类制定的。「也许这个采取用户的高层次策略加入到机器算法中的方式，可以让人更容易理解规划的制定。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;在正进行的工作中，Kim 和 Shah 正在使用自然语言处理技术（natural-language-processing techniques）使系统完全自动化，在无需人为干预的情况下，将用户对其高级策略的自由形式描述（free-form descriptions）转换为线性时间逻辑（natural-language-processing techniques）。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 12px;"&gt;原文链接：&lt;/span&gt;&lt;/em&gt;&lt;em&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;http://news.mit.edu/2017/human-intuition-planning-algorithms-0207&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="min-height: 1em; text-align: justify; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="line-height: 25.6px; font-family: 微软雅黑; font-size: 14px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; color: rgb(127, 127, 127); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="color: rgb(62, 62, 62); line-height: 25.6px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; color: rgb(127, 127, 127); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;©本文由机器之心编译，&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; font-size: 18px; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(127, 127, 127); line-height: 25.6px; font-family: 微软雅黑; text-align: justify; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(217, 33, 66); font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(217, 33, 66); line-height: 1.6; font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-size: 12px; color: rgb(217, 33, 66); line-height: 1.6; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-size: 12px; color: rgb(217, 33, 66); line-height: 1.6; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="font-size: 14px; line-height: normal; font-family: &amp;#39;Helvetica Neue&amp;#39;;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;点击阅读原文下载论文&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/div&gt;</description>
      <pubDate>Wed, 08 Feb 2017 12:09:17 +0800</pubDate>
    </item>
    <item>
      <title>学界 | ICLR2017公布论文接收名单，匿名评审惹争议</title>
      <link>http://www.iwgc.cn/link/4615830</link>
      <description>&lt;div class="article-content"&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;section style="color: rgb(62, 62, 62); font-size: 16px; white-space: normal; background-color: rgb(255, 255, 255); line-height: 28.4444px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="border: 0px currentcolor; font-family: 微软雅黑; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; border-style: solid none; font-family: inherit; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-top: -1.2em; min-height: 1em; font-size: 1em; border: currentcolor; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(255, 255, 255); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(117, 117, 118);"&gt;机器之心整理&lt;/span&gt;&lt;/p&gt;&lt;section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px; font-family: inherit; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-top: 5px; margin-bottom: 5px; min-height: 1em; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(127, 127, 127); font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;编辑：微胖&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style="min-height: 1em; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; text-align: justify; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 12px;"&gt;2017 ICLR 将于 4 月 26-27 日在法国东南部港口城市土伦举行。近日，大会接收论文名单公布。在 507 篇提交论文中，有 15 篇论文应邀进行演讲，poster 181 篇，应邀参加研讨会的有 48 篇。其中，FAIR 合著被接收的论文共 14 篇。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px; color: rgb(123, 12, 0);"&gt;全部结果：https://openreview.net/forum?id=BkjLkSqxg&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1486528561ibAvXV.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 12px;"&gt;图片来自 Nando 推特&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;这 15 篇应邀演讲的论文分别是：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Making Neural Programming Architectures Generalize via Recursion&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;PDF:https://openreview.net/forum?id=BkbY4psgg&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Jonathon Cai, Richard Shin, Dawn Song&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;End-to-end Optimized Image Compression&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;PDFhttps://openreview.net/pdf?id=rJxdQ3jeg&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Johannes Ballé, Valero Laparra, Eero P. Simoncelli&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Optimization as a Model for Few-Shot Learning&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;https://openreview.net/pdf?id=rJY0-Kcll&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Sachin Ravi, Hugo Larochelle&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Learning End-to-End Goal-Oriented Dialog&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;https://openreview.net/pdf?id=S1Bb3D5gg&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Antoine Bordes, Y-Lan Boureau, Jason Weston&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Towards Principled Methods for Training Generative Adversarial Networks &lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;https://openreview.net/pdf?id=Hk4_qw5xe&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Martin Arjovsky, Leon Bottou&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Reinforcement Learning with Unsupervised Auxiliary Tasks&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;https://openreview.net/pdf?id=SJ6yPD5xg&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Max Jaderberg, Volodymyr Mnih, Wojciech Marian Czarnecki, Tom Schaul, Joel Z Leibo, David Silver, Koray Kavukcuoglu&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Multi-Agent Cooperation and the Emergence of (Natural) Language&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;https://openreview.net/forum?id=Hk8N3Sclg&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Angeliki Lazaridou, Alexander Peysakhovich, Marco Baroni&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Understanding deep learning requires rethinking generalization&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;https://openreview.net/forum?id=Sy8gdB9xx&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, Oriol Vinyals&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Neural Architecture Search with Reinforcement Learning&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;https://openreview.net/pdf?id=r1Ue8Hcxg&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Barret Zoph, Quoc Le&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Q-Prop: Sample-Efficient Policy Gradient with An Off-Policy Critic&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;https://openreview.net/forum?id=SJ3rcZcxl&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Shixiang Gu, Timothy Lillicrap, Zoubin Ghahramani, Richard E. Turner, Sergey Levine&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Learning to Act by Predicting the Future&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;https://openreview.net/forum?id=rJLS7qKe&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Alexey Dosovitskiy, Vladlen Koltun&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;https://openreview.net/forum?id=H1oyRlYgg&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Nitish Shirish Keskar, Dheevatsa Mudigere, Jorge Nocedal, Mikhail Smelyanskiy, Ping Tak Peter Tang&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Semi-supervised Knowledge Transfer for Deep Learning from Private Training Data&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;https://openreview.net/pdf?id=HkwoSDPgg&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Nicolas Papernot, Martín Abadi, Úlfar Erlingsson, Ian Goodfellow, Kunal Talwar&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Amortised MAP Inference for Image Super-resolution&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;https://openreview.net/forum?id=S1RP6GLle&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Casper Kaae Sønderby, Jose Caballero, Lucas Theis, Wenzhe Shi, Ferenc Huszár&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Learning Graphical State Transitions&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;https://openreview.net/forum?id=HJ0NvFzxl&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Daniel D. Johnson&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;另外，Nando 在推特上公开表示了对以下几篇论文的赞赏和喜爱。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;论文：Third Person Imitation Learning，&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;作者： Bradly C Stadie, Pieter Abbeel, Ilya Sutskever&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1486528562d6vqSQ.jpg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;论文：Modular Multitask Reinforcement Learning with Policy Sketches&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;作者：Jacob Andreas, Dan Klein, Sergey Levine&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/14865285622VkfHF.jpg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;论文：Optimization as a Model for Few-Shot Learning&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;作者：Sachin Ravi, Hugo Larochelle&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/148652856291qmNM.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;论文：Making Neural Programming Architectures Generalize via Recursion（被 Nando 形容为突破）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;作者：Jonathon Cai, Richard Shin, Dawn Song&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1486528562tmLH87.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;不过，有趣的是，2016 年刷爆各路媒体的 LipNet 论文却出人意料地遭拒。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 14px;"&gt;来自牛津大学、Google DeepMind 和加拿大高等研究院（CIFAR）的研究人员发表了一篇具有重要价值的论文，提出了 LipNet——一种可以将可变长度的视频序列映射成文本的模型，其使用了时空卷积、一个 LSTM 循环网络和联结主义的时间分类损失（connectionist temporal classification loss）。它是第一个将深度学习应用于模型的端到端学习的模型，可以将说话者的嘴唇的图像帧序列映射到整个句子上。这个端到端的模型在预测句子前不再需要将视频拆分成词。在 GRID 语料库上，LipNet 实现了 93.4% 的准确度，超过了经验丰富的人类唇读者和之前的 79.6% 的最佳准确度, 将自动唇读技术的前沿水平推进到了前所未有的高度。在不久的将来，这一视频识别应用会非常有用。——机器之心报道（&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720335&amp;amp;idx=1&amp;amp;sn=b030d7f82d10acde0378035c900264df&amp;amp;chksm=871b0c31b06c852746f35e16814808ceb13e91b091732afa48b2bb8c6d6f2f542df26e7f5575&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720335&amp;amp;idx=1&amp;amp;sn=b030d7f82d10acde0378035c900264df&amp;amp;chksm=871b0c31b06c852746f35e16814808ceb13e91b091732afa48b2bb8c6d6f2f542df26e7f5575&amp;amp;scene=21#wechat_redirect"&gt;重磅论文 | 如何通过机器学习解读唇语？DeepMind 要通过 LipNet 帮助机器「看」懂别人说的话&amp;nbsp;&lt;/a&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;）&lt;/p&gt;&lt;/blockquote&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;据悉，Nando de Freitas 和匿名评审产生了激烈冲突，评审认为，论文并无洞见和让人惊艳的结果。但是，Nando 感觉受到了羞辱，指责评审论点根本是废话，也不懂深度学习，评审建议毫无必要。Nando 认为，匿名评论不合理，但是，评审认为这位大牛有以大压小的嫌疑。最终，会议 AC 坚决站在了评审这边，拒了这篇论文，连研讨会都没有收。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;机器之心分析师个人认为：&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 14px;"&gt;&lt;em&gt;我也觉得 LipNet 算法方面创新有限，demo 视频也没有给人惊艳感。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 14px;"&gt;&lt;em&gt;LipNet 也是挂在 zisserman 名下的文章，它的实验结果很优秀，但是 ICLR 好像有一个更关注算法创新和理论推进这种高大上的初衷，所以 , LipNet 这样的文章如果是几年前深度学习还没那么热的时候应该是会被录取的，因为那时候，你只要用深度学习又征服了一个新的 cv 或者其他领域的一个课题或应用，就有可能发到相关的顶级会议，可如今深度学习文章已经满大街了，再拿这种征服一个课题上的几个数据集，或者发布一个大规模数据集的方式来发 ICLR 就略显草率了，也不像 DeepMind 的逼格，纯属个人拙见。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Github 上也有网友表示，在读了许多论文的评审建议后，发现 LipNet 的评审建议最富洞见，也最有趣，当然，也极富争议。这既暴露了某些自负，也暴露了学术大牛和匿名评审之间的冲突，这至少表明，评审程序还是起作用的，没有像媒体一样跟风炒作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="min-height: 1em; text-align: justify; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="line-height: 25.6px; font-family: 微软雅黑; font-size: 14px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; color: rgb(127, 127, 127); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="color: rgb(62, 62, 62); line-height: 25.6px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; color: rgb(127, 127, 127); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;©本文为机器之心原创，&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; font-size: 18px; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(127, 127, 127); line-height: 25.6px; font-family: 微软雅黑; text-align: justify; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(217, 33, 66); font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(217, 33, 66); line-height: 1.6; font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-size: 12px; color: rgb(217, 33, 66); line-height: 1.6; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/div&gt;</description>
      <pubDate>Wed, 08 Feb 2017 12:09:17 +0800</pubDate>
    </item>
    <item>
      <title>资讯 | 微软任命王永东博士为全球资深副总裁</title>
      <link>http://www.iwgc.cn/link/4615831</link>
      <description>&lt;div class="article-content"&gt;&lt;section style="color: rgb(62, 62, 62); font-size: 16px; white-space: normal; background-color: rgb(255, 255, 255); line-height: 28.4444px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="border: 0px currentcolor; font-family: 微软雅黑; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; border-style: solid none; font-family: inherit; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-top: -1.2em; min-height: 1em; font-size: 1em; border: currentcolor; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(255, 255, 255); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important; background-color: rgb(117, 117, 118);"&gt;机器之心授权转载&lt;/span&gt;&lt;/p&gt;&lt;section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px; font-family: inherit; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-top: 5px; margin-bottom: 5px; min-height: 1em; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(127, 127, 127); font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;作者：微软中国&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style="min-height: 1em; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; text-align: justify; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;br style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/p&gt;&lt;blockquote style="color: rgb(62, 62, 62); font-size: 16px; white-space: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/blockquote&gt;&lt;blockquote&gt;&lt;p style="line-height: 1.75em; text-align: justify;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 12px;"&gt;微软公司今天宣布，任命微软（亚洲）互联网工程院院长王永东博士为微软全球资深副总裁。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p style="line-height: 1.75em; text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="line-height: 1.75em; text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;「永东博士展现了科学家的智慧和出色的领导才能。永东博士和他的团队在人工智能等诸多领域的研究与开发中取得了突破性的进展，不仅为微软公司，更为我们的客户的发展做出了贡献。我们期待永东和他的团队在未来取得更出色的成绩。」微软公司执行副总裁沈向洋博士表示。&lt;/span&gt;&lt;/p&gt;&lt;p style="line-height: 1.75em; text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="line-height: 1.75em; text-align: justify;"&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=401882267&amp;amp;idx=1&amp;amp;sn=eb5a4cf6e10b6dc3787303f421a8f77b&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=401882267&amp;amp;idx=1&amp;amp;sn=eb5a4cf6e10b6dc3787303f421a8f77b&amp;amp;scene=21#wechat_redirect"&gt;&lt;span style="font-size: 14px;"&gt;王永东博士&lt;/span&gt;&lt;/a&gt;&lt;span style="font-size: 14px;"&gt;领导微软人工智能与研究事业部以及 Office 产品事业部在亚洲的团队，负责微软在亚太地区的互联网产品与服务的研发，方向主要涵盖微软必应（Bing）搜索引擎、在线广告技术、语音及自然语言处理技术、小娜、小冰、Office 365、人工智能以及移动互联网等领域。他带领的团队分布在北京、苏州、东京、台北和西雅图贝尔维尤。&lt;/span&gt;&lt;/p&gt;&lt;p style="line-height: 1.75em; text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="line-height: 1.75em; text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;王永东博士于 2009 年加入微软的必应团队，并于同年 8 月返回中国创建微软（亚洲）互联网工程院。他创建并打造了世界一流的研发团队，在基础架构、编程语言、机器学习、人工智能、用户体验、设计以及在线服务等方面取得了出色的成绩。他主持并推动了人工智能微软小冰的研究和开发工作。微软小冰已成为全球领先的人工智能机器人，并在中国、日本和美国与数千万用户建立了密切的感情联系。&lt;/span&gt;&lt;/p&gt;&lt;p style="line-height: 1.75em; text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="line-height: 1.75em; text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;王永东博士同时兼任微软亚太研发集团首席技术官，负责为微软亚太研发集团设立技术研发策略、愿景及整体方向。&lt;/span&gt;&lt;/p&gt;&lt;p style="line-height: 1.75em; text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="line-height: 1.75em; text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;在加入微软之前，王永东博士曾在雅虎公司工作并担任工程副总裁，负责国际市场的搜索引擎的研发工作，以及与雅虎日本、阿里巴巴的搜索合作。1996 到 2003 年间，王永东博士在 Inktomi 公司从事搜索引擎的研发工作，他也是 Inktomi 公司创建初期的第一批工程师。1991 年到 1996 年，他在美国赛贝斯（Sybase）公司工作，参与并负责分布式数据库产品 (Sybase Replication Server) 的研发。&lt;/span&gt;&lt;/p&gt;&lt;p style="line-height: 1.75em; text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="line-height: 1.75em; text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;王永东博士 1984 年毕业于上海交通大学计算机专业，1985 年赴美国加州大学伯克利分校深造并于 1992 年获计算机科学博士学位。从 1993 年到 1999 年，王永东博士应邀在加州大学伯克利分校计算机专业兼职任教。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="min-height: 1em; text-align: justify; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="line-height: 25.6px; font-family: 微软雅黑; font-size: 14px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; color: rgb(127, 127, 127); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="color: rgb(62, 62, 62); line-height: 25.6px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; color: rgb(127, 127, 127); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;©本文为机器之心经授权转载，&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; font-size: 18px; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(127, 127, 127); line-height: 25.6px; font-family: 微软雅黑; text-align: justify; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(217, 33, 66); font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(217, 33, 66); line-height: 1.6; font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-size: 12px; color: rgb(217, 33, 66); line-height: 1.6; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/div&gt;</description>
      <pubDate>Wed, 08 Feb 2017 12:09:17 +0800</pubDate>
    </item>
    <item>
      <title>Face++旷视科技首席科学家孙剑首次接受专访：计算机视觉亟待解决哪些问题？</title>
      <link>http://www.iwgc.cn/link/4601237</link>
      <description>&lt;div class="article-content"&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;section style="max-width: 100%; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; background-color: rgb(255, 255, 255); line-height: 28.4444px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%; border-width: 0px; border-style: initial; border-color: currentcolor; font-family: 微软雅黑; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; max-width: 100%; border-style: solid none; font-family: inherit; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-top: -1.2em; max-width: 100%; min-height: 1em; font-size: 1em; border-width: initial; border-style: initial; border-color: currentcolor; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(255, 255, 255); background-color: rgb(117, 117, 118); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;机器之心原创&lt;/span&gt;&lt;/p&gt;&lt;section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px; max-width: 100%; font-family: inherit; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-top: 5px; margin-bottom: 5px; max-width: 100%; min-height: 1em; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(127, 127, 127); font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;作者：虞喵喵&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style="max-width: 100%; min-height: 1em; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;2015 年 12 月 10 日，在 ImageNet 计算机识别挑战赛中，由首席研究员孙剑带领的微软亚洲研究院视觉计算组，通过 152 层神经网络的应用，以绝对优势获得图像分类、物体定位以及物体检测全部三个主要项目的冠军。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;半年前，孙剑博士离开微软研究院入 Face++ 旷视科技（以下简称 Face++）任首席科学家兼 Research 负责人，引发业内热议。孙剑博士于半月前撰写了《创业公司里的研究之美》，详细描述了 Face++ 的研究方向、展开研究的方式。在他看来，无论是使命定位、人员组成和研发方式，Face++ 的 Research 和 MSR 的研究没有本质差别，都是一群富有 Geek 精神的自我驱动者在探索前沿技术。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;但仍有不少问题困扰我们。已经在图像领域耕耘十余年的他，为什么会选择创业公司？从大公司到创业公司，又有哪些变化？图像识别领域的下一个「大」问题是什么？152 层的神经网络的创想，究竟是怎样出现的？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;为此，机器之心专访孙剑博士，从残差网络、ImageNet 测试、数据标注等多个角度展开了话题。内容整理如下，以飨读者。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;span style="font-size: 16px;"&gt;&lt;strong&gt;关于 152 层神经网络和残差学习&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;strong&gt;&lt;em&gt;&lt;span style="font-size: 14px;"&gt;机器之心：在 2015 年在 ImageNet 测试中，您带领团队使用了 152 层神经网络，取得了三个主要项目的冠军。您和您的团队是如何想到这个方法，又是怎样去实现的？&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;孙剑：很多时候做研究，是在无数次的尝试中最后总结出的方法，同时把一个复杂的方法进行简化。做这个（残差网络），我们试了非常多的方法，有一些方法我们都没有公布。中间经历过很多，做了实验之后最后总结出（残差网络），发现它非常有效。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;找到这个有效的方式后，我们分析它的原理，为什么能起作用。最后在论文中以残差学习的形式呈现，这是我们当时认为最好的一种解释。后来很多人尝试新的解释和改进，也有 A 解释、B 解释、C 解释，有些我们是认同的，有些我们不认同，其实蛮有意思的。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;残差网络并不是说做到多少层，而是你也可以简单的做到这么多层，它核心使深层网络的优化变得容易。残差网络相当于将问题重新描述，但本质没变，以至于用现有的优化算法就很好解。以前不收敛，现在就能收敛了；以前收敛到很差的结果，现在就非常容易收敛到很好结果，所以它本质上是解决了优化问题。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1486442524XQfaCA.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;span style="font-size: 12px; color: rgb(136, 136, 136);"&gt;&lt;em&gt;相关结果截图，来自 ImageNet 2015 测试（ILSVRC2015）网站&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;这个问题困扰了神经网络工作者非常长时间。为什么叫深度学习？深度就是网络层数，层数越多就越深，刚开始做 5 层就算深度。2012 年 Geoffrey Hinton 做了 8 层，他的论文专门写了一段证明 8 层比 5 层好，越深越好，因为还有很多人不相信这是有道理的。就算他们做得已经很好了，还有一些论文中说浅的网络也能做得一样好，「深」是不必要的。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;在神经网络研究的历史中，很长时间内大家不相信那么深的网络能够优化出来。做深度学习之前大家研究 SVM（Support Vector Machine，支持向量机），研究稀疏表示，很大程度上是线性问题。大家试图研究凸的（问题），非凸的还想办法转成凸的做，对于这么深的网络、这么复杂的事情、高度非线性又有这么多参数，数据又很少，很多人都不相信能把它优化出来。今天能够相当程度地解决也包含很多因素。残差学习是其中一个重要因素，但不是唯一的。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;把大家研究出来的结论放在一起，才导致今天任意给一个深度网络都能很容易地训练出来，深度再也不是网络不收敛训练不好的问题，破除了以前的魔咒。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;最后要说一下做出这个残差网络完全是团队（何凯明、张祥雨、任少卿和我）的集体智慧结晶，缺少任何一人都不敢说能走得到这一步，中间经历很多的失败和曲折。我深感能把我们 4 个不同技能的人凑在一起，打下一个「大怪兽」的幸运；和他们在一起忘我的研究过程是我研究生涯中最难忘的经历之一。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;机器之心：在图像识别之外，残差网络还可以运用到其它领域吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;孙剑：最近语音识别、自然语言处理都在用。它是一种思想，并不是一个局限于图像识别的一个方法。这个思想用在别的地方都管用，我们看到了非常多的例子，大公司、小公司都在用。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1486442525DvUQig.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;&lt;em&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;论文《Deep Residual Learning for Image Recognition》中，在 ImageNet 上使用残差网络优化后的效果比对图表&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;而且最先进的系统、最复杂的系统都在用这个思想。并不是简单的用残差网络这个方式做，比如语言处理中的一个环节想要做做深，原来两层就不行，现在可以做得很深。用残差学习或跳层连接做得很深，效果很好，训练也很容易。并不是说以前不能搭这么深，搭这么深结果更差，现在有自由度想搭多深搭多深。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;当然也不是说越深越好，跟问题和数据都有关系。考虑复杂度和效果肯定是找折衷点，不过现在不受深度的约束了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;机器之心：那您还会继续残差网络的研究吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;孙剑：这是我们的一个中间结果。我觉得残差网络是一方面，但是我们做研究希望找下一个大想法，当然结构可能融合了残差网络方法，因为它这个很好的思想并不是具体的一个网络。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;后来有很多人开发各种网络，结构都不一样，但残差网络的思想是其中必不可少的部分。现在所有网络都是残差网络，重点已经不是加残差网络了，而是说在以加了它为基础的情况下，再去研究别的特性，把这个问题再深刻理解，怎么能够做得更好。举个例子，分类能做得好，但这个网络未必适合于检测、分割这样的问题。只有把问题理解更深入，才能设计出最适合特定问题的网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;span style="font-size: 16px;"&gt;&lt;strong&gt;关于 ImageNet 测试与数据&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;机器之心：ImageNet 已经诞生了很长时间，现在用它的测试结果判断一个图像识别模型好不好用还可行么？或者，我们应该如何去判断一个图像识别的模型是优秀的？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;孙剑：ImageNet 今天仍有它的价值。做新问题新的标注数据很少，还离不开这个数据集。它很通用，上面 pre-train 的模型肯定不是最优的，但是在只有很少数据的时候起到了很大作用。另外 ImageNet 做得很好，它的训练和测试之间也是非常一致的。它是诞生研究方法、新的思想的平台，包括我们做人脸识别，都是通过 ImageNet 继承来的思想和做法。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;当然遵循游戏规则得到了冠军固然可贺，但主要还是看是否有可以通用的新方法或思想。随着深度网络的快速发展，ImageNet 1K 这个数据目前已经很容易出现严重的过拟合了，期待下一代的 ImageNet 出现。我们最近也在考虑如何设计更好的 ImageNet。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;机器之心：李飞飞后来也做了图像与语言结合的 Visual Genome，您认为在数据集方面还有哪些值得去做的事？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;孙剑：Visual Genome 这个数据集非常好，李飞飞她们付出了非常大的努力，我们也在用这个数据集。数据集中不只有图像一个层次，图像里面的物体、物体之间的关系都标出来了，包括动作关系、位置关系都有。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1486442525yrQLdb.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 12px;"&gt;Visual Genome 的标注情况，详见其官网 Paper 部分&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;这些是研究认知问题必须要有的东西。比如房子上是没有马的，这件事情是常识。以前通过大量的数据统计学习可以做，送进来很多训练数据，确实数据里房子上没有马。但其实也隐含这件事，还没有表示出来，一旦你的算法出现了这种情况（房子上有马）就是已经做错了。但是如果能引入语言的话，他就会告诉你新的常识，房子上没有马。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;换句话说，为什么 Visual Genome 清楚的描述照片很重要？比如你想教计算机认图片，你怎么教？教小孩图里面有什么、谁在干什么，语言可能是最自然的教计算机认图的方式。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;希望这个库更大，也许再增加两个数量级就会产生下一个意想不到的突破。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;strong&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 14px;"&gt;机器之心：有更多维度的标注数据，会是解决图像识别问题的重要方向之一吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;孙剑：现阶段可能是。有两个新的方向我们也在尝试，一个是制造合成数据，通过图形学的方法造出一些非常逼真的、和真正训练图像很像的图。用这个方法可以产生大量数据，而且有标注，可以得到很好的效果，能不能搞得真实还需图形学的同行们努力。另一种方法是，通过对抗学习或者叫对抗神经网络，可以从一堆样本中没有监督的自动生成生成新的样本。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;标注方面有的标注是人工，有的标注网上已经有的，包括视频中前后两帧的相关性也是一种标注。我们训练人脸识别，只需要知道这几张照片是同一个人，另几张照片不是同一个人的。或者只需要知道这两张是同一人，那两张是同一人，这些标注都可以用来训练。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;获取训练数据的方式是非常多的，数据训练也是非常重要的，我们也是最大努力获取最好的数据。对于旷视的研究员来说，获取数据是研究责任的一部分，想办法获取也好，造也好，拿到数据是工作职责之一。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;span style="font-size: 16px;"&gt;&lt;strong&gt;关于计算机视觉的过去和未来&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;em&gt;&lt;span style="font-size: 14px; color: rgb(136, 136, 136);"&gt;机器之心：您涉足图像领域已经有近二十年的时间，在您看来这个行业有什么样的特点？到今天有哪些可以称之为里程碑的事件？&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;孙剑：我至今还觉得我还是这个行业的新手，好多东西了解还是比较浅的，不敢妄自评判里程碑事件，这绝不是谦虚。当然深度学习是最近、最重要的事件，再之前可能是机器学习方法引入计算机视觉，改变了计算机视觉中很多问题的研究方式。在现在火热的深度学习之前，更多的是怎么用机器学习、统计学习来研究和思考视觉问题。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;这不是某一个时间点突然发生的，而是一段时间内慢慢发生的。这对计算机视觉改变很大，以至于今天非常大比例的计算机视觉人员都是非常懂机器学习的人。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;有一个里程碑是深度传感器的普及。2009 年，微软 Kinect 诞生是当时的一个大事件，因为终于可以很方便和低成本地获取 3D 信息 了。计算机视觉有两大问题，一个图像理解，一个三维重建。求解 3D 是梦想，原来需要拍两张或多张照片，费很大的劲儿来重建。今天有 sensor 直接可以测量 3D。它一下就开启了今天和未来的很多应用。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;至于未来，我的导师沈向洋博士经常引用的一句话是：「The best way to predict the future is to create it.」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;机器之心：接下来计算机识别或者说图像识别的发展，哪些问题是亟待解决的？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;孙剑：我觉得挺难预测的。今天大家都在研究无监督学习，因为监督学习已经比较成熟了，但无监督学习不够好，这是非常大的问题。我在很多年前读过《On Intelligence》，最近又读了一遍，再次受到很多启发。无监督学习当然很重要，现在有很多人研究，但还没做到马上能解决问题，从一堆无标注的数据生成另一堆无标注的数据，很难说立刻能带来多大的实际价值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/14864425254XmiJI.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 12px;"&gt;《On Intelligence》，副标题为「How a New Understanding of the Brain will Lead to the Creation of Truly Intelligent Machines」&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;我现在看好两个研究方向，一个是深度神经网络，必须能记住东西。并非长短时的短期记忆，而是像小孩长大一样的长时间记住，有一个大的记忆库，把事物放进去还可以决定要不要拿掉，或者把它们关联在一起，都需要有记忆机制。现在大多数有监督学习都记在网络参数里，并没有显式的记忆。虽然已经有很多不错的研究了，但还没到实用，我觉得这会是一个非常大的突破。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;还有一个方向是，如何完成连续的输入－输出。人之所以能处理这些视频、做好无监督学习，因为在实时处理各种视频，连续输入、连续输出。现在的问题是，大家不知道怎么准备这样的训练数据来教计算机。可以把视频输入进去，可你想教它什么呢？教它什么，教到什么颗粒度还不清楚。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;送入连续的、动态的内容，少量的有标注（数据）、大量的没标注，因为不可能将所有的内容都标注。在学术领域中组织一个大的训练问题让大家研究，才能推动下一步的进展。因为现在数据的进出都在拟合一个单一的函数 F(x)，深度学习完成得非常好。但当函数不是静态的输入－输出时，是不断变化的输入，该怎么做是非常大的挑战。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;机器之心：有一种声音认为，我们现在的计算机视觉太专注于研究人脸识别这样的功能分支，这还是停留在识别（或者说是感知）层面，是否也应该去关注认知这个更加重要的目标？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;孙剑：这是个误解，计算机视觉领域从来就没有太专注研究人脸这个问题，Face++ 也不是只研究人脸。我们主要做我们最关心的 4 个计算机视觉的核心问题（图像分类、物体检测、语义分割、和序列学习），还有核心网络训练问题、底层构架问题、深度学习平台问题等。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1486442526qjID53.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;认知层面的东西当然也要研究，不然人工智能解不掉。最近的 Image Caption（看图说话）是一个非常好的研究课题，它把图像感知和这个语义理解串在一起了，而且它可以反过来帮助解决感知的问题。感知经常会出错，出的错又是很不合理的。不合理是因为没有常识，比如在房子上识别出马。常识其实在语言里面，要通过语言才能表示出来，人是通过语言、通过概念抽象来表示的。这个东西不研究清楚，就没法表示知识，没法表示房子上一般不可能有马这件事情。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;机器之心：深度学习是图像识别最主流的一个方法，去年《Science》也发表了一篇关于通过贝叶斯程序学习识别手写体的文章。要让图像识别能够发展得更快更好，除了深度学习是不是也需要一些其他的方法或模型？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;孙剑：深度学习是个广泛的概念，是端对端的，具体表现形式是深层神经网络。我觉得再发展下来，他可能就是一个无监督学习、增强学习内的部件，它和其他方法并不相互排斥。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;深度学习狭义的讲是有监督的深度学习，或者有监督训练的神经网络。广义的讲它已经渗透在无监督学习和增强学习里面了，它是一个大的概念集合。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 14px;"&gt;机器之心：最近图像识别比较火的方向是医疗，Hinton 认为不需要放射科医生了，因为图像处理技术已经足够成熟。在您看来医疗上的图像识别已经到这个程度了吗？或者接下来需要做什么?&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;孙剑：我觉得今天在整体还不成熟，个别问题有希望。医疗数据还是不够大规模而且不够开放，医疗数据经常是 3D 的，3D 既有优点也有缺点。另外医生做出判断也并不是只是看图像，还设计很多背景知识。从好的一方面讲，医疗影像识别相对一般的自然图像识别容易，因为自然图像中的事物特别多，涉及我们对常识的理解和对知识的表达；而医疗图像是相对比较限定的，它的歧义、困难都少很多。今天的问题可能是数据不够，研究的人不够多，数据平台不够开放，还有病人隐私问题。种种问题综合在一起，现在可能非常个别情况下是可以用，大多情况据我所知还需要研究。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;span style="font-size: 16px;"&gt;&lt;strong&gt;关于首席科学家与 Face++ 旷视科技&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;机器之心：您为什么会在半年前加入 Face++？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;孙剑：我就想试试，想有这段经历。接触计算机视觉已经 20 年了，最早在大三就接触了图像处理，后来在我大四末做的毕业设计「混沌神经网络的硬件实现」，当然那时候的神经网络是另一番模样。我也很早就研究过人脸识别，但是用的是上上一代的技术了。现在有了深度学习，真的让以前不能落地的一些事情能落地了。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;其实在微软，我一直是同时注重研究方法和实际应用的风格，做了很多研究工作应用到公司产品上去了。我上大学期间我从教我自动控制的老师学习了这样一个理念：做好事情要即做神也做鬼，做神是说要把方法搞明白、作对了，做鬼是说要用实践来检验、来指导。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;想加入创业公司是因为今天创业公司跟以前创业公司不一样了。你可以认为今天的创业公司就是大公司的一个部门，并且投入全部的人力、心力和财力，200% 聚焦在做一件事情。我想参与在这个非常专注的过程中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1486442526wpOJb9.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;&lt;em&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;旷视科技目前的主要产品&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;机器之心：Face++ 很早就有研究院这样的设置吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;孙剑：Face++ 是技术公司，最早全是研究员，而且非常早的采用了深度学习的方法。所以可以认为一开始 Face++ 就是一个研究院，然后慢慢的有产品、商务、销售，然后慢慢就变成现在这样子。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;因为深度学习，特别是计算机视觉，在纯研究性的工作之外有很多工程性的事情要做。它是实践性非常强的一门学科，必须动手做实验，动手处理数据、理解问题，所以我们研发不分家。做好的研究成果会以内部的算法库、SDK，交付给产品部门；产品部门在 SDK 基础上，再去开发他们的产品，然后产品再到销售。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;机器之心：您接下来要主要研究的方向，或者说研究院要研究的方向是什么？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;孙剑：就像之前说的，研究院的主要聚焦在 4 个核心研究课题上（图像分类、物体检测、语义分割、和序列学习），这和我在微软所做的完全一致，我们会继续推进在这些问题上的进展。新的方向我们也在探索，但还不是主线。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;机器之心：那是产品引导我们的研究工作，还是研究工作相对独立，更贴近于前沿技术？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;孙剑：现在所有公司的研究院已经没有没有纯粹的纯研究了，真正的纯研究只有在学校里才有。每个公司的研发部门，都有不同程度的目的折衷，所以不能说是完全独立做纯研究，或者完全为了产品开发。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;strong&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 14px;"&gt;机器之心：对于创业公司，更需要前沿研究的科研成果，还是工程化成果？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;孙剑：我们都要，这不是贪心，而是最好的方式。我们付出很大精力和资源来研究和提升本质方法，本质方法的提升会传导到产品上去，比如精度更高了、速度更快了。这方面不能短视，必须短期、中期、长期（目标）都有。公司刚创立的时候其实没产品，做的都是研究相关的东西。研究本身也分两种研究，应用性研究和基础研究，非常基础的研究放之四海皆准，应用性研究要解决问题。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;其实这是大家都懂的道理，但是知易行难，控制好度是关键。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;机器之心：此前您的分享中提到 Face++ 将涉足机器人，能具体谈谈吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;孙剑：现在我们做人脸识别、物体识别的硬件模组，和国内几家家庭服务型机器人都有合作。可以认为机器人的核心部件是眼睛、脑、手和脚：视觉是眼镜，手是机械臂，脚这个东西叫做 AGV+导航，当然还有更难的双足、多足机器人。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Face++ 已经在提供想机器人行业提供硬件模组，其中内置了我们的算法。下一步，我们非常有兴趣会研究它的身体部分、手的部分、腿的部分，做完整的机器人。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="max-width: 100%; min-height: 1em; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; line-height: 25.6px; font-family: 微软雅黑; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; font-style: normal; color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; font-style: normal; color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;©本文为机器之心原创，&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; font-style: normal; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; max-width: 100%; min-height: 1em; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); font-size: 18px; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(127, 127, 127); line-height: 25.6px; font-family: 微软雅黑; text-align: justify; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; max-width: 100%; min-height: 1em; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(217, 33, 66); font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="max-width: 100%; min-height: 1em; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(217, 33, 66); line-height: 1.6; font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="max-width: 100%; min-height: 1em; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; font-size: 12px; color: rgb(217, 33, 66); line-height: 1.6; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/div&gt;</description>
      <pubDate>Tue, 07 Feb 2017 12:39:27 +0800</pubDate>
    </item>
    <item>
      <title>现场报道 | AAAI-17 Workshop：自动驾驶与人工智能</title>
      <link>http://www.iwgc.cn/link/4601238</link>
      <description>&lt;div class="article-content"&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;section style="max-width: 100%; white-space: normal; background-color: rgb(255, 255, 255); line-height: 28.4444px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%; border-width: 0px; border-style: initial; border-color: currentcolor; font-family: 微软雅黑; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; max-width: 100%; border-style: solid none; font-family: inherit; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="color: rgb(62, 62, 62); font-size: 1em; margin-top: -1.2em; max-width: 100%; min-height: 1em; border-width: initial; border-style: initial; border-color: currentcolor; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; background-color: rgb(117, 117, 118); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;机器之心原创&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px; max-width: 100%; font-family: inherit; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="color: rgb(62, 62, 62); font-size: 16px; margin-top: 5px; margin-bottom: 5px; max-width: 100%; min-height: 1em; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(127, 127, 127); font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;作者： 闫骥&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-top: 5px; margin-bottom: 5px; max-width: 100%; min-height: 1em; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color:#7f7f7f"&gt;&lt;span style="font-size: 12px;"&gt;&lt;strong&gt;整理：微胖、蒋思源、李亚洲、朱思颖&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style="max-width: 100%; min-height: 1em; text-align: justify; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;&lt;em&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;AAAI-17 人工智能大会正在火热进行中，机器之心在现场的分析师参加完一场 Workshop 之后发回了精彩的报道。此场 Workshop 探讨的主题是人工智能与自动驾驶。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;已过去的十年见证了连接和自动化汽车（Connected and Automated Vehicles）的飞速发展。CAV 本可以避免在过去十年发展过程中的 90% 以上的交通事故；大量减缓交通拥堵；大幅降低汽车能源消耗；显著提高道路使用率。然而，现有的 CAV 系统不足以应对大规模多种数据分析的挑战，这些数据由车载传感装置——摄像机、雷达、红外线、激光雷达等所获取。并且这些 CAV 系统不能在复杂驾驶环境下做出时间要求严格（time-critical）的决策。要解决这两个难题，单独的人工智能技术，例如，感知（perception），规划（planning）以及推理（reasoning）等难以胜任，需要支持紧密合作的创新型计算方法的加入。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;这个研讨会的使命是打造人工智能社区内的协同环境——囊括计算机视觉、认知、推理、学习、规划和 CAV。这个活动的三个目标：（1）确认 CAV 系统中的关键人工智能挑战；（2）发掘应对这些挑战的有前景的人工智能解决方案；（3）丰富这个多学科课题的未来研究。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1486442527yrQLdb.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;以下是机器之心分析师闫骥记录的研讨会内容：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 16px;"&gt;介绍&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;这篇文章报道了 2017 AAAI 主题为「用于连接和自动化车辆的人工智能」研讨会。我对这场研讨会的总体印象是与会者就这一论题从广泛、不同视角进行了交流。既有技术深度的分析，也有法律和社会应用这一大框架下的讨论。发言人员背景广泛：有的来自联邦高速公路管理局（FHWA），有的来自学术界，比如纽约大学从事人工智能研究，或交通管理研究的人员。还有的来自知名科技公司，比如 FAIR 和百度 IDL。另外还有自动驾驶领域创业公司的创始人，比如 AutoX 以及 ISee.ai。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;span style="font-size: 16px;"&gt;&lt;strong&gt;深度学习和自动化驾驶&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;这场研讨会一开始，贾扬清博士发表了演讲，谈到了深度学习框架近期取得的一些进展。他的演说集中讨论了所谓的四个原则——MAPS。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;M—模块性（Modularity）：现在，在 Caffe、Theano、TF 等框架中有很多冗余 APIs。既然很多深度学习模块是可以重复使用的，那么，一个更好的重组方式就是将公共模块下推到共享核心库中。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1486442528e6vrTR.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;A—增强计算模式。他指出，当前深度学习社区趋于使用更低浮点精度的数值计算（1），这有很多优点：降低模型大小、节能、更快的网络链接以及更好的性能&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;P—便携性。他表示，人们对在移动设备上运行强大训练过的模型的需求越来越多。他通过打开一个摄像头，用苹果手机展示了一个 demo。这个 demo 可以实时做图像分类识别。模型是在使用简化版的 Resnet 在 ImageNet 数据上训练完后在手机本地运行的&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;S - 可扩展性。他展示了近些年来，神经网络在深度/大小方面日益递增的情况。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Later. Two PHD students from NYU gave a talk on end to end training&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;接下来。两位来自纽约大学的博士研究生就端到端的训练发表了他们的看法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;近期，英伟达的工作（2）使得端到端的训练引发人们关注。基本上，论文假设已经有了一个教师策略（teach policy）。然后，使用使用监督学习来训练网络，模拟这个教师策略。这一方法的主要不足在于学习的算法只能在教师策略接触过的状态上进行训练。但是，当汽车处于教师策略从未涉及过的危险状态时，情况会很危险，因为算法还没有学会如何安全运行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;接着，他们展示了一个解决问题的办法，所涉及的论文是几年前的了（3）。直观上，训练学生策略的方式是迭代的。在首次迭代时，学生仅在教师策略见识过的状态基础上进行训练。每进行下一次迭代，学生就会基于自己习得的策略采取行动。这使得学生可以进入教师之前没有见过的状态中，对于每个未曾见过的状态，学生也会询问并存储来自教师策略的行动并用以训练。这一方法使得学生可以进入具有潜在危险的状态并学习如何恢复。这一方法的不足之处在于必须假设总有一个可以询问的教师策略，而这在自动驾驶案例中，是不切实际的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;这使得两位研究人员提出了这一方案（4），基本上避免在每个状态上询问教师策略。实现的方式是通过使用标准 CNN，所谓的安全策略，训练一个独立的分类器来判定学生策略的行动对教师策略的偏离是否达到了一个固定阈值。一旦这个分类器被训练过了，当分类器认为学生行动有危险时，学生才询问教师策略。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;总体上，这似乎是个好主意，有效克服了监督学习中有偏见的状态空间。不过，这在自动驾驶中的实用性似乎还有疑问。实验仅在 TORCS 上训练过，这是个赛车游戏，还不是真实生活。真实生活中，基于一个训练过的安全策略，实现人类驾驶和自动驾驶无缝对接，这个方案的实用性能有多大呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;随后，布加勒斯特理工大学（University Politehnica of Bucharest）的博士生发表了一场在航空测绘方面的演讲。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;他发表演说解决的问题（5）就是从谷歌卫星地图获取数据，并提取道路和建筑的信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1486442528vnNIJI.jpg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;他谈到了传统应用 CNN 的方法，即基于卷积神经网络的小型滤波器提取局部特征。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;他提出了一种能将局部图像特征和全局图像特征相结合的神经网络架构，局部特征由像 VGG 那样的网络（小型滤波器）提取，全局特征由 AlexNet 那样的网络（相对大型的滤波器）提取。并且他添加了跳过联结（skip connections）提升了表现。（代码将会很快发布）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1486442528SLa5xv.jpg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;试验结果表明两种类型网络架构的融合提高了性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/14864425284WlhIH.jpg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;后来 MIT 的一个学生在视频数据自动标注（6）方面做了一个演讲&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;他察觉到视频帧上的监督学习需要大量的标注数据，而获取这些标注数据的成本是十分高昂的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;该演讲者介绍了一种使用隐马尔可夫模型的新方法，他利用视频帧潜在状态转移的概率帮助自动标注视频帧。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;该论文已经在标注驾驶员在汽车内的注意方向上完成了实验，自动标注准确率已经达到了 90% 多，并且降低了 84 倍标注劳动量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;该演讲者还介绍了两个很有意思的公开赛 DeepTraffic &amp;amp; DeepTesla&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;AutoX 的创始人演示了一个 Demo，用他们的深度学习算法在南海岸地区驾驶汽车的视频，并且强调了他们方法的几个独特点：&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;该讲座播放了特斯拉、Uber 和谷歌发布的 Demo，然后从里面指出了他们的物体探测边界框检测算法所犯的错。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;AutoX 声称他们不需要检测四周障碍物的边界框。他们的神经网络直接学习学习预测在每个道路线内和障碍物的距离。他们的规划控制模块并不涉及到学习，完全是基于规则编程。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;AutoX 自动驾驶不依赖任何 HD 地图进行导航。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;他们宣称主要是在 Google Street View（输入图像）和谷歌地图的开放数据上进行的训练。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;span style="font-size: 16px;"&gt;&lt;strong&gt;不仅仅是自动连接的汽车&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;尽管技术界将主要关注点放在构建自动驾驶系统上，政府和学界正在寻求一个基础框架使汽车像传感器一样能在路上行驶时进行无缝交流。普遍共识认为，实现道路基础架构的连接性（connectedness）将是对自动驾驶技术的一个非常重要的补充。也有交通理论背景的演讲嘉宾，这些嘉宾谈到了实现之后的主要好处。交通理论表明，交通流将完全和水流一样，前提是如果道路上驾驶的司机都以相同的方式驾驶。有一个连接的汽车基础架构将会促使交通流的平滑。连接的基础架构不仅可以支持车与车之间的交流，还能实现车与交通信号之间的交流、车与道路之间的交流等。要完成这个基础架构需要政府在不同层面上的大力参与。联邦高级机构的一位发言人谈到来自联邦政府的促进这个基础架构落地的计划&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;FHWA 提供资金给连接应用相关的研究，包括自适应的巡航控制、滑翔航道等汽车周边相关以及交通信号的连接（如交通灯）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;连接汽车的技术规格：5.9GHz DSRC（专用短程通信技术）+ GNSS（全球导航卫星系统——暂时没有使用的频段）速度曲线限制、红灯限制&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;复杂的政治局面需要指引。当地政府机构负责道路，联邦机构负责汽车最低必备条件的提供。汽车和道路法规来自政府两个不同层级的彼此独立管理。当构建一个连接的道路或者说汽车基础架构，那么这个两个不同层级不能继续保持独立&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;联邦政府目前正考虑给制造连接汽车的制造商授权。这项法律程序一般情况下需要花费几年。最快在 2018 年出台法律文件，这也表明最早的汽车模型将会在 2020 年出来，希望到那个时候自动化已经进入第三阶段。因新政府任命，法律进程暂时停滞。没有联邦资金什么都不会发生&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/14864425296ZojLJ.jpg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;span style="font-size: 16px;"&gt;&lt;strong&gt;产业界讲座&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;来自联邦高速管理部门的演讲者谈到了自动驾驶汽车的现状：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;出于安全与环境的考虑，才有了建立连接自动驾驶汽车的动力。2015 年大约有 35K 人死于交通事故、630 万起事故、690 万次交通延误、500 亿的公吨的二氧化碳。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;其实自动驾驶是 20 多年的老概念了，但技术还未完善。SAE J3016 为自动驾驶划分了不同的等级。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;大部分制造商提供 1 级的自动驾驶系统，一些提供了 2 级系统（Tesla）。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;十几家制造商和科技公司目前在多个州进行测试。不只是测试乘客汽车，也有重型商业卡车。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;许多制造商的目标是到 2020 年达到 3/4 等级。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;韩旭（Tony Han）是百度自动驾驶部门的主管（曾是百度 DeepSpeech 的主管），他演示百度在中国的自动驾驶视频，也讲解了他们的策略。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;以中国为主的商业策略：百度不打算与美国的公司竞争美国市场，但在技术上很乐意展开竞争。（Tony 提到百度的技术目前落后于 Waymo，但百度有冲劲，会尽快赶上。）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;谈到了中国自动驾驶面临的独特挑战：交通拥挤、司机有的很暴躁、难以识别的道路标志。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;百度的技术依赖地图，而且也正在建立自己的 HD 地图。Tony 提到建立 HD 地图的公司需要小心谨慎，防止触犯法律，因为中国这么做需要政府许可。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;百度大量的使用 Lidar 这样昂贵的传感器。他打赌不久的将来，这样传感器的价格将会大幅度削减。他们大幅度投资了 Lidar 制造商 Velodyne。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;百度也正在加州 Sunnyvale 做本地道路测试。在演示视频中，汽车好像经常骤停。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;一些公开的数据：95% 的行人检测，99.9% 的信号检测。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;span style="font-size: 16px;"&gt;&lt;strong&gt;结语&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;该研讨会针对连接自动驾驶汽车（CAV) 现在与未来的状态，给出了非常宽广与深度的描述。它也强调了我们建立 CAV 所面临的几个关键挑战：昂贵的传感器价格、缺乏 HD 地图覆盖、消费者接受度／体验、难以得出客观的安全基准从而解决不安全的问题（近期发布的 DMV「7」安全报告使用 disengagement 作为标准是模糊不清的、缺乏政府层次的基础设施支持。演讲者的不同背景也表明，解决方案不只是技术问题，也是政策问题，需要私营部门、科技／汽车／保险产业、不同政府层次（地方、州、国家层次）的公共部门之间的紧密合作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;参考文献：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: left; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;1. Mixed precision programming with CUDA 8 https://devblogs.nvidia.com/parallelforall/mixed-precision-programming-cuda-8/&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: left; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;2. End to end learning for self driving cars https://arxiv.org/abs/1604.07316&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: left; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;3. A reduction of imitation learning and structured prediction to no-regret online learning http://www.jmlr.org/proceedings/papers/v15/ross11a/ross11a.pdf&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: left; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;4. Query efficient imitation learning for End-to-End autonomous driving https://arxiv.org/pdf/1605.06450v1.pdf&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: left; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;5. A local - global approach to semantic segmentation in aerial images https://arxiv.org/pdf/1607.05620.pdf&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: left; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;6. Semi-automated annotation of discrete states in large video datasets https://arxiv.org/pdf/1612.01035.pdf&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: left; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;7. Autonomous vehicle disengagement report 2016 https://www.dmv.ca.gov/portal/dmv/detail/vr/autonomous/disengagement_report_2016&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="max-width: 100%; min-height: 1em; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; line-height: 25.6px; font-family: 微软雅黑; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; font-style: normal; color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; font-style: normal; color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;©本文为机器之心原创，&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; font-style: normal; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; max-width: 100%; min-height: 1em; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); font-size: 18px; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(127, 127, 127); line-height: 25.6px; font-family: 微软雅黑; text-align: justify; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; max-width: 100%; min-height: 1em; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(217, 33, 66); font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="max-width: 100%; min-height: 1em; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(217, 33, 66); line-height: 1.6; font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="max-width: 100%; min-height: 1em; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; font-size: 12px; color: rgb(217, 33, 66); line-height: 1.6; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/div&gt;</description>
      <pubDate>Tue, 07 Feb 2017 12:39:27 +0800</pubDate>
    </item>
    <item>
      <title>深度 | 谷歌Lukasz Kaiser为你解读深度学习如何变革自然语言处理</title>
      <link>http://www.iwgc.cn/link/4601239</link>
      <description>&lt;div class="article-content"&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;section style="font-size: 16px; white-space: normal; line-height: 28.4444px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="border-width: 0px; border-style: initial; border-color: currentcolor; font-family: 微软雅黑; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; border-style: solid none; font-family: inherit; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-top: -1.2em; min-height: 1em; font-size: 1em; border-width: initial; border-style: initial; border-color: currentcolor; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color:#ffffff"&gt;&lt;span style="background-color: rgb(117, 117, 118);"&gt;机器之心原创&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="color: rgb(62, 62, 62); background-color: rgb(255, 255, 255); padding: 16px 16px 10px; font-family: inherit; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-top: 5px; margin-bottom: 5px; min-height: 1em; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(127, 127, 127); font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;作者：&amp;nbsp;鹿者也、ChainnZ&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style="min-height: 1em; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; text-align: justify; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;br&gt;&lt;span style="font-size: 14px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 12px;"&gt;2017 年 1 月 11 日，一个名为 2017 人工智能前沿大会（AI Frontiers Conference）的会议在加利福尼亚圣塔克拉拉举行。包括 Jeff Dean（谷歌大脑的负责人）、邓力（微软人工智能首席研究员）、Adam Coates（百度人工智能实验室负责人）、Alex Smola（亚马逊机器学习负责人）在内的 20 多位世界级业内人士和研究学者向 1500 余名参会者分享了人工智能最前沿的发展情况。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;在本次会议中，谷歌大脑高级研究员 Lukasz Kaiser 就自然语言处理的发展现状及目前谷歌翻译的能力做了报告。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/14864425304XmiJI.jpg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;strong&gt;自然语言处理是什么？&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;自然语言处理近些年的变化归因于深度学习的发展。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;自然语言处理（NLP）是一个非常大的概念。在本报告中，Lukasz 将其特指为文本到文本的任务（text to text task）。许多语言学家认为文本到文本任务是绝对属于符号工程（symbolic project）的领域，包括语法分析、翻译、语言建模等。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1486442531MF4Zrp.jpg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;上述任务通常是由人类进行处理的，但神经网络能否为我们代劳？很多人不相信，直至神经网络真的做到了这一点。但神经网络是如何做到的？Lukasz 在接下来的幻灯片中给出了一些解释。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1486442531YRgbDB.jpg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;为使神经网络能理解一个句子，我们需要解决的问题到底是什么？&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Lukasz 提到：「一开始出现神经网络的时候，它主要用来做图像识别，处理同一个维度上的像素信息。而语句和图像不一样。」[1] 不同的句子由不同数量的词组成，这意味着一个句子的输入维度是不规则的。如果想用神经网络来解析这种情况，循环神经网络（RNN）将会是自然之选。接下来就是训练该网络，如果需要用到的步骤太多，计算的负担将会非常重。那么接下来，我们就用到了长短期记忆（LSTM）。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;strong&gt;先进的序列到序列 LSTM&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;LSTM 让我们能够训练这种循环神经网络。但在 1997 年，在 LSTM 应用的很早期，所能采用的规模很小，没有适合的硬件能处理这样的任务，这些缺点使得 LSTM 仅仅是一种理论突破。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;但是，人们还不能利用这种方法来解决实际的问题。直到最近这几年（大概是 2014 年），编码器－解码器（encoder-decoder）架构 [3] 的出现使得 LSTM 变成了一种切实可行的方法，该方法不仅仅能构筑单层网络，而且能构筑很多层的网络。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1486442531TLa6yw.jpg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;在构筑起这些层之后，通过更大的模型我们得到了更好的结果。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Lukasz 接下来给出了一个语法分析的例子。有了从学校学的知识，要读懂一个句子，我们可能会先识别其中的动词或名词，同时思考一下语法，就像幻灯片 5 中所示的语法分析树那样。而这是以前旧的标准做法，用这种做法去创建自然语言处理模型，去输入词汇含义、语法和句式结构，以使神经网络理解并生成句子。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1486442531EwVRih.jpg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;有别于传统的做法，Lukasz 的研究团队仅仅是把语法树写成以他们所能想象到最最简单的方式所组成的序列里的一句话，这其中包含了括号和符号。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;仅通过编写序列的方式来训练网络，而网络根本不知道什么语法树、或者括号、或者任何背景知识。这样做的问题在于缺少数据，因为所有的数据（序列）仅来源于研究人员的编写。相对于旧的训练方法，即输入语法，或者句子结构，新的训练方法似乎在提供背景知识方面更弱。但是，新的方法反而得到了更好的结果，因为网络可以自行学习所有这些知识。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;LSTM 也适用于语言模型。语言模型的性能是以复杂度来度量的。更低的复杂度就意味着更好的性能。通过与过去所用模型的对比，复杂度的测量结果急剧地下降，这意味着获得了显著的改进。在 2016 年所达到的最好分数是 28（而 2013 年是 67.6），能达到这样的成绩在以前被认为是不可能的。决定因子是模型的大小。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1486442532KC1Xpn.jpg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Lukasz 也给了一些 LSTM 应用于语言建模和句子压缩方面的例子。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;最让人印象深刻改进发生在将 LSTM 应用于翻译领域。正像 Lukasz 所描述的那样，在学校里，我们逐词地学习外国语言。但是如果我们不用这种方式来学，我们就是听人们用那种需要交流，看上去好像也可以。实际上，幼儿们学习就是采用这种方式，这实际上就是神经网络学习的方式。在这种情况下，训练数据的大小和数量是问题的关键。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;翻译的性能由 BLEU 分数来衡量，分值越高性能越好。在过去的两年中，分值从 20.7 提升到了 26.0。Lukasz 的模型大小似乎是决定因素。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/14864425321UjeGE.jpg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;在早些年（两年以前），经过训练的网络能够达到「人工系统」（也就是能逐个短语进行转化的短语系统）的水平，并且把它做的越来越大，但却始终达不到比较好的效果。通过比较 PBMT（一种旧的标准翻译模型）和 GNMT（采用了 LSTM 的新模型）的结果你会发现，同样是翻译一个德语句子，新模型的结果很明显更清晰更能让人理解。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;这样的结果说明翻译过程不再是非要人工参与的工作，而可以变成仅仅需要一个大的神经网络和很多次训练而已。正如 Lukasz 所说，该理论对于许多自然语言处理任务都适用。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;不过它究竟有多好呢？我们能考评它吗？我们请人对谷歌翻译最新发布的神经网络的翻译结果进行评价，评价的分值从 0 到 6，其中 0 分意味着翻译得无厘头，6 分意味着是完美的翻译。而且，为了对新旧系统进行比较，我们请人工的翻译（母语是该语言但不是专业的语言学家）也加入这场比赛，并且也让人们去评分。下一张幻灯片显示了这三种翻译系统的评分结果。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1486442532MF4Zrp.jpg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;结果显示新的系统有了巨大的改进，而且在某些情况下（比如英语到西班牙语的翻译）几乎和人类的翻译者一样好。通过研究发现，更大的数据库能产生更好的结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/14864425331TieGE.jpg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;strong&gt;LSTM 的局限&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;但是，序列到序列 LSTM 仍然有一些问题待解决。Lukasz 列出了其中的两个：&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;1. 速度的限制&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;这些模型都很大。鉴于对数据库大小的依赖，牵扯到相当大的计算量，在这种情况下，处理速度是个大问题。为了缩短处理时间，TPU 在帮助研究人员开展这种翻译的时候是一个很重要的硬件选择。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;除此之外，翻译的过程太循序渐进了。即使计算的速度非常快，仍然要一个词一个词地来。即使是一个小任务，处理时间也很慢。为了解决这一问题，新的并行模型（Neural GPU, ByteNet）也许期望能帮助解决这个问题。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;2. 需要很多数据&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;序列到序列 LSTM 需要很多数据。为了解决这个问题，提出了基于注意力和其他能增加数据效率的新架构。其他一些方法可以被用于进行规则化，比如 dropout、信任惩罚（confidence penalty）以及层标准化。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;strong&gt;总结&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;深度学习极大地改变了自然语言处理领域。序列到序列的 LSTM 在很多自然语言处理任务上取得了业界最好的成绩。Google 翻译将 LSTM 用于产品中，获得了翻译质量的巨大提高。但是，新的模型也带来了一些 LSTM 的问题，特别是在速度与对大量数据的依赖上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="min-height: 1em; text-align: justify; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="line-height: 25.6px; font-family: 微软雅黑; font-size: 14px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; color: rgb(127, 127, 127); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="color: rgb(62, 62, 62); line-height: 25.6px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; color: rgb(127, 127, 127); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;©本文为机器之心原创，&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; font-size: 18px; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(127, 127, 127); line-height: 25.6px; font-family: 微软雅黑; text-align: justify; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(217, 33, 66); font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(217, 33, 66); line-height: 1.6; font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-size: 12px; color: rgb(217, 33, 66); line-height: 1.6; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/div&gt;</description>
      <pubDate>Tue, 07 Feb 2017 12:39:27 +0800</pubDate>
    </item>
    <item>
      <title>资源 | 谷歌开源BoundingBoxes，迄今为止最大的带注释图像数据集</title>
      <link>http://www.iwgc.cn/link/4601240</link>
      <description>&lt;div class="article-content"&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;section style="max-width: 100%; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; background-color: rgb(255, 255, 255); line-height: 28.4444px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%; border-width: 0px; border-style: initial; border-color: currentcolor; font-family: 微软雅黑; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; max-width: 100%; border-style: solid none; font-family: inherit; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-top: -1.2em; max-width: 100%; min-height: 1em; font-size: 1em; border-width: initial; border-style: initial; border-color: currentcolor; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(255, 255, 255); background-color: rgb(117, 117, 118); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;选自Google Research Blog&lt;/span&gt;&lt;/p&gt;&lt;section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px; max-width: 100%; font-family: inherit; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-top: 5px; margin-bottom: 5px; max-width: 100%; min-height: 1em; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(127, 127, 127); font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-top: 5px; margin-bottom: 5px; max-width: 100%; min-height: 1em; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(127, 127, 127); font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="color: rgb(127, 127, 127); font-family: 微软雅黑; font-size: 12px; text-align: center; white-space: normal; background-color: rgb(255, 255, 255); max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;参与：李泽南、朱思颖、蒋思源&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style="max-width: 100%; min-height: 1em; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 12px;"&gt;昨日，谷歌宣布开放了一个基于 Youtube 视频的图像数据集 Youtube&lt;span style="text-align: justify;"&gt;-BoundingBoxes Dataset&lt;/span&gt;，为所有研究者进行模型训练和研究提供了新资源。谷歌宣称这个数据集的检测数量（detection count）为ImageNet的五倍。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;目前深度学习面临的最大挑战之一是让计算机能够理解一个具体场景。举个例子，虽然人类知道在一堵墙后消失并很快再次出现的小球很可能是同一个物体，但这对算法来说一点也不显而易见。理解这样的场景不仅需要一组对视频里每一帧所包含的物体的全局图片，而且还需要对这些物体在每一帧内的位置以及位置进行记录。YouTube-8M 是我们在去年刚刚发布的数据集，这个数据集是由自动标记的 YouTube 视频组成。尽管这个数据集的推出促进了这个领域进一步的研究进展，但它只是解决这个难题的一块拼图。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;今天，为了促进视频理解研究领域的研究进展，我们推出了 YouTube-BoundingBoxes 数据集，这个数据集包含有在 23 个物体类别上的 1050 万人工标注的帧，其中包含 500 万边界框（bounding boxes），它们密集标记了 38 万条 15-20 秒钟长度的 YouTube 视频片段（从 24 万个视频中截取），其图像质量类似于手机摄像。这个数据集的标注和边界框精度超过了 95%。迄今为止，它是对时间连续帧内的物体进行跟踪，包含边界框的最大人工注释视频数据集。这个数据集的体量足以用于训练大规模模型，并且可为真实场景的视频捕捉进行训练。最重要的是，数据集中人工标记的注释包含了物体在真实世界中被遮挡、产生运动模糊和自然光照变化等情形。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1486442534YRgbDB.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;span style="font-size: 12px; color: rgb(136, 136, 136);"&gt;&lt;em&gt;左侧条形图：现有图片（红）与视频（蓝）数据集的检测数量对比。其中 YT-BB 的数字在最下面。右侧表：计数、分类注释和带有边界框的视频&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;该数据集的关键特点是：它为所有视频加入了边界框及注释，这些边界框可以用于训练利用时态信息进行识别、定位和追踪对象的模型。在视频中，单个带注释的对象可能会被完全遮挡，并在随后的帧中再次出现。所以，针对某个对象的注释可能不会出现在所有帧上，但是如果它被正确地定位和追踪到，则可以在整个视频的尺度上被模型理解和识别。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;我们希望这一数据集最终能帮助到计算机视觉和机器学习社区，最终激发出解决真实世界问题的新的分析和理解工具。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1486442535PH62ts.jpg"/&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;&lt;em&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;四个视频片段，以每秒一帧的频率采样。第一个例子的最后一帧显示了由于图像模糊和遮挡（上图火车，蓝色箭头）对识别有界对象在视觉上的挑战性。当然，这些相对清晰的，时间上紧连的帧，仍然可以让计算机在其中识别物体。注意：在红色框中的事物可能有一部分无法被分辨出来：中上图橙色箭头所指的熊，它的头不可见。中下图蓝色箭头所指的两只狗，身体的一部分被互相遮挡。下图的飞机事例中，物体的一部分在镜头之外。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;我们希望这个数据集可以帮助计算机视觉和机器学习界的研究者，找到新的分析和理解现实世界视觉问题的方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;相关论文：YouTube-BoundingBoxes: A Large High-Precision Human-Annotated Data Set for Object Detection in Video&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1486442535WOd9Az.jpg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px; text-align: justify;"&gt;摘要：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px; text-align: justify;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px; text-align: justify;"&gt;我们引入了一个视频 URL 的大型数据集，它被密集采样对象边界框（densely-sampled object bounding box）进行了标注，我们称它为 YouTube-BoundingBoxes（YT-BB）。该数据集由大约 38 万个约 19 秒长的视频段组成，在没有进行编辑或后处理情况下自动被选为在自然设置中抽取目标特征，这些短视频的录制质量相当于手机视频拍摄的质量。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;目标表征了 COCO 标注数据集的一个子集。所有视频段被都用高精度分类标签和边界框以每秒一帧图片的频率进行了人工标注。我们使用了精确的人工注释级联确保每个类和紧密边界框（tight bounding boxes）的标注精度高于 95％。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;最后，我们使用它训练和评估了几种著名的深度学习网络架构，并报告了每帧分类和定位的的基准数据，从而为以后的研究提供一个可比较的基准点。我们还证明了视频时间的邻近性（the temporal contiguity of video）可以如何提升这种推论。目前，这个数据集已被公开，我们希望这个巨大的数据库可以推动视频对象检测和跟踪的新进步。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;相关链接：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: left; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 12px;"&gt;Youtube8M：&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: left; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;https://research.google.com/youtube8m/ (https://research.google.com/youtube8m/%E3%80%82)&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: left; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;Youtube BoundingBoxes：&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: left; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;https://research.google.com/youtube-bb/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="max-width: 100%; min-height: 1em; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; line-height: 25.6px; font-family: 微软雅黑; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; font-style: normal; color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; font-style: normal; color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;©本文为机器之心编译，&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; font-style: normal; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; max-width: 100%; min-height: 1em; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); font-size: 18px; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(127, 127, 127); line-height: 25.6px; font-family: 微软雅黑; text-align: justify; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; max-width: 100%; min-height: 1em; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(217, 33, 66); font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="max-width: 100%; min-height: 1em; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(217, 33, 66); line-height: 1.6; font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="max-width: 100%; min-height: 1em; color: rgb(62, 62, 62); white-space: normal; background-color: rgb(255, 255, 255); font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; font-size: 12px; color: rgb(217, 33, 66); line-height: 1.6; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/div&gt;</description>
      <pubDate>Tue, 07 Feb 2017 12:39:27 +0800</pubDate>
    </item>
    <item>
      <title>开源 | 微软开源生物模型分析器：一款基于云的生物研究工具</title>
      <link>http://www.iwgc.cn/link/4601241</link>
      <description>&lt;div class="article-content"&gt;&lt;p style=" max-width: 100%; min-height: 1em; color: rgb(62, 62, 62) ; ; ; ; ; ; ; ; ; ; ; ; ; "&gt;&lt;span style="max-width: 100%; font-family: 微软雅黑, sans-serif; font-size: 15px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;section style="max-width: 100%; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; line-height: 28.4444px; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%; border-width: 0px; border-style: initial; border-color: currentcolor; font-family: 微软雅黑; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; max-width: 100%; border-style: solid none; font-family: inherit; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-top: -1.2em; max-width: 100%; min-height: 1em; font-size: 1em; border-width: initial; border-style: initial; border-color: currentcolor; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(255, 255, 255); background-color: rgb(117, 117, 118); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;转自微软亚洲研究院&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px; max-width: 100%; font-family: inherit; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-top: 5px; margin-bottom: 5px; max-width: 100%; min-height: 1em; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(127, 127, 127); font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;微软研究院AI头条&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style="max-width: 100%; min-height: 1em; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=" max-width: 100%; min-height: 1em; color: rgb(62, 62, 62) ; ; ; ; ; ; ; ; ; ; ; ; ; "&gt;&lt;span style="max-width: 100%; font-family: 微软雅黑, sans-serif; font-size: 15px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;微软近日在 GitHub 上开源了「生物模型分析器」（Bio Model Analyzer，简称 BMA）。这是一款能够帮助生物学家模拟细胞互动和通信过程的基于云的工具。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;生物模型分析器（BMA）能够创建计算机模型，让研究人员将健康细胞的正常代谢过程与疾病发作时的异常代谢过程进行对比。「在硅基上」（即使用计算机而非较为传统的模型）从事这项工作，将允许研究人员以更快的速度检测比以前更多样的可能情况。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;微软英国剑桥研究院编程原理及工具研究组资深研究员、剑桥大学生物化学系副教授 Jasmin Fisher 认为，BMA 还可以加速有关药物间相互作用和抗药性等领域的研究，并可能最终为患者提供更为个性化和有效的癌症治疗方案。&lt;/span&gt;&lt;/p&gt;&lt;p style=" max-width: 100%; min-height: 1em; color: rgb(62, 62, 62) ; ; ; ; ; ; ; ; ; ; ; ; ; "&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=" max-width: 100%; min-height: 1em; color: rgb(62, 62, 62) ; ; ; ; ; ; ; ; ; ; ; ; "&gt;&lt;span style="max-width: 100%; font-family: 微软雅黑, sans-serif; font-size: 15px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=" max-width: 100%; min-height: 1em; color: rgb(62, 62, 62) ; ; ; ; ; ; ; ; ; ; ; ; "&gt;&lt;img src="http://wxrss.b0.upaiyun.com/1486442537ME3Zqp.jpg"/&gt;&lt;/p&gt;&lt;p style=" max-width: 100%; min-height: 1em; color: rgb(62, 62, 62) ; ; ; ; ; ; ; ; ; ; ; ; ; "&gt;&lt;span style="max-width: 100%; font-family: 微软雅黑, sans-serif; color: rgb(178, 178, 178); font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;Jasmin Fisher&lt;/span&gt;&lt;span style="max-width: 100%; font-family: 微软雅黑, sans-serif; font-size: 15px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/span&gt;&lt;br style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/p&gt;&lt;p style=" max-width: 100%; min-height: 1em; color: rgb(62, 62, 62) ; ; ; ; ; ; ; ; ; ; ; ; "&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;BMA是微软利用计算机科学加速癌症研究和治疗突破的研究项目之一。Fisher在2016年的一篇报道中说：“我们正努力变革生物学日常研究的方式。”&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;GitHub链接：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;https://github.com/Microsoft/BioModelAnalyzer&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px;"&gt;BMA官网：http://biomodelanalyzer.org/&lt;/span&gt;&lt;/p&gt;&lt;p style=" max-width: 100%; min-height: 1em; color: rgb(62, 62, 62) ; ; ; ; ; ; ; ; ; ; ; ; "&gt;&lt;span style="max-width: 100%; font-family: 微软雅黑, sans-serif; font-size: 15px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p style="max-width: 100%; min-height: 1em; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; text-align: justify; line-height: 1.75em; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; line-height: 25.6px; font-family: 微软雅黑; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; font-style: normal; color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; font-style: normal; color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;©本文为机器之心获授权转载，&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; font-style: normal; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;转载请联系微软亚洲研究院&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; max-width: 100%; min-height: 1em; color: rgb(62, 62, 62); white-space: normal; font-size: 18px; line-height: 1.75em; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(127, 127, 127); line-height: 25.6px; font-family: 微软雅黑; text-align: justify; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; max-width: 100%; min-height: 1em; color: rgb(62, 62, 62); white-space: normal; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(217, 33, 66); font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="max-width: 100%; min-height: 1em; color: rgb(62, 62, 62); white-space: normal; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(217, 33, 66); line-height: 1.6; font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="max-width: 100%; min-height: 1em; color: rgb(62, 62, 62); white-space: normal; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; font-size: 12px; color: rgb(217, 33, 66); line-height: 1.6; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/div&gt;</description>
      <pubDate>Tue, 07 Feb 2017 12:39:27 +0800</pubDate>
    </item>
  </channel>
</rss>
