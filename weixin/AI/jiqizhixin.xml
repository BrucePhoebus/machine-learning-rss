<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>机器之心独家对话吴恩达：很多技术其实是中国最先开始应用的</title>
      <link>http://www.iwgc.cn/link/3966674</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;吴恩达，百度首席科学家、百度大脑项目负责人。在最近的百度语音开放平台三周年主题活动上，机器之心对这位与 Geoffrey Hinton、Yoshua Bengio、Yann LeCun 齐名的人工智能专家进行了专访，深度了解了百度的人工智能研究、吴恩达的人工智能之路，以及更多的有关人工智能技术的话题。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;一、在百度的人工智能研究&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2014 年 5 月 16 日，百度官方宣布建立硅谷实验室并任命吴恩达作为首席科学家，领头百度北京与硅谷的实验室。当时，百度投入了 3 亿美元在硅谷建起专注人工智能的实验室。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但吴恩达来到百度，并非重头开始建立深度学习。在 2013 年，百度就已建立深度学习研究院（IDL），并在图像识别、基于图像的搜索、语音识别、自然语言处理与语义智能、机器翻译等领域做出重大进展。当时，IDL 由余凯（2012 年加入百度，2015 年离职）组建，百度 CEO 李彦宏任院长，余凯任常务副院长。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;加入百度之后，吴恩达做了一件事。「他订购了 1000 个 GPU，并在 24 小时内得到。而在谷歌，他可能几周或几个月才能得到。」当时深度学习创业公司 SkyMind 的联合创始人 Adam Gibson 在一次采访中曾这么说道。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;百度之前从未买过这样的硬件。在这样的支持下，吴恩达在百度建立了一个进行深度学习的 GPU 集群，使得百度成为了世界上第一个建立深度学习 GPU 集群的公司。几年来，百度不断在 GPU 和超级计算机方向做投入，加大深度学习的研究。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在加入百度之后，曾帮助谷歌建立 Google Brain 的吴恩达也在百度建起了「大脑」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW97Eu3kQ28xCXnW6b2iagC06aJ5JbdzicYLg8nIsUXIQRMFuF31tw1kj7kcVXsPwpwENvL2LFAvp0QA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图片：百度大脑官网&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从百度大脑的官网，我们就可以明晰的看到吴恩达在百度的人工智能研究：机器学习、语音技术、图像、自然语言处理、用户画像。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;机器学习&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今年 9 月份，吴恩达在百度世界大会上宣布开源深度学习平台 PaddlePaddle。PaddlePaddle 的前身是百度于 2013 年自主研发的深度学习平台 Paddle（Parallel Distributed Deep Learning，并行分布式深度学习），一直为百度内部工程师研发使用，并且已经做出了一些实际的产品，较为成熟。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;据介绍，PaddlePaddle 是一个云端托管的分布式深度学习平台，支持 GPU 运算，支持数据并行和模型并行。对于序列输入、稀疏输入和大规模数据的模型训练有着良好的支持，仅需少量代码就能训练深度学习模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是在谷歌宣布开源 TensorFlow 之后，又一科技巨头开源的深度学习平台。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不到一个月，百度再次宣布开源基准工具 DeepBench，可对硬件平台的深度学习性能进行评估，帮助硬件开发人员优化深度学习硬件，从而加快深度学习研究。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW97Eu3kQ28xCXnW6b2iagC06hiaY6xxibqE9fllXc5YlWVML3MwtJr9GhFjEGtBETb1mMr5queCuCPiaQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;语音技术&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「百度大脑已经有好几种不同的人工智能技术，其中比较成熟的就是我们的语音技术。」吴恩达在百度语音开放平台三周年的主题活动上说。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW97Eu3kQ28xCXnW6b2iagC06Gwpq19nK1qqaLcT1jKPV8icR0UlhuhbKyefHqtMON0J0FcWCI4CYgzw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;长久以来，人与机器交谈一直是人机交互领域内的一个梦想。最近几年来，随着深度神经网络的应用，计算机理解自然语音的能力也有了彻底革新。但人机的自然交互，涉及到语音方面的多项技术。在此次主题活动上，吴恩达谈到了百度在语音识别、语音合成、语音输入方面的研究。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「这几年来，我们的团队在不断地优化语音识别系统，在 2012 年开始使用 DNN 模型，后来有比较好的特征，之后开始用 Sequence Discriminative Training，也开始使用 LSTM 模型，加上 CTC，今年我们的团队开发了 Deep CNN 模型，效果在不断进步，这就是我们的语音识别系统。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;百度于 2015 年 11 月发布的 Deep Speech 2 已经能够达到 97% 的准确率，并被麻省理工科技评论评为 2016 年十大技术突破之一。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;语音识别的记录不断在被刷新，今年微软在英语语识别上准确率的突破也几乎媲美人类。但是，使用计算机生成语音——这个过程通常被称为语音合成（speech synthesis）或文本转语音（TTS）——仍在很大程度上基于所谓的拼接 TTS（concatenative TTS），其中有一个由单个人录制的大量短语音片段构成的非常大的数据库，然后再将这些短语音组合起来构成完整的话语。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今年 9 月份的时候，谷歌 DeepMind 爆出在语音合成上的突破性研究——WaveNet，将机器语音合成的表现与人类之间水平的差距至少缩减了 50%。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们的语音合成模型也变得越来越好。这几年来我们在好几个技术方面有比较大的突破，语音合成效果变得越来越好。现在百度在中国语音合成的能力达到业界领先的水平。」据百度讲，百度情感合成技术主要聚焦在为合成语音「加入情感」，目前可达到接近真人发声效果。它们在今年早些时候曾利用此技术，复原已逝明星张国荣的声音。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2016 年，我们也看到了深度学习在图像（识别准确率、风格迁移）、自然语言处理、机器翻译（谷歌神经机器翻译系统）等其他领域取得的最新进展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;比如在自然语言处理任务上，序列到序列模型的注意实现了很大的进展。在后续的专访中，吴恩达表达了自己的看法，「从研究者的角度来看，未来几年有非常多有可能带来突破的思想，它们有可能能够以全新的方式创造出更好的自然语言处理系统。比如说，在词嵌入（word embedding）上，我们可以看到仍有很大的进展。在跨模型学习上，也有一些研究成果。当你同时学习计算机视觉和自然语言处理的时候，那是非常激动人心的。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在研究上，吴恩达认为迁移学习和多任务学习是很好的研究方向。他拿百度的 NLP 团队在 2015 年研究举例说，「如果同时学习多个语言对之间的翻译，效果会比同时学习一个语言对的效果好。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当时，谷歌的神经机器翻译的出现引起了业内的极大关注。但在机器之心之前对百度 NLP 团队的专访中，我们了解到百度的在线翻译系统一年前就应用了基于神经网络的翻译方法。去年百度在 ACL 会议上发表论文《Multi-Task Learning for Multiple Language Translation》，探讨用 NMT 技术解决多语言翻译及语料稀疏的问题，这也就是吴恩达上面所说的多任务学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;说到谷歌的神经机器翻译，我们依此为例向吴恩达追问技术到产品的部署问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;吴恩达回应说，「中国、美国和其它地方的公司在实现先进人工智能的产品部署上都动作很快。但很多人并不知道很多部署实际上是中国的公司最先开始的，虽然不是全部，但也不少。就拿使用神经网络来为机器翻译进行序列学习的特定例子来说吧。实际上，百度比谷歌更早搞明白如何开发和部署它。除此之外，我们还能找到很多首先在中国被开发出来或产品化的技术。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他还提到，「中国科技行业的发展速度是激动人心的。然而现在却有一个令人吃惊的事实摆在我们面前：很多东西是最先在中国实现的，可能一年之后才传入美国，但人们首先想到的还是美国的例子，而不是中国的。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;也许这是对中国人工智能研究实力的一次很好回应。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今年 10 月份的时候，白宫发布的《国家人工智能研究与发展策略规划》报告中称中国的人工智能研究已经走在了美国前面。在提及「深度学习」或「深度神经网络」的期刊论文数量上，中国在 2013 年就超越了美国。而且有媒体称，中国的相关论文不仅数量上远超其他国家，质量上的表现也毫不逊色。这一消息受到了业内许多人士的质疑，认为数量不谈，质量上肯定还有很大差距。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;众说纷纭，难以有一基准评出高低。但高盛近期的一份调查报告认为，人工智能前沿的参与者可能会继续来自美国和中国。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;人工智能之路&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1976 年初生，吴恩达今年刚好 40 岁，不惑之年。他与 Geoffrey Hinton、Yoshua Bengio、Yann LeCun 合称为深度学习「四大天王」，但有人曾质疑吴的人气为何这么高？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 VB 较早的一篇专访中是这样评论吴恩达的，「Bengio 在训练神经网络上取得很大进展，LeCun 开发了卷积神经网络，Hinton 普及了受限玻尔兹曼机。而吴采用最好的，并进行部署与改进。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谈起吴恩达，我们会想到他做过哪些事？取得过哪些成就？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;吴恩达出生于伦敦，父亲是一位香港医生。吴恩达年轻时候是在香港和新加坡度过的，父亲对人工智能在医疗领域的应用的兴趣影响到了他。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他告诉我们，「当时我还在新加坡，我的父亲是一位医生，他对人工智能在医疗领域的应用很感兴趣。所以当时我就很幸运地有些人工智能方面的书。我很小就开始学习人工智能，确切地说，是我 12 岁的时候。我 16 岁时，很幸运地进入新加坡国立大学做实习。在那里，我开始研究神经网络，甚至和教授一起写了一篇小的研究论文。那篇论文今天看来不怎么样，所以我也就不推荐你们读了。不过打那时起，我就对神经网络以及它们从数据中学习的能力，非常着迷。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;21 岁时，吴恩达获得了卡内基梅隆大学的计算机科学学士学位。之后他在 1998 年获得了麻省理工学院的硕士学位，并于 2002 年获得了加州大学伯克利分校的博士学位，导师是 Michael I. Jordan。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在拿到博士学位后，吴恩达开始了在斯坦福大学的工作。后来，他成为了斯坦福大学计算机科学系和电子工程系副教授，人工智能实验室主任。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2010 年，时任斯坦福大学教授的吴恩达加入谷歌开发团队 X Lab，作为顾问。他是较早从学界加入产业界的研究人员之一。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从 2010 年到今年，随着人工智能、深度学习的兴起，越来越多优秀的学术界人才被企业所拉拢——Geoffrey Hinton、Russ Salakhutdinov、李飞飞。这一现象的加剧引起了业内的一阵恐慌，害怕优秀学者的流失会影响人工智能人才的造血。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谈到这一现象吴恩达观察到了不一样的角度，他认为近期的另一个变化就是公司也在创造人工智能人才，可能创造人才的规模要比学校更大：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「因为极大的缺乏人才，所以百度这样的公司的招聘部门都投入很大。这也是为什么百度里有无数关于深度学习、计算机视觉、自然语言处理、语音识别的课程，我们会常规性的训练职员，从而让他们更有所长。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;事实上，百度硅谷办公室已经有了这样的荣誉：硅谷学习人工智能的地方。所以，我认为除了大学之外公司成为创造更多人工智能人才的地方来帮助我们做激动人心的工作，这是一个非常有前景的发展，这就是我们所面临的。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;教学课程，是吴恩达的另一荣誉。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2008 年，吴恩达发起了「Stanford Engineering Everywhere」（SEE）项目，把斯坦福的许多课程放到网上，供免费学习。他自己也教了一些课程，如机器学习课程，包含了他录制的视频讲座和斯坦福 CS299 课程的学生材料。2011 年 8 月时，Coursera 作为一家公益创业公司正式成立，并逐渐成为了世界上最大的 MOOC 平台之一。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;同样是 2011 年，吴恩达与 Jeff Dean、Greg Corrado 联合创立了谷歌大脑。当时，吴恩达向谷歌 Jeff Dean 提及了自己在 X 内部实验的项目 Project Marvin，然后他们用自己的空余时间催生出了谷歌大脑（后来拉来了有神经科学背景的 Greg Corrado）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在谷歌大脑期间，最出名的案例就是他们所开发的人工神经网络通过观看 YouTube 视频，自主学会识别哪些是关于猫的视频。这个案例为人工智能领域翻开崭新一页。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从2002年博士毕业任教到现在成为百度首席科学家，吴恩达 14 年中在谷歌、斯坦福、百度都带领、扶持过一些成功的人工智能团队。基于这些经验，他近期曾在哈佛商业评论上撰文呼吁大部分有数据但缺乏深度人工智能知识的公司来&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720432&amp;amp;idx=2&amp;amp;sn=83ae4ce687079fe40c273abad7a34603&amp;amp;chksm=871b0cceb06c85d8d48047e61a3782dbea3e926a4282e50986cb2fb3014e4dc23cb7ec031d0c&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720432&amp;amp;idx=2&amp;amp;sn=83ae4ce687079fe40c273abad7a34603&amp;amp;chksm=871b0cceb06c85d8d48047e61a3782dbea3e926a4282e50986cb2fb3014e4dc23cb7ec031d0c&amp;amp;scene=21#wechat_redirect"&gt;设立首席人工智能官&lt;/a&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他对我们解释说，「我们都知道人工智能意味着什么，在目前的发展环境下，公司需要重新考虑自身业务如何与新技术相结合以获得竞争优势。越来越多的公司雇佣了熟悉人工智能的高管，我认为这很快就会形成一个特定的职位。我认为有专人来从事这一工作会使公司的运转效率更高，这个人需要拥有足够的技术知识，对人工智能的发展有独到的见解。所以首席人工智能官需要通晓人工智能的运行方式，而不仅仅是具有技术知识，它需要有开阔的眼界，明白如何将技术用于促进商业发展，为公司带来效益。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心原创文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 18 Dec 2016 10:36:44 +0800</pubDate>
    </item>
    <item>
      <title>学界 | OpenAI MiniWoB环境介绍：与网站交互的强化学习代理基准</title>
      <link>http://www.iwgc.cn/link/3966676</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自OpenAI&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Mini World of Bits，简称 MiniWoB，是一个用于与网站交互的强化学习代理的基准。其代理可以感知小网页（210x160 像素）的原始像素和产生键盘和鼠标动作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;iframe class="video_iframe" data-vidtype="2" style="   z-index:1; " height="375" width="500" frameborder="0" data-src="https://v.qq.com/iframe/preview.html?vid=g1311y86ym2&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0" allowfullscreen=""&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该环境用 HTML/Javascript/CSS 写成，设计的目的是为了测试代理与常见网页浏览器元素的交互能力，这些元素包括按钮、文本框、滑块、日期选择器等等。这个基准的环境可以通过 OpenAI Universe 获取。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;发布地址：&lt;span&gt;http://alpha.openai.com/miniwob/index.html&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;环境预览地址：&lt;span&gt;http://alpha.openai.com/miniwob/preview/index.html&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;OpenAI Universe：&lt;span&gt;https://universe.openai.com&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;MiniWoB 环境&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中的每一个环境都是一个 210 像素高、160 像素宽的 HTML 网页（即与 ATARI ALE 模拟器的尺寸相同）。其最顶上的 50 个像素（黄色背景）包含了任务查询——一个关于代理应该在坏境所做的事情的描述。该环境的逻辑是用 Javascript 编写的，其会监控事件并分配奖励（reward）。我们认为 MiniWoB 就类似于是视觉识别领域的 MNIST 数据集，其中的这些环境很小、是自包含的（self-contained）、并且含有许多代理在浏览互联网时需要克服的挑战。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该基准中的任务包含许多常见的 UI 元素，范围涵盖从简单（比如点击取消按钮）到复杂（比如，搜索从 SFO 到 LAX 的 2016 年 12 月 5 日的航班并预定最便宜的机票）等各种难度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9kibMYlPbZoY8fPoWnM3PWaSXwdRPsP44sE7mDkthfnibBFMXmFn5sgC20rBSDLBq0QKXqgM0o1t3g/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;基准&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;MiniWoB 基准包含了一系列训练/测试分开的环境。其终极目标是在无需太多交互步骤的情况下在测试环境上良好地执行任务。被测试的模型可以在训练环境中进行不限次数的预训练。我们也计划发布训练环境的演示，因为许多模型如果仅靠强化学习，可能难以取得良好的效果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;12/05/2016, Version 0&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;80 environments&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;train/test split COMING SOON&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;贡献环境。因为该环境目前还非常小，而且也很容易通过 Javascript/HTML/CSS 书写，所以我们也鼓励社区为未来该基准的发行版提供贡献。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;MiniWoB 的完整源代码将在未来几周通过 GitHub 发布，所以贡献也将变得非常方便。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;启动代码&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些环境都被整合到了 OpenAI Universe 之中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了训练强化学习代理，我们调整了运行 MiniWoB 环境的 Universe 指令。下面的简单代码可以用来创建一个可以以 5 FPS 的速度在 MiniWoB 的 160x160 像素的「游戏」区域随机点击的代理：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9kibMYlPbZoY8fPoWnM3PWaSrXQXmy9Fg0nmhqDeTNSAiaoWicMmOjkt799icYTeqhts0RRcKLnPMjdw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;原文链接：http://alpha.openai.com/miniwob/index.html&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;br/&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;br/&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 18 Dec 2016 10:36:44 +0800</pubDate>
    </item>
    <item>
      <title>专栏 | 当AI遇上AR ——从微软HoloLens Processing Unit (HPU)说起</title>
      <link>http://www.iwgc.cn/link/3966677</link>
      <description>&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心专栏&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：痴笑&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;AI+AR&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能（AI）与增强现实（AR）的概念在最近乃是当红炸子鸡，火遍大江南北。AI 与 AR 的概念区别不小，但是也有不少交集。目前，AI 最热门的应用就是在计算机视觉（Computer Vision，CV）领域，而 AR 的实现（图像渲染）自然也离不开 CV 。举个例子吧！《龙珠》想必大家都看过（如果你没看过说明你很年轻！大叔很羡慕你！），里面的战斗力探测眼镜就是 AI + AR 的一个极好例子：战斗力探测眼镜用基于 CV 的 AI 首先做物体识别，把眼镜视野里面的战斗对象与背景区分开，然后用一套AI算法去评估该对象的战斗力，最后把战斗力标注到眼镜视野里的目标周围（什么？战斗力只有5？），从而实现 AR 。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW97Eu3kQ28xCXnW6b2iagC06hc1lYdnJHWPic1nEf4GOYicVhaDtNoRmRQ2flnp95ickTGJWq6GsqtxMw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;《龙珠》里的战斗力探测眼镜是AI+AR应用的一个极好例子&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;HoloLens 与 HPU&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如今，实现战斗力探测的 AI + AR 技术已经不再为赛亚人所独有，地球人也拥有了这项技术！例如，微软的 HoloLens 在已公布的 AI + AR 设备中可谓佼佼者，凭借微软的金字招牌以及酷炫的演示动画吸引了无数科技爱好者的眼球。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前，用于 AI / AR 的处理器架构该如何设计仍然处于探索阶段，Intel 想借机推自己基于 CPU 的方案，Nvidia 想利用 GPU 弯道超车，而 Qualcomm 也拼接 Snapdragon 平台在一边虎视眈眈。在今年的商用芯片峰会 HotChips 上，微软公布了应用在 HoloLens 中的处理器芯片（HoloLens Processing Unit, HPU）。HPU 的架构和 CPU 以及 GPU 都不相同，可谓是开创了 AI / AR 领域芯片的新范式。我们采访了 UCLA 从事人工智能芯片和硬件研究的 Li Du, Yuan Du 以及 Yilei Li 博士，接下来将详细分析 HPU 芯片架构并展望未来 AI / AR 芯片设计中的范式转换。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW97Eu3kQ28xCXnW6b2iagC060A0S4Jtoic6M4ls2LfO8KzvegU8ghALZCoOlc38VMZ67EDibFUd3wHuw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;em&gt;&lt;span&gt;HoloLens可以实现众多AI/AR应用&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微软公布的 HoloLens 系统架构如下图所示。就在绝大多数移动设备的处理器都基于 ARM 结构的今天，HoloLens 的主处理器使用的仍然是 Intel 的 Cherry Trail SoC（包括CPU与集成的GPU），让人感叹维持了二十余年的 Wintel 联盟坚不可破。微软最新公布的 HPU 也可以在图上看到，HPU 严格来说是一款协处理器，其作用是协助主处理器加速运算一些专门的运算（如用于 CV 的矩阵运算，用于 CNN 的卷积运算等）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 UCLA 有多年异构运算与互联研究经验的 Yuan Du 博士表示，「由于 CPU 必须要考虑通用性而无法对一些 AR / VR 运算进行优化，因此在应用场景中会大量遇到的专门运算如果都交给 CPU 做会使系统的整体性能变得很差，于是我们需要设计一款专用的加速器来协助加速这些运算，微软在这里的加速器就是 HPU 。HPU 通过 PCIe 高速接口与主处理器所在的 SoC 通信，不过 PCIe 的功耗其实是比较大的，未来可望会用上更先进的互联技术。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微软公布的 HPU 处理能力达到每秒 1T（10^12）次像素运算，功耗则小于 4W。HPU 能够融合来自 5 个摄像头、一个深度传感器以及运动传感器的输入信息，将信息压缩并传送到主处理器。此外 HPU 还能实现 AI 手势识别。据说微软曾评估了来自于各大厂商的商用芯片，却没有找到任何一款产品能满足系统算法对性能的要求。这款微软自己开发的 HPU 是采用台积电 28nm 工艺，内含 24 颗可重配置的 Tensilica 数字信号处理器（DSP）核心以及高达 8MB 的 Cache。除此以外，还有专用加速器用于给各类专门任务加速。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW97Eu3kQ28xCXnW6b2iagC06Uc41aickmPqtI5lrRAFNaCF7rXSz2KBZJ4e5q3FCtvheJ6xIicBqGDzQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;HoloLens 系统架构，HPU 与显示设备紧密耦合并且和主处理器 Intel Cherry Trail SoC 由高速 PCIe 接口互联&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;HPU 有何不同&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果仔细观察 HPU 架构，会发现它与目前借着 AI / AR 及人工智能风口飞地很高的 GPU 有点像，但并不相同。说它们“有点像”是因为 HPU 和 GPU 都有不少计算核心，这样可以实现数据的并行处理。HPU 和 GPU 要处理的都是画面中的一个个像素，而像素之间其实并没有关联性，因此可以由并行处理来提高执行效率。与之相对的是 CPU，为了照顾通用性 CPU 无法放置大量的计算核心来实现大规模并行运算，因此完全用 CPU 来处理 AI / AR 操作会导致速度很慢。另一方面，HPU 与 GPU 之间也有很大的不同。首先，HPU 上的计算核心是可配置 DSP 而非类似 Nvidia GPU 里面的 CUDA core。另外，HPU 的片上Cache（用于快速存取数据）高达 8MB，远大于 GPU 的片上 Cache 容量（Tegra X1 上Cache 仅有 2 MB）。这是为什么呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Du Li 和 Yilei Li 博士表示，「归根到底，这些都是因为应用的区别。GPU 就像一艘巨轮，设施豪华（运算精度高），耗油巨大（功耗巨大），在处理海量的数据时可以实现非常高的吞吐率，但是实时性并不好：你可以想象巨轮在行驶前需要做许多准备工作，并不是指令一下说走就走（延迟较大）。当然在需要处理的数据量足够大时，这些准备时间相对于计算时间来说可以忽略不计。HPU 就像一艘小船，轻便而省油（功耗较小），而且指令一下可以说走就走（延迟较小），虽然运算的吞吐量不能和 GPU 相比但是实时性很好。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 HoloLens 中，实时性非常重要：例如，在你的头部移动时，你显示的内容也要相应改变，如果在你头部移动和现实内容改变之间存在明显延迟则使用者会感到晕眩（这也是为什么很多人在玩 3D 游戏时会头晕的原因）。另外，由于 HoloLens 是移动设备，因此芯片的功耗需要严格控制，功耗巨大的 GPU 架构并不适合。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW97Eu3kQ28xCXnW6b2iagC06NxbjiaMpOSe90lusPmNAejnVjtwub9QKkFEZgSaJVr98GL7Djk07PLA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;HPU 芯片结构，可见 DSP 计算核心以及大容量片上 Cache（SRAM）&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;让我们来看看 HPU 和 GPU 的几点不同是如何对应应用场合的要求的。首先，HPU 选择了可重配置的 DSP。使用可重配置的 DSP 可以根据应用场合切换配置来实现性能－功耗的最优折衷，可以说 HPU 使用可配置 DSP 是为了实现在给定功耗下的最佳性能。其次，HPU 使用很大的片上 Cache。使用片上 Cache 可以实现低延迟数据存取，从而满足HoloLens 对于实时性的要求。HPU 与显示设备紧密耦和也能帮助降低延迟。与之相反，通常 GPU 的片上 Cache 都较小，而绝大部分数据都存在片外 DRAM 中并使用高速 GDDR 接口实现数据传送。这样做既增大了数据存取延时又消耗了很大的功耗，并不适合 HoloLens 这样的应用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，值得注意的是，HPU 还集成了许多专用加速器。这些专用加速器可以帮助 HPU 快速执行一些算法（单靠 DSP 往往无法满足这些算法的性能需求）。这使得 HPU 又有点像 Qualcomm 的 Snapdragon SoC，因为 Snapdragon 也是在芯片上会集成许多特定算法（如视频编解码，AES 加密）的加速器。这些加速器的功耗往往很低，但是使用这些加速器也是要付出代价的：专用加速器在不需要使用的时候会处于闲置状态无法用做其他用途，这部分用于专用加速器的芯片面积在加速器闲置的时候相当于是浪费了。因此，专用加速器就能量而言效率非常高（即完成运算需要的能量很小），但是就芯片面积而言效率很差（即增加了芯片成本）。因此集成哪些专用加速器需要经过性能－功耗－成本三方面的仔细折衷。HPU 集成的这些专用加速器相信会在一些关键的应用中起很大的加速作用，从而保证 HoloLens 能以很高的性能实现算法同时消耗很低的功耗。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;根据微软的数据，使用专用加速器配合 DSP 可以实现 200 倍以上的性能改善，效果可谓惊人。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;芯片 IP 随着 AI / AR 概念变得更重要&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;近来 AI / AR 技术发展非常快。为了实现新的算法以及满足新的应用需求，往往要速度更快功耗更低的硬件，这就需要相应的芯片也能快速迭代以满足算法和应用的需求。另一方面，许多传统只在软件领域活动的巨头（如 Google，Facebook）在这波风潮里也在向着硬件领域蠢蠢欲动，为了使自己的 AI / AR 硬件性能达标，使用通用的 CPU / GPU 很困难，必须有定制芯片。以往的先三年技术积累再开始量产芯片的做法根本无法跟上现在的高速节奏，必须有能从头开始在一年内就交付的快速芯片设计方法。为了满足这两个需求，使用芯片 IP 几乎是必须的。当使用购买的芯片 IP 时，设计者只需把精力集中在整体架构设计上，所有没有时间或者资源做具体设计的芯片模块都可以向第三方购买。相比从头设计所有模块，基于 IP 的芯片设计方法大大加快了设计速度，而整个芯片中第三方 IP 所占的比例也会越来越多。在之前的芯片巨头靠出售芯片盈利，而芯片中每一个第三方 IP 都要付出权利金，因此高通这类公司不到万不得已不会使用第三方 IP，而是会倾向于自己做模块。举例来说，高通芯片面积中使用第三方 IP（不包括ARM的架构授权）的比例通常小于 5%。然而，这些从软件领域过来做硬件的巨头制造芯片并不指望靠芯片盈利，而是要用在自家硬件里。对于它们来说，硬件是否能盈利甚至都不重要，它们需要的是营造自己的生态圈抢占市场。因此，对它们来说芯片最关键的是性能要强，而且上市速度要快，所以它们完全不介意买许多第三方 IP。前面讨论的微软 HPU 就是一个极好的例子。微软的芯片设计团队相对于 Intel 和高通等半导体业界巨头来说非常小，但是借助于从 Cadence 购买的 Tensillica DSP IP，微软仍然能够在短时间内快速完成高性能大型芯片的设计，而且第三方 IP 占的芯片面积高达 60% 以上。可以说，随着 AI / AR 概念越来越普及，相应的芯片 IP 也会越来越热门。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除了 Tensillica 之外，也有其他公司在提供 AI / AR 方面的芯片 IP。老牌 DSP 和通讯 IP 供应商最近发布了针对 AI 和 CV 的 XM6 DSP 平台。该 DSP 平台为深度学习优化，从而可以较高效地完成 AI / AR 运算。在各大高校和科研机构，AI IP 的开发也是一个热点，例如 MIT 由 Yu-Hsin Chen 开发的 Eyeriss 深度学习加速器 IP 可以以很低的功耗完成高速卷积运算，自从在 2015 年的 ISSCC（国际固态半导体电路会议）上发表后收到了巨大的关注。此外，UCLA 的 Yilei Li，Li Du 和 Yuan Du 所在的团队也在积极开发一种新架构的 AI 加速器，这种加速器采用类似乐高积木的形式，每一块芯片完成一层网络的部分运算，通过把不同的芯片用封装内互联连接起来，可以实现任意大小的网络，同时可以减小因访问内存造成的性能损失。我们预期在不久的将来，AI/AR IP 领域会越来越红火。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;结语&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;作为 AI / AR 处理器芯片的先锋，HPU 的架构与 GPU 相似（多核并行运算）但又有很大不同（使用定点 DSP 和大容量片上 Cache），另一方面它又从用于手机的多媒体 SoC（如 Snapdragon）借鉴了集成专用加速器的方法，可谓是博采众长又不拘泥于一家之说。另外，为了追上算法和应用的发展，AI / AR 芯片可能会大量使用第三方芯片 IP。我们预期在未来的 AI / AR 处理器芯片架构中看到如下的设计范式转移：GPU 追求高吞吐量-&amp;gt; AI / AR 芯片追求低延时；CPU／GPU 追求通用性-&amp;gt; AI / AR 处理器为特定应用集成大量专用加速器；CPU / GPU 模块多为自己设计-&amp;gt; AI / AR 处理器大量使用第三方 IP。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心发布，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 18 Dec 2016 10:36:44 +0800</pubDate>
    </item>
    <item>
      <title>前沿 | 源于自然高于自然：MIT正在打造生物启发式机器人</title>
      <link>http://www.iwgc.cn/link/3966678</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自MIT&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机械工程师 Sangbae Kim 打造了可用于灾难响应的类似动物的机器。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;也许不久的将来，灾难地区的应急响应就可能会包含四条腿的、狗一样的机器人，它们可以穿过火灾区域或地雷区域，然后以后腿支撑立起来转动门把手或打穿墙壁。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这样的机器人救护员可能已经准备好在未来 5 到 10 年内实现部署了，MIT 机械工程副教授 Sangbae Kim 说。他与 Biomimetic Robotics Laboratory（仿生机器人实验室）的同事们正在向着这个目标而努力——借鉴生物力学的原理、人类决策和机械设计，打造 Kim 所说的能够执行开门、打穿墙壁或关闭阀门等「真实的物理工作」的机器人。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9kibMYlPbZoY8fPoWnM3PWaMVBPgPMD5uRLjwgZKJicG3oa463Zfic2FN3LwWlJc9zXtbR6DrNX9qfA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt; Sangbae Kim，图片来源：Ian MacLellan&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「假设在一栋建筑里面出现了毒气泄漏，你需要去关闭里面的一个阀门，但是让人进去关闭会太过危险。」Kim 说，「目前，还没有什么单个机器人能够完成这个任务。我希望能够打造有希望比人类做到更多并且能在我们的生活中提供帮助的应急响应机器人。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了做到这一点，今年刚获得终身职位的 Kim 正在试图将其实验室的两个主要项目融合到一起：MIT Cheetah（一种重 70 磅的四腿机器人，它可以自动奔跑和越过障碍）和 HERMES（一种远程操控的两腿机器人，需要一个人类操作员进行远程控制，类似于机器人「阿凡达」）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我想象会有一种能够做一些体力的、动态的工作的机器人，」Kim 说，「对于研究中你感到兴奋的部分，每个人都在尝试寻找重叠区域。很多人喜欢看体育节目，因为有假说认为，当你看到别人那么劲爆地运动时，你大脑里面的『镜像神经元（mirror neurons）』会激活，同时你也会感受到那种兴奋感。对于我来说，当我的机器人能够动态地执行任务和保持平衡时，我也会感到真正地兴奋。这样的感觉激励着我的研究。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;一个军队教官变成的机器人学家&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Kim 出生于韩国首尔，他说他母亲记得他从小就是一个爱思考的人。「只要是有螺丝的东西，都会被我拆开，」Kim 说，「而且她说刚开始的时候，几乎所有东西都被我弄坏了。后来，情况就开始好转了。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;后来他进入了首尔的延世大学学习机械工程。在大学第二年，依照韩国的强制兵役制度，他和他的其他男性同学加入了韩国军队，他在那里担任了两年半的演习军官。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们教新兵了解成为一名军人的所有细节，比如如何穿衬衫和裤子、扣腰带、以及甚至在走路的时候该如何握拳，」Kim 回忆道，「早上 5:30 就要起床，直到晚上 10:30 所有人都快累得睡着了才结束，中间没有任何休息。教官是出了名的刻薄，我觉得这是有原因的——他们必须要跟得上安排得很紧的日程。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;服完兵役之后，Kim 回到延世大学继续学习，并开始被机器人学所吸引，尽管当时该校还没有这个学科的正式项目。他最后参加了一个学生比赛制造能执行特定任务的机器人的班级项目，这些任务包括：夺旗、比赛、机器人对抗，这有点类似于 MIT 受欢迎的 Course 2.007 (Design and Manufacturing)——现在 Kim 也是这门课的教员之一。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Kim 说：「这个班级真的给了我的事业很大的激励，让我在机器人学领域扎下了根。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;iframe class="video_iframe" data-vidtype="1" style="   z-index:1; " height="375" width="500" frameborder="0" data-src="https://v.qq.com/iframe/preview.html?width=500&amp;amp;height=375&amp;amp;auto=0&amp;amp;vid=e035686ormu" allowfullscreen=""&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;仿生机器人的梦想&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在他大学的最后一年，Kim 开发了一种相对廉价的 3D 扫描器，然后他和另外三位同学一起创立了一家商业化这个设备的公司 Solutionix，其产品是在 Kim 的设计上的扩展。但是当该公司开始进入融资的早期阶段时，Kim 又有了新想法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Kim 说：「当我把它做出来以后，我就失去了兴奋感，因为我已经完全搞懂它了。我喜欢把事情搞明白。在公司起步一年后我意识到了这一点：我应该从事开发早期阶段的研究，而不是改进成熟的产品。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这款产品首批发货后不久，他就离开了韩国来到了斯坦福大学，他就读了一个机械工程研究生项目。在那里，他首次尝到了自由设计的滋味。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「那真是一次改变人生的经历，」Kim 说，「和环境非常保守的韩国比起来，这里有更自由、更有创造性的环境。这是一个相当大的文化冲击。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Kim 加入了 Mark Cutkosky 的实验室，这位工程学教授一直在致力于寻找设计生物启发的机器人的方法。特别值得一提的是，该团队当时正在试图开发一款模仿壁虎攀爬的机器人，其使用了一种特殊的毛来帮助机器人停留在竖直的墙面上。Kim 对这种毛机制（hairy mechanism）进行了调整，发现它真的有效。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「那是凌晨 2 点半，我正在实验室里，我睡不着，我已经尝试了很多东西，我的心在怦怦直跳。」Kim 回忆说，「在一些带有大窗户的门上，（这个机器人）爬得非常顺滑，它使用了世界上第一种定向粘合剂，那是我发明的。我很高兴地将其展示给其他人看，那天晚上我给他们全都发了一段视频。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他和他的同事成立了一家创业公司来进一步开发壁虎机器人。但再一次，Kim 失去了在实验室里的那种快感。不久之后他就离开了这家公司，进入哈佛大学开展博士后研究。在哈佛大学，他帮助设计了 Meshworm——一种柔性的自动机器人，能够像蚯蚓一样扭曲地爬过地面。然后，Kim 将自己的目光放到了更大型的设计上。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我开始不再研究小型机器人，因为它们很难做到一些真实的体力上的工作。」Kim 说，「所以我决定开发一款更大的四足机器人来执行人类水平的任务——这是一个长期的梦想。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;寻找设计原理&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2009 年，Kim 接受了 MIT 机械工程系的助理教授职位，然后他成立了自己的仿生机器人实验室（Biomimetic Robotics Lab）并设定了一个特别的研究目标：设计和制造一个四足猎豹机器人。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们选择猎豹，因为它是最快的陆地动物，所以我们了解它的特征是最好的，但也有很多动物与猎豹有相似之处。」Kim 说，「它们有一些微妙的差别，但你可能不能从这些特征中了解到设计原理。」事实上，Kim 快速研究了其中一些案例，发现在机器人上重现特定的动物行为可能不是最好的选择。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们的案例中一个很好的例子是马的奔跑。」Kim 说，「在一匹骏马上，这是很美的，你还能听到哒哒的马蹄。我们对此很着迷，想要重现它。但事实证明马的奔跑方式对机器人来说用处不大。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;动物往往都会偏爱各自特定的步态，因为这涉及到肌肉、关节和骨头的复杂相互作用。然而，Kim 发现，由电机驱动的猎豹机器人表现出了与其灵感来源非常不同的动力学（kinetics）。比如说，在高功率情况下，该机器人能够以 14 英里每小时的速度稳定前进——比自然界的任何动物都快得多。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们必须理解什么是我们所需的主导原理，并且要问：那是生物系统的一个局限性吗，或者我们能否在工程领域实现它？」Kim 说，「找到能够囊括动物和机器之间的差异的有用原理是一个非常复杂的过程。有时候执迷于动物的特征和特性会妨碍你在机器人领域取得进步。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;一个「秘方」&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除了在实验室打造机器人，Kim 也在 MIT 任教，包括他已经任教了 5 年的 2.007。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「这仍然是我最喜欢的班级，这里的学生真正已经脱离了『家庭作业-考试』的模式，他们有机会自己亲自上手创造自己的项目。」Kim 说「今天的学生在使用 3D 打印和乐高的创客运动中成长起来，他们在等待 2.007 这样的东西。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Kim 还教授着一门他在 2013 年创立的课程——生物启发机器人学（Bioinspired Robotics），参加这个课程的 40 位学生 4 人一组根据生物力学和动物运动方式设计和制造机器人。过去的一年，学生们在 Lobby 7 上展示了他们的设计，包括一台投掷机、一个轨迹优化的踢球机和一个跳跃在跑步机上的袋鼠机器。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「在许多人类的运动中存在一些秘方，因为肌肉有非常特别的性质，如果你没有很好地了解它们，你就会表现很糟，让自己受伤。」Kim 说，「这全部都基于肌肉运动，而我在努力弄懂世界中的这些事物，并将它们用在机器人世界中。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文链接：http://news.mit.edu/2016/faculty-profile-sangbae-kim-1216&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 18 Dec 2016 10:36:44 +0800</pubDate>
    </item>
    <item>
      <title>一周论文 | 提高seq2seq方法所生成对话的流畅度和多样性</title>
      <link>http://www.iwgc.cn/link/3966679</link>
      <description>&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em;"&gt;&lt;span&gt;&lt;strong&gt;引言&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对话系统是当前的研究热点，也是风险投资的热点，从2016年初开始，成立了无数家做chatbot、语音助手等类似产品的公司，不管是对用户的，还是对企业的，将对话系统这一应用推到了一个新的高度。seq2seq是当前流行的算法框架，给定一个输入，模型自动给出一个不错的输出，听起来都是一件美好的事情。seq2seq在对话系统中的研究比较多，本期PaperWeekly分享4篇的paper notes，涉及到如何提高所生成对话的流畅度和多样性，使得对话系统能够更加接近人类的对话。4篇paper如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1、Sequence to Backward and Forward Sequences: A Content-Introducing Approach to Generative Short-Text Conversation, 2016&lt;br/&gt;2、A Simple, Fast Diverse Decoding Algorithm for Neural Generation, 2016&lt;br/&gt;3、DIVERSE BEAM SEARCH: DECODING DIVERSE SOLUTIONS FROM NEURAL SEQUENCE MODELS, 2016&lt;br/&gt;4、A Diversity-Promoting Objective Function for Neural Conversation Models, 2015&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em; margin-bottom: 10px;"&gt;&lt;span&gt;&lt;strong&gt;Sequence to Backward and Forward Sequences: A Content-Introducing Approach to Generative Short-Text Conversation&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Lili Mou, Yiping Song, Rui Yan, Ge Li, Lu Zhang, Zhi Jin&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em;"&gt;&lt;span&gt;&lt;strong&gt;单位&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Key Laboratory of High Confidence Software Technologies (Peking University), MoE, China&lt;br/&gt;Institute of Software, Peking University, China&lt;br/&gt;Institute of Network Computing and Information Systems, Peking Univerity, China&lt;br/&gt;Institute of Computer Science and Technology, Peking University, China&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em;"&gt;&lt;span&gt;&lt;strong&gt;关键词&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;content-introducing approach&lt;br/&gt;neural network-based&lt;br/&gt;generative dialogue systems&lt;br/&gt;seq2BF&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em;"&gt;&lt;span&gt;&lt;strong&gt;文章来源&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;arXiv, 2016&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em;"&gt;&lt;span&gt;&lt;strong&gt;问题&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;使用引入内容方法，用于处理基于神经网络的生成式对话系统&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em;"&gt;&lt;span&gt;&lt;strong&gt;模型&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglDIqGiccAGHDDzliawRIHnnAvA8jnQzrQwczgSoE8ATkkbtLzujgaK1Yah29QLxaicELx3G5n1ibhLXA/640?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该模型由两部分组成：&lt;br/&gt;1、use PMI to predict a keyword for the reply&lt;br/&gt;使用逐点互信息(PMI)进行预测，选取PMI值最大的单词作为回答中的关键词，该关键词可以出现在回答语句中的任意位置。&lt;br/&gt;&lt;/span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglDIqGiccAGHDDzliawRIHnnA65mrbuO9DfLfp72jVsTzFSboRcCUPcib7cic0ECJGaibGqWfu6iaPRDPpw/640?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2、generate a reply conditioned on the keyword as well as the query&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使用sequence to backward and forward sequences(seq2BF)模型来生成包含关键词的回答。以该关键词为基点，将回答语句划分为两个序列：&lt;br/&gt;(1) 反向序列：关键词左侧的所有单词以逆序排列&lt;br/&gt;(2) 正向序列：关键词右侧的所有单词以顺序排列&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;seq2BF 模型具体工作如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;(1) 使用 seq2seq 神经网络将问题编码，仅对关键词左侧的单词进行解码，逆序输出每个单词&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;(2) 使用另一个seq2seq模型将问题再次编码，在给定上步中解码后的逆序单词序列下，对回答中的剩余单词进行顺序解码，输出最终单词序列&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglDIqGiccAGHDDzliawRIHnnAkk8wGystS3cEGjUZ6lkL2icoq4HRCCf41gndnvX4qjBUALxawKzrA0w/640?wx_fmt=png"/&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em;"&gt;&lt;span&gt;&lt;strong&gt;资源&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Dataset：&lt;/span&gt;&lt;a target="_blank" rel="external" style="color: rgb(67, 149, 245); max-width: 100%; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important; text-decoration: underline;"&gt;&lt;span&gt;http://tieba.baidu.com&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em; margin-bottom: 10px;"&gt;&lt;span&gt;&lt;strong&gt;相关工作&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;1、 Dialogue Systems&lt;br/&gt;(1) (Isbell et al., 2000; Wang et al., 2013) retrieval methods&lt;br/&gt;(2) (Ritter et al., 2011) phrase-based machine translation&lt;br/&gt;(3) (Sordoni et al., 2015; Shang et al., 2015) recurrent neural networks&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2、 Neural Networks for Sentence Generation&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;(1) (Sordoni et al., 2015) bag-of-words features&lt;br/&gt;(2) (Shang et al., 2015) seq2seq-like neural networks&lt;br/&gt;(3) (Yao et al., 2015; Serban et al., 2016a) design hierarchical neural networks&lt;br/&gt;(4) (Li et al., 2016a) mutual information training objective&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;简评&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本文的创新点在于，不同与目前普遍存在的从句首到句尾顺序生成目标单词的方法，引入逐点互信息方法来预测回答语句中的关键词，使用seq2BF机制确保该关键词可以出现在目标回答语句的任意位置之中并确保输出的流利度，相比于seq2seq的生成方法显著地提升了对话系统的质量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em; margin-bottom: 10px;"&gt;&lt;span&gt;&lt;strong&gt;A Simple, Fast Diverse Decoding Algorithm for Neural Generation&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em;"&gt;&lt;span&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Jiwei Li, Will Monroe and Dan Jurafsky&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em;"&gt;&lt;span&gt;&lt;strong&gt;单位&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Stanford&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em;"&gt;&lt;span&gt;&lt;strong&gt;关键词&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;seq2seq, diversity, RL&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em;"&gt;&lt;span&gt;&lt;strong&gt;文章来源&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;arXiv, 2016&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em;"&gt;&lt;span&gt;&lt;strong&gt;问题&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;seq2seq模型decoder时改进beam search，引入惩罚因子影响排序结果，并加入强化学习模型来自动学习diversity rate，使得解码出的结果更具多样性&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em;"&gt;&lt;span&gt;&lt;strong&gt;模型&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglDIqGiccAGHDDzliawRIHnnAVtIkYTCbksM2PXu0u6gRgOeibsJePM1zaSuc6OHlMQKGv0kR6s1zBbw/640?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对比标准beam search，本模型引入惩罚因子，公式如下&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglDIqGiccAGHDDzliawRIHnnASpdHCExQevcBq87OTvbWP8LgAibZaX8L3uYbQ0AB7s9UePCk2A9Mwtw/640?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中$\gamma$称为diversity rate，k’范围为[1,k]，K为beam size&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;强化学习模型中，策略为&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglDIqGiccAGHDDzliawRIHnnAGQJiap4ETOibsxjqCe3cJ1myEodt59X9A5VEHpsxwXLV7GlQv3VfelZw/640?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;reward为评价指标，例如机器翻译中的BLEU值等&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em;"&gt;&lt;span&gt;&lt;strong&gt;资源&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;1、回复生成实验数据集：OpenSubtitles&amp;nbsp;&lt;/span&gt;&lt;a target="_blank" rel="external" style="color: rgb(67, 149, 245); max-width: 100%; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important; text-decoration: underline;"&gt;&lt;span&gt;https://github.com/jiweil/mutual-information-for-neural-machine-translation&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;span&gt;（代码模型可从作者另外一篇文章的源码稍加改动）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2、机器翻译数据集：WMT’14&amp;nbsp;&lt;/span&gt;&lt;a target="_blank" rel="external" style="color: rgb(67, 149, 245); max-width: 100%; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important; text-decoration: underline;"&gt;&lt;span&gt;http://www.statmt.org/wmt13/translation-task.html&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em;"&gt;&lt;span&gt;&lt;strong&gt;相关工作&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglDIqGiccAGHDDzliawRIHnnA0UzpFpbxTbA8SSIicqkRA4pvrUQbCRjuCNiadjsILicDKT1iaWZcBMg8Nw/640?wx_fmt=png"/&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em;"&gt;&lt;span&gt;&lt;strong&gt;简评&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;本模型的创新点在于引入惩罚因子，使得decoder时对standard beam search算法进行重排序，并引入强化学习模型，自动学习diversity rate。作者分别在三个实验上进行验证，机器翻译、摘要抽取与对话回复生成，实验表明在不同的实验上有不同的表现，但是总体而言本方法能够在一定程度上解码出更具有多样性的句子。（思路简明清晰，对于传统的beam search稍加改动，原文中作者提到在Matlab代码中只改动一行即可）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em; margin-bottom: 10px;"&gt;&lt;span&gt;&lt;strong&gt;DIVERSE BEAM SEARCH: DECODING DIVERSE SOLUTIONS FROM NEURAL SEQUENCE MODELS&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em;"&gt;&lt;span&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Ashwin K Vijayakumar, Michael Cogswell, Ramprasath R. Selvaraju, Qing Sun1 Stefan Lee, David Crandall &amp;amp; Dhruv Batra&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em;"&gt;&lt;span&gt;&lt;strong&gt;单位&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Virginia Tech, Blacksburg, VA, USA&lt;br/&gt;Indiana University, Bloomington, IN, USA&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em;"&gt;&lt;span&gt;&lt;strong&gt;关键词&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Beam Search; Diversity; Image Caption; Machine Translation; Visual Question Answer; Chatbot&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em;"&gt;&lt;span&gt;&lt;strong&gt;文章来源&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;arXiv, 2016.10&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em;"&gt;&lt;span&gt;&lt;strong&gt;问题&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;如何改进beam search解码算法，使其在seq2seq模型中可以生成更加丰富的结果？&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em;"&gt;&lt;span&gt;&lt;strong&gt;模型&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;经典的beam search算法以最大后验概率作为优化目标函数，每一个time step只保留B个最优的状态，是一种典型的贪心算法，这个经典算法常常被用于解码可选状态数量多的情形，比如生成对话、生成图片描述、机器翻译等，每一步都有词表大小的可选状态集。seq2seq模型的流行，让这种解码算法的研究变得热门。在生成对话任务时，用经典的beam search会生成类似“我不知道”等这种没有营养的对话，虽然没有语法上的错误，而且可能在一定的评价体系内会得到不错的分数，但实际应用效果太差，因此diversity的研究变得热门。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本文针对diversity的问题，提出了一种改进版的beam search算法，旨在生成更加多样性的话。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglDIqGiccAGHDDzliawRIHnnAR7AS1iaHMC9yu58tPAQcQ8iayGOKiboIVgVt1gPt7GeIdF68oKJ309MqA/640?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;新算法的主要思路是将经典算法中的Beam进行分组，通过引入一个惩罚机制，使得每一组的相似度尽量低，这一项保证了生成的话相互之间差异更大一些，即满足了多样性的需求，在每一组Beam中，用经典的算法进行优化搜索。具体的算法流程如下图：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglDIqGiccAGHDDzliawRIHnnAYOaicnxWKPjp4657WOu0mOTEwmyFsZh8BicbH69JNF2B7tTiarZRHPxCQ/640?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;实验中，用了Image Caption、Machine Translation和VQA三个任务进行了对比，验证了本文算法的有效性，并且对算法中的几个参数进行了敏感度分析，分析了分组数对多样性的影响。&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em;"&gt;&lt;span&gt;&lt;strong&gt;资源&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;1、本文算法torch实现&amp;nbsp;&lt;/span&gt;&lt;a target="_blank" rel="external" style="color: rgb(67, 149, 245); max-width: 100%; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important; text-decoration: underline;"&gt;&lt;span&gt;https://github.com/ashwinkalyan/dbs&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;span&gt;2、本文在线demo dbs.cloudcv.org&lt;br/&gt;3、neuraltalk2实现&amp;nbsp;&lt;/span&gt;&lt;a target="_blank" rel="external" style="color: rgb(67, 149, 245); max-width: 100%; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important; text-decoration: underline;"&gt;&lt;span&gt;https://github.com/karpathy/neuraltalk2&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;span&gt;4、机器翻译开源实现dl4mt&amp;nbsp;&lt;/span&gt;&lt;a target="_blank" rel="external" style="color: rgb(67, 149, 245); max-width: 100%; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important; text-decoration: underline;"&gt;&lt;span&gt;https://github.com/nyu-dl/dl4mt-tutorial&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em;"&gt;&lt;span&gt;&lt;strong&gt;相关工作&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;相关的工作主要分类两类：&lt;br/&gt;1、Diverse M-Best Lists&lt;br/&gt;2、Diverse Decoding for RNNs&lt;br/&gt;之前Jiwei Li将解码算法的目标函数换成了互信息进行优化解码，对diversity进行了研究。&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em;"&gt;&lt;span&gt;&lt;strong&gt;简评&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;本文研究的问题是一类基础问题，beam search算法作为一种经典的近似解码算法，应用的场景非常多。但在实际应用中，尤其是具体到生成对话、生成答案等任务上，存在一些适应性的问题，比如diversity。只是生成简单而又安全的话对于实际应用没有太多的意义，所以本文的研究非常有意义。本文的实验从三个不同的任务上对改进后的beam search都做了对比验证，非常扎实的结果验证了算法的有效性，并且对几个关键参数进行了敏感度分析，有理有据。同时在github上开源了代码，并且给出了一个在线demo。在评价方面，不仅仅设计了几个自动评价指标，而且用了人工评价的方法对本文算法进行了验证，是一篇非常好的paper，值得学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em; margin-bottom: 10px;"&gt;&lt;span&gt;&lt;strong&gt;A Diversity-Promoting Objective Function for Neural Conversation Models&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em;"&gt;&lt;span&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Jiwei Li, Michel Galley, Chris Brockett, Jianfeng Gao, Bill Dolan&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em;"&gt;&lt;span&gt;&lt;strong&gt;单位&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Stanford University, Stanford, CA, USA&lt;br/&gt;Microsoft Research, Redmond, WA, USA&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em;"&gt;&lt;span&gt;&lt;strong&gt;关键词&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Sequence-to-sequence neural network models, conversational responses, Maximum Mutual Information(MMI)&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em;"&gt;&lt;span&gt;&lt;strong&gt;文章来源&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;arXiv, 2015&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em;"&gt;&lt;span&gt;&lt;strong&gt;问题&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;使用MMI训练sequence-to-sequence model for conversational responses generation&lt;br/&gt;传统的ML(最大似然估计)在训练sequence-to-sequence model的时候，易产生与输入无关的’safe’ responses(最大似然估计的弊病—-always try to cover all mode of input data)&lt;br/&gt;作者通过使用MMI, 最大化输入与输出的互信息，能够有效避免与输入无关的responses，得到更为diverse的responses.&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em;"&gt;&lt;span&gt;&lt;strong&gt;模型&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;MMI最早在speech recognition中提出并应用(discriminative training criteria). 语音识别中，通常先用ML训练声学模型，然后再接MMI和语言模型，对声学模型进一步调优。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在本文中，作者通过提出MMI用于seq-to-seq model的优化。作者提出了MMI-antiLM和MMI-bidi 两个不同的MMI的formulations. MMI在seq-to-seq的应用中存在decoding的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;MMI-antiLM中，作者通过使用带有权重的LM以生成更为diverse的responses by penalizing first word。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;MMI-bidi中，搜索空间的数目过大，导致expolring所有的可能性在实际中无法实现。作者首先产生N-best list, 然后根据相应的准则函数 re-rank得到的N-best list。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在MMI不同的formulation中，作者通过启发式的设计，使得decoding更为容易且产生的response更为diverse，在相关的数据集上取得了较好的BLEU且产生的response更为diverse。&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em; margin-bottom: 5px;"&gt;&lt;span&gt;&lt;strong&gt;简评&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;最大后验概率通常作为优化的目标函数，但很多应用场景中得到的结果并不理想。本文采用了一个新的而且也是其他领域中比较常见的目标函数来替换最大后验概率，在生成对话时得到了更加丰富的结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em; margin-bottom: 5px;"&gt;&lt;span&gt;&lt;strong&gt;总结&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;对话系统是一个相对高级的、综合性很强的任务，所依赖的基础任务比较多，比如分词、命名实体识别、句法分析、语义角色标注等等。对于规范的中文表达而言，句法分析仍是一个没有解决好的问题，更何况是不那么规范的人话，句法分析的准确性又要下一个level了，随之语义角色标注也得不到好的效果。经典的、基础的任务还有很长的路要走，对话系统这种更难、更复杂的任务相信不是一年、两年就可以突破的事情，虽然现在大热，做的人很多，但就目前的研究水平来看，应该还有很长的路要走。seq2seq是个逃避这些问题的好方法和好思路，但相对来说更加不成熟，而且存在着很多的问题，想通过大量的数据来覆盖所有的问题，是一种不太科学的思路。我想，seq2seq是个好方法，但传统的NLP方法也是必不可少的，而且两者应该是相互补充的。越多的人关注对话系统，就会越快地推动这个领域的发展，希望早日看到靠谱的、成熟的解决方案。感谢@Penny、@tonya、@zhangjun和@皓天 四位童鞋完成的paper notes。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;关于PaperWeekly&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;PaperWeekly是一个分享知识和交流学问的学术组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;微信公众号：PaperWeekly&lt;/span&gt;&lt;/strong&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkSMlEJFo90NY8rCXr3mJMBibduVHxMKSHzQtVkHz8kNwpjCKBiccGuqLE0WpPuAbdtEs6cTF5iabpAQ/640?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微博账号：PaperWeekly（&lt;/span&gt;&lt;a target="_blank" rel="external" style="color: rgb(67, 149, 245); max-width: 100%; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important; text-decoration: underline;"&gt;&lt;span&gt;http://weibo.com/u/2678093863&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&amp;nbsp;）&lt;br/&gt;微信交流群：微信+ zhangjun168305（请备注：加群交流或参与写paper note）&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 18 Dec 2016 10:36:44 +0800</pubDate>
    </item>
    <item>
      <title>重磅 | 微软发布数据集MS MARCO，打造阅读理解领域的「ImageNet」</title>
      <link>http://www.iwgc.cn/link/3955978</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自微软&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote style="color: rgb(62, 62, 62); font-size: 16px; white-space: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/blockquote&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;今天早些时候，微软在其官方博客上宣布发布了一个包含 10 万个问题和答案的数据集，研究者可以使用这个数据集来创造能够像人类一样阅读和回答问题的系统。此外，微软计划效仿 ImageNet，与其他人合作、最终创办正式的竞赛等。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个数据集名叫 MS MARCO，表示 Microsoft MAchine Reading COmprehension（微软机器阅读理解）。其背后的团队声称这是目前这一类别中最有用的数据集，因为这个数据集是基于匿名的真实数据构建的。通过将该数据集免费开放给更多的研究者，该团队希望能够促进机器阅读领域的研究突破，就像之前研究者已经在图像识别和语音识别领域所取得颠覆性突破一样。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;MS MARCO 数据集地址：http://www.msmarco.org&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW97Eu3kQ28xCXnW6b2iagC06ibp0qu0Ig59mjrEboib6TvfYhF2yR9fuZ4JOWKwAGIIfdzzprAb52Dfw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他们也希望这次开放能够促进「人工通用智能（AGI/artificial general intelligence）」的长期目标的实现，即创造出能够像人类思考的机器。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW97Eu3kQ28xCXnW6b2iagC06u8rCNjRukHX5liaEqwToQ2xz3HyAicjk3UyRmXunjExkiafv7gh9ticF0g/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Rangan Majumder，微软 Bing 搜索引擎部门合作伙伴组的程序经理&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微软 Bing 搜索引擎部门合作伙伴组的程序经理（partner group program manager）Rangan Majumder 是这个项目的领导者，他说：「为了实现人工通用智能的目标，我们首先需要机器能够像人类一样阅读和理解文档。这个数据集是向这个方向迈出的一步。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Majumder 说，目前回答复杂问题的系统仍然还处在婴儿阶段。Bing 这样的搜索引擎和小娜那样的虚拟助手还只能回答一些基本的问题，比如「光明节那天开始？」或「2000 乘以 43 等于多少？」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Majumder 说，但在许多案例中，搜索引擎和虚拟助手只会将用户引导至一些搜索结果。&lt;/span&gt;&lt;span&gt;当然用户仍然会获得他们想要的信息，但那也需要用户在搜索结果列表中寻找所需的答案链接。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了实现更好的自动问答系统，研究者需要更强大的训练数据。这样的训练数据需要能够教会人工智能系统识别问题和组织答案，并最终能够根据它们之前从未见过的特定问题构建出自己的答案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Majumder 及其团队（包括微软的一些研究者和从事产品开发的人）表示，MS MARCO 数据集是非常有用的，因为该数据集的问题基于来自 Bing 搜索引擎和小娜虚拟助手的真实的、匿名的查询。该团队根据研究者所认为的更有趣的查询而对这些问题进行了选择。除此之外，这些问题的答案都是根据真实的网页而人工书写的，准确性已经过了验证。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过提供真实的问题和答案，这些研究者表示他们可以训练出能更好地应对人们常问问题的细微差别和复杂性的系统，其中包括那些没有明确答案或有多个可能答案的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;比如说，这个数据集中包含了这样一个问题：「What foods did ancient Greeks eat?（古希腊人吃什么食物？）」要正确回答这个问题，他们需要检索多个文档中的信息，最后给出谷物、蛋糕、牛奶、橄榄、鱼、大蒜和卷心菜等食物作为答案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微软首席人工智能科学家、深度学习技术中心（Deep Learning Technology Center）合作伙伴研究经理（partner research manager）邓力说之前的数据集在设计上都有一些特定的限制和局限性。这能让研究者可以更轻松地创造出可以被机器学习研究者形式化为所谓的「分类问题（classification problem）」的解决方案，但却不能帮助机器理解问题的实际文本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW97Eu3kQ28xCXnW6b2iagC06FI7Kefq1AjkyPZteCDyp4Us9hFxxOJH4dIFl9U210svLUD9mNbyTGA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;微软深度学习技术中心合作伙伴研究经理邓力&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;邓力说 MS MARCO 的设计目的是为了帮助研究者实验更先进的深度学习模型，从而推动人工智能研究的进一步发展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他说：「我们的数据集不只是为了使用真实世界数据，也是为了移除这些限制，以使新一代的深度学习模型能够在它们回答问题之前先理解数据。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Majumder 说系统回答复杂问题的能力能够帮助人们更有效地获取信息，从而增强人类的能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;让我们举个例子，假设一个加拿大学生需要了解她是否满足一个贷款项目的申请资格。搜索引擎可能会将该用户引导至一系列的相关网站，然后她需要自己阅读那些条条款款然后才能得出结论。但如果她有更好的工具，她的虚拟助手就能帮助她扫描这些信息，然后给出一个更细致的、甚至个性化的答案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Majumder 说：「鉴于世界上的许多知识都是以书写的形式存在的，如果我们能让机器像人类一样阅读和理解文档，我们就为所有各种各样可能的情形开启了大门。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;长期目标：「人工通用智能（artificial general intelligence）」&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;至少就目前而言，研究者还仍然远远不能创造出能够理解人类所说的、看见的或写出的内容的系统——很多人将其称为「人工通用智能」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在过去几年，微软与其它地方的机器学习和人工智能研究者在创造识别对话中单词的系统上已经取得了极大的进步，在准确识别图像组成上也是如此。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Majumder 说，「微软在语音识别和图像识别上已经起着领头作用，现在我们也打算带领阅读理解的研究。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是，他提到这不是任何单独一家公司就能解决的难题。Majumder 说他们团队开放这个数据集的一个原因就是想要与领域内的其他人合作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;MS MARCO 类似于机器学习和人工智能的其它领域的训练集，包括 ImageNet 数据集——它被认为是测试图像识别进展的第一数据集。微软的一个研究团队曾使用 ImageNet 来测试自己的首个深度残差网络，在图像识别的准确率上有了巨大的提升。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;MS MARCO 团队也打算效仿 ImageNet，创建一个取得最好研究成果的团队排行榜。最终，他们可能会像 ImageNet 年度挑战赛一样创造一个更正式的比赛。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;任何想要下载并将其用于非商业应用的研究人员都可以免费使用 MS MARCO 数据集。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文：https://www.microsoft.com/en-us/research/publication/ms-marco-human-generated-machine-reading-comprehension-dataset/&amp;nbsp;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Sat, 17 Dec 2016 11:07:24 +0800</pubDate>
    </item>
    <item>
      <title>前沿 | 半监督学习新进展：深度渲染混合模型能像人类婴儿一样学习</title>
      <link>http://www.iwgc.cn/link/3955980</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自science daily&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李泽南、蒋思源&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;来自莱斯大学和贝勒医学院（Baylor College of Medicine）的神经科学和人工智能专家们正在从人类的大脑中获得灵感，创造了一种新的「深度学习」方法，这种方法能使计算机像人类婴儿一样自己学习视觉世界。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;blockquote style="color: rgb(62, 62, 62); font-size: 16px; white-space: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW97Eu3kQ28xCXnW6b2iagC0604DIDLics372bMkJ1gqDWYokKHzREa4JLiasrWrGHEuMxvO33SbUia8Jw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;左 Richard Baraniuk, Tan Nguyen and Ankit Patel.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;来自莱斯大学和贝勒医学院（Baylor College of Medicine）的神经科学和人工智能专家们正在从人类的大脑中获得灵感，创造了一种新的「深度学习」方法，这种方法能使计算机像人类婴儿一样自己学习视觉世界。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在研究中，该团队的「深度渲染混合模型（deep rendering mixture model）」通过联邦雇员和高中学生书写的 10000 个数字的标准数据集学会了自己如何辨别手写数字。本月初，这个团队在 NIPS 2016 大会上发表了这项研究的论文《Semi-Supervised Learning with the Deep Rendering Mixture Model》，研究者们描述了如何通过 10 个 0 到 9 之间的手写数字样本来训练他们的算法，然后让机器使用数千样本数据自我学习。在研究中，该算法在正确区分手写数字方面，几乎比所有每个数字都要用数千样本进行训练的旧方法都要好。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;莱斯大学电气和计算机工程和贝勒医学院神经科学联合任命的助理教授、本研究的领导者 Ankit Patel 说：「如果用深度学习的术语来解释，我们的系统使用了一种被称为半监督学习的方法。而在深度学习领域目前最成功的方法使用的是被称为监督学习的技术，这种方法在训练时需要提供成千上万标记好的样本，比如告诉机器：这样是 1，这样是 2。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「人类不会这样学习，」Patel 说道。「当婴儿的第一年刚学习观看事物的时候，他们对于这些事物的具体所指的感知很少。父母可能就只会给他们标注很少的事物：瓶子、椅子、妈妈等，婴儿在这一段时间上甚至不能理解口语，他们通过与世界的互动来学习，这个过程在大部分情况下都是无监督的。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Patel 表示他正和本研究的合作者 Tan Nguyen 设计一个半监督学习系统进行视觉数据训练。这个系统不需要多少「人工标注」的训练样本来进行训练。在此之前，使用监督学习的神经网络在通过 MNIST 数据库超过万种手写数字的测试前，需要使用数百到数千已标记的手写数字训练样本进行训练。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个半监督式的 Rice-Baylor 算法是一个「卷积神经网络」——这是一种从生物大脑得到启发，由多层人工神经元组成的网络。这些人工神经元（即处理单元）分层排列。第一层扫描图像并且执行像搜索边缘和颜色变化那样的简单任务，第二层检查第一层的输出并搜索更复杂的特征。在数学上，这种在模式内寻找模式的嵌套方法被称为非线性过程（nonlinear process）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Patel 这样形容卷积神经网络：「它本质上是一个非常简单的视觉皮层。输入一个图像后，每层都处理图像的一点点特征，这个过程随着层级不断深入，在最后一层，系统对图像获得了深刻和抽象的理解。」目前所有无人驾驶汽车的系统中都使用了卷积神经网络，因为它是目前最好的视觉处理方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;就像人类的大脑一样，神经网络在刚刚生成的时候就像一张白纸，随着与世界的交互渐渐充盈。在面对图像的时候，每一个卷积网络处理单元在一开始都是相同的，随着大量图像的训练，每个单元渐渐开始特化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「边缘（edge）非常重要，」Nguyen 说道。「许多低层神经元往往会成为边缘检测器，它们专注于寻找这种常见且对于视觉解释非常重要的特性。同时，每个神经元都会进行自我训练以寻找特定模式，例如 45 度边缘或 30 度红——蓝转换。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「当它们探测到特定的模式时，它们就会被激发，并将信息传递到下一层，让下一层在此基础之上识别其他模式，这个过程不断进行，」Nguyen 解释道。「非线性变换的次数实际上代表了网络的深度，更深意味着更强大。神经网络越深，它能够解决的问题就越复杂。在网络的深层，处理单元探寻的是非常抽象的概念，如眼球、垂直光栅、或者一辆校车。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Nguyen 在今年一月开始与 Patel 合作，彼时后者刚刚开始他在莱斯大学和贝勒医学院的学术生涯。在此之前，Patel 已经研究机器学习多年，他之前的工作包括将机器学习应用到从大宗商品交易到弹道导弹防御等许多领域，他刚刚在莱斯大学的 Richard Baraniuk 实验室结束了为期四年的博士后工作。在 2015 年末，Baraniuk、Patel 和 Nguyen 发表了他们的第一个理论框架，可以导出卷积神经网络的确切结构，并提供了消除其局限性的一套原则性解决方案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Baraniuk 认为，坚实的理论基础对于设计更加先进的卷积神经网络至关重要。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「视频中的图像是一个很好的例子，」Baraniuk 说道。「如果我在看一个视频，逐帧地观看，假如我想了解所有的对象和它们如何移动等等特性，这会是一个巨大的挑战。想象一下，人脑需要多长时间来标记每个对象，每一帧图像，没有人有这么强大的处理能力。同样的，为了让机器感知它在视频中看到的内容，它必须了解自己看到了哪些对象，明白三维空间的概念和其他大量真正复杂的东西。人类自己学习这些东西，并把它们视作理所当然，但这种能力在今天的人工智能神经网络中完全缺失。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Patel 认为他们在 NIPS 上发表的新一代人工神经网络，最终甚至可以反过来帮助神经科学家们更好地了解人类大脑的工作方式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「视觉皮层中的世界和卷积神经网络中的世界，看起来似乎有一点相似，但在某些层面上也大不相同，」Patel 说道。「大脑的处理方式也许和机器相似，但其中机制仍然区别很大。我们目前对于大脑的研究理论认为，大多数学习都是无监督的。我和我的神经科学家同事们正在试图回答这样几个问题：什么是由视觉皮层中的神经回路实现的半监督学习算法？它与我们的深度学习理论有什么关系？」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们的理论或许可以用来帮助解释大脑处理信息的方式，」Patel 补充道。「大脑的算法远远优于我们设计的任何神经网络。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;论文：使用深度渲染混合模型的半监督学习（Semi-Supervised Learning with the Deep Rendering Mixture Model）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW97Eu3kQ28xCXnW6b2iagC06cqiclWnKLQDTU8176usqZhCIL6pqyenjMlA57IjHK2Tl2pmHPnF2Dtg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：半监督学习算法通过在学习期间同时使用标记的和未标记的数据来降低训练数据的成本。深度卷积网络（DCN）在监督学习的任务中已经取得了巨大的成功，因此目前也被广泛地应用于半监督学习。在本研究中，我们使用了最近开发的深度渲染混合模型（DRMM/Deep Rendering Mixture Model），这是一个概率生成模型（probabilistic generative model）——其建模了潜在的扰动变化，其推理算法产生了 DCN。我们为该 DRMM 开发了一个 EM 算法，以使该 DRMM 能够同时从标记数据和未标记数据中学习。在 DRMM 理论的指导下，我们引入了一个新的非负性约束（non-negativity constraint）和一个变分推理项（variational inference term）。在 MNIST 和 SVHN 数据集上，我们的方法实现了当前最佳的表现，在 CIFAR10 上也实现了可媲美最佳表现的结果。我们还深入研究了一个在半监督环境下训练的 DRMM 可以如何使用合成渲染的图像表征潜在的扰动变化。总的来说，本研究为监督、无监督和半监督学习提供了一个统一的框架。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Sat, 17 Dec 2016 11:07:24 +0800</pubDate>
    </item>
    <item>
      <title>教程 | 如何DIY一个《西部世界》的机器人接待员？</title>
      <link>http://www.iwgc.cn/link/3955982</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自TechCrunch&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;参与：Terrence、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有人选择看到这个世界的局限性，那就是死路一条。在这里，我们选择看到世界的可能性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW97Eu3kQ28xCXnW6b2iagC06Uh6BjBsfENYB3Tn6kStAWGrAjE6e6JqTNH8Sgvjicvlu3KHbAymEQAw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;回顾《西部世界》的第一季，我不得不说，Lisa Joy 和 Jonathan Nolan 对人工智能细致入微的理解真是让人印象深刻。那些幻想、幕后故事甚至在其他接待员上训练接待员的想法都给了真正的人工智能研究一些启示。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;建立一个西部世界的接待员有点像是把宜家的家具一点点拼装起来，然而在幻想上——这个方向并没有什么用。这里给出了 DIY 自己的西部世界机器人接待员的一些准则。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此外，我们说服了牛津大学和斯坦福大学的人工智能研究院和语义机器首席科学家 Daniel Klein 博士，请他谈了谈可以如何应对这些挑战。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;第一步：买一个波士顿动力的机器人&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;波士顿动力公司最先进的机器人 Atlas 需要这么多的改进，我甚至不会考虑这是骗人的。&lt;/span&gt;&lt;span&gt;Atlas 可以在各种不平的表面上走动，打开门，甚至在被击倒后站起来——但你肯定不会误认为这是人类。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;iframe class="video_iframe" data-vidtype="1" style="   z-index:1; " height="375" width="500" frameborder="0" data-src="https://v.qq.com/iframe/preview.html?width=500&amp;amp;height=375&amp;amp;auto=0&amp;amp;vid=l0185h5pbbu" allowfullscreen=""&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器人有 330 磅重，行走很笨拙，所以除非你只想建立一个有故障的皮克特警长并在某天打电话给他，否则你需要做一些大规模的改动。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于初学者，你必须找到一种实现人类精细运动技能的方法。我们的面部有 43 块肌肉，以惊人的方式来帮助人们交流和传达情绪。不幸的是，增加更多人的特征也会带来问题——会让它看起来更加恐怖（参考「恐怖谷理论」）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;要打造一个真正的人类模拟，你必须要有正确的皮肤温度，你必须搞定那些小的细节，哪怕是汗水。握着未经打磨的接待员的粗糙冷冰冰的手，会毁了整个经历的瞬间。当然，我们得承认整个计划具有很大挑战性，但是我们至少知道目标在哪里。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;第二步：归纳智能&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能需要大量的信息来完成一个单一的、明确的任务。我们用数据训练我们的机器数周，然后它们可以玩一个游戏或分类垃圾邮件。相比之下，即使只有有限的信息，人类也可以实现更多能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;想象一下，你只是因为触摸炉子上的煎锅而烧伤了你的手。如果你的结论是煎锅会烧伤人，那你可能就是一个不成功的 DeepMind 实验。这里最明显的答案是炉子上的一个锅烧伤了你，因为它被加热过——而过多的热可能会烧伤我们。计算机可能会选择不再触摸任何煎锅——这可太愚蠢了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Klein 教授解释说，解决这个问题有两种主要的方法。首先是从下到上，而另一个是从上到下。现在人工智能中的大部分工作是自下而上的。我们努力做更复杂的事情——比如从单词到句子到完全对话。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一种方法是输入规则，让系统找出如何自己实现所需结果的细节。我们从底部比从顶部做了更多的进步。找出可以如何从上到下有效地工作，然后你会发现你在某家技术公司有了至少七位数的薪资。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;第三步：看着人类寻找灵感&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW97Eu3kQ28xCXnW6b2iagC06iaYEibXYSuVmeqkWvibe6TxQXRarMWrBrW1lKlTlO3zZNVPBztzzFwfvg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;就像 Bernard 研究 Theresa 一样，我们可以从我们自己的物种收集很多。智力，无论是人的还是人工的，都需要信息和目标。我们可以模拟信息和目标与实用程序之间的相互作用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在旧金山的卡布奇诺的成本是 5 美元，但它的效用考虑到你可以做的没有卡路里的价值（或缺乏），你花在咖啡和你的后咖啡因生产力上的时间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从这里，建模决策就像为事物计算实用程序并询问哪个更高一样简单。引入一些博弈理论、一点理性选择，甚至一些行为经济学，你会越来越接近打造一个接待员的目标。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「数据、学习、记忆、计算和硬编码的目标能使智能有效，」Klein 教授说。「这对机器和人来说都是如此。人类的目标是短视的，我想让自己的生活中被满足，我们做出折中的决策，以最大限度地发挥这些功能。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在你开始怀疑自己也是一个接待员了吗？这只是个想法。我们努力模拟一切，特别是在更长的时间范围，因为世界是一个非常复杂和动态的系统——甚至对于我们最复杂的处理器来说也太复杂。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们的系统今天使用暴力来破解问题，」Klein 教授说。「人类会做更多的元计算（meta computation），思考要考虑什么。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今天最先进的技术是使用强化学习帮助一台计算机赢得围棋比赛。我们捕捉各种走子策略的效用，消除低效率，这就是我们想要的。重要的是，在像围棋这样的游戏中的硬编码假设是我们想赢！这个开始的假设很好地连接到剧中「基石」背景故事的想法（注：是指故事中机器人接待员人格成立所设定的基础）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;第四步：让接待员和其它接待员对话&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;让接待员在空闲时间互相交谈是从机器学习角度培训他们的一个很好的方式。同样，一些科技公司今天也使用模拟训练数据来加快训练过程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一件要记住的是，真正的人类不断在即兴发挥。一个只是运行一个静态目标函数的接待员不是很有趣。如贝叶斯认知（Bayesian cognition）这样容易适应的东西，天生适合接待员。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们可以把数据变成行为，」Klein 教授说。「同样的算法可以可怕，也可以伟大，伟大的例子甚至更多。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;世界存在于一系列不断变化的状态中，并且良好的人工智能需要能够实时响应以更新其偏好。增加输入的数量增加了复杂性和混乱——这两件事虽然听起来可怕，但实际上是相当必要的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;第五步：不要忘记幻想（reveries）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW97Eu3kQ28xCXnW6b2iagC06kGGgdPm5W4gLoUzO0bdDaHQQPTX64ViamXFmiayia23Ea9XDB9HicagvsA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后但并非最不重要的：幻想（reveries）。他们从紧急行为（emergent behavior）和相变（phase transitions）的想法剥离，这是对人工智能空间中的研究人员的真正挑战。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Klein 教授解释说：「如果你建立一组能力，比如说 A、B 和 C，并添加一种方式，让它们进行交互，比如说相加（+），你可以生成 A + B、B + C、C + A 等等这些你之前不能生成东西。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这也可以说是最小的记忆，看起来就像是无害的手势，但却可以破坏一个复杂的系统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;两主体主义（Bicameralism，与你说话的声音）已经被视为一种意识理论，但是这样的声音可能会强迫行为的涌现，这类似于幻想（reveries）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们看到了病毒意识本质的主题，」Klein 教授补充说，「我们看到同样的事情与想法，一个模因（meme）是一个病毒的想法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;蝴蝶效应解释了蝴蝶翅膀这样轻微的事物可能会以不可预见的方式极大地改变任何复杂的系统——无论是海洋潮汐还是认知。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;祝你在打造自己的西部世界接待员上好运。最后也祝人类好运，毕竟人类正变得越来越不重要了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，机器之心系今日头条签约作者，本文首发于头条号，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Sat, 17 Dec 2016 11:07:24 +0800</pubDate>
    </item>
    <item>
      <title>干货 | Nervana技术深度解读：使用Neon的端到端语音识别是如何实现的</title>
      <link>http://www.iwgc.cn/link/3941389</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Nervana&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：杨旋、张瑞宁、chen chen&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;语音是一种固有的即时信号。语音中所承载的信息元素在多个时间尺度上演变。在空气压强的影响下，同一个声源的频率只会发生几百上千赫兹的变化，所以我们可以利用声音去判断一个声源的位置，并把它与周围嘈杂的环境区分开来以获得传递的信息。语音的功率谱中的缓慢变化的部分就是音素（phoneme）的生成序列，其中音素是构成我们所说的词的最小单位。除此之外，其中由单词组成的序列的变化更缓慢，这些词就组成了短语和叙事的结构。然而，这些元素在时间尺度上没有严格的区分界限。相反，各种尺度的元素都混合在了一起，所以时间上下文是十分重要的，其中较为稀少的停顿就可以作为元素之间区分的界限。自动语音识别（ASR）系统就必须弄明白这种噪声多尺度数据流，将其转换为准确的单词序列。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在撰写本文时，当下最流行和成功的语音识别引擎采用了一种混合系统来构建。即同时将深度神经网络（DNN）与隐藏马尔科夫模型（HMMs），上下文相关电话模型（context-dependent phone models），n-gram 语言模型（n-gram language models），和一种维特比搜索算法（Viterbi search algorithms）的复杂变体进行混合使用。这个模型相当的复杂，需要一套精致的训练方法，以及相当多的专业知识来帮助搭建模型。如果说深度学习的成功能教会我们什么东西，那就是我们可以经常用一种通用的神经网络来替代复杂的，多维度的机器学习方法，这些神经网络经过训练以后可以用来优化可微分的代价函数（cost function）。这种方法（我们暂且把这种方法称为「纯正」的 DNN 方法），已经在语音识别上取得了巨大的成功。现在，一旦我们有了相当多的训练数据和足够的计算资源，我们就可以更加轻松地构建一个高水准的大词汇量连续语音识别（Large Vocabulary Continuous Speech Recognition (LVCSR)）系统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本文的目的是为了对如何使用 Neon 来建立一个使用「纯正」DNN 方法的语音识别系统提供一种简单的指导介绍，其中 DNN 遵循了 Graves 和 他协作者所倡导的方法，同时，百度的人工智能研究人员对其进行了进一步的开发，让其成为了一种完整的端到端的 ASR 管道（end-to-end ASR pipeline）。同时，作为对本博文的补充，我们将会开源我们实现的这个端到端的音识别引擎（end-to-end speech recognition engine）的代码。在其最初始形式中，系统使用双向循环神经网络（BiRNN）来训练模型以直接从频谱图产生转录，而不必显示地将音频帧与转录对齐。与之取代的是一种隐式对齐，我们采用了 Graves 的连接体时间分类（CTC）算法（Connectionist Temporal Classification ，CTC）来实现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然「纯正」DNN 方法现在允许使用具有最先进性能的 LVCSR 系统进行训练，但是显式的解码步骤 ： 将模型输出转换为单词的可感知序列，在评估期间仍然是十分关键的。解码的技术是多种多样的，我们通常同时使用加权有限状态传感器（weighted finite state transducers）和神经网络语言模型（neural network language models）。如果想要了解相关的内容，那么需要一篇更加深入的文章来进行介绍，而本文主要限于 ASR 管道的训练部分。如果需要的话，我们为读者提供一些额外的参考知识来以填补空缺，希望能给读者传达构建端到端语音识别引擎的完整视图。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;简单扼要的说，端到端语音识别流水线由三个主要部分组成：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 特征提取阶段，其将原始音频信号（例如，来自 wav 文件）作为输入，并产生特征向量序列，其中有一个给定音频输入帧的特征向量。特征提取级的输出的示例包括原始波形，频谱图和同样流行的梅尔频率倒频谱系数（mel-frequency cepstral coefficients，MFCCs）的切片。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 将特征向量序列作为输入并产生以特征向量输入为条件的字符或音素序列的概率的声学模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 采用两个输入（声学模型的输出以及语言模型）的解码器并且在受到语言模型中编码的语言规则约束的声学模型生成的序列的情况下搜索最可能的转录。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9Iicdl6w0e8yz3Cx1yLlo7iarvHtWXEAL6fxMvYWia79sb7GMiaQaicAWVNHs8ZIoRw9JP0qApwcVeOOQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;处理数据&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当构建端到端语音识别系统时，一套有效的加载数据的机制是十分关键的。我们将充分利用 Neon 1.7 版本中新添加的功能：Aeon，一个能够支持图像，音频和视频数据的高级数据加载工具。使用 Aeon 大大简化了我们的工作，因为它允许我们直接使用原始音频文件训练声学模型，而不必困扰于对数据显示地预处理过程。此外，Aeon 能让我们更加容易的指定我们希望在训练期间使用的光谱特征的类型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;提取数据&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通常，语音数据以一些标准音频格式的原始音频文件和一些包含相应转录的一系列文本文件的形式被分发。在许多情况下，转录文件将包含形如：&amp;lt;音频文件的路径&amp;gt;，&amp;lt;音频文件中的语音的转录&amp;gt;的行的形式。这表示所列出的路径指向包含转录的音频文件。但是，在许多情况下，转录文件中列出的路径不是绝对路径，而是相对于某些假定目录结构的路径。为了处理不同数据打包情况，Aeon 要求用户生成包含绝对路径对的「清单文件」（manifest file），其中一个路径指向音频文件，另一个路径指向相应的转录。我们将为读者介绍 Neon 的演讲示例（包括链接）和 Aeon 文档以获取更多详细信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除了清单文件，Aeon 还要求用户提供数据集中最长的话语的长度以及最长的转录的长度。这些长度可以在生成清单文件时被提取。比如可以使用当下流行的 SoX 程序去提取音频文件的时长。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们通过训练由卷积（Conv）层，双向复现（bi-directional recurrent (BiRNN)）层和完全连接（FC）层（基本上遵循「Deep Speech 2」，如示意图所示）组成的深层神经网络来建立我们的声学模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9Iicdl6w0e8yz3Cx1yLlo7iaotLPFeibgsffF0kcQXXBxicrRQ7SVZ24RRmuA0bvNAbiaRnuZcF5GhNvA/0?wx_fmt=png"/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除了在输出层使用 softmax 激活函数，我们在其它层都采用 ReLU 激活函数。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如图所示，网络采用光谱特征向量作为输入。利用 Aeon dataloader，Neon 可以支持四种类型的输入特性：原始波形，频谱图，mel 频率谱系数（mel-frequency spectral coefficients (MFCSs)）和 mel 频率倒频谱系数（mel-frequency cepstral coefficients (MFCCs)）。MFSCs 和 MFCCs 是从频谱图中导出的，它们基本上将频谱图的每个列转换为相对较小数量的与人耳的感知频率范围更相近的独立系数。在我们的实验中，我们还观察到，在所有其他条件相等的情况下，用 mel 特征训练的模型作为输入执行效果略好于用频谱图训练的模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;光谱输入被传送到了 Conv 层。通常，可以考虑具有采用 1D 或 2D 卷积的多个 Conv 层的架构。我们将利用可以允许网络在输入的「更广泛的上下文」（wider contexts）上操作的 strided convolution 层。Strided convolution 层还减少序列的总长度，这又显著减小了存储器的占用量和由网络执行的计算量。这允许我们训练甚至更深层次的模型，这种情况下我们不用增加太多的计算资源就可以让性能得到较大的改进。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Conv 层的输出被送到 BiRNN 层的栈中。每个 BiRNN 层由串联运行的一对 RNN 组成，输入序列在如图所示的相反方向上呈现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9Iicdl6w0e8yz3Cx1yLlo7iat2TG5oKyjk4MDRUqtymBcWZc8M2mx8bjTiczbLbjicdmPefBtRIWsM1Q/0?wx_fmt=png"/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;来自这对 RNN 的输出将被串接起来如图所示。BiRNN 层特别适合于处理语音信号，因为它们允许网络访问输入序列 [1] 的每个给定点处的将来和过去的上下文。当训练基于 CTC 的声学模型时，我们发现使用「vanilla」RNN 而不是其门控变体（GRU 或 LSTM）是有好处的。这主要是因为后者具有显着的计算开销。如 [2] 所讲，我们还对 BiRNN 层应用批次归一化（batch normalization），以减少整体训练时间，同时对总体字错误率（WER）测量的模型的精度几乎没有影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在每次迭代中，BiRNN 层的输出先传递给一个全连接层，然后转而将信息传递给 softmax 层。在 softmax 层中的每个单元都对应着字母表中描述目标词汇表中的单个字符。例如，如果训练数据来自英语语料库，那么字母表通常将包括 A 到 Z 的所有字符和任何相关的标点符号，也包括用于分离文本中单词的空格字符。基于 CTC 的模型通常还需要包括特殊的「空白」字符的字母表。这些空白字符促使模型可以可靠地预测连续的重复符号以及语音信号中的人为部分，例如，暂停，背景噪声和其他「非语音」情况。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此，对于给定话语的帧序列，该模型要为每帧生成一个在字母表上的概率分布。在数据训练期间，softmax 的输出会被传输到 CTC 代价函数（后文将详细论述），其采用真实的文本来（i）对模型的预测值进行打分，以及（ii）生成用以量化模型预测值的准确性的误差信号。总体目标是训练模型来提升在真实场景下的预测表现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;训练数据&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;根据经验，我们发现使用随机梯度下降法和动量与梯度限制配对法会训练出最优性能的模型。更深层的网络（7 层或更多）在大体上也有同样的效果。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们采用 Sutskever 等人实现的 Nesterov 的加速梯度下降法去训练模型。大多数模型的超参数，例如：网络的深度，给定层中的单元数量，学习速率，退火速率，动量等等，是基于现有的开发数据集根据经验选择出来的。我们使用「Xavier」初始化方法来为我们的模型中的每一层进行初始化，虽然我们还没有系统地调查过是否通过使用其他可取代的初始化方案，来比较实验的结果是否有所优化。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们所有的模型都使用 CTC 损失标准进行训练，对 CTC 计算法内部过程的详细解释超出了本博客的范围。我们将在这里提出一个简要概述，为了获得更深的理解，建议读者去阅读 Graves 的论文。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;CTC 计算法以「折叠」函数的动作为核心，该函数采用一系列字符作为输入，并通过首先去除输入字符串中的所有重复字符，然后删除所有「空白」符号来产生输出序列。&lt;/span&gt;&lt;span&gt;比如说，如果我们使用「_」表示空白符号，然后&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9Iicdl6w0e8yz3Cx1yLlo7iaQodpzEGZAPOFaf4iacr9ibrMIJZpFFibfpiauPoVBKP4EicAoxV2LOIA9VA/0?wx_fmt=png"/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;给定一个长度为 T 的话语和其对应的「ground truth」的转录，CTC 算法会构建「转置」的折叠函数，其定义为所有可能的长度为 T 的，折叠到「ground truth」转录上的字符序列。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;任意序列出现在该「转置」集合中的概率是可以直接从神经网络中的 softmax 输出计算出来的。然后将 CTC 成本定义为序列的概率和的对数函数，它存在于「转置」集合中。该函数对于 softmax 的输出是可区分的，这是反向传播中所要计算的误差梯度。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以一个简单示例来做说明，假设输入话语有三个帧，并且相应的转录本是单词「OX」。同样，使用「_」表示空白符号，折叠为 OX 的三字符序列集包含 _OX，O_X，OOX，OXX 和 OX_。&lt;/span&gt;&lt;span&gt;CTC 算法设置 &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9Iicdl6w0e8yz3Cx1yLlo7iamicRFu2zerDOTjVHYaE5zzSEicr8uMeEIM7o6dHiaFbx1ufCT0icPibxQiaA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P(abc) = p(a,1)p(b,2)p(c,3)，其中 p(u,t) 表示单元「u」, 时间 t（帧）时 softmax 模型的输出值。因此 CTC 算法需要枚举固定长度的所有序列，其折叠到给定的目标序列。当处理非常长的序列时，通过前向 -后向算法，枚举组合可以被有效的执行，这就非常接近采用 HMMs 方法的处理问题的思想。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;评价&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一旦模型训练完成，我们可以通过预测一段系统从未听过的语音来评估它的性能。由于模型生成概率向量序列作为输出，因此我们需要构建一个解码器（decoder）来将模型的输出转换成单词序列（word sequence）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;解码器的工作是搜索模型的输出并生成最有可能的序列作为转录（transcription）。最简单的方法是计算&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9Iicdl6w0e8yz3Cx1yLlo7iaU2B9IicCLEXK69GIbgt6zFzkyh2NUomhcMPa72ctibS7mcVLKx3tzZgg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中 Collapse（...）是上面定义的映射（mapping）。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管用字符序列训练模型，我们的模型仍然能够学习隐式语言模型（implicit language model），并已经能够非常熟练地用语音拼写出词语（见表 1）。通常在字符级别用 Levenshtein 距离计算的字符错误率（CERs）来测量模型的拼写性能。我们已经观察到，模型预测的很多误差是没有在训练集中出现过的单词。因此，可以合理地预计，随着训练集规模的增加，总的 CER 数值将继续改进。这个预期在深度语音 2（Deep Speech 2）的结果中得到证实，它的训练集包括超过 12000 小时的语音数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;table align="center"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); word-break: break-all;" align="center" valign="middle"&gt;&lt;p&gt;&lt;span&gt;Model output without LM constraints&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;没有 LM 约束的模型输出&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); word-break: break-all;" align="center" valign="middle"&gt;&lt;p&gt;&lt;span&gt;「Ground truth」transcription&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;完全实况转录的结果&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;younited presidentiol is a lefe in surance company&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;united presidential is a life insurance company&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;that was sertainly true last week&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;that was certainly true last week&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;we’re now ready to say we’re intechnical default a spokesman said&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;we’re not ready to say we’re in technical default a spokesman said&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;表 1：模型对华尔街日报评估数据集的预测样本。我们故意选择了模型难以判断的例子。如图所示，加入语言模型约束后基本上消除了在没有语言模型的情况下产生的所有「拼写错误」。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然我们的模型显示了非常好的 CER 结果，模型的读出单词拼写（spell out words phonetically）的倾向导致了相对较高的单词错误率。我们可以通过加入从外部词典和语言模型得到的解码器来约束模型，以此改进模型的性能（WER）。根据 [3,4]，我们发现使用加权有限状态传感器（WFST）是一个特别有效的完成这项任务的方法。我们观察到 WER 数值在 WSJ 和 Librispeech 数据集上相对提高了 25％。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;表 2 列出了使用华尔街日报（WSJ）语料库训练的各种端到端语音识别系统。为了测试「苹果」（公司）与「苹果」（水果）的识别结果，我们选择仅用 WSJ 数据集训练和评估的系统的公开数据进行系统间的比较。然而，结果显示在同一数据集上训练和评估的混合 DNN-HMM 系统比使用纯深神经网络架构的系统表现更好 [6]。另一方面，结果显示当训练集的数据量更大时，纯深度神经网络架构能够实现与混合 DNN-HMM 系统相同的性能 [引用 DS2]。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;Reference&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;CER&lt;br/&gt;(no LM)&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;WER&lt;br/&gt;(no LM)&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;WER&lt;br/&gt;(trigram LM)&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;WER&lt;br/&gt;(trigram LM w/ enhancements)&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;Hannun, et al. (2014)&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;10.7&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;35.8&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;14.1&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;N/A&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;Graves-Jaitly (ICML 2014)&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;9.2&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;30.1&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;not reported&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;8.7&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;Hwang-Sung (ICML 2016)&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;10.6&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;38.4&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;8.88&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;8.1&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;Miao et al. (2015) [Eesen]&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;not reported&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;not reported&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;9.1&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;7.3&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;Bahdanau et al. (2016&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;6.4&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;18.6&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;10.8&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;9.3&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(205, 224, 223);" align="center" valign="middle"&gt;&lt;span&gt;Our implementation&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(205, 224, 223);" align="center" valign="middle"&gt;&lt;span&gt;8.64&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(205, 224, 223);" align="center" valign="middle"&gt;&lt;span&gt;32.5&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(205, 224, 223);" align="center" valign="middle"&gt;&lt;span&gt;8.4&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(205, 224, 223);" align="center" valign="middle"&gt;&lt;span&gt;N/A&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;表 2：我们只使用华尔街日报数据集来训练和评估各种端到端的语音识别系统的性能。CER（character error rate）指的是比较由模型得到的字符序列与实际转录的字符序列的字符错误率。LM 指的是语言模型。最后一列指的是使用附加技术（如重新评分、模型聚合等）解码的例子。&lt;/span&gt;&lt;br/&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;未来的工作&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;将 CTC 目标函数嵌入神经网络模型的语音识别模型，让我们初次看到了这种 纯正 DNN 模型的能力。不过，最近，所谓的基于注意机制（attention mechanism）增强的编-解码器（encoder-decoder）的 RNN 模型正在兴起，并作为用一种使用 CTC 标准 [4,5] 训练的 RNN 模型的可行的替代方案。基于注意机制的编-解码器模型与基于 CTC 标准的模型，都是被训练用于将声音输入序列（acoustic input）映射（map）到字符/音位（character/phoneme）序列上。正如上面所讨论的，基于 CTC 标准的模型被训练用于预测语音输入的每个帧对应的字符，并在逐帧的预测与目标序列序列之间搜索可能的匹配。与之相反，基于注意机制的编-解码器模型会在预测输出序列之前首先读取整个输入序列。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该方法概念上的优点是，我们不必假设输出序列中的预测字符是相互独立的。CTC 的算法基于这个假设，而该假设是毫无根据的——因为字符序列出现的顺序是与比之之前较早出现的字符序列是高度条件相关的。最近的研究工作显示，LVCSR 系统的基于注意机制的编-解码器模型相对于基于 CTC 标准的模型在字符出错率上有明显的改善 [4]。在我们这两种方法被整入语言模型之前进行评估，得出的评断是正确的，这也支持了基于注意机制的模型是比基于 CTC 标准的模型更好的声学模型的论断。然而，值得指出的是，当语言模型被用来确定单词错误率时，这种性能上的差异就消失了。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们正致力于建立 ASR 系统的基于注意机制的编-解码器网络的 Neon，竭诚欢迎各类参与。代码可以参见&lt;/span&gt;&lt;span&gt; https://github.com/NervanaSystems/deepspeech.git.&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em style="color: rgb(136, 136, 136);"&gt;&lt;span&gt;原文链接：https://www.nervanasys.com/end-end-speech-recognition-neon/&lt;/span&gt;&lt;/em&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 16 Dec 2016 11:40:09 +0800</pubDate>
    </item>
    <item>
      <title>开源 | 谷歌开源Land Lines：简单一笔为你匹配谷歌地球对应位置</title>
      <link>http://www.iwgc.cn/link/3941390</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自GoogleDevelopersBlog&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;新年将近，如果你不愿意亲自在寒冷的冬天里外出旅行，那么你可以尝试一下谷歌地球（Google Earth）。但地球这么大，你却不知道看哪里？没关系，谷歌近日又推出了一项神奇的新功能：Land Lines。你只需要简简单单画一笔，谷歌就能为你将这一笔和谷歌地球上的地理或建筑线条匹配起来，将你带到你意想不到的地方：东南亚群岛的海岸线、欧洲小镇的街角、南美横贯的河流……&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这一切只需要轻轻一画。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;体验地址：&lt;span&gt;https://lines.chromeexperiments.com&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该项目有两种体验方式。一是画（draw）——能帮你找到与你画的线匹配的卫星图像；二是拉（drag）——可以创建一条互相连接的河流、高速公路和海岸线的线条。下面是一个简单的演示：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_gif/KmXPKA19gW9Iicdl6w0e8yz3Cx1yLlo7iaAezXBn7X5YJ1o26FxiccEomnBvm6o8obxLIsWyBBcsNz7QLbMypwkfw/0?wx_fmt=gif"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这一切都运行在你的手机网页浏览器中，不需要任何服务器。（桌面 Chrome 浏览器也可使用。）据谷歌介绍，这些响应是通过机器学习、数据优化和 vantage-point tree 分析图像和存储该数据所得到的。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌解释说：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;我们组合性地使用了 OpenCV 的基于结构化森林（Structured Forests）机器学习的边检测和 ImageJ 的 Ridge Detection 库。这将最初的超过 5 万张高分辨率图像数据集减少到了能够代表这些线的形状的仅仅几千张图像，如下图所示。这样的处理以往需要花费几天时间，我们只用了几个小时就完成了。&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9Iicdl6w0e8yz3Cx1yLlo7iawDHEz35Zv6D0uTmzZDSnk9cgibbtVY2PPZbJAFbvMyTRs3bqVZzUnqQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;来自线条检测处理（line detection processing）的输出示例。其中主线以红色突出显示，而辅助线则以绿色显示。&lt;/span&gt;&lt;/em&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在绘画实验中，谷歌将结果数据存储到了 vantage-point tree 中。这让该应用可以有效地在所有图像上运行手势匹配（gesture matching），并在毫秒级的时间内给出结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9Iicdl6w0e8yz3Cx1yLlo7iaTWWpWggibvIFAuzvCQzEs2O3gWicHktdWVUYfLsVgb8kc78bUhnkz2OQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;使用 vantage-point tree 的一个早期的手势匹配样本，其中右边是画出的输入，而左边则是最接近的结果。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9Iicdl6w0e8yz3Cx1yLlo7iaqnT6eqGRgJM7aC9mFKiaWLhZthePNwkL82mE5LnoibicWA0OlToTBouqQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;另一个用户手势分析的示例，其中右边是画出的输入，而左边则是最接近的结果。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该项目是与黑客兼艺术家 Zach Lieberman 合作开发的。Land Lines 是一个大型视觉数据连接主题探索实验。开发团队表示他们在他们的开发过程中采用了多种机器学习库。Lieberman 还写了一份有关的学习经历，该项目的代码也已经开源，相关链接如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Lieberman 的经历：&lt;span&gt;https://developers.google.com/web/showcase/2016/land-lines&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Land Lines 开源地址：&lt;span&gt;http://github.com/ofZach/landlines/&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;vantage-point tree 开源地址：&lt;span&gt;https://github.com/fpirsch/vptree.js&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;OpenCV Structured Forests 机器学习：&lt;span&gt;http://docs.opencv.org/3.1.0/d0/da5/tutorial_ximgproc_prediction.html&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;ImageJ 的 Ridge Detection 库：&lt;span&gt;http://imagej.net/Ridge_Detection&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 16 Dec 2016 11:40:09 +0800</pubDate>
    </item>
  </channel>
</rss>
