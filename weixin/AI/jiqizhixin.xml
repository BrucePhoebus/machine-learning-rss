<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>模型学习全面概述：利用机器学习查找软件漏洞</title>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650723383&amp;idx=1&amp;sn=a7146db5966a949b63bb02f3ab0f3f02&amp;chksm=871b1049b06c995ff4e14ec28bf8d7a24bb0ace8060ea94748fd75db77098612edb25dc19581&amp;scene=0#rd</link>
      <description>
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自ACM&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Frits Vaandrager&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Communications of the ACM 近日发表一篇题为《Model Learning》的文章，详细介绍了模型学习及其研究现状和应用。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本文的要点是：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;模型学习的目标是通过提供输入和观察输出来构建软件和硬件系统的黑箱状态图模型（black box state diagram model）。模型学习的算法的设计师一个基本的研究问题。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;模型学习正在成为一种高效的漏洞寻找技术，有银行卡、网络协议和遗产软件等领域的应用。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;iframe allowfullscreen="" class="video_iframe" data-vidtype="1" frameborder="0" height="417" src="https://v.qq.com/iframe/preview.html?vid=f0376e2xzl0&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0" width="556"&gt;&lt;/iframe&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在新算法的设计上，最新出现了很多新进展，既有有限状态图（Mealy 机）背景的进展，也有数据（register automata）背景的进展。通过抽象（abstraction）技术的使用，这些算法可以被应用到复杂系统上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;按下按键观察结果，这是我们学习一个装置或计算机程序的惯常做法。孩童尤其擅长这一点，无需借助手册他们便可以搞懂如何正确使用智能手机或微波炉。鉴于以上，我们建构了一个心智模型&amp;mdash;&amp;mdash;一个装置状态图：做一些实验，即可获知该装置的整体状态以及输入所对应的状态转换与输出结果。本文介绍了自动执行此任务的算法的设计与应用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有很多推断软件组件模型的方法，比如分析代码、挖掘系统日志、执行测试；有不同的模型被推断过，比如隐马尔可夫模型、变量之间的关系、类图（class diagrams）。在本文中，我们关注一种特定类型的模型，即状态图（state diagrams），其对于理解许多软件系统的行为至关重要，例如（安全和网络）协议和嵌入式控制软件。模型推断技术分为白箱和黑箱，区别在于是否需要访问代码。本文只讨论黑箱技术。这些技术的优点是相对容易使用，并可以应用在我们没有代码访问权限或足够的白箱工具的情况下。作为最终的限制，我们只考虑主动学习（active learning）的技术，即通过主动地对软件进行实验（测试）来完成它们的任务的技术。此外，还有一个广泛的被动学习（passive learning）工作，其中模型是从（一组组）运行的软件构建的。主动学习的优点是它提供了软件组件的完整行为模型，而不仅仅是在实际操作期间发生的特定运行的模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;状态图（或自动机（automaton））的主动性黑箱学习的基本问题的研究已经持续了几十年。1956 年，Moore 首先提出了学习有限自动机（finite automata）的问题，并提供了一个指数算法，还证明这个问题本质上是指数式的。后来，不同的组织以不同的名字对这个问题进行着研究：控制论学家把它称为「系统辨识（system identification）」；计算语言学家称之为「语法推理（grammatical inference）」；一些论文将其命名为「常规推理（regular inference）」、「常规外推（regular extrapolation）」、「主动性自动机学习（active automata learning）」；安全研究者造了个新术语「协议状态模糊（protocol state fuzzing）」。本文中，我们使用的术语「模型学习（model learning）」与经常使用的「机器检查（model checking）」类似。虽然「模型检查」被广泛用于分析有限状态模型，但「模型学习」则是通过观察输入-输出数据以构建模型的补充技术。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1987 年，Angluin 发表了一篇研讨论文，她表明可以使用所谓的会员查询（membership query）和等价查询（equivalence queries）来学习到有限自动机。自此之后，尽管提出了更快算法，但最有效的学习算法依然遵循着 Angluin 所提出的 MAT（minimally adequate teacher/最低限度足够的教师）的原则。在 MAT 框架中，学习被看作是一个博弈（game），其中学习器（learner）必须通过询问教师（teacher）来推断一个未知的状态图的行为。在我们的设定中，教师知道状态图，其被称为 Mealy 机（Mealy machine），简称：M。一开始，学习器只知道 M 的输入 I 和输出 O。学习器的任务是通过两种类型的查询学习 M：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;使用会员查询 (MQ/membership query)：学习器询问输入序列&amp;sigma; &amp;isin; I*对应的输出结果是什么。教师使用输出序列 AM(&amp;sigma;) 来回答。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;使用等价查询 (EQ/equivalence query)：学习器询问一个带有输入 I 和输出 O 的虚拟的 Mealy 机 H 是否正确，即：H 和 M 是否等同。如果情况属实，教师回答「是」。否则教师回答「否」，并提供一个反例&amp;sigma; &amp;isin; I*来区分 H 和 M。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Angluin 的 L*算法能够通过询问会员查询和等价查询的多项式数（多项式数的大小对应于典型的 Mealy 机）来学习 Mealy 机 M。在 Angluin 的算法中我们给 L*做了一个简化，实际的实现中（例如 LearnLib 和 libalf）则包含很多优化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Peled 等人作出了重大发现：MAT 框架可以用来学习软硬件组件的黑箱模型。假设我们有一个组件，我们称之为系统学习（SUL），其行为可以由（未知的）Mealy 机 M 描述。我们进一步假设，总是可以使 SUL 回到其初始状态。现在，通过使 SUL 回到初始状态并进一步观察给到 SUL 的输入序列所对应的输出结果可以实现会员查询。等价查询可以通过有限数量的测试查询（TQ/test queries）以使用一致性测试（CT/conformance testing）工具来接近。测试查询询问 SUL 对输入序列的响应，类似于会员查询。如果其中一个测试查询呈现反例，则等价查询的答案为否，否则答案为是。示意图如图 4 所示。在这种方法中，学习者的任务是构造假设，而一致性测试工具的任务是测试这些假设的有效性。由于测试工具只能构造有限数量的查询，因此我们无法确定一个学习模型的正确性。然而，如果我们假定机器 M 的状态数量有界限，则存在有限和完整的一致性测试套件。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/dc5036990176d3b67a07eb1ae7c7fd3209211dc3"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图.4&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Peled 等人和 Steffen 等人的开创性工作在模型学习和正式方法的领域之间建立了迷人的联系，特别是模型检验和基于模型的测试。随后的研究已经证实，在没有反应系统的易处理的白箱模型的情况下，学习模型通常是可以以相对低的成本获得的优良的替代方案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了检查学习模型的属性，可以使用模型检查（model checking）。事实上，Peled 等人已经在一种叫「黑箱检查（black box checking）」的方法中展示了如何完全整合模型学习与模型检查，其基本思想是使用模型检查器作为图 4 中一致性测试工具的「预处理器（preprocessor）」。当教师接收到学习器的假设时，首先运行模型检查器以验证假设模型是否满足 SUL 规定的所有属性。只有假设为真时，才转发给一致性测试器（conformance tester）。如果其中一个 SUL 属性不成立，那么模型检查器产生一个反例。现在有两种情况。第一种可能性是反例可以在 SUL 上再现。这意味着我们已经在 SUL（或其规定中）中展示了一个错误，我们停止学习。第二种可能性是反例不能在 SUL 上再现。在这种情况下，教师遵循假设是不正确的原则向学习器返回反例。在后来的工作中，黑箱检查方法已经进一步完善，并已成功应用于几个工业案例。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大多数学习算法的所需会员查询数量随着输入数量线性增长，并与状态数量成二次方。这意味着当输入数量增长时，学习算法规模相当好；换句话说，制定一个新的假设是容易的。然而，检查假设是否正确（一致性测试）会很快成为大量输入的瓶颈。如果当前假设具有 n 个状态，则 SUL 具有 n' 个状态，并且存在 k 个输入，则在最坏的情况下，需要运行包含 n'-n 个输入的所有可能序列的测试序列，即 k(n' &amp;minus; n) 个可能性。因此，模型学习目前只能应用于少于 100 个输入的情况下。因此，我们寻求帮助我们减少输入数量的方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;抽象（abstraction）是将模型学习方法扩展到现实应用程序的关键。Cho 等人通过在僵尸网络服务器和学习软件之间放置仿真器/映射器（emulator/mapper），将字母符号具体化为有效的网络消息并将它们发送到僵尸网络服务器（botnet servers），成功推断出现实僵尸网络命令和控制协议的模型。当接收到响应时，仿真器作反向处理：它将响应消息抽象为输出的字母，并将它们传递到学习软件。这种学习设置的示意图概述如图 5 所示。处理抽象的中间映射器组件的想法是非常自然的，并且在许多关于自动机学习的案例研究中被隐含地或明确地使用。Aarts 等人通过与谓词抽象（predicate abstraction）和抽象解释（abstract interpretation）建立连接，发展出了关于中间性抽象（intermediate abstraction）的数学理论。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/d7a65a7246a36154ea5a3f5a78481e7630e48394"/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;图.5&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个补充性的简单但实用的方法是将模型学习应用在多个更小的输入子集上。这将明显降低学习复杂性；还因为对于有限数量的刺激，可达状态的集合通常将更小。然后，对于输入的子集学习的模型可以用于在学习更大子集的模型时生成反例。例如，Chalupar 等人已经应用的另一种方法是将通常以特定顺序发生的多个输入动作合并成单个高级动作，从而减少输入的数量。再次，已经用少量高级输入学习的模型可以用于在后续实验中产生反例，其中这些输入被分解成它们的组成部分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;正如 C.A.R. Hoare 所说，一个人可以说，在每个大程序中都有一个小的状态机试图出去。通过选择适当的输入动作集合并定义适当的映射器/抽象，我们可以使这个小状态机对学习者可见。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;应用案例&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;近年来，模型学习已经成功应用于不同领域的许多实际案例。工业应用的例子有，例如，在西门子的电信系统的回归测试（regression testing），在法国电信的集成测试，在施普林格出版社线上会议的自动测试，在沃尔沃科技的线控制动系统的测试要求。下面，我将概述奈梅亨大学（Radboud University）在智能卡、网络协议和遗产软件（legacy software）方面进行的一些代表性案例研究。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;智能卡。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;Chalupar 等人使用模型学习来反向工程 e.dentifier2&amp;mdash;&amp;mdash;一种用于网上银行的智能卡阅读器。为了能够学习 e.dentifier2 的模型，作者构建了一个由树莓派（Raspberry Pi）控制的乐高机器人，可以操作读取器的键盘（参见图 6）。从笔记本电脑控制所有这些之后，他们可以使用 LearnLib 学习 e.dentifier2 的模型。他们学习了一个版本的 e.dentifier2 的四态 Mealy 机，揭示了存在的一个安全缺陷，并且表明该缺陷不再存在于新版本设备的三态模型中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/f3be5c730ffb415a252d548f206abac9e4511271"/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;图.6&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在另一项研究中，Aarts 等人学习了银行卡上的 EMV 协议套件的实现模型，这些银行卡有来自几家荷兰和德国银行的，有荷兰和瑞典银行发行的万事达信用卡以及一张英国签证借记卡。为了学习模型，LearnLib 对每个卡执行 855 到 1696 个会员和测试查询，并生成 4 到 8 个状态的模型。（图 7 展示了其中一个学习的模型）。所有卡产生不同的模型，只有荷兰银行卡上的应用程序是相同的。所学到的模型没有揭示任何安全问题，虽然注意到一些怪异问题。作者认为，模型学习将作为安全评估的一部分发挥作用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/a1b8936f74b1f3c6d46db6e72c6b084a9b0994a8"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图.7&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;网络协议。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我们的社会已完全依赖于网络和安全协议的正确运作；这些协议中的错误或漏洞可能会导致安全漏洞甚至是彻底的网络故障。模型检查已被证明是一种用于发现此类错误与漏洞的有效技术。然而，由于针对协议实现的详尽模型检查通常不可行，因此模型检查通常会应用于根据协议标准开始人工制作的模型。这意味着由于协议实现不符合模型检查的规范，其出现的错误便无法被捕捉。研究证明，模型学习能够有效地找到此类错误，使这项技术得以与模型检查互补。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;例如，De Ruiter 和 Poll 使用支持多种密钥交换算法和客户端认证选项的测试工具分析了 TLS 协议的服务器端和客户端实现。结果表明模型学习（或称为协议状态模糊）可以捕获一类有趣的实现缺陷，而这种缺陷在安全协议实现中十分常见：在九个受测试的 TLS 实现中，有三个能够发现新的安全缺陷。如 Java Secure Socket Extension 便是一类学习了 Java 1.8.0.25 版本的模型。他们发现该模型包含两条通往应用程序数据交换的路径：常规 TLS 协议运行和另一意外运行。客户端以及服务器应用程序都以为它们处于安全的连接上交谈，但实际上任何人都能够通过利用这种行为读取并篡改客户端的数据。所以修复作为安全更新的一个关键部分而被发布，并且他们能够通过学习 JSSE 1.8.0.31 版本的模型来确认问题是否已解决。得益于人工构建的抽象/映射器，经验丰富的 Mealy 机包含 6 至 16 个状态并且规模都很小。另外，由于对不同的 TLS 实现的分析产生了独一无二的 Mealy 机，模型学习也可用于为 TLS 实现添加指纹印记。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Fiterau 等人在一个涉及 Linux、Windows 以及使用 TCP 服务器与客户端的 FreeBSD 实现的案例研究中将模型学习与模型检查进行了结合。模型学习用于推断不同组件的模型，而后应用模型检查来充分探索当这些组件（如 Linux 客户端和 Windows 服务器）交互时可能的情况。案例研究揭示了 TCP 实现中不符合其 RFC 规范的几个例子，具体示例参见图 8。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/bf065a80d1dd600eed33d1ba7af5cacdd70bfa3f"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图.8&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;遗产软件（Legacy software）&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。遗产系统被定义为「不知如何处理却对组织至关重要的大型软件系统」（7）。通常这些系统的技术已经过时，并且文档存在限制，原始开发人员也已经离职。此外现有的回归测试将受限。鉴于以上特征，需要改变传统组件的创新存在风险。故而开发了几种技术用于提取隐藏在传统组件中的关键业务信息，并支持重构实现的结构。Margaria 等人（30）首先指出，模型学习可能有助于确认传统组件和重构实现具有相同的行为。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;例如 Schuts 等人在飞利浦的开发项目中使用模型学习来支持传统嵌入式软件的复兴。该项目涉及到一个新引入的硬件组件&amp;mdash;&amp;mdash;电源控制组件（PCC），用于启动和关闭介入放射学系统。系统中的所有计算机都具有软件组件，即在启动和关闭的执行期间通过内部控制网络与 PCC 通信的电源控制服务（PCS）。为了处理具有不同接口的 PCC 的新硬件，则需要 PCS 的新型实现。由于必须支持新型和旧型 PCC 硬件的不同配置，新型与旧型 PCS 软件需要具有完全相同的外部行为。图 9 说明了所遵循的方法。由传统的 A 实现以及重构的 B 实现可获得 Mealy 机器模型 MA，而使用模型学习可获得 MB；这些模型将使用等价检查器进行比较。当等价检查器发现反例&amp;sigma;时，我们将检查 A 和 MA 在输入&amp;sigma;上表现是否相同，同样检查 B 和 MB 在输入&amp;sigma;上是否相同。若 A 和 MA 或者 B 和 MB 存在差异，我们便会要求学习者基于反例&amp;sigma;构造一个改进的模型。否则&amp;sigma;便表示 A 和 B 之间的差异，而我们也会根据对于&amp;sigma;的响应表现差劲的行为来改变 A 或 B（或是两者）。为了解决可扩展性问题，往往通过增加刺激来学习以及迭代地检查实现。在组件集成之前的早期阶段，重构实现和传统实现都出现了问题。也正因如此，才能避免开发的后期阶段昂贵的重工现象。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/0ed2dd0fde8d121bb311178fea9335a6112c4712"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图.9&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;最新进展&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;近年来，有关模型学习的算法已取得显著进步，这对将这些技术应用扩展到更大的系统而言至关重要。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;基本算法&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。自 1987 年以来，Angluin's 的 L *算法已得到显着改善。原始 L *对观察表中的每个条目执行成员资格查询；但这通常是多余的，因为该查询的唯一目的是区分状态（行）。因此，Kearns 和 Vazirani 通过鉴别树（discrimination trees）将 L *算法的观察表进行重设，而该鉴别树基本上是用于确定等价状态的决策树。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;L *的另一个低效的体现是将反例的所有前缀作为行添加到表格中。通过一致性测试或运行时监控获得的反例样本可能极长且极小，而这会导致大量多余的成员资格查询。Rivest 和 Schapire 发现不必将反例的所有前缀作为行添加到表格中，将一个选定的后缀添加为列便足够了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Isberner 等人提出的新 TTT 算法是目前用于主动学习的最有效的算法。该算法基于 Kearns 和 Vazirani 以及 Rivest 和 Schapire 的想法，但消除了通过清理内部数据结构及重新组织判别树来处理长型反例时过长的鉴别树。假设某 Mealy 机 M 具有 n 个状态和 k 个输入值，并且返回的最长反例长度为 m。然后在最坏的情况下 TTT 算法需要长度为 O（n + m）的 O（n）个等价查询和 O（kn2 + nlog m）个成员资格查询。这种最坏情况的查询和符号复杂度与 Rivest 和 Schapire 的算法一致，但实践中 TTT 的速度更快。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;TTT 算法通常比 L *算法产生更多的中度假设（intermediate hypotheses）。这表明单就 membership 查询中使用的输入符号数量可能并不是比较学习算法的适宜度量：我们还需考虑实现等价查询所需的测试查询的数量。membership 与测试查询中的输入符号的总数似乎是比较实践中学习方法的可靠度量。我的两个学生 J.Merman 和 A.Fedotov 在大量基准（协议、控制软件、回路等）上，比较了学习算法和测试算法的不同组合，并发现 TTT 使用的输入符号平均比 L*少 3.9 倍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当可以同时运行 SUL 的多个实例时，学习和测试能够很容易被并行化。能够加速学习的另一项技术是保存并恢复 SUL 的软件状态（检查点）。其中的益处是：当 learner 想要从保存的 q 状态中探索不同的外向转换时，仅仅需要恢复 q，这通常比复位系统，再经由输入序列返回到 q 要快得多。Henrix（21）报告了在实验中使用 DMTCP（分布式多线程检查点）进行检查点加速学习，系数为 1.7。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;寄存器自动机。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;尽管我们已经看到学习状态机中基本算法的诸多进步，但这些算法仅能成功学习相对很小的状态机。为了能把这些算法扩展至现实应用领域，使用者一般需要手动构建抽象或者映射器。2这可能是个耗时的活动，需要几次迭代和 SUL 的专业知识。因此，最近已经进行了许多工作以将学习算法推广到结构更多结构、类型更丰富类的模型中去，特别是其中数据值可以被传送，存储和操纵的 EFSM 模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;模型学习算法的开发正是对寄存器自动机进行的特定扩展。11 &amp;nbsp;这些自动机具有有限的一组状态，但都用一组可用于存储数据值的寄存器进行扩展了。输入和输出动作被参数化为具体的数据值，可以在转换保护中进行相等测试并存储在寄存器中。图 10 给出了寄存器自动机的简单示例，即容量为 2 的 FIFO 集。一个 FIFO 集对应于一个只能存储不同值的队列。它有一个 Push（d）输入符，用来尝试在队列中插入值 d 的符号，还有一个 Pop 输入符，用来尝试从队列中取回一个值。如果输入值可以成功添加，则 Push 的对应输出为 OK，如果输入值已经在队列中或者队列为满，则 Push 的对应输出为 KO。如果以队列中最旧的值作为参数，则 Pop 的对应输出是 Out，如果队列是空的，则 Pop 的对应输出是 KO。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/8f111fd54618c02246493d0136066f86393d1aa1"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图.10 &lt;/span&gt;&lt;/em&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;抽象是将模型学习方法扩展至现实应用的关键&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在寄存器自动机中，所有数据值是完全对称的，且这种对称性是可以在学习过程中被利用的。在本文中已经探索了两种不同的方法。第一种方法，以 Cassel 等人为代表，12 &amp;nbsp;已在软件工具 LearnLib26 和 RALib 中得到实施。10 模型学习算法通常依赖于 Nerode 关系（Nerode relation）来识别已学过的自动机的状态和转换：如果两个词的残差语言（residual languages）吻合，这两个词则导致相同的状态。现在的基本思想是为寄存器自动机设计出一个类似 Nerode 的同余关系，而这决定了已推断的自动机的寄存器的状态、转换、和内容。这种实施方法的技术基础是所谓的符号决策树（symbolic decision trees），它可以用来总结许多用简明符号表达的测试结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;学习寄存器自动机的第二种方法，以 Aarts 等人为代表，已在软件工具 Tomte 中得到实施。这种方法使用反例引导的抽象提炼来自动构建适当的映射器。这种想法源于一个彻底抽象，即完全忽略在输入和输出动作中出现的数据值。当这种抽象过于粗糙时，learner 将观察到非确定性行为。比如在图 10 的示例中，输入序列 Push Push Pop Pop 大部分情况触发的输出为 OK OK Out KO，但有时为 OK OK Out Out。出现这种行为就需要对抽象进行提炼。在我们的示例中，比如就第二个 Push，我们至少需要两个抽象版本，因为这显然关乎该输入的数据值是否等于第一个 Push 的数据值。RALib 和 Tomte 在性能上都优于 LearnLib。Tomte 和 RALib 的性能大致相当。RALib 在一些基准测试中胜过 Tomte，但是 Tomte 能够学习一些 RALib 无法处理的寄存器自动机，例如容量为 40 的 FIFO 集。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;研究挑战&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;即使模型学习已经在许多地方得到成功应用，但该研究领域仍处于起步阶段。模型学习的应用具有巨大的潜力，尤其是在传统控制软件领域，但是还需要对算法和工具进行更多的研究，以将模型学习从目前的学术原型水平转变为可实际使用的技术水平，从而方便应用于大量不同类型的系统。在这里，我将讨论一些主要的研究挑战。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;谓词与数据操作。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;最近对寄存器自动机模型学习算法所做的扩展是一个突破，这可能使模型学习适用于更大范围的系统。由于不允许对数据进行操作的限制，可以被描述为寄存器自动机的系统类型很少，并且主要由一些学术样例构成，例如有界重传协议和一些简单数据结构等等。然而，如 Cassel 等人所指，12 使用 SMT 解决寄存器自动机的新学习算法可以被扩展为 EFSM 的形式，其中模型防护（guard）可能包含谓词，如 successor 和小于关系（less than relation）。目前已经有 RALib 的原型实现，而且我们正在接近可以自动学习真实世界协议模型的目标，这样的协议可以像 TCP、SIP、SSH 和 TLS 等等，而这些都不需要手动定义抽象。然而，我们对使用不同谓词和操作学习 EFSM 的算法的理解仍然有限，而且还有许多悬而未决的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;即使模型学习已经在许多地方得到成功应用，但该研究领域仍处于起步阶段。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Isberner24开发了一种用于可视下推自动机（VPA）的模型学习算法，该算法是 Alur 和 Madhusudan 提出的一种限制类型的下推自动机。5 这个结果在某种意义上与学习寄存器自动机上的结果正交：使用寄存器自动机学习，可以学习具有存储来自无限域的、带有有限容量存储值的堆栈，而使用 VPA 学习可以学习具有无限容量的堆栈，其存储来自有限域的数据值。从实践角度来看，开发一种通用于寄存器自动机和 VPA 这一类模型的学习算法将是有用的。许多协议中的消息可以缓冲，因此我们需要能够学习具有无限容量的队列的算法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;超越 Mealy 机。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;在 Mealy 机中，单个输入始终触发单个输出。然而，在实践中，系统可以用零个或多个输出来响应输入。此外，系统的行为通常是时序相关的，并且某个输出可能仅在某些输入未能在一定量的时间内得到时才发生。因此，模型学习的实际应用经常严重受限于 Mealy 机缺乏表达性。例如，为了将 TCP 实现为 Mealy 机，我们必须消除基于时序的行为以及重传（retransmissions）。17 &amp;nbsp;已经有一些初步的工作，将学习算法扩展到 I / O 自动机 4和事件记录自动机，18 但是仍然需要大量的工作将这些想法变成实际的工具。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由于一个输入序列可能导致在不同运行中会有不同的输出事件，因此从这种意义上来说，系统通常是非确定的。然而，现有的模型学习工具只能够学习确定性的 Mealy 机。在实际应用中，我们有时可以通过将不同的具体输出事件抽象为单个抽象输出以消除非确定性，但在许多情况下这是不可能的。Volpato 和 Tretmans 38 提出了一种*L **对非确定性 I / O 自动机的主动学习的调整方案。他们的算法能够学习非确定性 SUL，并且它允许我们构造部分或近似模型。同样，还需要进行大量工作以将这些想法纳入最先进的工具，如 LearnLib、libalf、RALib 或 Tomte。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;模型质量&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。由于模型学习算法生成的模型是通过有限数量的测试获得的，所以我们不能确保它们是正确的。然而，从实践的角度来看，我们希望能够对学习模型的质量进行定量说明，例如，断言假设高概率地近似正确。Angluin 6 &amp;nbsp;根据 Valiant 的 PAC 学习方法提出了这样的一种设定。她的想法是假设在输入字母表 I 上一组单词的一些（未知）概率分布。为了测试假设，一致性测试器（参见图 4）选择指定数量的输入词（这些是统计独立的事件），并检查每个词，无论 SUL 的输出结果是否和假设相一致。只有当完全一致时，一致性测试仪才会向 learner 返回答案&lt;em&gt; 'yes'&lt;/em&gt;。如果选择一个字符串所表现出来的差异的概率最多为&amp;epsilon;，则该假设被认为是 SUL 的&amp;epsilon;近似。给定 SUL 的状态数量的界限以及两个常数&amp;epsilon;和&amp;delta;，Angluin 的多项式算法产生模型，使得该模型是 SUL 的近似的概率为至少 1 -&amp;delta;。Angluin 的结果是优雅的，但在反应系统的设置中不现实，因为我们通常在输入词上没有固定的分布。（输入受 SUL 环境的控制，且此环境可能会发生改变。）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们使用传统一致性测试，可以设计出一个测试套件，该测试套件可在给定 SUL 状态数量上限的情况下保证学习模型的准确性。但是这种方法也不能令人满意，因为所需要的测试序列的数量会随着 SUL 的状态数量呈现指数型增长。因此，挑战在于如何在 Angluin 方法和传统的一致性测试之间建立一个折中。系统日志通常提供了一个输入词集合的概率分布，该输入词集合可被用来作为定义某个度量标准的启动点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;打开箱子。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;使用黑箱模型学习技术可以有很多原因。例如，我们可能想要了解组件的行为，但是不能访问代码。或者我们可以访问代码，但没有合适的工具来分析它（例如，在旧版软件的情况下）。即使在「白箱」情况下，我们可以访问代码并有强大的代码分析工具，黑箱学习也是有意义的，例如因为黑箱模型可以用于生成回归测试，用于检查是标准是否一致，或作为更大的基于模型开发的系统的一部分。一个重要的研究挑战是结合黑箱和白箱模型提取技术，例如，使用白盒方法，如静态分析和 concolic 测试，以帮助回答由黑箱 learner 提出的等价性查询。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;致谢。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;部分工作是在 STW 项目 11763（ITALIA）和 13859（SUMBAT）以及 NWO 项目 628.001.009（LEMMA）和 612.001.216（ALSEP）的背景下进行的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;参考文献：&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;1. Aarts, F., Fiterău-Broştean, P., Kuppens, H., Vaandrager, F. Learning register automata with fresh value generation. In ICTAC'15, LNCS 9399 (2015). Springer, 165&amp;ndash;183.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;2. Aarts, F., Jonsson, B., Uijen, J., Vaandrager, F. Generating models of infinite-state communication protocols using regular inference with abstraction. Formal Methods Syst. Des. 46, 1 (2015), 1&amp;ndash;41.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;3. Aarts, F., de Ruiter, J., Poll, E. Formal models of bank cards for free. In SECTEST'13 (2013). IEEE, 461&amp;ndash;468.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;4. Aarts, F., Vaandrager, F. Learning I/O automata. In CONCUR'10, LNCS 6269 (2010). Springer, 71&amp;ndash;85.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;5. Alur, R., Madhusudan, P. Visibly pushdown languages. In STOC'04 (2004). ACM, 202&amp;ndash;211.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;6. Angluin, D. Learning regular sets from queries and counterexamples. Inf. Comput. 75, 2 (1987), 87&amp;ndash;106.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;7. Bennett, K. Legacy systems: coping with success. IEEE Softw. 12, 1 (1995), 19&amp;ndash;23.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;8. Berg, T., Grinchtein, O., Jonsson, B., Leucker, M., Raffelt, H., Steffen, B. On the correspondence between conformance testing and regular inference. In FASE'05, LNCS 3442 (2005). Springer, 175&amp;ndash;189.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;9. Bollig, B., Katoen, J.-P., Kern, C., Leucker, M., Neider, D., Piegdon, D. libalf: The automata learning framework. In CAV'10, LNCS 6174 (2010). Springer, 360&amp;ndash;364.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;10. Cassel, S., Howar, F., Jonsson, B. RALib: A LearnLib extension for inferring EFSMs. In DIFTS 15 (2015).&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;11. Cassel, S., Howar, F., Jonsson, B., Merten, M., Steffen, B. A succinct canonical register automaton model. J. Log. Algebr. Meth. Program. 84, 1 (2015), 54&amp;ndash;66.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;12. Cassel, S., Howar, F., Jonsson, B., Steffen, B. Active learning for extended finite state machines. Formal Asp. Comput. 28, 2 (2016), 233&amp;ndash;263.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;13. Chalupar, G., Peherstorfer, S., Poll, E., Ruiter, J. Automated reverse engineering using Lego. In WOOT'14 (Aug. 2014). IEEE Computer Society.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;14. Cho, C., Babic, D., Shin, E., Song, D. Inference and analysis of formal models of botnet command and control protocols. In CCS'10 (2010). ACM, 426&amp;ndash;439.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;15. Clarke, E., Grumberg, O., Peled, D. Model Checking. MIT Press, Cambridge, MA, 1999.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;16. Feng, L., Lundmark, S., Meinke, K., Niu, F., Sindhu, M., Wong, P. Case studies in learning-based testing. In ICTSS'13, LNCS 8254 (2013). Springer, 164&amp;ndash;179.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;17. Fiterău-Broştean, P., Janssen, R., Vaandrager, F. Combining model learning and model checking to analyze TCP implementations. In CAV'16, LNCS 9780 (2016). Springer, 454&amp;ndash;471.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;18. Grinchtein, O., Jonsson, B., Leucker, M. Learning of event-recording automata. Theor. Comput. Sci. 411, 47 (2010), 4029&amp;ndash;4054.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;19. Groce, A., Peled, D., Yannakakis, M. Adaptive model checking. Logic J. IGPL 14, 5 (2006), 729&amp;ndash;744.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;20. Hagerer, A., Hungar, H., Niese, O., Steffen, B. Model generation by moderated regular extrapolation. In FASE'02, LNCS 2306 (2002). Springer, 80&amp;ndash;95.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;21. Henrix, M. Performance improvement in automata learning. Master thesis, Radboud University (2015).&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;22. Hungar, H., Niese, O., Steffen, B. Domain-specific optimization in automata learning. In CAV 2003, LNCS 2725 (2003). Springer, 315&amp;ndash;327.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;23. de la Higuera, C. Grammatical Inference: Learning Automata and Grammars. Cambridge University Press, 2010.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;24. Isberner, M. Foundations of active automata learning: An algorithmic perspective. PhD thesis, Technical University of Dortmund (2015).&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;25. Isberner, M., Howar, F., Steffen, B. The TTT algorithm: A redundancy-free approach to active automata learning. In RV'14, LNCS 8734 (2014). Springer, 307&amp;ndash;322.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;26. Isberner, M., Howar, F., Steffen, B. The open-source LearnLib - A framework for active automata learning. In CAV'15, LNCS 9206 (2015). Springer, 487&amp;ndash;495.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;27. Jhala, R., Majumdar, R. Software model checking. ACM Comput. Surv. 41, 4 (Oct. 2009), 21:1&amp;ndash;21:54.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;28. Kearns, M.J., Vazirani, U.V. An Introduction to Computational Learning Theory. MIT Press, 1994.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;29. Lee, D., Yannakakis, M. Principles and methods of testing finite state machines&amp;mdash;A survey. Proc. IEEE 84, 8 (1996), 1090&amp;ndash;1123.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;30. Margaria, T., Niese, O., Raffelt, H., Steffen, B. Efficient test-based model generation for legacy reactive systems. In HLDVT'04 (2004). IEEE Computer Society, 95&amp;ndash;100.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;31. Moore, E. Gedanken-experiments on sequential machines. In Automata Studies, Annals of Mathematics Studies 34 (1956). Princeton University Press, 129&amp;ndash;153.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;32. Peled, D., Vardi, M., Yannakakis, M. Black box checking. J. Autom. Lang. Comb. 7, 2 (2002), 225&amp;ndash;246.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;33. Rivest, R.L., Schapire, R.E. Inference of finite automata using homing sequences. Inf. Comput. 103, 2 (1993), 299&amp;ndash;347.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;34. de Ruiter, J., Poll, E. Protocol state fuzzing of TLS implementations. In USENIX Security'15 (2015). USENIX Association, 193&amp;ndash;206.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;35. Schuts, M., Hooman, J., Vaandrager, F. Refactoring of legacy software using model learning and equivalence checking: an industrial experience report. In iFM'16, LNCS 9681 (2016). Springer, 311&amp;ndash;325.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;36. Shahbaz, M., Groz, R. Analysis and testing of black-box component-based systems by inferring partial models. Softw. Test. Verif. Reliab. 24, 4 (2014), 253&amp;ndash;288.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;37. Valiant, L.G. A theory of the learnable. In STOC'84 (1984). ACM, 436&amp;ndash;445.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;38. Volpato, M., Tretmans, J. Approximate active learning of nondeterministic input output transition systems. Electron. Commun. EASST 72 (2015).&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;39. Windm&amp;uuml;ller, S., Neubauer, J., Steffen, B., Howar, F., Bauer, O. Active continuous quality control. In CBSE'13 (2013). ACM, 111&amp;ndash;120.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br&gt;原文链接：http://cacm.acm.org/magazines/2017/2/212445-model-learning/fulltext#F7&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Sun, 19 Feb 2017 12:19:19 +0800</pubDate>
    </item>
    <item>
      <title>深度 | 机器学习很有趣Part6：怎样使用深度学习进行语音识别</title>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650723383&amp;idx=2&amp;sn=4e013da4bf6d30cedb1020cc299d87ea&amp;chksm=871b1049b06c995f8e6cbdfacd22b098e37a7957a07db876fbd1ddeb30bfd8497b8e1fba4d3d&amp;scene=0#rd</link>
      <description>
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自Medium&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Adam Geitgey&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：邵明&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;还记得machine learning is fun吗？本文是该系列文章的第六部分，博主通俗细致地讲解了神经网络语音识别的整个过程， 是篇非常不错的入门级文章。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;语音识别正闯入我们的生活。它内置于我们的手机、游戏机和智能手表。它甚至正在让我们的家庭变得自动化。只需要 50 美元，你就可以买到亚马逊的 Echo Dot&amp;mdash;&amp;mdash;一个能允许你订购比萨饼，获得天气报告，甚至购买垃圾袋的魔法盒&amp;mdash;&amp;mdash;只要你大声说：「Alexa，订购一个大披萨！」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/ab0cdf534867bcd6e2fbbfdd09cc00bfa8266027"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Alexa, order a large pizza!&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Echo Dot 在这个假期很受欢迎，亚马逊似乎没有 Echo Dot 的库存了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;语音识别已经存在数十年了，但是为什么现在才刚刚开始成为主流呢？原因是深度学习让语音识别足够准确，能够让语音识别在需要精心控制的环境之外中使用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;吴恩达早就预测，当语音识别的准确率从 95％达到 99％时，语音识别将成为人与计算机交互的主要方式。4％的准确性差距就相当于「难以容忍的不可靠」到「令人难以置信的有用性」之间的差异。由于有深度学习，我们正在走向顶峰。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;让我们学习怎样利用深度学习进行语音识别！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;机器学习并不总是黑箱&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你知道神经网络机器翻译怎样工作，你可能会猜到：我们可以简单地将声音录音输入神经网络，然后训练神经网络来生成文本：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/37157aa7103c398b2bddda58a3719fcafec52a4c"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是用深度学习进行语音识别的核心，但我们还没有完全做到（至少在我写这篇文章的时候没做到&amp;mdash;&amp;mdash;我打赌，在未来的几年我们可以做到）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最大的问题是语音会随着速度变化。一个人可能很快地说出「Hello！」，而另外一个人可能会很缓慢说「heeeelllllllllllllooooo!」。这就产生了一个更长的声音文件和更多的数据。这两个声音文件本应该被识别为完全相同的文本「hello！」而事实证明，把各种长度的音频文件自动对齐到一个固定长度的文本是很难的一件事情。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了解决这个问题，我们必须使用一些特殊的技巧和一些除了深度神经网络以外的额外处理。让我们看看它是如何工作的吧！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;将声音转换成「字节」&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;语音识别的第一步是很显而易见的&amp;mdash;&amp;mdash;我们需要将声波输入到计算机。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在第 3 章中（https://medium.com/@ageitgey/machine-learning-is-fun-part-3-deep-learning-and-convolutional-neural-networks-f40359318721#.tvzicp8bh），我们学习了如何把图像处理成数字序列，以便我们能直接将其输入进神经网络进行图像识别：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/48c812da665dea547eb405b0f6e3193aac8a3ed5"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图像仅是图片中每个像素值的数字编码数组&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;声音以波的形式传播。我们怎样将声波转换成数字呢？让我们使用我说的「hello」这个声音片段作为例子：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/e045cd4bfb3fb17d8ee10fea717978a677abbd7f"/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;音频「Hello」的波形&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;声波是一维的。在每个时刻，它有单一的高度值对应。让我们放大声波的一个小部分，看看：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/ae8ef99057e156f1a67ee7c9065572d340610423"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了将这个声波转换成数值，我们只记录波在等间隔点的高度值：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/2b9367fb15a6c9a6d3fc6941bcca500f872ee018"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;声波采样&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这被称为「采样」。我们采取每秒读取数千次的方式，并把声波在对应时刻的高度值记录下来。这基本上是一个未被压缩的.wav 音频文件。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「CD 音质」以 44.1kHZ（每秒读取 44100 次）进行采样。但是对于语音识别，16kHz 的采样频率足以覆盖人类语言的频率范围。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;让我们用 16kHz 的方式对「Hello」音频采样，这是前 100 个样本：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/63911371fa6b1d0c34ec63dd130f114fd3e93839"/&gt;&lt;/p&gt;&lt;p&gt;&lt;em style="color: rgb(136, 136, 136); font-size: 12px; text-align: center;"&gt;每个数字代表声波在第 1/16000 间隔处时刻的高度值。&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;数字采样快速入门助手&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你可能会认为：采样只是对原始声波的粗略近似，因为它只是间歇性读取数据，我们的读数之间有差距，所以我们丢失了数据，对吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/4f3e35c21efa7aff56b21bfc0a79c68a1366f4b9"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数字采样能否完美重现原始声波？如何处理那些间距？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;借鉴奈奎斯特定理 (Nyquist theorem)，我们可以利用数学从间隔的采样中完美地重建原始声波&amp;mdash;&amp;mdash;只要以我们希望得到的最高频率的两倍来进行采样就可以实现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我提到这一点，是因为几乎每个人都会犯这个错误：认为使用更高的采样率总是能获得更好的音频质量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;采样声音数据的预处理&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们现在有一个数值数组，每个数值代表声波在间隔为 1 / 16,000 秒的时刻时的高度值（振幅）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们可以将这些数值输入神经网络。但是试图通过直接处理这些样本来识别语音模式是困难的。相反，我们可以通过对音频数据预处理来简化问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;让我们将采样的音频以 20 毫秒时间段长进行分组。这是我们第一个 20 毫秒的样本音频，即我们的前 320 个样本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/3cb44a53d08b41d88c0b834d8598d87d95d96eb0"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;将这些数值绘制为简单的线图，给出了对于 20 毫秒时间段的原始声波的粗略近似：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/5c9945f4423a5d95df7f0def17b2fd820fc62441"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然这段录音只有 1/50 秒的时长，但即使这样短暂的时长也包含不同频率的声音。有低音、中音，甚至高音混在一起。但总的来说，这些不同频率的声音混合在一起构成了人类复杂的语音。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了使这些数据更容易进行神经网络处理，我们将这复杂的声波分成不同部分。我们将一步步分离低音部分，下一个最低音部分，以此类推。然后通过将每个频带（从低到高）中的能量相加，我们就为各个类别（音调）的音频片段创建了一个指纹。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;想象你有一段某人在钢琴上弹奏 C 大调的音频。这段音频是由三个音符组合而成的 - C，E 和 G &amp;ndash; 他们混合在一起组成一个复杂的音频。我们想把这个复杂的音频分解成单独的音符：C，E 和 G。这和我们语音识别的想法一样。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们可以使用数学中的傅里叶变换来完成。傅里叶变换将复杂的声波分解成简单的声波，一旦我们得到了这些简单声波，我们将每一个声波包含的能量加在一起。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最终结果是从低音（即低音音符）到高音，每个频率范围的重要程度。下面的每个数字表示在我们的 20 毫秒音频剪辑中每个 50Hz 频带中的能量：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/58652dc023e40c8002c3270368bb6d97e57e416c"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;表中的每个数值表示每个 50Hz 频带中的能量&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当你把它以图表形式画出，你更容易看出：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/bd62d8b5a3e1a251f4613c64639d3cf2e7b968c8"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你可以看出，我们的 20 毫秒的声音片段中有很多低频能量，高频能量较少。这是典型的「男性」的声音。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果我们以每 20 毫秒的音频块重复这个过程，我们最终会得到一个频谱图（每一列从左到右都是一个 20 毫秒的块）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/8c12fca7e1b7c5823c9263f61f554fdee654615b"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;「hello」声音片段的完整频谱图&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;频谱图很棒，因为你可以从音频数据中看到音符和其他音高模式。相比于原始声波，神经网络可以更加容易地从这种数据中找到规律。因此，这（频谱图）就是我们将实际输入到神经网络的数据表征方式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;从短声音中识别字符&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有了易于处理音频形式，我们将把它输入到深度神经网络。神经网络的输入是 20 毫秒的音频块，对于每个小的音频切片，神经网络都会试图找出与声音对应的字母。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/8046c2dc0832e3e93cb4ac632825f72d914866c9"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们将使用循环神经网络&amp;mdash;&amp;mdash;即是具有能影响未来预测的记忆的神经网络。因为它预测的每个字母都将影响它对下一个字母的预测。例如，如果我们已经说出「HEL」，那么接下来我们很可能说出「LO」以说出「Hello」。我们不太可能会说像「XYZ」这种根本无法发音的词。因此，具有先前预测的记忆将有助于神经网络对未来进行更准确的预测。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当我们在神经网络上运行我们的整个音频剪辑（一次一块）后，我们最终将得到与每个音频块最可能对应的字符的一个映射。这是一个看起来像是我说」Hello」时的映射：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/e2bae96e0e8aa701363b0f6f64147ab8452ca5e3"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们的神经网络可能预测到我说的是「HHHEE_LL_LLLOOO」，也可能是「HHHUU_LL_LLLOOO」或甚至「AAAUU_LL_LLLOOO」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们用几个步骤来整理输出结果。首先，我们会用单个字符替换重复的的字符：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;HHHEE_LL_LLLOOO becomes HE_L_LO&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;HHHUU_LL_LLLOOO becomes HU_L_LO&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;AAAUU_LL_LLLOOO becomes AU_L_LO&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然后，我们将移除所有空白&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;HE_L_LO 变成 HELLO&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;HU_L_LO 变成 HULLO&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;AU_L_LO 变成 AULLO&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这让我们得到三种可能的转录 -「Hello」，「Hullo」和「Aullo」。如果你大声说出这些单词，这些转录的声音都类似于「Hello」。因为它每次只预测一个字符，神经网络会得出一些试探性的转录。例如，如果你说「He would not go」，它可能会给一个可能转录「He wud net go」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;技巧是将这些基于发音的预测与基于书写文本（书籍，新闻文章等）的大数据库的似然分数相结合。你抛出看起来最不可能是真的的转录，并保持转录看起来最现实。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在我们可能的转录「Hello」、「Hullo」和「Aullo」中，显然「Hello」在文本数据库中更频繁地出现（更不用说在我们原始的基于音频的训练数据中），因此可能是正确的。所以我们选择「Hello」作为我们的最后的转录。这就完成了！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;等一下！&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是如果有人说「Hullo」那又怎么样？「Hullo」是一个有效的词。也许「Hello」是错误的转录！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/ce206795bfab410a7e668ad6c9e84e456ce7ab01"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然实际上可能有人说的是「Hullo」而不是「Hello」。但是这样的语音识别系统（基于美式英语训练）基本上不会将「Hullo」作为转录。相比」Hello「，用户不太可能说「Hullo」，即是你在说」Hullo「ullo，它也总是会认为你在说「Hello」，无论你发「U」的声音有多重。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;试试看！如果你的手机设置为美式英语，尝试让你的手机的数字助理识别「Hullo」。你不能达到目标！它会拒绝！它总是会理解为「Hello」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不识别「Hullo」是合理的，但有时你会发现令人讨厌的情况:你的手机就是不能理解你说的语句。这就是为什么这些语音识别模型总需要更多的数据训练来处理这些少数情况。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;我能建立自己的语音识别系统吗？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器学习最酷的事情之一就是它有时看起来十分简单。你得到一堆数据，将把它输入到机器学习算法当中去，然后就能神奇的得到一个运行在你的游戏笔记本电脑显卡上的世界级人工智能系统... 对吧？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有些情况下的确是这样，但是语音识别却并不如此简单。语音识别是一个难题，你必须克服无限的挑战：质量差的麦克风、背景噪声、混响和回声、口音变化等等。这些问题都需要呈现在你的训练数据中，以确保神经网络可以处理它们。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;还有另一个例子：你知道当你在一个大房间里说话时，你会不自觉地提高你的音调以便掩盖噪音吗？人类在什么情况下都可以理解你，但神经网络需要特殊训练来处理这些情况。所以你需要得到人们在噪音中大声说话的训练数据！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;要构建一个达到 Siri、Google Now！或 Alexa 等水平的语音识别系统，你需要得到大量的训练数据，如果没有雇佣成百上千的人为你记录数据，你很难做到。用户对低质量语音识别系统的容忍度很低，因此你不能吝啬语音数据。没有人想要一个只有 80% 的时间有效的语音识别系统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;像谷歌或亚马逊这样的公司，现实生活中记录的成千上万小时的口语音频，对他们来说就是「黄金」。这就是将他们世界级语音识别系统与你自己的系统拉开差距的法宝。在手机上免费使用 Google Now! 和 Siri 或是不收取转录费且售价 50 美元的 Alexa，都是为了让你尽可能地使用它们。你说的每句话都将被这些系统所记录，然后这些数据将被用于训练未来的语音识别算法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不相信我？如果你有一部安装了 Google Now！的安卓手机，点击这里去收听你对它说过的每一句话：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/268e4de2196b29148322fc655ddd91263ce46629"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你可以通过 Alexa 在亚马逊上找到相同的东西。然而不幸的是，苹果手机并不允许你利用你的 Siri 语音数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以，如果你正在寻找创业的想法，我不建议你建立自己的语音识别系统与 Google 竞争。相反，你应该找到一种能让人们将他们几个小时的录音给予你的方法。这种数据可以是你的产品。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;学习更多&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个被用来处理不同长度音频的算法被称为 Connectionist Temporal Classification（CTC）。你可以阅读来自 2006 年的原始文章：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;http://www.cs.toronto.edu/~graves/icml_2006.pdf。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;百度的 Adam Coates 在湾区深度学习学校做了关于「用深度学习做语音识别」的精彩演讲。你可以在 YouTube 上观看这段视频（https://youtu.be/9dXiAecyJrY?t=13874，他的演讲从 3 分 51 秒开始）。强烈推荐。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文链接：https://medium.com/@ageitgey/machine-learning-is-fun-part-6-how-to-do-speech-recognition-with-deep-learning-28293c162f7a#.34p9sntcc&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Sun, 19 Feb 2017 12:19:19 +0800</pubDate>
    </item>
    <item>
      <title>学界 | iPOP：首个基于个性化大数据的个性化医学研究</title>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650723383&amp;idx=3&amp;sn=5edcae5ed03be548d3ec1e0540992b6c&amp;chksm=871b1049b06c995f7dede3225969c851609a5c188dc0c440df194771f857727a3bfb731389fd&amp;scene=0#rd</link>
      <description>
&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Genome Hunter&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：王灏、李亚洲、李泽南&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;该研究是关于 Mike Snyder 教授的「整合性个人组学图谱」（integrative personal omics profile，iPOP）；Mike Snyder 教授是该论文的通讯作者，也是斯坦福大学遗传学系主任。这是首项针对个人的健康与疾病状态进行的大规模 iPOP 研究。该论文于 2012 年发表在 Cell 上。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/1804ea9e90c9c0e4bce9aa8feb5e5f0638cf922b"/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;背景&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在基因组的层面上，我们与我们的邻居或者朋友具有 99.9% 的相似性。但正是这 0.1% 的不同，让我们每个人都与众不同。这些微小的遗传变异对于我们的健康具有巨大的影响。因此，疾病的发生过程和我们对于治疗的反应都与我们的基因组序列紧密相关。除了我们的基因组，人与人之间的差异也体现在 RNA、蛋白质和代谢产物的层面上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;长时间段的 iPOP 数据的收集&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过在 14 个月中持续收集 Snyder 教授的血液组分，将来自基因组、转录组、蛋白质组、代谢物组、抗体的图谱的结合起来，最终形成了 iPOP 数据集（图 1）。研究者使用了多种技术（包括全基因组测序、RNA 序列、人类细胞因子检测和质谱分析）来生成这一巨大的数据集（其包含采集自 20 多个时间点，总共超过 30 亿个数据点）。简单来说，基因组图谱提供了个体的基因组序列和种系变异。此外，转录组、蛋白质组、代谢物组和抗体图谱使得人们可以观测到个体在一段时间内基因表达趋势的动态变化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/0b55a9274a8508de6ce62f5f9d005fb1020d8543"/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;图 1. iPOP 的实验流程和数据分析方法。PBMC：外周血单核细胞（peripheral blood mononuclear cell）。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在该研究过程中，Snyder 教授受到了两次病毒性感染：（1）第一次是开始于第 0 天的人鼻病毒（human rhinovirus，HRV）感染；（2）第二次是开始于第 289 天的呼吸道合胞病毒（respiratory syncytial virus，RSV）感染。它为研究者提供了在病毒感染的反应期间研究基因表达动态变化的绝佳机会。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;iPOP 预测与疾病和药物相关的变异&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此前的数十年研究已经鉴定了众多与疾病和药物使用相关的遗传变异（即生物标志物）。因此，研究者首先分析了与疾病和药物应答有关的遗传变异。他们发现 Synder 教授的基因组序列包含多种与疾病相关的罕见变异，包括 2 型糖尿病以及一些与药物应答有关的变异（图 2）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/183c164da754f446e22e9544c75c981649024233"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 2. 一些重要的与疾病和药物相关的遗传变异示例&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;用 iPOP 监测糖尿病风险并帮助治疗&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在此项研究之前，Snyder 教授并没有与糖尿病相关的已知风险因素，并且从实验一开始时血糖水平是正常的。如上所述，Snyder 在研究过程中受到了 RSV 感染（从第 289 天开始）。显而易见，体内免疫反应激活了。令人意外的是，在其身体对病毒产生应答的同时，胰岛素信号通路表达水平下降，并且血糖水平同时升高，这是开始罹患糖尿病的标志（图 3）。在 RSV 感染后长达数月（第 301 天后），血糖水平持续处于高位。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/05094f8ea09d0a5312dc8a4b1cb990c3880bb98b"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;图 3. 本研究中的血糖水平趋势。有两次病毒感染：从第 0 天开始的 HRV 感染（红色箭头），以及从第 289 天开始的 RSV 感染（绿色箭头）&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Snyder教授在改变饮食和运动后，监测显示血糖水平呈逐渐下降的趋势。 这些结果表明，基因组序列可用于预估健康个体的患病风险，并且疾病的生物标志物（本文中的血糖）可用于监测和检测该疾病的治疗情况。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;整合性组学分析提供更多的生物医学信息&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了进一步利用转录组和基因组数据，作者对每个时间点的转录组、蛋白质组和代谢组学数据进行了整合分析，观察它们与不同生理状态的相关性（图 4）。特别地，他们着眼于系统地寻找随时间变化的相关模式。为了处理时间序列中的数据异质性和缺失数据，他们使用了一种傅立叶谱分析方法（Lomb-Scargle 变换）来为每个时间序列曲线构建周期图。Lomb-Scargle 方法已被成功应用于天文学中以处理非均匀采样的时间序列数据，也被用于多种形式的生物学问题上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/eb7a45bd4c88219972ed2b0efa53f6eaf83654fc"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 4. 转录组、蛋白质组和代谢组数据的整合分析。数据点被聚类以鉴定疾病相关的生物学通路&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该数据集的整合分析证实了之前的发现。它表明，在感染 RSV 后的发病以及后续的应答过程中，机体产生了一个全身性的反应，包括在 RSV 感染后第 18 天有一个明显的应答。在随后的时间点中，多种与感染或者应激应答有关的生物学通路，以及与高血糖水平有关的生物学通路均受到影响，其中包括包括胰岛素应答通路。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;结论&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;iPOP 提供了一个针对健康状态的多维视角，包括健康状况、对病毒的应答、疾病恢复以及糖尿病发病。总而言之，该研究证明利用基于 iPOP 的方法是有助于实现个性化医学的：从基因组序列鉴定疾病风险，并且通过其他分子组分指标监测疾病状态。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过多种高通量技术将基因组信息与检测生理状态的常规方法结合起来，将有助于个性化医学的实现。从这项研究产生的丰富数据将是个性化医学发展领域的宝贵资源。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，该论文的作者创建了一个网站，以方便人们使用 iPOP 资源（http://snyderome.stanford.edu）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/c09d7855ed7ae47b50550defdd6340cf07d6f9af"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 5. 提供 iPOP 数据和结果的网站&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&amp;copy;本文为机器之心原创，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Sun, 19 Feb 2017 12:19:19 +0800</pubDate>
    </item>
    <item>
      <title>资源 | 5 个Python 库，照亮你的机器学习之路</title>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650723383&amp;idx=4&amp;sn=46167955885a52878e2000bc157b8478&amp;chksm=871b1049b06c995fedbde3ea18fb5a75c1365d58aa49e85c548524097963cdfa598a92a97d82&amp;scene=0#rd</link>
      <description>
&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自Infoworld&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Serdar Yegulalp&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：黄小天、李亚洲、微胖&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;这些 Python 库帮助你加速数据传输，通过 AWS Lambda 对大型计算工作做碎片化处理，并使用略低于 TensorFlow 的模型工作。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器学习令人兴奋，但具体工作复杂而困难。通常它涉及很多手动提升&amp;mdash;&amp;mdash;汇总工作流及传输渠道，设置数据源，以及在内部部署和云部署的资源之间来回分流。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;用来提高工作效率的手头工具越多越好。庆幸的是，Python 是一个威力巨大的工具语言，在大数据和机器学习之中被广泛使用。下面是 5 个 Python 库，帮助你缓解来自交易提升的重负。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/47c2529a4976fde926318162fd181709da4bdc9f"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;PyWren&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：https://github.com/ericmjonas/pywren&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;PyWren，一个带有强大前提的简单包，能使你运行基于 Python 的科学计算工作量，以作为 AWS Lambda 函数的多个例子。项目 At The New Stack 的简介这样描述 PyWren: 把 AWS Lambda 用作一个巨大的平行处理系统，以处理那些可被切割成诸多小任务的项目，这些小任务的运行不需要占用很多内存或硬盘。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Lambda 函数的一个缺点是运行时间最长不能超过 300 秒。但是，如果你需要一个只花费几分钟就能完成的工作，并在数据集中需要运行数千次，那么 PyWren 也许是一个好选择，它可以一种用户硬件上不可用的规模平行化云端的工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌的 TensorFlow 框架正迈入伟大时刻，因为刚发布了 1.0。人们通常会问一个问题：如何利用在上面训练的模型而无需使用 TensorFlow 本身？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Tfdeploy&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：https://github.com/riga/tfdeploy&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Tfdeploy 可以部分解决这个问题。将训练过的 TensorFlow 模型输出「一个简单的基于 Numpy 的可调用对象（callable）」，也就是说，借由 Tfdeploy，可以在 Python 中使用模型，而且 Numpy 的数学和统计库被作为唯一的依靠。几乎所有能在 TensorFlow 上跑的运行也能在 Tfdeploy 上跑，而且你可以通过标准 Python 隐喻方式来延伸库的行为（比如，超载一个类别）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在，坏的消息是：Tf 部署并不支持 GPU 加速，要是 Numpy 能克服那一点该多好。Tfdeploy 的创造者建议 gNumPy 项目是一个可行的替代。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Luigi&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：https://github.com/spotify/luigi&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;编写成批作业通常只是处理海量数据的其中一步：你也不得不将所有这些工作串联起来，做成类似工作流程的东西。Luigi 是 Spotify 打造的，用于「解决所有通常与长期运行成批处理作业有关的管道问题。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有了 Luigi，研发人员就可以从事几个很难、与数据无关的任务处理&amp;mdash;&amp;mdash;「一个 Hive 询问，一个在 Jave 上完成的 Hadoop 任务，一个 Scala 上的 Spark 任务，一个从数据库中导出表格」&amp;mdash;&amp;mdash;创造一个端到端运行它们的工作流。对任务的整个描述以及依存性被打造为 Python 模块，和 XML 配置文档或其他数据形式不同，因此，可以被组合到其他以 Python 为中心的项目中去。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Kubelib&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：https://github.com/safarijv/kubelib&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你采用 Kubernetes 作为完成机器学习工作的编排系统（orchestration system），你最不想要的就是它产生的问题比能解决的问题都多。Kubelib 为 Kubernetes 提供了一系列的 Python 接口，本来是用 Jekins scripting 作为帮助。但没有 Jenkins 的情况下也能够使用，它能够完成 暴露在 kubectl CLI 或者 Kubernetes API 中的所有事。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722553&amp;amp;idx=1&amp;amp;sn=ce635e60fa8f1cc16982c5d6a9a6931b&amp;amp;chksm=871b1487b06c9d9180d7f881784e68d4b9785481c38aa86eccc183aed8254b2a452e073a0c9b&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722553&amp;amp;idx=1&amp;amp;sn=ce635e60fa8f1cc16982c5d6a9a6931b&amp;amp;chksm=871b1487b06c9d9180d7f881784e68d4b9785481c38aa86eccc183aed8254b2a452e073a0c9b&amp;amp;scene=21#wechat_redirect" target="_blank"&gt;&lt;strong&gt;&lt;span&gt;PyTorch&lt;/span&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：https://github.com/pytorch/pytorch&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不要忘记了最近发布的、引人注目的 Python 库新成员 Pytorch，这是 Torch 机器学习框架的一个工具。PyTorch 不仅为 Torch 添加了 Python 端口，也增加了许多其他的便利，比如 GPU 加速，共享内存完成多重处理（multiprocessing，特别是多核上隔离开的工作。) 最好的是，它们能为 Numpy 中的无加速功能提供 GPU 驱动的替代选择。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文链接：http://www.infoworld.com/article/3171654/artificial-intelligence/5-python-libraries-to-lighten-your-machine-learning-load.html&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Sun, 19 Feb 2017 12:19:19 +0800</pubDate>
    </item>
    <item>
      <title>一周论文 | 增强学习在Image Caption任务上的应用</title>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650723383&amp;idx=5&amp;sn=7e1137712b4dcbab846b025f37f02e7f&amp;chksm=871b1049b06c995fa3d2b528f705aaf851c120626d048603d1f3149cc0ad7a695b4b27f78315&amp;scene=0#rd</link>
      <description>
&lt;h1 style=" max-width: 100%; color: rgb(62, 62, 62) ; ; ; ; ; ; ; ; ; ; ; ; "&gt;&lt;span&gt;&lt;strong&gt;引言&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二十二期的PaperWeekly对Image Captioning进行了综述。今天这篇文章中，我们会介绍一些近期的工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Image Captioning的模型一般是encoder-decoder的模型。模型对$p(S|I)$进行建模，$S$是描述，$I$是图片。模型的训练目标是最大化log似然：$\max_\theta\sum_i \log P(S_i|I_i, \theta)$。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而使用最大似然训练有两个问题：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1、虽然训练时最大化后验概率，但是在评估时使用的测度则为BLEU，METEOR，ROUGE，CIDER等。这里有训练loss和评估方法不统一的问题。而且log似然可以认为对每个单词都给予一样的权重，然而实际上有些单词可能更重要一些（比如说一些表示内容的单词）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2、第二个问题为Exposure bias。训练的时候，每个时刻的输入都是来自于真实的caption。而生成的时候，每个时刻的输入来自于前一时刻的输出；所以一旦有一个单词生成的不好，错误可能会接着传递，使得生成的越来越糟糕。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如何解决这两个问题呢？很显而易见的想法就是尽量使得训练和评估时的情形一样。我们可以在训练的时候不优化log似然，而是直接最大化CIDER（或者BLEU，METEOR，ROUGE等）。并且，在训练时也和测试时一样使用前一时刻的输入，而不是全使用ground truth输入。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而这有什么难点呢？第一，CIDER或者这一些metric并不是可直接求导。（这就是为什么在分类问题中，我们把0-1 error近似成log loss，hinge loss的原因）。其次从前一时刻输出获得后一时刻的输入涉及到采样操作，这也是不可微的。为了能够解决这些不可微的问题，人们就想到了Reinforcement learning。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;h1 style=" max-width: 100%; color: rgb(62, 62, 62) ; ; ; ; ; ; ; ; ; ; ; ; "&gt;&lt;span&gt;&lt;strong&gt;RL基本概念&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;RL中有一些比较重要的基本概念：状态（state），行为（action），回报（reward）和决策（policy）。决策是一个状态到动作的函数，一般是需要学习的东西。拿打游戏的例子介绍RL最简单。如果说是玩flappy bird，RL要学习的就是在什么位置跳，能使得最后得到的分数越高。在这个例子里，最后的分数就是回报，位置就是状态，跳或者不跳就是行为，而什么时候跳就是学到的策略。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果放在Image captioning中，状态就是你看到的图片和已生成的单词，而动作就是下一个单词生成什么，回报就是CIDER等metric。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;h1 style=" max-width: 100%; color: rgb(62, 62, 62) ; ; ; ; ; ; ; ; ; ; ; ; "&gt;&lt;span&gt;&lt;strong&gt;相关文献&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最近已经有很多工作将RL用在NLP相关的问题上。[1]第一次将REINFORCE算法用在image caption和seq2seq问题上。[5]将使用了更先进的RL算法 &amp;mdash; Actor-critic &amp;mdash; 来做machine translation上。[2,4]将[1]的算法进行稍许改进（仍旧是REINFORCE算法），使用在了image captioning上。[3]将REINFORCE用在序列生成GAN中，解决了之前序列生成器输出为离散不可微的问题。[6]将RL用在自然对话系统中。这篇文章中我们主要介绍[1,2,4]。&lt;/span&gt;&lt;/p&gt;&lt;h1 style=" max-width: 100%; color: rgb(62, 62, 62) ; ; ; ; ; ; ; ; ; ; ; "&gt;&lt;br&gt;&lt;/h1&gt;&lt;h1 style=" max-width: 100%; color: rgb(62, 62, 62) ; ; ; ; ; ; ; ; ; ; ; ; "&gt;&lt;span&gt;&lt;strong&gt;RL算法背景&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这三篇文章使用的是REINFORCE算法，属于增强学习中Policy Gradient的一种。我们需要将deterministic的策略形式 $a=\pi(s,\theta)$转化为概率形式，$p(a) = \pi(a|s, \theta)$。Policy Gradient就是对参数$\theta$求梯度的方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;直观的想，如果我们希望最后的决策能获得更高的reward，最简单的就是使得高reward的行为有高概率，低reward的行为有低概率。所以REINFORCE的更新目标为&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;$$\max_{\theta} \sum R(a,s)\log \pi(a|s, \theta)$$&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;$R(s,a)$是回报函数。有了目标，我们可以通过随机梯度下降来更新$\theta$来获得更大的回报。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而这个方法有一个问题，训练时梯度的方差过大，导致训练不稳定。我们可以思考一下，如果reward的值为100到120之间，现在的方法虽然能更大地提高reward为120的行为的概率，但是也还是会提升低reward的行为的概率。所以为了克服这个问题，又有了REINFORCE with baseline。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;$$\max_{\theta} \sum (R(a,s) - b(s))\log \pi(a|s, \theta)$$&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;$b(s)$在这里就是baseline，目的是通过给回报一个基准来减少方差。假设还是100到120的回报，我们将baseline设为110，那么只有100回报的行为就会被降低概率，而120回报的行为则会被提升概率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;h1 style=" max-width: 100%; color: rgb(62, 62, 62) ; ; ; ; ; ; ; ; ; ; ; ; "&gt;&lt;span&gt;&lt;strong&gt;三篇paper&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一篇是FAIR在ICLR2016发表的[1]。这篇文章是第一个将RL的算法应用的离散序列生成的文章。文章中介绍了三种不同的方法，这里我们只看最后一种算法，Mixed Incremental Cross-Entropy Reinforce。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大体的想法就是用REINFORCE with baseline来希望直接优化BLEU4分数。具体训练的时候，他们先用最大似然方法做预训练，然后用REINFORCE finetune。在REINFORCE阶段，生成器不再使用任何ground truth信息，而是直接从RNN模型随机采样，最后获得采样的序列的BLEU4的分数r作为reward来更新整个序列生成器。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里他们使用baseline在每个时刻是不同的；是每个RNN隐变量的一个线性函数。这个线性函数也会在训练中更新。他们的系统最后能比一般的的cross extropy loss，和scheduled sampling等方法获得更好的结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他们在github开源了基于torch的代码，&lt;/span&gt;&lt;a rel="external" style="color: rgb(67, 149, 245); max-width: 100%; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important; text-decoration: underline;" target="_blank"&gt;&lt;span&gt;https://github.com/facebookresearch/MIXER&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二篇论文是今年CVPR的投稿。这篇文章在[1]的基础上改变了baseline的选取。他们并没有使用任何函数来对baseline进行建模，而是使用了greedy decoding的结果的回报作为baseline。他们声称这个baseline减小了梯度的variance。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个baseline理解起来也很简单：如果采样得到句子没有greedy decoding的结果好，那么降低这句话的概率，如果比greedy decoding还要好，则提高它的概率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个方法的好处在于避免了训练一个模型，并且这个baseline也极易获得。有一个很有意思的现象是，一旦使用了这样的训练方法，beam search和greedy decoding的结果就几乎一致了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前这篇文章的结果是COCO排行榜上第一名。他们使用CIDEr作为优化的reward，并且发现优化CIDEr能够使所有其他metric如BLEU，ROUGE，METEOR都能提高。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他们的附录中有一些captioning的结果。他们发现他们的模型在一些非寻常的图片上表现很好，比如说有一张手心里捧着一个长劲鹿的图。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第三篇论文[4]也是这次CVPR的投稿。这篇文章则是在$R(a,s)$这一项动了手脚。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;前两篇都有一个共同特点，对所有时刻的单词，他们的$R(a,s)$都是一样的。然而这篇文章则给每个时刻的提供了不同的回报。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其实这个动机很好理解。比如说，定冠词a，无论生成的句子质量如何，都很容易在句首出现。假设说在一次采样中，a在句首，且最后的获得回报减去baseline后为负，这时候a的概率也会因此被调低，但是实际上大多数情况a对最后结果的好坏并没有影响。所以这篇文章采用了在每个时刻用$Q(w_{1:t})$来代替了原来一样的$R$。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个$Q$的定义为，&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;$Q\theta(w{1:t}) = \mathbb{E}{w{t+1:T}}[R(w{1:t}, w{t+1:T})]$&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;也就是说，当前时刻的回报，为固定了前t个单词的期望回报。考虑a的例子，由于a作为句首生成的结果有好有坏，最后的Q值可能接近于baseline，所以a的概率也就不会被很大地更新。实际使用中，这个Q值可以通过rollout来估计：固定前t个词后，随机采样K个序列，取他们的平均回报作为Q值。文中K为3。这篇文章中的baseline则跟[1]中类似。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从实验结果上，第三篇并没有第二篇好，但是很大一部分原因是因为使用的模型和特征都比较老旧。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;h1 style=" max-width: 100%; color: rgb(62, 62, 62) ; ; ; ; ; ; ; ; ; ; ; ; "&gt;&lt;span&gt;&lt;strong&gt;总结&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;将RL用在序列生成上似乎是现在新的潮流。但是现在使用的大多数的RL方法还比较简单，比如本文中的REINFORCE算法可追溯到上个世纪。RL本身也是一个很火热的领域，所以可以预计会有更多的论文将二者有机地结合。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;h1 style=" max-width: 100%; color: rgb(62, 62, 62) ; ; ; ; ; ; ; ; ; ; ; ; "&gt;&lt;span&gt;&lt;strong&gt;参考文献&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;[1] Ranzato, Marc&amp;rsquo;Aurelio, Sumit Chopra, Michael Auli, and Wojciech Zaremba. &amp;ldquo;Sequence level training with recurrent neural networks.&amp;rdquo;&amp;nbsp;arXiv preprint arXiv:1511.06732&amp;nbsp;(2015).&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;[2] Rennie, Steven J., Etienne Marcheret, Youssef Mroueh, Jarret Ross, and Vaibhava Goel. &amp;ldquo;Self-critical Sequence Training for Image Captioning.&amp;rdquo;&amp;nbsp;arXiv preprint arXiv:1612.00563&amp;nbsp;(2016).&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;[3] Yu, Lantao, Weinan Zhang, Jun Wang, and Yong Yu. &amp;ldquo;Seqgan: sequence generative adversarial nets with policy gradient.&amp;rdquo;&amp;nbsp;arXiv preprint arXiv:1609.05473&amp;nbsp;(2016).&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;[4] Liu, Siqi, Zhenhai Zhu, Ning Ye, Sergio Guadarrama, and Kevin Murphy. &amp;ldquo;Optimization of image description metrics using policy gradient methods.&amp;rdquo;&amp;nbsp;arXiv preprint arXiv:1612.00370&amp;nbsp;(2016).&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;[5] Bahdanau, Dzmitry, Philemon Brakel, Kelvin Xu, Anirudh Goyal, Ryan Lowe, Joelle Pineau, Aaron Courville, and Yoshua Bengio. &amp;ldquo;An actor-critic algorithm for sequence prediction.&amp;rdquo;&amp;nbsp;arXiv preprint arXiv:1607.07086&amp;nbsp;(2016).&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;[6] Li, Jiwei, Will Monroe, Alan Ritter, Michel Galley, Jianfeng Gao, and Dan Jurafsky. &amp;ldquo;Deep reinforcement learning for dialogue generation.&amp;rdquo;&amp;nbsp;arXiv preprint arXiv:1606.01541&amp;nbsp;(2016).&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;h1 style=" max-width: 100%; color: rgb(62, 62, 62) ; ; ; ; ; ; ; ; ; ; ; ; "&gt;&lt;span&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;罗若天，&lt;/strong&gt;TTIC博士生 &amp;nbsp;研究方向&amp;nbsp;CV+NLP&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;博客&lt;/strong&gt;&lt;span&gt;：&lt;a style="color: rgb(67, 149, 245); max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;http://ruotianluo.github.io&lt;/a&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;专栏&lt;/strong&gt;&lt;span&gt;：&lt;a style="color: rgb(67, 149, 245); max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;https://zhuanlan.zhihu.com/c_73407294&lt;/a&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;github&lt;/strong&gt;&lt;span&gt;:&amp;nbsp;&lt;a style="color: rgb(67, 149, 245); max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;https://github.com/ruotianluo&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;关于PaperWeekly&lt;/span&gt;&lt;/strong&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;PaperWeekly是一个分享知识和交流学问的学术组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微信公众号：PaperWeekly&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/74e43d689e2973dc494ef5c2c85c981e72b56552"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微博账号：PaperWeekly（&lt;/span&gt;&lt;a rel="external" style="color: rgb(67, 149, 245); max-width: 100%; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important; text-decoration: underline;" target="_blank"&gt;&lt;span&gt;http://weibo.com/u/2678093863&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&amp;nbsp;）&lt;br&gt;微信交流群：微信+ zhangjun168305（请备注：加群交流或参与写paper note）&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;
</description>
      <pubDate>Sun, 19 Feb 2017 12:19:19 +0800</pubDate>
    </item>
    <item>
      <title>首届TensorFlow开发者大会：值得关注的亮点都在这里（附资源）</title>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650723351&amp;idx=1&amp;sn=c981581ad9b85bec4fffcb9a6a154e97&amp;chksm=871b1069b06c997f81fe23bf404dc414aa91f7d50f452626a42bb1330c4da70f17fe937644bb&amp;scene=0#rd</link>
      <description>
&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：吴攀、李亚洲、微胖&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当地时间 2 月 15 日，谷歌在加州山景城召开了第一届年度 TensorFlow 开发者大会（TensorFlow Developer Summit 2017），这可算得上是 TensorFlow 开发者、支持者与爱好者的第一次盛会，谷歌也在此次会议上发布了开发者期待已久的 &lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650723249&amp;amp;idx=1&amp;amp;sn=2503c119815d74f25703b252ee45f844&amp;amp;chksm=871b17cfb06c9ed9fc1c43f32750f9f4294c59514c174480ed3542722e621beca10d399505b4&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650723249&amp;amp;idx=1&amp;amp;sn=2503c119815d74f25703b252ee45f844&amp;amp;chksm=871b17cfb06c9ed9fc1c43f32750f9f4294c59514c174480ed3542722e621beca10d399505b4&amp;amp;scene=21#wechat_redirect" target="_blank"&gt;TensorFlow 1.0&lt;/a&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;经过一年多的发展，TensorFlow 得到了越来越多开发者的认可，也成为了 GitHub 上最受欢迎的框架之一。从发布以来，TensorFlow 一直在不断完善和增加新功能，比如分布式 TensorFlow、Windows 系统支持等，直到最近 TensorFlow 1.0 正式版的诞生。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/4290410650e327c5697de7caa3b0aa3c1007e32b"/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;图：TensorFlow 的版本更迭&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但除了这个我们早就已经预计到的重磅消息之外，这个首届 TensorFlow 开发者大会上还有什么值得开发者关注的亮点呢？机器之心在此根据本次大会上的演讲对会上值得关注的内容进行了梳理，并按框架对比、产品和应用、移动端与嵌入式 TensorFlow、资源分别进行了总结，希望能对 TensorFlow 开发者能有所帮助。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;框架对比&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自开源以来，TensorFlow 经过一年多的发展已经成为了 GitHub 上最流行的框架。如同 Jeff Dean 下图中演示那样，短短一年时间，TensorFlow 已经超越 scikit-learn、Caffe 等框架，已在 GitHub 获得了最多的 Star 量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/74344fd4d960cb5b4c579fc7ad937fae8d0c3931"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图注：有大量的人在为 TensorFlow 作出贡献，并用其进行各种有趣的尝试。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此外，Jeff Dean 在 Keynote 中介绍说，TensorFlow 现在已经支持 Python、C++、Java、R、Haskell、Go 在内的多种语言。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;框架之间的对比也成为了机器学习社区所关注的一个话题。之前机器之心编译的一篇文章中，数据科学公司 Silicon Valley Data Science 的数据工程师 Matt Rubashkin（UC Berkeley 博士）对深度学习的 7 种流行框架进行了横向对比，其中包括语言支持、速度、兼容 Keras 在内的 8 项衡量标准，结果如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/d5d2108468ddfa8ad82a37d5c610d1c749a599ff"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在本次开发者大会上，谷歌专门也设置了两场演讲凸显 TensorFlow 的优势：XLA 以及 Keras 与 TensorFlow 的融合。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;速度是高效的机器学习框架的一切。在这次大会中，Chris Leary 与 Todd Wang 讲解了通过 XLA（加速线性代数）方法减少训练和推断时间的方式。他们介绍了 TensorFlow 如何使用 XLA、JIT、AOT 以及其它编译技术来最小化执行时间和最大化计算资源。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/ff59a73920cd6b26cb3e34648a118b760ec50a38"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;兼容 Keras：Keras 是成长最快的深度学习框架之一。在此次大会上，Keras 的主要作者 Francois Chollet 用视频 QA 案例演示了如何在 TensorFlow 中使用 Keras。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/a224f0445867ec9418df65126597f9cc06ef18c2"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;产品与应用&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;经过一年飞速的发展，TensorFlow 也逐渐得到了业界的认可，许多企业、公司都在基于 TensorFlow 开发自己的产品或将 TensorFlow 整合到自己的产品中去。其中包括 Airbnb、Uber、Twitter、英特尔和高通等等，当然也还有去年宣布从 &lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715087&amp;amp;idx=3&amp;amp;sn=a736c842914fc58f4789219a85a66206&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715087&amp;amp;idx=3&amp;amp;sn=a736c842914fc58f4789219a85a66206&amp;amp;scene=21#wechat_redirect" target="_blank"&gt;Torch 转向 TensorFlow 的 DeepMind&lt;/a&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/38d5572e112bc29c46eecdab718a8212e487fb59"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而谷歌自己当然更是在产品开发上给予了 TensorFlow 所有可以提供的支持。据谷歌工程开发主管 Megan Kacholia 介绍，TensorFlow 目前已经在以下十几种产品中得到了应用，其中包括谷歌翻译、Google Play、YouTube 和 Gmail 等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/ad79489326b276d596c608afc5f14dd8c413ae3e"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌也不吝于分享自己在 TensorFlow 产品应用方面的经验。Google Research 的软件工程师 Jonathan Hseu 在一个演讲中介绍了 TensorFlow 生态系统（参考：&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720302&amp;amp;idx=4&amp;amp;sn=5a54ac9d2097f0db11d1da8a65cf2e4c&amp;amp;chksm=871b0c50b06c85466eb0bb5e455e306deca82662d83895f9d6ad2311539a9adf7056dac306ac&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720302&amp;amp;idx=4&amp;amp;sn=5a54ac9d2097f0db11d1da8a65cf2e4c&amp;amp;chksm=871b0c50b06c85466eb0bb5e455e306deca82662d83895f9d6ad2311539a9adf7056dac306ac&amp;amp;scene=21#wechat_redirect" target="_blank"&gt;《资源 | TensorFlow 生态系统：与多种开源框架的融合》&lt;/a&gt;），谈到了 TensorFlow 和产品基础设施的整合方式，并介绍了从数据准备到模型训练到产品应用整个过程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/a34a1601ab76550f3d0e8a3ec395b4f4bc10a5d2"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在数据准备阶段，主要处理过程是：从各个数据源获取数据&amp;rarr;执行预处理&amp;rarr;导出一个 TensorFLow 支持的文件格式。在这个阶段用的比较多的工具是 Apache Spark、Hadoop MapReduce 和 Apache Beam。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在模型训练阶段，可以选择本地训练（自己的本地机器或远程虚拟机）或分布式训练（速度更快，但需要合适的基础设施）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然后就是将训练好的模型导出投入到产品中，Hseu 在这里推荐了 TensorFlow Serving 和 In-Process TensorFlow。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而在这些阶段的语言支持上，Python 的支持当然是最好的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/15a87503d971714377c8e547f20563578af0336d"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;接下来，Google Research 的软件工程师 Noah Fiedel 就做了关于 TensorFlow Serving（serving 是指将训练好的模型应用到生产中的过程）的演讲。Fiedel 介绍说，serving 的目标是实现在线的、低延迟的应用，能将多个模型应用到单一一个流程中，可以随时间加载一个模型的多个版本，可以实时计算成本变化以满足产品需求（通过 CloudML、Docker &amp;amp; K8s 自动扩展），在训练时间通过 mini-batching 提高效率（除非有异步的要求）。而 TensorFlow Serving 就是一个专为生产环境设计的，用于机器学习模型的灵活高性能 serving 平台：https://tensorflow.github.io/serving&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/08680458459bd5f349ad8397d4946a2b715f067b"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;还在演讲后面介绍一种新技术 SavedModel，这是一种用于 TensorFlow 模型的通用的序列化格式（universal serialization format），已经包含在了 TensorFlow 1.0 中，其有两个重要功能：支持多个 MetaGraph（同时共享变量和 asset）和 SignatureDef。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/32192c4b29f74644193a70a4af2cb10ee116ba03"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中 SignatureDef 定义了由 TensorFlow graph 所支持的计算的签名。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/86fb3b71491f3c03792e2513da8e7cb4b152bccf"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此外还有 Multi-headed Inference 和 Sequence Models 技术：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/747f63a779c7b5509867c3e141ecc4303ce4b08b"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/ac4e820e73ba0178511310da3216b8e0299ac67c"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;分布式 TensorFlow 也是一个值得关注的亮点，Google Research 的软件工程师 Derek Murray 带来了一个自底向上的关于分布式 TensorFlow 的介绍，并展示了所有可以用来利用这种力量的工具。我们为什么要使用分布式 TensorFlow 呢？随着技术和方法的不断发展，深度学习系统的规模也变得越来越大，对计算资源的要求也随之增长。为了应对这个问题，我们可以将计算分配给不同的 GPU 集群而并行地进行计算，从而减少计算时间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/c1df8d66a3166b54b0ec2c9b44eae18831f0fef1"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们需要分布式 TensorFlow 的情况是模型非常大的时候，比如谷歌的「&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716578&amp;amp;idx=1&amp;amp;sn=aae84df4e4e218afcd9f2d7cc88c96eb&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716578&amp;amp;idx=1&amp;amp;sn=aae84df4e4e218afcd9f2d7cc88c96eb&amp;amp;scene=21#wechat_redirect" target="_blank"&gt;宽度&amp;amp;深度&lt;/a&gt;」模型 和超大规模模型，现有的单个硬件可能无法将它装进去进行计算。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/d53b02dfa4799951c731ddc30911f763128219fb"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/d78747c6089d71e1572df2df8a6eb60642316e61"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;超大规模有多达 680 亿个参数&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在具体的应用方面，Google Research 的软件工程师 Heng-Tze Cheng 介绍了用 TensorFlow 实现「宽度&amp;amp;深度学习」&amp;mdash;&amp;mdash;将记忆（memorization）和归纳（generalization）结合到一起。参阅《&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716578&amp;amp;idx=1&amp;amp;sn=aae84df4e4e218afcd9f2d7cc88c96eb&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716578&amp;amp;idx=1&amp;amp;sn=aae84df4e4e218afcd9f2d7cc88c96eb&amp;amp;scene=21#wechat_redirect" target="_blank"&gt;深度 | 谷歌新开源「宽度&amp;amp;深度学习」框架：结合记忆和归纳实现更优推荐 &lt;/a&gt;》，该网络已经在 Google Play 上得到了应用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/d74eac2a8e781f6ca45e155b385aa205248e3a66"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;TensorFlow 的高级 API，你需要 10 行代码就能实现一个这种类型的网络模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/25f3edc6836de6a9ffc0a765da7fb92a26b28a3c"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Google Research 的产品经理 Lily Peng 以视网膜成像为例介绍了 TensorFlow 在医疗领域的应用。机器之心之前已经有过介绍了《&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720846&amp;amp;idx=1&amp;amp;sn=2f98ec55be6e608ab7b69bae31a8ed23&amp;amp;chksm=871b0e30b06c872680991cbe6441617c36c9e500486decb1603426f918212f7f31fc7ed19737&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720846&amp;amp;idx=1&amp;amp;sn=2f98ec55be6e608ab7b69bae31a8ed23&amp;amp;chksm=871b0e30b06c872680991cbe6441617c36c9e500486decb1603426f918212f7f31fc7ed19737&amp;amp;scene=21#wechat_redirect" target="_blank"&gt;重磅 | 谷歌研发人工智能眼科医生：用深度学习诊断预防失明&lt;/a&gt;》。在谈到 TensorFlow 所发挥的作用时，Peng 介绍说 TensorFlow 的优点包括：快速的原型构建、支持大规模实验并且可以根据实际的应用所收集到的数据和标签重新训练模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/d535b38df46b5c6dd2ae39f039774c072ee0050c"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此外，不久之前得以上 Nature 封面的癌症方面的研究也应用到了 TensorFlow。斯坦福大学的研究人员训练了一个可以诊断皮肤癌的算法。在论文中，他们展示了使用一个单一的深度卷积神经网络进行皮肤病变分类的过程，该网络仅使用像素和疾病标签作为输入，直接从图像中端到端地训练出来。测试结果显示深度卷积神经网络在这两个任务上的表现都达到了所有测试的专家的水平，证明了该人工智能的皮肤癌鉴定水平达到了媲美皮肤科医生的水平。配备该深度神经网络的移动设备可以让皮肤科医生的诊断拓展到临床之外。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在此次开发者大会上，论文的合作者之一 Brett Kuprel 讲解了如何使用 TensorFlow 进行癌症图像分类，这是受到学界、业界极大关注的应用之一。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;iframe allowfullscreen="" class="video_iframe" data-vidtype="1" frameborder="0" height="417" src="https://v.qq.com/iframe/preview.html?vid=k03756n3r9k&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0" width="556"&gt;&lt;/iframe&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此外，谷歌研究科学家 Doug Eck 介绍了基于 TensorFlow 的音乐和艺术生成项目 Project Magenta。机器之心之前也曾深度介绍过该项目《&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719723&amp;amp;idx=2&amp;amp;sn=03925a0eb5a8b78cc2642781b924032c&amp;amp;chksm=871b0195b06c888336f97ac330524580589bf29b073aa76585319a6ad43744a5697d6a424b0f&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719723&amp;amp;idx=2&amp;amp;sn=03925a0eb5a8b78cc2642781b924032c&amp;amp;chksm=871b0195b06c888336f97ac330524580589bf29b073aa76585319a6ad43744a5697d6a424b0f&amp;amp;scene=21#wechat_redirect" target="_blank"&gt;深度 | 人工智能改变 MIDI 创作：谷歌 Magenta 项目是如何教神经网络编写音乐的？&lt;/a&gt;》。&lt;/span&gt;&lt;span&gt;Eck 在演讲中谈到了选择 TensorFlow 的原因：可以使用能操作一切（MIDI、音频）的 Python，灵活且高速的图像、音频、视频 I/O、有很好用的 TensorBoard 和非常好的开发者社区。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/22c30ceca8ac042d2bb97428838cfaa0b9c25094"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后要提及的是谷歌收购的 DeepMind 团队在去年从 Torch 转向 TensorFlow 之后，也在积极地将其用到各种应用上。在大会的一场演讲中，来自 DeepMind 应用团队的 Daniel Visentin 就提到了 DeepMind 将它们的人工智能技术应用到谷歌的数据中心上，从而寻找帮助谷歌降低能源费用的方法。而这种方法的开发就得益于围绕 TensorFlow 开发的一些更高水平的库。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/6d8a5b9ed334d41fc0c6ae14b51f6b748172e474"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;移动端与嵌入式 TensorFlow&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;服务器端的大规模机器学习应用，Google 当仁不让（当然，Facebook、Twitter、Linkedin、Netflix、Amazon 等也有自己的看家本领）。但是，移动计算市场对机器学习的需求极其强劲，谷歌自然不会放弃这块巨大的蛋糕。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;Pete Warden 带来了主题为「移动端与嵌入式 TensorFlow」的演讲。首先，对 TensorFlow 生态系统做了基本介绍，接着就移动端实现 TensorFlow 以及一些问题解决（当然，也是 TensorFlow 的优点）做了简单讲解。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前，TensorFlow 支持的平台包括安卓、iOS 以及树莓派。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/5037f216a3043d72e501f9f4d4693864f9a3da67"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;TensorFlow 还与许多芯片制造商，比如 英特尔、ARM 、Movidius 等密切合作，确保 TensorFlow 在一大堆不同硬件上运行更快更流畅。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/d108b8260fd4deda47183d5fa98486fae531287f"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;简单介绍 TensorFlow 的生态环境后，Pete Warden 利用介绍了安卓系统、iOS 以及树莓派的 TensorFlow 实现，还给出了应用实例。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/89ab4e4f414d6049604c101736ffcdb0c76ce569"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;安卓应用程序用的是 Java，怎么办？答案在上面。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 TF 实现中，通常会遇到一些问题，比如&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/d1971f269d8e1a29f36710ce6a5d8436e6e6c386"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为此，你可能需要知道 TensorFlow 的打造原理，比如，TensorFlow 的组件巨多，根本不存在一个把这些内容都列出来的单一文件。这时，你需尝试有效操作办法：&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/d550bb5520261db2df9e4bef09deb6ba3ef7c9fe"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;接下来，管理模型大小和速度问题，TensorFlow 有不少办法压缩模型大小。其中，最关键的步骤就是量子化权重。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/e5a0f4fc8f03a70b3729f7612bcf6fd5d9ead005"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后介绍了管理二进制文件大小。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/9a8516c8959206c8b2487df59a3a0a949d961c8a"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;TensorFlow 资源汇集&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Ashish Agarwal 在本次开发者大会上介绍了机器学习工具包，他谈到 TensorFlow 虽然是一个非常强大的框架，然而也一直以来都缺乏可以即时使用的解决方案。常用的机器学习工具包括：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/f4c50818b0ec8c5136cc8858054b37348c542708"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Agarwal &amp;nbsp;介绍了了一个旨在解决这一问题的算法工具包，并表示这个工具包是 TensorFlow 中的高性能、分布式、可扩展的机器学习算法实现，可以直接拿来使用，比如下面这个联合实现 k-均值和 DNN 的案例：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/1f89ff2372bd192429048ed09320dcbb9dedab68"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后机器之心在下面梳理了我们关于 TensorFlow 的报道：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;基本概述和新闻&lt;/strong&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2"&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720407&amp;amp;idx=1&amp;amp;sn=768d7248e0ab5fa469dbae86d11152e1&amp;amp;chksm=871b0ce9b06c85ffefa2e0c8f6fb7ae4cc1c0500cda7bad008fe68ed6b87d7c8765d138e1fd1&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720407&amp;amp;idx=1&amp;amp;sn=768d7248e0ab5fa469dbae86d11152e1&amp;amp;chksm=871b0ce9b06c85ffefa2e0c8f6fb7ae4cc1c0500cda7bad008fe68ed6b87d7c8765d138e1fd1&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;" target="_blank"&gt;&lt;span&gt;TensorFlow开源一周年：这可能是一份最完整的盘点&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=401936398&amp;amp;idx=2&amp;amp;sn=9b34d959e50825b24a90dbef09f2d9fd&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=401936398&amp;amp;idx=2&amp;amp;sn=9b34d959e50825b24a90dbef09f2d9fd&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;" target="_blank"&gt;&lt;span&gt;TensorFlow：最棒的深度学习加速器&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720846&amp;amp;idx=4&amp;amp;sn=a15185b1435b14ec6c9ab15366e4f7de&amp;amp;chksm=871b0e30b06c8726020e17d0bf4ad79791a472e320224782b8f69317e9f4a17391e0c9a9fa3d&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720846&amp;amp;idx=4&amp;amp;sn=a15185b1435b14ec6c9ab15366e4f7de&amp;amp;chksm=871b0e30b06c8726020e17d0bf4ad79791a472e320224782b8f69317e9f4a17391e0c9a9fa3d&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;" target="_blank"&gt;&lt;span&gt;终于来了，TensorFlow 新增官方 Windows 支持&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715969&amp;amp;idx=3&amp;amp;sn=1116cce76c0a18b6462acee8c77c2278&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715969&amp;amp;idx=3&amp;amp;sn=1116cce76c0a18b6462acee8c77c2278&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;" target="_blank"&gt;&lt;span&gt;谷歌开源平台TensorFlow向iOS开放&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715679&amp;amp;idx=1&amp;amp;sn=0722624d88f17a70d9663bc918f9ac82&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715679&amp;amp;idx=1&amp;amp;sn=0722624d88f17a70d9663bc918f9ac82&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;" target="_blank"&gt;&lt;span&gt;想揭开深度学习隐藏层的神秘面纱？试试Tensor Flow的神经网络游乐场&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722208&amp;amp;idx=5&amp;amp;sn=392a6aa77f0f5eeb976636f4fe791cc7&amp;amp;chksm=871b0bdeb06c82c84cb811fa6e059b988f56249d027dbdcb5f28fe45a1167f27c1f1e1cd6de2&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722208&amp;amp;idx=5&amp;amp;sn=392a6aa77f0f5eeb976636f4fe791cc7&amp;amp;chksm=871b0bdeb06c82c84cb811fa6e059b988f56249d027dbdcb5f28fe45a1167f27c1f1e1cd6de2&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;" target="_blank"&gt;&lt;span&gt;TensorFlow版本号升至1.0，正式版即将到来&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650723249&amp;amp;idx=1&amp;amp;sn=2503c119815d74f25703b252ee45f844&amp;amp;chksm=871b17cfb06c9ed9fc1c43f32750f9f4294c59514c174480ed3542722e621beca10d399505b4&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650723249&amp;amp;idx=1&amp;amp;sn=2503c119815d74f25703b252ee45f844&amp;amp;chksm=871b17cfb06c9ed9fc1c43f32750f9f4294c59514c174480ed3542722e621beca10d399505b4&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;" target="_blank"&gt;&lt;span&gt;谷歌召开首届TensorFlow开发者大会，正式发布TensorFlow 1.0&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720302&amp;amp;idx=4&amp;amp;sn=5a54ac9d2097f0db11d1da8a65cf2e4c&amp;amp;chksm=871b0c50b06c85466eb0bb5e455e306deca82662d83895f9d6ad2311539a9adf7056dac306ac&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720302&amp;amp;idx=4&amp;amp;sn=5a54ac9d2097f0db11d1da8a65cf2e4c&amp;amp;chksm=871b0c50b06c85466eb0bb5e455e306deca82662d83895f9d6ad2311539a9adf7056dac306ac&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;" target="_blank"&gt;&lt;span&gt;TensorFlow 生态系统：与多种开源框架的融合&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715438&amp;amp;idx=2&amp;amp;sn=3dafb301ec8103fce7ad88d6039cb3ad&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715438&amp;amp;idx=2&amp;amp;sn=3dafb301ec8103fce7ad88d6039cb3ad&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;" target="_blank"&gt;&lt;span&gt;谷歌TensorFlow的一份全面评估报告：好的坏的及令人讨厌的&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721938&amp;amp;idx=1&amp;amp;sn=a7568453296f8b34f1bbb6287cb994d0&amp;amp;chksm=871b0aecb06c83fad3b111c2f48206b26c85762e2b9834a07dddd7a282b60a5df2f78c104de5&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721938&amp;amp;idx=1&amp;amp;sn=a7568453296f8b34f1bbb6287cb994d0&amp;amp;chksm=871b0aecb06c83fad3b111c2f48206b26c85762e2b9834a07dddd7a282b60a5df2f78c104de5&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;" target="_blank"&gt;&lt;span&gt;对比深度学习十大框架：TensorFlow最流行但并不是最好&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650723269&amp;amp;idx=1&amp;amp;sn=959bfccb95502778aadeb1c906044b0d&amp;amp;chksm=871b17bbb06c9ead069be0bca912814ae8b1c10533f90f64cfd46b70a68c89c3df6492139dfc&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650723269&amp;amp;idx=1&amp;amp;sn=959bfccb95502778aadeb1c906044b0d&amp;amp;chksm=871b17bbb06c9ead069be0bca912814ae8b1c10533f90f64cfd46b70a68c89c3df6492139dfc&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;" target="_blank"&gt;&lt;span&gt;从TensorFlow到Theano：横向对比七大深度学习框架&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719562&amp;amp;idx=3&amp;amp;sn=f62ba6a54a5d6c0a11ee21fa4e103382&amp;amp;chksm=871b0134b06c8822abc72d89c493790d7fb0257c9298456e0f7bf9db75a554fb331f08396770&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719562&amp;amp;idx=3&amp;amp;sn=f62ba6a54a5d6c0a11ee21fa4e103382&amp;amp;chksm=871b0134b06c8822abc72d89c493790d7fb0257c9298456e0f7bf9db75a554fb331f08396770&amp;amp;scene=21#wechat_redirect" target="_blank"&gt;&lt;span&gt;TensorFlow工程设计主任Rajat Monga问答：计算能力是深度学习发展的主要瓶颈&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715087&amp;amp;idx=3&amp;amp;sn=a736c842914fc58f4789219a85a66206&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715087&amp;amp;idx=3&amp;amp;sn=a736c842914fc58f4789219a85a66206&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;" target="_blank"&gt;&lt;span&gt;DeepMind：Torch很好，但我们要去老板家的TensorFlow了&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=400417166&amp;amp;idx=2&amp;amp;sn=c040ad708a421fe61ed0eedf064ec73c&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=400417166&amp;amp;idx=2&amp;amp;sn=c040ad708a421fe61ed0eedf064ec73c&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;" target="_blank"&gt;&lt;span&gt;探秘谷歌人工智能实验室，TensorFlow在这里诞生&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;前沿研究&lt;/strong&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2"&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715794&amp;amp;idx=3&amp;amp;sn=3c328f66f24dee02b6a29a7821c7f6a1&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715794&amp;amp;idx=3&amp;amp;sn=3c328f66f24dee02b6a29a7821c7f6a1&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;" target="_blank"&gt;&lt;span&gt;Google Brain论文：TensorFlow，一个大规模机器学习系统&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719022&amp;amp;idx=1&amp;amp;sn=3eeb1958e695388817dd32b0d228ced9&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719022&amp;amp;idx=1&amp;amp;sn=3eeb1958e695388817dd32b0d228ced9&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;" target="_blank"&gt;&lt;span&gt;DeepMind最新生成模型WaveNet，将机器合成语音水平与人类差距缩小50%（附论文）&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722733&amp;amp;idx=4&amp;amp;sn=6e437dbda2795bfa95cd64f82f6c4d7a&amp;amp;chksm=871b15d3b06c9cc5b68f70b42c35cd5823b58780bce6420cd9f4f365e775be47e4a78d61633e&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722733&amp;amp;idx=4&amp;amp;sn=6e437dbda2795bfa95cd64f82f6c4d7a&amp;amp;chksm=871b15d3b06c9cc5b68f70b42c35cd5823b58780bce6420cd9f4f365e775be47e4a78d61633e&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;" target="_blank"&gt;&lt;span&gt;谷歌翻译整合神经网络：机器翻译实现颠覆性突破（附论文）&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720113&amp;amp;idx=1&amp;amp;sn=b45bd28cef19a06c717717d3622d58de&amp;amp;chksm=871b030fb06c8a199334d745ad1be56b6b7aeb364596743be7215cc7c6a15a23053c8b60639f&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720113&amp;amp;idx=1&amp;amp;sn=b45bd28cef19a06c717717d3622d58de&amp;amp;chksm=871b030fb06c8a199334d745ad1be56b6b7aeb364596743be7215cc7c6a15a23053c8b60639f&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;" target="_blank"&gt;&lt;span&gt;谷歌增强型风格迁移新算法：实现基于单个网络的多种风格实时迁移（附论文）&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;span&gt;&lt;strong&gt;应用实现与开源&lt;/strong&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2"&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719367&amp;amp;idx=2&amp;amp;sn=f55be5c1efdbf75f98ec77d6d94c6b62&amp;amp;chksm=871b00f9b06c89eff2bf15e38deb2d060a5c1f5ffb4e01839b920572f9c5499bf7a0129e25b8&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719367&amp;amp;idx=2&amp;amp;sn=f55be5c1efdbf75f98ec77d6d94c6b62&amp;amp;chksm=871b00f9b06c89eff2bf15e38deb2d060a5c1f5ffb4e01839b920572f9c5499bf7a0129e25b8&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;" target="_blank"&gt;&lt;span&gt;Show and Tell：谷歌在 TensorFlow 上开源图像描述系统&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718578&amp;amp;idx=3&amp;amp;sn=2c4141258b0134642c5f4312a56301de&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718578&amp;amp;idx=3&amp;amp;sn=2c4141258b0134642c5f4312a56301de&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;" target="_blank"&gt;&lt;span&gt;谷歌开源新的 TensorFlow 代码，如何进行文本自动摘要&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718786&amp;amp;idx=4&amp;amp;sn=274bbf2332427a274123f6b9e009487e&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718786&amp;amp;idx=4&amp;amp;sn=274bbf2332427a274123f6b9e009487e&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;" target="_blank"&gt;&lt;span&gt;谷歌开放 TF-Slim：在 TensorFlow 中定义复杂模型的高层库&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716578&amp;amp;idx=1&amp;amp;sn=aae84df4e4e218afcd9f2d7cc88c96eb&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716578&amp;amp;idx=1&amp;amp;sn=aae84df4e4e218afcd9f2d7cc88c96eb&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;" target="_blank"&gt;&lt;span&gt;谷歌新开源「宽度&amp;amp;深度学习」框架：结合记忆和归纳实现更优推荐（附论文）&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718798&amp;amp;idx=2&amp;amp;sn=d18431b7d6e352a1001a938d007dec82&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718798&amp;amp;idx=2&amp;amp;sn=d18431b7d6e352a1001a938d007dec82&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;" target="_blank"&gt;&lt;span&gt;谷歌开放Inception-ResNet-v2：一种新的图像分类卷积神经网络模型&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715438&amp;amp;idx=1&amp;amp;sn=3573abf9634a55c9547409a35ca18b38&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715438&amp;amp;idx=1&amp;amp;sn=3573abf9634a55c9547409a35ca18b38&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;" target="_blank"&gt;&lt;span&gt;谷歌开源最精确自然语言解析器SyntaxNet的深度解读：一次关键进步以及一个重要工具&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650723201&amp;amp;idx=2&amp;amp;sn=81dd9fbd5f00b1d17437c17a2e14f8c9&amp;amp;chksm=871b17ffb06c9ee92edc24c76eb32c05173ce2831c4109fb779293fdec9de146bf5e34fadd6d&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650723201&amp;amp;idx=2&amp;amp;sn=81dd9fbd5f00b1d17437c17a2e14f8c9&amp;amp;chksm=871b17ffb06c9ee92edc24c76eb32c05173ce2831c4109fb779293fdec9de146bf5e34fadd6d&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;" target="_blank"&gt;&lt;span&gt;雅虎BigML团队开源大数据分布式深度学习框架TensorFlowOnSpark&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650723010&amp;amp;idx=1&amp;amp;sn=18ce6c3662b346b8d47f19cac8d797ed&amp;amp;chksm=871b16bcb06c9faaf3a5f7decb67ba6d7f0a16ec7b574f05a518a8d6831175c0a1cbeb966c40&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650723010&amp;amp;idx=1&amp;amp;sn=18ce6c3662b346b8d47f19cac8d797ed&amp;amp;chksm=871b16bcb06c9faaf3a5f7decb67ba6d7f0a16ec7b574f05a518a8d6831175c0a1cbeb966c40&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;" target="_blank"&gt;&lt;span&gt;谷歌发布深度学习库TensorFlow Fold，支持动态计算图&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650723201&amp;amp;idx=3&amp;amp;sn=204b20981a52c8e190624e0c0e445857&amp;amp;chksm=871b17ffb06c9ee9b4fc57ea05762dde2f54229f7510c1f60deb7b6707ec3647066aa192a0a5&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650723201&amp;amp;idx=3&amp;amp;sn=204b20981a52c8e190624e0c0e445857&amp;amp;chksm=871b17ffb06c9ee9b4fc57ea05762dde2f54229f7510c1f60deb7b6707ec3647066aa192a0a5&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;" target="_blank"&gt;&lt;span&gt;Wasserstein GAN 的 TensorFlow 实现&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720302&amp;amp;idx=4&amp;amp;sn=5a54ac9d2097f0db11d1da8a65cf2e4c&amp;amp;chksm=871b0c50b06c85466eb0bb5e455e306deca82662d83895f9d6ad2311539a9adf7056dac306ac&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720302&amp;amp;idx=4&amp;amp;sn=5a54ac9d2097f0db11d1da8a65cf2e4c&amp;amp;chksm=871b0c50b06c85466eb0bb5e455e306deca82662d83895f9d6ad2311539a9adf7056dac306ac&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;" target="_blank"&gt;&lt;span&gt;TensorFlow 生态系统：与多种开源框架的融合&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719713&amp;amp;idx=3&amp;amp;sn=b9a3fbdd5a0bc14a4a3b3a94039b9a85&amp;amp;chksm=871b019fb06c888987a8664b5145091caf888f4bd48581cc053a393800e9f17b29b839804cee&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719713&amp;amp;idx=3&amp;amp;sn=b9a3fbdd5a0bc14a4a3b3a94039b9a85&amp;amp;chksm=871b019fb06c888987a8664b5145091caf888f4bd48581cc053a393800e9f17b29b839804cee&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;" target="_blank"&gt;&lt;span&gt;DeepMind语音生成模型WaveNet的TensorFlow实现&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721559&amp;amp;idx=4&amp;amp;sn=950d87934d39712fab6164d3d2a37be5&amp;amp;chksm=871b0969b06c807f47b6fac20daae25d6d2f57495f6624554550fad7177f56657d208f40690d&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721559&amp;amp;idx=4&amp;amp;sn=950d87934d39712fab6164d3d2a37be5&amp;amp;chksm=871b0969b06c807f47b6fac20daae25d6d2f57495f6624554550fad7177f56657d208f40690d&amp;amp;scene=21#wechat_redirect" target="_blank"&gt;&lt;span&gt;OpenAI 的 PixelCNN++实现：基于 Python3 和 TensorFlow&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720463&amp;amp;idx=2&amp;amp;sn=50d88169778ec31a1e1e2d801325005d&amp;amp;chksm=871b0cb1b06c85a7e0299fc733b67d3107970f1176186a2ac8ca2dd5a23d896b5041e592ab4d&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720463&amp;amp;idx=2&amp;amp;sn=50d88169778ec31a1e1e2d801325005d&amp;amp;chksm=871b0cb1b06c85a7e0299fc733b67d3107970f1176186a2ac8ca2dd5a23d896b5041e592ab4d&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;" target="_blank"&gt;&lt;span&gt;DeepMind提出的可微神经计算机架构的TensorFlow实现&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;教程&lt;/strong&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2"&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717557&amp;amp;idx=1&amp;amp;sn=6c8239ec01c2a3f0def744063d070eec&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717557&amp;amp;idx=1&amp;amp;sn=6c8239ec01c2a3f0def744063d070eec&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;" target="_blank"&gt;&lt;span&gt;谷歌官方指南：如何通过玩TensorFlow Playground来理解神经网络&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722700&amp;amp;idx=1&amp;amp;sn=4e14edc4b11cda185cb0788e197118a5&amp;amp;chksm=871b15f2b06c9ce44805dd3bd33103fe5d03159636dadf685c2f517cfd94f9ca378773cf83cc&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722700&amp;amp;idx=1&amp;amp;sn=4e14edc4b11cda185cb0788e197118a5&amp;amp;chksm=871b15f2b06c9ce44805dd3bd33103fe5d03159636dadf685c2f517cfd94f9ca378773cf83cc&amp;amp;scene=21#wechat_redirect" target="_blank"&gt;&lt;span&gt;没有博士学位，照样玩转TensorFlow深度学习&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718229&amp;amp;idx=1&amp;amp;sn=adaf68f2c193028f1c4de5b8d3217cca&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718229&amp;amp;idx=1&amp;amp;sn=adaf68f2c193028f1c4de5b8d3217cca&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;" target="_blank"&gt;&lt;span&gt;如何在 TensorFlow 中用深度学习修复图像？（附论文）&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719794&amp;amp;idx=2&amp;amp;sn=8e320caa1d32f7a444a17bfa93b318ad&amp;amp;chksm=871b024cb06c8b5a421efa2eedff5b7149d17028d99e95a38857785db06c1eb2b7796d6e7e4f&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719794&amp;amp;idx=2&amp;amp;sn=8e320caa1d32f7a444a17bfa93b318ad&amp;amp;chksm=871b024cb06c8b5a421efa2eedff5b7149d17028d99e95a38857785db06c1eb2b7796d6e7e4f&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;" target="_blank"&gt;&lt;span&gt;资源 | 数十种TensorFlow实现案例汇集：代码+笔记&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719723&amp;amp;idx=4&amp;amp;sn=f86e2f30bcee67a424d4617b72560b8d&amp;amp;chksm=871b0195b06c88832108944311c2494a30483590c8c301b0076e2190734a3271e2929db312ed&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719723&amp;amp;idx=4&amp;amp;sn=f86e2f30bcee67a424d4617b72560b8d&amp;amp;chksm=871b0195b06c88832108944311c2494a30483590c8c301b0076e2190734a3271e2929db312ed&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;" target="_blank"&gt;&lt;span&gt;10种深度学习算法的TensorFlow实现&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718466&amp;amp;idx=1&amp;amp;sn=016f111001e8354d49dd4ce279d283cd&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718466&amp;amp;idx=1&amp;amp;sn=016f111001e8354d49dd4ce279d283cd&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;" target="_blank"&gt;&lt;span&gt;机器学习敲门砖：任何人都能看懂的TensorFlow介绍&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&amp;copy;本文为机器之心原创，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;
</description>
      <pubDate>Sat, 18 Feb 2017 12:44:39 +0800</pubDate>
    </item>
    <item>
      <title>深度 | 深度学习概览之自然语言处理：从基本概念到前沿研究</title>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650723351&amp;idx=2&amp;sn=d0d17c52ab576d3fc4ff2f7982c30309&amp;chksm=871b1069b06c997f43333956b8b2c6cbcb192444eedb41005cc0729c77c45f7184ff516b8aae&amp;scene=0#rd</link>
      <description>
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自Adit Deshpande blog&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Adit Deshpande&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：赵华龙、王宇欣、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote style="color: rgb(62, 62, 62); font-size: 16px; white-space: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/blockquote&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;本文是 Adit Deshpande 的 Deep Learning Research Review 系列文章的第三篇，总结和解读了深度学习在自然语言处理领域的应用。在这里，机器之心随带推荐一篇之前发过的文章《&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721979&amp;amp;idx=4&amp;amp;sn=783ef5189604021eadb39b3d28a08ce6&amp;amp;chksm=871b0ac5b06c83d378629c45f23805227da892c2e934dce6e6aa5d9d5dc0612174842f6e3017&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721979&amp;amp;idx=4&amp;amp;sn=783ef5189604021eadb39b3d28a08ce6&amp;amp;chksm=871b0ac5b06c83d378629c45f23805227da892c2e934dce6e6aa5d9d5dc0612174842f6e3017&amp;amp;scene=21#wechat_redirect" target="_blank"&gt;总结 | 2016 年最值得读的自然语言处理领域 Paper&lt;/a&gt;》&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;自然语言处理介绍&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;介绍&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自然语言处理（NLP）研究的问题是关于如何构建通过处理和理解语言来执行某些任务的系统。这些任务可包括&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;问答（像 Siri、Alexa、Cortana 所做的那些）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;情感分析（决定是否某句话包含积极或消极的内涵）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;图像到文字的映射（生成一幅输入图像的注释）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;机器翻译（将一段文字翻译成另一种语言）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;语音识别&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;词性标注&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;命名实体识别&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;传统的 NLP 方法涉及很多语言学领域自身的知识。要理解诸如音位和语素这样的术语是非常基本的要求，就好像他们的研究统统都是语言学问题一样。让我们来看看传统 NLP 是如何尝试理解下面的话的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/8c351764b3ae85dbddb35a4098074ff49dfdd33f"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;假设我们的目标是收集关于这个词的一些信息（表征其情感，找到它的定义等）。使用我们语言领域的知识，我们可以把这个词分成 3 部分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/aaf0289b15d35f88ca8ecd51065c5aa196fa8378"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们知道前缀「un」表示反对或相反的想法，我们知道「ed」可以指定单词的时间段（过去时态）。通过识别词干「兴趣」的含义，我们可以很容易地推导出整个词的定义和情感。看起来很简单吧？然而，当考虑英语中所有不同的前缀和后缀时，需要非常熟练的语言学家来理解所有可能的组合和意义。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/e2b8a461d460e842a4d012af3c00ae1802147806"/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;深度学习如何很好地解决这些问题？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从最基础层面来说，深度学习即是表征学习（representation learning）。通过卷积神经网络（CNN），我们可以看到不同的过滤器（filter）组合可以用来将各种物体分类。这里，我们将采用一种相似的方式，通过大数据集来创建对各种词的表征。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;本文概论&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本文将以这样的方式来组织文章的内容结构：我们将首先浏览一下构建 NLP 深度网络的基本构建块，然后来谈一谈最近研究论文所能带来的一些应用。不知道我们为什么使用 RNN 或者为什么 LSTM 很有效？这些疑问都很正常，但希望你在读完下面的这些研究论文之后能更好地了解为什么深度学习技术能够如此显著地促进了 NLP 的发展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;词向量（Word Vectors）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由于深度学习爱用数学进行工作，我们将把每个词表示为一个 d 维向量。让我们使 d = 6。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;[Image: https://quip.com/-/blob/cGAAAAubYyb/u9YfGL3mGnMUFhrXOfGArQ] 现在让我们考虑如何填这些值。我们想要以这样的方式填充值：向量以某种方式表示词及其语境、含义或语义。一种方法是创建共生矩阵（coocurence matrix）。假设我们有以下句子：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/c09211bacfcc8f47f54288bf2d374ab316572951"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从这句话，我们要为每个特定的词都创建一个词向量。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/58169d57fd3296c60b3f8b0ca3a1f79bdbf04a6a"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;共生矩阵是包含了在语料库（或训练集）中每个词出现在所有其他词之后的计数数目的矩阵。让我们看看这个矩阵。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/0a20120d27c8d99cbefd6eaedf7082b8e1d9c9ad"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从该矩阵中提取行可以让我们的词向量简单初始化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/533c3da92ecd19e2b91af76430c17f5a996d51ea"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;请注意，通过这个简单的矩阵，我们可以获得一些非常有用的见解（insight）。例如，请注意「love」和「like」这两个词都包含 1，用于名词（NLP 和狗）后的计数。它们与「I」的交集也是 1，因此表明这些词必须是动词。对于远比一个句子更大的数据集，你可以想象这种相似性将变得更加清楚，因为「like」，「love」和其他同义词将开始具有相似的单词向量，因为它们都在相似的上下文中使用。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在，尽管这是一个了不起的起点，但我们注意到每个词的维数将随着语料库的大小线性增加。如果我们有一个百万词（在 NLP 标准中并不是很多），我们将有一个一百万乘一百万尺寸的矩阵，它将会非常稀疏（大量的 0）。从存储效率上讲这绝对不是最好的。在寻找表示这些词向量的最优方法方面已经有许多进步。其中最著名的是 Word2Vec。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Word2Vec&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;词向量初始化技术背后的基本思想是，我们要在这种词向量中存储尽可能多的信息，同时仍然保持维度在可管理的规模（25 - 1000 维度是理想的）。Word2Vec 基于这样一个理念来运作，即我们想要预测每个单词周围可能的词。让我们以上一句话「I love NLP and I like dogs」为例。我们要看这句话的前 3 个词。3 因此将是我们的窗口大小 m 的值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/bfcf4f0651ac695741a7039d43ba9c84e4ffe7f9"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在，我们的目标是找到中心词，「love」，并预测之前和之后的词。我们如何做到这一点？当然是通过最大化/优化某一函数！正式地表述是，我们的函数将寻求给定当前中心词的上下文词的最大对数概率。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/e1bbd5fc9fe7644964c357e7920aa403f669b8b5"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;让我们对这一点再深入地探究。上面的成本函数（cost function）基本上是说我们要添加'I'和'love'以及'NLP'和'love'的对数概率（其中「love」是两种情况下的中心词）。变量 T 表示训练句子的数量。让我们再仔细研究一下那个对数概率。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/80ec9abc71a42d16aa0f9362a8cfca84a0ed76fe"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Vc 是中心词的词向量。每个词由两个向量表示（Uo 和 Uw），一个用于当该词用作中心词时，一个用于当它用作外部词（outer word）时。向量是用随机梯度下降（SGD）来训练的。这绝对是一个理解起来更让人困惑的方程之一，所以如果你仍然有疑问想了解到底发生了什么，你可以查看以下两个资源：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;How does word2vec work?：https://www.quora.com/How-does-word2vec-work&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Word Embedding Explained and Visualized - word2vec and wevi：https://www.youtube.com/watch?v=D-ekE-Wlcds&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一句总结：Word2Vec 寻求通过最大化给定中心词的上下文词的对数概率并通过 SGD 修改向量来找到不同词的向量表示。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（可选：论文《Distributed Representations of Words and Phrases and their Compositionality》的作者接着详细介绍了如何使用频繁词的负采样（negative sampling）和下采样（subsampling）获得更精确的词向量。）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有人认为，Word2Vec 最有趣的贡献是使得不同词向量之间表现出线性关系。经过训练，词向量似乎能捕获不同的语法和语义概念。这些线性关系是如何能通过简单的对象函数和优化技术来形成的，这一点真是相当难以置信。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/d10ab5b0c1e77300c6d3d3f5dfff9919c8ecc619"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;额外补充：另一种很酷的词向量初始化方法：GloVe（将共生矩阵与 Word2Vec 的思想结合在一起）：http://nlp.stanford.edu/pubs/glove.pdf&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;循环神经网络（RNN）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;好吧，那么现在我们有了我们的词向量，让我们看看它们如何与循环神经网络结合在一起的。RNN 是当今大多数 NLP 任务的必选方法。RNN 的最大优点是它能够有效地使用来自先前时间步骤的数据。这是一小片 RNN 的大致样子。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/ad1045195639c1544edabb0ff9d847cd513c61a6"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt; 因此，在底层，我们有我们的词向量（xt，xt-1，xt + 1）。每个向量在同一时间步骤（ht，ht-1，ht + 1）有一个隐藏状态向量。让我们称之为一个模块（module）。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/9d816409980c11cbfed4e9aa7731111964e342c0"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;RNN 的每个模块中的隐藏状态是在前一时间步骤的词向量和隐藏状态向量二者的函数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/9a595a9723b0962a90d378f5f8ce083fa1ac5638"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你仔细看看上标，你会看到有一个权重矩阵 Whx，我们将它乘以我们的输入，并且在上一个时间步骤中，用一个循环出现的权重矩阵 Whh 乘以隐藏状态向量。请记住，这些循环出现的权重矩阵（recurrent weight matrix）在所有时间步骤上都是相同的。这是 RNN 的关键点。仔细考虑一下这一点，它与传统的（比如 2 层的神经网络）非常不同。在这种情况下，我们通常对于每个层（W1 和 W2）都有不同的 W 矩阵。这里，循环权重矩阵在网络中是相同的。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了得到特定模块的输出（Yhat），将以 h 乘以 WS，这是另一个权重矩阵。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/bfcc34df4c2d810a99ac65737cf9fbc814938509"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;让我们现在退一步并且来理解 RNN 的优点是什么。与传统神经网络的最明显的区别是，RNN 接受输入的序列（在我们的例子中是词）。你可以将其与典型的 CNN 进行对比，在 CNN 中你只需要一个单一的图像作为输入。然而，使用 RNN，输入可以是从一个短句到一篇 5 段文章等各种长度。此外，该序列中的输入的顺序（order）可以极大地影响在训练期间权重矩阵和隐藏状态向量的改变情况。在训练之后，隐藏状态将有望捕获来自过去的信息（以前的时间步骤）。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;门控循环单位（GRU）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在让我们来看门控循环单元（GRU）。这种单元的目的是为计算 RNN 中的隐藏状态向量提供一种更复杂的方法。这种方法得以使我们保留捕获长距依赖（long distance dependencies）的信息。让我们想想看为什么在传统 RNN 设置中长期依赖会成为一个问题。在反向传播期间，误差将流经 RNN，即从最近的时间步骤至最早的时间步骤。如果初始梯度是个小数字（例如&amp;lt;0.25），则通过第 3 或第 4 模块，梯度实际上将会消失（链式规则乘以梯度），因此较早时间步骤的隐藏状态将无法更新。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在传统的 RNN 中，隐藏状态向量通过下面的公式计算得来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/905490eb905a51f7c37a20e7a26e084cf89295fe"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;GRU 提供了一个计算此隐藏状态向量 h(t) 的不同方式。计算分为 3 个分量，一个更新门（update gate），一个重置门（reset gate）以及一个新的记忆容器（memory container）。两个门均是前一时间步骤上输入词向量和隐藏状态的函数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/ceda5176b7faf1a563a5a62b2dd8e487a4f70cc0"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关键区别在于每个门使用不同的权重。这种区别通过不同的上标来表示。更新门使用 Wz 和 Uz，而重置门使用 Wr 和 Ur。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在，通过以下方式计算新的记忆容器：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/6b5abdc6f21b8e3382485ade1d648f7aacc6f949"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;空心点表示Hadamard积&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在，如果你仔细看看公式，你将看到，如果重置门单元接近 0，那么整个项也变为 0，此时可以忽略来自之前时间步骤的 ht-1 的信息。在这种情况下，单元只是新的词向量 xt 的函数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;h(t) 的最终公式写为：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/a8fbdd36ec5141af066a29aed82f51f78508329f"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;ht 是一个由三部分构成的函数：重置门、更新门和记忆容器。通过观察当 zt 接近 1 和接近 0 时会发生什么是理解这点最好的方法。当 zt 接近 1 时，新的隐藏状态向量 ht 主要取决于先前的隐藏状态，且因为（1-zt）变为 0 使得我们会忽略当前的存储容器。当 zt 接近 0 时，新的隐藏状态向量 ht 主要取决于当前的存储容器，此时我们会忽略之前的隐藏状态。观察这三部分最直观的方法可以总结如下。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;更新门， 如果 zt〜1，则 ht 完全忽略当前词向量，且只复制上一个隐藏状态（如果行不通，看看 ht 方程，并且注意当 zt〜1 时 1 - zt 项发生什么）。如果 zt〜0，则 ht 完全忽略上一时间步骤上的隐藏状态，且依赖新的记忆容器。此门让模型控制着之前隐藏状态中应影响当前隐藏状态的信息的多少。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;重置门， 如果 rt〜1，则存储容器阻止来自之前隐藏状态的信息。如果 rt〜0，则存储容器忽略之前的隐藏状态。如果该信息在将来不具有相关性，则此门会令模型删除信息。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;记忆容器：取决于重置门。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;阐明 GRU 有效性的常见示例如下。假设你有以下语段。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/4052a26b8054100d3953017f8490ac16ca62b689"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt; 和相关问题「2 个数字的和是什么？」。由于中间语句对手头问题绝对没有影响，重置门和更新门将允许网络在一定意义上「忘记」中间语句，同时仅学习应修改隐藏状态的特定信息（这种情况下是数字）。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;长短时记忆单元（LSTM）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你对 GRU 感到满意的话，那么 LSTM 并不会让你更加满意。LSTM 也是由一系列的门组成。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/e6ba037ada2ff285f2e632c361c576fe89009fbd"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;肯定有更多的信息需要采集。因为这可以被认为是 GRU 背后的想法的延伸，我不会进行深入地分析。如果你想对每一个门和每一步计算进行深入地演算，请查看 Chris Olah 的一篇非常好的博客文章：http://colah.github.io/posts/2015-08-Understanding-LSTMs/。这是迄今为止，在 LSTM 上最受欢迎的教程，它一定会帮助你理解这些单元工作的这么好的原因和其工作方式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;LSTM 和 GRU 的比较&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;让我们从两者相似之处看起。这两种单元具有能够保持序列中字的长期依赖性的特殊功能。长期依赖性指两个词或者短语可能会在不同的时间段出现的情况，但是它们之间的关系对于解决最终目标仍然至关重要。LSTM 和 GRU 能够通过忽略或者保持序列中的某些信息的门来获取这些依赖性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;两个单元之间的差异在于它们所拥有的门的数量（GRU &amp;ndash; 2, LSTM &amp;ndash; 3）。这影响了输入通过的非线性数，并最终影响整体计算。GRU 也不具有与 LSTM 相同的记忆单元（ct）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;看论文之前&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;只是做一个快速的注释。还有一些其他的深度模型在自然语言处理（NLP）当中很有用。递归神经网络（recursive neural networks）和用于自然语言处理（NLP）的卷积神经网络（CNN）有时会在实践中应用，但不像循环神经网络（Recurrent neural Network）那样流行。循环神经网络（RNN）是在大多数深度学习自然语言处理（NLP）系统中的支柱。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;好的。现在我们对与自然语言处理（NLP）相关的深度学习有了不错的理解，让我们来看一些论文。由于在自然语言处理（NLP）中有许多不同领域的问题（从机器翻译到问题回答），我们可以研究许多论文，但是我发现其中有三篇论文有着独到的见解。2016 年，在自然语言处理（NLP）方面有着巨大的进步，但是让我们从 2015 年的一篇论文看起。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：记忆网络（Memory Networks）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;链接：https://arxiv.org/pdf/1410.3916v11.pdf&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;简介：&lt;/span&gt;&lt;span&gt;第一篇文章，我们将要讨论的是在问答（Queston Answering）子领域的一个非常有影响力的论文。作者是 Jason Weston、Sumit Chopra 和 Antoine Bordes，这篇论文介绍了一类称为记忆网络的模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;记忆网络的直观思想是：为了准确地回答关于一段文本的问题，你需要以某种方式记忆被提供的最初的信息。如果我问你「RNN 代表什么？」，（假设你已经完全阅读了这篇文章），你将会给我一个答案。因为你通过阅读这篇文章的第一部分所得到的信息，将会存储在你记忆中的某个地方。你只需要几秒钟来找到这个信息，并用文字将其表述出来。现在，我不知道大脑是如何作到这一点的，但是为信息保留存储空间的想法仍然存在。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本文中描述的记忆网络是唯一的，因为它是一种能够读写的关联记忆（associative memory）。有趣的是，我们并没有这种类型的卷积神经网络或者 Q 网络（Q-Network）（应用于强化学习）或者传统的神经网络的记忆。这是因为问答任务很大程度上依赖于建模的能力或者保持追踪长期依赖性的能力，比如追踪故事中的角色或事件的时间线。使用卷积神经网络和 Q 网络，「记忆（memory）」是一种内置在网络的权重。因为它可以学习从状态到动作的不同的筛选或者映射。首先，可以使用 RNN 和 LSTM，但是它们通常不能记忆来自过去的输入（这在回答任务中中非常重要）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;网络架构&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;好的，现在让我们来看一看这个网络如何处理它给出的初始文本。就像大多数机器学习算法一样，第一步是将输入转化为特征表示。这需要使用词向量、词性标签等。这真的取决于编程者。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/bc78a8496565c9680612f1a235d8f18ae805cd47"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下一步将采用特征表示 I(x)，并允许更新我们的记忆 m 以反映我们接收到的最新的输入 x。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/91f212fa7f4dbab1df0883d0ab7b7cc7af41061f"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你可以认为记忆 m 是一种由单独的记忆 mi 组成的数组。这些单独的记忆 mi 中的每一个都可以作为整体的记忆 m，特征表示 I(x) 和/或者它本身。该函数 G 可以简单地将整个表示 I(x) 存储在单独的记忆单元 mi 中。基于新的输入，你可以修改函数 G 来更新过去的记忆。第三和第四步包括基于问题读取记忆以获得特征表示 o，然后对其解码以输出最终答案 r。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/9b19c76597c861ff8b03435ce5fc93b336b677be"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;R 函数可以用来将特征表示从记忆转化为问题的即可靠又准确的答案。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在，让我们来看第三步。我们希望这个 O 模块输出一个特征表示，使其最佳地匹配给定问题 X 的一个可能的答案。现在这个问题将要与每个独立的记忆单元进行匹配并且基于记忆单元支持该问题的程度被「评分」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/c18408ac237a8a7741b1dd80988d77e45b85f5ac"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们使用评分函数的 argmax 值来找到支持问题的最佳输出表示（你也可以取多个最高得分单位，不必限于 1）。评分函数是计算不同问题和选取存储单元的不同嵌入之间的矩阵乘积的函数（更多细节请查看论文）。你也可以这样认为，你将两个单词的单词向量相乘以找到他们的相似之处。然后将输出表示 o 馈送入 RNN 或者 LSTM 或者另一个输出可靠答案的评分函数。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该网络以监督的方式训练，其中训练数据包括原始文本、问题、支撑句（supporting sentences）、以及 ground truth 答案。这里是目标函数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/88217f4daf01e73f09c2d060cd4a1746d14705b9"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt; 对于那些感兴趣的人，这是构建这种记忆网络方法的论文。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;End to End Memory Networks：https://arxiv.org/pdf/1503.08895v5.pdf&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Dynamic Memory Networks：https://arxiv.org/pdf/1506.07285v5.pdf&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Dynamic Coattention Networks ：https://arxiv.org/pdf/1611.01604v2.pdf&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：用于情感分析的 LSTM 树（Tree LSTMs for Sentiment Analysis）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;链接：https://arxiv.org/pdf/1503.00075v3.pdf&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;简介：&lt;/span&gt;&lt;span&gt;下一篇文章讨论了情感分析方面的进步，确定短语是否有正面或者负面的含义/意义。更正式地说，情感可以被定义为「对于某个情况或事件的看法或者态度」。当时，LSTM 是情感分析网络中最常用的单元。作者：Kai Sheng Tai、Richard Socher 和 Christopher Manning，本文介绍了以一种非线性的结构将 LSTM 连接在一起的新方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种非线性组合背后的动机在于自然语言中表现出的将序列中的词变成短语的特性。这些取决于词的顺序的短语可以有着与原始的组成词不同的意义。为了表示这种特性，LSTM 单元的网络被布置成树状结构，其中不同单元受其子节点的影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;网络架构&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;LSTM 树和标准树之间的一个区别是，后者的隐藏状态是当前输入和先前时间步长的隐藏状态的一个函数。然而，对于 LSTM 树，其隐藏状态是当前输入和其子单元的隐藏状态的函数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有着新的基于树的结构，一些数学变换，包括具有遗忘门（forget gates）的子单元。对于那些对细节感兴趣的人，请查看论文获取更多信息。然而，我想要关注的是为什么这些模块比线性 LSTM 工作的更好。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/32333cc0eeba611e73a835936f8da060c5e78496"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使用 LSTM 树，单个的单元能够并入其所有子节点的隐藏状态。这非常有趣，因为一个单元可以不同地评价其每个子节点。在训练期间，神经网络可以实现特定词（也许是在情感分析中的「not」或者「very」），这对句子的整体情感非常重要。将节点评价的更高为网络提供了极高的灵活性，并可以提高其性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：神经机器翻译（Neural Machine Translation）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;链接：https://arxiv.org/pdf/1609.08144v2.pdf&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;简介：&lt;/span&gt;&lt;span&gt;我们今天要讨论的最后一篇论文描述了机器翻译任务的另一种方法。作者为谷歌大脑的 Jeff Dean、Greg Corrado、Orial Vinyals 等人，本文介绍了一种机器翻译系统，该系统为谷歌流行的翻译任务的支柱。与之前使用的谷歌生产系统相比，该系统平均减少了 60% 的翻译错误。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;传统的自动翻译方法包括基于短语匹配的变体。这种方法需要大量的语言领域的知识，最终它的设计被证明太脆弱并且缺乏泛化能力。传统方法的一个问题是它将尝试逐个翻译输入的句子。结果，更有效的方法是（神经机器翻译（NMT）使用的方法）一次翻译整个句子，从而允许上下文更加广泛并且使语言重新排列的更加自然。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;网络架构&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本文作者介绍了一个深层 LSTM 网络，可以端对端的训练 8 个编码器和解码器层。我们可以将这个系统分为 3 个部分，编码器 RNN、解码器 RNN 和注意模块。从更高的等级，编码器致力于将输入的句子转变为向量的表示，解码器产生输出表示，然后注意模块告知解码器在解码任务期间要关注什么（这是一种使用句子的整体语境的思想）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/d589db18105d9d2759c37d4c1f61eeb48d6589af"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本论文的其余部分主要集中于大规模部署这样的服务相关的挑战。将详细讨论诸如计算资源量、延迟和大容量部署等主题。机器之心曾经报道过对这项研究的解读，请参阅《&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720582&amp;amp;idx=2&amp;amp;sn=06076c800c912622d8fa42665d7de1fc&amp;amp;chksm=871b0d38b06c842e3f6edaa5d36046b6702d26a0bcfb710c2010e5f0815389bf4f60077441ef&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720582&amp;amp;idx=2&amp;amp;sn=06076c800c912622d8fa42665d7de1fc&amp;amp;chksm=871b0d38b06c842e3f6edaa5d36046b6702d26a0bcfb710c2010e5f0815389bf4f60077441ef&amp;amp;scene=21#wechat_redirect" target="_blank"&gt;深度 | 逐层剖析，谷歌机器翻译突破背后的神经网络架构是怎样的？&lt;/a&gt;》&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;结论&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们总结了关于深度学习帮助自然语言处理任务的方法。在我看来，该领域一些的未来目标关注在改进客户服务聊天机器人、完善机器翻译、并希望使问答系统能够获得对非结构化或者冗长的文本（比如维基百科页面）的更深入的了解。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文链接：https://developers.googleblog.com/2017/02/debug-tensorflow-models-with-tfdbg.html&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;
</description>
      <pubDate>Sat, 18 Feb 2017 12:44:39 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 河南最快超算平台启用，加速智慧城市和人工智能应用</title>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650723351&amp;idx=3&amp;sn=282478e4f9e33c94ec1048dbed2f5ef7&amp;chksm=871b1069b06c997fc4b8d549a71a4f44e2b76d3a9e83d242f31dcc1b7d95c2514457faaa3c8e&amp;scene=0#rd</link>
      <description>
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Yan&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2 月 16 日，河南省最快超级计算机在郑州大学（郑州）超算中心正式投入使用。郑州大学超算中心的设备在软件的调度作用下形成了一个紧耦合的全面系统，借助高性能计算集群强大的计算能力，以深度学习硬件为优化工具，使用大数据分析的方法，对包括政务云学习在内的众多应用进行支撑。郑州大学还计划以该超算系统为平台，建设全国最大的人工智能人才培训基地，打造完整的人工智能综合生态，将成为河南省和郑州市在智慧城市和人工智能等领域加速科技创新的重要基础设施。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/f7ffb43bf39a7211dc2ee23a02f31ce8bfc42bac"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该系统部署了 Caffe-MPI 人工智能计算框架，该框架是浪潮集团在开源 Caffe 的基础上，依托中国并行计算联合实验室的资源，开发了 Caffe-MPI 并行版本，Caffe-MPI（https://github.com/Caffe-MPI/Caffe-MPI.github.io）由浪潮的 HPC 应用开发团队进行开发。Caffe-MPI 是一款分布式集群版本，目前支持 GPU 与 MIC 集群并行计算。如下是使用 KNL 集群运行 Caffe-MPI 框架的一个示例，可以看出计算时间得到大大减少。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/dcd695ecd19b2cd1ece7302b0a7aba3b4bc9d0d2"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前，该系统已经完成一期工程，其峰值计算性能达 800 万亿次每秒。在二期工程中，该超级计算机计划升级到每秒 3000 万亿次，将作为网格节点并入国家高性能计算环境。中国工程院院士、浪潮集团首席科学家王恩东表示，浪潮集团一直积极参与郑州智慧城市建设，此次与郑州大学的合作，是浪潮智慧计算战略的重要落地。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「人工智能实际上是这两年浪潮重点发展的方向。我们的定位是做人工智能应用背后计算力和基础设施的提供者。」浪潮集团高性能计算总经理刘军说：「现在中国绝大多数人工智能应用的背后，有超过 60% 以上的计算力是浪潮的运行，我们有专门的团队会针对人工智能的应用去设计相应的计算设施，帮助他们优化计算框架的软件，提供更好更适合的解决方案。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;浪潮在人工智能领域进行了深度布局。目前，浪潮已经拥有以图搜图、语音识别、企业网络安全深度学习应用和深度学习语音识别加速等应用案例，也包括完善的异构加速产品、ClusterEngine 集成深度学习作业管理调度及集群系统监控、基于高性能系统设计开发 Caffe-MPI 等产品。在刘军看来，人工智能所需要的大数据相当于汽油，像谷歌的 AI、百度用的 PaddlePaddle 等相当于车轮，而浪潮则是把这些整合起来做出高性能的一部车给开发者、应用者使用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在同一天开幕的世界大学生超级计算机竞赛（ASC17）中，郑州大学（郑州）超算将与神威&amp;middot;太湖之光成为承担不同赛题的运算平台。本届大赛由亚洲超算协会、郑州大学、国家超算无锡中心、浪潮合作举办，参赛队伍数量比去年增长 31%，共有来自世界各国 230 支队伍参赛将争夺进入总决赛的 20 强名额。ASC 竞赛发起人、中国工程院院士、浪潮集团首席科学家王恩东表示，随着超级计算、大数据、云计算相互融合，以人工智能为代表的智慧计算将成为未来计算产业里面最重要的组成部分，这将对计算技术带来新的挑战。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一个关键性运算平台神威&amp;middot;太湖之光，是世界上首台峰值计算速度超过十亿亿次的超级计算机，采用中国国产处理器构建。国家超算无锡中心主任、清华大学教授杨广文称，「我们做计算机的核心任务是怎么让这些应用人员把超算融合应用起来，没有超算，大数据、人工智能的开发非常困难，所以我们要降低人工智能使用超算的门槛。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;值得关注的是，此次竞赛增加了无人驾驶的交通预测赛题，希望推动在校大学生了解掌握最新的人工智能算法、大数据应用及先进计算架构的相关知识和能力。交通预测是当前热门的无人驾驶技术中最关键的应用软件之一，可以在考虑时空关系后对交通情况做出合理预测，帮助车辆选择最合适的路线，特别是在城市拥堵情况下的路线选择更有现实的意义。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;据了解，交通预测试题来自百度深度学习研究院，在预赛阶段，将给出某城市前 50 个工作日实际采集的交通状况的训练数据集，各参赛队可以通过百度 PaddlePaddle 深度学习计算框架进行数据训练，最终对第 51 个工作日早高峰期间每 5 分钟的交通状况进行预测，百度将根据交通预测的准确度评判各队的预赛成绩。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&amp;copy;本文为机器之心原创，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;
</description>
      <pubDate>Sat, 18 Feb 2017 12:44:39 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 谷歌发布tfdbg：让TensorFlow机器学习模型调试更简单</title>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650723351&amp;idx=4&amp;sn=fad502a5ae7903ec3f14c5214aae1d83&amp;chksm=871b1069b06c997f804e0876944a1c4c839a8990fcdca5fae6274762645c394fc1631181d92b&amp;scene=0#rd</link>
      <description>
&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自Google Blog&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;作者：蔡善清&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;参与：李泽南、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;随着 2 月 16 日谷歌开发者大会上 &lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650723249&amp;amp;idx=1&amp;amp;sn=2503c119815d74f25703b252ee45f844&amp;amp;chksm=871b17cfb06c9ed9fc1c43f32750f9f4294c59514c174480ed3542722e621beca10d399505b4&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650723249&amp;amp;idx=1&amp;amp;sn=2503c119815d74f25703b252ee45f844&amp;amp;chksm=871b17cfb06c9ed9fc1c43f32750f9f4294c59514c174480ed3542722e621beca10d399505b4&amp;amp;scene=21#wechat_redirect" target="_blank"&gt;TensorFlow1.0&lt;/a&gt; 的发布，这一最流行的深度学习框架迈进了新的时代。昨天，谷歌宣布开源 TensorFlow Debugger，一个专用于调试TensorFlow 代码的新工具，希望以此让开发者们能够更轻松地构建机器学习项目。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今天，我们很高兴发布 TensorFlow Debugger：一个让 TensorFlow 中机器学习模型变得容易的工具。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;地址：https://www.tensorflow.org/programmers_guide/debugger&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;TensorFlow 是谷歌开源的机器学习框架，它基于数据流图。构建一个典型的 TensorFlow 机器学习项目需要经历两个步骤：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 使用 Python API 将机器学习模型设置为数据流图。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 使用 Session.run() 对这个流图进行训练或应用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此前，如果在第二阶段出现了错误和 bug（如 TensorFlow runtime），我们很难进行 debug 工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了了解这种情况，请注意标准的 Python debugger，Session.run() 调用是一个单独的语句，不会暴露流图的内部结构（节点及其连接）和状态（输出数组或节点的张量）。一些低级的 debugger，如 gdb 无法理解 TensorFlow 流图的堆栈结构和变量值。所以，一个专用的运行环境调试器（debugger）是目前 TensorFlow 用户所急需的工具。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;tfdbg 的出现完美解决了运行环境调试器的需求。让我们看看它在一个简短的，用于运行简单线性方程梯度下降的代码片段中的表现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;import numpy as np
import tensorflow as tf
import tensorflow.python.debug as tf_debug
xs = np.linspace(-0.5, 0.49, 100)
x = tf.placeholder(tf.float32, shape=[None], name="x")
y = tf.placeholder(tf.float32, shape=[None], name="y")
k = tf.Variable([0.0], name="k")
y_hat = tf.multiply(k, x, name="y_hat")
sse = tf.reduce_sum((y - y_hat) * (y - y_hat), name="sse")
train_op = tf.train.GradientDescentOptimizer(learning_rate=0.02).minimize(sse)

sess = tf.Session()
sess.run(tf.global_variables_initializer())

sess = tf_debug.LocalCLIDebugWrapperSession(sess)
for _ in range(10):
  sess.run(train_op, feed_dict={x: xs, y: 42 * xs})&lt;/pre&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;正如代码高亮处所示，会话对象被包装为 debugging（LocalCLIDebugWrapperSession），因此调用 run() 方式将启动 tfdbg 的命令行界面（CLI）。使用鼠标点击或输入命令，你可以继续进行连续调用，检查流图节点和它们的属性，通过中间张量显示流图中执行所有相关节点的完整历史记录。通过使用 invoke_stepper 命令，你可以在「步进模式」中执行 Session.run() 调用。在该模式下，您可以跳转到所选节点，观察和修改它们的输出，然后继续检查下一步，这类似于程序语言的 debug（就像在 gdb 或 pdb 中）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在开发 TensorFlow 机器学习模型时，我们经常会遇到的问题是由于溢出、被零除、log0 等情况下出现的错误值（无穷大和 NaN）在大型 TensorFlow 流图中，寻找这样的错误是费时费力的。但现在通过 tfdbgCLI，你可以很快地找到罪魁祸首。以下视频展示了如何使用 tfdbg 解决神经网络代码中的无穷大/NaN 问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;iframe allowfullscreen="" class="video_iframe" data-vidtype="1" frameborder="0" height="417" src="https://v.qq.com/iframe/preview.html?vid=y03769m8n8i&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0" width="556"&gt;&lt;/iframe&gt;&lt;br&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相比于其他 debug 选择，比如 Print Ops，tfdbg 需要更少的代码行变化，还能提供对 graph 更全面的覆盖，以及更交互的 debug 体验。tfdbg 能够加速模型开发、debug 工作流程。它还提供了其他的特征，比如对服务器环境中废弃张量（dumped tensors）的离线 debug，还有融合 tf.contrib.learn 的特征。在你开始的时候，可以先浏览这一文档：&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://www.tensorflow.org/programmers_guide/debugger。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;运行 tfdbg 需求的 TensorFlow 最低版本是 0.12.1。报告 bug 时，请在 Github 上 TensorFlow 的问题页面开个问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以下论文详细展示了 tfdbg 的设计。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/16e7926e0b40df71256c00ac2a8cbd06422fbea3"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;论文：TensorFlow Debugger: Debugging Dataflow Graphs for Machine Learning&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：可调试性在机器学习系统的开发中非常重要。包括 TensorFlow 和 Theano 在内的多个普遍使用的机器学习框架都是基于数据流图的（dataflow graph)。虽然数据流图能提供分布式训练这样的便利，但这种范式也使得模型问题的 debugg 相比于传统的程序式模型的 debugg 更难。在此论文中，我们提出了 TensorFlow Debugger（tfdbg) 设计，为 TensorFlow 中的机器学习模型专门设计的 debugger。tfdbg 提供的特征包括检验运行时数据流图和媒介图形元素（张量，trensors），以及模拟在图上的步骤。我们将会讨论该 debugger 在开发和测试使用案例中的应用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;论文地址：https://research.google.com/pubs/pub45789.html&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;
</description>
      <pubDate>Sat, 18 Feb 2017 12:44:39 +0800</pubDate>
    </item>
    <item>
      <title>学界 | DeepMind提出PathNet：或可通过迁移学习实现通用人工智能</title>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650723351&amp;idx=5&amp;sn=704f34894da5166701baa9af39684b3e&amp;chksm=871b1069b06c997fdc63010119881f748ba8808be0e6d5ca946ac32f32ee70e2b0ead1fa8cff&amp;scene=0#rd</link>
      <description>
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自medium&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Th&amp;eacute;o Szymkowiak&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：黄小天、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通用人工智能（articial general intelligence/AGI）至今看起来仍然是遥不可及的一个技术圣杯，但这没有妨碍研究者向这个方向的努力。近日，一直研究成果不断的 DeepMind 又在 arXiv 上发布了一篇也许向这个方向迈进了一步的新论文，该论文提出了一种 PathNet，宣称能够实现某种巨型神经网络（giant neural network）。麦吉尔大学学生兼该校人工智能协会社长 Th&amp;eacute;o Szymkowiak 在 Medium 上发了一篇短文介绍了这篇论文。机器之心对这篇短文进行了编译，并对原论文进行了摘要介绍，原论文可点击文末「阅读原文」下载。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自从科学家开始构建和训练神经网络以来就一直没能跨过「迁移学习（transfer learning）」的难关。迁移学习是指人工智能学习不同任务并将预学习到的知识应用于全新任务的能力。很显然，具备预先知识的人工智能将在面对新任务时比全新开发的神经网络能表现得更好、训练得更快。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;也许 DeepMind 能用 PathNet 达到这一目标。PathNet 是一个由神经网络组成的网络（network of neural networks），通过随机梯度下降和遗传选择方法做训练。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;PathNet 由模块构成的层组成，其中每个模块都可以是一个任意类型的神经网络&amp;mdash;&amp;mdash;可以是卷积网络、循环网络、前馈网络等等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/5f6b9a1e1800c077dc5b45516d90a76fcf767e20"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 1：一个随机初始化的路径（框图 1 中的紫色线）的集合在学习任务 A Pong 游戏的过程中进化。在训练结束时，最好的路径是固定的（框图 5 中的暗红色线），并且会有一个针对任务 B 的新的路径（框图 5 中的淡蓝色线）集合被生成出来。这个路径集合然后在 Alien 游戏上得到训练，然后在 Alien 游戏上逐渐进化，在训练结束时固定达到最佳路径，如框图 9 中的深蓝色线所示。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这 9 个框图是在不同迭代时的 PathNet。在这个案例中，PathNet 被训练用 Advantage Actor-critic（A3C）玩两个不同的游戏。尽管在一开始 Pong 和 Alien 看上去很不同，但我们确实观察到（看一下得分图）了一个使用 PathNet 的迁移学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;它如何训练&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先，我们需要定义模块。设 L 为层数，N 为每一层的最大模块数（论文表明，N 通常是 3 或 4）。最后一层是密集的，并且不在不同任务之间共享。通过 A3C，最后一层表示价值函数（value function）和策略评估（policy evaluation）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那些模块定义完之后，网络之中生成 P 基因型 (=路径)。由于 A3C 的异步属性，需要多个工作器（worker）评估每一个基因型。在 T 个 episode 之后，一个工作器从其他路径中选一对进行比较，如果这些路径中的一些有更好的适配，那就采用它，并用那个新路径继续训练。如果不，则工作器继续评估其路径的合适程度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;迁移学习&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在学习了一个任务之后，网络会固定最优路径上的所有参数。所有其它参数将被重置，因为照论文上讲，如果不这样做，PathNet 将会在新任务中表现很差。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过使用 A3C，用于新任务的 PathNet 上的反向传播不会修改先前任务中的最优路径。这可以看作是保存先前知识的护卫。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;结果&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/0f60c6549ed750cc7519489d4105e9adecabe9a0"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 7：我们在超参数搜索上的最佳运行的结果。其中的表现是通过测量学习曲线下方的区域（在训练过程中每次 episode 的平均得分）而进行评估的，而不是通过最终得分。然后该迁移分数被定义为一个架构的相对表现，这是与一个带有一个固定最大尺寸路径的独立基线（控制量/control）进行比较得到的，这个基线是仅在目标任务上训练得到的（最上面一行）。当存在加速时，该比率大于 1，减速则该比率小于 1. 我们给出了在我们选择的源-目标（source-target）游戏上得到的迁移分数曲线，并在这个迁移矩阵（transfer matrix）中总结了所有的这种游戏对。接下来的 3 行显示出了 fine-tuning 控制的结果，后 3 行给出了 PathNet 的结果。绿色表示发生了正迁移（positive transfer），蓝色表示负迁移（negative transfer）。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;PathNet 并不在每一对游戏上都能有效（蓝色单元格等于负迁移）。但是重要的是 PathNet 已经对一些游戏对实际有效了，我们已经踏出了迈向更好迁移学习的巨大一步。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;延展思考&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;可以想象在将来，我们会有巨型的人工智能（giant AI），它们被训练完成数以千计的任务并且能够泛化，也就是：通用人工智能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/557ac4246b112b8468df6378c7f56aa39eacdde9"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;论文：PathNet：在超级神经网络中的进化通道梯度下降（PathNet: Evolution Channels Gradient Descent in Super Neural Networks）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果多个用户训练同一个巨型神经网络（giant neural network），同时允许参数复用，并且不会遗忘太多东西，则这对通用人工智能而言将是高效的。PathNet 是在这个方向上迈出的第一步。它是一个将代理嵌入到神经网络中的神经网络算法，其中代理的任务是为新任务发现网络中可以复用的部分。代理是网络之中的路径（称为 views），其决定了通过反向传播算法的前向和后向通过而被使用和更新的参数的子集。在学习过程中，锦标赛选择遗传算法（tournament selection genetic algorithm）被用于选择用于复制和突变的神经网络的路径。路径适配（pathway fitness）即是通过成本函数来度量的自身的表现。我们实现了成功的迁移学习；固定了从任务 A 中学习的路径的参数，并据此再进化出了用于任务 B 的新路径，这样任务 B 要比从头开始或 fine-tuning 学习得更快。任务 B 中进化的路径会复用任务 A 中进化出的最优路径的一些部分。在二元的 MNIST、CIFAR 和 SVHN 监督学习分类任务和一系列的 Atari、Labyrinth 强化学习任务上，我们都实现了正迁移，这表明 PathNet 在训练神经网络上具有通用性应用能力。最后，PathNet 也可以显著提高一个平行异步强化学习算法（A3C）的超参数选择的稳健性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;原文地址：https://medium.com/@thoszymkowiak/deepmind-just-published-a-mind-blowing-paper-pathnet-f72b1ed38d46#.bzxfs9cig&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;br&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;br&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Sat, 18 Feb 2017 12:44:39 +0800</pubDate>
    </item>
  </channel>
</rss>
