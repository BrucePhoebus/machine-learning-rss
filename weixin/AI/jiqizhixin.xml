<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>重磅 | 微软发布数据集MS MARCO，打造阅读理解领域的「ImageNet」</title>
      <link>http://www.iwgc.cn/link/3955978</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自微软&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote style="color: rgb(62, 62, 62); font-size: 16px; white-space: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/blockquote&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;今天早些时候，微软在其官方博客上宣布发布了一个包含 10 万个问题和答案的数据集，研究者可以使用这个数据集来创造能够像人类一样阅读和回答问题的系统。此外，微软计划效仿 ImageNet，与其他人合作、最终创办正式的竞赛等。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个数据集名叫 MS MARCO，表示 Microsoft MAchine Reading COmprehension（微软机器阅读理解）。其背后的团队声称这是目前这一类别中最有用的数据集，因为这个数据集是基于匿名的真实数据构建的。通过将该数据集免费开放给更多的研究者，该团队希望能够促进机器阅读领域的研究突破，就像之前研究者已经在图像识别和语音识别领域所取得颠覆性突破一样。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;MS MARCO 数据集地址：http://www.msmarco.org&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW97Eu3kQ28xCXnW6b2iagC06ibp0qu0Ig59mjrEboib6TvfYhF2yR9fuZ4JOWKwAGIIfdzzprAb52Dfw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他们也希望这次开放能够促进「人工通用智能（AGI/artificial general intelligence）」的长期目标的实现，即创造出能够像人类思考的机器。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW97Eu3kQ28xCXnW6b2iagC06u8rCNjRukHX5liaEqwToQ2xz3HyAicjk3UyRmXunjExkiafv7gh9ticF0g/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Rangan Majumder，微软 Bing 搜索引擎部门合作伙伴组的程序经理&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微软 Bing 搜索引擎部门合作伙伴组的程序经理（partner group program manager）Rangan Majumder 是这个项目的领导者，他说：「为了实现人工通用智能的目标，我们首先需要机器能够像人类一样阅读和理解文档。这个数据集是向这个方向迈出的一步。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Majumder 说，目前回答复杂问题的系统仍然还处在婴儿阶段。Bing 这样的搜索引擎和小娜那样的虚拟助手还只能回答一些基本的问题，比如「光明节那天开始？」或「2000 乘以 43 等于多少？」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Majumder 说，但在许多案例中，搜索引擎和虚拟助手只会将用户引导至一些搜索结果。&lt;/span&gt;&lt;span&gt;当然用户仍然会获得他们想要的信息，但那也需要用户在搜索结果列表中寻找所需的答案链接。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了实现更好的自动问答系统，研究者需要更强大的训练数据。这样的训练数据需要能够教会人工智能系统识别问题和组织答案，并最终能够根据它们之前从未见过的特定问题构建出自己的答案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Majumder 及其团队（包括微软的一些研究者和从事产品开发的人）表示，MS MARCO 数据集是非常有用的，因为该数据集的问题基于来自 Bing 搜索引擎和小娜虚拟助手的真实的、匿名的查询。该团队根据研究者所认为的更有趣的查询而对这些问题进行了选择。除此之外，这些问题的答案都是根据真实的网页而人工书写的，准确性已经过了验证。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过提供真实的问题和答案，这些研究者表示他们可以训练出能更好地应对人们常问问题的细微差别和复杂性的系统，其中包括那些没有明确答案或有多个可能答案的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;比如说，这个数据集中包含了这样一个问题：「What foods did ancient Greeks eat?（古希腊人吃什么食物？）」要正确回答这个问题，他们需要检索多个文档中的信息，最后给出谷物、蛋糕、牛奶、橄榄、鱼、大蒜和卷心菜等食物作为答案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微软首席人工智能科学家、深度学习技术中心（Deep Learning Technology Center）合作伙伴研究经理（partner research manager）邓力说之前的数据集在设计上都有一些特定的限制和局限性。这能让研究者可以更轻松地创造出可以被机器学习研究者形式化为所谓的「分类问题（classification problem）」的解决方案，但却不能帮助机器理解问题的实际文本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW97Eu3kQ28xCXnW6b2iagC06FI7Kefq1AjkyPZteCDyp4Us9hFxxOJH4dIFl9U210svLUD9mNbyTGA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;微软深度学习技术中心合作伙伴研究经理邓力&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;邓力说 MS MARCO 的设计目的是为了帮助研究者实验更先进的深度学习模型，从而推动人工智能研究的进一步发展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他说：「我们的数据集不只是为了使用真实世界数据，也是为了移除这些限制，以使新一代的深度学习模型能够在它们回答问题之前先理解数据。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Majumder 说系统回答复杂问题的能力能够帮助人们更有效地获取信息，从而增强人类的能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;让我们举个例子，假设一个加拿大学生需要了解她是否满足一个贷款项目的申请资格。搜索引擎可能会将该用户引导至一系列的相关网站，然后她需要自己阅读那些条条款款然后才能得出结论。但如果她有更好的工具，她的虚拟助手就能帮助她扫描这些信息，然后给出一个更细致的、甚至个性化的答案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Majumder 说：「鉴于世界上的许多知识都是以书写的形式存在的，如果我们能让机器像人类一样阅读和理解文档，我们就为所有各种各样可能的情形开启了大门。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;长期目标：「人工通用智能（artificial general intelligence）」&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;至少就目前而言，研究者还仍然远远不能创造出能够理解人类所说的、看见的或写出的内容的系统——很多人将其称为「人工通用智能」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在过去几年，微软与其它地方的机器学习和人工智能研究者在创造识别对话中单词的系统上已经取得了极大的进步，在准确识别图像组成上也是如此。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Majumder 说，「微软在语音识别和图像识别上已经起着领头作用，现在我们也打算带领阅读理解的研究。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是，他提到这不是任何单独一家公司就能解决的难题。Majumder 说他们团队开放这个数据集的一个原因就是想要与领域内的其他人合作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;MS MARCO 类似于机器学习和人工智能的其它领域的训练集，包括 ImageNet 数据集——它被认为是测试图像识别进展的第一数据集。微软的一个研究团队曾使用 ImageNet 来测试自己的首个深度残差网络，在图像识别的准确率上有了巨大的提升。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;MS MARCO 团队也打算效仿 ImageNet，创建一个取得最好研究成果的团队排行榜。最终，他们可能会像 ImageNet 年度挑战赛一样创造一个更正式的比赛。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;任何想要下载并将其用于非商业应用的研究人员都可以免费使用 MS MARCO 数据集。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文：https://www.microsoft.com/en-us/research/publication/ms-marco-human-generated-machine-reading-comprehension-dataset/&amp;nbsp;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Sat, 17 Dec 2016 11:07:24 +0800</pubDate>
    </item>
    <item>
      <title>前沿 | 半监督学习新进展：深度渲染混合模型能像人类婴儿一样学习</title>
      <link>http://www.iwgc.cn/link/3955980</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自science daily&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李泽南、蒋思源&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;来自莱斯大学和贝勒医学院（Baylor College of Medicine）的神经科学和人工智能专家们正在从人类的大脑中获得灵感，创造了一种新的「深度学习」方法，这种方法能使计算机像人类婴儿一样自己学习视觉世界。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;blockquote style="color: rgb(62, 62, 62); font-size: 16px; white-space: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW97Eu3kQ28xCXnW6b2iagC0604DIDLics372bMkJ1gqDWYokKHzREa4JLiasrWrGHEuMxvO33SbUia8Jw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;左 Richard Baraniuk, Tan Nguyen and Ankit Patel.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;来自莱斯大学和贝勒医学院（Baylor College of Medicine）的神经科学和人工智能专家们正在从人类的大脑中获得灵感，创造了一种新的「深度学习」方法，这种方法能使计算机像人类婴儿一样自己学习视觉世界。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在研究中，该团队的「深度渲染混合模型（deep rendering mixture model）」通过联邦雇员和高中学生书写的 10000 个数字的标准数据集学会了自己如何辨别手写数字。本月初，这个团队在 NIPS 2016 大会上发表了这项研究的论文《Semi-Supervised Learning with the Deep Rendering Mixture Model》，研究者们描述了如何通过 10 个 0 到 9 之间的手写数字样本来训练他们的算法，然后让机器使用数千样本数据自我学习。在研究中，该算法在正确区分手写数字方面，几乎比所有每个数字都要用数千样本进行训练的旧方法都要好。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;莱斯大学电气和计算机工程和贝勒医学院神经科学联合任命的助理教授、本研究的领导者 Ankit Patel 说：「如果用深度学习的术语来解释，我们的系统使用了一种被称为半监督学习的方法。而在深度学习领域目前最成功的方法使用的是被称为监督学习的技术，这种方法在训练时需要提供成千上万标记好的样本，比如告诉机器：这样是 1，这样是 2。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「人类不会这样学习，」Patel 说道。「当婴儿的第一年刚学习观看事物的时候，他们对于这些事物的具体所指的感知很少。父母可能就只会给他们标注很少的事物：瓶子、椅子、妈妈等，婴儿在这一段时间上甚至不能理解口语，他们通过与世界的互动来学习，这个过程在大部分情况下都是无监督的。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Patel 表示他正和本研究的合作者 Tan Nguyen 设计一个半监督学习系统进行视觉数据训练。这个系统不需要多少「人工标注」的训练样本来进行训练。在此之前，使用监督学习的神经网络在通过 MNIST 数据库超过万种手写数字的测试前，需要使用数百到数千已标记的手写数字训练样本进行训练。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个半监督式的 Rice-Baylor 算法是一个「卷积神经网络」——这是一种从生物大脑得到启发，由多层人工神经元组成的网络。这些人工神经元（即处理单元）分层排列。第一层扫描图像并且执行像搜索边缘和颜色变化那样的简单任务，第二层检查第一层的输出并搜索更复杂的特征。在数学上，这种在模式内寻找模式的嵌套方法被称为非线性过程（nonlinear process）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Patel 这样形容卷积神经网络：「它本质上是一个非常简单的视觉皮层。输入一个图像后，每层都处理图像的一点点特征，这个过程随着层级不断深入，在最后一层，系统对图像获得了深刻和抽象的理解。」目前所有无人驾驶汽车的系统中都使用了卷积神经网络，因为它是目前最好的视觉处理方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;就像人类的大脑一样，神经网络在刚刚生成的时候就像一张白纸，随着与世界的交互渐渐充盈。在面对图像的时候，每一个卷积网络处理单元在一开始都是相同的，随着大量图像的训练，每个单元渐渐开始特化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「边缘（edge）非常重要，」Nguyen 说道。「许多低层神经元往往会成为边缘检测器，它们专注于寻找这种常见且对于视觉解释非常重要的特性。同时，每个神经元都会进行自我训练以寻找特定模式，例如 45 度边缘或 30 度红——蓝转换。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「当它们探测到特定的模式时，它们就会被激发，并将信息传递到下一层，让下一层在此基础之上识别其他模式，这个过程不断进行，」Nguyen 解释道。「非线性变换的次数实际上代表了网络的深度，更深意味着更强大。神经网络越深，它能够解决的问题就越复杂。在网络的深层，处理单元探寻的是非常抽象的概念，如眼球、垂直光栅、或者一辆校车。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Nguyen 在今年一月开始与 Patel 合作，彼时后者刚刚开始他在莱斯大学和贝勒医学院的学术生涯。在此之前，Patel 已经研究机器学习多年，他之前的工作包括将机器学习应用到从大宗商品交易到弹道导弹防御等许多领域，他刚刚在莱斯大学的 Richard Baraniuk 实验室结束了为期四年的博士后工作。在 2015 年末，Baraniuk、Patel 和 Nguyen 发表了他们的第一个理论框架，可以导出卷积神经网络的确切结构，并提供了消除其局限性的一套原则性解决方案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Baraniuk 认为，坚实的理论基础对于设计更加先进的卷积神经网络至关重要。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「视频中的图像是一个很好的例子，」Baraniuk 说道。「如果我在看一个视频，逐帧地观看，假如我想了解所有的对象和它们如何移动等等特性，这会是一个巨大的挑战。想象一下，人脑需要多长时间来标记每个对象，每一帧图像，没有人有这么强大的处理能力。同样的，为了让机器感知它在视频中看到的内容，它必须了解自己看到了哪些对象，明白三维空间的概念和其他大量真正复杂的东西。人类自己学习这些东西，并把它们视作理所当然，但这种能力在今天的人工智能神经网络中完全缺失。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Patel 认为他们在 NIPS 上发表的新一代人工神经网络，最终甚至可以反过来帮助神经科学家们更好地了解人类大脑的工作方式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「视觉皮层中的世界和卷积神经网络中的世界，看起来似乎有一点相似，但在某些层面上也大不相同，」Patel 说道。「大脑的处理方式也许和机器相似，但其中机制仍然区别很大。我们目前对于大脑的研究理论认为，大多数学习都是无监督的。我和我的神经科学家同事们正在试图回答这样几个问题：什么是由视觉皮层中的神经回路实现的半监督学习算法？它与我们的深度学习理论有什么关系？」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们的理论或许可以用来帮助解释大脑处理信息的方式，」Patel 补充道。「大脑的算法远远优于我们设计的任何神经网络。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;论文：使用深度渲染混合模型的半监督学习（Semi-Supervised Learning with the Deep Rendering Mixture Model）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW97Eu3kQ28xCXnW6b2iagC06cqiclWnKLQDTU8176usqZhCIL6pqyenjMlA57IjHK2Tl2pmHPnF2Dtg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：半监督学习算法通过在学习期间同时使用标记的和未标记的数据来降低训练数据的成本。深度卷积网络（DCN）在监督学习的任务中已经取得了巨大的成功，因此目前也被广泛地应用于半监督学习。在本研究中，我们使用了最近开发的深度渲染混合模型（DRMM/Deep Rendering Mixture Model），这是一个概率生成模型（probabilistic generative model）——其建模了潜在的扰动变化，其推理算法产生了 DCN。我们为该 DRMM 开发了一个 EM 算法，以使该 DRMM 能够同时从标记数据和未标记数据中学习。在 DRMM 理论的指导下，我们引入了一个新的非负性约束（non-negativity constraint）和一个变分推理项（variational inference term）。在 MNIST 和 SVHN 数据集上，我们的方法实现了当前最佳的表现，在 CIFAR10 上也实现了可媲美最佳表现的结果。我们还深入研究了一个在半监督环境下训练的 DRMM 可以如何使用合成渲染的图像表征潜在的扰动变化。总的来说，本研究为监督、无监督和半监督学习提供了一个统一的框架。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Sat, 17 Dec 2016 11:07:24 +0800</pubDate>
    </item>
    <item>
      <title>教程 | 如何DIY一个《西部世界》的机器人接待员？</title>
      <link>http://www.iwgc.cn/link/3955982</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自TechCrunch&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;参与：Terrence、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有人选择看到这个世界的局限性，那就是死路一条。在这里，我们选择看到世界的可能性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW97Eu3kQ28xCXnW6b2iagC06Uh6BjBsfENYB3Tn6kStAWGrAjE6e6JqTNH8Sgvjicvlu3KHbAymEQAw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;回顾《西部世界》的第一季，我不得不说，Lisa Joy 和 Jonathan Nolan 对人工智能细致入微的理解真是让人印象深刻。那些幻想、幕后故事甚至在其他接待员上训练接待员的想法都给了真正的人工智能研究一些启示。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;建立一个西部世界的接待员有点像是把宜家的家具一点点拼装起来，然而在幻想上——这个方向并没有什么用。这里给出了 DIY 自己的西部世界机器人接待员的一些准则。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此外，我们说服了牛津大学和斯坦福大学的人工智能研究院和语义机器首席科学家 Daniel Klein 博士，请他谈了谈可以如何应对这些挑战。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;第一步：买一个波士顿动力的机器人&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;波士顿动力公司最先进的机器人 Atlas 需要这么多的改进，我甚至不会考虑这是骗人的。&lt;/span&gt;&lt;span&gt;Atlas 可以在各种不平的表面上走动，打开门，甚至在被击倒后站起来——但你肯定不会误认为这是人类。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;iframe class="video_iframe" data-vidtype="1" style="   z-index:1; " height="375" width="500" frameborder="0" data-src="https://v.qq.com/iframe/preview.html?width=500&amp;amp;height=375&amp;amp;auto=0&amp;amp;vid=l0185h5pbbu" allowfullscreen=""&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器人有 330 磅重，行走很笨拙，所以除非你只想建立一个有故障的皮克特警长并在某天打电话给他，否则你需要做一些大规模的改动。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于初学者，你必须找到一种实现人类精细运动技能的方法。我们的面部有 43 块肌肉，以惊人的方式来帮助人们交流和传达情绪。不幸的是，增加更多人的特征也会带来问题——会让它看起来更加恐怖（参考「恐怖谷理论」）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;要打造一个真正的人类模拟，你必须要有正确的皮肤温度，你必须搞定那些小的细节，哪怕是汗水。握着未经打磨的接待员的粗糙冷冰冰的手，会毁了整个经历的瞬间。当然，我们得承认整个计划具有很大挑战性，但是我们至少知道目标在哪里。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;第二步：归纳智能&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能需要大量的信息来完成一个单一的、明确的任务。我们用数据训练我们的机器数周，然后它们可以玩一个游戏或分类垃圾邮件。相比之下，即使只有有限的信息，人类也可以实现更多能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;想象一下，你只是因为触摸炉子上的煎锅而烧伤了你的手。如果你的结论是煎锅会烧伤人，那你可能就是一个不成功的 DeepMind 实验。这里最明显的答案是炉子上的一个锅烧伤了你，因为它被加热过——而过多的热可能会烧伤我们。计算机可能会选择不再触摸任何煎锅——这可太愚蠢了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Klein 教授解释说，解决这个问题有两种主要的方法。首先是从下到上，而另一个是从上到下。现在人工智能中的大部分工作是自下而上的。我们努力做更复杂的事情——比如从单词到句子到完全对话。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一种方法是输入规则，让系统找出如何自己实现所需结果的细节。我们从底部比从顶部做了更多的进步。找出可以如何从上到下有效地工作，然后你会发现你在某家技术公司有了至少七位数的薪资。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;第三步：看着人类寻找灵感&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW97Eu3kQ28xCXnW6b2iagC06iaYEibXYSuVmeqkWvibe6TxQXRarMWrBrW1lKlTlO3zZNVPBztzzFwfvg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;就像 Bernard 研究 Theresa 一样，我们可以从我们自己的物种收集很多。智力，无论是人的还是人工的，都需要信息和目标。我们可以模拟信息和目标与实用程序之间的相互作用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在旧金山的卡布奇诺的成本是 5 美元，但它的效用考虑到你可以做的没有卡路里的价值（或缺乏），你花在咖啡和你的后咖啡因生产力上的时间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从这里，建模决策就像为事物计算实用程序并询问哪个更高一样简单。引入一些博弈理论、一点理性选择，甚至一些行为经济学，你会越来越接近打造一个接待员的目标。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「数据、学习、记忆、计算和硬编码的目标能使智能有效，」Klein 教授说。「这对机器和人来说都是如此。人类的目标是短视的，我想让自己的生活中被满足，我们做出折中的决策，以最大限度地发挥这些功能。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在你开始怀疑自己也是一个接待员了吗？这只是个想法。我们努力模拟一切，特别是在更长的时间范围，因为世界是一个非常复杂和动态的系统——甚至对于我们最复杂的处理器来说也太复杂。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们的系统今天使用暴力来破解问题，」Klein 教授说。「人类会做更多的元计算（meta computation），思考要考虑什么。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今天最先进的技术是使用强化学习帮助一台计算机赢得围棋比赛。我们捕捉各种走子策略的效用，消除低效率，这就是我们想要的。重要的是，在像围棋这样的游戏中的硬编码假设是我们想赢！这个开始的假设很好地连接到剧中「基石」背景故事的想法（注：是指故事中机器人接待员人格成立所设定的基础）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;第四步：让接待员和其它接待员对话&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;让接待员在空闲时间互相交谈是从机器学习角度培训他们的一个很好的方式。同样，一些科技公司今天也使用模拟训练数据来加快训练过程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一件要记住的是，真正的人类不断在即兴发挥。一个只是运行一个静态目标函数的接待员不是很有趣。如贝叶斯认知（Bayesian cognition）这样容易适应的东西，天生适合接待员。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们可以把数据变成行为，」Klein 教授说。「同样的算法可以可怕，也可以伟大，伟大的例子甚至更多。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;世界存在于一系列不断变化的状态中，并且良好的人工智能需要能够实时响应以更新其偏好。增加输入的数量增加了复杂性和混乱——这两件事虽然听起来可怕，但实际上是相当必要的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;第五步：不要忘记幻想（reveries）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW97Eu3kQ28xCXnW6b2iagC06kGGgdPm5W4gLoUzO0bdDaHQQPTX64ViamXFmiayia23Ea9XDB9HicagvsA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后但并非最不重要的：幻想（reveries）。他们从紧急行为（emergent behavior）和相变（phase transitions）的想法剥离，这是对人工智能空间中的研究人员的真正挑战。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Klein 教授解释说：「如果你建立一组能力，比如说 A、B 和 C，并添加一种方式，让它们进行交互，比如说相加（+），你可以生成 A + B、B + C、C + A 等等这些你之前不能生成东西。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这也可以说是最小的记忆，看起来就像是无害的手势，但却可以破坏一个复杂的系统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;两主体主义（Bicameralism，与你说话的声音）已经被视为一种意识理论，但是这样的声音可能会强迫行为的涌现，这类似于幻想（reveries）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们看到了病毒意识本质的主题，」Klein 教授补充说，「我们看到同样的事情与想法，一个模因（meme）是一个病毒的想法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;蝴蝶效应解释了蝴蝶翅膀这样轻微的事物可能会以不可预见的方式极大地改变任何复杂的系统——无论是海洋潮汐还是认知。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;祝你在打造自己的西部世界接待员上好运。最后也祝人类好运，毕竟人类正变得越来越不重要了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，机器之心系今日头条签约作者，本文首发于头条号，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Sat, 17 Dec 2016 11:07:24 +0800</pubDate>
    </item>
    <item>
      <title>干货 | Nervana技术深度解读：使用Neon的端到端语音识别是如何实现的</title>
      <link>http://www.iwgc.cn/link/3941389</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Nervana&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：杨旋、张瑞宁、chen chen&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;语音是一种固有的即时信号。语音中所承载的信息元素在多个时间尺度上演变。在空气压强的影响下，同一个声源的频率只会发生几百上千赫兹的变化，所以我们可以利用声音去判断一个声源的位置，并把它与周围嘈杂的环境区分开来以获得传递的信息。语音的功率谱中的缓慢变化的部分就是音素（phoneme）的生成序列，其中音素是构成我们所说的词的最小单位。除此之外，其中由单词组成的序列的变化更缓慢，这些词就组成了短语和叙事的结构。然而，这些元素在时间尺度上没有严格的区分界限。相反，各种尺度的元素都混合在了一起，所以时间上下文是十分重要的，其中较为稀少的停顿就可以作为元素之间区分的界限。自动语音识别（ASR）系统就必须弄明白这种噪声多尺度数据流，将其转换为准确的单词序列。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在撰写本文时，当下最流行和成功的语音识别引擎采用了一种混合系统来构建。即同时将深度神经网络（DNN）与隐藏马尔科夫模型（HMMs），上下文相关电话模型（context-dependent phone models），n-gram 语言模型（n-gram language models），和一种维特比搜索算法（Viterbi search algorithms）的复杂变体进行混合使用。这个模型相当的复杂，需要一套精致的训练方法，以及相当多的专业知识来帮助搭建模型。如果说深度学习的成功能教会我们什么东西，那就是我们可以经常用一种通用的神经网络来替代复杂的，多维度的机器学习方法，这些神经网络经过训练以后可以用来优化可微分的代价函数（cost function）。这种方法（我们暂且把这种方法称为「纯正」的 DNN 方法），已经在语音识别上取得了巨大的成功。现在，一旦我们有了相当多的训练数据和足够的计算资源，我们就可以更加轻松地构建一个高水准的大词汇量连续语音识别（Large Vocabulary Continuous Speech Recognition (LVCSR)）系统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本文的目的是为了对如何使用 Neon 来建立一个使用「纯正」DNN 方法的语音识别系统提供一种简单的指导介绍，其中 DNN 遵循了 Graves 和 他协作者所倡导的方法，同时，百度的人工智能研究人员对其进行了进一步的开发，让其成为了一种完整的端到端的 ASR 管道（end-to-end ASR pipeline）。同时，作为对本博文的补充，我们将会开源我们实现的这个端到端的音识别引擎（end-to-end speech recognition engine）的代码。在其最初始形式中，系统使用双向循环神经网络（BiRNN）来训练模型以直接从频谱图产生转录，而不必显示地将音频帧与转录对齐。与之取代的是一种隐式对齐，我们采用了 Graves 的连接体时间分类（CTC）算法（Connectionist Temporal Classification ，CTC）来实现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然「纯正」DNN 方法现在允许使用具有最先进性能的 LVCSR 系统进行训练，但是显式的解码步骤 ： 将模型输出转换为单词的可感知序列，在评估期间仍然是十分关键的。解码的技术是多种多样的，我们通常同时使用加权有限状态传感器（weighted finite state transducers）和神经网络语言模型（neural network language models）。如果想要了解相关的内容，那么需要一篇更加深入的文章来进行介绍，而本文主要限于 ASR 管道的训练部分。如果需要的话，我们为读者提供一些额外的参考知识来以填补空缺，希望能给读者传达构建端到端语音识别引擎的完整视图。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;简单扼要的说，端到端语音识别流水线由三个主要部分组成：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 特征提取阶段，其将原始音频信号（例如，来自 wav 文件）作为输入，并产生特征向量序列，其中有一个给定音频输入帧的特征向量。特征提取级的输出的示例包括原始波形，频谱图和同样流行的梅尔频率倒频谱系数（mel-frequency cepstral coefficients，MFCCs）的切片。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 将特征向量序列作为输入并产生以特征向量输入为条件的字符或音素序列的概率的声学模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 采用两个输入（声学模型的输出以及语言模型）的解码器并且在受到语言模型中编码的语言规则约束的声学模型生成的序列的情况下搜索最可能的转录。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9Iicdl6w0e8yz3Cx1yLlo7iarvHtWXEAL6fxMvYWia79sb7GMiaQaicAWVNHs8ZIoRw9JP0qApwcVeOOQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;处理数据&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当构建端到端语音识别系统时，一套有效的加载数据的机制是十分关键的。我们将充分利用 Neon 1.7 版本中新添加的功能：Aeon，一个能够支持图像，音频和视频数据的高级数据加载工具。使用 Aeon 大大简化了我们的工作，因为它允许我们直接使用原始音频文件训练声学模型，而不必困扰于对数据显示地预处理过程。此外，Aeon 能让我们更加容易的指定我们希望在训练期间使用的光谱特征的类型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;提取数据&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通常，语音数据以一些标准音频格式的原始音频文件和一些包含相应转录的一系列文本文件的形式被分发。在许多情况下，转录文件将包含形如：&amp;lt;音频文件的路径&amp;gt;，&amp;lt;音频文件中的语音的转录&amp;gt;的行的形式。这表示所列出的路径指向包含转录的音频文件。但是，在许多情况下，转录文件中列出的路径不是绝对路径，而是相对于某些假定目录结构的路径。为了处理不同数据打包情况，Aeon 要求用户生成包含绝对路径对的「清单文件」（manifest file），其中一个路径指向音频文件，另一个路径指向相应的转录。我们将为读者介绍 Neon 的演讲示例（包括链接）和 Aeon 文档以获取更多详细信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除了清单文件，Aeon 还要求用户提供数据集中最长的话语的长度以及最长的转录的长度。这些长度可以在生成清单文件时被提取。比如可以使用当下流行的 SoX 程序去提取音频文件的时长。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们通过训练由卷积（Conv）层，双向复现（bi-directional recurrent (BiRNN)）层和完全连接（FC）层（基本上遵循「Deep Speech 2」，如示意图所示）组成的深层神经网络来建立我们的声学模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9Iicdl6w0e8yz3Cx1yLlo7iaotLPFeibgsffF0kcQXXBxicrRQ7SVZ24RRmuA0bvNAbiaRnuZcF5GhNvA/0?wx_fmt=png"/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除了在输出层使用 softmax 激活函数，我们在其它层都采用 ReLU 激活函数。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如图所示，网络采用光谱特征向量作为输入。利用 Aeon dataloader，Neon 可以支持四种类型的输入特性：原始波形，频谱图，mel 频率谱系数（mel-frequency spectral coefficients (MFCSs)）和 mel 频率倒频谱系数（mel-frequency cepstral coefficients (MFCCs)）。MFSCs 和 MFCCs 是从频谱图中导出的，它们基本上将频谱图的每个列转换为相对较小数量的与人耳的感知频率范围更相近的独立系数。在我们的实验中，我们还观察到，在所有其他条件相等的情况下，用 mel 特征训练的模型作为输入执行效果略好于用频谱图训练的模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;光谱输入被传送到了 Conv 层。通常，可以考虑具有采用 1D 或 2D 卷积的多个 Conv 层的架构。我们将利用可以允许网络在输入的「更广泛的上下文」（wider contexts）上操作的 strided convolution 层。Strided convolution 层还减少序列的总长度，这又显著减小了存储器的占用量和由网络执行的计算量。这允许我们训练甚至更深层次的模型，这种情况下我们不用增加太多的计算资源就可以让性能得到较大的改进。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Conv 层的输出被送到 BiRNN 层的栈中。每个 BiRNN 层由串联运行的一对 RNN 组成，输入序列在如图所示的相反方向上呈现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9Iicdl6w0e8yz3Cx1yLlo7iat2TG5oKyjk4MDRUqtymBcWZc8M2mx8bjTiczbLbjicdmPefBtRIWsM1Q/0?wx_fmt=png"/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;来自这对 RNN 的输出将被串接起来如图所示。BiRNN 层特别适合于处理语音信号，因为它们允许网络访问输入序列 [1] 的每个给定点处的将来和过去的上下文。当训练基于 CTC 的声学模型时，我们发现使用「vanilla」RNN 而不是其门控变体（GRU 或 LSTM）是有好处的。这主要是因为后者具有显着的计算开销。如 [2] 所讲，我们还对 BiRNN 层应用批次归一化（batch normalization），以减少整体训练时间，同时对总体字错误率（WER）测量的模型的精度几乎没有影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在每次迭代中，BiRNN 层的输出先传递给一个全连接层，然后转而将信息传递给 softmax 层。在 softmax 层中的每个单元都对应着字母表中描述目标词汇表中的单个字符。例如，如果训练数据来自英语语料库，那么字母表通常将包括 A 到 Z 的所有字符和任何相关的标点符号，也包括用于分离文本中单词的空格字符。基于 CTC 的模型通常还需要包括特殊的「空白」字符的字母表。这些空白字符促使模型可以可靠地预测连续的重复符号以及语音信号中的人为部分，例如，暂停，背景噪声和其他「非语音」情况。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此，对于给定话语的帧序列，该模型要为每帧生成一个在字母表上的概率分布。在数据训练期间，softmax 的输出会被传输到 CTC 代价函数（后文将详细论述），其采用真实的文本来（i）对模型的预测值进行打分，以及（ii）生成用以量化模型预测值的准确性的误差信号。总体目标是训练模型来提升在真实场景下的预测表现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;训练数据&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;根据经验，我们发现使用随机梯度下降法和动量与梯度限制配对法会训练出最优性能的模型。更深层的网络（7 层或更多）在大体上也有同样的效果。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们采用 Sutskever 等人实现的 Nesterov 的加速梯度下降法去训练模型。大多数模型的超参数，例如：网络的深度，给定层中的单元数量，学习速率，退火速率，动量等等，是基于现有的开发数据集根据经验选择出来的。我们使用「Xavier」初始化方法来为我们的模型中的每一层进行初始化，虽然我们还没有系统地调查过是否通过使用其他可取代的初始化方案，来比较实验的结果是否有所优化。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们所有的模型都使用 CTC 损失标准进行训练，对 CTC 计算法内部过程的详细解释超出了本博客的范围。我们将在这里提出一个简要概述，为了获得更深的理解，建议读者去阅读 Graves 的论文。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;CTC 计算法以「折叠」函数的动作为核心，该函数采用一系列字符作为输入，并通过首先去除输入字符串中的所有重复字符，然后删除所有「空白」符号来产生输出序列。&lt;/span&gt;&lt;span&gt;比如说，如果我们使用「_」表示空白符号，然后&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9Iicdl6w0e8yz3Cx1yLlo7iaQodpzEGZAPOFaf4iacr9ibrMIJZpFFibfpiauPoVBKP4EicAoxV2LOIA9VA/0?wx_fmt=png"/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;给定一个长度为 T 的话语和其对应的「ground truth」的转录，CTC 算法会构建「转置」的折叠函数，其定义为所有可能的长度为 T 的，折叠到「ground truth」转录上的字符序列。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;任意序列出现在该「转置」集合中的概率是可以直接从神经网络中的 softmax 输出计算出来的。然后将 CTC 成本定义为序列的概率和的对数函数，它存在于「转置」集合中。该函数对于 softmax 的输出是可区分的，这是反向传播中所要计算的误差梯度。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以一个简单示例来做说明，假设输入话语有三个帧，并且相应的转录本是单词「OX」。同样，使用「_」表示空白符号，折叠为 OX 的三字符序列集包含 _OX，O_X，OOX，OXX 和 OX_。&lt;/span&gt;&lt;span&gt;CTC 算法设置 &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9Iicdl6w0e8yz3Cx1yLlo7iamicRFu2zerDOTjVHYaE5zzSEicr8uMeEIM7o6dHiaFbx1ufCT0icPibxQiaA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P(abc) = p(a,1)p(b,2)p(c,3)，其中 p(u,t) 表示单元「u」, 时间 t（帧）时 softmax 模型的输出值。因此 CTC 算法需要枚举固定长度的所有序列，其折叠到给定的目标序列。当处理非常长的序列时，通过前向 -后向算法，枚举组合可以被有效的执行，这就非常接近采用 HMMs 方法的处理问题的思想。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;评价&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一旦模型训练完成，我们可以通过预测一段系统从未听过的语音来评估它的性能。由于模型生成概率向量序列作为输出，因此我们需要构建一个解码器（decoder）来将模型的输出转换成单词序列（word sequence）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;解码器的工作是搜索模型的输出并生成最有可能的序列作为转录（transcription）。最简单的方法是计算&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9Iicdl6w0e8yz3Cx1yLlo7iaU2B9IicCLEXK69GIbgt6zFzkyh2NUomhcMPa72ctibS7mcVLKx3tzZgg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中 Collapse（...）是上面定义的映射（mapping）。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管用字符序列训练模型，我们的模型仍然能够学习隐式语言模型（implicit language model），并已经能够非常熟练地用语音拼写出词语（见表 1）。通常在字符级别用 Levenshtein 距离计算的字符错误率（CERs）来测量模型的拼写性能。我们已经观察到，模型预测的很多误差是没有在训练集中出现过的单词。因此，可以合理地预计，随着训练集规模的增加，总的 CER 数值将继续改进。这个预期在深度语音 2（Deep Speech 2）的结果中得到证实，它的训练集包括超过 12000 小时的语音数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;table align="center"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); word-break: break-all;" align="center" valign="middle"&gt;&lt;p&gt;&lt;span&gt;Model output without LM constraints&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;没有 LM 约束的模型输出&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255); word-break: break-all;" align="center" valign="middle"&gt;&lt;p&gt;&lt;span&gt;「Ground truth」transcription&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;完全实况转录的结果&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;younited presidentiol is a lefe in surance company&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;united presidential is a life insurance company&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;that was sertainly true last week&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;that was certainly true last week&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;we’re now ready to say we’re intechnical default a spokesman said&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;we’re not ready to say we’re in technical default a spokesman said&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;表 1：模型对华尔街日报评估数据集的预测样本。我们故意选择了模型难以判断的例子。如图所示，加入语言模型约束后基本上消除了在没有语言模型的情况下产生的所有「拼写错误」。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然我们的模型显示了非常好的 CER 结果，模型的读出单词拼写（spell out words phonetically）的倾向导致了相对较高的单词错误率。我们可以通过加入从外部词典和语言模型得到的解码器来约束模型，以此改进模型的性能（WER）。根据 [3,4]，我们发现使用加权有限状态传感器（WFST）是一个特别有效的完成这项任务的方法。我们观察到 WER 数值在 WSJ 和 Librispeech 数据集上相对提高了 25％。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;表 2 列出了使用华尔街日报（WSJ）语料库训练的各种端到端语音识别系统。为了测试「苹果」（公司）与「苹果」（水果）的识别结果，我们选择仅用 WSJ 数据集训练和评估的系统的公开数据进行系统间的比较。然而，结果显示在同一数据集上训练和评估的混合 DNN-HMM 系统比使用纯深神经网络架构的系统表现更好 [6]。另一方面，结果显示当训练集的数据量更大时，纯深度神经网络架构能够实现与混合 DNN-HMM 系统相同的性能 [引用 DS2]。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;Reference&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;CER&lt;br/&gt;(no LM)&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;WER&lt;br/&gt;(no LM)&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;WER&lt;br/&gt;(trigram LM)&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;WER&lt;br/&gt;(trigram LM w/ enhancements)&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;Hannun, et al. (2014)&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;10.7&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;35.8&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;14.1&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;N/A&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;Graves-Jaitly (ICML 2014)&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;9.2&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;30.1&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;not reported&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;8.7&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;Hwang-Sung (ICML 2016)&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;10.6&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;38.4&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;8.88&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;8.1&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;Miao et al. (2015) [Eesen]&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;not reported&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;not reported&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;9.1&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;7.3&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;Bahdanau et al. (2016&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;6.4&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;18.6&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;10.8&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;9.3&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(205, 224, 223);" align="center" valign="middle"&gt;&lt;span&gt;Our implementation&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(205, 224, 223);" align="center" valign="middle"&gt;&lt;span&gt;8.64&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(205, 224, 223);" align="center" valign="middle"&gt;&lt;span&gt;32.5&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(205, 224, 223);" align="center" valign="middle"&gt;&lt;span&gt;8.4&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(205, 224, 223);" align="center" valign="middle"&gt;&lt;span&gt;N/A&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;表 2：我们只使用华尔街日报数据集来训练和评估各种端到端的语音识别系统的性能。CER（character error rate）指的是比较由模型得到的字符序列与实际转录的字符序列的字符错误率。LM 指的是语言模型。最后一列指的是使用附加技术（如重新评分、模型聚合等）解码的例子。&lt;/span&gt;&lt;br/&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;未来的工作&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;将 CTC 目标函数嵌入神经网络模型的语音识别模型，让我们初次看到了这种 纯正 DNN 模型的能力。不过，最近，所谓的基于注意机制（attention mechanism）增强的编-解码器（encoder-decoder）的 RNN 模型正在兴起，并作为用一种使用 CTC 标准 [4,5] 训练的 RNN 模型的可行的替代方案。基于注意机制的编-解码器模型与基于 CTC 标准的模型，都是被训练用于将声音输入序列（acoustic input）映射（map）到字符/音位（character/phoneme）序列上。正如上面所讨论的，基于 CTC 标准的模型被训练用于预测语音输入的每个帧对应的字符，并在逐帧的预测与目标序列序列之间搜索可能的匹配。与之相反，基于注意机制的编-解码器模型会在预测输出序列之前首先读取整个输入序列。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该方法概念上的优点是，我们不必假设输出序列中的预测字符是相互独立的。CTC 的算法基于这个假设，而该假设是毫无根据的——因为字符序列出现的顺序是与比之之前较早出现的字符序列是高度条件相关的。最近的研究工作显示，LVCSR 系统的基于注意机制的编-解码器模型相对于基于 CTC 标准的模型在字符出错率上有明显的改善 [4]。在我们这两种方法被整入语言模型之前进行评估，得出的评断是正确的，这也支持了基于注意机制的模型是比基于 CTC 标准的模型更好的声学模型的论断。然而，值得指出的是，当语言模型被用来确定单词错误率时，这种性能上的差异就消失了。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们正致力于建立 ASR 系统的基于注意机制的编-解码器网络的 Neon，竭诚欢迎各类参与。代码可以参见&lt;/span&gt;&lt;span&gt; https://github.com/NervanaSystems/deepspeech.git.&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em style="color: rgb(136, 136, 136);"&gt;&lt;span&gt;原文链接：https://www.nervanasys.com/end-end-speech-recognition-neon/&lt;/span&gt;&lt;/em&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 16 Dec 2016 11:40:09 +0800</pubDate>
    </item>
    <item>
      <title>开源 | 谷歌开源Land Lines：简单一笔为你匹配谷歌地球对应位置</title>
      <link>http://www.iwgc.cn/link/3941390</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自GoogleDevelopersBlog&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;新年将近，如果你不愿意亲自在寒冷的冬天里外出旅行，那么你可以尝试一下谷歌地球（Google Earth）。但地球这么大，你却不知道看哪里？没关系，谷歌近日又推出了一项神奇的新功能：Land Lines。你只需要简简单单画一笔，谷歌就能为你将这一笔和谷歌地球上的地理或建筑线条匹配起来，将你带到你意想不到的地方：东南亚群岛的海岸线、欧洲小镇的街角、南美横贯的河流……&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这一切只需要轻轻一画。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;体验地址：&lt;span&gt;https://lines.chromeexperiments.com&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该项目有两种体验方式。一是画（draw）——能帮你找到与你画的线匹配的卫星图像；二是拉（drag）——可以创建一条互相连接的河流、高速公路和海岸线的线条。下面是一个简单的演示：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_gif/KmXPKA19gW9Iicdl6w0e8yz3Cx1yLlo7iaAezXBn7X5YJ1o26FxiccEomnBvm6o8obxLIsWyBBcsNz7QLbMypwkfw/0?wx_fmt=gif"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这一切都运行在你的手机网页浏览器中，不需要任何服务器。（桌面 Chrome 浏览器也可使用。）据谷歌介绍，这些响应是通过机器学习、数据优化和 vantage-point tree 分析图像和存储该数据所得到的。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌解释说：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;我们组合性地使用了 OpenCV 的基于结构化森林（Structured Forests）机器学习的边检测和 ImageJ 的 Ridge Detection 库。这将最初的超过 5 万张高分辨率图像数据集减少到了能够代表这些线的形状的仅仅几千张图像，如下图所示。这样的处理以往需要花费几天时间，我们只用了几个小时就完成了。&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9Iicdl6w0e8yz3Cx1yLlo7iawDHEz35Zv6D0uTmzZDSnk9cgibbtVY2PPZbJAFbvMyTRs3bqVZzUnqQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;来自线条检测处理（line detection processing）的输出示例。其中主线以红色突出显示，而辅助线则以绿色显示。&lt;/span&gt;&lt;/em&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在绘画实验中，谷歌将结果数据存储到了 vantage-point tree 中。这让该应用可以有效地在所有图像上运行手势匹配（gesture matching），并在毫秒级的时间内给出结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9Iicdl6w0e8yz3Cx1yLlo7iaTWWpWggibvIFAuzvCQzEs2O3gWicHktdWVUYfLsVgb8kc78bUhnkz2OQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;使用 vantage-point tree 的一个早期的手势匹配样本，其中右边是画出的输入，而左边则是最接近的结果。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9Iicdl6w0e8yz3Cx1yLlo7iaqnT6eqGRgJM7aC9mFKiaWLhZthePNwkL82mE5LnoibicWA0OlToTBouqQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;另一个用户手势分析的示例，其中右边是画出的输入，而左边则是最接近的结果。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该项目是与黑客兼艺术家 Zach Lieberman 合作开发的。Land Lines 是一个大型视觉数据连接主题探索实验。开发团队表示他们在他们的开发过程中采用了多种机器学习库。Lieberman 还写了一份有关的学习经历，该项目的代码也已经开源，相关链接如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Lieberman 的经历：&lt;span&gt;https://developers.google.com/web/showcase/2016/land-lines&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Land Lines 开源地址：&lt;span&gt;http://github.com/ofZach/landlines/&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;vantage-point tree 开源地址：&lt;span&gt;https://github.com/fpirsch/vptree.js&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;OpenCV Structured Forests 机器学习：&lt;span&gt;http://docs.opencv.org/3.1.0/d0/da5/tutorial_ximgproc_prediction.html&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;ImageJ 的 Ridge Detection 库：&lt;span&gt;http://imagej.net/Ridge_Detection&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 16 Dec 2016 11:40:09 +0800</pubDate>
    </item>
    <item>
      <title>学界 | IEEE发布人工智能道德准则设计，确保人工智能为人类服务（附草案）</title>
      <link>http://www.iwgc.cn/link/3941391</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自TechCrunch&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：Jane W&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;随着人工智能应用的日益普及，对人工智能所涉及到的法律、社会、伦理和道理问题也正在成为一个越来越值得关注的话题。近日，电气和电子工程师协会（IEEE）发布了世界首个人工智能道德准则设计草案《Ethically Aligned Design》。该草案目前仍在意见征求中，草案 PDF 版本可点击文末「阅读原文」下载。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;专业技术协会 IEEE 认为，有道德标准设计的人工智能系统能够造福全人类并且避免算法偏差，但是技术行业缺乏对道德的归属感和责任感已经成为阻碍它发展的一个因素。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicr33MwRF3MYPqDITzNX5zhRRzang7dNX0FrcFVP0iaHvsg3XBr7mA27O0lKAESia5FNyPNB50Pgs6w/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;近日，IEEE 发布了第一个框架文件版本，希望它能引导行业走向光明，并帮助技术人员建立和睦有益的自治系统，而不是认为道德与他们没有关系。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该文件称为「道德准则设计（Ethically Aligned Design）」，它基于 100 多名在人工智能、法律、伦理、哲学和政策领域工作的学术界、科学界、政府和企业部门的「思想领袖」，包括了一系列详细的建议。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;IEEE 希望它能成为人工智能/自治系统（AS）技术专家的重要参考文件，因为自治技术在未来几年内会进入越来越多的系统。它也邀请了有关各方面对该文件做了反馈——IEEE 全球倡议网站（The IEEE Global Initiative』s website）有标准的提交指南模板。网站声明所有的反馈意见都将公开发布，这些反馈应不晚于 2017 年 3 月 6 日提交。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;网站地址：&lt;span&gt;http://standards.ieee.org/develop/indconn/ec/autonomous_systems.html&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该组织更广泛的希望是能够通过创造共识和促进开发实现道德目标，为 IEEE 标准提出基于道德准则设计概念的倡议。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「通过为技术专家提供同行推动的、实用的建议，以创建符合道德标准的自治和智能的产品、服务和系统，我们可以超越与这些技术相关的恐惧，为人类的现在及将来带来有价值的福利，」IEEE 标准协会（IEEE Standard Association）常务董事 Konstantinos Karachalios 在一份声明中说。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这份 136 页的文件分为一系列章节，从一般原则开始——例如需要确保人工智能尊重人权、运作透明，以及人工智能是否为自动决策负责——然后再转到更具体的领域，例如如何将「人类准则或价值观」融入自治系统，如何解决潜在的偏见，如何达成信任，以及如何从外部评估并实现价值校正。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一部分讨论指导伦理研究和设计的方法论——与其它问题一起（例如工科学位的常规课程不包含伦理学），在这里，技术行业缺乏对道德的所有权和责任感被认为是一个问题。IEEE 还指出实现伦理人工智能的其它问题，例如自治系统缺乏一个独立的审查组织来监督算法操作，以及在创建算法时使用「黑箱组件（black-box component）」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;IEEE 也提到，一个帮助技术行业克服道德盲点的建议是确保那些建立的自治技术覆盖「多学科和多样化的群体」，以便涵盖所有潜在的伦理问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;它还讨论了制定「监督智能和自治技术的制造过程」的标准，以确保受众用户不被自主行为伤害。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在监督产品是否符合道德标准时，要建立「独立的国际协调机构」，并且监督应该时刻存在，无论是在产品发布时还是在其发展并与其它产品交互时。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「当构建可能影响人类安全或健康的系统时，仅仅假定系统的工作方式是不够的。工程师必须确认和评估黑箱软件所涉及的道德风险，并在可能的情况下实施应急策略，」IEEE 写道。「技术专家应该能够通过透明和可追溯的标准来描述他们的算法或系统要做什么。在我们力所能及的范围内，它应该是可预测的，但考虑到人工智能/自治系统的性质，它可能更需要具有追溯性（retrospective）和缓解导向性（mitigation oriented）。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「类似于航空领域的飞行数据记录仪，这种算法的可追溯性能够提供导致特定可疑或危险行为的算法参考。即使这些过程仍然有些不透明，技术人员也可以寻求间接验证结果和检测危害的方法。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;它的最终结论是，因为决策过程的不透明性以及检查或验证这些结果具有困难性，工程师「只有在非常谨慎和伦理关怀」的情形下部署黑箱软件服务或组件。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;文件中另一部分——有关通用人工智能的安全性和有益性——也警告说，随着人工智能系统越来越有能力，人工智能「无法预期或无意识的行为会越来越危险」，而提高安全性到通用级别会使未来的人工智能系统面临困境。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「在开发和部署日益自主和强大的人工智能系统时，研究人员和开发人员将面临越来越复杂的伦理和技术安全问题，」文件指出。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该文件还涉及到对由个人数据支持的人工智能系统固有的不对称性——从这个角度讲，该技术获得的收益不是平均分配的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「人工智能和自治系统（AI/AS）驱动了算法经济，它们可以广泛访问我们的数据，但我们仍然与这个来源于生活发现的收益相脱离，」它提到。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「为了解决这种不对称性，人们有必要定义、访问和管理他们的个人数据，作为他们个人身份信息的管理人。关于收集个人信息的类型，还需要定义新参数加以规范。未来应建立对有限具体数据交换的知情权和同意权机制，而不是长期牺牲信息资产。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;原文链接：https://techcrunch.com/2016/12/13/ieee-puts-out-a-first-draft-guide-for-how-tech-can-achieve-ethical-ai-design/&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 16 Dec 2016 11:40:09 +0800</pubDate>
    </item>
    <item>
      <title>资源 | 谷歌开源机器阅读理解数据集MC-AFP</title>
      <link>http://www.iwgc.cn/link/3941392</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自GitHub&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;MC-AFP 是一个基于公众可用的 Gigaword 数据集（AFP 部分）生成的机器理解数据集。创造这样数据集的技术在论文「Building Large Machine Reading-Comprehension Datasets using Paragraph Vectors」中有所报告。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们生成了一个大约有 2 百万样本的数据集，在上面估算人类的准确率大概为 90%。一种结合了循环神经网络的表征能力与全连接多层网络判别能力的全新神经网络架构在此数据集上取得的最好结果是：83.2% 的准确率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;压缩包中附上的是加密的 MC-AFP 数据集以及密码。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;项目地址：&lt;/span&gt;&lt;span&gt;https://github.com/google/mcafp&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;论文：Building Large Machine Reading-Comprehension Datasets using Paragraph Vectors&lt;/span&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：我们提出的技术对机器阅读理解任务有双重贡献：使用 paragraph-vector 模型创造大型机器理解（MC）数据集的技术；一种全新的、混合的神经网络架构，它结合了循环神经网络的表征能力与全连接多层网络的判别能力。我们使用 MC-数据集生产技术建立了一个大约 2 百万样本的数据集，在上面我们凭借经验判断出了人类水平（大约 91）的准确率，以及各种计算机模型的表现。在我们试验过的所有模型中，我们的混合神经网络架构获得了最高的表现（83.2）的准确率。该架构与人类水平之间的差距为未来模型的提升提供了足够的空间。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;论文地址：&lt;span&gt;https://arxiv.org/pdf/1612.04342v1.pdf&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 16 Dec 2016 11:40:09 +0800</pubDate>
    </item>
    <item>
      <title>学界 | Yann LeCun提交ICLR 2017论文：使用循环实体网络跟踪世界状态</title>
      <link>http://www.iwgc.cn/link/3941393</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自arXiv.org&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：杜夏德&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;论文标题：TRACKING THE WORLD STATE WITH RECURRENT ENTITY NET WORKS&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9Iicdl6w0e8yz3Cx1yLlo7iah9OcsiacMU7QP2ibIE0A0TYZRQIhxsrq9ZHloUKxryT1NkdK7SbkKSNQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：我们介绍了一种新模型：循环实体网络（EntNet/Recurrent Entity Network）。它配备了一个动态长期记忆（dynamic long-term memory），能让它在接受新数据时维持和更新世界最新状态的表征。在语言理解任务中，它不仅能像记忆网络（Memory Network（Sukhbaatar et al., 2015））那样能在被要求回答一个问题或者给出回应时推理，还可以一边阅读文本一边进行推理。就像神经图灵机（Neural Turing Machine）或者可微神经计算机（Differentiable Neural Computer，Graves et al., 2014; 2016）那样，它能维持一个固定大小的记忆并能学习去执行基于位置和内容的读取和写入任务。然而，与那些模型不同的是，它有一个简单的并行架构，该架构包含了几个记忆位置，这些位置能实现同时更新。该 EenNet 在 bAbI 任务中实现了新的最佳表现纪录，同时也是首个能在一万个训练样本场景中解决所有任务的方法。我们还证明了它可以解决一个需要大量事实支持的推理任务，而其它方法无法解决这个问题，同时它也可以泛化到其训练范围之外，也能被实际地用到 Children』s Book Test 等大型数据集中，在这项任务上，它的表现十分具有竞争力，能一次阅读一个故事。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;论文地址： &lt;span&gt;https://arxiv.org/pdf/1612.03969v1.pdf&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Fri, 16 Dec 2016 11:40:09 +0800</pubDate>
    </item>
    <item>
      <title>重磅 | 谷歌大脑养成记：从识别猫到突破性机器翻译</title>
      <link>http://www.iwgc.cn/link/3928460</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自NYT&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;em style="color: rgb(136, 136, 136); font-size: 12px;"&gt;谷歌如何使用人工智能来改进谷歌翻译等许多谷歌服务？《纽约时报》杂志今日发布了一篇重磅长篇《The Great A.I. Awakening》全面解读谷歌利用机器学习重塑自身的战略。机器之心编译时进行了适当的删减。&lt;/em&gt;&lt;br/&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;序言：你即你所读&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;十一月一个周五的晚上，东京大学著名人机交互教授 Jun Rekimoto（暦本純一）正在准备演讲，他开始留意到社交媒体上出现了一些奇特的博文。谷歌公司颇受欢迎的机器翻译服务已经突然有了大幅提升。Jun Rekimoto 开始亲自测试这一服务。结果让他惊讶不已。他在一篇博文中写下了一些发现。他比较了两个版本的《伟大的盖茨比》（一个 1957 年 Takashi Nozaki 的版本，一个是 Haruki Murakami 近期的修订版本）中的几个句子，选择了谷歌翻译能够翻译的句子。他后来对我解释道，Haruki Murakami 的翻译非常优美，但显然是 Murakami 风格的。谷歌翻译后的日文尽管有点小小的不自然，但是，读起来感觉更加易懂（transparent）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;接着，博文的第二部分从另一个方向（日文到英文）检查了谷歌翻译。他把自己翻译的海明威《乞力马扎罗的雪》的开头输入进去，让谷歌翻译成英文。结果发现翻译的准确度难以置信。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Rekimoto 将自己的发现放在了 Twitter 上，几个小时后，数以千计的人也贴出了自己的实验结果。一些翻译结果很赞，另一些的翻译结果颇有喜剧效果。每个人都好奇：谷歌翻译是怎么变得如此惊艳的？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌公司的人工智能研究机构谷歌大脑（Google Brain）成立于五年前。成立原则是：通过试错熟悉周围世界的人工「神经网络」或许会发展出类似人类的灵活能力。这个概念不是新东西。不过，其大部分历史，在绝大多数计算机科学家看来，有些狼藉甚至神秘。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管如此，2011 年以来，谷歌大脑已经证实深度学习方法可以解决传统手段无法解决的难题。语音识别之前并不理想，直到谷歌大脑更新了这一技术；机器学习的应用在谷歌移动平台安卓上的表现堪比人类。同样，图像识别也是硕果累累。不到一年前，谷歌大脑首次开始充满热情地更新整个产品线。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;翻译工具声名鹊起的那一年是 2006 年，打那时起，它就成为谷歌最可靠也最受欢迎的资产；月用户量达 5 亿多人，每天需要进行 1400 亿词的翻译。它不仅自成一体，也是谷歌邮件、浏览器以及其他产品的一部分，是该公司数字业务中浑然天成的一部分。Pichai 解释说，不仅仅是难民危机，公司也估计翻译的地理政治重要性：他身后的屏幕上出现了一幅图表，一个陡峭的曲线表明最近阿拉伯语和德语之间的翻译需求翻了五番。谷歌翻译团队一直在稳定地为产品添加新的语言和功能，不过，过去四年的质量提升已经明显放缓。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;直到今天，翻译工具引进了人工智能技术。首轮尝鲜的语言包括英语、西班牙语、法语、葡萄牙语、德语、中文、日语、韩语和土耳其语。接下来还有上百种语言——大概每个月处理八种，直至明年年底。翻译工具的焕然一新仅花了九个月的时间。人工智能系统一夜之间取得的成果相当于旧的技术一辈子成果的总和。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌决定以人工智能为中心的策略也反映出整个业界范围内的机器学习热。过去四年中，特别是谷歌、Facebook、苹果、亚马逊、微软和百度这六家公司已经启动了人工智能人才争夺战，特别是争夺大学里的人才。公司许诺的资源和自由已经让顶尖学术机构的人才越来越少。硅谷谁人不知 Mark Zuckerberg 用电话、视频聊天等糖衣炮弹亲自督导公司最想要的研究生。诱人的七位数年薪并非罕见。参加这一领域最重要的学术会议的人员已经翻了四倍。利害攸关的不仅是渐进创新，还要控制住能够代表未来全新计算平台的东西：无处不在的人工智能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;Part 1:学习的机器&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1. 大脑的诞生&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然 Jeff Dean 的职称是高级研究员（senior fellow），但却是谷歌大脑实际上的负责人。作为医疗人类学家与公共健康流行病学专家的儿子，Dean 在世界多个地方长大——明尼苏达州、夏威夷、波士顿、阿肯色州、日内瓦、乌干达、索马里、亚特兰大。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在高中和大学的时候，他写的软件被世界卫生组组所使用。从 1999 年开始，他就加入了谷歌，从此他几乎插手了谷歌的每一个重大业务中的核心软件系统。谷歌公司文化的一个可爱伪影就是 Jeff Dean Facts，模仿「罗礼士的真相」写下：Jeff Dean 的 PIN 是 pi 的后四位；在贝尔发明电话之后，他看到有一通 Jeff Dean 的未接电话；在系统最大等级是 10 的时候，Jeff Dean 提升到了 11 级（这一个确实是真的）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2011 年的一天，Dean 走进谷歌的休息区碰见了吴恩达。当时吴恩达还是斯坦福大学计算机科学教授，也是谷歌的顾问。吴恩达告诉了 Dean 关于 Project Marvin 的事，这个项目是吴恩达最近帮助建立的实验「神经网络」的一次内部尝试。Dean 自己也在 1990 年在明尼苏达大学上学时做过简单版本的神经网络。如今，研究神经网络的学术人员 5 年来又开始发展，从屈指可数的几个增长到了几十位。吴恩达告诉 Dean 由谷歌神秘部门 X 实验室正在做的 Project Marvin 已经取得了一些惊人成果。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Dean 对此非常感兴趣，愿意在此项目上付出「20%」的工作时间，也就是期望每个谷歌员工在自己核心工作之外的项目上付出的工作时间。不久之后，他建议吴恩达让另一个有神经科学背景的 Greg Corrado 加入进来。在春末，吴恩达最好的毕业生之一 Quoc Le 也加入了进来，成为了第一个实习生。然后，一些谷歌工程师喜欢称 Project Marvin 为谷歌大脑。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因为人工智能一词是 1956 年才被首次提出，一批研究员一直以来在思考创造人工智能的最佳途径，写出很大的、综合的程序，能同时展示逻辑推理与世界上足够知识的规则。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;例如，如果你想要从英语翻译到日语，你要把英语的所有语法规则编程到计算机，然后是牛津英语词典中的所有定义。接下来你还要把日语的语法规则与单词编程，只有所有的语句用源语言输入之后才能让它把语句翻译成目标语言。这种观念通常被称为符号人工智能，因为它对认知的定义是基于符号逻辑的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但这种老旧的方法主要有两个问题。第一个就是这样做非常耗费人工时间。第二个就是这种方法只能处理规则和定义都非常清晰的问题，比如数学问题和国际象棋。对于翻译来说，这种方法完全失效，因为词语不仅只有词典上定义，而且语言的使用中常常有很多特殊用法，尽管有很多语法规则。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;iframe class="video_iframe" data-vidtype="1" style="   z-index:1; " height="375" width="500" frameborder="0" data-src="https://v.qq.com/iframe/preview.html?width=500&amp;amp;height=375&amp;amp;auto=0&amp;amp;vid=e0355310x9a" allowfullscreen=""&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;一份 1961 年的文摘强调人工智能研究的前提：如果你可以编程让计算机模拟高级的认知任务如数学和象棋，那么你终将找到让计算机实现模拟意识的途径。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个系统所能做到的事情是有限的。20 世纪 80 年代，卡内基梅隆大学的一位机器人方面的研究员指出，让计算机去做那些成人能够做到的事情很容易，但是让它们去做那些 1 岁孩童做的事情几乎是不可能的，像是拿着一颗球，或者是辨别车辆等。在 20 世纪 90 年代前，计算机象棋方面取得了一些进展，但我们离强人工智能还很远。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌大脑是首个投资人工智能所能呈现的可能的重大商业机构。Dean、Corrado 和吴恩达用兼职时间工作，协作实验，但他们很快就取得了进展。他们从近期的理论基础以及上世纪 80 年代、90 年代的思路中获取设计灵感，并利用公司无与伦比的数据资源和大量计算基础设施，在大量的银行标记数据（例如，准确录音的语音文档）上构建网络，结果计算机的回应和真实情况实现了很好的匹配。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Dean 相当保留地说，「进化中动物发育出眼睛是一大进步。」当时，我们像往常一样坐在一间带有白板的会议室，他在白板上密密麻麻写上谷歌大脑的时间轴，以及与近期神经网络的历史拐点的关系。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「现在计算机有了眼睛，我们可以围绕现有的能力建造眼睛从而理解不同的难题。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他们建造的这些能力看起来很简单，但影响很大。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicr33MwRF3MYPqDITzNX5zhT1DuUhcFWc3IzJz4JZYsH5qY2ojdHOMmcR4JRouY5wMDZUCliaRZMiaA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图：Geoffrey Hinton&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2. 想像不到的实习生&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Dean 说，在谷歌大脑诞生的一两年左右，该部门在开发一岁儿童智能水平的机器上取得非常好的结果。其语音识别团队将他们的旧系统和神经网络结合了起来，实现了近 20 年来最好的提升。他们的系统的物体识别能力也提升了一个数量级。这并不是因为谷歌在这一年突然想出了什么突破性的方法，而是谷歌开始向其中投入更为显著的资源和人才。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;作为当时一些概念的提出者和优化者，Geoffrey Hinton 在谷歌大脑成立的第二年加入谷歌大脑，和吴恩达共事（吴恩达现在在百度领导着 1300 人的人工智能团队）。当时，Hinton 只想离开其在多伦多大学的岗位 3 个月，所以因为一些合同上的原因他的身份是实习生。在「实习」培训期间，Hinton 还问了「什么是 LDAP（一种用户登录方法）？」这样的问题。那里有很多 25 岁左右的聪明学生一起培训，他们只是对深度学习有所耳闻而已，他们会问：「这个老头子是谁？为什么他在这里实习？」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Hinton 说：「在午餐时间，有人大叫：『Hinton 教授，我上过你的课！你在这里做什么？』自那以后，一切都变好了。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;几个月后，Hinton 带着两个学生在 ImageNet 图像识别竞赛上展现出了真正激动人心的成果。谷歌很快就接触了 Hinton，要给他和他的学生工作邀请。他们接受了。Hinton 说：「我认为他们对我们的知识产权感兴趣，结果发现他们感兴趣的是我们。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Hinton 来自一个老式的英国家庭，希望在天文学或流体动力学领域做出一些小的贡献。他有一位伟大的曾曾外祖父乔治·布尔——计算机基础的布尔逻辑的提出者，还有一位曾曾祖父是著名外科医生，他的父亲是一位有冒险精神的昆虫学家，他的叔叔是洛斯阿拉莫斯国家实验室研究员……他在剑桥和爱丁堡上学，然后在卡内基梅隆任教，最后落脚多伦多大学，并在那里度过了他的半生时间（他的研究工作得到了加拿大政府的大力支持）。我在当地的谷歌办公室拜访了他，他会说一些奇怪的话，比如说：「计算机会比美国人先理解讽刺。」&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自 60 年代末 Hinton 在剑桥的本科阶段以来，他就一直在研究神经网络，被视为这个领域的先驱。但在那个时候，当他谈论机器学习时，人们看他就好像在谈论托勒密球或水蛭。那时候神经网络被当作是未经证实的愚蠢想法。造成这种看法的主要原因是当时一个被炒作过度的项目：Perceptron（感知器）——康奈尔大学心理学家 Frank Rosenblatt 在 50 年代末开发的一个人工神经网络。该研究的资助者美国海军预期其「能走路、说话、看见、书写、复制自己和意识到自己的存在」。结果没让任何人满意。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;美国的人工智能元老 Marvin Minsky 也在他 1954 年普林斯顿的论文里研究过神经网络，但自那以后，他渐渐地就对 Rosenblatt 对神经范式的夸张说法感到厌倦了（他们当时也在竞争美国国防部的资金）。后来，Minsky 和他的 MIT 同事出版了一本书，证明有一些非常基本的问题是感知器无法解决的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Minsky 对感知器的批评只扩展到了一层（layer）的网络，而后来，他却又阐释了和当代的深度学习非常相似的思想。但那个时候 Hinton 已经明白使用很多层的网络可以执行复杂的任务。对于神经网络的最简单的描述是：基于发现数据中模式的能力来进行分类和预测。如果只有一层，你只能发现一个简单模式；有更多的层时，你甚至能发现模式的模式。比如图像识别，现在这项任务依赖于一种被称为「卷积神经网络」的技术（该技术是由 Yann LeCun 在其 1998 年的开创性论文中提出的，他是 Hinton 的博士后）。该网络的第一层学习非常简单的「边（edge）」，意味着一个 off-pixel 之后跟着一个 on-pixel，或相反。后续的每一层都会在前一层中寻找模式。边的某一个模式可能是圆或三角形，而圆或三角形的模式又可能是一张脸……这种技术有点类似于人类视觉系统处理到达眼睛的信息的方式。在每一个感知步骤，不重要的细节会被丢弃。如果边、圆、三角形之类的模式能够组合成一张脸，那么我们的目的就达到了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;iframe class="video_iframe" data-vidtype="1" style="   z-index:1; " height="375" width="500" frameborder="0" data-src="https://v.qq.com/iframe/preview.html?width=500&amp;amp;height=375&amp;amp;auto=0&amp;amp;vid=k0355veznol" allowfullscreen=""&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;多层的深度神经网络的问题在于试错（trial-and-error）的部分会随着深度的增加而越来越复杂。这就像让孩子学习把玩具放进身边的箱子 A，一下子就学会了。如果让他学习带着玩具走过一段很多分支的路然后放进 A 箱，那就可能会在中间走错路。怎么让机器学会这样复杂的指令呢？为了解决这个问题，Hinton 及其同事在 70 年代末和 80 年代的停滞期发明（或者说重新发明）了一个解决方案，然后计算机科学家对神经网络的兴趣有了短暂的恢复。Hinton 说：「人们对此感到兴奋，但我们炒作过度了。」不久之后，计算机科学家又继续将 Hinton 看作是怪人和神秘主义者了。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但这些思想却受到了哲学家和心理学家的欢迎，他们将其称为「联结主义（connectionism）」或「并行分布式处理（parallel distributed processing）」。Hinton 说：「少数几个人的想法就让这个思想继续燃烧，这是一个不错的神话。在人工智能领域这确实是事实，但是在哲学领域，很多人相信这是正确的，他们只是不能实践。」尽管 Hinton 得到了加拿大政府的资助，但他自己也不能做到。「那时候的计算机算力和数据都不够。我们这边的人常常说：『呃，如果我有一台真正大的机器，它就有效果。』这可不是什么很有说服力的论据。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3. 深度学习的深度解释&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人脑中神经元的平均数量的数量级大概是 1000 亿。其中每一个神经元都与其它 10000 个神经元相连，这意味着突触的数量是在 100 万亿到 1000 万亿之间。我们目前仍然远远不能构建那么大规模的网络，但谷歌大脑的投资已经帮助实现了大约小鼠大脑的人工神经网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了理解为什么规模会如此重要，你首先要理解这项技术的细节。有些人认为人工智能可以直接从图书馆或网络上读取理解知识，但事实并非如此。它们的工作是在数据中寻找模式——先是基本模式，然后寻找更复杂的模式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果这个简短的解释不够说明问题，没有技术背景的读者可以阅读下一节关于猫的故事（当然这一节也有猫）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;假设你要在老式的符号式人工智能模型上编程一个猫识别器。那么你需要花大量的时间来帮机器定义什么是「猫」——四条腿软软的毛、尖尖耳朵喵喵叫……所有这些信息组合起来构成了一只猫。然后你向其展示一张图片用于识别。首先，该机器需要分解图片中不同的元素，然后再将这些元素和它记忆中的信息进行比对。如果有四条腿、尖耳朵、有胡须、有尾巴、表情傲慢，那么这就是一只猫。但是这个模型却不能识别苏格兰折耳猫——这种有基因缺陷的猫的耳朵耷拉在头上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在让我们来尝试用神经网络识别猫。我们并不会人工编写猫的定义，它们的定义存在于大量互连的「开关」之中，就像一条带有大量分岔路的道路。在这团开关的一边是输入的图片，在另一边则是对应的输出标签。然后你让网络自己通过调整其中的每一个开关来将一个输入映射到对应的输出。这个训练过程就像是走隧道迷宫一样，目的就是要将输入和合适的输出连接到一起。训练数据越多，隧道的数量和复杂性就越大。一旦训练完成，这团开关之中就有了大量的隧道，可以在其从未见过的数据上做出可靠的预测，这就是所谓的「监督学习」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为什么这样的网络需要如此之多的神经元和数据呢？因为从某种程度上讲，该网络的工作方式就像是一种「机器民主」。可以假想你想要计算机进行 5 种分类，你的网络由数亿个神经元「投票人」组成，他们可以进行 5 个选项的投票：猫、狗、蜘蛛猴、勺子和除颤器。然后你拿出一张图片问：这是猫、狗、蜘蛛猴、勺子和除颤器中的哪一个？投票者开始投票，然后网络统计员根据大多数的意见认为这是狗。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然后你告诉他：「不对，这是猫。再投一次。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然后，统计员回头检查哪些投了猫，哪些选了其它的。选了猫的投票者获得了加权——「一票可当两票用」（至少在选择猫的时候，选择其他分类时权重可能不同）；这样不断调整知道得到正确的答案。所以重要的不是单个神经元的票，而是整个投票的模式。你的投票者越多，你就能获得越多的模式。如果你有数百万个投票者，你就能获得数十亿种模式。每一种模式都可以对应一种结果，这些不同的模式归类成不同的类别。训练的数据越多，网络就越了解一种模式属于哪一个类别，就能在未来遇到没有标注的图片时做出更准确的分类。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;计算机科学领域对这些思想有如此大的抵触的部分原因是其输出只是基于模式的模式（patterns of patterns) 的预测，这不会是完美的，而且这样的机器也不能为你定义到底什么是一只猫。只有当它看到一只猫时，它才能知道那是猫。但这个方法的最主要缺点还是数据量。要让神经网络理解一只猫是在懒洋洋晒太阳还是躲在阴影里注视世界，我们需要给神经网络送入大量大量的数据，需要大量大量的投票者。而这是很难满足的需求。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;值得一提的是，神经网络的概率性本质使其无法胜任某些任务。但有些情况我们又需要它完美，比如自动驾驶汽车的应用。但这不是唯一的缺陷。监督学习是一种基于有标签数据的试错过程。也就是说，机器的学习使用了人类最先设计的分类，这个过程有很大程度上的人类参与。如果你的训练数据存在对女性或少数族裔的偏差，那么最后得到的模型也会是有偏见的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4. 猫识别论文&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在最初的一两年，谷歌大脑设计出了具有 1 岁孩童智力的机器，这些努力让其最终从 X 实验室毕业，进入了公司更宽阔的研究中。（谷歌 X 负责人曾提到谷歌大脑曾支付过 X 的所有花费）。而那时的谷歌大脑团队依然不足 10 人，也不清楚最后会得到什么。但即使如此，他们仍在思考接下来会发生什么。人的思想不需要多少时间就能学会识别球和其它东西，时间或长或短。然后，开始进军语言。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌大脑在这个方向迈出的第一步是一篇关于猫的论文，也让谷歌大脑出名了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这篇论文证明的是带有十亿「突触」连接的神经网络（要比当时公开的任何神经网络都要大数百倍，当然也要比我们大脑小无数数量级）能观察原始的未标记数据，从而为自己挑选出高级的人类概念。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌大脑研究员像网络展示了 YouTube 视频的数百万张静止图片，无论是翻滚的猫，还是面部清楚的猫，神经网络会先剥离出一个稳定的模型，能毫不迟疑地识别出这是猫。机器之前从未被编程过有关猫的先验知识，它直接接触世界、为自己抓取想法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当时大部分的机器学习还受限于标记数据的质量。猫识别论文证明机器也能过处理原始为标记数据，即使这些数据人类之前从未建立先验知识。这不仅是猫识别研究上的重大进展，也是整个人工智能的重大进展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这篇猫论文的第一作者是 Quoc Le。他在越南顺化城边长大，父母都是农民，家中甚至没有电。但艰苦的环境没有埋没 Quoc Le 的数学天赋，他很小就被送到科学院学习。在上世纪 90 年代后期，他还在学校中的时候，他尝试开发了一个聊天机器人。他想看看这到底有多难。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「但事实上，」他对我悄悄说道，「这实在是难。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Quoc Le 从越南的农村一路走来，进入了堪培拉的澳大利亚国立大学。在那里，他进行了人工智能的一些研究。时间主导的方法，例如给机器传递边缘这样的概念，让他感觉有点像是作弊。Quoc Le 当时并不知道，这一领域当时在全世界有几十位学者正在做着同样的研究，很多人都不约而同想到了机器可以从头开始学习。在 2006 年，Quoc Le 在德国大学城 Tübingen 的马克斯·普朗克生物控制论研究所任职。在一个读书小组中，他接触了 Geoffrey Hinton 的两篇论文。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「当时出现了一次很大的争论，」他对我说道。「一次非常大的争论。」我们坐在一个小型会议室里，一个狭窄的有着很高天花板的空间，配备了一个小桌子和两个白板。他看着他在他背后白板上画的曲线，轻声说道，「我从没有见过这样激烈的辩论。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他记得他在读书小组中站起来发言，「这就是未来。」他表示，发表这种言论在当时那种情形下可不是一个很好的选择。他在澳洲国立大学的前导师，在小组里坐在他的旁边，事后发来电子邮件质问：「你为什么要这样做？」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我当时没有办法回答这个问题，」Le 说，「我只是好奇。那是一个成功的范式，但实话说我只是对这个新范式感到好奇。」2006 年时，此类讨论活动还屈指可数。」很快他进入了吴恩达的门下，在斯坦福大学开始了追随 Hinton 理念的旅程。「到 2010 年底，我已经非常确定马上将有变革会发生了。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随后发生了什么？不久以后，Le 成为了 Google Brain 的实习生，在那里，他继续着自己的研究——最终成就了这篇猫的论文。在一个简单的层面上，Le 希望看到计算机是否可以训练自己识别给定图像中最重要的信息。他的神经网络训练了从 YouTube 中获取的大量数据。之后，他命令神经网络丢掉图像中包含的一些信息，但他没有指定抛弃哪些信息。机器开始服从命令，抛弃一些信息，一开始，被抛弃的内容是随机的。随后他说：「好了，现在根据保留的信息尝试重新构建原始图像。」这就像他在让机器「总结」一张图片的内容，然后再从总结描述中还原这张图片。如果图片描述中包含的是不相关的信息——如天空的颜色而不是胡须——机器就不能有效地重建原始图像。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这就像一个原始人，需要在剑齿虎附近隐蔽自己的行踪，这个过程不能发出一点声音。Le 的神经网络不需要原始人那样小心，它可以无限次地试错。每一次它都会在数学上「选择」一个新的最优解试图让信息的处理更加准确。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;神经网络在某种程度上来说是一个黑箱。它识别模式，但识别模式的过程对于人类观察者而言并不总有直观意义。同样的网络既能识别猫，也能识别出某些形式的家具和动物的组合，比如一条长椅和一只山羊重叠在一起。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Le 并不认为自己是一个语言学者，但他认为这项研究和他早期的聊天机器人有一些相同之处。在猫论文之后，他意识到如果你要求神经网络总结一张照片，你应该要求它生成一句完整的话来形容照片的内容。这个问题是 Le 和他在谷歌中的同事 Tomas Mikolov 在之后两年里的主要研究内容。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在那个阶段，谷歌大脑发展迅速。有一段时间，他们在大楼的同一层办公，可以随时和高管们分享自己的想法。他们后来收到了一封电子邮件，信中要求他们禁止团队成员在 Larry Page 和 Sergey Brin 的套房前面的沙发上睡觉，因为这会让来访的客人们感到尴尬。随后，他们被分配在街对面的一个大楼中，在那里，他们在厨房中交流，不会被繁文缛节所拖累。在那段时间，谷歌的竞争对手们纷纷加快了追赶步伐。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Le 一直向我强调他与 Tomas Mikolov 的密切合作，他以一种奇怪的方式重复 Mikolov 的名字，听起来有点可怕，他在说这个词的时候表现出了前所未有的庄严，我终于无法抑制住自己的好奇心，问道：「他是...？」Le 点了点头。「他现在在 Facebook 了。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicr33MwRF3MYPqDITzNX5zh9rRBf1iaRz3lia97aEJ080ozrEme9TIxjy566Nhul0btTFruyTAHnh8g/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Google Brain 团队的图片小组在 2012 年发布著名的「猫论文」，展示了神经网络对于未标记数据的分析能力&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他们花费了很长一段时间构建这个神经网络架构，使其不仅可以进行简单的照片分类，也可以识别各种静态的，但同样复杂的结构，如语言和音乐。其中用到的许多方法在 20 世纪 90 年代已被提出，Le 和他的同事们回到那些长期被忽视的研究成果中去寻找。他们明白，一旦建立起了具有基本语言预测能力的系统，你就可以用它从事其他各种智能的任务——例如自动回复电子邮件或预测一个谈话流程。你会发现它看起来很神奇；在外行眼里，看起来它就像是在思考。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;Part II：语言机器&amp;nbsp;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;5. 语言学的转向&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前谷歌大脑团队不像是一个巨大的企业层次分明的科技公司的一个部门，而更像是一个社团或者一个学术集体，或者说是一个「星际酒店」。这些年来谷歌大脑团队的成员一直是整个谷歌内部比较自由且广受赞誉的员工。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当我 6 月份开始进驻谷歌大脑团队的时候，办公室里还有成排的空工位，但已被贴上便利贴，上面大多写着类似「Jesse，6/27」（新职工及将要入职时间）这样的标注。现在这些空工位都已满。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌大脑团队的发展使得团队的负责人 Dean 开始有点担忧公司对需求的掌控。他想一改谷歌以往「成功毁灭者」的形象，而外界对谷歌的这个印象是由于谷歌在产品开发落地上的能力远不及其在理论研究上的能力。他曾做过简单的估算，并用一个只有 2 页的 PPT 向执行董事汇报了他的估算。「假设未来使用安卓手机的用户每人每天和手机语音对话的时间为三分钟，那么这就是我们所需服务器的总量。」也就是谷歌需要将他们的全球计算能力扩增 1 到 2 倍。「这个数量听起来有些吓人，但是我们必须去做——去建造新的数据处理中心。」他不愿去设想如果不这样做的后果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是还有另外一种解决方案：只需设计芯片，成批量的设计出让所有计算过程更快的芯片并在全球各地的数据中心使用。这些芯片将被称为「张量处理单元（TPU）」，这些芯片区别于普通芯片在执行计算过程时是非精确计算，这也是体现芯片价值之处。如在计算 12.246 乘 54.392 的时候，芯片会给一个 12 乘 54 的近似计算值。在数学层面上，一个神经网络只是一组成百上千或者成千上万的矩阵的有序计算。对这些矩阵的计算过程而言，计算速度比精确计算更重要。「一般情况下，为某一特别任务而设计硬件是一个不明智的做法。因为这样设计出来的硬件只能加速该项任务的计算过程。但是由于神经网络的普适性，你可以在很多其他的任务执行时运用专为神经网络而设计的硬件。」Dean 说。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当芯片的设计过程即将完成的时候，Le 和两个同事终于证明出神经网络可以用来构造语言模型。他的结论是基于「词向量」而得出的。当你看到图像的时候，大脑会从边缘到图形依次概括图像主要内容。语言概括的过程也与此类似，你本质上也是在构建不同维度的距离图。在构建的时候，依据惯用使用规则，构建一个词和其他单独的每一个词的距离。计算机并不是以人认知语言的方式进行语言分析的，而是在构建的距离图里转移、偏转或者倾斜词向量。二维的向量图是没有价值的。比如在地图中你希望 "cat "在 "dog "附近，同时 "cat "也在 "tail""supercilious""meme"附近，因为你需要构建这些词相互之间的关系而且一个词（这里是"cat"）对于其他所有词的关系有强弱之分。如果一个词与其他所有词之间的关系各自成为一个独立的向量维度，那么一个词与其他词之间的关系就能一步构建出来。但是创建一个维度为 16 万的向量不是一件容易的事，所幸的是某种语言的词向量图完全可以用一个只有一千维度的向量图来很好的构建出来。换句话说来说，在这个词向量图的空间里，每个词是由一组 1000 个数值来定位的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是在这样构建的空间里，并不能很好地显示出不同种人的称呼之间的区别。如果把定位「king」的那组数对应的减去定位「queen」的那组数中相同位置的数那么得到的新向量将会同定位「man」的那组数对应减去定位「man」那组数的向量相同。如果让机器学习整个英语词汇所构建的向量空间图以及整个法语词汇所构建的向量空间图，在理论上你是可以训练出这样的一个神经网络，从英语中选取一条语句对应的生成法语中向量值相同的语句。在训练时，你只需要先将大量的英文语句作为网络的数据输入，然后将对应的法语语句作为网络的输出，进行一个监督学习的过程，在机器完成这个监督学习之后神经网络将会习得词语之间的关系，这就跟图像分类器能识别不同像素点之间的关系一样。词语和像素之间的主要区别在于一副图像中的像素点在时间上是没有先后之分的，而词语的使用是有时间先后的。你需要时刻让神经网络"记住"它是以时间先后的顺序来处理语句，即从语句的第一个词至最后一个词的顺序进行。在 2014 年 9 月的某周里，这种处理方法的所有理论工具在三篇论文中被提出来。一篇来自 Le，另外两篇来自加拿大和德国的研究者。他们的研究催发了一些开发式的项目如谷歌大脑的 Magenta 项目，这个项目是对机器如何创作艺术作品和音乐作品的研究。同时也为工具性的研究（如机器翻译）扫清障碍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;6. 伏击&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Le 的论文表明神经翻译是靠谱的，但是他只使用了一个相对较小的公共数据集。（对于谷歌来说很小，要知道谷歌拥有世界上最大的公共数据集。过去十年旧的翻译系统已经积累了比其使用的数据集大上成百上千倍的生产数据。）更重要的是，Le 的模型对于超过 7 个单词的句子就不怎么管用了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Mike Schuster 那时是 Brain 团队的一名研究科学家，接管了这项研究。他明白如果谷歌找不到一种能将理论见解拓展到产品层面的方式，其他人也会找到的。这个项目花了他两年的时间。Schuster 说，「你想要翻译一些东西，你就要有数据、做实验，并且你做了，效果未必如你所愿。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Schuster 是个时刻保持紧张专注，大脑永远灵活的家伙，皮肤黝黑，肩膀不宽，穿着窄口过膝迷彩短裤，脚踩一双闪着荧光的 Nike Flyknits。Schuster 在前西德 blast-furnace 区的杜伊斯堡长大，研究的是电子工程，后来去京都研究早期的神经网络。上世纪 90 年代，他做了一个会议室大小的神经网络机器实验；花费数百万美元，训练了好几周才能做一些你现在一个小时内就能在台式电脑上训练出来的东西。1997 年，他发表了这篇研究的论文，之后的十五年都几乎没有人引用过；今年，这篇文章被引用了 150 次左右。他不乏幽默，但穿着上总是流露出一种严肃的感觉，他的签名带着一种日本人和德国人特有克制感。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个非解决不可的问题很棘手。一方面，Le 的代码是自定义编写的，与谷歌之后新开发的开源机器学习平台 TensorFlow 不兼容。2015 年秋天，Dean 给 Schuster 介绍了另外两名工程师，Yonghui Wu 和 Zhifeng Chen。然后他们花了两个月将 Le 的结果复制到这个新系统上。Le 就在旁边，但是他从头到尾都没有给过他们一点指导。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;就像 Schuster 说的那样，「很多工作都不是在完全清楚的情况下完成的。他们不知道自己为什么要做。」今年二月，谷歌的研究组织——谷歌的一个松散部门，大约有 1000 名员工，做的都是前瞻性和一些未知的研究——将总部外的各个带头人召集到联合广场上的 Westin St. Francis 酒店，奢华程度略低于谷歌自己在东部一英里之外三藩市里的那家店。上午是几轮的「闪电会谈」，快速汇报最新的研究进展，下午是悠闲的跨部门「促进讨论。」这次召集是为了提供一个场合能促进不可预测的、不明朗的、贝尔实验室风格的交流，期望这种交流能给公司带来更多的生产力量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;午餐时间，Corrado 和 Dean 两人在找谷歌翻译的负责人 Macduff Hughes。Hughes 一个人用餐，两名谷歌大脑的成员坐在离他有点距离的两边位置上。就像 Corrado 说的那样，「我们伏击了他。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「O.K.」Corrado 想放松 Hughes 的警惕，让他的呼吸恢复平稳。「我们要和你谈点事。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他们告诉 Hughes 2016 年是个不错的时机，可以用神经网络重整一下谷歌翻译——数百名工程师超过十年编出来的代码。这个旧系统采用的是 30 年来所有机器翻译系统采用的方法：它能将连续的句子片段隔开，在一个大型统计衍生词汇表中检索句子中的单词，然后使用一组后处理规则附上适当的结果，再重新排列起来组合成句子。这个方法叫「基于短语的统计机器翻译」，因为直到该系统获取下一个短语，它才知道这个短语是什么。这就是为什么谷歌翻译的输出有时像一对抖动后的冰箱贴。如果谷歌大脑团队的神经网络能用到翻译中来，就能实现阅读并在一个草稿上呈现完整的句子。它会扑捉整个语境，这和句子表达的意思紧密相关。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;赌注似乎很低：谷歌翻译带来的收入最小，而且这种情况可能会一直持续下去。对于大多数以英语为母语的用户来说，即使是激进地升级一个服务，也不会给他们带来任何用户体验上提升。有个案例可以说明这个问题，人类水平的机器翻译不仅是短期内的必需品，长期来看其发展也很可能会带来颠覆性的变化。在这中间，公司打什么样的战略至关重要。谷歌估计，英语中有 50% 的使用来自 20% 的世界人口。如果谷歌打算进军中国——这里大多数搜索引擎流量的市场份额属于它的竞争对手百度——或印度，得体的机器翻译将是基础系统不可或缺的一部分。2015 年 7 月，百度也发表了一篇关于神经机器翻译的开创性论文。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在更远的将来，机会更多，机器翻译可能是迈向一个使用人类语言的通用计算设备的第一步。这将在真正的人工智能的发展道路上代表一个主要的转折点，或许它本身就是主要的转折点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;硅谷的大多数人都意识到机器学习是一条捷径，所以 Hughes 预料到 Corrado 和 Dean 会来找他谈这个事情。他仍然保持怀疑。这个温和强壮刚刚步入中年的男人，蓬乱的褐色头发，两鬓却已斑白。Hughes 是一个典型直线条的工程师，就是那种上世纪 70 年代出现在波音飞机草稿桌上工匠。他知道，多年来在谷歌其他岗位上或者谷歌之外其他地方的很多人一直试图做神经翻译的研究，不仅是实验室里的还有能投入量产的，但是收效甚微。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Hughes 听了他们的案例，最后小心翼翼地说，这听上去就好像他三年内就能做出来一样。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Dean 却不这么想。「如果我们真的想做，今年内就能做出来。」人们喜欢并崇拜 Dean 的一个原因就是他总能成功地实现自己的想法。另一个原因是，他能轻松地说一件很严肃的事情，「我们能不能把我们的想法加进去。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Hughes 那时肯定神经翻译不会那么快实现，他个人不关心是一个原因。「我们来为 2016 年做准备，」他回去告诉他的团队。「我们不会说 Jeff Dean 没那么快。」一个月后，他们终于可以运行一个并排（side-by-side）实验，将 Schuster 的新系统与 Hughes 的旧系统相比较。Schuster 想用它来试一试英语-法语翻译，但是 Hughes 建议他换个语种试试。「英语-法语太简单了，提升不会太明显。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Schuster 不会坚持这个挑战。评估机器翻译的基准度量是 BLEU 得分，它将机器翻译的结果与许多可靠的人类翻译的平均水平相比较。当时，英语-法语最好的得分是 20s。有一个点的改进就是非常好；两个点的改进就算是十分出色了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;英语 - 法语语对上的神经系统改进比旧系统多达 7 分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Hughes 告诉 Schuster 的团队，在过去四年里，他们自己的系统中从来没有出现过这么大的改进。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了确保这不是侥幸得出的，他们也利用人力对此进行了平行比较。在用户体验得分中，其中例句得分从 0 到 6，平均改善了 0.4——大致相当于旧系统在其整个生命周期的总增益。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicr33MwRF3MYPqDITzNX5zhxhZSG03us3Nk8PI3xZfibtEeJNIxs6kibuFJJtnYJgwy5H6KOdrPpPdw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;谷歌的 Quoc Le（图右），他的工作证明了神经翻译的合理性，Mike Schuster 帮助将这项工作应用于谷歌翻译。图片来源：Brian Finke for The New York Times&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;三月中旬，Hughes 给他的团队成员发了一封邮件，暂停了所有旧系统有关项目。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;7. 将理论变为产品&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在那之前，神经翻译团队只有三个人（Schuster、Wu 和 Chen），但是在 Hughes 的支持下，更多的团队开始了联合。后来他们在谷歌大脑写字楼开会，会议一般有十几人参加。当 Hughes 或 Corrado 在的时候，他们是仅有的以英语为母语的人，工程师们用混杂的语言和数学进行表达，不过他们讲中文、德语和日语等其他语言。在 Google，谁举行会议并不总是完全清楚的，但这次会议是没有疑义的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不过即便如此，他们所需要采取的步骤还是不完全确定的，整个过程都是不明确的。Schuster 将手伸出到胸前 8 英寸说：「这就像在大海里游泳，你只能看到这么远的距离，目标就在某处，或许它就在我们这里」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大多数谷歌的会议室都配有视频聊天显示器，它会在闲置时显示极高分辨率的过饱和公开 Google+照片，包括梦幻森林、北极光或德国国会大厦。Schuster 指向正在显示华盛顿纪念碑水晶般静立的夜景屏幕，「外人会认为我们每个人都有双筒望远镜，可以看到遥远的前方。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;到达现在的理论工作已经让他们精疲力竭了，那么将它转化为可行的产品呢，做学术的科学家可能就会将其归于纯粹的工程学，并认为要实现起来是不难的。首先，他们需要确保有良好的数据进行训练。谷歌数十亿词的「阅读」训练主要是由中等复杂性的完整句子组成，就像海明威的那样。其中一些是公共领域内的：统计机器翻译 Rosetta Stone 就是数百万页的加拿大议会的完整的双语记录建立的。然而它的大部分都从 10 年收集的数据中剔除，包括从热心的受访者得到的众包翻译数据。他们团队的语料库里有大约 9700 万个独特的英语「单词」。但是一旦他们删除了表情符号、拼写错误和冗余，他们的有效词汇量就只剩下了大约 16 万。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然后你不得不重新关注用户实际想要翻译的内容，这通常与是否使用合理的语言无关。谷歌发现许多人不去看复杂句子翻译地是否完整，而是考察那些奇怪的小碎片语言。如果你希望网络能够处理用户查询流，那么就必须确保将其定向到处理小碎片语言。该网络对其训练的数据非常敏感，正如 Hughes 向我提出的一点：「神经翻译系统就像一个小孩，它正在学习一切」他笑着说：「你们都应该谨慎点」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不管怎样，他们需要确保整个翻译过程是快速和可靠的，这样用户才能接受这个产品。在今年 2 月，神经翻译翻译一条 10 个单词长的句子需要 10 秒钟，他们是不可能去推荐一个如此慢的翻译系统。所以翻译小组开始对一小部分用户进行延迟实验，以伪造延迟的形式识别容错。他们发现，如果翻译需要 2 倍到 5 倍的时间不会被注意到，但是到达八倍的减速就会了。他们不需要确保所有语言都是这样，在高流量的语言（如法语或中文）的情况下，他们几乎不会放慢速度。而对于一些更模糊更抽象的事物，他们知道如果用户能获得更好的质量，那么基本不会害怕轻微的延迟。他们只是想防止用户转换到某些竞争对手的服务上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于 Schuster 而言，他承认不是太清楚他们团队能否让这个系统运行地足够快。Schuster 还记得和 Chen 在小厨房里的对话，他当时说：「一定有一些我们不知道的，但能使我们的系统运行地足够快的东西，虽然我不知道是什么」。不过他们都知道他们需要更多的计算机，确切地说是需要更多的图形处理器训练神经网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Hughes 去问 Schuster 他是怎么想的：「我们是不是应该使用一千块图形处理器？」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Schuster 回答：「为什么不用 2 千块？」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;十天后，他们增加了 2000 块图形处理器。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;到 4 月份，原来的三人阵容已经超过 30 人，其中一些人，如 Le，来自谷歌大脑团队，许多人还是来自谷歌翻译。5 月，Hughes 为每种语对配备了一位临时主管，每个人都需要将结果录入到一个大型的共享绩效评估电子表格中。在任何时候都至少有 20 个人正在进行为期一周的独立实验，并处理出现的各种意想不到的问题。有一次有一个模型毫无缘由地把开始所有句子中的数字删除。这个问题花了几个月的时间才得以解决。Schuster 说：「所有人都在着急地大喊大叫。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;到春末，各部分的工作都聚在一起。团队引入了一些诸如 word-piece model、coverage penalty、length normalization 的概念。Schuster 说，「每个部分的结果都能改进几个百分点，总体就会有显著的效果。」一旦模型标准化，它将只是一个单一的多语言模型，而不是目前使用的翻译的 150 种不同模型，这一模型将会随着时间的推移而不断改进。但是，当一个工具通过学习机器来实现普遍化时，实现自动化的过程会需要异于常人的才智和努力。但是很多做出的决定都依赖的是直觉。每层需要使用多少个神经元？1024 还是 512？有多少层？一次运行多少句？需要训练多久？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;Schuster 对我说，「我们做了成百上千次实验，直到我们确定在一周后我们可以停止训练。你总是在问我们什么时候才可以结束？我怎么知道我做了些什么？你永远不知道你做了些什么。机器学习的机制永远都达不到完美的状态。你需要训练，在某一个时间，你需要停下来。这就是整个系统的本质。对于某些人来说，这确实很困难。这就是创造艺术一样，你得拿着你的刷子慢慢让它变得完美。所以我们要去做，有些人会做得越来越好，有些人会越来越糟糕。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;5 月份，谷歌大脑团队了解到，他们唯一能够使系统作为产品快速实现的方法是能够在 TPU 上运行。正如 Chen 所说：「我们甚至不知道代码是否能工作。但是我们知道没有 TPU 肯定是不行的。」他还记得曾经一个接一个地去请求 Dean，让他帮忙保留一些 TPU。Dean 保留了，但是 T.P.U.s 却不能正常工作。Wu 花了两个月的时间坐在硬件团队的人旁边，试图找出原因。他们不只是在调试模型，他们也在调试芯片。神经翻译项目成为整个基础设施投资概念的验证。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;六月一个星期三的晚上，在 Quartz Lake 举办的一个会议以对近来出现在行业权威网上论坛上百度的一篇论文的讨论开始。Schuster 说，「确实百度出了一篇论文，就好像有人在监视着我们一样——相似的架构、相似的结果。」它们的 BLEU 分数是谷歌在二三月份内部测试时达到的分数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌团队知道它们应该早一点发布自己的结果，这样或许就能够打败它们的竞争对手。但 Schuster 说道：「推出要比发布更重要」。最终他们确实首先推出了更好的服务。但是 Hughes 说，「我们不想说这是一个新系统，我们只想确保它能够正确运行。理想的情况是看到大批人在 Twitter 上面说：『你们有看到谷歌翻译现在有多厉害吗？』」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;8. 一次庆祝&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;9 月下旬一个星期一的下午，团队的论文最终发布，论文共有 31 位作者。第二天谷歌大脑和谷歌翻译的成员聚集在为厨房中举行了一个小小的庆祝活动。一定程度上，它们是在庆祝谷歌大脑和谷歌翻译的联合工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌的神经翻译终于开始运作了起来。在聚会举办的时候，公司的中英翻译已经处理了 1800 万条查询指令。几周之后，谷歌正式将神经翻译拓展到了中英互译领域，这是谷歌取得最好业绩的语言对。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Hughes 说道：「上一分钟存在问题，上上一分钟也存在问题，对论文的测量误差或者是一个奇怪的标点符号都可能导致系统缺陷，但所有的问题我们都解决了，或者至少当前是有效解决了。神经翻译目前取得了一些进步，但是这种进步是间断的、垂直的，而不是一条光滑的曲线。相关的翻译并不仅是关于两个团队，而是关于将理论转变为现实，目的是为了交流、合作。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Dean 说：「它们展示了可以同时处理两大主要任务的能力：做研究，并且将结果摆在 5 亿人（我猜测）的面前。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所有人听到都发出了笑声，并不是因为这句话夸大其词，反倒是因为它丝毫没有夸张。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;后记：没有灵魂的机器&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;或许对于人工智能最著名的历史性批判或者是在其立场上做出的断言，便设计到了翻译的问题。伯克利的哲学家 John Searle 中 1980 年提出中文屋（Chinese room）的实验。在这个思想实验当中，他将一个只会说英语的人关在一间只有一个开口的封闭房间中。房外的人不断向房间内递进用中文写成的问题。房间里面的人只有几张桌子和一本用英文写成的手册，指示他该如何处理收到的汉语讯息及如何以汉语相应地回复。房内的人便按照手册的说明，很快他们的回答似乎就变得与与讲中文的人没有什么差别了。那么我们可以说房间里面的人「懂」中文吗？Searle 的答案是否定的。他在之后用计算机来作比喻，他说「给适当编程的电子计算机赋予正确的输入和输出，就会造成一种计算机和人脑一样也具有思维的感觉。」&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于谷歌大脑团队，以及在硅谷从事机器学习工作的几乎每个人来说，这种观点都有些文不对题。这并不是说它们在无视哲学问题，而是说他们对智能的思维有着完全不一样的看法。和 Searle 不一样，他们没有从特殊的心理方面来分析「意识」，Gilbert Ryle 将其称之为「意识的灵魂」。他们只是相信我们称之为「意识」的复杂技能分类，在很多简单机制的协调活动中是随机出现的。因此，逻辑推理就成为了一种补足的方式，就像是我们扔球和接球的能力一样。人工智能并不是要去建立一种思维，它是对于解决问题工具的改进。Corrado 在我第一天进入谷歌的时候就对我说，「人工智能并不是关于机器『知道什么』和『理解什么』，而是关于它可以『做什么』，还有至关重要的一点是——它目前还不能做什么」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而「知道」和「做」这两个概念当中确实存在一些文化和社会含意。Schuster 曾经因为媒体将「谷歌表示人工智能翻译的能力已经与人类无异」（GOOGLE SAYS A.I. TRANSLATION IS INDISTINGUISHABLE FROM HUMANS）放上头条一度在论文中强调这一点，他经常重复论文中的观点——「现在的发展状况比以前要好很多，但还是不及人类。」他希望人们能够清楚地意识到他们所做的工作是在帮助人类，而不是要取代人类。然而机器学习的崛起又为我们提出了难题。如果你相信，根据 Searle 的观点，人类「洞察力」当中存在着一些特殊之处，那你就可以在人类和机器之间划出一条明显的界限。如果你持相反的看法，那么就当然不能。所以为什么那么多人都支持前者似乎就容易理解了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 2015 年 MIT 关于人工智能根源的一次大会上，有人问 Noam Chomsky 他对机器学习的看法是怎么样的。他轻蔑的回答说，整个市场都仅仅是在做数据预测，其实就像是天气预报一样。即使神经翻译能够完美演绎，对于语言的本质也并不能产生什么深远的影响。这种预测能够成为我们完成任务的一种很好的工具，但是不能帮助我们理解事情为什么会这样发生。在医学扫描上，机器已经能够比人类放射专家更准确地检测出肿瘤，但是机器不能告诉你是怎么得病的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那么问题是放射专家能够告诉你吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;医学诊断是受到机器学习威胁最直接最不可预测的一个领域。放射科医生一般都经过广泛培训，并且报酬优渥，我们认为他们的技能是一种专业洞察力——最高级的思想领域。在过去的一年里，研究人员不仅发现神经网络可以比医疗图像更早找到肿瘤，而且机器甚至可以根据病理报告的文本做出诊断。放射科医生做的事情其实更像是一种预测模式而不是逻辑分析。他们并没有告诉你是什么导致了癌症，他们只是告诉你它在那里。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你出于某种目的建立了一个模式匹配装置，它可以在为别人服务时进行调整。一个翻译工程师既可以利用一个网络评价艺术品，也可以用它来驱动一个自主无线电控制的汽车。用于识别猫的网络可以用于训练 CT 扫描。一个用于翻译的神经网络可以很快处理数百万页的法律的文件，所需要的时间和收费最昂贵的资格律师相比也仅仅是一小部分。那些机器可以做的工作也不再仅仅是我们之前所做的一些重复性的工作。我们不只是在谈论 350 万名可能很快面临失业的卡车司机。我们谈论的还有库存管理者、经济学家、财务顾问、房地产代理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在硅谷发生的最重要的事情现在不是分裂。相反，它对体制的建设和权力的巩固，在规模和速度上都达到了人类历史上可能是前所未有的程度。谷歌大脑有实习生，有常驻职员，有培训其他部门的「忍者」。每个地方都有免费自行车头盔和免费的雨伞、水果沙拉、午休的地方、共享的跑步机书桌、按摩椅、高级糕点、婴儿衣服捐赠场所、配备教练的两层攀岩墙、阅读小组和政策会谈以及各种支持网络。这些大规模投资的受益者可以控制分布在四大洲 13 个数据中心的复杂协调服务器，所拥有的数据中心吸引的电力足以照亮大城市。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但即使像谷歌这样庞大的机构也将面临自动化的浪潮，一旦机器可以从人类的语音当中进行学习，即使程序员的舒适工作也受到威胁。Hughes 在回忆过去 10 年翻译代码库历史时候曾说，「不要担心，新的代码库将会继续发展，一切都会变得越来越好。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;原文链接：http://www.nytimes.com/2016/12/14/magazine/the-great-ai-awakening.html?_r=0&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 15 Dec 2016 16:14:18 +0800</pubDate>
    </item>
    <item>
      <title>专访 | 云从科技创始人周曦：刷分的人脸识别没有任何意义</title>
      <link>http://www.iwgc.cn/link/3928461</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：虞喵喵&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一家成立不到两年的图像识别公司，如何在短时间内拿下众多银行客户？&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自 2015 年 4 月成立以来，海通证券、西安银行、中国建行等多家金融机构先后应用了云从的人脸识别系统。今年 9 月，中国农业银行更是率先将云从的技术应用到 37 家分行，成为全国第一家应用人脸识别技术的四大行。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;作为云从科技的创始人，周曦博士师从「计算机视觉之父」Thomas Huang（黄煦涛）教授，并在 2007-2011 年期间 6 次获得智能识别类世界大赛冠军。2011 年受邀回国后，周曦博士进入「中国科学院百人计划」，联合 UIUC（伊利诺伊大学厄巴纳-香槟分校）及新加坡国立大学成立中国科学院重庆研究院智能多媒体技术研究中心。期间带领团队研发出智能图像侦查仪、公安千万级人像检索机、人脸识别智能人员管理系统、大规模动态人群特征检测系统等产品，并作为中国科学院人脸识别唯一代表参与战略先导 A 类专项「新疆安防布控」。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;多年的学科钻研和技术、实践经验积累，使得云从自诞生之初就有着不俗的竞争力。可移动式大规模数据采集阵列、双层异构深度神经网络等复杂名词的背后，是云从「希望帮助更多人」的初心。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9DFP58EX6ymYTnLpicibkXOrxh1XKAbE69802iaAH3kGCpibHVsMuESWSsnzDb7N4o3EXr9ehHPfhoibw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;云从科技创始人周曦&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器之心专访周曦博士，从个人经历、云从科技的技术特色、金融业的技术应用特点、图像识别的发展等多个角度，还原这家图像识别公司的不同面貌。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;从语音转行图像，希望技术真正「有用」&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心&lt;/span&gt;&lt;span&gt;：您为什么选择了图像这个方向？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;周曦&lt;/span&gt;&lt;span&gt;：最早我在中科大做语音。后来去北京，在微软亚洲研究院语音识别组也呆了很长时间。但这期间「做了错误的判断，做了正确的决定」——我觉得语音没前途。按照摩尔定理，语音识别每 18 个月错误率能够减半，但我感觉离实用还是很难。而图像识别的视频和图像是个大得多的领域，可以解决的问题要多得多。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从信息分析来看，语音是一维信号，图像是二维信号，视频是三维信号，从信息上看图像比语音丰富。从任务来看，Audio（声音）本身是有很多任务的，但 Speech（语音）和 Audio 是两回事儿。Speech 是人的声音，背景音等很多声音对我们意义不大。我们想要研究的就是 Speech，这造成了所有做语音这一行，能做的任务就是能把说话的内容识别准。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图像和视频是完全不同的，人脸识别大概对应着语音识别。把图像中的人找到，再识别他是谁、他的情绪、年龄、性别。这只是浩瀚的图像识别和视频识别中的一小部分，对于我们来说有用的不止这一点。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;医学上应用图像处理，可以识别早期癌症等疾病。为什么体检后很多疾病没有检查出来？不是没拍到，是需要非常专业、非常资深的医生才能看出来。如果疾病尤其是癌症早期就看出来，基本能够治愈。通过图像识别和大数据，更好的把有嫌疑的部分都找到后再请专业的人确认，这样不就可以挽救很多人的生命吗？&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;再比如做工业视觉，生产线上的东西是不是有瑕疵，有没有裂缝？表面平不平？也可以通过图像视频看出来。又比如现在很「火」的自动驾驶，可以通过图像识别出所有路面的情况，是不是有标志等等。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于图像来说，识别宇宙万物都很有意义，不止是识别人的脸才有意义。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图像做一点点事都可能帮助到别人。当时我看到一条新闻，国外有人在泳池下装了一个摄像头，能自动识别出游泳者是不是溺水。做图像视频可以有很多的方法帮助别人，就觉得这个还蛮有意思的。所以「做了一个错误的判断，一个正确的决定。」来到美国，开始做图像视频。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;span&gt;机器之心&lt;/span&gt;：在美国您跟从 Thomas Huang（黄煦涛）教授学习，他是怎样一位老师？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;周曦&lt;/span&gt;：他是那种给我们营造环境的大师，给我们很大的平台和 high-level 的指导，比较轻松自由的环境，可以去做自己想做的方向。Thomas Huang 给我们很大的视野和平台。他本身是顶级教授，他指大的方向，给我们看大的视野是什么，我们自己三五成群研究自己感兴趣的东西。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9DFP58EX6ymYTnLpicibkXOricIsy0hTia3vZBECaXQ8J7G3h1VmicQuuKKEmxRWFLryroOl0HkSGBXQg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Thomas S. Huang（黄煦涛）教授在图像处理、模式识别、计算机视觉领域有奠基性贡献&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;span&gt;机器之心&lt;/span&gt;：那您后来为什么创业做了云从？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;周曦&lt;/span&gt;：很多时候都是幸运。我本来做语音、后来做图像，都属于人工智能甚至机器学习这一个分支里，有一定的学科交叉，很多东西都是复用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当时的语音识别走在图像识别前面，已经到了系统化的阶段。我到美国时，图像还没到这个阶段。从语音转到图像，让我们在方法论和做系统这件事上远远领先了所有人。当时图像领域都是「单兵作战」，在一个电脑上跑或者在一个服务器上跑任务。语音领域的人都认为必然需要 cluster 服务器阵列，分布式的提交任务。我到 UIUC 时发现还没有，马上就搞了一个。有 cluster 服务器就相当于正规军，别人是散兵游勇。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;语音有很多做得很好的算法和思想，我也在图像上实践。果不其然效果很好，2006-2010 年之间拿了很多世界冠军。拿了这么多冠军我就想，总要做什么有意义的事儿吧。这个东西要「实用」，不管是检查零件还是挽救溺水的生命，在各种场合下要能帮到大家。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这时就发现，虽然能识别宇宙万物，但图像识别一定要具体到一件事上才能帮助到别人。想来想去，人脸是图像中很重要的东西，把人脸做好可以做很多事。于是我们就先选了人脸识别。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;后来发现，如果没有商务推广能力也是不行。2013 年底、2014 年初，我发现芬兰有一家小公司做刷脸支付，觉得很好玩，就率先在国内做了刷脸支付。2014 年是做出来了，在手机上可以使用了，但其实是没有用的，因为没有人真的用。我只是告诉别人，可以这么玩儿，谁会真的去用呢？哪个金融机构会拿这个真的去做事呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果我们永远只在学术里，还是帮助不了人，做不了什么事儿。一定要自己有个公司、自己有能力去做商务推广，把这个东西往前推动，就有了云从。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;短时间搞定多家客户背后，是多年的实践积累&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;span&gt;机器之心&lt;/span&gt;：云从成立一年半时间，为什么能拿到银行、公安这么多客户？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;周曦：技术积累就不说了，很多年我一直在尝试怎么让技术实用。从学术到好用的系统，有很长的距离。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们在美国拿很多世界冠军，回国就是想让技术能实用。从 2011 年回国做了好多年，我们在中科院做的很多系统已经在新疆等地使用了。产品是成熟的，只是还没在商业推广起来。虽然公司去年成立，但准备工作特别完善。如果不全力以赴、以公司这样严肃的方式运作，是没有办法得到大家的认可的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9DFP58EX6ymYTnLpicibkXOrklJB4tTHiaiaF3g9ibkOVOHXnCJeJv7g5nLdhiagrGiaDjoPBRx8WLl2jicg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;云从科技部分应用案例，可于其官网查看具体内容&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;还有一点是我们做东西很集中，&lt;span&gt;我觉得专注是很重要的。一个是研究的东西很集中，虽然什么都能做，但现在还是做好人脸；第二是行业上要集中，各行各业都能做，我们只做金融和安防。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;span&gt;机器之心&lt;/span&gt;：银行这个行业应用分支有什么具体特点？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;周曦&lt;/span&gt;：银行的要求是，一定是一个严肃、认真的公司。不仅要求稳定，同时希望有非常快的响应速度。银行有严格的「2 小时、4 小时、8 小时原则」，系统宕机 2 小时，行长就要去当地人民银行喝茶；4 小时没解决，就要写报告；8 小时没解决，这就是严重事故，银行的评级一定会下降、甚至是关门，就是这么严重。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对我们这种 IT 供应商来说，能保证程序出现问题两小时之内修复吗？这是非常难的。如果人脸是其中的标准环节，恰好人脸识别的服务器宕机，银行只能关门，民众会怎么想？大家可能觉得银行是要垮了，会出现很大的金融事件，然后出现挤兑。这个就是银行的特点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们的系统还必须从总行部署，压力很大，需要我们非常专业。云从虽然成立时间不长，但很认真，在全国十个城市有销售服务中心，全国每一个省有自己的销售服务人员，要保证各个地方一线有云从的人。真的出现问题，我们要第一时间过得去。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;银行是很看重销售服务体系的，大部分互联网模式的公司可能不太重视这个事情。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;&lt;span&gt;机器之心&lt;/span&gt;：云从的「超大规模移动式数据采集阵列」是怎样的装置？作用是什么？&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;周曦&lt;/span&gt;：这实际上是受我在了解医学过程中的影响。我们这一行，其实没有做医学那么认真。医学上做 CT 切片时，因为光线是流明，从正极白到负极白每一度都要拍摄下来。这些图片形成一个严格的表格，可以反向查表解决问题。不能做错手术、不能误判、医学是很严格的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但我们这行经常说「情况很复杂，只能搞个大概」，光线、角度、遮挡、表情，影响因素很多。医学是值得学习的，所以当时从美国回来就做了结构化数据。采数据容易，结构化数据不容易。就算从互联网上下载 1000 万张人脸，或者在大街上安装摄像头收集行行色色的人脸，这些数据都是非结构化的。一张人脸的照片拿出来，它是什么角度？是什么光线？光源从哪儿来？有没有遮盖？是什么表情？有没有模糊？很难一张一张标回来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以我们花了很大力气，做了这个移动式采集阵列。&lt;span&gt;横向上从负 30 度到正 30 度，纵向上从 0 度到 30 度，每隔 5 度安装一个摄像头。7 层 13 列，一共 91 个摄像头形成了一个阵列，使用的摄像头是当时我们从加拿大进口的高速摄像机元件。&lt;/span&gt;这个阵列结构是可拆卸的。我们自己做了同步单元，保证毫秒级触发同步采集。因为视频量非常大，我们还要保证存储跟得上，整套东西做好是个宏大的工程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9DFP58EX6ymYTnLpicibkXOrmWjbFC6W8psibAsic54Bp0o0U7DhdStrxl6Lib7JWvln3qpvgQXDzXNjw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;采集的空间是有标尺的，人的脸部都是固定的，加上我们自己做了光源阵列，可以获得光线和角度属性。我们还自己设计了剧本规定了表情，遮挡方面有假发、帽子、眼睛等等。获得的每一张照片，属性都是自动获得的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但只是这样，就不需要「移动」了。实验室环境是不够的，从实验室到实用都要去做，所以这个阵列要可拆卸、可移动。银行业务很多在大堂办理，所以我们还要采集大堂情况下的数据；公安有时监控的是通道，我们就在通道采集数据看具体是什么情况。依靠这个结构化数据采集阵列，我们得到了广泛的数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为什么在大数据背景下，我们还要费力气做结构化数据？就像我们常说社会是最好的学校，为什么还要设立小学、中学、大学？在学校学习的是结构化知识体系，让小孩有三观和基础知识，再去接受广泛的数据洗礼，进行大量的学习。如果从最开始就随便学，最后学习的结果就不可控了。所以&lt;span&gt;需要先有结构化数据，再有海量的非结构化数据，才能做出最好的模型&lt;/span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;span&gt;机器之心&lt;/span&gt;：那么云从的另一项技术「双层异构深度神经网络」，是如何做到将看起来不相似、但实际是同一个人的人脸对应起来的？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;周曦&lt;/span&gt;：双层异构是双层、异构两件事。很多时候注册的照片是证件照，比较端正；现场照往往过了好几年，现场的光线、表情、角度等等各种因素都比不过证件照，需要用复杂的网络解开。描述每个东西都是一个分布，同一个人要满足同一个分布，但因为种种因素同一个人的照片之间已经隔得很远。我们不用强行把两张照片圈在一起，而是让他们在两个层上组成分布，用线将它们连接起来。接受注册和测试时的不同，将中间的原因找出来，这个就是双层。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;异构和双层是相辅相成的。大数据有一个特点，只要数据足够多就可以让它自己学习，但实际上影响因素是什么，人是知道的。人们知道原因是光线、遮挡、表情造成了差异，可以完全让它自己去学习，也可以提前告诉它可以省很多力。异构就是结构化不一样，数据是一种结构，知识是另外一种结构。要把知识簇给出，映射到一个一个簇中，让它用更少的代价解决这件事。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;用「三个苹果」举例。教一个孩子认识苹果，大概三个就够了。告诉他「圆圆的」、「上面有果蒂」、摸起来是什么感觉，这就是苹果。下一次再看见苹果，问他「这是什么」，他可能知道也可能不知道。如果不知道，可以告诉他「这就是上次说的苹果」。他会问「颜色为什么不一样」，可以回答「上次是青苹果，这次是红苹果」，孩子就会知道「苹果有不同颜色」。几次之后，他就认识苹果了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深度学习要想「搞定苹果」，需要多少个苹果？通常要 1000 或者 10000 个苹果的训练数据，训练结果达到识别率 90%。也就是说假如有 10000 个苹果，有 1000 个会识别错。我们问电脑，「这 1000 个为什么识别错了？」它不会回答「颜色不一样」，而是说「求了偏导、积分等，结果是 0.4，预置值 0.5 以上才是苹果，所以它不是苹果」。如何纠正电脑？没有办法，只能说是训练数据不够多，再找 10 万张苹果的照片训练。终于，识别率到达了 98%，效果还不错。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在我看来这并不是人工智能，&lt;span&gt;和小孩子沟通的过程才叫人工智能，因为他理解我抽象出来的概念。通过颜色、形状、材质等几个抽象出来的概念，定义了一个新的事物，当他有不同的理解时，也会用同样的概念提出问题，再来纠正他的认知。我们在一个很高的层次做交互，能够举一反三。&lt;/span&gt;一个点一个点的求偏导、求积分，是没办法交流的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除了基本的、初级的像素信息外，要加入上层的 concept（概念信息）和 attribute（属性信息），才能做到在更高的层面交互，快速的举一反三，迭代出问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;&lt;span&gt;机器之心&lt;/span&gt;：图像识别会涉及到大量运算，我们如何提升反应速度？&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;周曦&lt;/span&gt;：这又涉及到工程上的问题。为什么（图像识别）门槛很高？因为它不是搞一个模型就行的问题。人脸识别本身就有几十个模块，从检测、跟踪、分割、关键点、旋正，到质量分析、光线补偿、角度补偿、遮挡补全等等等等，对于任何一个模块又要针对每种场景做不同的适配。比如关键点提取如果应用在手机前端，供应商会要求模型大小在 1M 以下，而整个人脸识别模型在服务器端是有超过 1 亿个参数的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;同时，我们还要求很快，比如视频中有很多人，要求在 1ms 之内识别出多有的关键点。为什么是 1ms？因为还有很多的模块要运行，要满足所有的运行时间加在一起达到「实时」（30ms 之内）。有时候又要求很准，比如美妆应用对关键点的识别偏一个像素，就会让人感到不适。又要小、又要快、又要准，就要有不同的算法和模型应对不同的场景。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;几十个模块、每个模块要有不同的场景、还要应对所有的硬件（不同的手机型号、服务器、嵌入式设备），这就是我们常常说的「无数的精力都放到适配上了」。研究出一种新算法，Android、iOS、Linux 等等所有的模型都要重新更新一遍，这是很累的。所以为什么像我们这样的公司都要有庞大的研发队伍，很多人不理解为什么做一个人脸识别研发团队要超过 200 人，原因就在这里。这还只是核心技术的一小块，还不算在不同的行业做闸机、迎宾等等不同的设备。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;&lt;span&gt;机器之心&lt;/span&gt;：您曾在一次演讲中提到云从能够解决「人从哪里来」的问题，现在我们已经能做到对单人实现历史轨迹提取了吗？&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;周曦&lt;/span&gt;：这个不能光靠我们，首先要将所有的监控视频结构化，先将其中的人脸数据提取保存起来。将来如果想快速得到某一个人的信息，可以从系统快速的发布请求到所有的服务器端，将得到的信息组合起来。轨迹图、甚至这个人做过什么事、和谁说过话，信息链就会整合出来。现在在技术上是可行的，但数据联动等还不能保证。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;刷分的人脸识别，没有任何意义&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：图像识别发展到现在，您认为有哪些标志性事件？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;周曦&lt;/span&gt;：图像识别曾经很火过。到了 20 世纪末、本世纪初，这行变得很惨淡，大家都觉得未来遥遥无期、没有希望。直到 2001 年的 ICCV，Paul Viola 和 Michael Jones 发表了《Robust Real-Time face detection》，在现场引起了轰动。他们用摄像头对准大家，现场所有人的脸都被圈出来了。图像识别第一次有实用的东西出现，这是图像识别命运的扭转。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一件挽救了图像识别命运的事件，是 911。911 后美国政府率先要求全部应用摄像头，海量视频出现后需要加强智能监控，客观上也让经费大幅提升。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深度学习也是一个巨大的标志性事件，深度学习在 2006 年提出，2009 年左右开始在图像中应用。一直到现在，仍是大爆发的阶段。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;硬件先行、大数据也有了，云计算云存储又得到了非常好的发展，需要有算法将他们的能力表达出来。深度学习，就是炊米的「巧妇」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：中国在图像识别研究上，大概是什么样的位置？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;周曦&lt;/span&gt;：就图像识别而言，我们在国际上是领先的，至少没有落后美国。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在中国，尤其是人脸识别，需求是比美国旺盛的。需求推动造成企业敢于投入资金，大家的投入也很大，再加上算法基础相当，中国的数据更多，所以中国是不会落后于美国的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;span&gt;机器之心&lt;/span&gt;：有一种声音认为，现在的图像识别每天都在参赛刷分，离解决人类视觉认知等初衷太远，您怎么看这种观点？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;周曦&lt;/span&gt;：刷分是没意义的。我们的初心是让图像识别真的有帮助，真的能用起来。一定要有人沉得下来做基础研究，也要有人做实用的东西。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们是偏向做有用的东西，把好的技术在银行、公安、机场等各个地方用起来，让民众觉得很好用、很舒服。为了解决这件事就会面临很多科研问题，比如晚上光线不好，就无法进自己的家门了吗？应该 24 小时每天稳定的让每个人使用，这就是实用中出现的科研问题，同样要去解决。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;做原创性研究比如怎样从理论上解决大数据的问题，也很了不起。但刷分是没有意义的，因为解决的是制造出来的、不存在的问题，只是炫技。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心原创文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 15 Dec 2016 16:14:18 +0800</pubDate>
    </item>
  </channel>
</rss>
