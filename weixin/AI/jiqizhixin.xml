<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>2016中国人工智能大事件：从百度深度学习平台到中国脑计划</title>
      <link>http://www.iwgc.cn/link/4456043</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：李亚洲、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote style="color: rgb(62, 62, 62); font-size: 16px; white-space: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;2017 年元旦，机器之心以 3 分钟视频的方式回顾了全球人工智能在过去一年中取得的发展。开源、无人驾驶、创业、深度学习等词汇似乎成为了人工智能领域的表征，一次又一次的拨动我们的神经。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721913&amp;amp;idx=1&amp;amp;sn=61fa411795fac54aacfa771959f0cba5&amp;amp;chksm=871b0a07b06c83118bf01830b545b89571d1550efab887e4369eef22ce5893fc0d9da3197df2&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721913&amp;amp;idx=1&amp;amp;sn=61fa411795fac54aacfa771959f0cba5&amp;amp;chksm=871b0a07b06c83118bf01830b545b89571d1550efab887e4369eef22ce5893fc0d9da3197df2&amp;amp;scene=21#wechat_redirect"&gt;元旦的视频总结&lt;/a&gt;中，我们能够明显的看到中国在整个人工智能领域的参与度。MXNet、百度无人车、科大讯飞都让我们看到了中国对人工智能发展的推动。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在为春发蓄势的年末，机器之心回顾了国内在 2016 年发生的人工智能大事件。百度无人车体验、开源深度学习平台 PaddlePaddle，多种算法、应用竞赛的举办，商汤、旷视、图普等创业公司新一轮融资的成功，这些种种让我们相信中国会成为人工智能的前沿阵地，如同高盛报告中提到的「人工智能前沿的重要参与者可能会继续来自美国和中国」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;百度开源深度学习平台 PaddlePaddle&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 2016 年 9 月 1 日百度世界大会上，百度首席科学家 Andrew Ng（吴恩达）宣布正式对外开放百度内部 3 年内不断丰富、优化的深度学习平台 Paddle，并更名为 PaddlePaddle：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9iaSgfTFRChrskKuUMbnjjpYicPfqxFR5BWtJichEEsuzCRaGTnzam4qPmZ9olBa9CNXFRrK9micibTUQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;深度模型：广泛支持各种深度学习模型，包括 DNN，CNN，RNN，复杂记忆（Memory）模型，NTM 等，支持多种优化算法&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;模型训练：支持多机多显卡训练，充分利用机器性能，支持稀疏更新&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;模型预测和评估：支持线下多语言（Python/C++）预测接口&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;据介绍，PaddlePaddle 有着极大的易用性、灵活性、高效性与扩展性。随着亚马逊年底宣布使用 MXNet，深度学习框架之间的竞争是愈演愈烈。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;第三届世界互联网大会，百度无人车体验&lt;/span&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;iframe class="video_iframe" data-vidtype="1" allowfullscreen="" frameborder="0" height="417" width="556" data-src="https://v.qq.com/iframe/preview.html?vid=h0346g9f437&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0"&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2015 年底，百度宣布正式成立自动驾驶事业部，且表示「计划三年实现自动驾驶汽车的商用化，五年实现量产。」一年将近，在第三届世界互联网大会在乌镇召开之际，百度无人车邀请了多位嘉宾切身体验百度已经从「测试」走向「试乘」的无人车。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这成为百度继 2013 年启动无人车项目、2015 年底完成多种路段测试、今年 9 月和 10 月分别获得美国加州自动驾驶汽车道路测试许可证和完成加州首次公共道路测试，无人车项目的有一个重大进展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这也是国内首次第四级别的自动驾驶汽车全程无干预的在全开放城市道路上行驶，投入乌镇运营无人车 15 辆，3 天内超过 200 位乘客规模化试乘，应付了多时段的复杂气象条件。更加重要的是，这是支持 5 款车型的跨平台无人驾驶技术。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;参考文章：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720582&amp;amp;idx=3&amp;amp;sn=998e786926ccae181bd2cfb915a6fa69&amp;amp;chksm=871b0d38b06c842eab4405aa07ade9ea08dbfd0de6a2a8eea2b60ea5f1d93428d6c8614d83d2&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720582&amp;amp;idx=3&amp;amp;sn=998e786926ccae181bd2cfb915a6fa69&amp;amp;chksm=871b0d38b06c842eab4405aa07ade9ea08dbfd0de6a2a8eea2b60ea5f1d93428d6c8614d83d2&amp;amp;scene=21#wechat_redirect"&gt;业界 | 体验百度无人车，系统性人工智能技术让自动驾驶越来越近&amp;nbsp;&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;腾讯 AI Lab 研究院成立&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今年，腾讯成立了人工智能研究院腾讯 AI Lab，专注机器学习、计算机视觉、语音识别、自然语言处理等人工智能领域的研究。但腾讯一直没有对外做过多宣传，机器之心是报道腾讯 AI Lab 研究的第一家媒体。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;后来，腾讯副总裁、AI Lab 院长姚星在 2016 年腾讯研究院年会上正式向外公布了腾讯 AI Lab 所关注 AI 四个基础研究领域和 4 个专属研究方向，并且强调说，「AI 对腾讯来说是非常重要的，对整个中国互联网都很重要。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;参考文章：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722553&amp;amp;idx=3&amp;amp;sn=5a9b6e4dfe30957744b9331c65dbfdca&amp;amp;chksm=871b1487b06c9d91e37b9cc02f910ac7460a23fa9dc4cd5929835b497b811128f87ee9083e20&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722553&amp;amp;idx=3&amp;amp;sn=5a9b6e4dfe30957744b9331c65dbfdca&amp;amp;chksm=871b1487b06c9d91e37b9cc02f910ac7460a23fa9dc4cd5929835b497b811128f87ee9083e20&amp;amp;scene=21#wechat_redirect"&gt;演讲 | 腾讯副总裁姚星：人工智能真实的希望与喧哗的隐忧&lt;/a&gt;；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720536&amp;amp;idx=1&amp;amp;sn=76e38d366841b567d38c4334df175eeb&amp;amp;chksm=871b0d66b06c8470d96d6faf9c636e0e0eed6d0e89e74abd3ecfe52c68f384a906c95efd1329&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720536&amp;amp;idx=1&amp;amp;sn=76e38d366841b567d38c4334df175eeb&amp;amp;chksm=871b0d66b06c8470d96d6faf9c636e0e0eed6d0e89e74abd3ecfe52c68f384a906c95efd1329&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;独家专访 | 腾讯 AI Lab 公布首项研究：提出独特神经网络实现实时视频风格变换&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;腾讯大数据开源高性能计算平台 Angel&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 12 月 18 日于深圳举办的腾讯大数据技术峰会暨 KDD China 技术峰会上，腾讯大数据宣布推出了面向机器学习的「第三代高性能计算平台」——Angel，并表示将于 2017 年一季度开放其源代码。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;据腾讯数据平台部总经理、首席数据专家蒋杰介绍，Angel 是腾讯大数据部门发布的第三代计算平台，使用 Java 和 Scala 语言开发的面向机器学习的高性能分布式计算框架，由腾讯大数据与香港科技大学、北京大学联合研发。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9iaSgfTFRChrskKuUMbnjjpNQwV6YI4AibLP62GprMXOiaW86w1MB3WhfZibyWC5oq1z2ic1fjPHrdzKw/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;采用参数服务器架构，解决了上一代框架的扩展性问题，支持数据并行及模型并行的计算模式，能支持十亿级别维度的模型训练。不仅如此，Angel 还采用了多种业界最新技术和腾讯自主研发技术，性能更高、系统更具易用性。自今年年初在腾讯内部上线以来，Angel 已应用于腾讯视频、腾讯社交广告及用户画像挖掘等精准推荐业务。Angel 更是腾讯大数据下一代的核心计算平台。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;参考文章：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721559&amp;amp;idx=1&amp;amp;sn=0ca5ad4d7ce70c260cb596c8eae76d97&amp;amp;chksm=871b0969b06c807feba50561c516c9987e0a0b354f0ab554d14de2b8e7035134f879f1419b77&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721559&amp;amp;idx=1&amp;amp;sn=0ca5ad4d7ce70c260cb596c8eae76d97&amp;amp;chksm=871b0969b06c807feba50561c516c9987e0a0b354f0ab554d14de2b8e7035134f879f1419b77&amp;amp;scene=21#wechat_redirect"&gt;腾讯大数据将开源高性能计算平台 Angel，机器之心专访开发团队&amp;nbsp;&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;人工智能华人力量&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;就像前面所说的「人工智能前沿的重要参与者可能会继续来自美国和中国」，2016 年，我们看到了华人对人工智能发展所做出的贡献，华人力量也逐渐被国际所认可。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;华人力量的彰显可从两个维度得见：1. 中国力量在国际学术组织和会议上的存在感和影响力愈发强大，可以看成是中国人工智能快速发展的一个标志；2. 一批优秀的华人学者为产业界所看重，其中最具代表性的美籍华人李飞飞。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 百度副总裁王海峰当选 ACL 会士&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;11 月 28 日晚，国际计算语言学会（The Association for Computational Linguistics：ACL）公布了 2016 年 ACL 会士名单。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;截至目前，ACL 历史上在全球范围内累计评出过 40 位会士。而王海峰则成为了首位获此荣誉的中国大陆科学家，同时也是 ACL 目前最年轻的会士。ACL 会士评选委员会在对王海峰的评语中写道：王海峰在机器翻译、自然语言处理和搜索引擎技术领域，在学术界和工业界都取得了杰出成就，对于 ACL 在亚洲的发展也做出了卓越贡献。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;参考文章：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720823&amp;amp;idx=3&amp;amp;sn=e0670a173ef0af638625f4eda6a78355&amp;amp;chksm=871b0e49b06c875f13241f75027892adc1b7e01daf521d7dcc26e04d681c08041b13709ab979&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720823&amp;amp;idx=3&amp;amp;sn=e0670a173ef0af638625f4eda6a78355&amp;amp;chksm=871b0e49b06c875f13241f75027892adc1b7e01daf521d7dcc26e04d681c08041b13709ab979&amp;amp;scene=21#wechat_redirect"&gt;资讯 | 百度副总裁王海峰当选 ACL 会士，成为中国大陆首位获此殊荣的科学家&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 黄学东、周志华当选 2016ACM Fellow&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2016 年 12 月 8 日，世界领先的计算机学会、全球最大的计算机领域专业性学术组织 Association for Computing Machinery（ACM）正式公布了 2016 年当选的 ACM Fellow 名单。今年共有 53 名成员入选。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;新当选的 ACM Fellow 中，仅有两位华人：一位是美国微软首席语音科学家黄学东博士，贡献是「对口语语言的处理」；另一位是中国大陆学者、南京大学的周志华教授，当选理由是「对机器学习和数据挖掘的贡献」（for contributions to machine learning and datamining）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 李飞飞加入谷歌&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2016 年 11 月 16 日，谷歌宣布其雇佣了两位人工智能领域的顶级研究者：斯坦福大学人工智能实验室主任李飞飞、前 Snapchat 研究主管李佳，这两位华裔女科学家都是计算机视觉行业的专家。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在人工智能风起的今天，科技巨头从学术界拉拢人才已经成为了一种常态，而李飞飞加入谷歌的消息无疑也掀起了轩然大波。从另一个角度来讲，李飞飞作为第一代中国移民，最后成为谷歌人工智能团队新任领导者，也让我们看到了华人力量的崛起。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;参考文章：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720553&amp;amp;idx=1&amp;amp;sn=c88e48aab2d789d744ac1629ffec9a8a&amp;amp;chksm=871b0d57b06c844121d6fdf6fda546996e87c1cc395bef55fde20cb910b2fe1bbcdf8d1ce6c9&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720553&amp;amp;idx=1&amp;amp;sn=c88e48aab2d789d744ac1629ffec9a8a&amp;amp;chksm=871b0d57b06c844121d6fdf6fda546996e87c1cc395bef55fde20cb910b2fe1bbcdf8d1ce6c9&amp;amp;scene=21#wechat_redirect"&gt;深度 | 谷歌新人李飞飞：击碎玻璃天花板的华裔女科学家&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;中国脑计划一体两翼战略，推动人工智能发展&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2016 年 11 月份时，中国科学院神经科学研究所、中国科学院脑科学与智能技术卓越创新中心、香港科技大学生命科学部和分子神经科学国家重点实验室、中国科学院自动化研究所在《Neuron》上联合发表了一篇概述论文《China Brain Project: Basic Neuroscience, Brain Diseases, and Brain-Inspired Computing》，介绍了「中国脑计划」在基础神经科学、脑疾病和脑启发计算上的研究进展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在论文中，作者们写到，「神经科学的一个普遍目标——理解人类认知的神经基础——应该成为「中国脑计划（China Brain Project）」的核心。此外，中国也应该投入资源和研究能力，以满足迫切的社会需求。由主要脑疾病造成的社会压力逐渐上升，所以现在迫切需要一种预防、诊断和治疗脑疾病的新方法。在大数据的新时代，受大脑启发而得的计算方法和系统对于实现更强的人工智能和更好地利用越来越多的信息至关重要。正是由于对这些问题的考虑，中国脑计划项目提出了「一体两翼」战略（图 1）。其中对基本神经回路机制的认知的基础研究提供了输入并且接受来自脑疾病的诊断/干预和脑启发智能技术（两翼）的反馈。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9iaSgfTFRChrskKuUMbnjjpicvEXkvvHm2CdoibU9I9do7dWUhPCgG1jdzGZysGfo6fRB2OS0HdRBXw/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此篇论文的作者包括：蒲慕明（Mu-ming Poo）、杜久林（Jiu-lin Du）、熊志奇（Zhi-Qi Xiong）、叶玉如（Nancy Y. Ip）、徐波（Bo Xu）、谭铁牛（Tieniu Tan）。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;参考文章：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720765&amp;amp;idx=1&amp;amp;sn=d023cbc68ce9cec7e00ebc44d940a7d9&amp;amp;chksm=871b0d83b06c84952a94754e60f22126dd64a9c198deaeccc7ae3c6dc04eb0f190c9877de4f3&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720765&amp;amp;idx=1&amp;amp;sn=d023cbc68ce9cec7e00ebc44d940a7d9&amp;amp;chksm=871b0d83b06c84952a94754e60f22126dd64a9c198deaeccc7ae3c6dc04eb0f190c9877de4f3&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-align: justify;"&gt;深度 | 全面解读中国脑计划：从基础神经科学到脑启发计算&lt;/a&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;神经机器翻译，不止谷歌一家&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2016 年 9 月底，谷歌宣布将其神经机器翻译技术（GNMT）整合到了其谷歌翻译应用中，引起了很大关注。但实际上，利用人工智能做机器翻译的企业并不只有谷歌一家，中国的百度、讯飞、搜狗等公司都在 2016 年拿出了一些值得关注的机器翻译上的新应用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在机器之心 2016 年对百度 NLP 团队和百度首席科学家吴恩达的采访中，他们就曾谈到百度其实也非常早的就进入到了神经网络机器翻译领域。已当选 ACL Fellow 的百度副总裁王海峰博士就曾告诉机器之心：「我们从 2014 年开始便尝试做基于神经网络的翻译系统，2015 年发布在线翻译系统的时，BLEU（Bilingual Evaluation Understudy）指标已经比传统的 SMT（统计机器翻译）系统高六、七个点。我们同时还开发了离线版本，可以在手机上使用，当时学术界对于深度学习的翻译方法到底是否实用还有一番争论，我们很早就发现基于 Attention 机制的 Seq2Seq 深度学习模型是有用的，经过多次实验验证，在很多集合上超过了传统方法。同时，针对 NMT 本身存在的一些问题，进行了技术攻关，短短 3 个月的时间便完成了开发和上线。当大家还在讨论 Attention 机制时，我们已经结合了原有的统计方法上线。可以说，百度翻译是全球首个互联网神经网络翻译系统。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除了百度外，讯飞和搜狗也在持续投入机器翻译技术。2015 年，科大讯飞曾在美国国家标准技术研究院（NIST）组织的机器翻译大赛（Open Machine Translation Evaluation，NIST 2015）中取得了全球第一的好成绩。而在 2016 科大讯飞年度发布会上，该公司正式发布了「晓译翻译机」。据介绍：这款机器基于科大讯飞机器翻译的国际领先技术，达到了英语大学六级的水平，能够实现语音输入后中英、汉维的实时翻译，具有易用性、稳定性、安全性等特点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;搜狗也在 2016 年 5 月份上线了英文搜索（后在 12 月份升级为搜狗海外搜索频道并新增了搜狗翻译频道）。搜狗英文搜索可提供跨语言检索功能，可自动将中文翻译成英文进行查询，再生成英文查询结果。在 11 月的乌镇世界互联网大会上，搜狗展示了机器同传技术，可将演讲者的中文同步翻译成英文并实时上屏。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;参考文章：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719470&amp;amp;idx=1&amp;amp;sn=3368dea980517ea7d7942967da2740dc&amp;amp;chksm=871b0090b06c89863620be4e75c757940d03d8a43cd3c1d9a8309b6594c1bccd769cab193177&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719470&amp;amp;idx=1&amp;amp;sn=3368dea980517ea7d7942967da2740dc&amp;amp;chksm=871b0090b06c89863620be4e75c757940d03d8a43cd3c1d9a8309b6594c1bccd769cab193177&amp;amp;scene=21#wechat_redirect"&gt;重磅 | 谷歌翻译整合神经网络：机器翻译实现颠覆性突破&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721480&amp;amp;idx=1&amp;amp;sn=191cb46a8ebbb71519d5d668705aa81b&amp;amp;chksm=871b08b6b06c81a0265fc5de459f78cd5e1e887f3569f57a2e7ccb4ff7835d73c66699cc483a&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721480&amp;amp;idx=1&amp;amp;sn=191cb46a8ebbb71519d5d668705aa81b&amp;amp;chksm=871b08b6b06c81a0265fc5de459f78cd5e1e887f3569f57a2e7ccb4ff7835d73c66699cc483a&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;机器之心独家对话吴恩达：很多技术其实是中国最先开始应用的&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717168&amp;amp;idx=2&amp;amp;sn=462ac989178d34f15ab56947416b8b5f&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717168&amp;amp;idx=2&amp;amp;sn=462ac989178d34f15ab56947416b8b5f&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;机器之心专访 | 讯飞研究院王士进：如何让机器拥有阅读推理能力？&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716160&amp;amp;idx=1&amp;amp;sn=871d9d398de5cf665265e5eeab3dc040&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716160&amp;amp;idx=1&amp;amp;sn=871d9d398de5cf665265e5eeab3dc040&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;专访 | 搜狗的人工智能研发与应用：让技术在产品中创造更多用户价值&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722227&amp;amp;idx=2&amp;amp;sn=4dd4514c3e957422697a8854a2dae8d6&amp;amp;chksm=871b0bcdb06c82dbf69d2f2157b287318471692720449c5f12001188b26830f7fcf0e4d9ce17&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722227&amp;amp;idx=2&amp;amp;sn=4dd4514c3e957422697a8854a2dae8d6&amp;amp;chksm=871b0bcdb06c82dbf69d2f2157b287318471692720449c5f12001188b26830f7fcf0e4d9ce17&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;业界 | 搜狗知音引擎再进一步，实现语音实时翻译&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;算法与应用大赛&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据竞赛是今年中国人工智能领域的又一亮点，学术界、产业界纷纷举办数据竞赛来争取人才，挖掘新技术的产业应用。当然，以下三场竞赛并不代表 2016 年内举办过的全部竞赛，但管中窥豹，希望大家能从中洞见数据竞赛在人工智能发展中带来的益处。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今日头条 2016 Byte Cup 世界机器学习比赛：2016 年，中国人工智能学会主办，今日头条、电气电子工程师学会（IEEE）中国代表处协办了 2016ByteCup 国际机器学习竞赛。这场数据分析竞赛的主题是：如何在社交问答系统中精准地匹配专家和问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;据了解，此次数据竞赛共有 1000 多支队伍参赛，冠亚季军队伍分别是 brickmover、天穹战队和西电战队。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;参考文章：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721644&amp;amp;idx=2&amp;amp;sn=f2145ab0797a722b6887cc8a9ebb219d&amp;amp;chksm=871b0912b06c8004ffb4338f6c790c7b9b50f69b6bf638414ec9e28fab1c5ec5beddbd139ab9&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721644&amp;amp;idx=2&amp;amp;sn=f2145ab0797a722b6887cc8a9ebb219d&amp;amp;chksm=871b0912b06c8004ffb4338f6c790c7b9b50f69b6bf638414ec9e28fab1c5ec5beddbd139ab9&amp;amp;scene=21#wechat_redirect"&gt;专访 | 今日头条 2016 Byte Cup 大赛实战经验分享：要充分挖掘模型本身的信息&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;上海 BOT 大数据应用大赛：今年上海大数据产业基地（市北高新）、上海大数据联盟、英特尔（中国）有限公司和华院数据技术（上海）有限公司联合主办，机器之心协办了国内首个专业化人工智能大赛「2016 上海 BOT 大数据应用大赛」。在计算机视觉与人工智能聊天机器人商业应用这两大热门赛题上，全球近 400 支专业团队进行了角逐。本次大赛从 2016 年 9 月 1 日初赛开始到 11 月 11 日总决赛结束，经历了三个多月。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;参考文章：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720516&amp;amp;idx=3&amp;amp;sn=80ed2bde64e872e29dbeb2bab36e8c0b&amp;amp;chksm=871b0d7ab06c846c28886012b6c117597f5ee3b8617b0095253139a1170aef63f91d09022098&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720516&amp;amp;idx=3&amp;amp;sn=80ed2bde64e872e29dbeb2bab36e8c0b&amp;amp;chksm=871b0d7ab06c846c28886012b6c117597f5ee3b8617b0095253139a1170aef63f91d09022098&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;业界 | 2016 上海 BOT 大数据应用大赛闭幕：决赛 11 个聊天机器人项目盘点&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;滴滴 Di-Tech 算法大赛：今年上半年，滴滴研究院举办首届 Di-Tech 算法大赛，这是一场面向全球大数据人才的算法竞赛。滴滴通过开放国内真实的出行数据，用最炙手可热的研究课题征集更聪明的解决方案。而且此次比赛中获得的解决方案有机会直接应用于「滴滴出行」产品端。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;参考文章：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717305&amp;amp;idx=3&amp;amp;sn=abc06a528c76ed2cb2c16c1991508e07&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717305&amp;amp;idx=3&amp;amp;sn=abc06a528c76ed2cb2c16c1991508e07&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;业界 | 滴滴算法大赛背后，是对人工智能人才与技术的呼唤&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;融资：图像识别公司屡获巨额融资&lt;/span&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;创业、融资是体现人工智能热度的另一个维度。2016 年，我们看到人工智能成为了最受资本市场追捧的领域之一，机器之心很早就关注的一批创业公司接连获得高额融资。下面这三家融资的成功引起了业内极大的关注。当然，这并非完全性统计。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 旷视科技：旷视科技（Face++）是一家专注于机器视觉和人工智能的技术公司，是国内人脸识别领域知名的创业公司。据机器之心获得的消息称，旷视科技获 2000 万美元新一轮融资。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9iaSgfTFRChrskKuUMbnjjpaaXibhfkFkk6z9l8mvoOUQ6jkIduoShibS8EEfJRfpFKiaqouEPWMLvicQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;旷视科技成立于 2011 年，创业之初获得了联想之星的一笔天使融资；2013 年获得创新工场百万美元 A 轮投资。2014 年 11 月，获得 2200 万美元 B 轮融资，2015 年完成 B 轮 4700 万美元融资。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;延展文章：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722208&amp;amp;idx=3&amp;amp;sn=a1f217aa810783e9dfb137072f11d969&amp;amp;chksm=871b0bdeb06c82c853d4d6d4177523e33cd35d10e3c59f6f98b2e1924381cffbc06ace4520b3&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722208&amp;amp;idx=3&amp;amp;sn=a1f217aa810783e9dfb137072f11d969&amp;amp;chksm=871b0bdeb06c82c853d4d6d4177523e33cd35d10e3c59f6f98b2e1924381cffbc06ace4520b3&amp;amp;scene=21#wechat_redirect"&gt;专栏 | 旷视 (Face++) 孙剑：创业公司里的研究之美&amp;nbsp;&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 图普科技：据机器之心一手消息称，图普科技已经于今年 9 月完成了新一轮融资，金额为千万美元，由晨兴资本领投，北极光创投跟投。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图普科技由微信创始团队成员之一的李明强创办，主要做基于图像识别技术的第三方内容审核服务，在识别色情、暴恐、时政敏感信息、小广告等违规图片和视频方面市场占有率领先。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;延展文章：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717202&amp;amp;idx=2&amp;amp;sn=31b6924db5eb4500fa4a57d9669878fc&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717202&amp;amp;idx=2&amp;amp;sn=31b6924db5eb4500fa4a57d9669878fc&amp;amp;scene=21#wechat_redirect"&gt;专访 | 图普科技李明强：用产品思维打造图像识别的场景化应用&amp;nbsp;&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 商汤科技：2016 年 12 月 14 日，商汤科技宣布完成 1.2 亿美元新一轮融资，本轮由鼎晖投资，万达集团、IDG 资本、StarVC 等投资方共同参与。此前商汤科技，曾于 2014 年 11 月获得 IDG 资本的千万美元投资；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;商汤集团是一家科技创新公司，致力于引领人工智能核心「深度学习」技术突破，构建人工智能、大数据分析行业解决方案。目前，商汤汇聚了一支庞大的深度学习算法研究团队，拥有上百名深度学习研究人员。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;延展文章：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716578&amp;amp;idx=2&amp;amp;sn=471e5e957b51feedc88062532a5a041c&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716578&amp;amp;idx=2&amp;amp;sn=471e5e957b51feedc88062532a5a041c&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;CVPR2016 | 商汤科技论文解析：服饰识别搜索技术&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716578&amp;amp;idx=2&amp;amp;sn=471e5e957b51feedc88062532a5a041c&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716578&amp;amp;idx=2&amp;amp;sn=471e5e957b51feedc88062532a5a041c&amp;amp;scene=21#wechat_redirect"&gt;CVPR 2016｜商汤科技论文解析：人脸检测中级联卷积神经网络的联合训练&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716180&amp;amp;idx=2&amp;amp;sn=e217c6b32ee5ef5eb8a6a7470c872e8a&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716180&amp;amp;idx=2&amp;amp;sn=e217c6b32ee5ef5eb8a6a7470c872e8a&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;CVPR 2016｜商汤科技论文解析：行为识别与定位&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716355&amp;amp;idx=2&amp;amp;sn=da3bae2c4352773db3660ca113977245&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716355&amp;amp;idx=2&amp;amp;sn=da3bae2c4352773db3660ca113977245&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;CVPR 2016 | 商汤科技论文解析：物体分割&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 23 Jan 2017 12:33:02 +0800</pubDate>
    </item>
    <item>
      <title>专访 | 搜狗+NMT+团队：神经机器翻译将消除跨语言沟通障碍</title>
      <link>http://www.iwgc.cn/link/4456044</link>
      <description>&lt;p&gt;&lt;span&gt;2016 年 5 月 19 日，搜狗正式上线英文搜索。搜狗英文搜索可提供跨语言检索功能，可自动将中文翻译成英文进行查询，再生成英文查询结果。对于不擅长英文的用户，可以节省很多「先翻后搜」的搜索时间；在 11 月的乌镇世界互联网大会上，搜狗展示了机器同传技术，可将演讲者的中文同步翻译成英文并实时上屏；12 月 21 日，搜狗英文搜索正式升级为搜狗海外搜索频道（overseas.sogou.com），并同步上线了搜狗翻译频道 (fanyi.sogou.com)。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9iaSgfTFRChrskKuUMbnjjpNEibSNticR6Vkhaeo4T0YsHibxsI7HlXCH4GUx0NsnJj2csfbJialvJGJg/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;近三年来，「神经网络机器翻译技术」成为人工智能翻译主流。该技术通过「端到端」的方法将翻译平行语料进行映射，以「编码器—注意力机制—解码器」的结构，解决翻译问题。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自 2016 年 8 月搜狗 NMT 团队成立至今，其自主研发的「机器翻译·一期系统」基本搭建完成。近日，人工智能媒体《机器之心》对搜狗 NMT 团队进行了专访。搜狗搜索技术负责人许静芳、搜狗搜索机器翻译负责人翟飞飞、清华计算机系副教授刘洋，就「搜狗神经机器翻译」的优势、团队组建和技术拓展等问题，展开了深度的分享。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;采访如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;搜狗翻译可生成更流畅的翻译结果&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：神经机器翻译（NMT）将整个输入句子视作翻译的基本单元，相比于之前的基于短语的翻译系统，除了所需的工程设计更少这个优点外，句子意思理解的精确度有哪些提升？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;刘 洋： &lt;/span&gt;&lt;/strong&gt;&lt;span&gt;NMT 有两个关键的技术很重要，一个是 gating，另外还有一个是 attention，这两个特别适合处理语言中长距离调序，比如中英文结构差异特别大，词语顺序存在全局变化，NMT 处理这种情况特别有优势，生成的译文要比传统的方式生成的译文流利很多，这是 NMT 很突出的特点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;翟飞飞：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;在统计机器翻译中，我们使用调序模型来处理不同语言之间词序不同的问题。但在处理长距离调序时，由于搜索空间太大，调序模型很难做到有效建模，导致许多统计机器翻译系统生成的译文存在较多词序错误，难以看懂。但 NMT 的模型架构对处理长距离调序问题特别有效，生成的译文更为流利。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;搜狗翻译有望实现「多场景即时对话翻译」&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器之心：在更高层次上自然语音处理上，实现两种语言的实时对话还需要多久？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9iaSgfTFRChrskKuUMbnjjp33XWRUozgicndicD4mckwkaicShp6icv2cp6u9OArC3jAiaGTSUFFepaVHQ/0?wx_fmt=jpeg"/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;搜狗搜索技术负责人许静芳&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;许静芳：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我觉得这个会很快，当然有一个前提，就是提出什么样的要求，如果要求特别流畅，包括上下文的理解，那不一定能做到。但由于语言的障碍，至少可以从以前的不能交流变成现在能够辅助理解和交流，这个会非常快。在某些场景口语交互或者日常的生活场景上，达到非常流利地交流，我觉得这也是在一两年的时间内可以做得非常好的一件事情。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然这里面也会涉及到更多的口语上的交互，又会和语音挂上钩，涉及到多种语音识别，包括和口音、设备关联在一起，会很复杂。但单纯在翻译这个层面，这个会非常快，现在已经做到有帮助。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9iaSgfTFRChrskKuUMbnjjpbUMVvicyX1wtNkKpkF9oISqtq6zwiaHFTJmqpKCUTTaiaEbZujJ0acDVw/0?wx_fmt=jpeg"/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em style="color: rgb(136, 136, 136);"&gt;&lt;span&gt;清华计算机系副教授刘洋&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em style="color: rgb(136, 136, 136);"&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;刘 洋：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我个人觉得在「多场景即时对话翻译」领域至少有两个挑战。从方法层来说，最难的就是语言歧义性问题，这是自然语言处理所最大的挑战。人类语言和机器语言不一样，机器语言要求精准、没有歧义，比如 C+，JAVA。但是自然语言的歧义性很高，比如英文词「bank」，既可能是指「银行」，也可能是指「堤岸」。口语交互过程中歧义现象很严重。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从数据层面来说，无论是语音识别、机器翻译还是语言合成，都是数据驱动的方法，系统性能严重依赖于标注数据的规模、质量和覆盖率。对于开放领域的即时对话翻译而言，目前还缺乏大规模、高质量、广覆盖的标注语料库。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;搜狗翻译水平已部分超越 Google 等巨头&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：通过深度学习来搭建的实时翻译技术与数据密不可分，搜狗的 NMT 在大型数据集上工作有哪些挑战？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;许静芳：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我想这个挑战应该是对所有机器翻译团队都类似的一个有趣的现象是业内翻译做得好的团队大多来自搜索公司。搜索和翻译本身是密不可分的，这个密不可分首先是数据层面，语料的挖掘，搜索本身天然有优势，在这里面，其实都涉及很多自然语言处理、数据挖掘的问题，搜索积累的经验可以很快地应用到翻译上来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：相较于谷歌和百度的神经机器翻译，搜狗这次发布的神经机器翻译有哪些差异性的特征？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;许静芳：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;首先，对翻译问题的理解、重视和投入问题，在不同的公司不同的阶段是有差异的。其次，聚焦在技术上面，NMT 从发展到应用在商业系统里也就这一、两年左右的事情，本身这个技术正处在非常快速的迭代的过程中。如果现在要去比较我们（搜狗）和百度、谷歌的差异，我们自己本身在翻译的模型，语料的挖掘，特别是深度学习模型很大，用的语料很多。在模型在分布式训练上，搜狗也有自己的创新。我们和谷歌最新的工作去对比，在某些方法上，可以看出我们比谷歌做得好，最终在中英两种语言互译的效果优于也验证了这个事情。搜狗比谷歌更有动力去做好翻译这件事情。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;搜狗翻译技术持续改进，未来可期&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：刚才谈到模型，现在 seq2seq+attention 的模型已经在 NMT 及其他众多 NLP 任务上取得了非常好的效果，我也注意到搜狗的神经网络做到了 5 层。之前有些论文提到了通过增加更多层的网络来取得更好的效果，您认为这个准确吗，通过不断增加网络层数来提升效果？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;许静芳：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我觉得这是方法之一，但不是唯一的方法，而且层数变深了以后，在数据和模型训练，包括网络的结构和优化方法上，都应该去适配这样的网络结构，所以我觉得适当加深层数是一种有效的方法，但不是唯一的途径。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;刘 洋：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;增加层数肯定有帮助，能够提高模型的表达能力，但是层数增加的越多，训练的难度也越大，需要更先进的技术。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：这种模型（seq2seq+attention）在效果方面是否已经达到了上限，从而需要新的模型解决？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;许静芳：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我觉得远远没有，从算法层面，这种网络的结构只是其中之一，包括损失函数的设置、先验知识连接、模型后处理等方面都有很多工作要做。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;刘 洋：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;肯定有提升空间。目前看来，有两个问题非常明显。第一个问题是漏词。很多用户反映神经机器翻译系统在生成译文时经常漏掉重要的词没有翻译，严重影响了译文的忠实度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一个问题是缺乏篇章一致性。目前的翻译都按照句子为基本单位进行翻译，没有考虑篇章层面的上下文信息，会导致翻译同一个篇章出现同一个词在不同句子中的译法不一样。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;搜狗独创的「深度学习」训练模型&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：除此之外，搜狗的 NMT 还有哪些正在应用的模型？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9iaSgfTFRChrskKuUMbnjjpzqR3TxWV0ljQibGR5FG7vo3ia6iarrexib9quvIKVV7QRvswshQw67LeIQ/0?wx_fmt=png"/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;搜狗搜索机器翻译负责人翟飞飞&lt;/span&gt;&lt;/em&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;翟飞飞：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;目前很多通用的 NMT 相关方法我们都在使用，同时依托天工研究院，我们和清华的机器翻译团队也合作进行了很多模型技术上的探索，取得了不错的成果，翻译性能稳步提升。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;刘 洋：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;清华的机器翻译团队由孙茂松教授领导，我是技术负责人。在这次与搜狗合作研发机器翻译系统的过程中，我们多年积累的技术和经验得到充分体现。另外，我们也受到最新的前沿技术的启发，如生成对抗网络和 zero-shot learning。相关的技术目前正在申请专利和撰写论文，预计不久会公开。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：不同语言的语料规模差别很大，英文中的语料非常多，但中文语料就显得非常少。请问，是否能将 NMT 的研究成果应用在不同语言语料构建上，从而提升其他语言 NLP 研究水平？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;翟飞飞：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我个人觉得是可以的，比如现在有各种各样的工作用来自动生成训练语料，但具体怎么操作，还要针对不同的任务，生成的数据能不能拿来使用，也需要经过评测之后，才能判定。。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：搜狗的 NMT 有应用在外部的对准模型吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;翟飞飞：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;外部对准模型是一个相对比较通用的技术，我们也在使用，同时也在探索其他的相关技术。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：在哪些具体场景，搜狗 NMT 的表现会比较好？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;许静芳：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt; 搜狗的机器翻译整体来说有非常好的调序能力，翻译译文流畅，利于理解。英文我们利用翻译的主场景是跨语言检索，所以书面语言的翻译效果比口语还要更好一些，英翻中比中翻英效果的领先优势更突出。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;四个月上线，搜狗翻译打通华语世界与英语世界&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;机器之心：这次根据机器翻译推出了海外搜索，国内获取英文信息一直是非常困难的事情，川总在演讲中也提到过这个。用先进的机器翻译技术切入这个刚需变成产品，而这个产品又会因为用户频繁使用来产生更多数据并优化技术。这可能是我们目前所看到的机器翻译技术最恰当的产品形态。当初我们是怎么想到这种产品思路的？以及海外搜索和机器翻译的良好互动将实现什么样的一种目标？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;许静芳：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;海外搜索的前身叫英文搜索，是 2016 年 5 月份发的一款产品。有几个背景，首先全世界的信息 10% 是中文，90% 是英文。不管是国情还是文化，英文的质量在某些领域是明显高于中文的质量，并且平均水平还是高于中文的水平。其次国人随着各方面的进步，有非常迫切打开眼界与国际接轨的需求。世界是平的，有这样的需求存在。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;搜狗 5 月份发布英文搜索是让用户搜索更优质的英文内容。由于各种原因，国内并没有特别好用的英文搜索，搜狗英文搜索是将优质的英文信息引入，给大家提供这样的入口，才能接触到这样的信息。在 5 月份上线的时候就附带一个小的功能，举个例子，在爆发魏则西的事件的时候，大家要查滑膜肉瘤，查细胞免疫疗法，大家知道中文的概念，而且也明白，更权威性的信息与知识在国外。但是当用户在用搜索英文信息的时候，首先遇到的第一个门槛就是不知道如何用英文拼写出」滑膜肉瘤」，」细胞免疫疗法」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以搜狗英文搜索当时就有一个功能是允许用户用中文查询词，通过机器翻译自动翻译成英文查询词，再找到英文信息。当时面向的用户，是英文相对还可以，但在一些专业术语上需要补足的用户，尤其在不太熟悉的领域，构建英文表达很困难。但是如果返回英文结果，能读懂但比中文结果要困难。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个功能上线以后，在这个主打英文语言的搜索频道，中文的查询词占 20% 以上，而且随着时间的推移，还在逐步的提升。可以说这样的功能是很受用户欢迎，所以我们想把目标用户范围扩得更大一点，英文水平再差一点的同学，也能帮助他去阅读。进一步想法：把搜索结果能够翻译成中文，让不懂英文的用户在这里基本能看懂；懂英文的，借助机器翻译，也能更快到去找到他想要的信息。所以海外搜索的想法是在英文搜索发布不久，就已经萌生出来的，只不过翻译很难，搜索也很难，要把这两件事结合在一起，是难上加难。我们在英文搜索发布之后，大概花了四个月左右的时间，在建立团队的基础上，首先构建自己自主的机器翻译的能力，而且机器翻译的第一场景就是跨语言检索。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;机器之心：现在有很多企业都和高校实验室建立了非常紧密的合作关系，能介绍下搜狗在 NMT 上和清华大学的合作吗？&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;许静芳：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;这是非常成功的校企合作的案例。2016 年搜狗捐赠清华大学打造天工智能计算研究院，机器翻译也是天工智能研究院下面的第一个合作项目，将搜狗的技术能力与清华刘洋教授的机器翻译团队的长期积累相结合充分发挥两个团队各自的优势，最终也取得非常好的效果。机器翻译的技术门槛很高，业内很多团队做机器翻译都是一年以后上线，或者两年以后再上线的，我们其实只花了四个月，这也体现搜狗在人工智能上的优势与决心。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;天工智能计算研究院是 2016 年成立的，但是这个研究院的前身是搜狗和清华计算机系的搜索技术联合实验室，这个实验室已经有 9 年的时间。搜狗一直以都非常支持学术界的研究，我们对学术界开放了最多的数据集，也有着广泛的合作，可以说搜狗在这方面是推动了国内相关方向的发展，也推动了全世界关于中文的研究。2016 年联合实验室进一步升级成研究院，还有很多其他项目正在进行中，相信马上会有一些其他的成果会出来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 23 Jan 2017 12:33:02 +0800</pubDate>
    </item>
    <item>
      <title>演讲 | 中科院徐波：中国脑计划的现状和发展方向</title>
      <link>http://www.iwgc.cn/link/4456045</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;编辑：虞喵喵、李泽南&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;去年 11 月底，中国科学院神经科学研究所、中国科学院脑科学与智能技术卓越创新中心、香港科技大学生命科学部和分子神经科学国家重点实验室、中国科学院自动化研究所在《Neuron》上联合发表了一篇概述论文&lt;/span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720765&amp;amp;idx=1&amp;amp;sn=d023cbc68ce9cec7e00ebc44d940a7d9&amp;amp;chksm=871b0d83b06c84952a94754e60f22126dd64a9c198deaeccc7ae3c6dc04eb0f190c9877de4f3&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720765&amp;amp;idx=1&amp;amp;sn=d023cbc68ce9cec7e00ebc44d940a7d9&amp;amp;chksm=871b0d83b06c84952a94754e60f22126dd64a9c198deaeccc7ae3c6dc04eb0f190c9877de4f3&amp;amp;scene=21#wechat_redirect" style="font-size: 14px;"&gt;《China Brain Project: Basic Neuroscience, Brain Diseases, and Brain-Inspired Computing》&lt;/a&gt;&lt;span&gt;，介绍了「中国脑计划」在基础神经科学、脑疾病和脑启发计算上的研究进展。中国脑计划引起了人们的广泛关注。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最近，该论文联合作者之一，中国科学院自动化研究所所长，中国科学院脑科学与智能技术卓越创新中心（CEBSIT）副主任徐波在中国中文信息学会第八次全国会员代表大会上做了「类脑智能研究及发展方向」的主题演讲，以下是机器之心现场整理的内容。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8pKMq7FfCv5GPQGsEnoqGPiczSpylOd5ZXiauvheaUaeXhq6icDJibtNFvic6PQlhHoSbicy9DwViaI5bqg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;非常高兴有机会能和大家一起分享，类脑研究出现的时间不长，这个领域里有很多不成熟的地方，希望我们的研究能为大家带来新思考。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;众所周知，人工智能是目前科学界的研究热点。在人工智能领域里，除了深度学习以外，类脑计算这个词出现的也越来越多了。类脑计算通常是指研发新类型的芯片，电子器件和体系结构等等，在软件上与信息处理研究，构建模型和算法等等相关。类脑计算还有一种提法，在 863 的课题里面叫做类人智能。类人智能主要是行为级别的考量，目标是在功能上产生与人可以相比较的智能，但不关注达到目标需要使用什么样的方法，所以这里面有一些细微的差别。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在英文里，类脑在学界存在着不同的说法。有人喜欢用 brain like，顾名思义，通过研究复制或者部分复制人类大脑，这种说法忽略了如何复制大脑；另外一种是 brain inspire，受脑启发的智能，或者受脑启发的计算，简称类脑。这是基本名词和概念的解释。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在内容的第一部分中，我选择了和计算学习相关的一些方向进行介绍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;脑科学对人工智能的启发&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今年 1 月初 AlphaGo 打败众多围棋冠军是人工智能快速发展的标志。但其实人工智能最大的前景在于它会在未来 5 到 10 年中与各个行业深度融合。这是一个艰难的过程，因为每个行业都有它的门槛，但是不管怎么样，人工智能已经成为一个国家层面的战略方向。我们现有的大多数的智能可称为大数据智能，或监督数据学习，它的最大特点是：这个系统呈现出多大的智能，它的背后就存在着多少人力的投入。包括围棋的应用、语音识别、图像识别，都需要大量的人工标注性的工作。但是，我们看到的大数据的智能，有两种问题无法解决：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一类问题被称作超大规模空间，这意味着状态空间非常大，数据再多，对这样的问题而言都是稀疏的。此类问题用现有的方法很难解决。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一个问题在于现有人工智能都是专用的智能。下围棋的系统不能下象棋，扫地的不会擦桌子，它基本上没有自我学习，举一反三，触类旁通的能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;反过来看看人类的大脑，欧盟 2012 年的脑计划报告中写道：在自然界里，除人脑以外，还没有一个自然或者人工系统，能够具有对新环境新挑战的自适应能力。新信息与技能自动获取能力在复杂信息进行有效的决策，并稳定工作，直至几十年的能力。也没有任何系统能够在多处损伤的情况下，保持像人脑一样的鲁棒性。而且与其他人工智能相比，人脑的功耗非常低。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;受脑启发的智能，据我们的理解，实际上是横跨脑科学、认知科学到智能科学，并持续发展的一个方向。在脑科学中，有很多个尺度的大脑的观察机理可供借鉴。其实在很多的脑计划里面，比如美国的脑计划（2013 年启动），它的重点是在突破大脑的观察的技术，测量的技术，希望能看到每个神经元的放电活动。而日本的脑计划（2014 年启动）主要关注于脑疾病。欧盟的脑计划（2012 年启动）主要是做大脑模拟，为新一代的信息处理的研究提供依据。从其他国家的类似计划中我们可以获得很多信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8pKMq7FfCv5GPQGsEnoqGPtgvPVGblKUicLQRFV1eU5jSQ92TRuIiaAP8nCOAmECmCkfk0g3Aj9Vsw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外，在认知科学中，我们也可以获得很多的信息。比如近年来，我们在大脑中的视觉、听觉、语言中对于认知通路的研究正在变得越来越清晰。在这其中视觉通路的研究是最多的，这些研究为我们理解脑认知功能奠定了基础。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;智能科学大家都比较熟悉了，本来就存在一套计算方法在这个领域发展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8pKMq7FfCv5GPQGsEnoqGPDPVUrCy7sF1bj0jzd33G358F8RyFbRhsAtibNwTCPgNjMGObnXSKWpA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;类脑智能的核心问题在于：我们能不能把脑科学、认知科学和智能科学里面的一些研究成果整合起来，来产生比我们现有的人工智能、神经网络、深度学习，更好的算法和模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如图所示，类脑研究有两个源头，一个是神经科学。这是一个统计，过去三十年产生的神经科学的知识，大概是 80 年代以前的 46 倍。现在的神经科学发展速度更快，因为神经科学的发展，主要依赖于新技术的出现。现在每年神经科学新发现的数字，是 80 年代以前的 100 倍，这个速度还在不断加快，越来越很多的知识可供我们使用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从类脑智能角度，人们可以借用什么东西呢？从大的角度来说，或者多尺度的大脑信息处理，这些机制能不能被我们所用呢？我们现在知道神经元的类型非常多，人脑中有上百种神经元，粗略分类至少有有抑制性的跟兴奋性的两类的神经元。然而，现在的人工神经元都是单点式的简化的模型，还有人在做有树突的人工神经元模型。第二，神经突触的形成跟消亡，是我们最基本的学习的机制。现有的人工神经网络输出都是一类函数，而生物的神经网络，是一种神经兴奋发放模式，一个被称为尖峰神经网络的机制，它和现有的计算机神经网络不一样。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;现有认知模型&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关于可塑性机制，最基本的可塑性机制比较简单，但在整个大脑中又会产生非常复杂的现象。关于连接，就是神经元的前项连接、后项连接跟撤销的意志，这在生物体内都可以观察到，这就是所谓的神经元。从脑区级别来看，像神经回路、功能环路、基底神经节、丘脑型这样的感知决策模型，和像前额叶脑区、运动脑区等形成的模仿学习功能，像多感知的突兀，它是视觉、听觉、触觉向外脑区上颞叶，与整合区形成了一个多通道学习和记忆方式。它是不同的认知和不同的脑区相互协作的结果，从通用智能角度来看，生物体中还有很多机制可以借鉴。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从认知来看，我们对人脑处理外界信息的方式已经有了大致的了解。人类拥有视觉、听觉、触觉、嗅觉、味觉，结合短时记忆经过工作记忆的处理，可以慢慢地把信息进行理解抽象，变成长时记忆，人类会在成长过程中慢慢形成自我的概念，形成过去的经验。长时记忆会对后来的视觉、听觉、触觉产生反馈与影响。所以从认知的角度来说，记忆模型各不相同，不同类型的记忆实际上利用了不同的通路。像程序性的记忆，我们一旦掌握了某些技能，比如学会了骑自行车，学会了游泳，你就可能永远会都不会忘记，所以这些程序性的记忆，还有像无意识的条件反射，大多被称为内涵式记忆，当然还有外显式的记忆等等。我们在认知科学里面可以做很多认知实验，这些问题将来我们都会去验证、去发现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从认知科学中我们将获得什么？其实最典型的就是很多人都在用的 random、推理、tension memory 这样的模型。此类模型有三个部分，其中一个就是短时记忆。比如我们进行小组对话，用这个模型做关于对话的理解，那整个对话的意思就是一个短时记忆，系统进行编码以后再进行工作记忆处理，随后你对这个对话可以提出任何问题，系统会产生响应。但在这个对话里面，在理解一个问题的时候，可能需要很多背景的支持，这些内容可能存储在长时记忆模块里。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是一种典型的模型，我个人认为它是受到认知科学启发的。深度学习研究者们正在进行这方面的研究，这也是我们做的，我们把 tension 机制细化到词级别的颗粒度上，通过多轮的迭代，最后获得需要的答案。由此观之，类脑就是人工智能的发展动力，至少是一个可以参考的路径。除了欧盟、日本，在美国脑计划中专门有一个项目叫做 mapping，通俗来讲，它是要研究一立方毫米体积的一个脑区，把它整个从外面到突出极的所有连接结构绘制出来，美国在这个项目上投入了 1 亿美元作为启动资金。他们下一步计划把探究出来的结构用到人工智能里面。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;中国在 2016 年的人大上通过了十三五的发展规划，其中脑科学与类脑研究成为了 100 个重大项目里面的第四位，这些部分都是和脑科学相关的，不仅是疾病研究，还有类脑研究。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;换个角度，从人工智能的角度求解这个问题。面对常规的一个问题，系统的求解需要把一个问题形式化，不论是律师、媒体还是下象棋，一定首先需要人的介入，把这个问题分解成几块，其中每一块都可以转化为一个图灵机的问题。然后再用现有的计算机结构来实现人工智能问题的求解。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从类脑智能的角度来看，我们希望计算机能够通过像人一样用序列化的学习方式来减少对人工形式化的依赖。如果我们实现了这一设想，我们就非常接近通用的人工智能了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这就是第一部分内容：类脑研究主要将不断从神经科学、认知科学，尤其是神经科学中受到启发。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8pKMq7FfCv5GPQGsEnoqGPicZxTgBeJWTzDYC50rfCqgR9dd3KevVFCqX72ac7BeZqKVgFzI0MW1Q/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;类脑研究的主要方向&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;类脑研究具体是哪几个方向？我们正在探究各种可能性，我们认为大脑具有高度可塑性机制。未来的人工神经网络或许可以受此启发。这是一个 STDP，它描述了人类局部神经元之间突触的连接强度，随着相邻两个神经元先后放电的时间差异——增强或减弱而产生不同表达的神经的机制。这是生物学习机制中最基本的元素，它实现的功能是通过有持续地激活神经元集群，产生神经连接发生有序的强化，可用于储存信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这样一个简单的、生物化的学习机制。它是无监督的，非数学化的。例如在空间维度信息的学习和记忆、手写数字识别、图像存储与提取、以及机器人的动作序列学习，还有短周期节律的学习都可以借鉴这种机制。实际上研究人员已经在进行此类探索了。这样的学习机制将会与目前不同的人工神经网络，包括现有的监督学习去比较。它目前的性能比生物体中的效率要差一点，但是仍然达到了 95% 的准确率。目前的探索证明了生物学机制的潜力。纯生物 STDP 可适应机制可以让机器人学会绕着某一条线走路。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是一种轻监督的任务，机器自己理解路的概念，理解需要沿着路前进。我们在加油站外广场的 24 小时监控图像里，通过人工智能分析，可以识别图像内容，而且对内容进行分类。此外，我们开发了序列记忆系统，它可以识别音乐节拍，然后重现出来。所有这些都应用了这样的机制。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从微观角度来看可熟悉机制，无监督的学习方法已经在上述的一些任务里取得了一定的进展。但是它引出了认知范围的能力的问题。目前的无监督学习只能适用于有限范围内的任务处理，因为它基本没有在结构上面做特别多的处理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这一领域的研究还有很多方向可以进一步深化。比如秒量级的节律信息处理，就是说研究节拍之间，比如节拍超过几百毫秒的时候，STDP 怎么如何记录这种节拍。如果希望使用生物的学习方式，一定要有结构的配合，包括信息的无监督编码的提取和复杂特征的编码。在这一方面，比如 spike，这个神经网络功耗非常低，同时是弱监督的。生物机制中的 bottom-up 与数学上的 top-down（目标函数驱动）的方法如何整合，来形成新一代的人工神经网络，是未来我们研究的方向。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8pKMq7FfCv5GPQGsEnoqGPymZoPBXpHk6P7icBE1jUfqEgUGMRfx3Inic7QxAYM80WaZEjg3PibriaibQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在有很多其他领域的学者跨界在进行这方面的研究。本次讨论的关键词，可塑性机制，脉冲神经网络（脉冲神经网络和人工神经网络的输出不同，它不可微分，所以数学上的原有的理论不能适用）还有强化数据深度学习。这些概念，如何整合在一起？如果可以提出一个新的模型，它的学习效率更高，对数据的依赖性、监督性、标记的依赖更弱，会是非常有意思的工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8pKMq7FfCv5GPQGsEnoqGPIIaA324YuuicXTwUFAPN0MiatJfkRNpWaOoImNAeDO2pOYH7kUOEQ1icg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二个方向，实际上认知功能都是由若干个环路或者是一个通路组成的，是若干脑区构成的一个通路。这个体系作为整体呈现出人类的认知功能，从计算的角度来看，最核心的问题在于，不同脑区之间是什么样的协同关系？刚才的讨论中已经提到了一部分，很多的功能，包括模仿、决策、整合，都需要十几个脑区协同合作（假如细分的话，这个数字会更大），但整合起来才能产生复杂强大的认知功能。脑区有几种组织方式？我的看法倾向于层次化的方式，尤其在感知方面，在视觉方面这种方式非常明显，从感官到第一要区，再到高级的认知功能和记忆、判断推理、眼动、控制四肢手、运动规划都有这种方式的痕迹。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8pKMq7FfCv5GPQGsEnoqGPYH6ztxz1Zrpia7d45WndFjXD42aUIs2ROcsALz7QJC5qeeNwzfDwDQg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一种组织方式体现在高级认知系统中，我认为是模块化的。不同的脑区之间有相互反馈和信息的交互。比如记忆系统的沟通，强化学习性，它的连接关系相对来说是层次性的，比视觉系统复杂。在研究协同方面，我们也做了很多工作，比如视觉和层次的研究，我们根据现有的神经科学数据，构建了视觉的各种模型，它和以前的此类模型，包括 20 年前的听觉模型等方式大不相同。在新的视觉模型中，我们通过多层次构建了一个符合生物进化机制的目标函数，来求解区域之间的连接强度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然模型每层之间也有新的特性，例如侧向连接。模型中神经元的数量来自于一些生理数据。受到这些结构启发的模型，它在感受、空间分布，还有相应的神经元细胞的响应，实际观察来看同步性是非常相似的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然，模型还包含有类结蹄组织结构，神经元的倾向分位，差异分布等等特性。我们看到的协同，就是层次化的脑区的协同，我们希望能够构造符合生物进化机制的目标函数，使得它能量消耗最低。具体表现为突出的、连接的低能耗，还有表征的低能耗。另外我们从多脑区、高级定制、协同等方面也进行了研究，开发出了进阶模型。模拟了十几个脑区，完成从视觉编码开始，到最后做出决策的所有任务。这种模型被称为运动感知和决策模型。其中包含兴奋性通路和抑制性通路，还有内部的连接关系及扩散结构，不同的脑区相互作用等等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;应该说，这个模型基本上是用仿生的思路开发的。另外，我们对单个神经元的类型也做了很多的尝试。我们用不同类型的神经元构造出整个网络，模拟了脑区之间的竞争的机制，学习行为选择和权重更新等机制。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个模型最终展现出来的学习机制总体而言比较简单，就是通过多巴胺的释放来调节学习的速度，这有点类似于奖惩信度分配——强化学习里面的逻辑机制。它呈现出了类似强化学习的功能，但它的复杂度、学习的速度都比后者要快。我们把刚才提到的视觉层次化与运动决策模块化整合在一起，研究无人机躲避障碍和处理突发事件的新方法，这些实验也是我们研究的一部分。这类研究最大的特点就是它具有可解释性，它完成每个决策时，每个脑区，每个神经网络发挥的作用都可以解释的，研究者可以清楚地观察到。这是我们新一代人工神经网络的重要特征。它不像现有的监督学习方式，在训练后处于黑箱状态，人们无法获知神经网络每一层的功能。我们的模型从仿生角度设计，可以较清晰地观察特定脑区在发挥什么样的作用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第三部分更加复杂，但对于类脑智能的价值也非常大。就是探究如何构造一个可以发育演化的模型。现有的神经网络学习与人类最大的区别在于时间尺度。人类的学习也许会经历几年或几天，它的时间序列非常长。我们目前的感知系统无法这样学习。我们的机器学习始终把目标函数作为优化的唯一的机制。而且在优化过程中，我们能看到其中有很多表示，其中印证了神经科学的一些发现，包括刚刚讲到的脑区细胞类型、分子状态、计算和存储的机制。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在最早神经科学把神经元的概念引入到机器学习中，启发了深度学习等方式之后，最新的成功研究和神经科学的关系越来越少了。但是，我们现在看到神经科学与机器学习融合的新机会正在出现。我们首先意识到机器学习的目标函数正在变得越来越复杂。现有的大多数神经网络都是单一目标函数，但有很多的神经网络可以随着不同的神经层、深度、时间产生变化。比如学习次数不同导致目标函数的不同, 它可能会有持续的捆绑性，我们在底层机器学习的设计中也许需要把它考虑在内。还有大家最熟悉的对抗式学习，它是由两个神经网络组成的，用一个网络修正另一个网络的输出的目标函数。这些方向为我们未来的机器学习模型打开了思路。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了使优化更加高效。机器学习已经发展出了不同的网络结构。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;神经科学与人工智能之间的关系存在三大假设：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1、大脑具有优化目标函数的能力。大脑特定的脑区，特定的结构具有在数学层面上优化目标函数的能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2、目标函数在不同脑区和发育阶段是不同的，现代机器学习的发展，实际上也是从这里受到启发的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3、大脑中存在大量的专用机制，这是天生的、在进化中得来的，可以有效地解决一些关键的计划问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从大脑优化目标函数的方式中，我们可以观察到人类在运动过程中其实有很多的策略，从进化角度考虑，人类必须减少能量的消耗，减少运动的风险，降低受到伤害的几率。我们目前认为目标优化策略机制在大脑中广泛存在，它们形成了不同的特定处理方式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那么大脑目标函数优化的确切含义是什么？有很多的网络结构，比如馈增网络，有些存在反向通道，STDP 机制和一些相关结构。在经过学习后可以产生和数学上的 BP（错误反穿）一样的效果的学习机制。但目前有关大脑中存在 BP 学习机制还是一种假设。在神经科学中，哪一种运行机制假说是对的还没有定论。但这些假设可以给人带来很多启发。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二个假设是目标函数在不同脑区和不同发育阶段是不同的。这很容易让人理解，在构造神经网络应用的时候，可能一个网络被用于进行分类、决策，另一个网络会不断地随时间、环境，或者被其他动机驱动，产生变动的目标函数，因此，这个神经网络就会更加适应环境，具有更好的表现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8pKMq7FfCv5GPQGsEnoqGPzzNE8D9tdwNb7lEw5exzhofjCZU9dM5P0ztUibc8x6vZbQrXAevvN3w/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前的深度学习正在向无监督方向发展，人脑是否存在真正的无监督学习？我们现在仍然只能进行假设，因为大脑实在太复杂了，目前的神经科学还难以支撑这样的结论。顺着假说的思路，利用无监督学习来解决特定的问题是目前研究者面临的挑战，如果按照刚才的优化目标来看，大脑目标函数是随着时间和不同的发育阶段而变化的。因此，我们需要探讨的问题是，真正的演化是不是根据当前的状态？我们能不能通过一系列目标函数来建立回路和行为？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们总是希望用较少的数据来训练完美的模型，人类的大脑在进行学习时不需要一个具有数百万已标记数据的数据集来训练。人类只需要一些简单的逻辑和少量事例，就可以触类旁通，仅需要非常少的数据即可完成训练。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在，我们希望计算机可以把复杂的问题分解成若干的不同的阶段，每阶段只需少量数据进行训练，输出相应的目标函数，如果这个方向出现了成果，那么人工智能就向前迈进了一步。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二，在增强学习上，我们目前认为大脑中普遍存在此类机制。增强学习和深度学习正在不断地被整合，此类研究也已经出现了很大的进展。它的基本思想就是用强化学习来产生定义的目标，也就是说所谓的有效错误反弹，它也可以理解为通过学习需要达到的目标，加上强化的过程。我们可以把这种学习方式理解为不断变化的 cost function，加上半监督学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第三，专业系统如何进行有效计算的问题，这与实现机制结构相关。不同模式的信息在不同领域中被用来解决各种类型的问题。有些区域是 highly recurrent，有些区域是在不同的激活状态，有些区域好像在做信息的路由，基底区在做增强学习跟离散的决策。在大脑中可能存在一些较为固化的结构在做无监督学习，这意味着深层次的模型可能是大脑中的固定结构，因为深层次模型是不需要监督的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;还有一些有关物理世界固有特性的目标函数，比如说一个物体，我们推动它会产生惯性。在特定结构下做出优化，即使有一组强大的基因来决定，我们的 cost-function 要在一个空白的网络上演化出复杂的认知也是非常困难的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8pKMq7FfCv5GPQGsEnoqGPFDq1kmYspzFKU2iah0ibItZ4Gyd6XAIZHouDubxmKV0TpmSHiaMq9HfoQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;从大脑中寻找灵感&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;预设一个结构对解决复杂问题而言是必要条件，优化公式的学习是在复杂的动态的协同过程中完成的。我们知道大脑中存在很多特殊结构，用于完成各种类型的任务，这种机制并不需要经过大量学习。目前，智能研究社区非常关心大脑到底有没有反向传播（backpropagation）机制，我们可以设计一种模型，实现类似大脑的反向传播，但从生物学中更复杂的技术层面上看，类脑的角度是非常有益的。无论如何，一旦生物运算机制被我们破解，我们就可以把它复制到计算机领域中，使得人工智能程序的学习变得更加简单、更加有效。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在演化部分里有这样一个结论：假如我们目前的技术向内容的认知能力方向发展，最后出现的算法将会远远超出目前硬件技术所能容纳的范围。从大脑的角度来看，目前人造的数据驱动方式都无法达到人脑的运行效率。所以，我们需要转变思路，吸收很多的模块化机制，反应偶然性的推理方式，原始物理和心理机制，来构建能够理解感知现实世界的模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;DARPA（美国国防高级研究计划局）的局长在 2014 年的一份报告中讲到：生物是自然界的终极创新者，任何直观创新的机构如果不从作为复杂系统的大脑中寻求灵感，都将是愚蠢的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大脑拥有上千亿个神经元细胞，百万亿的突触形成的网络，其复杂程度也许让我们一时难以复制。我可以先用一个简单的模型来说明这个问题：亚马逊蚂蚁，上千只蚂蚁组成的群体，当它形成一个环形的运动状态，它会一直爬行，直到所有蚂蚁都累死为止。但是当遇到阻碍的时候，它们又能搭桥；碰到蛇的时候，它们可以互相配合进行抵抗。蚂蚁的行为非常简单，但它们可以通过协同合作来完成个体无法做到的任务。对于大脑来说，原理也是类似的。当我们最终了解了大脑的复杂系统信息共享，自主性和实际性信号处理等等机制的秘密，人类的科技水平将会出现新的突破。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8pKMq7FfCv5GPQGsEnoqGPdT1IYKAocGibMRuADOic5r079uy0Pwic5DmUnwo8dOKmcaYeQdM3QaicCQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有人说现代科学已经进入了复杂性微积分时代，我们正在从多种研究角度，从心理、计算、动力学、混沌、进化等不同的角度在研究复杂性。但是整个生物学领域里面，越来越多信息处理的思想来正在形成我们理解动物行为的理论框架。虽然在生命系统中，信息的处理和计算的完整概念还非常的模糊，科学家们对于它定义的形式化都还没有形成共识。但是，可以预见的是，计算机科学及更广泛的计算领域终将从类脑智能的研究中获益。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以上是我个人对于类脑智能的一些见解。这是我们目前正在进行的研究，把一个鼠脑的几百个脑区，七千多万个神经元用一些现有的信息处理方法进行完整的模拟。现在，我们的研究还处于初始阶段。在全脑的尺度中，即使是一些非常初级的功能也需要进行大量的探索，但我们的征途已经开始。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谢谢大家。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编辑，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 23 Jan 2017 12:33:02 +0800</pubDate>
    </item>
    <item>
      <title>干货 | 创业经验分享：如何打造一家硬科技创业公司？</title>
      <link>http://www.iwgc.cn/link/4456046</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自backchannel&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：邵明、微胖、杜夏德&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;人工智能时代的黎明已经到来，在科技创业这个领域，旧的规则已经不再适用，Lytro 公司 CEO Jason Rosenthal 近日在 Backchannel 上发表了一篇文章分享了他打造硬科技（Hard Tech）创业公司的经验。百度首席科学家吴恩达也在其社交网络上分享了这篇文章并评论说：「比起大多数消费产品（主要是消费者风险），硬科技产品（带有技术风险）需要更耐心的投入。」&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote style="color: rgb(62, 62, 62); font-size: 16px; white-space: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicKlJibSVAicqxlFTC2znL3Mf9u3t5kywibwDVm6P2brqrDPxyvvg5lYJQVzxP1kV6mplJnfoAq7M98w/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;几年前，我有一个惊人的发现。我用了不少于 15 年时间去开发和发布科技产品，但是突然间，过去练就的技能和直觉变得没啥用了。实际上，如果我还坚守着这些旧东西，它们会把我的公司毁掉。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是我创办自己的公司 Lytro（打造用于电影、电视节目和虚拟现实体验创作的新型摄像头和软件）的一点领悟。创办 Lytro 后，我开始面临着一种新的挑战——一种「硬科技初创公司（hard tech startup）」面临的挑战。创办这样的公司，你一开始并不知道发明所需的核心技术到底能否奏效。物理学、生物学和摩尔定律都以意想不到的方式折磨着你。设计一款赢得市场的产品已经够难的了，但是这些赢科技创业公司面临的困难更大。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Lytro 的目标是向释放虚拟现实、传统电影和电视行业的创作自由。有了 Lytro Cinema，导演和摄影师就能在后期制作中，借助计算机控制镜头的更多方面——比如焦距、曝光、帧速率。为此，我们不得不开发世界上最高分辨率、帧速率最高的图像传感器；发明一种新型的光学器件；解决海量数据带来的存储难题；创造一种全新的成像算法（imaging algorithms）。当初着手时，我们并不知道能不能做到这些。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;面对这种挑战的初创公司必须抛弃传统创业智慧。在过去的十年间，Eric Ries 的经典书籍《精益创业（The Lean Startup）》已经为开发成功的产品和公司设置了默认准则。全球互联网用户的数量急剧增加，基础设施的成本大幅度减少（如亚马逊网络服务），企业家可以快速、低成本迭代某个想法并实现产品/市场匹配。智能手机的爆炸性增长和社交网络的兴起扩大了产品分布渠道，年轻的公司接触自己的目标客户变得容易得多。但是，这些经验规则不适用于硬科技初创公司。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我采取了全新的思维方式，并对这种思维演进感到非常振奋，我相信我们正处于将科幻小说主题转化为现实的边缘。如今，最活跃的创业领域之一就是硬科技领域，包括自动驾驶汽车，太空、人工智能、虚拟现实和基因组学。较之传统互联网产品。这些硬科技公司的产品可能更激动人心，意义也更加深远。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以下就是我的硬科技创业经验。尽管这个例子是 Lytro 特有的，但是我相信它们广泛适用于那些正在试图利用全新尖端技术的公司。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1.从最小可行技术性验证（the Minimal Viable Technical Validation，MVTV）开始&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;众所周知，一种流行的产品研发方法就是最小可行性产品（MVP），其目标就是开发只具备足够功能的产品，看看早期客户群体反响如何。这个过程通常很快、节约资本还能迭代成功方式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是，这套方法对硬科技产品却不起作用。这里，你通常要解决尚未有人成功解决的问题，所以，你不得不想出最快最节约成本的方式去确定自己的建议是否可行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2015 年初，我们遇到过一个典型案例，当时我们开始尝试在系统核心部位加一个光场图像传感器。光场相机不仅能像传统相机那样捕获光的强度，还能捕获给定场景中其他光学特征，例如光的传播方向。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了实现产品目标，我们需要一个能记录每秒 300 帧的 755 兆像素（MP）的传感器。这像素大约是当前行业标准（8.3 MP）的 90 倍。我们自己打造这样的传感器将会花费 3 年多时间以及 1000 多万美元——如果我们可以做到的话。所以，我们首先要知道这个核心想法是否具有技术可行性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们的团队由 Jon Karafin 和 Brendan Bevensee 领导，我们的团队不是试图白手起家构建目标传感器，而是决定将许多现成的图像传感器拼接成一个巨大的单片传感器，实现 755 兆像素（MP）的目标。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一步，确定是否使其中两个传感器很好地协调工作。单单这一过程就需要相当多供应链管理工作和校准工作。这是我们团队制作的第一个测试图像：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicKlJibSVAicqxlFTC2znL3Mf138YVvj8qcWcoOZ811XibDB46PX3STJwnlSrVkegOeYMTSWJpLCELUQ/0?wx_fmt=png"/&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Lytro 的业务发展副总裁 Jim Migda 不情愿地为 Lytro 相机拍摄第一张测试图像摆姿势。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;结果，MVTV 给了我们继续往下走的信息构建小规模、低分辨率的光场视频采集系统。尽管我们保持分辨率和 MVTV 一样，但是，我们增加了所有能将其转化成光场系统的软硬件。我们整个项目的代码是 Trillion, 所以，我们将该原型命名为 Mini-T。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicKlJibSVAicqxlFTC2znL3MfpAzggCglT49ZDEC9cpH7jlNgM6IJtYicZacOm9iaoTKIMkMNrn36hCLQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Mini-Tin 的实验室和野外测试拍摄&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使用 Mini-Tin，我们开发了一套 demo 和概念验证，它们给我们继续构建完整系统提供了信心。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;iframe class="video_iframe" data-vidtype="1" allowfullscreen="" frameborder="0" height="417" width="556" data-src="https://v.qq.com/iframe/preview.html?vid=p0369ylpobh&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0"&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;/span&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;我们的第一个低分辨率光场视频显示了 Lytro Cinema 的一些计算能力。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然后，我们又用了 8 个月打造出产品的第一个版本，并在 2016 年 4 月（距离项目启动时，仅过去 12 个月）的 National Association of Broadcasters (NAB）会展上发布了该版本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicKlJibSVAicqxlFTC2znL3MfYvVMdia0ia2yJI6vrJqQwT8FdVDP8JJg47aFZtXhLWCpiaa8aWibG9lqvQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2.如果破译供应链没能杀死你，那么它会使你更强大&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;专注于融合专有硬件和软件的硬科技初创公司的最大挑战之一是关键组件可能不以你需要的形式存在——如它们存在的话。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当我创办 Lytro 时，我天真地认为解决这个问题很简单，就像去中国深圳或者其它一些制造中心一样，与领先的供应商和合同制造商对话，要么找到现成的东西，要么去说服供应商调整现有的零件。毕竟，为什么这些供应商不和一家能开发很酷的产品并且具有开创性的硅谷公司合作呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWicKlJibSVAicqxlFTC2znL3MfOJiaqb1aGFNIU3LbXwcXfF97ibzWj2cwCvjhIcMrLeoJ0cQNsCjgbXJA/0?wx_fmt=jpeg"/&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;中国深圳是技术世界里的制造中心。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;结果证明我完全错了。找出最能够为你提供所需产品的供应商们本身就是一种暗黑艺术。大型科技公司经常利用市场的力量确保别人不能够利用它们供应链中特别重要的部分。智能手机行业里经常使用这种策略，这里的竞争超过显示器、镜头、光学、房产和其它组件行业。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一次经历这个过程是艰难的。我们必须找到图像传感器、相机的电子产品、光学产品的适当组合方式。很多时候我都觉得我们完成不了，路走到头了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicKlJibSVAicqxlFTC2znL3MfHlu4CZ0SvXCIUF4TO2kqunrMAzQRZ5CWhWP65UybN9ibHdUhh3jnVKg/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随着时间的推移，我开始发现这个挑战是发明过程中的有趣部分。这是既是一个寻求合适供应商的寻宝活动，也是一个解谜游戏。因为在此过程中我们要学着改进我们的设计，找到我们想要的东西。在第一次解决这个问题的过程中经常会产生一整套改进现有设计的新思路。并且这些新思路可以成为一家公司竞争优势的来源。在我们的案例中，最符合我们要求的供应商自于美国和欧洲，而不是亚洲。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3. 从原型到产品的过程比你想象的更难、更漫长&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以，你已经成功建立了一个改变游戏规则的产品的原型。所有的主要功能都像你设想的那样，甚至更好。你丢掉了第一个测试版客户。你相信自己可以改变整个产业或者人们的生活方式，这种信念非常强大。这一路上，你唯一需要面对的是将你的产品原型转化成强大的产品，并准备好面对顾客对你产品的严格审查。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;预测任何技术从原型转化成产品所需要的时间、努力和资本都是困难的。但是，根据我经验来看，预测硬科技产品周期特别困难。一个好的经验法则是，在最保守的时间、成本估计的基础上，投入双倍的时间和成本。原因是，你正在硬件和软件水平上试图去做从来没有做过的事情，面临的是完全未知的境况。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 Lytro Cinema 的案列中，我们发现关于系统的每个部分，包括机械、电子、光学部分都至少要进行一次重大返工才能满足未来客户的需求。（我们的目标客户是大型预算电影和电视节目，毫不奇怪，这些客户是世界上最需技术和创造性的客户之一）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;许多硬科技企业家在首次将硬科技从原型转换成产品的阶段中，大大地低估了这一阶段所需要的时间和成本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在我与许多在 Kickstarter 上发起项目的企业创始人的对话中，我发现从原型到产品的这个过程中，许多项目比预期延长了数月、甚至数年，这远远超出了最初的预测。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;4.&amp;nbsp;先慢后快&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;建立一个硬科技初创公司会让你面对一系列有趣的智力问题，这些问题有潜在的巨大社会影响。在这里，竞争通常没有主流产品间的竞争激烈，不受硅谷「超速发展」的魔咒的束缚，但是却极需创业者的耐心。当你要打造一个极具颠覆性的技术或公司，其依赖的核心是全新的技术时，小心选择最初的客户是至关重要的事情。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对我们而言，这就意味着要密切关注最初几个客户的成功和满足感，这是我们业务的基础。如果从 20 个或者更多个客户着手，成功地抓住了一些客户目标，同时丢失了另外一些客户目标，这是一条更困难、更具风险路。为什么呢？因为，最先满足最先成功的客户将会是你最好的伙伴，会为你的产品吸引更多的客户，一个接着一个。要留出一些时间和空间去了解你的最初客户，去解释未知的未知事情，从少量的客户出发，去了解客户对产品所期盼的、需要加强的部分更容易。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;许多领域的技术创新都有它的起源，今天我们有越来越多的企业家正雄心勃勃地去着手于改变世界的难题。低成本的云计算、机器学习的复兴、基因组学的快速发展已经为用计算机解决新的问题打开了大门。全球供给链的形成、智能手机行业的大力驱动，已经使产品的制造越来越快、越来越便宜。硬科技初创公司深入挖掘这些新的领域，将硬件和软件相结合、软件和生物领域相结合，其复杂度远远超过了 5-10 年前的企业家们处理的难题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了在这些领域取得成功，我们要与时俱进，不断更新创业公司成功案例。这是我们成功的法则。我们的 Lytro Cinema 旅程刚刚启程，毫无疑问，这一路上，我们还会面对更多艰难的旅程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 23 Jan 2017 12:33:02 +0800</pubDate>
    </item>
    <item>
      <title>业界 | CMU人机德扑大战进入中场，人工智能豪取46万筹码</title>
      <link>http://www.iwgc.cn/link/4456047</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自CMU&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀、李泽南、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote style="color: rgb(62, 62, 62); font-size: 16px; white-space: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/blockquote&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;当地时间 1 月 11 日，在宾夕法尼亚州匹兹堡的 Rivers 赌场，由卡耐基梅隆大学（CMU）开发的名为 Libratus 的人工智能系统与人类顶级职业德州扑克玩家开始了奖金 20 万美元的比赛。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;据官网介绍，此次比赛共持续 20 天。由 4 名人类职业玩家 Jason Les、Dong Kim、Daniel McAulay 和 Jimmy Chou 对战人工智能程序 Libratus。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;iframe class="video_iframe" data-vidtype="1" allowfullscreen="" frameborder="0" height="417" width="556" data-src="https://v.qq.com/iframe/preview.html?vid=m0366yacxu6&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0"&gt;&lt;/iframe&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722085&amp;amp;idx=5&amp;amp;sn=6628c3a29d6cccfe1f56e2a6f39678ca&amp;amp;chksm=871b0b5bb06c824d587b32c60e9f76e34faf8b8f7811ad2f1738da44b1cdf5068967a555b13e&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722085&amp;amp;idx=5&amp;amp;sn=6628c3a29d6cccfe1f56e2a6f39678ca&amp;amp;chksm=871b0b5bb06c824d587b32c60e9f76e34faf8b8f7811ad2f1738da44b1cdf5068967a555b13e&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;Libratus 是一个玩无限德州扑克的人工智能程序&lt;/span&gt;&lt;/a&gt;&lt;span&gt;，由卡耐基梅隆大学的 Tuomas Sandholm 教授与 Noam Brown 博士所开发。Libratus 的策略并非基于专业玩家的经验，所以它的玩牌方式可能有明显的不同。基于在匹兹堡超级计算机中心大约 1500 万核心小时（core hours）的计算，它使用算法分析德扑规则，建立自己的策略。在此次的比赛中，Libratus 将继续提升自己的策略。据介绍，创造 Libratus 使用的算法并非为扑克专门设计的。在面临不完全或误导信息时，该人工智能进行推论的能力有着广泛的潜在应用，包括业务谈判、医疗、网络安全、竞拍等等。&lt;/span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在，人机德州扑克大战已经进入中场阶段，卡耐基梅隆大学（CMU）的人工智能程序「Libratus」面对四位世界级职业选手，处于大幅领先位置。截止第 12 天，Libratus 在已经结束的 49,240 局对决中已经获得了价值 459,154 美元的筹码。对此，参与对决的职业选手 Jimmy Chou 表示，他和其他牌手此前完全低估了 Libratus 的能力，现在他们正面临艰难的挑战。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「这个人工智能程序每天都在进步，」Chou 说道。「在牌桌上，我们就像在面对加强版的自己。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在为期 20 天的比赛里，四位德州扑克 1 对 1 顶尖高手将共与电脑进行 120,000 局无限制德州扑克对决。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然职业玩家为了人类的荣耀而战（也为了赢取 20 万美元奖金），但卡耐基梅隆大学的研究人员希望它们的计算机项目通过与世界上最顶级玩家的比赛，为人工智能建立新基准。Libratus 由 CMU 的计算机科学教授 Tumas Sandholm 和他的博士生 Noam Brown 建立。除了进行德州扑克比赛，Libratus 也可被用于进行商业谈判、设立军事策略、或为医疗制定流程等所有这些基于完美信息进行复杂决策的活动。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2015 年，在首次 Brains Vs. AI 的比赛中，4 位职业玩家与名为 Claudico 的人工智能进行了比赛。但 Sandholm 说随着比赛的进行，他认为 Libratus 的机会非常大，「算法的表现非常棒。算法在应对策略上做的越来越好，在驱动策略上也越来越好，在进行中的策略改进上也做的很好。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Chou 说他和其他专家每天都会分享笔记和想法，寻找他们也许可以利用的弱点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「在比赛开始的前一两天，我们看起来有很大的希望。」Chou 说，「但每当我们找到计算机的一个弱点，它就会向我们学习，第二天这个弱点就消失了。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种每天都会发生的变化出乎了人们的意料，Sandholm 说。每天晚上扑克比赛结束后，匹兹堡超级计算中心（Pittsburgh Supercomputing Center）的 Bridges 超级计算机都会执行能够提升该人工智能的策略能力的计算。自比赛开始以来，该中心已经为该扑克竞标赛分配了 Bridges 的更多计算节点。该比赛每天早上 11 点开始，下午 8 点结束。观众也可以在现场观看这场比赛，就在 Rivers 赌场的 Poker Room。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;感兴趣的场外观众也可以查看网络直播&lt;/span&gt;&lt;span&gt;：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://www.riverscasino.com/pittsburgh/BrainsVsAI&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Brain vs. AI 比赛得到了 GreatPoint Ventures、Avenue4Analytics、TNG Technology Consulting GmbH、Artificial Intelligence 杂志、英特尔和 Optimized Markets, Inc. 的赞助。该比赛由卡耐基梅隆计算机科学学院和 Rivers Casino 赌场合作举办，并且得到了匹兹堡超级计算中心（PSC）通过 XSEDE 的同行评议。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 23 Jan 2017 12:33:02 +0800</pubDate>
    </item>
    <item>
      <title>AI Talk | 百度IDL院长林元庆：击败最强大脑王昱珩背后的技术是什么？</title>
      <link>http://www.iwgc.cn/link/4447945</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编辑部&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;本周五《最强大脑》最后一场人机大战——视频捕捉影像的人脸识别完美谢幕。最后一场比赛中，小度战平人类顶级微观辨识高手王昱珩。至此小度以两胜一平的好成绩进入年后的脑王大战。我们专访了百度深度学习研究院院长林元庆，请其解读视频识别的关键技术点及整个小度团队的幕后工作。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;iframe class="video_iframe" data-vidtype="1" allowfullscreen="" frameborder="0" height="417" width="556" data-src="https://v.qq.com/iframe/preview.html?vid=s0368iawvtu&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0"&gt;&lt;/iframe&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;作为机器之心新栏目 AI Talk 的一部分，我们对这次视频专访的内容进行了剪辑，完整采访可见下面文字整理版本。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：这次视频识别主要使用了哪些技术方法？识别过程的实现路径是怎样的？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;林元庆&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：我们的系统首先对视频里出现的人脸进行检测和跟踪。直观的来讲检测和跟踪，就是系统去看视频里有几个人的人脸各自在哪里，是怎么移动的。系统在这个检测跟踪过程完成之后，在每个人的人脸图片里挑选几张质量比较好的去做下一步的人脸识别。通过随后的识别过程识别出这些照片中的人具体都是谁。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：对视频内容进行结构化分析时，如何用有效的特征对内容进行表达？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;林元庆&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：其实我们这个系统主要由两部分组成，一部分是实现检测和跟踪，另外一部分就是人脸识别识别。我们都是通过深度学习的方法学习出有用的特征。目前在特征提取上，我们很少运用人为设计的特征去对内容进行表达，大部分的特征都是运用深度学习，从海量数据里，通过机器学习去学到这些有效的特征。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：与静态识别相比，动态人脸识别有哪些区别？主要挑战是什么？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;林元庆&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：动态人脸识别比静态更为困难，动态的人脸识别里需要能检测出不同角度的人脸，而且动态的人脸整体质量偏低，有些帧的图片甚至会是模糊的，因为动态的情况下人是有移动的。那么在这些挑战下，我们需要有比较好的检测算法，在很多单帧的静态图片里检测出人脸图片质量比较好的图片，然后用这些质量比较好的图片去做下一步的人脸识别。主要的挑战也在这里，怎么更好的检测出人脸以及怎么判断出质量比较好的可以用于识别的人脸图片。另外，动态识别的视频每一秒有 30 帧，这里的又一个挑战是如何做到人脸实时检测。在静态人脸识别里，你需要做的只是处理一张图片；而动态的情况下你有很多图片，那么怎么快速计算，怎么选择出质量最好的图片甚至多帧的学习融合都是需要仔细考虑的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：这一技术训练时对硬件、数据要求高吗？所使用的样本量规模和训练时间的情况是怎样的？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;林元庆&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：我们现在开发出的这套人脸识别系统，在设计时特别考虑弱光条件下和有遮挡条件下人脸识别的实现。这次比赛里所用的人脸识别系统，是通过两个步骤来实现的。第一步是通用人脸识别模型的训练，我们花了很大力气来做。比赛系统里的模型，我们是用大概 200 万个人，总共 2 亿张的照片来训练的。2 亿张照片本身是一个非常大的数据，需要非常大的计算量和非常好的算法，能做到这一点借助了百度的 PaddlePaddle 平台，通过 PaddlePaddle，我们可以在多台机器上实现高效的并行计算。在这一步我们得到一个人脸识别基础能力非常好的通用模型。有了通用模型，下一步就是实现在不同的场景下的人脸识别。第一期的人机大战，比的是跨年龄的人脸识别，这一期比的场景是有暗光和遮挡的场景。我们在通用模型之上会特别去准备一些跟这个环境相近的数据集来进一步训练通用模型，最后得到弱光和遮挡环境下较好的人脸识别系统。后面的这个数据集相比之前的通用模型的数据集就小很多了，这样的数据本身也比较难收集，我们最后的数据集大概是 1 万人的量级。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：王昱珩在答题过程中其实改过答案但最终改错了，机器会出现类似的问题吗？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;林元庆&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：机器可能不太会出现（这种情况），因为唯一输入给机器的就是图像或视频信息，机器通过算法将要考虑到的因素已经都考虑了，最后是得到一个置信度也就是 Confidence Score，分数比较高的会被机器认为就是正确答案。虽然分数也是综合了非常多因素，但机器没办法再回去想出另外一个分数来。就像我们第一期里双胞胎的情况，机器最后决定什么分数就是什么分数，没办法再改。人不一样，除了看图像还会联想到一些信息，最终进行综合考量，但这会带来好结果也会有不好的结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：听说因为和王昱珩比赛而加班加点升级了算法，具体是做了哪些升级呢？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;林元庆&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：我们做系统升级不是因为要和王昱珩比赛，是我们原本就计划要做。所做的升级其实是针对这次比赛的内容—有遮挡的人脸识别。在这次比赛中，要识别的人脸可能戴口罩、戴墨镜甚至戴帽子，如何处理这些有遮挡的人脸图片，在人脸识别领域里还是悬而未决的问题。针对遮挡情况，我们也特地设计了一些比较新的算法。比如我们将人脸分为 7 个部分，每个部分的遮挡情况都是根据那个部位在深度学习的输出特征来描述这个部位被遮挡的程度，根据不同部位遮挡程度的不同决策出哪些部位是可以有效提供人脸信息的，进而可以用于人脸识别。简单来讲，就是让模型了解不同部位被遮挡的情况，然后根据情况来使用这个部位的信息。我们训练的是一个端到端的模型，输入照片后系统自动得到不同部位的遮挡信息，最后做综合决策。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：在这一过程中，小度如何用到推理能力？目前具备的推理能力水平如何？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;林元庆&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：小度在别的方面可能会用到更多的推理能力，比如说自动驾驶。但在人脸识别方面，它的推理能力还是比较初级，比如我们会去分析哪一些部位可能被遮挡，这些部位需要怎样根据这些信息作出最后的判断。从不同方面得到的信息进行相互作用也是需要通过数据和模型去学习出来，因此，在模型设计时就会涉及一些比较基本的推理能力，让小度通过数据去学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：要获得理想的识别结果，对人脸角度和像素分辨率都有什么样的要求？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;林元庆&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：其实我们在左右转向 45 度之内都能做到非常高精度的识别，但如果角度太大，比如说半脸就会很难了，精度会下降。从上往下看或从下往上看，也属于比较难的，上下 15 度左右还比较好处理，但如果角度太大，难度就会比较大。当然，我们也有计划再扩展算法。相比像素分辨率，其实更重要的是图片质量，如果图形都糊了，人都很难分辨出五官，（对机器来说）就更难了。但只要有足够的分辨率，放大之后你还能看到五官，比如说眼睛能看到瞳孔，基本上还是能够识别的比较好，质量越高肯定识别越好。当我们做系统（整体设计）的时候，其实可以想办法提高画面捕捉的水平，比如摄像头可以装得低一些，从一体化的角度来考虑怎么才能取得比较高的分辨率。比如说在一些机场，为了能在人路过时捕捉人脸进行识别，他们把摄像头放在一个大屏幕上，人走过的时候常常会看一下屏幕，这样就有可能捕捉到一个人脸稍正的画面。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：节目中第一题和第三题，小度都答对了，但第二题被形容错得很离谱，是什么原因造成的？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;林元庆&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：错的很离谱可能指的是，正确答案是一个相对比较胖一点的人，但是小度给的答案是一个胖瘦正常的。这是因为小度可能看的不单单是脸型，看到更多是比如鼻子的形状、嘴角的形状，对小度来说，它根本没有信息来判断人的脸型是不会变的，举个例子来讲，像我们在第一期跨年龄识别里看到，人的脸型完全是会变化的，小度无法得知它看到的这个照片跟库里的照片相比，只是几天或几个礼拜、几个月之前拍摄到的，它只能从原来学习出来的信息里进行判断。其实我们 IDL 工程师们后来仔细去看了结果，除了脸型（胖瘦）因素之外，其实也挺难确定那个人是不是就是最后的人，通过电视仔细看照片也很不容易，反倒是小度的答案的嘴型更接近真实答案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9iaSgfTFRChrskKuUMbnjjpwJujVajoOdibLMNPwTnrPRyQKLhJDeLEoDJV4pP3jEEkfmhdfSeiaYKA/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：在百度，这项技术目前仍然停留在技术研究阶段还是即将成为一个产品化的系统？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;林元庆&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：之前，人脸识别主要还是用在百度已有产品覆盖到的场景里，包括全网的人脸搜索、图片的人脸搜索，在百度之外做的非常少。但是从 2017 年开始，我们有计划要把百度人脸识别系统在公司之外用起来，包括我们现在跟景区在做的人脸闸机系统，游客进景区以后就可以刷脸进出，这在乌镇已经落地。在安防领域，水哥曾帮山东省公安厅从监控的视频里找到罪犯，但水哥只有一个，而这个系统其实已经可以做到非常好的识别精度，我们也希望它能够在更多的安防领域用起来。我们希望技术能得到广泛的应用，这也是我们今年需要努力的重要方向，争取把我们的技术落地到更多的实际生活中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：能否回顾一下这次小度人机大战的准备过程？比如团队筹备了多长时间？涉及到哪几个部门的配合？中间遇到过什么状况，如何解决的？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;林元庆&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：8 月底，节目组到百度来邀请我们参加，当时他们说希望做跨年龄的人脸识别和声音的识别，还带了一些测试数据，我们在一个会议室里面现场做了识别精度的测试。（当时）在跨年龄人脸识别方面做了 8 组测试，结果是对了 7 组，是节目组当时很震惊，觉得百度的人脸识别技术确实做得很好。事实上，当时我们还没有针对这个产品场景做过优化。这次提前测试之后，节目组在同时接触的国内几家人工智能领域的公司中选择了我们。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关于到底要不要参加，我们考虑了一两个星期，对我们整个团队来说，参加还是有一定风险。一方面，我们对自己的技术很有信心，也想看看百度经过这几年人工智能的积累，跟人类顶级选手比水平如何，即便输掉对技术的人来说也没什么，因为我们做实验也有失败的时候；但另一方面，这些选手很强，现场比拼确实没有十全的把握，我们还是会有压力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;决定参加之后，我们成立了一个二十几个人的课题组。其实这个项目非常复杂，不单单是算法，还包括人脸识别、声音的识别，我们为了节目的趣味性还做了一些技术的展示，比如与主持人、嘉宾的互动，其中用到的是个性化语音合成等等。大家都在一个会议室里面做封闭开发，除了技术开发我们还要跟节目组协调。为了让观众更容易理解，要做很多工作，公司内部涉及到很多跨部门协作，IDL、AI 平台部、语音技术部、系统部、品牌部、众测等。需要百度众测帮我们收集很多数据，需要海量的计算需要 GPU 的调配，包括配合节目播出做的 H5 页面让大家来亲自体验技术...... 总之，一个比分背后有非常多准备工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机器之心：在整个三期节目录制过程中，团队的状态是怎样的？接下来对小度的表现有什么预期？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;林元庆&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：重中之重的是算法，也就是系统的精度，我们核心成员一直在加班，经常忙到 3、4 点才回家，有时早上 7、8 点，回去睡一觉就回来再继续。因为最后非常非常紧张，大家承受的压力很大，我们第一期在最强大脑节目录制现场，我站在后台，节目组的人开玩笑说，元庆看着你好紧张，我说是很紧张。小度对错一道题，对于科学家来说跟平常的实验一样，我们做科学研究经常也会给人家做 Demo，一般是面对几十人到几百人做 Demo，压力也会蛮大的，但这次要做的 Demo 是展示我们的技术，面对是几千万上亿人，这个压力可想而知。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们现在赢了两局平了一局，根据节目规则，我们会进入脑王决战，我们收到的通知是脑王决战会在 3、4 月份举行。我们会再重新开始备战，但具体是什么节目内容，我们现在还不知道，唯一知道的是最后一期可能全部是人机大战，并且可能会安排 3 个选手跟小度 PK，这又给我们带来非常大的压力。节目给出的极端场景，比如跨年龄识别，我们之前其实没有做过，我们对人脸识别理解很深、技术也做的很好，但能在多大程度上把这些基础能力用在极端情况中，我们都是没有十全把握的。不过，相比（几个月之前）接下这个项目的时候，通过两个月准备，我们现在再去测这套人脸识别系统，比如给 10 个测试例子，小度已经做到完全比我们要好很多的程度。因此我们对脑王决赛充满信心，也非常期待。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicS08ZFjdibpLIeOjg73NAOyRulPA7upc5nBHVHQV4nEe1VYKJ0oCNRDHIgfRdEjDQg3atmJKUrSEg/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote style="color: rgb(62, 62, 62); font-size: 16px; white-space: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p&gt;&lt;span&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;「AI Talk」&amp;nbsp;是机器之心最新出品的视频访谈栏目，旨在邀请国内外人工智能顶级专家分享对技术和行业的观点，为大家呈现更为直观、丰富的内容。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 22 Jan 2017 19:28:52 +0800</pubDate>
    </item>
    <item>
      <title>观点 | 暮光女主发表人工智能学术论文，引来业内一片嘘声</title>
      <link>http://www.iwgc.cn/link/4447946</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Quora&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀、微胖、朱思颖&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;近日，电影&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722569&amp;amp;idx=3&amp;amp;sn=6ca8e1b70a80f57ad3d356ac48960c7e&amp;amp;chksm=871b1577b06c9c61a3637aa4a4bcba91bf5544e0f020d6b31016f7ce2d45b1c0ac6eb187c41b&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722569&amp;amp;idx=3&amp;amp;sn=6ca8e1b70a80f57ad3d356ac48960c7e&amp;amp;chksm=871b1577b06c9c61a3637aa4a4bcba91bf5544e0f020d6b31016f7ce2d45b1c0ac6eb187c41b&amp;amp;scene=21#wechat_redirect"&gt;《暮光之城》女主角 Kristen Stewart 的名字出现在了一篇 arXiv 论文的作者名单上&lt;/a&gt;，引起了极大的关注，一些读者将其评价为「颜值与智商双高的女神」。但抛开学术论文+电影明星的「自带光环」，这篇论文到底有多好呢？这个值得关注的问题已经出现在了问答网站 Quora 上，并且也吸引到了一些业内人士的观点，机器之心从中筛选了一些值得关注的答案进行了编译，了解更多观点可查看问题原地址：&lt;span&gt;https://www.quora.com/What-do-people-who-work-in-machine-learning-and-AI-think-of-actress-Kristen-Stewarts-research-paper-on-AI&lt;/span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;问题：机器学习和人工智能领域的业内人士怎么看待女演员 Kristen Stewart 的人工智能研究论文？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;回答者一&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：Xavier Amatriain，前机器学习研究人员，现 Quora 的首席工程师&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里涉及两个不同的问题：（1）我们如何评价这篇论文？（2）怎么看待这次「上头条」？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先回答第二个问题，因为我觉得这可能是问题的根本。今天人工智能的热度有一部分属于炒作，我也知道普通出版物（这里指报道这篇新闻的 Quartz——编译者注）会对一篇能将人工智能和好莱坞明星联系起来的论文感兴趣。也就是说，我认为 Quartz 的报道是把双刃剑。必须承认，我也在 Twitter 和 Facebook 上分享了这篇文章。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先，请注意，Quartz 使用了「发布（release）」而不是「发表（publish）」。这个表述很好。后来，他们也解释了在 ArXiv 上发布论文并不意味着通过了同行评议或者被研究社区认可。读者应该记住，尽管 ArXiv 降低了提交的要求，但是，他们并不为论文质量负责。简言之，即使提交一份研究草稿或课程计划都是可以的。现在，在论文被其他刊物或会议接收前，都应该在这个语境中看待这篇研究。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二，正如其他读者指出的，这不是「头条」所说的人工智能研究论文（research paper），而是一篇应用论文（application paper）。这完全是两码事。虽然这并不意味着它是一篇糟糕的论文，但是，需要根据不同的背景加以评价，因为该论文并没有介绍任何新的东西。据此，人工智能研究人员怎么看也就不是真的那么有关系了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我觉得自己多少有点资格发表一下看法。尽管我是做深度学习研究的，但是我发表的论文实际上都是应用方面的，从推荐系统到多媒体系统。实际上，我和一些艺术家合作发表过论文，其中一些论文还发表在了国际会议和期刊上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由此，我现在回答第一个问题：我怎么看这篇论文？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;呃，不幸的是，我对它没多大印象。作为一篇应用人工智能技术的论文，其价值有限。也存在许多问题，这些都不利于它被绝大多数会议接收：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 从这一应用中获得的经验真的很难泛化，这篇论文甚至一开始就没有这个目标。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 研究方法的比较也非常有限。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 参考不够。特别是，作为一篇应用型论文，对现有的人工智能/机器学习领域内的论文参考不够。作者应该参考其他利用人工智能进行艺术创作的研究方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;也就是说，比如，这篇论文可以提交给研讨会做「poster」。考虑其格式和长度，我猜这可能也是该论文的作者的想法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，既然其他回答中已经讨论过 Kristen Stewart 是否是名副其实的合作者这个问题，那么，我也来回答一下：肯定算是名副其实的合作者。还是刚才说过的，这是一篇应用论文（或者说艺术创作应用论文）。艺人的作用与研究人员的作用不相上下，甚至超过后者。实际上，分享一点小秘密，我非常确定在该论文里描述的 Kristen 的贡献比许多在博士论文上署名的知名教授和研究人员还多。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9iaSgfTFRChrskKuUMbnjjpO4v5cEJIibSLDkxurcs5icMHyppXN5Hrno6Cfkc4I1aiaJDVsFgU6rYBA/0?wx_fmt=png"/&gt;&lt;em style="color: rgb(136, 136, 136); text-align: justify;"&gt;&lt;span&gt;这是一篇我与艺术家合作的论文，几年前发表在 IEEE Multimedia 上。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;回答者二：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;Shashwat Verma，新加坡-麻省理工学院研究与技术联盟研究实习生&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;听说过 Prisma 吗？这个 App 将你上传的照片按你所挑选目标图片的风格进行重画。关于这个 App 的实现原理的论文是由 Gatys 等人完成的 https://arxiv.org/pdf/1508.06576v2.pdf&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那些还不知道Prisma做什么的人可以看下面的例子：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9iaSgfTFRChrskKuUMbnjjp63Diaw0uTpkglkT2hA26eppPsqBNQKcIgxMjhqEs3yfjuATOAPJc8IA/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一步：上传一张图片&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二步：挑选一种风格&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第三步：欣赏重画为目标风格的图片&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Prisma 是通过卷积神经网络（CNN）完成上述的图片重画过程。我在上面所提到的论文是运用深度学习来做一些艺术性的创作工作而不是给猫分类这样的任务。这是一篇很好的论文，论文的写作很用心并且你可以运行出论文里所提到的结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Krister Stewart 的论文只是「延伸（extend）」Gatys 等人的工作。首先，她的研究论文不是一个真正意义上的关于人工智能的论文。他们甚至很可能都没有做一篇人工智能论文的意愿。让我们来分析这篇「人工智能」论文中第一个也是唯一一个数学公式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;Experimenting with the style transfer ratio led us to conclude that it needed to be exponent form for meaningful creative exploration. Subjectively, this exponential form gave us a useful measure of unrealness, u , a rough way to map how impressionistic the style transferred image looked: style transfer ratio = 10^u&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以上内容为论文节选，唯一出现的数学公式为：风格转换系数=10^u&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Kristen Stewart（可能是这篇论文最重要的一个作者）的论文的「贡献」根本谈不上是「贡献」（contribution）。评论结束。Gatys 的论文中早有谈及这个公式，甚至有对改变风格转换系数值所依次得到的效果呈现图。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9iaSgfTFRChrskKuUMbnjjpM5Suq0oxcSx5SIibxUFicS66nibU3cCqTdocib3ZWWOtpZpFVZxGe951ag/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9iaSgfTFRChrskKuUMbnjjpGBBTIUoTal5s5xAfqgUWPuHAhb7xShvpqwXczqobpjwIic0S7lPxCjQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里补充给大家 Kristen 论文中的风格转换图（上）以及 Gatys 论文中的风格系数改变效果图（下），大家可以对比来看。（编译者注）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他们在论文中提到几个其他贡献，我相信，对于一篇论文来说，这些也是不够的。文中谈到几个参数（不是超参数）以及如何调这些参数。这完全不能构成一篇人工智能论文。他们只是把自己的工作像写博客那样让所有人知道。我个人没有发现他们论文中任何的价值点。没有一点能对我既有知识的进行扩充。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是，这篇论文或许对那些打算在电影制作中用深度学习技术实现风格转换的人有用，对那些需要调整参数来得到足够好的产品输出图片的人也有用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你真的想知道 Kristen Stewart 论文中那堆东西是怎么实现的或者说 Prisma App 的原理，那么你去读 Gatys 等人的论文吧。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，我认为，Kristen 甚至没有做任何与深度学习相关的技术工作。她很可能只是挂名在论文下面，就如那些没有参与任何论文研究的教授在论文下面挂名一样。Kristen 是一个演员不是一个深度学习工程师。这也是对该论文的作者、研究工程师 Bhautik J Joshi 的批评。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在我的分析里也许有错误的地方，非常欢迎大家挑出我错误的地方。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;加油！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;回答者三：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;Roman Trusov，Facebook 人工智能研究（FAIR）的 2016 年实习生&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这不是一篇研究论文，也不是关于人工智能的。唯一真实的部分就是「Kristen Stewart」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他们所做的：下载一个预训练了的直接可用的架构，然后在他们的图像集上运行了一下。你不需要为此做任何训练。要解决的问题是找到一个足够轻量的解决方案（vgg16 vs vgg19）以及设置一下去噪例程（denoising routines），这纯粹是个技术活儿。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果去掉「Kristen Stewart」，在机器学习领域里，没人会看把这篇文章两遍，仅此一点就可以判断出里面有多少科学成分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除此之外，试着减小 Erdős–Bacon 数字是一个不错的尝试，显然，这是真的。或许也能鼓励更多的女性踏入计算机科学领域。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在，是时候行动起来了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;回答者四：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;Alex Seewald&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Stewart 这次完成的工作更像是研究生的课程期末作业、人工智能爱好者发布的技术博客或本科生论文（thesis），却不像学术出版物。神经风格迁移（Neural style transfer）和与之相关的一切已经完成研究了。他们提到在实践中什么有效和无效的内容，对那些打算使用神经风格转移的人来说，是一些准确的信息（我在运用风格转移时，也有相似体验）。但是，说「在这些条件下，x 奏效但是 y 却不能」，这种深度的研究不能算真正的科学研究。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Kristen stewart 参与论文的事情让人们想知道她是如何参与的。通常仅列举作者名字的做法并不会真的给你这方面的答案。通常也没啥机会怀疑某人是否参与过论文。这一次，我并不相信，但是我想相信。我希望能在 CVPR 会议上遇见 Kristin Stewart。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 22 Jan 2017 19:28:52 +0800</pubDate>
    </item>
    <item>
      <title>学界 | 微软提出PrivTree：利用算法保护位置隐私</title>
      <link>http://www.iwgc.cn/link/4447948</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自微软&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀、蒋思源、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;打车、导航、外卖、AR 红包等各种基于位置的应用已经成为我们日常生活的重要组成部分，但位置的隐私安全也随之成为了我们需要关注的问题之一。近日，微软亚洲研究院高级研究经理 Winnie Cui 在微软研究博客上发文介绍了他们为位置隐私安全所提出的一种新算法 PrivTree。点击文末「阅读原文」可查阅相关论文。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据科学家 Anthony Tockar 在西北大学攻读硕士学位期间曾经尝试了一个研究，成功利用网上公开的数据追踪了纽约市的名人，详情可查阅：https://research.neustar.biz/author/atockar/。通过交叉参考（cross-referencing）名人在纽约市搭乘出租车的公开新闻和照片，Tockar 找到了名人搭上出租车的地点和目的地位置，以及他们为此支付了多少钱。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个案例说明，基于位置的服务（location-based services，即根据 GPS、IP 地址和 WiFi 网络映射获取用户的位置数据并基于其提供服务）可能会是隐私的一个噩梦。但它们也可能具有非常重要的价值，能够为用户提供实时导航、本地天气、基于地理位置的定向搜索结果等等有用的功能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 2011 年微软的一项调查《位置的使用和感知》（参阅：http://thelbma.com/research/3/microsoft-location-usage-and-perceptions/）中，我们发现有 94% 的消费者认为基于位置的服务很有价值。但是，这个调查还发现 52% 的用户对于与地理位置有关的数据隐私问题有所担忧。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;隐私问题现在是研究界的焦点之一。南洋理工大学教授 Xiaokui Xiao（萧小奎）说：「如今的计算机算力和公开可用的数据让我们可以更加简单地根据数据识别出个人。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;近日，Xiaokui Xiao 教授团队与位于北京微软亚洲研究院的 Xing Xie（谢幸）团队一个合作项目发现了有可能有可以缓解这种隐私问题的方法。这个联合团队提出了一种名叫 PrivTree 的数据操作技术，其可以对地理位置数据进行预处理以保护个人的隐私。之后，这些被隐私保护的数据可以被用在任何前瞻性分析（prospective analysis）之中，甚至可以公开发布，而不会有泄漏用户隐私的风险。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;PrivTree 可以通过数学的方式对个人的地理位置信息进行模糊化处理，同时还能在整体上维持该数据集的整体精度。在下面的例子中，数据集中的个人被投射到了一个由他们的地理位置坐标提供的地图上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9iaSgfTFRChrskKuUMbnjjpDb5mls5LicBlVPb2IckSShiacpGbUodexiasNktA2SgpC5RZggark4ib8g/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;其中每一个标记都代表了该地理位置数据库中的一个个体。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;接下来，PrivTree 会经历两个阶段来实现对单个个体的地理位置信息的模糊化处理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;阶段 1：地图分区&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9iaSgfTFRChrskKuUMbnjjpzpy4uLQesaZ6yDhTKSKZNOicG5skE7JbjPpr6mcf9kqSOluRj6wG0pw/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;该地图会基于数据点的密度而被分割成一些子区（sub-regions）。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;阶段 2：地点扰动&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9iaSgfTFRChrskKuUMbnjjpCMgEPy3WwKhFzBbr2QfTH49A5icMzzFYUWdicsLSDIjvWUIKflovfCxg/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;使用统计学分析，个体会按扰动方案（perturbation scheme）被随机移除，在添加或搅乱来保证隐私性的同时保证统计学的准确性。在对每个子区进行位置扰动（location perturbation）后，新的地理位置数据库就可以使用了。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这将产生一组新的数据点，并且它和原数据遵循类似的分布，只不过每个参与者真实的地理位置已经被掩盖了。然后经过隐私保护的数据将作为 PrivTree 的输出。PrivTree 可以扩展支持各种类型的地理位置数据，例如将你日常慢跑的线路上传到健康应用软件。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;研究论文《PrivTree：一种用于层级分解的差分隐私算法（PrivTree: A Differentially Private Algorithm for Hierarchical Decompositions）》已经被 ACM SIGMOD 2016（世界顶级数据管理会议）接收。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Xiao 教授谈到了与微软研究员之间的合作：「微软亚洲研究院在管理大型定位数据上的专业性在此项目成功上扮演着重要角色，比如北京的出租车数据。它帮助了我们开发、测试模型。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Xiao 教授计划进一步将 PrivTree 技术融合到微软的定位技术中，从而提供隐私保护。微软亚洲研究院的高级研究员 Xing Xie 教授也参与到了这一项目中，他说：「数据隐私是云计算时代的重大挑战，特别是包含大量个人隐私内容的用户定位数据。我们希望这一研究能有所贡献，并最终为每个人带来更安全的世界。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;论文：PrivTree: A Differentially Private Algorithm for Hierarchical Decompositions&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9iaSgfTFRChrskKuUMbnjjpJu7doIIZCIbXomJTKS5TV7S8FUIOSurdXCpGgZdlzS5aEDm5upH7IQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：给定 Omega 域上定义的一个元组集合 D，我们研究了在 Omega 上构建直方图（histogram）以逼近 D 中的元组分布的差分隐私算法（differentially private algorithms）。对于该问题现有的解决方案大多数都采用了一种分层分解方法（hierarchical decomposition approach），其递归式地将 Omega 分成子区域并计算每个子区域的有噪声元组数，直到所有的噪声数都低于一个特定的阈值。但是，这种方法需要我们&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;(i) 在 Omega 的分割中的递归深度上施加一个限制 h；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;(ii) 设置每个计数中的噪声，使之与 h 成比例。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;h 的选择是一个非常严重的难题：h 太小会导致直方图粒度太粗糙，h 太大则会导致当在确定一个子区域是否应该被分割时在元组计数中出现太多的噪声。此外，h 不能直接基于 D 而进行调制；否则，h 自身的选择就会暴露隐私信息和违反差分隐私。为了弥补现有方法的不足，我们提出了一种直方图构建算法 PrivTree，该算法采用了分层分解（hierarchical decomposition），但完全消除了对预定义的 h 的需求。PrivTree 的核心是一种全新的机制，其可以&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;(i) 在拉普拉斯分布（Laplace distribution）上利用一种新分析；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;(ii) 让我们可以在决定应该分割哪个子区域时仅使用常量的噪声，而无需担心分割的递归深度（recursion depth）。我们在建模空间数据上演示了 PrivTree 的应用，结果表明其可以被扩展到能处理序列数据（其中子区域中的决策并不是基于元组数，而是一个更复杂的度量）。我们在许多不同的真实数据集上的实验表明 PrivTree 在数据效用方面显著超越了当前最佳水平。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 22 Jan 2017 19:28:52 +0800</pubDate>
    </item>
    <item>
      <title>专题 | 脑芯编： 为什么 GPU 是 AI 的神外挂？</title>
      <link>http://www.iwgc.cn/link/4447949</link>
      <description>&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;〈五〉&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;一遇泰坦误终身&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;或许林燕妮自己也没有想到&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;写了一辈子的文&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;最后能和自己老公的「沧海一声笑」&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;一起流过的岁月的，&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;是那篇&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;《一遇杨过误终生》&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今天的主题，叫做「一遇到泰坦误终身」。你会问，泰坦是什么？Titan X -- NVIDIA Pascal 架构下的终极显卡（Graphics Card）产品。显卡？！这不是一个人工智能硬件的专栏，我又不玩游戏，关显卡什么事？且听小编慢慢道来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9iaSgfTFRChrskKuUMbnjjpmWou2aV8L6KxibAuyjHdMpXmIZcnPBKeTtUVlNVWrv0jEtibeHRfvcGg/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在进入正文以前，我们先来回忆两个概念，其一是加速器（你还记得挂在 ARM core 边上的加速协处理器么？见「脑芯编（三）」），其二是单指令多数据体系结构（SIMD，见「脑心编（四）」）。在人工智能大热之前，这两个方案就已经广泛地出现在我们的系统中，这个系统叫做「显卡」。那是一个显卡还在用来的投影（shadow）和渲染（rendering）的年代。除了高等级游戏玩家，普通人的电脑常有一个抬不起头的配置——「集显」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;显卡主要用于大规模的同一类型计算，比如向量积和一些简单的非线性操作。听起来有没有很熟悉？神经元也是同一类操作。也就是说在神经网络大红之前，显卡已经在类似硬件上默默耕耘了数十年。但是，十年前没有人会想到上帝会掉一个馅饼到 NVIDIA 额头上，让它成为了比肩 intel 的超强处理器帝国。原因有二，其一是显卡是最能体现体系结构中协处理架构和 SIMD 的硬件。除此之外，显卡还有一个法宝，称为——多线程并行（Multi-thread parallelism）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;最远的距离，是你的芯里没有我&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;张小娴说「世间最遥远的距离，不是生与死，天与地，是我在你面前，你却不知道我爱你。」而在数据处理器里，也有一个如此「遥远」的距离——存储数据访问失败。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;故事起源于计算机体系结构中存储的分级结构（memory hierarchy）。一般，一台处理器的数据存储的位置，以离计算单元的位置排序，包括寄存器表（Register File），高速缓存（cache），内存（DDR Memory）和硬盘（SSD/Hard Disk）。非常容易理解地，离计算单元越远，访问延时越长，但是可用作存储的空间越大。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9iaSgfTFRChrskKuUMbnjjpB0Vp6dRr4aXWWb7AZIJsWJLnhcPlJBESt3ickEnGfURjsFvJcya6BYg/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那问题是，什么样的数据，该放在 Cache 里呢？简单的答案，是不断被访问的数据。那万一不断被访问数据不在 Cache 里呢？那处理器就要派出一个信号兵，历经千山万水，走到 disk 来求得一本「真经」再带回处理器开始计算。那这段时间里，处理器单元在干什么呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;等。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;就像那些只能把爱存在心底的痴人。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;解药，只能是爱上另一个人。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;用计算机体系结构的话说，是执行——&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;另一个进程&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们在讲到 VLWI（超长指令集）谈到过说，其实不同类型的执行电路是相互独立的。对于一个包含 load/store 指令和 ALU 计算指令的处理器，完全可以同时执行 load/store 和计算，只要两者间的数据不存在依赖关系。即，处理单元在派出信号兵的时候，仍然也在高效率的计算。那么，我们把这两个没有数据依赖关系的指令称为它们分别属于两个进程（thread）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于这样的操作，处理器在传统体系架构往外还需要支持一个叫「scheduler」的发射器，用于分配当前处理器的不同模块分别处于哪一个进程中。显然地，就每个进程而言，其寄存器是独立的。共享的只是操作实现单元。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;GPU 就是在这一概念下产生。下图是一个典型的 GPU 多核单元。可以看到，他有 32 个处理单元，称为 CUDA Core，每个 CUDA Core 里有一个浮点计算单元和一个整数计算单元。16 为一队分为两组。还有 16 个 Load/Store，和四个特殊函数计算单元（SFU, Special Function Unit）用来计算三角函数之类的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9iaSgfTFRChrskKuUMbnjjpia7KwWASC20uca0ibAHiaHIjZEdGIeUuRXtbR4dW2dUzoqjUCO5Ls4m9g/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这样，这个处理器就可以以 16 为单位，在同一实现执行一条指令，即 SIMD。除此之外，LD/ST 与两组 CUDA Core 可以按照不同的指令同时对于不同的 Thread 进行不同的操作。至于当前情况对哪个 Thread 进行操作，由 Scoreboard（记分牌）和 Warp Scheduler 共同决定。因此，cuda 是不用等 ld/st 操作的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9iaSgfTFRChrskKuUMbnjjpuSrGGhIH0vic6yUskgfbsY7NpI451x3bP30QBnBB1L0ANjJcF719Cibg/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;讲到这里，不得不提一下 Nvidia 的起名，那也是一种境界。比如说线程吧，好好的 thread 的不叫，要叫 warp。如果各位硅工辅修一门「羊毛衫针织技术」课的就会理解这个名字精妙所在，上图是 google image 搜出来的 thread 和 warp。Thread 是单一没有规律的线，而 warp 是针织后多条并线错落有致的线。Warp 可以形象地体现 GPU 中每个线程的并行性和交替活跃的特征。可惜，大部分硅工连 warp 可以作名词都不知道。另外，NV 还把一个上述的并行的单元处理器叫做 streaming multiprocessor。对，简写就是那个五十度灰里羞羞的 SM，看 GPU 的文章时，一定不要对四处飞的 SM 想太多哦。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;时间上，一个可能的 SM 处理的操作如下图所示。通过 Warp Scheduler, 每个对应的 cuda core 将在不同的 thread 间跳跃以达到性能的最优值，同时成功地掩护处理器对存储器里所需数据的访问时间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9iaSgfTFRChrskKuUMbnjjpekFe3sicBO7OvlHQ1JYbCNib0ZkajezVZdNlUAtJGja7nQFSQnxrW2Cw/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;从费米到帕斯卡：泰坦之父们&lt;/span&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;希腊神话里面，泰坦们是天神 Uranus 和地神的 Gaia 的后代，是奥林匹斯众神（宙斯等）的父辈。然而，在 GPU 的世界里，泰坦之父却要贡献给这四个名字：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Fermi / Kepler / Maxwell / Pascal&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9iaSgfTFRChrskKuUMbnjjpabhlwVRU7CzpOKyD13HjM7gibrOjE71uIX8aoWiaxXmy1CbzlmVticjfQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这 4 位鼎鼎大名的先贤（不认识的请自行回去打屁股）又和 GPU 有什么关系呢？这又要归结到 Nvidia 牛逼的起名学了。10 年以前，专用图像处理芯片都叫做「显卡」（Graphics Card）。但 2008 年的时候，多家公司决定给他一个高霸上的名字——「图像处理单元」（Graphic Processing Unit, GPU）。Nvidia 从那时起，给每一代自己的图像处理芯片都冠一个牛逼哄哄的干爹姓。第一任干爹就是大名鼎鼎的核物理学家——Enrico Fermi。其实，fermi 前还有个，叫 tesla 姓，但是现在 tesla 已经被 NV 作为一个产品线名字了。就这样，GPU 以两年一代的速度，不断进取，如今已经发展到 Pascal 代。在今年刚过去的 CES，下一代架构 Volta 的样机已经出现了，集成在 xaiver 平台上。（请参考《矽说--从芯片核弹到未来平台：从 CES 看 Nvidia 的转型野心》）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9iaSgfTFRChrskKuUMbnjjpsa1RTu6K20IwSuicNmVCGyNFXVGmFCVuz8B2HTOY4KdBtQrXKNbAKyA/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Titan X 首次亮相时在 Maxwell 时代，目前能买到的新款已经更新到 Pascal。其实，N 家作为卖游戏显卡的主，出的了很多性能超越 Titan 的游戏卡（比如 GTX 1080，游戏跑分基本秒杀 Titan）。但是为啥 Titan X 一直是 AI 加速、特别是 training 的主要硬件外挂呢？有两个重要要原因。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一是，Titian 在单精度模式上拥有长足的优势。单精度指的是 16 位的浮点计算模式（FP16），而日常显卡是为双精度（32 位浮点）甚至更高的 FP64 模式设计的。Data scientist 的经验表明，深度学习往往仅需要单精度即可得到。大家可以从 (A+B)(C+D) = AC+AD+BC+DC 中可以简单地发现，FP32 所需要的硬件代价大约是 FP16 的 4 倍，可以做 FP16 的 Titian X 自然成了 AI 训练的首选。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二个原因是，Titan 卡上的存储空间（DRAM）是 NV 卡里最高的，达到 12GB。就如本文一开头所述的，离计算单元越近且越大的 Memory 越值钱。这一点在大规模神经网络中尤为有用。多少个矩阵乘就这么避免了被「五马分尸」的命运呢。因此，凭着这 12GB 的显卡内存，Titan 的运行 AI 是对「云深不知处」的主机内存访问又降低了很多。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;既然讲到了 GPU RAM，可能会有筒子们问 GPU 是在 GPU 芯片里的还是芯片外的？。答案是两者都是。从 Pascal 架构开始，GPU 所用的 DRAM 不再是与 GPU 分立的单独存储芯片，而采用 2.5D 封装的 HBM 结构，为了更近、更快、更宽（位宽）的访问存储器。详情请参考《矽说-那些年我们追的摩尔定律（二）》&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9iaSgfTFRChrskKuUMbnjjpkokMukmXq58KwLOMGGVOvGgFNk8K5q12NibRLtUfxmx8zl0g7Pic6Z1Q/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;(说了那么多 N 家，最后拿 A 家的 ppt 镇个楼)&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「一遇泰坦误终身」介绍了在 GPU 的在 SIMD 基础上的另一绝技——多线程，并且在此基础上义务地给 titan X 神卡做了个软文。可是，难道整个 AI 的硬件就要被黄教主统治了么？其他的硬件机遇在哪里？篇幅有限，且听下回分解。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;眼瞅着就要过年了，&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这也应该是年前脑芯的最后一更，&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;小编在这里给大家拜早年了！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 22 Jan 2017 19:28:52 +0800</pubDate>
    </item>
    <item>
      <title>投票 |「2016 年度学术公众号」20 强入围榜单出炉</title>
      <link>http://www.iwgc.cn/link/4447950</link>
      <description>&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/kKoeb9t5fNpXdhibh2jrmJrfga7z8p5mG5fkpAukdYwKKVnFmdHBGd5CVGBYFtF1934dlchUjXov9j8X26aO3vw/640?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;2016年11月，「科研圈」启动「2016年度学术公众号」评选，邀请科研人员、“科研圈”的数十万用户提名自己心中的最佳的垂直领域学术公众号。截止2017年1月17日，总计提名候选公众号235个。&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;“科研圈”综合读者提名、专家推荐、公众号体量、内容质量、更新频率及用户评价等指标，经过多轮筛选，最终出炉入围的20强学术公众号，覆盖七大学科领域。&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;现在，欢迎您给20个入围公众号投票，“科研圈”将根据读者投票结果与专家评审打分，评选出最终的 Top 10学术公众号。&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;点击文末「阅读原文」，为机器之心号投上一票。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;本次入围的20个学术公众号名单如下（根据字母顺序排名）：&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;blockquote style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section&gt;&lt;/section&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;span&gt;「&amp;nbsp;材料&amp;amp;化学类&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;」&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;br/&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/kKoeb9t5fNpXdhibh2jrmJrfga7z8p5mGwkEke0XpYJianh7j4w9AooM9YzJibzXmQhMT3zDLNm2CBtSVow1GgTPA/640?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/kKoeb9t5fNpXdhibh2jrmJrfga7z8p5mGxHWKGQXl4QwNg6nz1UHdAN4tozS6V59jlGQp1XN1RdnDgn9LuDib2eQ/640?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/kKoeb9t5fNpXdhibh2jrmJrfga7z8p5mG0bia5qlrQggmsyP8TPLph6SRmNAicSLiaMjtqAT6NftcvfjzjzjTOc1lg/640?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;「&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;计算机类&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;」&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/kKoeb9t5fNpXdhibh2jrmJrfga7z8p5mGPmF3CMew2KT0pV08CPDku2K0EbKcxZcWoBnSFTKyO6v8IFpGnVKl6g/0?"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/kKoeb9t5fNpXdhibh2jrmJrfga7z8p5mG1xMWXlkk6eicARic8D8VSR2VzGmOnh3kT8uCOvm1EfW7QDBaaNY7k8Xg/640?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/kKoeb9t5fNpXdhibh2jrmJrfga7z8p5mGmib64zLxCAdcOzF5IUibyQibIQfr8N40zKlrr3LSia0xD9Ob9OmgzRzCCQ/640?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;「&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;生物类&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;」&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/kKoeb9t5fNpXdhibh2jrmJrfga7z8p5mG5NRRL6xgUiaXNpLk8vpA4APmur5ia6gfgKb4Ywic2Y410MeHcvKJsnA6w/640?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/kKoeb9t5fNpXdhibh2jrmJrfga7z8p5mGrjczcw7YEfiacYqGU4ScoI4dvC8CBosblUlia6Sk2CR1kxCtHYNka5fg/640?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/kKoeb9t5fNpXdhibh2jrmJrfga7z8p5mGzHN9VW2KBQPCfzibOTkUzVtCia55vET9yK0Drh1GM6yojedD0pXnPJRw/640?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/kKoeb9t5fNpXdhibh2jrmJrfga7z8p5mGXuEPJvSBnnQRnYGVx5XFZortaWVYD9JwPUiakXibyL5LNUVofdHezEbQ/640?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/kKoeb9t5fNpXdhibh2jrmJrfga7z8p5mGV54X31lTbCXbceP2ic2B4icsrIMdThxicHIBWWCn9BNcXdhtNRmMru6jA/640?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;「&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;数学类&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;」&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/kKoeb9t5fNpXdhibh2jrmJrfga7z8p5mGyzibSUVm7cY7UfuX0Oia76N7oGiagbCJmeABcGZichLPNkwTqDW6HibA10g/640?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/kKoeb9t5fNpXdhibh2jrmJrfga7z8p5mGHnhKuIOZxwOrjzT1ibWKRWm8UU5Bz3uvNbqk6dRMicicVctmEdFeREsvg/640?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;「&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;物理类&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;」&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/kKoeb9t5fNpXdhibh2jrmJrfga7z8p5mGXHerydZ2wMiafA0MficGPgzj8eSgmZW9zib9AHbpeVB6RdNQvbpVWNWPw/640?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/kKoeb9t5fNpXdhibh2jrmJrfga7z8p5mGxiac3AiaKuQib2rMRLzmZWOmT3Jm8iaCBnicTa3KbT66EPTuP3Jb7dO6ibIw/640?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;「&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;心理学类&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;」&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/kKoeb9t5fNpXdhibh2jrmJrfga7z8p5mGq2zDHGWG8AArl5sicBg3o6hO95yqqAlvsNj6QSRX1ibUogk8bN2l8uFA/640?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;「&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;医药类&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;」&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/kKoeb9t5fNpXdhibh2jrmJrfga7z8p5mGKzf7WQfmawLnrnZvRN2bJyS99TB1dfFORSiciagvvpo4VwmcLgGMk4sw/640?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/kKoeb9t5fNpXdhibh2jrmJrfga7z8p5mGbYe6AnJkDApLhYrwpCWczT3j9iaSHYiaXcbPUPZTRbMntfialbxALdV8A/640?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/kKoeb9t5fNpXdhibh2jrmJrfga7z8p5mGnSCUL3lsXQg3y5p7ZVJgVHq3CjlatZaEMbgoy4oweAKG8k3LdDZGtA/640?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/kKoeb9t5fNpXdhibh2jrmJrfga7z8p5mGwicXMdEVYiaYWEzK5Zbe05V7Jht6CxRTGvicDBZqCYcdQhuibiaVENJW1SA/640?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;*****&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;「科研圈」综合读者提名情况、专家推荐、公众号体量及更新频率、用户评价等条件，筛选出入围20强，读者对20强进行投票的结果及专家打分，将决定最终的&amp;nbsp;Top 10。&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;“2016年度学术公众号”&amp;nbsp;Top 10榜单&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;五大平台 同步发布：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;《环球科学》杂志&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;《环球科学》官网&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微信平台“环球科学ScientificAmerican”&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微信平台“科研圈”&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;科研圈网站&amp;nbsp;&lt;/span&gt;www.keyanquan.net&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;敬请期待！&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/kKoeb9t5fNpXdhibh2jrmJrfga7z8p5mGbZ8bUictcS5UTicXKrCRg5A3oDtgBNoR0fiblFickleOKCv1WMfAx5aDIg/640?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;现在就点击「阅读原文」&lt;/span&gt;&lt;span&gt;，为机器之心投上一票吧！&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 22 Jan 2017 19:28:52 +0800</pubDate>
    </item>
  </channel>
</rss>
