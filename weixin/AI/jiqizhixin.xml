<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>重磅 | DeepMind官方确认Master身份：全面回顾AlphaGo的再度出山之旅</title>
      <link>http://www.iwgc.cn/link/4205976</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;font color="#ffffff"&gt;&lt;span&gt;机器之心报道&lt;/span&gt;&lt;/font&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李泽南、吴攀、微胖、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibc6yDDz4kPttFbcs6G6vQKHC804BtF13zRbmgmNSZ5Y1SJagqicQAVdicVWbrQWicbyXIoHzaLYz7zg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我就是 AlphaGo！2017 年 1 月 4 日晚 9 时，Master 的神秘面纱终于被揭开了。在对局周睿羊 9 段的第 59 局比赛之后，名为 Master 的账号在腾讯野狐围棋平台上主动透露了自己的身份：「我是 AlphaGo 的黄博士（黄士杰）。」随后，在对阵古力 9 段的最后一局结束后，这场由中日韩三国多名旗手对阵人工智能历时 7 天的跨年大战宣告结束。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;很快，Demis Hassabis 在自己的 Twitter 上发表了一份声明：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibc6yDDz4kPttFbcs6G6vQKV4iaCJsI9hfNVV39N8FYDY1fJ1bCQcO7pWptSzwnohzVPtVDStFsR5g/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;樊麾在微博上分享了这份声明并给出了中文版本：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibc6yDDz4kPttFbcs6G6vQKLNNHeaZic6NT7TGiarnNJAbRgO30BZLPmkz3E7qVFHicumheHYqdiciawiaQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;网名 Master 的神秘棋手于 12 月 29 日出现在弈城网上围棋平台（最初名为 Magist）。三天时间对局数量达到 30 盘，全部胜利，对手包括朴廷桓、陈耀烨、芈昱廷、唐韦星等当今世界顶级棋手，其中对朴廷桓 4 比 0，对陈耀烨为 2 比 0。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随着 Master 的连胜，网络围棋平台瞬间受到了大量关注，不少人开始猜测 Master 的真实身份。有人询问了 AlphaGo 开发者黄士杰博士，得到了不置可否的回答。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibc6yDDz4kPttFbcs6G6vQKjG2wQBWNmeVQheog5KaicRs980EJgIORBFHFubU6Uy0FcIsZSclh7Og/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随后，Master 在 2016 年 12 月 31 日宣布将休息一天。著名棋手柯洁在微博上表示：「我从三月份开始到现在研究了大半年的棋软，无数次的理论、实践，就是想知道计算机究竟强在哪里。昨晚辗转反侧，不想竟一夜无眠。人类数千年的实战演练进化，计算机却告诉我们人类全都是错的。我觉得，甚至没有一个人沾到围棋真理的边。但是我想说，从现在开始，我们棋手将会结合计算机，迈进全新的领域达到全新的境界。新的风暴即将来袭，我将尽我所有的智慧终极一战！」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 1 月 1 日晚 11 时，Master 转战腾讯野狐围棋，与各路高手展开了新的对局。因为名声鹊起，从李钦诚到古力、柯洁、党毅飞、江维杰、辜梓豪、朴永训、柁嘉熹、姜东润、井山裕太等人纷纷申请与之对战，但随后纷纷负于这一仍未公开姓名的神秘对手。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;到了 1 月 4 日下午，在网络围棋中与 Master 对战过的著名棋手包括柯洁、朴廷桓（韩国冠军）、井山裕太（日本冠军）、周俊勋（台湾省第一人）等人。1 月 4 日下午 3 点，中国「棋圣」聂卫平在与 Master 的对战中失利，这是 Master 的第 54 场胜利。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_gif/KmXPKA19gWibc6yDDz4kPttFbcs6G6vQK1TFr8b8W2JCXarxCiaQPGEOWvrj7jU7f8JdFECDR93RseIVmaGkjgQQ/0?wx_fmt=gif"/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;与柯洁的对战&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibc6yDDz4kPttFbcs6G6vQK6qppSvEwSNlo4NgCiaLsTYDAsLOxiacuUEsRVfgpLYYia3oqicNwVoMHrg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1 月 3 日 Master 战胜柯洁后，聂卫平表示：「Master 改变了我们传统的厚薄理念，颠覆了多年的定式，围棋远不像我们想象的那么简单，还有巨大的空间等着我们人类去挖掘，AlphaGo 也好，Master 也罢，都是『围棋上帝』派来给人类引路的。而在第二天负于 Master 后，聂卫平表示：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Master 技术全面，从不犯错，是其最大优势，人类要打败它的话，必须在前半盘领先，然后中盘和官子也不出错，这样固然很难，但客观上也促进了人类在围棋技术上的提高。这盘棋我布局不错，但中盘时打了一个大勺子，断送好局，有些可惜。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1 月 4 日晚，在连续对阵申真谞 9 段、周睿羊 9 段、古力 9 段后，AlphaGo 的连胜纪录扩大到了 60 场，按照事先的计划，谷歌围棋程序的非正式比赛测试暂时告一段落。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Master 在快棋赛中多次盘中获胜（没到收官阶段对手就认输了，这说明 Master 的优势很大），展示了人类棋手无法企及的快棋水平。网络快棋是目前职业选手练习的主要方式之一，因为每一步思考时间很短，和带奖金的正式比赛相比，快棋赛中对决双方更加容易出错，所以这次「升级版」AlphaGo 的实际围棋水平如何还需要正式规则比赛的进一步检验。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;值得一提的是，去年 12 月 13 日，多名谷歌高层曾经突访中国，他们在中国棋院与聂卫平、柯洁等人进行了交流，并达成了合作协议。随后在日本棋院 Journalist Club 的颁奖仪式上，Hassabis 曾表示：「2017 年对 AlphaGo 和围棋界都将是充满兴奋的一年。」人们没有意识到，在新的一年还未到来时，人工智能对于这项流传千年的古老技艺的冲击已经开始。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibc6yDDz4kPttFbcs6G6vQKib3jwLZ71tsspJITjYnM2eomicvL3xLPER78nPd98YNBibfHfBXvAiaEQg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;AlphaGo 的系统&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;AlphaGo 从高调宣战开始到 3 月底战胜李世乭，短短 2 个多月内已经博取了无数的眼球。如今再次出现了一个 Master，它是人？是 AI？还是二者的结合？业内猜疑不断。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;外行看热闹，内行看门道。在下棋这件事上我们可能看的是热闹（小编着实不懂棋的套路），但下围棋的人工智能系统我们曾了解过。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=402115604&amp;amp;idx=1&amp;amp;sn=f6edd2013badc51fa2a3fd2d751e780d&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=402115604&amp;amp;idx=1&amp;amp;sn=f6edd2013badc51fa2a3fd2d751e780d&amp;amp;scene=21#wechat_redirect"&gt;一月份的 Nature 封面报道&lt;/a&gt;中，曾详细地介绍了 AlphaGo 系统当时所采用的技术：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先 DeepMind 使用了如今火热的深度学习技术，同时还加上了另一种模拟技术来对潜在的步法进行建模。深度学习需要对一个大型的神经网络进行训练，使其对数据中的模式做出反应。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;AlphaGo 的关键在于使用的深度神经网络，而且 DeepMind 在 AlphaGo 中使用了两种不同的神经网络：第一种叫做策略网络（policy network），用来预测下一步；第二种叫做价值网络（value network），用来预测棋盘上不同的分布会带来什么不同的结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;AlphaGo 使用这两种网络的方法是把非常复杂的搜索树减少到可操作的规模。所以，它并不是在每一步都要考虑几百种步数，而只考虑政策网络提供的几十种最有前景的步法，价值网络的作用是减少搜索的深度，所以，它的搜索深度并不是特别深，它并不是一下子搜索出直达比赛末尾的 300 多步，而是搜索更少的步数，比如 20 多步，并评估这些位置，而不是一路评估到底，看谁最终能赢。搜索并不是靠蛮力，而是与某种与想象力很相似的东西。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibc6yDDz4kPttFbcs6G6vQKIUJ3icqcCVntbbhc4pfGLglF0IFQX1GcibjVllcJEKRfpO5N5CzibjlAw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721997&amp;amp;idx=1&amp;amp;sn=b7ac7a76a8f9b8f2ccfd240cd37d14a2&amp;amp;chksm=871b0ab3b06c83a531fe689786cc8eb5145d61063acaeea7f8d3ae714f78feb899bcadfa0998&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721997&amp;amp;idx=1&amp;amp;sn=b7ac7a76a8f9b8f2ccfd240cd37d14a2&amp;amp;chksm=871b0ab3b06c83a531fe689786cc8eb5145d61063acaeea7f8d3ae714f78feb899bcadfa0998&amp;amp;scene=21#wechat_redirect"&gt;DeepMind 官方发布的 2016 年度总结&lt;/a&gt;&lt;/span&gt;&lt;span&gt;中写道，「最激动人心的莫过于 AlphaGo 博弈过程中所呈现出来的创造力，有时，它的棋招甚至挑战了古老的围棋智慧。围棋，这一古往今来最富深谋远虑的游戏之一，AlphaGO 可以识别并分享其中洞见。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;就像首位和 AlphaGo 对战的专业选手&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=402655050&amp;amp;idx=1&amp;amp;sn=ce347e61a7012ece8866f775571e3ca9&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=402655050&amp;amp;idx=1&amp;amp;sn=ce347e61a7012ece8866f775571e3ca9&amp;amp;scene=21#wechat_redirect"&gt;樊麾在接受机器之心采访&lt;/a&gt;时表示：「AlphaGo 可能开辟出另外一种围棋的美，是我们想象不到的。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果观看了 AlphaGo 和李世乭的对弈，你或许不会对坐在李世乭对面的这位感到陌生。他就是 AlphaGo 的核心作者之一 Aja Huang（黄士杰），而这次代「Master」执子的也是黄士杰博士。值得注意的是，黄士杰还是 DeepMind 中唯一一位围棋高手（业余围棋 6 段），从他的硕博论文《计算机围棋打劫的策略》和《应用于计算机围棋之蒙地卡罗树搜寻法的新启发式算法》便可以看出他对围棋的热爱。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2011 年毕业于台湾师范大学计算机信息工程专业博士班的黄世杰在 2012 年便加入了 DeepMind 团队，也是该团队的早期核心成员之一。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在校期间，黄士杰的导师是曾研发 Crazy Stone 的 Rémi Coulom，而 Crazy Stone 正式在 AlphaGo 横空出世前最有名的围棋软件之一。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;黄士杰的导师此前在接受媒体报道时曾透露，黄士杰读硕士时就锁定围棋为他的研究课题，为了写程序，黄士杰有时在实验室一呆就是 16 小时，并将他开发的围棋程序以其老婆的英文名「Erica」命名。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面是黄士杰的论文引用情况。凭借发表于 Nature 的论文《Mastering the game of Go with deep neural networks and tree search》和另一篇论文《Move Evaluation in Go Using Deep Convolutional Neural Networks》的高引用量，黄士杰仅凭 4 篇论文就在短短两年时间内获得大约 388 到 851 之间的引用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibc6yDDz4kPttFbcs6G6vQKn0agVw5ZoEjKicu6EicIm6kjkS1JnpFTlOibwiaJ24EnOC07aCUcG9icv0w/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心原创，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 05 Jan 2017 00:20:00 +0800</pubDate>
    </item>
    <item>
      <title>深度 | 听！具备深度学习能力的助听器是怎么工作的？</title>
      <link>http://www.iwgc.cn/link/4205977</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自IEEE Spectrum&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;作者：汪德亮&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：Jane W、杨旋、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;本文作者汪德亮（DeLiang Wang）是美国俄亥俄州立大学教授、感知与神经动力学实验室的主任、IEEE Fellow。主要致力于机器感知和信号处理领域的研究，在听视觉处理的神经计算研究方面也取得了重大成果。汪教授也是大象声科的联合创始人兼 CTO。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当我离开家去上大学时，我的母亲开始失去她的听力。我回家分享我学到的东西，她会侧身倾听。很快发展到如果同时有多人说话她将很难与人对话。现在，即使有了助听器，她仍然需要努力分辨每句话的声音。当我的家人来用晚餐时，她仍然央求我们轮流和她说话。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我母亲的艰难处境也是助听器制造商所面临的一个经典问题。人类听觉系统能自然地在嘈杂的房间中分辨声音，但是制造一个能模仿这种能力的助听器已经困扰了信号处理专家、人工智能专家和听力学家陷入数十年。1953 年，英国认知科学家 Colin Cherry 首次将这称为「鸡尾酒会问题（cocktail party problem）」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;六十多年后，在需要助听器的人群中，只有不到 25％的人真正使用了助听器。令这些潜在用户犹豫的最大问题是助听器并不能区分同时发生的声音，如人的语音和经过的汽车的声音。助听器同时将两者音量调大，产生乱七八糟的音调。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在是我们解决这个问题的时候了。为了给助听器佩戴者提供更好的体验，最近，在哥伦布市的俄亥俄州立大学的实验室将基于深度神经网络的机器学习应用到了分离声音的任务了。我们测试了多个版本的数字滤波器，它们不仅可以放大声音，还可以隔离背景噪声和自动调整每种声音的音量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们相信这种方法最终可以恢复听力受损的人的理解能力，以达到甚至超过正常人的听力。事实上，我们的一个早期模型将受试者理解被噪声掩盖的语音单词的能力从 10％提高到 90％。因为听者理解含义不需要听清短语中的每个单词，这种改进通常意味着能否成功能理解一个句子。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;没有更好的助听器，人们的听力将无法得到保障。世界卫生组织估计，有 15％的成年人（或大约 7.66 亿人）患有听力受损。随着人口增长，这一数字还将继续增大；而且在成年人群中，年纪越大的人听力受损者所占的比例也越大。同时先进助听器的潜在市场不仅仅限于有听力受损的人。开发人员可以使用该技术来改进智能手机的语音识别功能。雇主们可以帮助工人降低嘈杂的工厂车间带来的噪音，军队可以为士兵们装备设备使他们能够在战争的混乱中听到彼此。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这一切都是巨大的潜在市场。根据在印度浦那市的市场研究公司 MarketsandMarkets 统计，现今 60 亿美元的全球助听器产业预计将以 6％的年增长率增长，这一趋势将持续到 2020 年。但是要满足所有新客户的要求，这意味着要寻找到一个能够解决鸡尾酒会问题的万全解决方法。终于，深度神经网络为前进的道路指明了方向。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibc6yDDz4kPttFbcs6G6vQKS5QTicyRn6OQVqhHmOXxveHM3rWT4OpuLMIROvKNX0zhfaicjickOwuMA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Clean Speech：为了将语音与噪声分离，机器学习程序将嘈杂的语音样本分解成被称作时频单元（time-frequency unit）的元素集合。下一步，它分析这些单元来提取区分语音与其它声音的 85 个特征。然后，该程序将特征传入经过训练的深度神经网络中，基于相似样本学习的经验，这个网络能够区分时频单元是否为语音。最后，该程序使用数字滤波器来过滤所有非语音单元，仅分离保留语音部分。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;几十年来，电气和计算机工程师尝试通过信号处理实现语音分离，但是均以失败告终。最流行的方法是使用语音活动检测器（voice-activity detector）来识别人语音间的间隙。在该方法中，系统把那些间隙中捕获的声音指定为「噪音」。然后，算法从原始记录中减去噪声，在理想状态下可以留下无噪声的语音。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不幸的是，这种称为谱减法（spectral subtraction）的语音增强算法是臭名昭着的，它要么会去除过多的语音，要么只去除微量的噪音。往往结果是一段不悦耳的合成音（称为音乐噪声（musical noise）），使音频听起来好像是在水下录制的。该问题是如此严重，以至于经过多年的发展，这种方法仍无法提高人们在嘈杂环境中识别语音的能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我意识到我们必须采取不同的方法。我们从加拿大蒙特利尔麦吉尔大学心理学家 Albert Bregman 的一个理论开始，他在 1990 年提出人类听觉系统将声音组织成不同的流（stream）。一条流本质上对应一个源（如附近朋友）发出的声音。每个声音流在音高、音量和方向都是独特的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibc6yDDz4kPttFbcs6G6vQK572M9OnO5E2tfiat5B3OL7jjTibkgvPh4fUgOh0KRb4s1fibf5opumW1Q/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;嘈杂的世界：人类的耳朵能一次捕获许多声音流，部分归功于其特殊的形状。一条流是指从单个源（如狗）发出的所有声波。所有流组合在一起，就构成了一个听觉场景（吠叫+警报+说话）。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;许多流放在一起——如曲棍球比赛的呐喊声中朋友的说话——构成了 Bregman 所谓的「听觉场景（auditory scene）」。如果同时有在相同频带（frequency band）的声音，那么场景中最响亮的声音会超过其它声音，这种原理称为听觉掩蔽（auditory masking）。例如，如果屋顶上有下雨的声音，人们可能就不会注意到房间角落时钟的滴答声。这个原理和其它一些原理已经被应用到了 MP3 文件压缩技术上——能使文件大小压缩到原始大小的十分之一——它的原理是消除被掩蔽的声音（如滴答作响的时钟）而不被用户注意到。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;回想 Bregman 的研究，我们想知道是否可以构建一个滤波器来确定一个声音流在特定频带内的某一时刻是否支配其它声音流。研究声音感知（sound perception）的心理声学家（Psychoacoustician）将人类听力范围平均划分为 20 赫兹至 20000 赫兹间的 20 多个频带。我们想要滤波器来告诉我们在某时刻这些频带内的包含语音或噪声的声音流哪个更强，这是分离两者的第一步。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2001 年，我的实验室是第一个设计这种滤波器的实验室，它将声音流标记为语音或噪音。我们可以基于一些区别特征（如振幅（响度）、谐波结构（音调的特定排列）和开始（onset）（特定声音开始的时间））在滤波器上开发机器学习程序，用来区别语音和其它声音。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个原始的滤波器是理想的二进制掩码（binary mask）。它在称为时频单元的声音段中标记语音和噪音，时频单元用来指定特定频带内的特定短暂间隔。滤波器分析嘈杂语音样本中的每个时频单元，并将每个标记为 1 或 0。如果「目标」声音（语音）比噪声更大，则记录 1，如果目标声音比噪声小，则记录 0。结果是 1 和 0 的集合，用来表示样本内噪声或语音哪个占主导地位。然后，滤波器删除所有标记为 0 的单元，并将那些得分为 1 的单元重新组合成语音。为了能从有噪声的音频中挑出语音并重新组合成可理解的句子，必须将一定百分比的时频单元标记为 1。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们于 2006 年与俄亥俄州的美国空军研究实验室（U.S. Air Force Research Laboratory）合作测试理想的二进制掩码。大约在同一时间，来自纽约雪城大学的一个团队独立评估了理想的二进制掩码。在这些试验中，滤波器能帮助患有听力障碍的人以及具有正常听力的听众更好地理解混合噪声的语句。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从基础上说，我们创建了一个实验室环境下完美无瑕的语音滤波器。但这个滤波器的优势在现实中并不成立。设计上，我们分别提供了语音和噪声的样本训练，然后用混合的相同样本进行测试。因为它已知答案（这就是为什么它被称为「理想」），滤波器知道什么时候语音比背景噪声更强。一个实际工作的滤波器必须完全靠自己、一边听一边处理地将一个空间中的噪声和语音分离开。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibc6yDDz4kPttFbcs6G6vQKJrC2nSZfrUJ1cekYiakhqUXJyng447JmYdTiaE1xK1enKC9ZO5MtJmgQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;听：照片拍摄于 2013 年，一个基于深度神经网络的语音分离机器学习程序正由俄亥俄州立大学的（从左到右）Sarah Yoho、DeLiang Wang、Eric Healy 和 Yuxuan Wang 测试。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不管怎样，对于听力受损的听众和具有正常听力的人来说，理想的二进制掩码显著地改善了他们的语音理解能力，这具有深刻的意义。它表明监督学习的分类技术，作为一种分离语音和噪声的方式，可以用来近似理想的二进制掩码。实际上，通过完成练习、接收反馈、绘制和从经验吸取教训，机器以分类的方式模仿人类学习。这本质上就是人类幼年学习将苹果区分于橘子的过程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在接下来的几年中，我的实验室第一次尝试通过分类近似理想的二进制掩码。大约在我们开发原始分类器的同一时间，在匹兹堡的卡内基梅隆大学的一个小组也在通过机器学习算法分类时频单元，但他们的目的不同：提高自动语音识别。后来，德克萨斯大学达拉斯分校的一个由 Philipos Loizou 领导的小组使用了一个不同的分类方法，成为第一个为依靠单耳（相对于双耳）具有正常听力的人改善语言清晰度的团队。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是这些早期的机器学习分类技术的准确度还不够高，能给助听器佩戴者提供的帮助还不够多。它们还不能处理一些比较复杂和不可预知的问题，不能把噪音和有效语音分离。为了达成这个目的，我们需要一些更强大的东西。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们在我们早期的分类算法的执行结果中看到了前景，我们决定采取下一个逻辑步骤来改进系统，让其在没有训练特定的噪声和句子的情况下也可以在嘈杂的真实环境中工作。正是这些具有挑战的事情促使我们尝试去做一些以前从未做过的事情：构建一个运行在神经网络上的机器学习程序（参考论文《An algorithm to improve speech recognition in noise for hearing-impaired listeners》），让其在经历复杂的训练过程之后可以将语音与噪声分离。程序将使用理想的二进制掩码来指导神经网络的训练。最后，我们成功做到了。在一项涉及 24 名测试对象的研究中，我们证明了该程序可以将听力障碍人士的理解程度提高约 50％。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从根本上说，神经网络是由一些相对简单的元素构成的软件系统，这些简单的元素聚合在一起就可以处理一些较复杂的问题。（这个系统的架构大致上是在模仿大脑中的神经元的工作）当遇到新的问题的时候，神经网络就会像人类大脑一样，通过调整各个神经元之间连接的权重来进行「学习」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibc6yDDz4kPttFbcs6G6vQKz7zuvlZYL7nTJhHOU71nViaCvwdV2rYLOicCHHDt46LtBicFCqT7WC5Xg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Smart Layers：深度神经网络的输入输出层之间有两个或两个以上的处理层，输入信息被输入到输入层（左），然后这些信息经过处理层的处理之后又被送到了输出层（右），这就是我们需要的结果。研究人员可以通过调整系统的参数和各个层之间的连接来提高系统的性能。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;神经网络具有很多种不同的形状和规模，并且它们的复杂度也各不相同。深层神经网络被定义为具有至少两个「隐藏」处理层，并且它们不直接和系统的输入输出层进行连接。每个隐藏层都会对前一层传递给它的内容进行优化，基于现有知识再添加一些新的考虑。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;举个例子，有一个用于识别客户手写体签名的程序（参考论文《Machine Learning for Signature Verification》），这个程序一开始会把新的签名和训练数据库中已经存在的签名进行对比。当然，经过训练后这个程序知道是不需要要求新的签名和原始签名必须完全匹配。其他层可以确定这个新签名和原始签名在某些特征上是否是保持一致的，比如字体的倾斜的角度或者是字母 i 上面的那一点的缺失。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了建立我们自己的深度神经网络，我们开始通过编写算法来提取一些特征，这些特征通过声音的振幅、频率和各个调制的变化来从噪声中提取有用的语音。我们选定了几十个特征，这些特征可以在一定程度上帮助我们的程序区分语音和噪声，我们使用了所有选定的这 85 个特征，希望可以使算法尽可能地强大。在我们所选定的这些属性中，最重要的是声音的频率和它们的振幅（声音大或者小）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;接下来，我们使用了这 85 个选定的特征来训练深度神经网以实现区分语音和噪声的目的。这个训练过程一共有两个阶段：第一阶段，我们通过无监督学习设置程序的参数。也就是说，为了让我们程序可以在以后运行的过程中把各种各样的输入信号进行分类，我们会将许多属性的样例集加载到程序中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;接下来是第二阶段的训练，我们将使用嘈杂的语音和我们所期望得到的分类结果的二进制掩码作为训练样本，这个过程是监督学习。其中，构成理想结果的二进制掩码的 1 和 0 的集合就像一个答案表，我们用它来测试并提高我们的程序分离语音和噪声的能力。对于每个新样本，程序将从嘈杂的语音中提取一组属性。然后，程序会对语音的频率、振幅等属性进行分析，在这之后滤波器会执行一个暂时的分类以确定这到底是有效语音还是噪音，接下来会把这个分类的结果和样例中的分类结果进行对比。如果这个结果与我们所期望得到的 01 序列不匹配，我们就会调整神经网络中相应的参数，以便网络在下一次运行的时候可以产生更接近理想二进制掩码的 01 序列结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了进行这些调整，我们首先会计算神经网络的误差，即对比理想二进制掩码和神经网络的最后一层（输出层）的输出结果之间的差异。当我们计算出误差以后，我们将使用它来改变神经网络各连接的权重，使得如果再次执行相同的分类，误差可以减小。为了减小误差，神经网络会对这个过程进行成千上万次的迭代。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了对整个系统进行进一步的改进，我们在第一个神经网络之后构建了第二个深度神经网络，第一个神经网络的输出会作为第二个神经网络的输入。第一个神经网络着重于在每个独立时间 - 频率单元内对属性进行标记，第二个网络将会检查特定单元周围的几个单元的属性。我们用一个比喻来说明这样做为什么会有帮助：假设我们正在购买房屋，如果把第一个网络比喻成房子的房间，那么第二个网络就像周围的社区。换句话说，第二网络向第一网络提供了关于它处理的语音和噪声的额外的上下文环境，并且进一步提高了其分类的精度。例如，音节可以跨越许多时间-频率单元，但是背景噪声可以在说话时突然改变。在这种情况下，上下文线索可以帮助程序更准确地分离语音和音节内的噪声。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在监督训练的最后阶段，深度神经网络分类器被证明远远优于那些早期的用于分离语音与噪声方法。事实上，对于任何依赖于单声道技术来帮助听觉有障碍的人去理解那些被噪声所掩盖的语音中的信息的技术而言，算法都是十分重要的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了在人类身上做测试，我们邀请了 12 名听力障碍人士和 12 名正常听力人士通过耳机收听嘈杂句子中的样本。每个样本都是一对组合；首先会同时播放语音和噪声，然后我们将使用我们的深度神经网络程序对相同的样本进行处理后再播放。这些样本会包括诸如「这个地方变冷了」和「他们吃了柠檬饼干」等句子，同时这些句子会被混杂在两种类型的噪音之中：一种是稳定的嗡嗡声和另一种是许多人同时说话的声音。稳定噪声类似于冰箱运行的声音，其音频波会一直重复，并且频谱的形状不会随着时间改变。我们增加了来自四个男性和四个女性的谈话声来模仿鸡尾酒宴会，创造了第二种嘈杂的背景声。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在使用我们的程序对句子处理之后，两组受试者在噪声中理解句子的能力都有了显着改善（参考论文《An algorithm to improve speech recognition in noise for hearing-impaired listeners》）。在对声音样本进行处理之前，有听力障碍的人可以听懂其中 29％的词，对声音处理之后，它们可以理解 84％的词了。在这其中还有几个人一开始只能理解原始样本中 10％ 的词，对样本进行处理后他们可以理解大约 90％的词。在稳定噪声的情况下进行测试也有类似的增益，他们能理解的词从 36％ 提升到了 82％。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于听力正常的人，我们的程序也能帮助他们更好地理解嘈杂环境中的句子，这意味着我们的程序将来可以帮助到比我们预期更多的人。具有正常听力的听众在稳定噪声中只能理解 37％ 的词，在我们程序的帮助下他们可以理解 80％ 的词了。在混乱噪声的情况下，他们能理解的词也从 42％ 提升到了 78％。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们实验的最有趣的结果之一是，在我们的程序的帮助下，听力障碍的人可以比正常听力的人的理解能力提升更多？显然，这个答案是肯定的。有听力障碍的听众使用我们的程序之后，比单纯依靠自己的听觉系统分离语音和噪音的正常听力者在嘈杂噪声和稳定噪声中分别多理解了 20％ 和 15％ 的词。由这个结果可得，在各种鸡尾酒宴会问题的解决方案中，我们使用深度神经网络构建的程序取得了迄今为止最优的结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然，程序的能力是有限的。例如，在我们的样本中，我们所使用的噪声样本与程序已经训练分类的噪声类型非常相似。为了让我们的程序在现实生活中起作用，程序需要快速的去学习并过滤掉多种类型的噪声，其中包括包括那些还没有遇到过的类型。例如，通风系统的嘶嘶声就与冰箱压缩机的嗡嗡声不同。此外，我们使用的噪音样本没有混合房间的墙壁和物体的声响，如果加入这些噪音将会使任何的鸡尾酒会噪声问题更加复杂。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在我们发布这些早期的结果之后，我们又购买了一个电影制作人设计的声音效果数据库，并使用了 10,000 个声音进一步地训练我们的程序。今年，我们发现经过再次训练的程序对于全新的噪音也可以提高听力受损听众和正常听众的理解能力了（参考论文《Large-scale training to increase speech intelligibility for hearing-impaired listeners in novel noises》）。现在，通过国家耳聋及其他交流障碍研究所（National Institute on Deafness and Other Communication Disorders）的资助，我们正在推动该计划在更多的环境中运行，并对更多的听力障碍者进行测试。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最终，我们相信我们的程序在拥有强大的计算性能的计算机上进行训练后，可以直接被嵌入助听器，或通过无线链路（如蓝牙）与智能手机配对，可以将处理的信号实时的传送到耳机中。助听器佩戴者也可以定期地更新他们的设备，因为制造商会对系统进行新噪声的训练，之后会发布新版本。我们已经为该技术提交了多项专利，并与合作伙伴一起对其进行了商业化，其中包括位于美国明尼苏达州伊甸草原的处于领先地位的助听器制造商 Starkey Hearing Technologies。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有了这种方法，鸡尾酒会问题看起来不像几年前那样令人生畏了。我们期望最终可以通过制造在更嘈杂的情况下进行更广泛的培训的软件来克服它。事实上，我怀疑这个过程和孩子们在生活中学习对噪声和语音的分离方式类似，他们通过反复接触大量的噪声和语音来学习。随着拥有越来越多的经验，这种方法会变得更好。这就是它吸引人的地方。对于年轻人而言，也是这个道理，时间是由我们自己掌控的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 05 Jan 2017 00:20:00 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 认知计算和知识工作的革命</title>
      <link>http://www.iwgc.cn/link/4205978</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;选自kmworld&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;参与：沈泽江、Jane W、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在未来十年，由于社交媒体处于最后阶段，认知计算（cognitive computing）将对机构组织造成颠覆性影响，甚至可能更甚。事实上，Gartner 预测智能机器时代（smart machine era）将是 IT 历史上最具颠覆性的。我们正处于涉及基本人类过程（human processes）的范式转变的边缘，这些人类过程引导了信息发现、洞察、问题解决以及决策的制定。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;认知计算、机器学习和预测分析将渗透我们生活的各个方面，从根本上改变我们在数字生活中学习和互动的方式。内容管理、协作和整个搜索体验将更加自动化、无缝化和个性化。结果是，我们将更严重的依赖于计算机，同时与它们形成越来越复杂、甚至亲密的关系。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而未来已经如此，至少认知计算已经被许多领域率先采用。认知能力开始在诸如医疗保健、软件、金融服务和石油和天然气勘探等行业中发挥重要作用。在 2016 年美国生产力与质量中心（APQC）的知识管理（APQC‘s knowledge management）观众调查中，9％的参与者表示，他们的机构已经在使用认知技术，另有 17％的计划或认真考虑使用认知应用-（见第 21 页图表，KMWorld 2017 年 1 月第 26 期第 1 刊）-。在此刻，各机构需要开始修改他们的战略并在员工如何创建、共享、访问和应用机构知识方面做好应对未来变化的准备。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;认知计算对知识管理（knowledge management）的影响尚未完全明朗，但是知识管理专业人员需要了解认知计算可以做什么以及如何适应它。为了探讨认知技术对知识管理能力和计划的影响，APQC 召开了第 9 届知识管理高级工作组会议（KM Advanced Working Group），参加会议的成员来自 APQC、德勤、安永、NASA、辉瑞以及美国陆军训练与教导司令部。他们一起研究了利用认知计算来管理和提供企业知识的机遇性和潜在应用场景。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;什么是认知计算？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;认知计算是用于模拟人类思维过程的计算机化模型的统称。根据德勤报告，认知系统可以「处理远远超出人类能力的信息，识别模式并提供潜在的解决方案，而这些通过传统的分析方式，人类可能永远无法识别。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;真正的认知系统结合了机器学习算法（使得软件能够基于经验改进）与高级数据挖掘能力（有助于识别大型数据集内的模式和关系）和自然语言处理（使得计算机能够理解人类语言并作出反应）。也许最知名的认知解决方案是 IBM 的 Watson，它使用自然语言处理和机器学习来从大量非结构化数据中理解问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些算法使得认知系统能够筛选大量的结构化和非结构化内容并针对用户的搜索或提问提供个性化的、直觉的反应。随着认知模型的扩展并不断纳入新的数据和信息，它们逐渐变得更加全面和准确。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;新兴认知革命的基础&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;传统上，计算机在有清楚定义的答案对错明确的查询方面是优异的。软件在过去二十年变得越来越复杂，因此当今的认知系统和机器学习应用程序能更加动态地处理问题。这使它们能够处理更复杂的问题，根据流入的新信息来改进它们的反应，并在众多可行的可能方案中判断最佳选择。这些能力可能最终使得认知系统能够对人类典型的的多方面、上下文关联的查询类型做出反应。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;APQC 的 KM Advanced Working Group 假设了三种现象将推动认知采纳（cognitive adoption）的新兴浪潮。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一个因素是机构和员工可用的大量数据。根据位于新加坡和印度的 Aureus Analytics 的分析，全球 90％的数据是在过去两年间创造的，随着物联网的应用，每年的数据总量将增长 40％。云存储使得即时访问大量数据成为可能，但是即使通过传统计算机程序辅助人类思维也不可能处理或理解这么多信息。因此需要认知系统，以便机构能够掌握大数据，并在混乱中发现模式和见解。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二个因素与技术本身有关。原始计算能力和分析模型的最新进展使系统可以遍历大量数据集（包括非结构化和富媒体内容），并以近乎实时的方式返回有意义的结果。语义分析（semantic analysis）分析定性数据，同时机器学习技术使系统能够理解用户的前后语义并提出后续问题以进一步优化其响应。最后，自然语言处理和用户接口的发展改善了人机交互，并为人与机器之间更紧密、更自然的合作铺平了道路。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后一个因素是知识工作的高成本。许多机构认为最大的投资是他们的劳动力，但劳动力并没有最大程度的被有效利用。根据 IDC，知识工作者平均花费近 20％的时间寻找内部信息。更直观的搜索功能包含了内部、外部、结构化和非结构化内容，并提供高度针对性的答案（而不是用户必须筛选的页面或文档的列表），可以为机构节省数十亿美元，并同时释放员工时间以进行更多有附加值的工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人们已经在智能手机上体验到了机器学习的厉害之处。例如，你是在晚 6 点左右看手机的时候，发现一条关于预计回家驾驶时间及回家驾驶路径的通知推送？这也许会让你丈二摸不着头脑——因为你从未告诉过你的手机你住哪里、你在哪里工作，并且你并没有专门设置让你的手机在特定时间推送关于交通状况的消息。但实际上，（借助机器学习等技术，）你手机内部的软件能够分析你手机在你日常作息、活动时采集的 GPS 数据，能预计你何时将会下班回家并提供相关的交通信息（例如你日常回家的路上是否会有交通拥堵）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不过，机器学习及认知计算的能力不仅限于这种有特定目标的应用（Targeted Applications）。IBM 认为，对认知计算而言，有三种更为广义的能力范围：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;参与性任务：通过对相关问题及时回复、提供目标信息，程序能够像专业助手一样。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;探索性任务：程序能够在大规模离散数据集中，发现之前未发现的模式或关系。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;辅助决策功能：程序对复杂且不断改变的大规模数据集进行分析后，能对不同的选择给出相应的置信分数，并对用户推荐最优选择。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;很显然，这三个领域都有可能增强甚至改变知识型工作。某些应用已经能够帮助人类做出决策，如某个能够分析海量医疗数据集的系统，可以发现过去未发现的在症状、疾病及后果之间的数据联系。另一些系统甚至能取代人类专家——如能够分析个人财务状况及目标并提供投资建议的系统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;知识管理最明确的应用之一，是能够处理关于职员的多维信息的系统。其中的多维信息包括，职员正在工作的项目，他/她的熟练度，他/她经常交往的对象及其他因素。这样的目的，是能够推荐可能的答案、解决方案或是行动。它将会持续读取数据并随时间生成更多的优化的结果。尽管某些问题仍需要人类的意会知识及推理能力，但机器学习仍能够用于最适用内容、数据集及领域，以协助特定情况下的决策过程。不论何种情况，其愿景是，职员能够花更少的时间搜寻知识，而可以把更多的时间花到学习和使用它上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;知识管理与认知计算的结合点&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在讨论了诸多可能的情况后，APQC 的 KM Advanced Working Group 指出，认知在如下所述的知识管理（Knowledge Management）的六个领域比较有前途。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;搜索与发现：认知计算在改进企业搜索及发现过程方面，有非常多的可能性。目前的搜索应用能够遍历非结构化的数据，并能够执行一些自动标记任务，但这些功能往往是局限的。在搜索功能融合了认知计算后，它将能够提供更为综合的答案。甚至是任务涉及到需要分析图像及视频，或是需要集成隐藏在多个文档中的信息时，它也能胜任。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;内容筛选：通过使用算法来搜寻不同类型的数据、寻找数据源中的相似点及在逻辑组中进行聚类，机器学习能够自动化内容筛选过程。内容将会被依次标记及展示（也可以根据搜索语句的额要求展示）。这项任务的目标，是提内容筛选过程的效率、降低过程的花费，同时也要能删除某些丢失情况（相关的内容存在，但是系统不能够连接用户到最优资源上）。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;专家定位：认知系统具有扫描海量完全不同信源的能力，能够识别其中的领域专家或为特定话题工作的人们。这样的系统能够提升同事推荐的质量、降低寻找问题帮助及答案的时间和揭开隐藏的专业知识。这些好处，能够帮助用户从建立个人档案、列出个人技能、经验、兴趣的反复工作中解脱出来。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;数据导向的可视化系统：一般而言，人们为了解释、探索及展示数据，而进行数据可视化。认知计算能够这些过程变得自动化、增强其处理能力并赋予其不可思议的处理速度。在如今的大数据时代，可视化被用来显示内容及展示数据及知识，能允许用户在不同的话题及想法上建立新的连接。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;经验教训分析：尽管许多组织在从项目及程序上习得教训方面颇具成效，但在真正地从过去地经验中学习并在未来应用经验方面，他们仍面临着困难。在正确编程的情况下，一个认知系统能够分析在已有数据库上习得经验，也能够处理那些未被正式叫做经验教训、但有助于改进或帮助发现机会的、从其他项目文件中得到的一些信息。因此，系统能基于目前工作项目的类型和阶段，向个人或团队提供相关的建议或想法。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;数字助手：大多数人所熟悉的当代智能个人助手，是如 Siri、Google Now 及微软 Cortana 之流、出现在他们的智能手机或其他设备上的智能助手。但更为先进的助手，具有改变职员与企业知识交互方式的潜力。在认知计算的帮助之下，一个数字程序可以成为职员的导师、指导或是助手，无论他们是在办公室还是在旅途中。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 05 Jan 2017 00:20:00 +0800</pubDate>
    </item>
    <item>
      <title>深度 | DeepMind官方年度总结：除了AlphaGo，我们还应该关注什么？</title>
      <link>http://www.iwgc.cn/link/4193468</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自DeepMind&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;作者：Demis Hassabis、Mustafa Suleyman、Shane Legg&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;参与：微胖、曹瑞、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;今日，DeepMind 的 CEO Demis Hassabis 等三人在其官方博客发表文章，总结 DeepMind 过去一年中所取的的研究成果，可谓是硕果累累。非常荣幸的是作为最早关注 DeepMind 研究的媒体之一，机器之心几乎全部报道过这些研究，及时为大家输送了好的人工智能研究成果，读者可点击文中的链接详细了解这些研究。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibc6yDDz4kPttFbcs6G6vQKBJAcOCr07I9NUib7uAlCg2PDZ9hQLlY5MFOyK74qhV5BYhugDdiac6PQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们所处的世界是一个极端复杂、紧急和难以掌控的系统——从气候变迁到意图征服的疾病——我们相信，智能系统将有助于揭开新的、促进社会公共善的科学知识。为此，我们需要一个具有通用目的、能够从零开始不断加深对问题理解的系统，该系统能借助这一能力识别出模式以及否则可能错失的科学突破。这也是 DeepMind 长期研究所关注的焦点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然距离所谓的智能仍路漫漫兮，但是，2016 年，我们仍然在许多核心基础问题上取得了振奋人心的进步，也首次得以见识这些进步可能给真实世界带来的积极影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们的 &lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=402115604&amp;amp;idx=1&amp;amp;sn=f6edd2013badc51fa2a3fd2d751e780d&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=402115604&amp;amp;idx=1&amp;amp;sn=f6edd2013badc51fa2a3fd2d751e780d&amp;amp;scene=21#wechat_redirect"&gt;AlphaGo&lt;/a&gt;——很幸运第二次登上《Nature》封面——在古老的围棋比赛中击败了世界冠军李世乭。许多专家认为，人类提前十年实现了这一壮举。于我们——也包括全世界围棋界——而言，最激动人心的莫过于 AlphaGo 博弈过程中所呈现出来的创造力，有时，它的棋招甚至挑战了古老的围棋智慧。围棋，这一古往今来最富深谋远虑的游戏之一，AlphaGO 可以识别并分享其中洞见，也昭示着人工智能有望为人类带来的价值。另外，我们也期待在新的一年能够玩转更多的游戏。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在生成模型领域，我们也取得了有意义的进步，搭建出能自己想象新构造和场景的程序。发表了有关图像生成的 PixelCNN 论文之后，我们发表了&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719022&amp;amp;idx=1&amp;amp;sn=3eeb1958e695388817dd32b0d228ced9&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719022&amp;amp;idx=1&amp;amp;sn=3eeb1958e695388817dd32b0d228ced9&amp;amp;scene=21#wechat_redirect"&gt; WaveNet&lt;/a&gt; 的研究论文。研究展示了这一程序在生成音频上的有用性，WaveNet 不是将录下的语音样本拼接起来，而是创造出的新的音频波形，可以实现世界上目前最生动的语音合成。我们正计划将这一成果融入谷歌产品中，能够提升百万用户的产品体验，我们对此感到很兴奋。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2016 年，我们的另一重要研究领域是记忆（memory），特别是如何将神经网络的决策智能和有关复杂结构化数据的存储、推理能力结合起来的难题。我们研究了 &lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719745&amp;amp;idx=2&amp;amp;sn=242eda88fa9a5572e60b43e451a1549b&amp;amp;chksm=871b027fb06c8b693cff17f43553625f008fcb7965582119b651dbbd17e116e35dc801ebeec3&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719745&amp;amp;idx=2&amp;amp;sn=242eda88fa9a5572e60b43e451a1549b&amp;amp;chksm=871b027fb06c8b693cff17f43553625f008fcb7965582119b651dbbd17e116e35dc801ebeec3&amp;amp;scene=21#wechat_redirect"&gt;Differentiable Neural Computers&lt;/a&gt;，也因此收获了 18 个月来第三篇发表在《Nature》上的文章。研究展示了能够同时像神经网络一样学习，也能像计算机一样存储数据的模型。这些模型已经能学会回答关于数据结构（从家谱到地铁交通地图）的问题，也让我们距离在复杂数据组中使用人工智能进行科学发现更近了一步。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在推进这些系统所能做的事情边界的同时，我们也投入大量时间提升它们的学习方式。一篇名为《&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720561&amp;amp;idx=1&amp;amp;sn=ef09af7ff21f7b61bed28076c349e6ec&amp;amp;chksm=871b0d4fb06c845965a37c5cdcfd2fae46b38bf42478423564e06021c02d37aeb33e53eea2ef&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720561&amp;amp;idx=1&amp;amp;sn=ef09af7ff21f7b61bed28076c349e6ec&amp;amp;chksm=871b0d4fb06c845965a37c5cdcfd2fae46b38bf42478423564e06021c02d37aeb33e53eea2ef&amp;amp;scene=21#wechat_redirect"&gt;Reinforcement Learning with Unsupervised Auxiliary Tasks&lt;/a&gt;》的论文就描述了将学习某种任务速度提升一个量级的方法，而且考虑到高质量训练环境对智能体的重要性，我们也开源了旗舰研究环境&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721081&amp;amp;idx=2&amp;amp;sn=fb1b2ba31d256c08e3c93e813deabc73&amp;amp;chksm=871b0f47b06c86510e447bd4c366d1d5c78bbffe3b92903eff2e8f5a6b2df67f5c440dc822e9&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721081&amp;amp;idx=2&amp;amp;sn=fb1b2ba31d256c08e3c93e813deabc73&amp;amp;chksm=871b0f47b06c86510e447bd4c366d1d5c78bbffe3b92903eff2e8f5a6b2df67f5c440dc822e9&amp;amp;scene=21#wechat_redirect"&gt; DeepMind Lab&lt;/a&gt;, 我们也正在和暴雪合作，为 &lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720302&amp;amp;idx=3&amp;amp;sn=756e17424570ea713a15b4a5e4a97666&amp;amp;chksm=871b0c50b06c8546c49e53fd9454846ce6928ce45449726af775f11546c6f27c5b40d2c4a700&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720302&amp;amp;idx=3&amp;amp;sn=756e17424570ea713a15b4a5e4a97666&amp;amp;chksm=871b0c50b06c8546c49e53fd9454846ce6928ce45449726af775f11546c6f27c5b40d2c4a700&amp;amp;scene=21#wechat_redirect"&gt;StarCraft II&lt;/a&gt; 研发为人工智能准备的训练环境。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然，这只是冰山一角，你可以通过阅读我们在众多顶级期刊上发表的的论文来了解我们的工作，从 Neuron 到 PNAS，再到一些像是&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715855&amp;amp;idx=1&amp;amp;sn=1668f4717e666850029502015a2d4db8&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715855&amp;amp;idx=1&amp;amp;sn=1668f4717e666850029502015a2d4db8&amp;amp;scene=21#wechat_redirect"&gt; ICLR&lt;/a&gt; 和 &lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721102&amp;amp;idx=2&amp;amp;sn=cbc44a149457d31ed9a8bbe825f09378&amp;amp;chksm=871b0f30b06c8626bb94cbd7a08fd4a5c8bec747082f49280fbd27e9c87c965de983a279796c&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721102&amp;amp;idx=2&amp;amp;sn=cbc44a149457d31ed9a8bbe825f09378&amp;amp;chksm=871b0f30b06c8626bb94cbd7a08fd4a5c8bec747082f49280fbd27e9c87c965de983a279796c&amp;amp;scene=21#wechat_redirect"&gt;NIPS &lt;/a&gt;这样重量级机器学习大会。我们也惊喜地看到社区中的其他成员已经在积极实现这些论文成果或者在此基础之上继续研究——只要看看 2016 年下半年围棋计算机程序的复兴即可！我们也很兴奋见证了人工智能和机器学习走向更为广阔的领域，变得越来越强大。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;同样，我们也非常惊喜地看到我们的工作对现实世界的影响。我们与谷歌数据中心团队合作使用了与 AlphaGo 相类似的科技，以&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717202&amp;amp;idx=3&amp;amp;sn=cbed5925a1c2c7150911c929db084162&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717202&amp;amp;idx=3&amp;amp;sn=cbed5925a1c2c7150911c929db084162&amp;amp;scene=21#wechat_redirect"&gt;研发一种冷却系统用电的新方法&lt;/a&gt;，此次合作将谷歌数据中心的电源使用效率显著提升了 15%。如果将这类技术规模化到另一个大规模产业系统被证实确实可行，那么，就真的有望显著改善全球环境和成本收益。我们正在和不同的谷歌团队合作，将前沿研究应用到全世界都在使用的产品和基础架构中，这只是其中的一个例子。另外，我们正在与两家英国（也是我们的家乡）&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720693&amp;amp;idx=2&amp;amp;sn=7986218c29a01d545205c1e7e33af396&amp;amp;chksm=871b0dcbb06c84dd6cfd7273a9c2f3ba8e4f0473ee70648bc08ffd6b706789e6599b3b70e124&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720693&amp;amp;idx=2&amp;amp;sn=7986218c29a01d545205c1e7e33af396&amp;amp;chksm=871b0dcbb06c84dd6cfd7273a9c2f3ba8e4f0473ee70648bc08ffd6b706789e6599b3b70e124&amp;amp;scene=21#wechat_redirect"&gt;国家医疗服务体系（NHS）&lt;/a&gt;内的医疗集团积极合作，探索如何用我们的技术改善影响着数以百万患者的诊断和治疗条件，我们也通过我们开发的移动应用和基础设施改善临床一线的护理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然，我们对现实世界所带来的影响不仅仅体现在对现实问题的解决上，还体现在算法和模型设计、训练和一般部署方式上。我们非常骄傲地看到，DeepMind已经参与成立&lt;/span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719494&amp;amp;idx=4&amp;amp;sn=0e371842af8ca4c3a17ef0cc3d8241fa&amp;amp;chksm=871b0178b06c886e25583a80815e0baf7193a4e5eb8e5e3007810dffce74c6c7956e6331236e&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719494&amp;amp;idx=4&amp;amp;sn=0e371842af8ca4c3a17ef0cc3d8241fa&amp;amp;chksm=871b0178b06c886e25583a80815e0baf7193a4e5eb8e5e3007810dffce74c6c7956e6331236e&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;AI合作组织（Partnership on AI）&lt;/span&gt;&lt;/a&gt;&lt;span&gt;，这一组织是一个非营利组织，汇聚了顶尖的研究实验室、社会团体、学术组织，旨在在诸如算法的透明性和安全性等领域探索出最好的实践方式。通过培育经验和洞见的多样性，我们也希望能够助力解决其中的一些难题，并找到将社会利益置于全世界人工智能社区核心的方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们仍是一家年轻的公司，处于公司愿景的早期阶段。但如果在 2017 年，我们能进一步在算法突破、社会影响与最佳道德实践三个方面同时做出进展，那我们就处于非常好的状态了，可为科学社区以及整个世界做出持续的、有价值的贡献。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 04 Jan 2017 11:22:02 +0800</pubDate>
    </item>
    <item>
      <title>前沿 | Nature：量子计算机或将在2017年走向实用化</title>
      <link>http://www.iwgc.cn/link/4193469</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Nature&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：蒋思源、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;谷歌、微软以及一众的实验室和创业公司正在竞相努力将量子计算从单纯的科研项目变成可以投入生产应用的产品。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibc6yDDz4kPttFbcs6G6vQKdd9a3pxngnnhIyzLJEYsJe7Jia2IhZTMagXTIZghQjCzY0fia6tMoKew/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;在实现量子计算的道路上，使用被囚禁于真空中的单个离子的量子计算是发展得最快的方法之一&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;很长时间以来，人们都普遍认为量子计算是一种至少还需要 20 年发展才能实现应用的技术，而且这种看法似乎一直以来都没改变过。但 2017 年这项技术将有望开始延伸到单纯的科研领域之外了！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌和微软这样的计算巨头最近聘请了一些这一领域内一些领先的头脑，并且为今年设定了一些有挑战性的目标。他们的勃勃雄心反映出了正发生在包含&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720969&amp;amp;idx=1&amp;amp;sn=d5723c205f594616932624684d3a1327&amp;amp;chksm=871b0eb7b06c87a1d4d9809b35c361a4d8a4bf75315eaa9502a051058b184fb233e5b2d2695c&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720969&amp;amp;idx=1&amp;amp;sn=d5723c205f594616932624684d3a1327&amp;amp;chksm=871b0eb7b06c87a1d4d9809b35c361a4d8a4bf75315eaa9502a051058b184fb233e5b2d2695c&amp;amp;scene=21#wechat_redirect"&gt;创业公司和学术研究实验室的一场范围更广的转变：量子计算从纯科研向工程应用的转变。&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「人们真的造出了东西，」马里兰大学帕克分校的物理学家 Christopher Monroe 说，他在 2015 年联合创立了创业公司 IonQ，「这是前所未见的，它不再只是研究了。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌在 2014 年开始了对超导量子计算的研究。该公司希望在今年（甚至不久之后）就实现超过最强大的「经典」超级计算机的量子计算机——这也被视为实现「量子霸权（quantum supremacy）」的里程碑（参阅《&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718798&amp;amp;idx=1&amp;amp;sn=3f6bbc60ab65501074c58d6881271b4a&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718798&amp;amp;idx=1&amp;amp;sn=3f6bbc60ab65501074c58d6881271b4a&amp;amp;scene=21#wechat_redirect"&gt;重磅 | 深度揭秘谷歌「量子霸权」计划：有望明年底突破经典计算极限&lt;/a&gt;》）。其竞争对手微软则押注了一种有趣但仍未经证实的概念——拓扑量子计算（topological quantum computing），微软希望能够实现该计算的首次演示。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此外，量子计算创业也在升温。Monroe 今年一开始就计划开始招聘了。联合创立了 Quantum Circuits 的耶鲁大学物理学家 Robert Schoelkopf 和在加州伯克利创立了 Rigetti 的前 IBM 应用物理学家 Chad Rigetti 都表示他们预期他们很快就将达到关键的技术里程碑。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;学术实验室也是类似。「我们已经证实了我们所需的所有组件和所有功能。」Schoelkopf 说，他继续在耶鲁大学带领着一个研发量子计算机的团队。他和其他研究者都表示：尽管还需要很多物理实验才能找到将这些组件结合一起的方法，但现在的主要挑战已经是工程上的了。目前带有最多量子比特（qubit）的量子计算机（带有 20 个量子比特）正在奥地利因斯布鲁克大学 Rainer Blatt 领导的一个学术实验室里面接受测试。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;经典计算机将信息编码成以两种状态（0 和 1）表示的比特，而构成量子计算机的量子比特则可以以「叠加（superpositions）」的形式同时处于这两种状态。此外，量子比特还有一种被称为「纠缠（entanglement）」的能力——可以实现量子状态的共享。这些能力让量子计算机可以同时执行大量计算。而且理论上，每增加一个量子比特，这些同时执行的计算的数量就会翻倍，这可以带来指数级的加速。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种快速性（rapidity）应该让量子计算机能够执行特定的任务，比如搜索大型数据库或大数因子分解——对于速度更慢的经典计算机来说，这样的任务有时候是不可能完成的。量子计算机也可以作为研究工具用于执行量子模拟（quantum simulations），从而让化学家可以以前所未有的详细程度理解化学反应或让物理学家可以设计出室温超导材料。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如今对如何建造量子比特有许多相竞争的设计，但还是有两个领跑者。尽管量子态因外部干扰很容易去相干，但它们都证实了量子比特具有长期储存信息的能力，并能执行逻辑计算。Schoelkopf 帮助量子计算先锋的一个方法就是将量子状态编码为超导环路中的振荡电流，这个方法也广泛被谷歌、IBM、Rigetti 和 Quantum Circuits 接受。IonQ 和几个主要的学术实验室追求的另一个方法是在真空阱（vacuum traps）中通过电磁场编码单个离子的量子比特。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;John Martinis 在加州大学圣巴巴拉分校（University of California, Santa Barbara）工作，在谷歌 2014 年聘请他和他的研究团队时，他说超导技术的成熟使他的团队设定了量子霸权（quantum supremacy）的雄伟目标。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他们团队计划使用「混沌（chaotic）」量子算法来实现这一点，该算法产生如同随机输出的结果（S. Boixo et al. Preprint at https://arxiv.org/abs/1608.00263; 2016）。如果算法在由相对较少量子比特组成的量子计算机上运行，那么经典计算机就能预测其输出。该小组预测一旦量子计算机拥有接近 50 个量子比特数，那么即使是最强大的经典超级计算机也完全跟不上它的步伐。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然计算结果没有任何用处，但是他们将证明在有些任务上量子计算机是无可匹敌的。Martinis 说这是一个重要的的心理阀值，它会吸引潜在客户的注意力。他说：「我认为这是一个开创性的实验。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是 Schoelkopf 并不把量子霸权看作「很有意思和有用的目标」，部分原因是因为它避开了纠错的挑战：系统具有在受到轻微扰动后恢复其信息到量子比特的能力，这要比量子比特数量增多还要困难。相反 Quantum Circuits 关注于从一开始就搭建完全错误矫正（fully error-corrected）的机器。这就需要建造更多的量子比特数，不过机器也能够运行更复杂的量子算法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Monroe 希望在近期实现量子霸权，但那并不是 IonQ 的主要目标。他说，这家创业公司的目标是构建带有 32 个或 64 个量子比特的机器，离子阱（ion-trap）技术让他们的设计可以比超导电路更灵活和更具扩展性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;同时，微软则押注一种仍待验证的技术。拓扑量子计算（topological quantum computing）依赖于处于激发态的物质——其通过像辫子一样互相缠绕来编码信息。和其它技术相比，存储在这种量子比特中的信息对外部扰动的抵抗力更强，使得纠错（error correction）更简单。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;到目前为止，还没有人创造出这种激发所需的这种物质状态，更不要说拓扑量子比特了。但微软已经聘请了这一领域的四位领先专家，包括荷兰代尔夫特大学的 Leo Kouwenhoven——他已经创造出了貌似正确的激发类型。「我告诉我的学生 2017 年是 braiding 的一年。」Kouwenhoven 说，他将在代尔夫特大学建立一个微软实验室。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其他研究者则更为谨慎。Blatt 说：「我不做关于未来的任何新闻发布。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;位于科罗拉多州博尔德的国家标准与技术研究所的物理学家 David Wineland 领导着一个研究离子阱的实验室，他也不愿意给出明确的预测：「我对长期未来持乐观态度，但『长期』是什么意思，我不知道。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 04 Jan 2017 11:22:02 +0800</pubDate>
    </item>
    <item>
      <title>学界 | 机器能有意识吗？新论文提出一种用于机器意识的情感计算模型</title>
      <link>http://www.iwgc.cn/link/4193470</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自arxiv.org&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：Terrence、沈泽江、李泽南&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;人类对于意识本质的探索一直在不断发展的过程中，随着近年来人工智能的进步，此类研究的进展正在加快。理解和建模意识不仅能够使人了解自身，更能为构建先进的机器系统提供帮助。最近，Software Foundation的一项研究提出了用于机器意识的情感模型。论文可点击阅读原文进行下载。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibc6yDDz4kPttFbcs6G6vQKCYVicdmhmJjBUTnCALPlq8Ojn12swiciatxelIxTpIycKYdqPSrBNfteA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;摘要&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在过去，有几种意识模型已经变得流行，并且已被用于机器意识的模型的开发，在模拟和实现中，一些研究成果已经出现。涉及情绪，行为和个性的情感计算属性并不是这些意识模型的重点，因为它们缺乏在软件应用程序和机器人中部署的动机。但情感属性是机器意识在未来的重要组成部分，情感属性或许可以帮助人工智能助理技术兴起。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人格和感情可以给予机器人除计算模型以外的额外意识成分。机器学习领域的最近的发展集中于深度学习，它可以帮助我们在能够更好地复制人类感觉知觉（例如语音识别和视觉）的方面进一步开发机器意识。随着这些技术的进步，在开发同步情感计算的不同方面的模型中，我们必将遇到更多的挑战。在本文中，我们回顾了一些现有的意识模型，并展示了一个情感计算模型，可以在机器人系统上实现人类的触摸和感受。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;导语&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如何定义意识一直是对人类意识模拟或建模的主要挑战。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;无论如何，意识的广义定义是意识的状态或质量，其特征在于感知，主体性，通过感觉知觉体验的能力，觉醒状态，自我意识，以及心理的控制，同时意识到思维过程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;意识的定义和模型中的挑战会影响意识的实现或模拟研究。在过去，人们已经针对某些意识模型进行了模拟研究，例如来自全局工作空间理论的信息流模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Shanahan 进行了一项研究，通过与环境的相互作用的内部模拟来实现预期和规划的认知功能。一种基于失重神经元的实现也被用于控制模拟机器人。人们也进一步尝试通过暴力搜索启发式来模拟特定形式的智力，以再现人类感知和认知的特征，包括情感。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此外，小规模的实现可以考虑基于动物的意识的模型，意识是动物生存所需。虽然在任务解决的过程中表现的智力不同，但限制人类的意识的定义并不严谨，因为所有生物都倾向于具有与人类意识重叠的某些属性。一些未被驯化的动物，如啮齿动物，可以生存在具有挑战性和广泛变化的气候和环境中。有一些研究表明，如老鼠这类的动物似乎会表达意识的某些方面，这不仅仅是为了生存。它们具有社会属性，例如与人类相似的认同感。高度的好奇心和创造力是意识的主要属性，这可能是区分人类和其余动物的因素。虽然智力也是意识的一个基础方面，但一些研究已经表明，智力是必要的，但不是创造力的充分条件。然而，除了人类，其他动物也显示出了一定的创造力水平。人们已经在尝试通过研究近死亡经验，通过吸纳意识的非物质主义方面，以非常规方式增强现有模型。此外，心理学和量子力学的思路也被纳入一项物质意识的研究。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了通过实证研究意识，Tononi 提出了意识信息整合理论，它可以量化实体拥有的决定其意识水平的综合信息量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该理论完全取决于系统集成信息的能力，无论被观测者是否具有强烈的自我意识，语言、情感、身体或身处环境如何。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此外，它试图解释为什么意识在例如睡眠状态的情况下既不需要感觉输入也不需要行为输出。在此基础上，进一步的研究是令其作为动力学和因果结构的函数，将集成信息应用于离散网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;信息综合理论 3.0（Information integrated theory 3.0）通过现象学公理和假设进一步细化了意识的性质，以便设计出满足这些公理的机制系统，从而产生意识。有人建议，具有纯前馈结构的系统不能产生意识，而某些性质的反馈或递归可能是意识的一个重要组成部分。这是基于以前的研究的结论，其中确定反馈的存在与否可以直接等价于存在或不存在意识。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;David Chalmers 强调了在定义意识方面的「解释鸿沟」，并指出问题难处来自于尝试以纯物理术语解释「意识」。综合信息理论是基于现象学公理。它从意识开始，表明具有一些反馈状态的复杂系统可能具有不同的意识水平。然而，这并不完全支持 Chalmers 所定义的意识经验的动机。Chalmers 从第一和第三人的视角和他们之间的关系来看待「意识经验」和「感觉」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;情感计算领域，致力于发展处可以模拟、识别和处理人类情感的系统——这本质上就是创造感觉或情感的体验。情感计算可以让人和人工系统更好的交流，能够促进人与人工系统的情感信任，增强两者联系。让人工意识拥有情感模型，是在未来的人类日常活动中引入移动技术和机器人的一大目标。例如，家庭厨房机器人利用情感计算的特性，能进一步从建立连接和通信。在不久的将来，性机器人、治疗和护理机器人的需求量也将越来越大，这类机器人都需要情感计算功能。此外，智能玩具和机器人宠物的出现可能有助于养育孩子和赡养老人。尽管基于移动应用的支持和学习系统已成功被部署，但是他们常常因缺乏实体交互性而被批评。在如压力管理和咨询等些领域，机器人的情感可以进一步地帮助人类。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;个性是潜意识的一个独立部分。但是过去提出的关于潜意识的模型，并没有很好的处理」个性「的特性。先前的一项研究提出了不同个性在工作绩效的选择、培训和发展、以及工作表现方面的影响。Nazir 等人进一步提出了基于文化个性的情感模型，包括人格的五个维度。Carver 和 Scheier 使用控制理论作为个性的概念框架，从社会、临床和健康心理学三方面进行解读。虽然这些研究在心理学领域非常受欢迎，但是在机器意识模型中，关于如何整融合对个性的理解，却并没有被广泛地研究。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们注意到，饥饿与疼痛，作为最重要的生存方面的生物元素，帮助人们形成了性格及情感。Starzyk 等人提出了动机学习模型，以研发某种自动系统，使之能够在动态改变的疼痛信号之间做出响应。这些信号，能够反映出外在的驱动力及内在的控制信号的相互作用。&lt;/span&gt;&lt;span&gt;将疼痛作为一种对某种目标（如食物）的抽象符号，也许会成为机器意识情感模型中的某种特性。尽管已经有不少著名的机器意识的模型被提出，但他们在处理人类情感的特性方面仍面临着局限性，而这些特性很有可能在机器人系统及其他相关的即将出现的科技中（为它们）带来情感与意识。这些拥有人类情感的系统将会带来广泛的社会影响力，包括社会认同、信任及可靠性方面的内容。同时，人类本身的局限也将会成为威胁。我们将自己的发展目标局限于发展「机器情感」，这也许会导致人造意识所产生的个性，并不会注重逻辑或是社会认同等积极因素。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本文将回顾一些现有的潜意识模型，并提出了一个高效的机器意识计算模型，它意图融合人的个性及情感。随后，本文将进一步讨论如何使用最新的科技及机器学习中的进展来研发这个高效的计算模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本文的余下部分按照如下内容组织：第二节给出了关于潜意识的背景知识及现有的模型；第三节展示了新提出的模型；第四节对新提出模型的进一步研究方向进行了讨论；第五节总结了全文。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibc6yDDz4kPttFbcs6G6vQKtf8NsPrTP4xnlCj5hVZ5sL0Hr0xh129wAN3bhQAA8yuAic8ibL0EyebA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;物理层面（硬件层面）及超物理层面（软件层面）的差异对比图&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibc6yDDz4kPttFbcs6G6vQKToAibHwtDf9eRw4tJW5ZdBsusF66MpM62oT3r5A0micreQmz07CHGZ3Q/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 2 机器意识与动物之间在处理如「疼痛」、「饥饿」、「疲倦」等情感元素的示意&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibc6yDDz4kPttFbcs6G6vQKyOZqNJiaYicbuwJxdYPzvPhicn58yES7zA0ibZTmk7eib7091cTrIwGw3jg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 7 在机器意识领域使用的机器学习及人工智能概念&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 04 Jan 2017 11:22:02 +0800</pubDate>
    </item>
    <item>
      <title>招聘 | 和旷视(Face++)一起开创人工智能黄金时代！</title>
      <link>http://www.iwgc.cn/link/4193471</link>
      <description>&lt;p&gt;&lt;strong&gt;&lt;span&gt;关于旷视 (Face++)&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;北京旷视科技有限公司 (Face++) 成立于 2011 年，是一家以计算机视觉为核心的人工智能企业，致力于为企业级用户和开发者提供全方位的行业智能解决方案和智能数据服务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;旷视 (Face++) 以智能云和智能互联为产品核心，深耕移动互联网、金融、安防、地产、机器人等多个行业，如今已成为人脸识别领域最具有影响力的品牌。截至 2016 年 12 月，旷视的 FaceID 产品已为全球 1.12 亿人完成了在线实名验证服务；且在公共安全领域实现了全国 25 省业务覆盖，累积协助公安破获各类案件超过 500 起，同时为 276 个园区、企业提供日均 124.9 万次人员出入通行管理数据服务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;工作在旷视&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8Mskm4jqawnibY3Hsk8TxIuRkbq4gztZyqF2GATibW0gicC4jPBlpeU4ffg/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8MqAwu6DtQ7hBh8OBibUSTI41iaYIDA9oZFoAfcB15iaO5LS3DdkxgV5Rgg/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8MmENFa3iaxdM54VsSiccBUq9HcySpOcNoYVy7uZUG7Thq2661XVpry2ew/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8MVoJMbGibGY07BBCOywwbCaS2IWwwTyctpmHZia04Vnwq01uaLUHX8gFA/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;团队情况&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;旷视的核心团队由来自清华大学、美国哥伦比亚大学、微软亚洲研究院等国际顶级院校、科研机构的技术极客，与来自谷歌、阿里巴巴、华为、微软等跨国企业的一流产品、商务人员组成，累计获得国际人工智能技术评测冠军 10 余项，获得国家、国际级信息学金奖人员超过 70 人次，产出国家、国际级发明专利超过 300 件。此外，旷视曾多次代表行业领先技术提供方参与多个人工智能国家及行业标准制定。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;热招岗位：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;算法研究员 、算法软件开发工程师&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;工作地点：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;北京&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;具体岗位要求&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1.算法研究员&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;岗位职责&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;推进计算机视觉和深度学习领域的核心算法；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;构建计算机视觉或深度学习领域的关键应用；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;将最好的算法在有趣有用的商业场景中落地。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;希望你具备&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="list-style-type: decimal;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;扎实的编程基础；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;有很强的自学能力和独立思考能力，善于思考和表达自己的想法；同时又具备良好的团队合作精神；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;使用过 Caffe，TensorFlow，MXNet，Torch，Theano 等开源深度学习框架优先；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;有深度模型训练、图像分类、物体检测与分割、文本分析与识别、视频分析、三维重建、计算摄影学、计算机图形学等相关科研经历者（例如顶级会议第一作者）优先。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2.算法软件开发工程师&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;岗位职责&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;与算法研发员一起工作，提出、实现、改进和测试算法；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;将算法运行在不同平台（例如手机客户端、云计算平台或服务器等），负责相关算法 SDK 的开发、优化和维护；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;针对要解决的应用问题搭建系统、设计方案、性能调优、与产品对接。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;希望你具备&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="list-style-type: decimal;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;扎实的编程基础，具有良好代码质量；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;有很强的自学能力和独立思考能力，善于思考和表达自己的想法；同时又具备良好的团队合作精神；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;了解软件工程的流程，有较好的系统设计和软件架构能力优先；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;有计算机视觉、深度学习、机器学习工程项目经历优先。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投递简历：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;career@megvii.com&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其他在招岗位请点击【阅读原文】查看&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 04 Jan 2017 11:22:02 +0800</pubDate>
    </item>
    <item>
      <title>机器学习初学者入门实践：怎样轻松创造高精度分类网络</title>
      <link>http://www.iwgc.cn/link/4179109</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Github&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是一个为没有人工智能背景的程序员提供的机器学习上手指南。使用神经网络不需要博士学位，你也不需要成为实现人工智能下一个突破的人，你只需要使用现有的技术就行了——毕竟我们现在已经实现的东西已经很突破了，而且还非常有用。我认为我们越来越多的人将会和机器学习打交道就像我们之前越来越多地使用开源技术一样——而不再仅仅将其看作是一个研究主题。在这份指南中，我们的目标是编写一个可以进行高准确度预测的程序——仅使用图像本身来分辨 data/untrained-samples 中程序未见过的样本图像中是海豚还是海马。下面是两张图像样本：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8M105rSLT1BfsDJJO4eiaDwWQEiamkGmCPtQskHiceq32SmeXePf7Rdc0gA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8McfumnibfyFuzWxEmzpcOx2V3czsiajEFDtbA2Luia0nWicvHcGObuBOshw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了实现我们的目标，我们将训练和应用一个卷积神经网络（CNN）。我们将从实践的角度来接近我们的目标，而不是阐释其基本原理。目前人们对人工智能有很大的热情，但其中很多都更像是让物理学教授来教你自行车技巧，而不是让公园里你的朋友来教你。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为此，我（GitHub 用户 humphd/David Humphrey）决定在 GitHub 上写下我的指南，而不是直接发在博客上，因为我知道我下面的写的一切可能会有些误导、天真或错误。我目前仍在自学，我发现现在还很缺乏可靠的初学者文档。如果你觉得文章有错误或缺失了某些重要的细节，请发送一个 pull 请求。下面就让我教你「自行车的技巧」吧！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;指南地址：https://github.com/humphd&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;概述&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们将在这里探索以下内容：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;设置和使用已有的、开源的机器学习技术，尤其是 Caffe 和 DIDITS&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;创建一个图像数据集&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;从头开始训练一个神经网络&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在我们的神经网络从未见过的图像上对其进行测试&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;通过微调已有的神经网络（AlexNet 和 GoogLeNet）来提升我们的神经网络的准确度&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;部署和使用我们的神经网络&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：我知道你说过我们不会谈论神经网络理论，但我觉得在我们开始动手之前至少应该来一点总体概述。我们应该从哪里开始？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于神经网络的理论问题，你能在网上找到海量的介绍文章——从短帖子到长篇论述到在线课程。根据你喜欢的学习形式，这里推荐了三个比较好的起点选择：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;J Alammar 的博客《A Visual and Interactive Guide to the Basics of Neural Networks》非常赞，使用直观的案例介绍了神经网络的概念：https://jalammar.github.io/visual-interactive-guide-basics-neural-networks/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Brandon Rohrer 的这个视频是非常好的卷积神经网络介绍：https://www.youtube.com/watch?v=FmpDIaiMIeA&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如果你想了解更多理论上的知识，我推荐 Michael Nielsen 的在线书籍《Neural Networks and Deep Learning》：http://neuralnetworksanddeeplearning.com/index.html&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;设置&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;安装 Caffe&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Caffe 地址：http://caffe.berkeleyvision.org/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先，我们要使用来自伯克利视觉和学习中心（Berkely Vision and Learning Center）的 Caffe 深度学习框架（BSD 授权）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;问：稍等一下，为什么选择 Caffe？为什么不选现在人人都在谈论的 TensorFlow？&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;没错，我们有很多选择，你也应该了解一下所有的选项。TensorFlow 确实很棒，你也应该试一试。但是这里选择 Caffe 是基于以下原因：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;这是为计算机视觉问题定制的&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;支持 C++ 和 Python（即将支持 node.js：https://github.com/silklabs/node-caffe）(https://github.com/silklabs/node-caffe%EF%BC%89)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;快速且稳定&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是我选择 Caffe 的头号原因是不需要写任何代码就能使用它。你可以声明性地完成所有工作（Caffe 使用结构化的文本文件来定义网络架构），并且也可以使用命令行工具。另外，你也可以为 Caffe 使用一些漂亮的前端，这能让你的训练和验证过程简单很多。基于同样的原因，下面我们会选择 NVIDIA 的 DIGITS。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Caffe 的安装有点麻烦。这里有不同平台的安装说明，包括一些预构建的 Docker 或 AWS 配置：http://caffe.berkeleyvision.org/installation.html&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;注：当我在进行练习的时候，我使用了来自 GitHub 的尚未发布的 Caffe 版本：https://github.com/BVLC/caffe/commit/5a201dd960840c319cefd9fa9e2a40d2c76ddd73&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 Mac 要配置成功则难得多，这个版本有一些版本问题会在不同的步骤终止你的进度。我用了好几天时间来试错，我看了十几个指南，每一个都有一些不同的问题。最后发现这个最为接近：https://gist.github.com/doctorpangloss/f8463bddce2a91b949639522ea1dcbe4。另外我还推荐：https://eddiesmo.wordpress.com/2016/12/20/how-to-set-up-caffe-environment-and-pycaffe-on-os-x-10-12-sierra/，这篇文章比较新而且链接了许多类似的讨论。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;到目前为止，安装 Caffe 就是我们做的最难的事情，这相当不错，因为你可能原来还以为人工智能方面会更难呢！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果安装遇到问题请不要放弃，痛苦是值得的。如果我会再来一次，我可能会使用一个 Ubuntu 虚拟机，而不是直接在 Mac 上安装。如果你有问题要问，可以到 Caffe 用户讨论组：https://groups.google.com/forum/#!forum/caffe-users&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：我需要一个强大的硬件来训练神经网络吗？要是我没法获取一个强大的 GPU 怎么办？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;是的，深度神经网络确实需要大量的算力和能量……但那是在从头开始训练并且使用了巨型数据集的情况。我们不需要那么做。我们可以使用一个预训练好的网络（其它人已经为其投入了数百小时的计算和训练），然后根据你的特定数据进行微调即可。我们后面会介绍如何实现这一目标，但首先我要向你说明：后面的一切工作都是在一台没有强大 GPU 的一年前的 MacBook 上完成的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外说明一点，因为我有一块集成英特尔显卡，而不是英伟达的 GPU，所以我决定使用 OpenCL Caffe 分支：https://github.com/BVLC/caffe/tree/opencl，它在我的笔记本电脑上效果良好！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当你安装完 Caffe 之后，你应该有或能够做下列事情：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;一个包含了你构建的 Caffe 的目录。如果你是按标准方式做的，应该会有一个 build/ 目录包含了运行 Caffe 所需的一切、捆绑的 Python 等等，build/ 的父目录将是你的 CAFFE_ROOT（后面我们会用到它）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;运行 make test &amp;amp;&amp;amp; make runtest，应该会通过&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;安装了所有的 Python 依赖包之后（在 python/ 中执行 for req in $(cat requirements.txt); do pip install $req; done；运行 make pycaffe &amp;amp;&amp;amp; make pytest 应该会通过&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;你也应该运行 make distribute 以在 distribute/ 中创建一个带有所有必要的头文件、二进制文件等的可分发的 Caffe 版本&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在我的机器上，Caffe 完全构建后，我的 CAFFE_ROOT 目录有以下基本布局：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;caffe/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;build/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;python/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;lib/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;tools/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;caffe ← this is our main binary&amp;nbsp;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;distribute/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;python/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;lib/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;include/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;bin/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;proto/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;到现在，我们有了训练、测试和编程神经网络所需的一切。下一节我们会为 Caffe 增加一个用户友好的基于网页的前端 DIGITS，这能让我们对网络的训练和测试变得更加简单。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;安装 DIGITS&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;DIGITS 地址：https://github.com/NVIDIA/DIGITS&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;英伟达的深度学习 GPU 训练系统（Deep Learning GPU Training System/DIGITS）是一个用于训练神经网络的 BSD 授权的 Python 网页应用。尽管我们可以在 Caffe 中用命令行或代码做到 DIGITS 所能做到的一切，但使用 DIGITS 能让我们的工作变得更加简单。而且因为 DIGITS 有很好的可视化、实时图表等图形功能，我觉得使用它也能更有乐趣。因为你正在尝试和探索学习，所以我强烈推荐你从 DIGITS 开始。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 https://github.com/NVIDIA/DIGITS/tree/master/docs 有一些非常好的文档，包括一些安装、配置和启动的页面。我强烈建议你在继续之前通读一下。我并不是一个使用 DIGITS 的专家，如果有问题可以在公开的 DIGITS 用户组查询或询问：https://groups.google.com/forum/#!forum/digits-users&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;安装 DIGITS 的方式有很多种，从 Docker 到 Linux 上的 pre-baked package，或者你也可以从源代码构建。我用的 Mac，所以我就是从源代码构建的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;注：在我的实践中，我使用了 GitHub 上未发布的 DIGITS 版本：https://github.com/NVIDIA/DIGITS/commit/81be5131821ade454eb47352477015d7c09753d9&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因为 DIGITS 只是一些 Python 脚本，所以让它们工作起来很简单。在启动服务器之前你要做的事情是设置一个环境变量，告诉 DIGITS 你的 CAFFE_ROOT 的位置在哪里：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;export CAFFE_ROOT=/path/to/caffe&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;./digits-devserver&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;注：在 Mac 上，这些服务器脚本出现了一些问题，可能是因为我的 Python 二进制文件叫做 python2，其中我只有 python2.7。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你可以在 /usr/bin 中 symlink 它或在你的系统上修改 DIGITS 启动脚本以使用合适的二进制文件。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一旦服务器启动，你可以在你的浏览器中通过 http://localhost:5000 来完成一切后续工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;训练一个神经网络&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;训练神经网络涉及到几个步骤：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 准备一个带有分类图像的数据集&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 定义网络架构&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 使用准备好的数据集训练和验证这个网络&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面我们会做这三个步骤，以体现从头开始和使用预训练的网络之间的差异，同时也展示如何使用 Caffe 和 DIGITS 上最常用的两个预训练的网络 AlexNet、 GoogLeNet。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于我们的训练，我们将使用一个海豚（Dolphins）和海马（Seahorses）图像的小数据集。这些图像放置在 data/dolphins-and-seahorses。你至少需要两个类别，可以更多（有些我们将使用的网络在 1000 多个类别上进行了训练）。我们的目标是：给我们的网络展示一张图像，它能告诉我们图像中的是海豚还是海马。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;准备数据集&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;dolphins-and-seahorses/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;dolphin/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;image_0001.jpg&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;image_0002.jpg&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;image_0003.jpg&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;...&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;seahorse/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;image_0001.jpg&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;image_0002.jpg&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;image_0003.jpg&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&amp;nbsp;...&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最简单的开始方式就是将你的图片按不同类别建立目录：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在上图中的每一个目录都是按将要分类的类别建立的，所建文件夹目录下是将以用于训练和验证的图片。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：所有待分类和验证的图片必须是同样大小吗？文件夹的命名有影响吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;回答都是「否」。图片的大小会在图片输入神经网络之前进行规范化处理，我们最终需要的图片大小为 256×256 像素的彩色图片，但是 DIGITS 可以很快地自动裁切或缩放（我们采用缩放）我们的图像。文件夹的命名没有任何影响——重要的是其所包含的图片种类。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：我能对这些类别做更精细的区分吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然可以。详见 https://github.com/NVIDIA/DIGITS/blob/digits-4.0/docs/ImageFolderFormat.md。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们要用这些图片来创建一个新的数据集，准确的说是一个分类数据集（Classification Dataset）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8MY1HgtW6jENNiaibicxwvZSvzupCpeVDewVcS5bIF2AgtLNPZoMLHdJ32w/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们会使用 DIGITS 的默认设置，并把我们的训练图片文件路径设置到 data/dolphins-and-seahorses 文件夹。如此一来，DIGITS 将会使用这些标签（dolphin 和 seahorse）来创建一个图像缩放过的数据集——图片的大小将会是 256×256，其中 75% 的为训练图片，25% 的为测试图片。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;给你的数据集起一个名字，如 dolphins-and-seahorses，然后鼠标点击创建（Create）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8MXbiclBUec8a5cYGGT1Abv3j52orMJHgXJoM8Hbuk0c5VEecibxMZHpgQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过上面的步骤我们已经创建了一个数据集了，在我的笔记本上只需要 4 秒就可以完成。最终在所建的数据集里有 2 个类别的 92 张训练图片（其中 49 张 dolphin，43 张 seahorse），另外还有 30 张验证图片（16 张 dolphin 和 14 张 seahorse）。不得不说这的确是一个非常小的数据集，但是对我们的示范试验和 DIGITS 操作学习来说已经足够了，因为这样网络的训练和验证就不会用掉太长的时间了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你可以在这个数据库文件夹里查看压缩之后的图片。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8Mzl6VFp6ib3y8WnaDPCfpWDrbNnHyMjJ2vZgSGmcc9YRicBun17DYKFIg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;训练尝试 1：从头开始&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;回到 DIGITS 的主页，我们需要创建一个新的分类模型（Classification Model）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8MRnf8rhpGfO7zWdgzOBibK3ddRia27ibQlqO0E3lDpiaWsUIKwY9Uibraodg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们将开始用上一步所建立的 dolphins-and-seahorses 数据集来训练模型，仍然使用 DIGITS 的默认设置。对于第一个神经网络模型，我们可以从提供的神经网络架构中选取一个既有的标准模型，即 AlexNet。AlexNet 的网络结构在 2012 年的计算机视觉竞赛 ImageNet 中获胜过（ImageNet 为计算机视觉顶级比赛）。在 ImageNet 竞赛里需要完成 120 万张图片中 1000 多类图片的分类。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8M9Zqj3EHbvA0WVfsu6U7ibQibdlURPazWqZLQ2OgBbRVqWhpr39XNdlpg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Caffe 使用结构化文本文件（structured text files）来定义网络架构，其所使用的文本文件是基于谷歌的 Protocol Buffer。你可以阅读 Caffe 采用的方案：https://github.com/BVLC/caffe/blob/master/src/caffe/proto/caffe.proto。其中大部分内容在这一部分的神经网络训练的时候都不会用到，但是了解这些构架对于使用者还是很有用的，因为在后面的步骤里我们将会对它们进行调整。AlexNet 的 prototxt 文件是这样的，一个实例： https://github.com/BVLC/caffe/blob/master/models/bvlc_alexnet/train_val.prototxt。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们将会对这个神经网络进行 30 次 epochs，这意味着网络将会进行学习（运用我们的训练图片）并自行测试（运用我们的测试图片），然后根据训练的结果调整网络中各项参数的权重值，如此重复 30 次。每一次 epoch 都会输出一个分类准确值（Accuracy，介于 0% 到 100% 之间，当然值越大越好）和一个损失度（Loss，所有错误分类的比率，值越小越好）。理想的情况是我们希望所训练的网络能够有较高的准确率（Accuracy）和较小的损失度（Loss）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;初始训练的时候，所训练网络的准确率低于 50%。这是情理之中的，因为第一次 epoch，网络只是在随意猜测图片的类别然后任意设置权重值。经过多次 epochs 之后，最后能够有 87.5% 的准确率，和 0.37 的损失度。完成 30 次的 epochs 只需不到 6 分钟的时间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8Mym2wHnhU0kR7XTE0qHWib4RNhjtBbia9n1f2b1bPZGKZBFJiaBWqqicL6g/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们可以上传一张图片或者用一个 URL 地址的图片来测试训练完的网络。我们来测试一些出现在我们训练和测试数据集中的图片：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8MKxAmcyqlGfHZSSSzMW4WQfEcWcs1XpnX1at779uBbRL9wlwBlxq9uQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8ME5mdcsax7IdAxcy96p0Dl17mvticTq0WgU8s8w8ad5T8iczyks5Tk0jA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;网络的分类结果非常完美，当我们测试一些不属于我们训练和测试数据集的其他图片时：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8M4PaXzhcexmBG2DPKsvylnZ4wvx7PkGWU0DEqdO11axS9sGcEIuGbpQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;分类的准确率直接掉下来了，误把 seahorse 分类为 dolphin，更糟糕的是网络对这样的错误分类有很高的置信度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;事实是我们的数据集太小了，根本无法用来训练一个足够好的神经网络。我们需要数万乃至数百万张图片才能训练一个有用的神经网络，用这么多的图片也意味着需要很强劲的计算能力来完成所有的计算过程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;训练尝试 2：微调 AlexNet&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;怎么微调网络&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从头设计一个神经网络，收集足量的用以训练这个网络的数据（如，海量的图片），并在 GPU 上运行数周来完成网络的训练，这些条件远非我们大多数人可以拥有。能够以更加实际——用较小一些的数据集来进行训练，我们运用一个称为迁移学习（Transfer Learning）或者说微调（Fine Tuning）的技术。Fine tuning 借助深度学习网络的输出，运用已训练好的神经网络来完成最初的目标识别。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;试想使用神经网络的过程就好比使用一个双目望远镜看远处的景物。那么当你第一次把双目望远镜放到眼前的时候，你看到的是一片模糊。当你开始调焦的时候，你慢慢可以看出颜色、线、形状，然后最终你可以分辨出鸟的外形，在此之上你进一步调试从而可以识别出鸟的种类。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在一个多层网络中，最开始的几层是用于特征提取的（如，边线），之后的网络层通过这些提取的特征来识别外形「shape」（如，一个轮子，一只眼睛），然后这些输出将会输入到最后的分类层，分类层将会根据之前所有层的特征积累来确定待分类目标的种类（如，判断为猫还是狗）。一个神经网络从像素、线形、眼睛、两只眼睛的确定位置，这样的步骤来一步步确立分类目标的种类（这里是猫）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们在这里所做的就是给新的分类图片指定一个已训练好的网络用于初始化网络的权重值，而不是用新构建网络自己的初始权重。因为已训练好的网络已经具备「看」图片特征的功能的，我们所需要的是这个已训练的网络能「看」我们所建图片数据集——这一具体任务中特定类型的图片。我们不需要从头开始训练大部分的网络层——我们只需要将已训练网络中已经学习的层转接到我们新建的分类任务上来。不同于我们的上一次的实验，在上次实验中网络的初始权重值是随机赋予的，这次实验中我们直接使用已经训练网络的最终权重值作为我们新建网络的初始权重值。但是，必须去除已经训练好的网络的最后分类层并用我们自己的图片数据集再次训练这个网络，即在我们自己的图片类上微调已训练的网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于这次实验，我们需要一个与经由与我们训练数据足够相似的数据集所训练的网络，只有这样已训练网络的权重值才对我们有用。幸运的是，我们下面所使用的网络是在海量数据集（自然图片集 ImageNet）上训练得到的，这样的已训练网络能满足大部分分类任务的需要。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种技术已经被用来做一些很有意思的任务如医学图像的眼疾筛查，从海里收集到的显微图像中识别浮游生物物种，给 Flickr 上的图片进行艺术风格分类。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;完美的完成这些任务，就像所有的机器学习一样，你需要很好的理解数据以及神经网络结构——你必须对数据的过拟合格外小心，你或许需要调整一些层的设置，也很有可能需要插入一些新的网络层，等等类似的调整。但是，我们的经验表明大部分时候还是可以完成任务的「Just work」，而且用我们这么原始的方法去简单尝试一下看看结果如何是很值得的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;上传预训练网络&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在我们的第一次尝试中，我们使用了 AlexNet 的架构，但是网络各层的权重是随机分布的。我们需要做的就是需要下载使用一个已经经过大量数据集训练的 AlexNet。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;AlexNet 的快照（Snapshots）如下，可供下载：https://github.com/BVLC/caffe/tree/master/models/bvlc_alexnet。我们需要一个二进制文件 .caffemodel，含有训练好的权重，可供下载 http://dl.caffe.berkeleyvision.org/bvlc_alexnet.caffemodel。在你下载这些与训练模型的时候，让我们来趁机多学点东西。2014 年的 ImageNet 大赛中，谷歌利用其开源的 GoogLeNet (https://research.google.com/pubs/pub43022.html)（一个 22 层的神经网络）赢得了比赛。GoogLeNet 的快照如下，可供下载： https://github.com/BVLC/caffe/tree/master/models/bvlc_googlenet。在具备了所有的预训练权重之后，我们还需要.caffemodel 文件，可供下载：http://dl.caffe.berkeleyvision.org/bvlc_googlenet.caffemodel&lt;span&gt;.&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有了 .caffemodel 文件之后，我们既可以将它们上传到 DIGITS 当中。在 DIGITS 的主页当中找到预训练模型（Pretrained Models）的标签，选择上传预训练模型（Upload Pretrained Model）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8MHG09h1ZdGlWNuU51icOiaVk9PzicA8hIicR8wlCo1rqEKAYicNMEicx1EFNQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于这些预训练的模型，我们可以使用 DIGITS 的默认值（例如，大小为 256×256 像素的彩色图片）。我们只需要提供 Weights (.caffemodel) 和 Model Definition (original.prototxt)。点击这些按钮来选择文件。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;模型的定义，GoogLeNet 我们可以使用 https://github.com/BVLC/caffe/blob/master/models/bvlc_googlenet/train_val.prototxt，AlexNet 可以使用 https://github.com/BVLC/caffe/blob/master/models/bvlc_alexnet/train_val.prototxt。我们不打算使用这些网络的分类标签，所以我们可以直接添加一个 labels.txt 文件：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8MfibrDes2l5qDkagdHL8FTYOLVyltoNiazwe1WqqQkq8o4E1YfX9yzPJg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 AlexNet 和 GoogLeNet 都重复这一过程，因为我们在之后的步骤当中两者我们都会用到。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问题：有其他的神经网络能作为微调的基础吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;回答：Caffe Model Zoo 有许多其他预训练神经网络可供使用，详情请查看 https://github.com/BVLC/caffe/wiki/Model-Zoo&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使用预训练 Caffe 模型进行人工神经网络训练就类似于从头开始实现，虽然我们只需要做一些调整。首先我们需要将学习速率由 0.01 调整到 0.001，因为我们下降步长不需要这么大（我们会进行微调）。我们还将使用预训练网络（Pretrained Network）并根据实际修改它。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8MxQj98Uhq6XCzjAR9pPTepUVxxibdrWicOKXGYErrpTiaKF81WIzoHuoTw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在预训练模型的定义（如原文本）中，我们需要对最终完全连接层（输出结果分类的地方）的所有 references 重命名。我们这样做是因为我们希望模型能从现在的数据集重新学习新的分类，而不是使用以前最原始的训练数据（我们想将当前最后一层丢弃）。我们必须将最后的全连接层由「fc8」重命名为一些其他的（如 fc9）。最后我们还需要将分类类别从 1000 调整为 2，这里需要调整 num_output 为 2。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面是我们需要做的一些调整代码：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;@@ -332,8 +332,8 @@&lt;/span&gt;
 }
 layer {&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp;name: "fc8"&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp;name: "fc9"&lt;/span&gt;
   type: "InnerProduct"
   bottom: "fc7"&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp;top: "fc8"&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp;top: "fc9"&lt;/span&gt;
   param {
     lr_mult: 1&lt;span&gt;@@ -345,5 +345,5 @@&lt;/span&gt;
   }
   inner_product_param {&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp; &amp;nbsp;num_output: 1000&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp; &amp;nbsp;num_output: 2&lt;/span&gt;
     weight_filler {
       type: "gaussian"&lt;span&gt;@@ -359,5 +359,5 @@&lt;/span&gt;
   name: "accuracy"
   type: "Accuracy"&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp;bottom: "fc8"&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp;bottom: "fc9"&lt;/span&gt;
   bottom: "label"
   top: "accuracy"&lt;span&gt;@@ -367,5 +367,5 @@&lt;/span&gt;
   name: "loss"
   type: "SoftmaxWithLoss"&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp;bottom: "fc8"&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp;bottom: "fc9"&lt;/span&gt;
   bottom: "label"
   top: "loss"&lt;span&gt;@@ -375,5 +375,5 @@&lt;/span&gt;
   name: "softmax"
   type: "Softmax"&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp;bottom: "fc8"&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp;bottom: "fc9"&lt;/span&gt;
   top: "softmax"
   include { stage: "deploy" }&lt;/pre&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我已经将所有的改进文件放在 src/alexnet-customized.prototxt 里面。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这一次，我们的准确率由 60% 多先是上升到 87.5%，然后到 96% 一路到 100%，同时损失度也稳步下降。五分钟后，我们的准确率到达了 100%，损失也只有 0.0009。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8M2VjGABJsyuCDtdZNUB3E2TDRQiael63c4s558PknnZgibSlB5LNSDdaA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;测试海马图像时以前的网络会出错，现在我们看到完全相反的结果，即使是小孩画的海马，系统也 100% 确定是海马，海豚的情况也一样。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8MwsP8X4UI9felfnvB2FptkApHOj9tUjiccd3wPfkeYlTqU7dw8JEKBuA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8MDDcRiaWq9icf9Yia4z6r01XrgBhpSkSxZTrNwNCZyZn9XXfM3PxcdMJZQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8ME7JicVZOHOL4L2katPvsib29KvpuavJBCsCywLY4N14JMQlxqTXP4icfA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;即使你认为可能很困难的图像，如多个海豚挤在一起，并且它们的身体大部分在水下，系统还是能识别。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8MvR2ErERZawZOcFdaDdFcvVpibqgicGsRE2RNftuVAc2tNm06rYE0Ldyw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;训练尝试 3：微调 GoogLeNet&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;像前面我们微调 AlexNet 模型那样，同样我们也能用 GoogLeNet。修改这个网络会有点棘手，因为你已经定义了三层全连接层而不是只有一层。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8MboCrlBN8GmexazlrsYBAlyz9RtxicgxJic92icIY20hftU7fN7oosq3pw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这个案例中微调 GoogLeNet，我们需要再次创建一个新的分类模型：我们需要重命名三个全连接分类层的所有 references，即 loss1/classifier、loss2/classifier 和 loss3/classifier，并重新定义结果类别数（num_output: 2）。下面是我们需要将三个分类层重新命名和从 1000 改变输出类别数为 2 的一些代码实现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;@@ -917,10 +917,10 @@&lt;/span&gt;
   exclude { stage: "deploy" }
 }
 layer {&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp;name: "loss1/classifier"&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp;name: "loss1a/classifier"&lt;/span&gt;
   type: "InnerProduct"
   bottom: "loss1/fc"&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp;top: "loss1/classifier"&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp;top: "loss1a/classifier"&lt;/span&gt;
   param {
     lr_mult: 1
     decay_mult: 1&lt;span&gt;@@ -930,7 +930,7 @@&lt;/span&gt;
     decay_mult: 0
   }
   inner_product_param {&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp; &amp;nbsp;num_output: 1000&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp; &amp;nbsp;num_output: 2&lt;/span&gt;
     weight_filler {
       type: "xavier"
       std: 0.0009765625&lt;span&gt;@@ -945,7 +945,7 @@&lt;/span&gt;
 layer {
   name: "loss1/loss"
   type: "SoftmaxWithLoss"&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp;bottom: "loss1/classifier"&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp;bottom: "loss1a/classifier"&lt;/span&gt;
   bottom: "label"
   top: "loss1/loss"
   loss_weight: 0.3&lt;span&gt;@@ -954,7 +954,7 @@&lt;/span&gt;
 layer {
   name: "loss1/top-1"
   type: "Accuracy"&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp;bottom: "loss1/classifier"&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp;bottom: "loss1a/classifier"&lt;/span&gt;
   bottom: "label"
   top: "loss1/accuracy"
   include { stage: "val" }&lt;span&gt;@@ -962,7 +962,7 @@&lt;/span&gt;
 layer {
   name: "loss1/top-5"
   type: "Accuracy"&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp;bottom: "loss1/classifier"&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp;bottom: "loss1a/classifier"&lt;/span&gt;
   bottom: "label"
   top: "loss1/accuracy-top5"
   include { stage: "val" }&lt;span&gt;@@ -1705,10 +1705,10 @@&lt;/span&gt;
   exclude { stage: "deploy" }
 }
 layer {&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp;name: "loss2/classifier"&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp;name: "loss2a/classifier"&lt;/span&gt;
   type: "InnerProduct"
   bottom: "loss2/fc"&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp;top: "loss2/classifier"&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp;top: "loss2a/classifier"&lt;/span&gt;
   param {
     lr_mult: 1
     decay_mult: 1&lt;span&gt;@@ -1718,7 +1718,7 @@&lt;/span&gt;
     decay_mult: 0
   }
   inner_product_param {&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp; &amp;nbsp;num_output: 1000&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp; &amp;nbsp;num_output: 2&lt;/span&gt;
     weight_filler {
       type: "xavier"
       std: 0.0009765625&lt;span&gt;@@ -1733,7 +1733,7 @@&lt;/span&gt;
 layer {
   name: "loss2/loss"
   type: "SoftmaxWithLoss"&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp;bottom: "loss2/classifier"&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp;bottom: "loss2a/classifier"&lt;/span&gt;
   bottom: "label"
   top: "loss2/loss"
   loss_weight: 0.3&lt;span&gt;@@ -1742,7 +1742,7 @@&lt;/span&gt;
 layer {
   name: "loss2/top-1"
   type: "Accuracy"&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp;bottom: "loss2/classifier"&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp;bottom: "loss2a/classifier"&lt;/span&gt;
   bottom: "label"
   top: "loss2/accuracy"
   include { stage: "val" }&lt;span&gt;@@ -1750,7 +1750,7 @@&lt;/span&gt;
 layer {
   name: "loss2/top-5"
   type: "Accuracy"&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp;bottom: "loss2/classifier"&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp;bottom: "loss2a/classifier"&lt;/span&gt;
   bottom: "label"
   top: "loss2/accuracy-top5"
   include { stage: "val" }&lt;span&gt;@@ -2435,10 +2435,10 @@&lt;/span&gt;
   }
 }
 layer {&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp;name: "loss3/classifier"&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp;name: "loss3a/classifier"&lt;/span&gt;
   type: "InnerProduct"
   bottom: "pool5/7x7_s1"&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp;top: "loss3/classifier"&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp;top: "loss3a/classifier"&lt;/span&gt;
   param {
     lr_mult: 1
     decay_mult: 1&lt;span&gt;@@ -2448,7 +2448,7 @@&lt;/span&gt;
     decay_mult: 0
   }
   inner_product_param {&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp; &amp;nbsp;num_output: 1000&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp; &amp;nbsp;num_output: 2&lt;/span&gt;
     weight_filler {
       type: "xavier"
     }&lt;span&gt;@@ -2461,7 +2461,7 @@&lt;/span&gt;
 layer {
   name: "loss3/loss"
   type: "SoftmaxWithLoss"&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp;bottom: "loss3/classifier"&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp;bottom: "loss3a/classifier"&lt;/span&gt;
   bottom: "label"
   top: "loss"
   loss_weight: 1&lt;span&gt;@@ -2470,7 +2470,7 @@&lt;/span&gt;
 layer {
   name: "loss3/top-1"
   type: "Accuracy"&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp;bottom: "loss3/classifier"&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp;bottom: "loss3a/classifier"&lt;/span&gt;
   bottom: "label"
   top: "accuracy"
   include { stage: "val" }&lt;span&gt;@@ -2478,7 +2478,7 @@&lt;/span&gt;
 layer {
   name: "loss3/top-5"
   type: "Accuracy"&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp;bottom: "loss3/classifier"&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp;bottom: "loss3a/classifier"&lt;/span&gt;
   bottom: "label"
   top: "accuracy-top5"
   include { stage: "val" }&lt;span&gt;@@ -2489,7 +2489,7 @@&lt;/span&gt;
 layer {
   name: "softmax"
   type: "Softmax"&lt;span&gt;&lt;span&gt;-&lt;/span&gt; &amp;nbsp;bottom: "loss3/classifier"&lt;/span&gt;&lt;span&gt;&lt;span&gt;+&lt;/span&gt; &amp;nbsp;bottom: "loss3a/classifier"&lt;/span&gt;
   top: "softmax"
   include { stage: "deploy" }
 }&lt;/pre&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我己经将完整的文件放在 src/googlenet-customized.prototxt 里面。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问题：这些神经网络的原文本（prototext）定义需要做什么修改吗？我们修改了全连接层名和输出结果分类类别数，那么在什么情况下其它参数也能或也需要修改的？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;回答：问得好，这也是我有一些疑惑的地方。例如，我知道我们能「固定」确切的神经网络层级，并保证层级之间的权重不改变。但是要做其它的一些改变就涉及到理解我们的神经网络层级是如何起作用的，这已经超出了这份入门向导的范围，同样也超出了这份向导作者现有的能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;就像我们对 AlexNet 进行微调，将下降的学习速率由 0.01 减少十倍到 0.001 一样。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;问：还有什么修改是对这些网络微调有意义的？遍历所有数据的次数（numbers of epochs）不同怎么样，改变批量梯度下降的大小（batch sizes）怎么样，求解器的类型（Adam、 AdaDelta 和 AdaGrad 等）呢？还有下降学习速率、策略（Exponential Decay、Inverse Decay 和 Sigmoid Decay 等）、步长和 gamma 值呢？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;问得好，这也是我有所疑惑的。我对这些只有一个模糊的理解，如果你知道在训练中如何修改这些值，那么我们很可能做出些改进，并且这需要更好的文档。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因为 GoogLeNet 比 AlexNet 有更复杂的网络构架，所以微调需要更多的时间。在我的笔记本电脑上，用我们的数据集重新训练 GoogLeNet 需要 10 分钟，这样才能实现 100% 的准确率，同时损失函数值只有 0.0070。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8McDVjtX1ayvNm8lQtmKVEicdJdev7GoLdLQOrBAfthqhyKkkHtpp085g/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;正如我们看到的 AlexNet 微调版本，我们修改过的 GoogLeNet 表现得十分惊人，是我们目前最好的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8MgbEicwKcW0E8QjK3EQ72QVdIoJbwePPQwhiaYk1SAUYibv0Iic8yzSAoibw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8MkDU08FiabKsEmYgkGh3zrrfosZ4p0iaUiaZUHAmGkEWHA4Vpibr5VMpwTg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8M7TfanqTgnyzrnVfnLBoDJlmao0ZKjic04BjT7LQuAmSOMsBECeTC9MQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;使用我们的模型&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们的网络在训练和检测之后，就可以下载并且使用了。我们利用 DIGITS 训练的每一个模型都有了一下载模型（Download Model）键，这也是我们在训练过程中选择不同 snapshots 的一种方法（例如 Epoch #30）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8MNB55cvRg1CnkLNjR752MV5N6X4HKAHh5iayWuxoa9pJtticuj77Cd6BA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在点击 Download Model 之后，你就会下载一个 tar.gz 的文档，里面包含以下文件：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;code style=" box-sizing: border-box; ; ; ; ; ; ; ; ; ; ; ; ; ; "&gt;deploy.prototxt
mean.binaryproto
solver.prototxt
info.json
original.prototxt
labels.txt
snapshot_iter_90.caffemodel
train_val.prototxt&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;在 Caffe 文档中对我们所建立的模型使用有一段非常好的描述。如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;一个网络是由其设计，也就是设计（prototxt）和权重（.caffemodel）决定。在网络被训练的过程中，网络权重的当前状态被存储在一个.caffemodel 中。这些东西我们可以从训练/检测阶段移到生产阶段。在它的当前状态中，网络的设计并不是为了部署的目的。在我们可以将我们的网络作为产品发布之前，我们通常需要通过几种方法对它进行修改：&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;1. 移除用来训练的数据层，因为在分类时，我们已经不再为数据提供标签了。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;2. 移除所有依赖于数据标签的层。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;3. 设置接收数据的网络。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;4. 让网络输出结果。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;DIGITS 已经为我们做了这些工作，它已经将我们 prototxt 文件中所有不同的版本都分离了出来。这些文档我们在使用网络时会用到：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;deploy.prototxt -是关于网络的定义，准备接收图像输入数据&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;mean.binaryproto - 我们的模型需要我们减去它处理的每张图像的图像均值，所产生的就是平均图像（mean image）。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;labels.txt - 标签列表 (dolphin, seahorse)，以防我们想要把它们打印出来，否则只有类别编号。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;snapshot_iter_90.caffemodel -这些是我们网络的训练权重。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;利用这些文件，我们可以通过多种方式对新的图像进行分类。例如，在 CAFFE_ROOT 中，我们可以使用 build/examples/cpp_classification/classification.bin 来对一个图像进行分类：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;$ cd $CAFFE_ROOT/build/examples/cpp_classification&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;$ ./classification.bin deploy.prototxt snapshot_iter_90.caffemodel mean.binaryproto labels.txt dolphin1.jpg&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这会产生很多的调试文本，后面会跟着对这两种分类的预测结果：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;0.9997 -「dolphin」&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;0.0003 -「seahorse」&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你可以在这个 Caffe 案例中查看完整的 C++ 源码：https://github.com/BVLC/caffe/tree/master/examples&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使用 Python 界面和 DIGITS 进行分类的案例：https://github.com/NVIDIA/DIGITS/tree/master/examples/classification&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，Caffe 的案例中还有一个非常好的 Python 演示：https://github.com/BVLC/caffe/blob/master/examples/00-classification.ipynb&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我希望可以有更多更好的代码案例、API 和预先建立的模型等呈现给大家。老实说，我找到的大多数代码案例都非常的简短，并且文档介绍很少——Caffe 的文档虽然有很多，但也有好有坏。对我来说，这似乎意味着会有人为初学者建立比 Caffe 更高级的工具。如果说在高级语言中出现了更加简单的模型，我可以用我们的模型「做正确的事情」；应该有人将这样的设想付诸行动，让使用 Caffe 模型变得像使用 DIGITS 训练它们一样简单。当然我们不需要对这个模型或是 Caffe 的内部了解那么多。虽然目前我还没有使用过 DeepDetect，但是它看起来非常的有趣，另外仍然还有其他我不知道的工具。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;结果&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;文章开头提到，我们的目标是编写一个使用神经网络对 data/untrained-samples 中所有的图像进行高准确度预测的程序。这些海豚和海马的图像是在训练数据或是验证数据时候从未使用过的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;未被训练过的海豚图像&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8M105rSLT1BfsDJJO4eiaDwWQEiamkGmCPtQskHiceq32SmeXePf7Rdc0gA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8Mx8rQzvwricOzO4ibS62RGTuU20WL9HhIh0kK5XibZWVjvV6DBhe3jabqg/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8MOiaC8thCPvY1eNhYfnhVIDX8pqvUmVvHHAciafqBmJRSe83aH4P0iasHQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;未被训练过的海马图像&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8McfumnibfyFuzWxEmzpcOx2V3czsiajEFDtbA2Luia0nWicvHcGObuBOshw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8M8icCODwPZc2tBL6YWjMsicJldpOwOw0Iiarl3Fht2suNo8YtbFKRLuDLQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8MncqtxTlqxdwPaLxBUHJOEW9mZVsp6XAZ3vPugjCN31LzTNI60ZWK6Q/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;接下来，让我们一起来看看在这一挑战当中存在的三次尝试的结果：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;模型尝试 1： 从零开始构建 AlexNet（第 3 位）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;table width="888" style="width: 737px;"&gt;&lt;thead style="box-sizing: border-box;"&gt;&lt;tr style="box-sizing: border-box; background-color: rgb(255, 255, 255); border-top: 1px solid rgb(204, 204, 204);"&gt;&lt;th style="box-sizing: border-box; padding: 6px 13px; border-top-width: 1px; border-top-color: rgb(221, 221, 221);"&gt;Image&lt;/th&gt;&lt;th style="box-sizing: border-box; padding: 6px 13px; border-top-width: 1px; border-top-color: rgb(221, 221, 221);"&gt;Dolphin&lt;/th&gt;&lt;th style="box-sizing: border-box; padding: 6px 13px; border-top-width: 1px; border-top-color: rgb(221, 221, 221);"&gt;Seahorse&lt;/th&gt;&lt;th style="box-sizing: border-box; padding: 6px 13px; border-top-width: 1px; border-top-color: rgb(221, 221, 221);"&gt;Result&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody style="box-sizing: border-box;"&gt;&lt;tr style="box-sizing: border-box; background-color: rgb(255, 255, 255); border-top: 1px solid rgb(204, 204, 204);"&gt;&lt;td style="box-sizing: border-box; padding: 6px 13px;"&gt;&lt;a style="box-sizing: border-box; background-color: transparent; color: rgb(64, 120, 192);"&gt;dolphin1.jpg&lt;/a&gt;&lt;/td&gt;&lt;td style="box-sizing: border-box; padding: 6px 13px;"&gt;71.11%&lt;/td&gt;&lt;td style="box-sizing: border-box; padding: 6px 13px;"&gt;28.89%&lt;/td&gt;&lt;td style="box-sizing: border-box; padding: 6px 13px;"&gt;&lt;g-emoji alias="expressionless" fallback-src="https://assets-cdn.github.com/images/icons/emoji/unicode/1f611.png" ios-version="6.0" style=" box-sizing: border-box ; ; ; ; ; ; ; ;; font-size: 18px; line-height: 20px; vertical-align: middle; "&gt;</description>
      <pubDate>Tue, 03 Jan 2017 13:30:23 +0800</pubDate>
    </item>
    <item>
      <title>资源 | NIPS 2016上22篇论文的实现汇集</title>
      <link>http://www.iwgc.cn/link/4179110</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自niut-blanche&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;日前，LightOn CEO 兼联合创始人 Igor Carron 在其博客上放出了其收集到的 NIPS 2016 论文的实现（一共 22 个）。他写道：「在 Reddit 上，peterkuharvarduk 决定编译所有来自 NIPS 2016 的可用实现，我很高兴他使用了『实现（ implementation）』这个词，因为这让我可以快速搜索到这些项目。」除了 peterkuharvarduk 的推荐，这里的项目还包括 Reddit 其他用户和 Carron 额外添加的一些新公布的实现。最终他还重点推荐了 GitXiv：http://www.gitxiv.com 。另外，在本文后面还附带了机器之心关于 NIPS 2016 的文章列表，千万不要错过。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;1. 使用快速权重关注最近的过去（Using Fast Weights to Attend to the Recent Past）&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：https://arxiv.org/abs/1610.06258&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GitHub：https://github.com/ajarai/fast-weights&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;2. 通过梯度下降来学习通过梯度下降的学习（Learning to learn by gradient descent by gradient descent）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：https://arxiv.org/abs/1606.04474&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GitHub：https://github.com/deepmind/learning-to-learn&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;3. R-FCN：通过基于区域的全卷积网络的目标检测（R-FCN: Object Detection via Region-based Fully Convolutional Networks）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：https://arxiv.org/abs/1605.06409&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GitHub：https://github.com/Orpine/py-R-FCN&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4. 用于 k-均值的快速和可证明的 Good Seedings（Fast and Provably Good Seedings for k-Means）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：https://las.inf.ethz.ch/files/bachem16fast.pdf.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GitHub：https://github.com/obachem/kmc2&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;5. 如何训练生成对抗网络（How to Train a GAN）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GitHub：https://github.com/soumith/ganhacks&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;6. Phased LSTM：为长的或基于事件的序列加速循环网络训练（Phased LSTM: Accelerating Recurrent Network Training for Long or Event-based Sequences）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：https://arxiv.org/abs/1610.09513&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GitHub: https://github.com/dannyneil/public_plstm&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;7. 生成对抗式模仿学习（Generative Adversarial Imitation Learning）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：https://arxiv.org/abs/1606.03476&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GitHub：https://github.com/openai/imitation&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;8. 对抗式多类分类：一个风险最小化的角度（Adversarial Multiclass Classification: A Risk Minimization Perspective）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：https://www.cs.uic.edu/~rfathony/pdf/fathony2016adversarial.pdf&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GitHub：https://github.com/rizalzaf/adversarial-multiclass&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;9. 通过视频预测的用于物理交互的无监督学习（Unsupervised Learning for Physical Interaction through Video Prediction）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：https://arxiv.org/abs/1605.07157&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GitHub: https://github.com/tensorflow/models/tree/master/video_prediction&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;10.权重规范化：一种加速深度神经网络训练的简单重新参数化（ Weight Normalization: A Simple Reparameterization to Accelerate Training of Deep Neural Networks）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：https://arxiv.org/abs/1602.07868&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GitHub：https://github.com/openai/weightnorm&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;11. 全容量整体循环神经网络（Full-Capacity Unitary Recurrent Neural Networks）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：https://arxiv.org/abs/1611.00035&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GitHub：https://github.com/stwisdom/urnn&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;12. 带有随机层的序列神经模型（Sequential Neural Models with Stochastic Layers）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：https://arxiv.org/pdf/1605.07571.pdf&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GitHub：https://github.com/marcofraccaro/srnn&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;13. 带有快速局部化谱过滤的图上的卷积神经网络（Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：https://arxiv.org/abs/1606.09375&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GitHub：https://github.com/mdeff/cnn_graph&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;14. Interpretable Distribution Features with Maximum Testing Power&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：https://papers.nips.cc/paper/6148-interpretable-distribution-features-with-maximum-testing-power.pdf&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GitHub：https://github.com/wittawatj/interpretable-test/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;15. 使用神经网络组成图模型，用于结构化表征和快速推理(Composing graphical models with neural networks for structured representations and fast inference )&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：https://arxiv.org/abs/1603.06277&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GitHub：https://github.com/mattjj/svae&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;16. 使用张量网络的监督学习（Supervised Learning with Tensor Networks）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：https://arxiv.org/abs/1605.05775&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GitHub：https://github.com/emstoudenmire/TNML&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;17. 使用贝叶斯条件密度估计的模拟模型的快速无ε推理（Fast ε-free Inference of Simulation Models with Bayesian Conditional Density Estimation）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：https://arxiv.org/abs/1605.06376&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GitHub：https://github.com/gpapamak/epsilon_free_inference&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;18. 用于概率程序的贝叶斯优化（Bayesian Optimization for Probabilistic Programs）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：http://www.robots.ox.ac.uk/~twgr/assets/pdf/rainforth2016BOPP.pdf&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GitHub：https://github.com/probprog/bopp&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;19. PVANet：用于实施目标检测的轻权重深度神经网络（PVANet: Lightweight Deep Neural Networks for Real-time Object Detection）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：https://arxiv.org/abs/1611.08588&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GitHub：https://github.com/sanghoon/pva-faster-rcnn&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;20. 数据编程：快速创建大训练集（Data Programming: Creating Large Training Sets Quickly）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：https://arxiv.org/abs/1605.07723&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;代码： snorkel.stanford.edu&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;21. 用于架构学习的卷积神经结构（Convolutional Neural Fabrics for Architecture Learning）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：https://arxiv.org/pdf/1606.02492.pdf&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GitHub：https://github.com/shreyassaxena/convolutional-neural-fabrics&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;22. 价值迭代网络（Value Iteration Networks）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;论文：https://arxiv.org/abs/1602.02867&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;TensorFlow 实现：https://github.com/TheAbhiKumar/tensorflow-value-iteration-networks&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;原作者的 Theano 实现：https://github.com/avivt/VIN&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;blockquote&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;机器之心 NIPS 2016 文章列表&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721406&amp;amp;idx=1&amp;amp;sn=8251dfebd3c360d180339c34c4710fa7&amp;amp;chksm=871b0800b06c81160244fcda78d7816da8ec31d5fbec546ba6e36241e6d32c0ca943ce9ce73d&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721406&amp;amp;idx=1&amp;amp;sn=8251dfebd3c360d180339c34c4710fa7&amp;amp;chksm=871b0800b06c81160244fcda78d7816da8ec31d5fbec546ba6e36241e6d32c0ca943ce9ce73d&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;"&gt;&lt;span&gt;深度 | NIPS 2016最全盘点：主题详解、前沿论文及下载资源（附会场趣闻）&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721081&amp;amp;idx=1&amp;amp;sn=d557968703d4af879b5cf6461069dacd&amp;amp;chksm=871b0f47b06c865185865fcd5ef92af7726e84ae9e689b7ced9986a08c9fe3113df296a8469a&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;"&gt;&lt;span&gt;独家 | 吴恩达 NIPS 2016 演讲现场直击：如何使用深度学习开发人工智能应用？&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721198&amp;amp;idx=1&amp;amp;sn=accdd701751ab9678285f3cdf073304f&amp;amp;chksm=871b0fd0b06c86c6fa49bbae856898920e26c4456bc02be42a947d23fe2b593110e911bf54da&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;"&gt;&lt;span&gt;独家 | 机器之心对话 NIPS 2016 最佳论文作者：如何打造新型强化学习观？&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721284&amp;amp;idx=1&amp;amp;sn=427e7f45c8253ab22a3960978409f5d1&amp;amp;chksm=871b087ab06c816c424ad03810be3e1b3aa9d6e99a5f325047796f110d178a07736f667d1a10&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;"&gt;&lt;span&gt;独家 | GAN 之父 NIPS 2016 演讲现场直击：全方位解读生成对抗网络的原理及未来&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721325&amp;amp;idx=4&amp;amp;sn=d570f04d737d09c1b1cebd962755af3f&amp;amp;chksm=871b0853b06c8145985f8c2c5ac7445118f18ce35532c0389b0e5ec24a7a1c4b841fe81280de&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;"&gt;&lt;span&gt;资源 | Bengio 和 LeCun 在 NIPS 2016 上的演讲&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718527&amp;amp;idx=2&amp;amp;sn=8d054db2eca7a0b25190a6cc050fc1d7&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;"&gt;&lt;span&gt;学界 | NIPS 2016 公布 571 篇接收论文&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721033&amp;amp;idx=2&amp;amp;sn=d0d143e72cf4a637a617be356008b323&amp;amp;chksm=871b0f77b06c86615ed6a59ede1bee6cbff68b6ec08fb9b300e347d9c34b931aabdc3d0fee4e&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;"&gt;&lt;span&gt;学界 | NIPS 2016 论文 SpotlightVideo 精选，三分钟了解一项最新研究进展&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721081&amp;amp;idx=3&amp;amp;sn=111d844d50c98582695d04fa2b252c89&amp;amp;chksm=871b0f47b06c86514ac934c44fe4df92f5d4209f209b94b4c89d1f138492dbaf7e47479803a3&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;"&gt;&lt;span&gt;学界 | NIPS 2016 现场：谷歌发布 28 篇机器学习论文&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720969&amp;amp;idx=2&amp;amp;sn=d1fae404486906125e01b5def7e26d94&amp;amp;chksm=871b0eb7b06c87a1d3e7d0b29e8c8f9e4c86f4949d04b0485df1b45823555a6c88a25ccf4dc4&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;"&gt;&lt;span&gt;学界 | DeepMind NIPS 2016 论文盘点（Part1）：强化学习正大步向前&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721102&amp;amp;idx=2&amp;amp;sn=cbc44a149457d31ed9a8bbe825f09378&amp;amp;chksm=871b0f30b06c8626bb94cbd7a08fd4a5c8bec747082f49280fbd27e9c87c965de983a279796c&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;"&gt;&lt;span&gt;学界 | DeepMind NIPS 2016 论文盘点（Part2）：无监督学习的新进展&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721081&amp;amp;idx=4&amp;amp;sn=af93b221818ff9f564b372de5fc1958f&amp;amp;chksm=871b0f47b06c8651744e4b2819322f4026b248f4474f619c7248f604dafe8490405d70d3d1f3&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;"&gt;&lt;span&gt;业界 | NIPS 2016 现场：LeCun 联同英伟达，推深度学习教学工具包&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721198&amp;amp;idx=4&amp;amp;sn=b2f6412538b2458116cd40f53bcdc23b&amp;amp;chksm=871b0fd0b06c86c6866c3e682aa9a15187154a67ae4b7df3d319cc2233fb5761c53da45abed1&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;"&gt;&lt;span&gt;业界 | 波士顿动力最新机器人亮相 NIPS 2016，但还未用到机器学习&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 03 Jan 2017 13:30:23 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 日本保险公司引入IBM Watson，这次人工智能代替了34名白领</title>
      <link>http://www.iwgc.cn/link/4179113</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Quartz&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李泽南、蒋思源&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWibu5UenPACiaQdmuAzZOXk8MZjFajRSpffAMibVU4akH0O7ibib7ibkexkK6TRxibHO773lPovySFQrnznw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在人们对于自动化的大部分注意力正集中在工业机器人、自动驾驶汽车等领域，很多学者们认为它们将从根本上改变劳动力的形式，有可能会代替数百万现有低技术工作岗位，一些国家的政府已经在为此&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721644&amp;amp;idx=1&amp;amp;sn=bfb26761cf5d118d4ed1dbafd04319f4&amp;amp;chksm=871b0912b06c8004ce420b78d657b9eee138c0e2990100ecfd759925804a0d248189b6014ba8&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721644&amp;amp;idx=1&amp;amp;sn=bfb26761cf5d118d4ed1dbafd04319f4&amp;amp;chksm=871b0912b06c8004ce420b78d657b9eee138c0e2990100ecfd759925804a0d248189b6014ba8&amp;amp;scene=21#wechat_redirect"&gt;制定政策&lt;/a&gt;。但对于人工智能而言，需要知识背景的白领工作似乎更加容易，在机器人客服、&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720780&amp;amp;idx=2&amp;amp;sn=cc64372d82354d3212baf84fce230928&amp;amp;chksm=871b0e72b06c8764cfe09654fa457da0fd764c0684d83b7fcd887c19401b3b4d623a07ab2bb9&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720780&amp;amp;idx=2&amp;amp;sn=cc64372d82354d3212baf84fce230928&amp;amp;chksm=871b0e72b06c8764cfe09654fa457da0fd764c0684d83b7fcd887c19401b3b4d623a07ab2bb9&amp;amp;scene=21#wechat_redirect"&gt;律师&lt;/a&gt;之后，自动化已经开始席卷金融行业。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;日本富国生命保险（Fukoku Mutual Life Insurance）近日宣布他们将要从 2017 年 1 月开始使用「IBM Watson Explorer」，代替 34 位保险索赔业务员的职位。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「人工智能将扫描被保险人的医疗记录与其他信息来决定保险赔付的金额，」富国生命在一份新闻稿中写道。「受伤定性、患者病史和治疗形式都将纳入理赔金额的考量。人工智能系统将自动搜索数据，完成数据计算任务，帮助该公司剩余的员工更快地处理理赔事宜。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;根据日本《每日新闻》的报道，在此项目中，富国生命将斥资 170 万美元（约合 2 亿日元）引入 IBM 公司的人工智能系统，随后每年的维持费用约为 12.8 万美元。通过使用人工智能系统，该公司将在未来每年节约 110 万美元的开支，这意味着此项投资两年后即可收回成本。「Watson AI 的效率预计会比人类员工高 30%，」富国生命保险的发言人表示。「本公司已经受益于 IBM 的新技术，类似的人工智能系统正被用于处理客户投诉电话等任务。如使用软件识别客户语音，将语音转换为文字，而后分析这些话的内容。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一些美国公司也在使用情绪分析软件来为顾客提供服务。这类软件一大优势就是可以获知顾客的情绪，当顾客对自助服务系统不满意，系统将自动转接到人工服务上去。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;《每日新闻》报告称，另有三家日本保险公司正在测试或引入人工智能系统，它们希望通过智能系统自动完成一些技术性工作，如为顾客提供合理的金融计划。以色列一家保险初创公司 Lemonade 已经募集了 6000 万美元，其 CEO Daniel Schreiber 称他们的未来目标是「用机器人和机器学习替代经纪人与文书工作」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;像 IBM Watson 这样的人工智能系统正自信满满地准备倾覆众多知识技术职位，如保险和金融服务。对此，哈佛商业评论（Harvard Business Review）在一篇报道中认为，这是因为许多工作能「由可以编纂成标准步骤的工作流程和基于标准格式的数据进行决策组成。」引入人工智能意味着提高现有员工生产力，还是机器完全替换人类工作岗位？一切还有待观察。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「几乎所有的工作都面临计算机在短期内无法处理的关键问题，」哈佛商业评论写道。「但是，我们不得不承认越来越多的知识型工作正在屈服于人工智能的崛起。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文链接：http://qz.com/875491/japanese-white-collar-workers-are-already-being-replaced-by-artificial-intelligence/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 03 Jan 2017 13:30:23 +0800</pubDate>
    </item>
  </channel>
</rss>
