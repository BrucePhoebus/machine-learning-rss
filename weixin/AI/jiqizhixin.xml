<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>腾讯大数据将开源高性能计算平台 Angel，机器之心专访开发团队</title>
      <link>http://www.iwgc.cn/link/3984747</link>
      <description>&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：吴攀、微胖&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随着近年来深度学习技术的发展，各种机器学习平台也纷纷涌现或从专用走向了开源。到现在，一家科技巨头没有一个主导的机器学习平台都不好意思跟人打招呼。比如谷歌有 TensorFlow、微软有 CNTK、Facebook 是 Torch 的坚定支持者、IBM 强推 Spark、百度开源了 PaddlePaddle、亚马逊也在前段时间高调宣布了对 MXNet 的支持。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在，腾讯也加入了这一浪潮。在 12 月 18 日于深圳举办的腾讯大数据技术峰会暨 KDD China 技术峰会上，腾讯大数据宣布推出了面向机器学习的「第三代高性能计算平台」——Angel，并表示将于 2017 年一季度开放其源代码。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBgEMocn7wnIb6FxeuQ6Qqsiar31NkpYWA0VS3K5LiajBSazicuzZbrNDiag/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;腾讯副总裁姚星在大会发言中说道：「人工智能的发展在过去 60 年中几经沉浮，今年终于发出了璀璨光芒，很大的原因就是跟云计算和大数据有关，这是一种演进发展的必然结果。如何处理好大数据，如何在有限的计算资源上对这些大数据进行深入挖掘和分析，这是未来整个产业发展和升级的一个大课题。我相信大数据将成为这次产业升级的基础，核心算法将成为这次产业升级的灵魂。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这次会议上，腾讯数据平台部总经理、首席数据专家蒋杰详细分享了腾讯大数据的发展之路以及 Angel 系统构建的生态圈层。据介绍，Angel 是腾讯大数据部门发布的第三代计算平台，使用 Java 和 Scala 语言开发的面向机器学习的高性能分布式计算框架，由腾讯大数据与香港科技大学、北京大学联合研发。它采用参数服务器架构，解决了上一代框架的扩展性问题，支持数据并行及模型并行的计算模式，能支持十亿级别维度的模型训练。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不仅如此，Angel 还采用了多种业界最新技术和腾讯自主研发技术，性能更高、系统更具易用性。自今年年初在腾讯内部上线以来，Angel 已应用于腾讯视频、腾讯社交广告及用户画像挖掘等精准推荐业务。Angel 更是腾讯大数据下一代的核心计算平台。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBeN5CkS7Kf4zbic7ZTZdl2nhUsicOtjKM2zkUGrKAm55URS2RLiaIzasvg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;近期，机器之心对腾讯数据平台部总经理、首席数据专家蒋杰进行了一次专访，请他详细谈了谈 Angel 的开发和开放背后的故事。（注：后文还附有蒋杰在本次会议上的演讲）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;一、Angel 特点与优势&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;为什么会选择在这个时间点开源 Angel？你怎么看待目前市面上开源的机器学习平台？相比于其他平台，Angel 的优势是什么？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;并不是我们刻意选择一个时间，而是水到渠成的过程。Angel 已在腾讯内部使用了一段时间，系统稳定性和性能经过了腾讯业务的检验，系统达到了一定成熟度，因此现在到了开放给所有用户的时候，希望能激发更多开放创意，让这个好平台逐步转化成有价值的生态系统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前的一些主要机器学习平台：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1）Spark(MLlib): 采用 MapReduce 的计算模型进行分布式机器学习的计算，通用性较好，但不是很适应大规模的模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2）Petuum: Petuum 验证了 SSP 的可行性，这是它带来的最大的贡献，功能方面也比较完备，不过在一定程度来说，更像是一个实验室的产品，离工业界的应用还有一段距离。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3）TensorFlow: Google 开源的机器学习系统，用来替代 DistBelief。提供了 Tensor 流编程模型，主要的优势在于为深度学习提供了通用的算子和 GPU 并行计算，目前 TensorFlow 开源的版本比较适用于单机多卡的环境，在多机多卡上性能有瓶颈。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;Angel 的哪一项特性最能吸引开发者？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;更高性能、更易用，并且在腾讯内部经历过十亿级别的大规模应用的考验，适合工业界使用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;根据这个数据（下图），Angel 的迭代时间显著优于 Spark，尤其是在模型较大的时候差距更是明显，达到这种效果的主要技术进步是什么？请通俗地解释一下。&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBpV7EpibAVN9Krw9I6YJBDhFrYyLX6Lk2HszsMdiaInwd94MWIwUra28g/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Angel 的模型，是分布式存放于多台高性能 Parameter Server 之上的，并且对模型的 pull &amp;amp; push 都做了专门的优化，对于大部分的机器学习算法，在模型越大的情况下，比起 Spark 的单点模型广播方式，性能自然越好。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;请对比一下 Angel 与 Spark、Petuum、GraphLab（Turi 底层技术，被 Apple 收购）等平台。&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Spark 的通用性很好，但架构上不适应大规模参数交换，因此我们才研发了 Angel。Petuum 验证了 SSP 的可行性，这是它带来的最大的贡献，功能方面也比较完备，不过在一定程度来说，更像是一个实验室的产品，离工业界的应用还有一段距离。GraphLab 图方面很强，但是很多机器学习算法不适合抽象为图模型，因此通用性方面不够好，另外，容错性一般。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;至于 Angel，我们主要融合了 Spark 和 Petuum 的优点，避免它们的一些短板，我们在性能、易用性、可靠性方面做了很大的加强。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;为什么考虑用 Java &amp;amp; Scala 来开发这个系统？而不是通常的 C/C++？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;主要是一个延续性的考虑，腾讯大数据平台起源于 Hadoop 和 Spark，都是基于 Java，考虑到用户的习惯，所以使用相同的语言，对于他们来说接受成本更低。另外，Scala 在接口更加的丰富和有表现力，也会对用户更加友好。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外是部署和升级的简单性，之前公司的分布式平台用的是 Java 架构为主，在这些机器上进行 Angel 运行资源的申请，都是透明的，迁移代价很低。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;目前我们了解到 Angel 在模型方面已经支持了 Latent DirichletAllocation (LDA)、MatrixFactorization (MF)、LogisticRegression (LR) 、Support Vector Machine(SVM)，而这些模型都离不开矩阵运算。可否谈谈 Angel 在矩阵运算上做了哪些优化？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前提供 Vector, Matrix 库，支持各种表达形式（稀疏或稠密）和常见存储格式（CSR，COO 等），支持常用数据类型和线性代数计算。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;你们在参数服务器上做了哪些优化？和 DistBeilef 相比，又有哪些不同？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Angel 是基于参数服务器的一个架构，与其他平台相比，我们做了很多优化。首先，我们能支持 BSP、SSP、ASP 三种不同计算和参数更新模式，其次，我们支持模型并行，参数模型可以比较灵活进行切分。第三，我们有个服务补偿的机制，参数服务器优先服务较慢的节点，根据我们的测试结果，当模型较大时，能明显降低等待时间，任务总体耗时下降 5%~15%。最后，我们在参数更新的性能方面，做了很多优化，比如对稀疏矩阵的 0 参数以及已收敛参数进行过滤，我们根据参数的不同数值类型进行不同算法的压缩，最大限度减少网络负载，我们还优化了参与获取与计算的顺序，边获取参数变计算，这样就能节省 20-40% 的计算时间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关于 DistBeilef，我们阅读过跟它相关的一些论文和资料，原理上有一定类似，但因为它没有开源，因此没有办法进行具体细节上的比较，但目前谷歌也用 TensorFlow 来替换它了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;能够支持数亿甚至数十亿的特征维度需要对系统基础架构和算法本身进行多方面的改进，特别是在算法方面，需要对每个算法进行特别的优化。Angel 在基础架构（infrastructure）和算法方面都做了哪些主要优化？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;正如刚才所说，Angel 是基于分布式参数服务器的一个架构，它解决了 Spark 上做参数更新的网络及计算的瓶颈，同时，我们在参数更新、网络调度、降低网络负载等等做了很多架构上面的优化，可以支持数据并行和模型并行，这样才能支持更大的模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在算法方面，其实算法种类繁多，每种都有自己特定的优化方法，但有框架上，会有一些通用的优化方法：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;对传输的算法模型进行低精度压缩，用较少的字节传输浮点数，减少网络流量，加快系统速度；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;每个计算节点建立索引，只向 PS 获取本节点需要的模型子集；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;过滤掉对模型影响较小的更新值，降低网络传输数据量等。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除了这些通用的方式，Angel 针对每种算法也做了大量有针对性的优化，例如 GBDT、LDA 等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GBDT：在 PS 端提供自定义的 Pull 函数，在 server 端完成树节点的分裂，避免将整个梯度直方图发送到计算节点，极大减少网络流量。计算节点向 PS 端 Push 本地的梯度直方图时，使用低精度压缩。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;LDA：Angel 实现了各种 LDA 的 sampler，可以根据具体应用场景选取最合适的 sampler；充分利用了数据稀疏的特点和非均匀分布的特点，提供高效的压缩方式，降低传输数据量；根据数据的分布情况来进行矩阵的划分策略，从而达到 ps 的负载均衡；对不同的词做了细粒度的调度，可以根据词-话题矩阵和文档-话题矩阵的大小来选择是在 worker 上做计算还是在 server 上做计算，从而减少网络开销。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;Angel 和 Spark 一样属于 in-memory 计算吗 in-memory 计算的一个难点在于资源配置和内存管理。在腾讯内部，Angel-as-a-service 是如何做到能够处理不同规模、频率、算法、时间需求的工作量的？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;是的，Angel 也属于 in-memory 计算，但是，Angel 占用的内存会比 Spark 小很多，因为 Angel 主要针对机器学习，专门进行了优化。另外，Angel 并不是一个常驻服务，每个计算任务独立，它的生命周期和计算任务一致，不长期占用。我们可以通过参数来设置 Angel 占用的资源量，也可以通过训练数据量和模型计算一个默认的资源占用量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;二、Angel 与深度学习&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;Angel 对深度学习和强化学习的支持怎么样？支持 GPU 吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Angel 支持基于 GPU 的深度学习，它支持 DL4J，另外，目前 Angel 还能支持如 Caffe、Torch 和 TensorFlow 等业界主流的机器学习框架，提供计算加速。两年前我们就开始在效果广告领域尝试使用深度学习，深度学习+在线学习在我们的效果广告取得很好的效果。我们也在广告领域开始强化学习的应用实验，并探索深度学习+强化学习的融合。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;在 TensorFlow、MXNet 等其它架构上已经实现的模型迁移到 Angel 上的难度有多大？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们在整体架构层面有兼容不同计算框架的设计考虑，同时我们建设了很多相对应配套的工具来降低迁移成本，因此，整体迁移难度很低。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;三、安全和隐私&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;随着信息安全和数据保密需求的日益增加，腾讯的基于云的大数据分析服务面临哪些信息安全和数据隐私的要求？这些要求如何影响了像 Angel 一样的系统的设计和实现？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据安全一直是腾讯首要关注的，我们在数据安全方面有很多规范，技术方面也会要求各层的平台进行全力安全保障。具体到 Angel，它有完善的用户认证和权限控制体系，确保非法用户无法登陆系统，合法的用户也只能看到自己的数据；其次，Angel 的数据存储在具有高容错性和可用性的分布式存储系统上，数据不会丢失，同时数据是分片的，同时也有独特加密格式，此外不同业务之间的数据是隔离的；最后，Angel 拥有完善的监控体系和日志审计，非法访问会被及时发现和处理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;四、背景与展望&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;在 Sort Benchmark 大赛中腾讯团队获得了 GraySort 和 MinuteSort 两项的冠军，速度大幅提升背后应用的技术是怎样的？为何能获得如此大的速度提升？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;比赛冠军，可以说是腾讯大数据平台的厚积薄发，我们的平台发展了 7 年，历经了三代的演进，经历了离线计算、实时计算、机器学习的三大阶段的发展，我们的平台每天都在经受着腾讯数以万亿计的业务量的考验，腾讯的业务量大并行业务类型复杂，迫使我们在高性能计算及资源调度方面必须适应业务的要求，必须灵活、性能高，并要有很好的灵活性。正式有了这些积累，才让我们在比去年更低的成本的条件下取得比去年提升几倍的成绩。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;腾讯内部已经用到了哪些基于 Angel 的产品？在推广中有哪些问题吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Angel 定位于大规模机器学习的计算，自今年初上线以来，已应用于腾讯视频、腾讯社交广告、用户画像挖掘等精准推荐业务，效果非常明显。目前基本上所有的 BG 都有业务在使用并且用户越来越多。推广过程中问题不少，主要是用户对一个新事物的接受需要一个逐步的适应过程，有一定的学习和业务迁移成本，所以，我们在易用性方面以及业务迁移方面做很多工作，降低用户的使用的门槛。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;开发这个框架投入了多少资源？开发团队有多少人？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Angel 项目在 2014 年开始准备，2015 年初正式启动，刚启动只有 4 个人，后来逐步壮大。项目跟北京大学和香港科技大学合作，一共有 6 个博士生加入到我们的开发团队。目前在系统、算法、配套生态等方面开发的人员，测试和运维，以及产品策划及运维，团队超过 30 人。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;Angel 已经支持了 SGD、ADMM 优化算法，后续还将支持哪些算法？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;主要看用户需求，应用有需要的，我们就会支持。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;能谈一下 Angel 此次开源的原因和意义吗？Angel 后续的短期计划和长期计划是什么？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;腾讯大数据平台来自于开源社区、受益于开源社区，所以我们自然而然地希望回馈社区。开源，让开放者和开发者都能受益，创造一个共建共赢的生态圈。在这里，开发者能节约学习和操作的时间，提升开发效率，去花时间想更好的创意，而开放者能受益于社区的力量，更快完善项目，构建一个更好的生态圈。我们一直都在回馈社区，开放了很多源代码，培养了几个项目的 committer，这种开放的脚步不会停止。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;开源只是个开头，后续我们会努力做好社区建设，我们会投入比较多的资源来响应社区的需求，我们会为 Angel 建设更多更好的配套生态来支持更多的业务场景。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;目前国内外几大科技巨头都在主推一个开源平台，腾讯此次开源后，如果看待这种竞争格局，以及腾讯在这方面的竞争优势？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;竞争一直都会存在，竞争促使进步，会让整个行业发展更快，所有从业人员和用户都是好事。至于各企业的平台，每家都有自己的优势，也有不足，开源能促使短板被优化。让竞争来的更猛烈些吧。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;为什么命名 Angel？开发中有什么有趣的故事吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们开发的初衷是一个可以计算更大模型，速度快到飞起来，像插上翅膀一样的平台，也希望它对用户足够友好，门槛低，易用性高，会是一个友好善良的平台形象。另外，这个项目对我们几个开发人员来说非常重要，心里很宝贝这个项目，所以自然而然想到了 Angel。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;以下是腾讯数据平台部总经理、首席数据专家蒋杰在本次会议上的演讲整理：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;很多人已经知道腾讯获得了今年的 Sort Benchmark 的排序的 4 项冠军，很多朋友来问我：腾讯是怎么做到的，背后支撑的究竟是什么样的技术？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今天，我借这个机会，跟大伙来讲讲背后的一些故事。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBUdqSRY7jmLiatHexAdB0XIHkYqRicaBC4miaFvhdIy5t2gk20b32BPqwA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相信很多人看过我们在很多城市机场投放的这个广告，这个广告里面画的是一个赛跑的选手。排序比赛就跟奥运会的百米赛跑一样，都要很快。但我想说的是：其实我们更像一个长跑选手，我们在跑马拉松。这场马拉松，我们跑了 7 年。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFB0tLgc2BaYhru5J62ia1LqSzqVxKOxNvjriciaqwnbwXFVElpFssibqSljQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;回顾过去几年的比赛成绩，几年前冠军都是被美国企业垄断的，最近三年则是 BAT 拿了冠军。应该说，这几年，国内互联网的发展速度不比美国慢，与此同时，以 BAT 为代表的国内互联网企业的计算能力也不落后于美国。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;过去几年，获得冠军的团队用的基本上都是 Hadoop 和 Spark。其实腾讯的大数据平台，也是始于 Hadoop。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBxHorg5T4NaWyWIOaIuCSC7SM64miarMzS5FWN4D38iahCfxGeqLvna0Q/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们之所以能获得四项的冠军，是我们经历了几年的打磨，追求极致，我们希望最大限度地压榨机器的性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先，从成本的角度，只有把硬件压榨到极致，成本才会低。我们采用的是 OpenPower 架构的机器，按节点数计算，我们规模只有去年冠军的六分之一。按照今年的硬件价格，我们总 TCO 成本远低于去年的冠军。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在调度层面，我们对调度算法做了深度优化，使得每台机器的 CPU、内存、网络、磁盘 IO 等每个环节都能发挥到极致。本次比赛的其中两项为 MinuteSort，比拼的就是一分钟内的排序数据量。在这里，时间调度的效率就变得非常重要，而在这两项比赛上我们比去年提升了 5 倍——是提升幅度最高的；这也从另一个方面说明了我们在调度效率上的领先性。总结为一句话就是：最大限度地压榨了硬件的性能，才让我们取得了这个成绩。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前我们用于比赛的这个集群，已经在我们的现网中用起来了，在高性能计算、图计算、深度学习等领域支撑着腾讯的现网应用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;回顾我们走过的 7 年，我们是 2009 年 1 月开始基于 Hadoop 来开发我们的大数据平台，七年的征程，我们历经了 3 代平台的发展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBxnQSicYV0HKDuduBhRPGYsoqkw4XmBiaGFVeGPBiaInWp8gNZj0lyPbRQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2009-2011 年是我们的第一代平台。我们的第一代平台只支持批量计算的场景，主要就是报表。在这个过程中我们重点发展了平台的可扩展性。我们不断增大集群的规模——从 09 年的几十台发展到了现在总规模接近 3 万台。总结起来：第一代就是「规模化」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二代用三个字总结就是「实时化」。这是 2012 年到 2014 年，主要支持在线分析和实时计算的场景，比如实时报表、实时查询、实时监控等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第三代是去年到现在，主要是建设机器学习平台来支持腾讯各业务数据挖掘的需求。这是从数据分析到数据挖掘的转变，三个字总结就是「智能化」。、&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFB2ZC7FmWe8ibMRN0o1nf4nj5G2iak6AqCJc8EfmSEhIOERNT29h6wM9gQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一代是离线计算的架构，是基于 Hadoop 开发的，我们起名叫 TDW——腾讯分布式数据仓库（Tencent distributed Data Warehouse）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;社区的 Hadoop 迭代慢，单一集群规模小，稳定性和易用性都很差，不能达到腾讯的要求，因此我们按腾讯的业务运营标准，做了深度定制开发，我们着重发展集群的规模，解决 Master 单点瓶颈不能扩展的问题，我们优化了调度策略来提高 Job 的并发性，也加强了 HA 容灾建设；还有很关键的一点的是，我们丰富了 Hadoop 的周边生态，建设了配套的工具和产品来降低用户的使用门槛。语法上，我们兼容 Oracle 的语法，方便腾讯各产品部门做程序的迁移。Hadoop 大数据的性能很强，但是小数据分析的效率很差，我们就集成了 PostgreSQL 来提升小数据的分析性能，从而打通 Hadoop 和 PG 的访问界限。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;就这样，我们从最开始的几十台、到几百台、到几千台。几年以后，在 2013 年单一集群达到了 4400 台，2014 年单一集群突破了 8800 台，处于业界领先的水平。目前我们的总规模接近 3 万台。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;TDW 的建成解决了我们内部三大业务痛点：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFB95v0gOOhqJia1zAfIYCtTib9sTicPlW25EFxFib3FydPMENsr8j3zWKcxw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一，它使我们具备了 T/P 级的数据处理能力，几十亿、百亿级的数据量，基本上 30 分钟就能算出来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二，它的成本很低，我们可以使用很普通的 PC Server，就能达到以前小型机一样的效果；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第三，容灾方面，原来只要有机器宕机，业务的数据肯定就有影响，各种报表、数据查询都出不来。现在 TDW 的机器宕机，业务完全无感知，系统会自动做切换、数据备份等等的事情。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;正是解决了业务的这些痛点，业务部门都愿意把计算迁移到 TDW。到 2012 年底，我们把所有原来在 Oracle 和 MySQL 上跑的报表都切换到 TDW。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;TDW 的建成，让我们具备了融合所有产品平台的数据的能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以前的各产品的数据都是分散在各自的数据库里面的，是一个个数据孤岛，现在，我们以用户为中心，建成了十亿用户量级、每个用户万维特征的用户画像体系。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBCytWye3ibBuxcNgLaibOjxfkdzWOu5U4nyg5k87G39zwHiafY8je4kwNg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以前的用户画像，只有十几个维度——主要就是用户的一些基础属性，比如年龄、性别、地域等。以前构建一次要耗费很多天，数据都是按月更新，有了 TDW，我们每天更新一次。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个用户画像已经应用在腾讯所有跟精准推荐相关的产品里面。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBtxH3ZZbzbND45diaoXr3iarosvmTH9wqN4AgiaAAoMVDVZf74oibicicbWcA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;推荐相信大家现在都耳熟能详，但是放在 6 年前，这还是一个刚刚新兴起的应用；TDW 为我们提供了一个快速切入快速支撑的能力。通过 MapReduce 的编程范式，基于 TDW 的平台，我们可以专注于各种推荐算法逻辑本身的实现，比如大家常见的 CF、MF、LR 这些算法、以及各种 hash 聚类算法；这个时候的推荐技术，面对海量的用户群体访问，更多还是基于一种实时查询的服务方式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一代平台解决了量大的痛点，但是在速度方面还有问题——数据是离线的，任务计算是离线的，实时性差。所以，我们建设了第二代大数据平台。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在第一代基础上，集成了 Hadoop 的第二代——Spark，同时，还融合了 Storm 流式计算的框架。这一代平台的集成，让我们的计算速度从原来的小时，发展到分钟，直至秒级。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFB80GHiau8xaHRBF6kMloz4Kib3SGK1j6xL3l4UZBlYoPQicX4AibUcaKMzQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据采集方面，我们构建了 TDBank，让原来通过接口机传文件的方式，T+1 的粒度，变成了毫秒级的实时采集。在这个采集平台里面，我们自研的消息中间件每天采集的消息条数超过 6.5 万亿，可以说是世界上消息量最大的消息中间件。同时，我们还有高可靠版本的消息中间件，能支持像金融、计费等高一致性的需求，保证消息不丢。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在资源调度层面，我们基于 Yarn，发展了我们的 Gaia 调度平台，Yarn 只支持 CPU 和内存的维度，而我们的 Gaia 还支持网络以及磁盘 IO 的维度，Yarn 只支撑离线计算，Gaia 能支持在线的场景，另外，我们还支持 Docker，我们平台现在每天有 1.5 亿 container。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBKeHic8dNPaYGib3sHDDwOeYs4gSF2PdX7zXuZDaP0ggrBz9VCiahI1Nsw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;再拿刚才提到的推荐例子，基于第一代平台的推荐应用会碰到 2 个问题，一个是随着用户量和访问量的增多，产生的数据会越来越多，多到在有限的时间根本不可能批处理地计算完，还有一点是用户的行为模式变化很快，需要更快地去更新各种维度的用户画像；数据的实时采集让用户行为实时画像的计算成为可能，这构成了流式计算的数据流。分布式的流式计算实时更新各个维度的统计量，进一步形成了推荐算法的实时训练数据，从而把上一代的 offline 的推荐系统变成了 online 的实时推荐系统。在广告的推荐应用上，我们可以看到每一次的实时加快，都带来了更大的点击率提升。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二代的平台，实时性和体量方面都能满足绝大多数业务需求。但随着我们的数据量越来越大，我们的瓶颈很快也出现了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBNib2LRPkysDvGSicHqZBjnBzTbiaw9wibefay3Om8JzgTNfey9BZiagOC7A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们在 Spark 上做数据训练的时候，每一轮的迭代，在更新数据的时候，都会遇到网络方面的瓶颈——因为更新数据的地方是一个单点，如果数据的维度很大，这套框架就无法支撑。在我们的实际应用中，千万级的维度都可以运行得不错，但是上了亿级，性能就非常低了，甚至跑不出来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以，我们必须要建设一个能支持超大规模数据集的一套系统，能满足 billion（十亿）级别的维度的数据训练；而且，这个系统必须能满足我们现网应用的工业级需求。它能解决 big data 和 big model 的需求，它既要能做数据并行，也要能做模型并行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBT6DTnr40mTNCgpoJPlrXy1hXjgGLWp9BApJEUE8qI9heWiaAKpLue4Q/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这个问题上，存在两种解决的思路：一个是基于第二代平台的基础上做演进，解决大规模参数交换的问题。另外一个，就是新建设一个高性能的计算框架。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们看了当时业内比较流行的几个产品：GraphLab（主要做图模型，容错差）；Google 的 Distbelief（还没开源）；还有 CMU Eric Xing 的 Petuum（当时很火，不过它更多是一个实验室的产品，易用性和稳定性达不到我们的要求）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;看了一圈，我们决定自研，走自研的路。我们前两代都是基于开源的，第三代则开始了自研的历程。其实在第二代，我们已经尝试自研，我们消息中间件——不论是高性能的，还是高可靠的版本——都是我们自研的。它们经历了腾讯亿万流量的考验，这也给了我们在自研方面很大的信心。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFB9E2MNLHuBia0IicVvuGJAiafVTWGVbarYjYibRwk7edg34Lq8OTFZ9T1Ow/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此，第三代整体的计算框架方面，我们也走了自研的道路。第三代的平台，核心是一个叫 Angel 的高性能计算平台。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们聚焦在高性能的计算框架方面，同时，也是我们往机器学习、深度学习演进的一个路线。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相比第二代，第三代的计算框架，可以支持 10 亿级维度的算法训练，由以前的数据并行，到可以支持模型并行。同时，我们第三代的平台，还支持 GPU 深度学习，支持文本、语音、图像等非结构化的数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBy1zEXmbkiapAmfCsWTWYzibhsj5O81Wf8mGatN4HU3TyicxrxEL8sZjOA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Angel 是基于参数服务器的一个架构，它跑在我们的 Gaia 平台上面的。它支持 BSP、SSP、ASP 三种计算模式；支持数据并行以及工业界更看重的模型并行（因为我们主要碰到的还是模型大的问题）；另外，在网络上我们有个原创的尝试，我们用了港科大杨老师的团队做的诸葛弩来做网络调度；Parameter Server 优先服务较慢的 Worker，当模型较大时，能明显降低等待时间，任务总体耗时下降 5%~15%。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFB65OwksSVbVEPLsfv1cLgSmk225OuTQcWXpmJwAdjc7OHytlrNKDJIQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Angel 提供很丰富的算法，支持 LR、SVM、LDA、GBDT 等等，并且集成了非常丰富的数学函数库，另外，还提供非常友好的编程界面，能跟 Spark、MR 对接，你能像用 MR、Spark 一样编程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Angel 跟其他平台（比如 Petuum 和 Spark 等）相比，就我们的测试结果，在同等量级下，Angel 的性能要优于其他平台。比如我们用 Netflix 的数据跑的 SGD 算法，大家看一下这个图的对比：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBbkuncTubQS9tGOhGqHJfhLlE08nr6EJMY7EhjLL0z1gAJotnfFuQaA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;同时，Angel 更适合超大规模的数据训练。目前 Angel 支持了很多腾讯内部的现网业务。这里举两个例子，比如，在构建用户画像方面，以前都是基于 Hadoop 和 Spark 来做，跑一次模型要 1 天甚至几天，话题只有 1k；而在 Angel 上，200 多亿文档、几百万个词、3000 亿的 token，1 个小时就跑完了。以前 Spark 能跑的，现在 Angel 快几十倍；以前 Spark 跑不了的，Angel 也能轻松跑出来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;再看一个案例。视频的点击预测，同等数据量下，Angel 的性能是 Spark 的 44 倍以上。用了 Angel 以后，我们维度从千万扩展到亿，训练时间从天缩短到半小时，而准确度也有不小的提升。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBtjANfkVY6dCFnguYRRl2lPl0R5ceAHOD7paHicMVOultuAQoc1ewF9Q/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Angel 不仅仅是一个只做并行计算的平台，它更是一个生态，我们围绕 Angel，建立了一个小生态圈，它支持 Spark 之上的 MLLib，支持上亿的维度的训练；我们也支持更复杂的图计算模型；同时支持 Caffe、TensorFlow、Torch 等深度学习框架，实现这些框架的多机多卡的应用场景。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;各位，临近尾声了，我想总结一下腾讯大数据平台发展的三个阶段：我们从离线计算起步，经过实时计算阶段，进入了机器学习的时代。我们从跟随开源，发展到自研，我们的发展历经了规模化、实时化，以及智能化的变迁。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，我要借这个机会跟大家公布一个消息，那就是：我们的大数据平台将全面开源。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们会在明年上半年把 Angel 以及 Angel 周边的系统进行开源。我们平台源自开源，我们的发展离不开开源，所以我们会以最大的力度拥抱开源。其实在开源的道路上，我们一直都在参与：我们第一代平台的核心 TDW-Hive 在 2014 年就开源了；我们还在很多社区项目贡献了很多核心代码，培养了好几个 committer。而未来，我们的开源力度只会越来越大。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谢谢大家。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心原创文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 19 Dec 2016 21:08:36 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 麦肯锡报告：机器的崛起，中国高管眼中的人工智能</title>
      <link>http://www.iwgc.cn/link/3984749</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;转自麦肯锡咨询公司&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;作者：&lt;span&gt;Christopher Thomas，梁刚&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自 20 世纪 50 年代「有思想的机器」诞生以来，软件开发人员一直在试图教会计算机如何像人类一样思考。然而，在接下来的几十年里，人工智能（AI）的发展速度并没有快速增长。相关技术的研究也通常伴随着停滞和挫折，因为开发成本过高，也缺乏足够的数据量来支持人工智能算法。&lt;/span&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而，在过去十年中，计算能力大幅提升，深度学习算法不断提高，机器学习变得更加强大，与此同时数据量的急剧增长也大大推动了这些算法的发展，人工智能从此进入了加速增长的新阶段。经过了 60 多年，人工智能的发展已接近临界点，完全具备实现大规模商用的潜力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在中国，人工智能也插上了腾飞的翅膀。「百度大脑」就是其中一个推动因素。这是一家百度建立的研发平台供第三方来开发人工智能应用，投资于无人驾驶汽车的研究，以及提供给蓬勃兴起关注于机器学习应用及相关商业模式创业公司的利用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而，我们最新的一项研究表明，人工智能的迅速发展可能更有利于科技板块，因为这一行业具有相关的人才、技术和资金，更易于推动人工智能的发展和普及。相比之下，中国的传统行业还没准备好利用人工智能技术，大多还没把其视作战略重点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;关键术语&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能是有关计算机系统的理论和发展，这类计算机系统能够代替人类智能执行一般由后者执行的任务，比如视觉感知、语音识别、决策和语言转换。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器学习也是一种人工智能，可以不通过明确的编程就能让计算机获得学习的能力。机器学习专注于开发能自学的计算机程序，遇到新数据时，这些程序能够自我成长并做出改变。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深度学习是人工智能的一项功能，主要通过模仿人脑的工作模式进行数据处理并生成供决策用的模式。深度学习是人工智能中机器学习的一个子集。深度学习具备的网络能够向无结构或无标签的数据学习，而无需任何监督。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了更好地了解人工智能对中国传统行业的潜在影响，我们最近对 80 家公司展开了一项调查。其中，60 家处于传统行业，如零售、重工业和建筑业。另外，调查对象还包括 20 位人工智能专家，他们来自中国领先的互联网公司，其中包括几家初创公司。调查对象覆盖各行各业，具有一定代表性，包括金融、医疗保健、零售、消费品、科技、媒体和电信。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有一点大部分受访者都认同，那就是人工智能会成为其所在行业的一股颠覆性力量。尽管变化的步伐可能因行业不同而有所差别，但 90％的受访者都认为，人工智能会从根本上改变自己的行业。在问到人工智能会怎样产生影响时，受访者提出了 100 多种潜在方式，从提高运营效率的应用程序开发，到全新的产品和服务开发，不一而足。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管人工智能带来了一线曙光，但我们的研究表明，传统行业公司仍在挣扎，犹豫该如何对这一技术进行投资。超过 40％的调查受访者表示，所在公司的 CEO 并没有将人工智能作为战略重点，60％以上的人认为，所在公司在过去一年中，人工智能战略并没有取得令人满意的进展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBMEejShrOgdQ1NwPBD9fFZicdPnuiaGKMqk8f4lwX0tMzk3nMbcHnMEDw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在调查中，大多数高管指出，人才匮乏是制定具体人工智能战略的主要障碍。事实上，中国只有不到 25％的人工智能从业者拥有超过 10 年的行业经验，而在美国这一比例也只有 50％。一名首席技术官表示，开设机器学习相关专业的中国高等院校屈指可数。即便是有此专业，大多数学生也开发不出现实生活中能真正运用的应用程序。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;鉴于以上种种挑战，传统行业的受访者认为，要在这一领域取得成功，前景不容乐观：84％的受访者表示，人工智能最大的赢家可能是互联网公司和创业公司，而不是现在的行业领军者。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBbB3wrVDBGlyjhk8yEDGQMdzg1eFV1gavoUsInw5NUhUXfvz7hxcckg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;人工智能到了爆发的临界点&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在技术突破和应用机会不断扩展的双重推动下，人工智能走到了大规模应用的临界&lt;/span&gt;&lt;span&gt;点。四大趋势表明，人工智能将给各行各业带来颠覆性的变革：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBIiaJ4UZn6SriafVdHo7wxCpicbu2DceN3iagLibst1teHeqhVqib7rsfo1UA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 领先的半导体厂商及 CPU 和 GPU 企业均将人工智能视作核心目标，斥巨资投入大&lt;/span&gt;&lt;span&gt;量处理技术，为人工智能及机器学习打下基础。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 开源人工智能平台的数量及规模持续激增，开发人员可以自由利用编程界面，使&lt;/span&gt;&lt;span&gt;用各类工具、算法以及训练数据，建立人工智能功能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 数据资源的规模及种类也大幅增加，意味着可以对机器进行训练，从而使其做出&lt;/span&gt;&lt;span&gt;更快更好地决策。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4. 高科技巨头以及风投机构对致力于「人工智能跨行业创新应用」的初创公司趋之&lt;/span&gt;&lt;span&gt;若鹜。从 2010 年到 2014 年，人工智能初创公司的风险投资额增加了 20 倍以上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBIbMuMb8urXLt56Z94uk3TgMPwLiazwdysviayp2A1KyY7d3tOOKkvRLQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们对这种历史性转折并不陌生。当技术创新与市场力量汇聚在一起时，便会创造&lt;/span&gt;&lt;span&gt;出足以扭转整个行业局势的产品。2007 年苹果手机 iPhone 的发布就是这样一个历史&lt;/span&gt;&lt;span&gt;时刻。当触摸屏的成熟技术与移动电话的日益普及交织在一起时，便产生了足以改变&lt;/span&gt;&lt;span&gt;整个行业领域的新产品。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然确切的时间仍无法预测，但人工智能似乎已走到了类似的爆发性历史转折点。&lt;/span&gt;&lt;span&gt;人工智能的重大技术进步创造了大量机会，将催生出改变游戏规则的产品和服务。&lt;/span&gt;&lt;span&gt;其中一项关键的应用便是语音识别。自然语言处理的成功率已接近 99％（技术临界点），全球和中国的大型科技企业正在努力推出相应的家用网络设备，如具备语音&lt;/span&gt;&lt;span&gt;输入技术的路由器。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在无人驾驶领域，关键技术也已接近临界点：比如目标跟踪算法，即用于识别车辆&lt;/span&gt;&lt;span&gt;附近目标的算法，已达到 90％的准确率。再比如，固态激光雷达也已面市（类似于雷&lt;/span&gt;&lt;span&gt;达，但以激光为工作光束），可用于收集车辆周围环境的高频数据。由于这些技术迅&lt;/span&gt;&lt;span&gt;速进入成熟可行阶段，各类大型科技公司，如谷歌、英伟达、英特尔和宝马都在快马&lt;/span&gt;&lt;span&gt;加鞭，努力开发自动驾驶汽车。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBI6V3UdutrC9DVEg629iaUjQjLnWN3CYibHNN6LlSK9wbeicBB7T8lgpsQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;中国将引领行业趋势&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管人工智能的发展主要受全球高科技企业的推动，中国企业也致力于在这一新兴&lt;/span&gt;&lt;span&gt;领域成为领导者。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;例如，中国对本土半导体行业的打造主要强调发展机器学习所依赖的 CPU 和 GPU&lt;/span&gt;&lt;span&gt;技术。百度以 96% 的准确率成为语音识别市场的领先企业，追上甚至赶超了谷歌、&lt;/span&gt;&lt;span&gt;微软及亚马逊等竞争对手。预计中国的人工智能应用市场将以 50% 的增速逐年增&lt;/span&gt;&lt;span&gt;长，远远超过全球市场 20% 的复合年增长率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;中国政府已经认定，人工智能是经济发展新的引擎，因而投入资金开展学术研究，&lt;/span&gt;&lt;span&gt;并为人工智能企业提供经济奖励。中国的互联网巨头将人工智能视为重点，而初创&lt;/span&gt;&lt;span&gt;公司不断开发各种人类智能应用，包括机器人、医疗卫生、以及无人机领域。部分中&lt;/span&gt;&lt;span&gt;国公司（比如 NIST 的科大讯飞和 Imagenet 的海康威视）在人工智能技术领域甚至&lt;/span&gt;&lt;span&gt;超过了全球知名的竞争对手。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;对传统企业的挑战: 成为行业的领导者还是落后于人&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;中国积极推进引领人工智能革命，为国内非高科技类企业带来一定难题，因为后者将&lt;/span&gt;&lt;span&gt;不得不开始采用人工智能技术。很多这类传统企业开始与互联网公司在人工智能&lt;/span&gt;&lt;span&gt;应用领域开展合作，以增加自身的成功几率。在这合作过程中，他们为今后可能颠覆&lt;/span&gt;&lt;span&gt;自己的对手提供珍贵的专有数据以及行业经验。与可能摧毁自己的公司合作，就像&lt;/span&gt;&lt;span&gt;他们冲击银行、商业及其他行业一样，真的能够帮助传统企业取得成功吗？高科技&lt;/span&gt;&lt;span&gt;企业是否成为中国人工智能繁盛时期的唯一赢家？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于传统企业而言，如果不开展合作，其他可采用的策略为：投入资金，加入人工智&lt;/span&gt;&lt;span&gt;能技术和能力的竞赛。然而，鉴于我们预测人工智能业未来的发展带有很多不确定&lt;/span&gt;&lt;span&gt;性，因此，仅靠预测采取上述举措可能是很不明智的。中国在人工智能领域发展的&lt;/span&gt;&lt;span&gt;这一优势能否被国内传统企业所充分利用？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;CEO 们需回答九个关于人工智能战略的问题&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于人工智能，中国传统企业大多不会战略性地采取「放任不管」的态度。中国企业&lt;/span&gt;&lt;span&gt;的 CEO 们必须积极思考这一问题，做出审慎的战略决策：是「发展壮大」、「建立合&lt;/span&gt;&lt;span&gt;作」、还是仅仅采取「观望」的态度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以下是企业领导人在制定人工智能战略时需回答的九大问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFB3QBkrS09YlqicTT6EzrPjOXzobRrVMrTr4BBbvbMuEA9mYo6ibQQyyxw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们现在处于怎样的阶段？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1) 我们所处的行业在采用人工智能技术方面处于怎样的阶段？我们现在正在使用&lt;/span&gt;&lt;span&gt;以人工智能为主的应用吗？还是正处于将人工智能运用到业务当中的最初阶段？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2) 我们所处的行业之中，谁正在引领使用人工智能技术？我们的公司是引领者、还&lt;/span&gt;&lt;span&gt;是追随者？有哪些最佳做法是我们的公司可以学习和借鉴的？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3) 我们的组织是否已经做好准备，制定并采纳人工智能战略？在公司内全面采用人&lt;/span&gt;&lt;span&gt;工智能技术需要具备哪些基础？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;未来我们的目标竞争领域是什么？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4) 在我公司所处的行业里，有哪些可行的人工智能应用案例？有哪些关键技术？哪&lt;/span&gt;&lt;span&gt;些企业可以进入我们所处的行业？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;5) 从近期和长期看，人工智能可取得哪些业务成效？在人工智能领域的投资预计&lt;/span&gt;&lt;span&gt;多久可以回报？在决定投资时机时预计会有哪些取舍？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;6) 我们应如何利用人工智能进入或打造新的领域？人工智能应用所提供的能力远&lt;/span&gt;&lt;span&gt;远超越了当前的规范，可能促使企业将当前重点扩大到其他领域。人工智能将如何&lt;/span&gt;&lt;span&gt;改变竞争规则，以及我公司所处的竞争格局？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们需要哪些人工智能能力？如何获得这些能力？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;7) 我们应利用哪些人工智能的能力？根据我们对潜在案例的分析，以及人工智能的&lt;/span&gt;&lt;span&gt;竞争影响，我们具体需要哪些技术和商业人才来实施我们的目的？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;8) 我们怎样才能获得上述能力？是外购、合作、还是自建？每项选择都有潜在的优&lt;/span&gt;&lt;span&gt;势和劣势。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;9) 我们应如何利用上述能力打造持续的创新流程？企业必须能预测上述能力将如&lt;/span&gt;&lt;span&gt;何推动企业在未来持续增长，才能够最大程度地利用人工智能的投资&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于传统行业的企业，问题不在于他们是否应该考虑在自身的业务及战略流程中采&lt;/span&gt;&lt;span&gt;用人工智能应用—而是他们应该制定怎样的人工智能战略，以及如何去实施这一&lt;/span&gt;&lt;span&gt;战略。中国的非高科技企业或者可以向国内高技术企业学习，或者眼睁睁看着对方&lt;/span&gt;&lt;span&gt;在技术行业独占鳌头。为避免落后或更糟的局面，CEO 们必须积极考虑人工智能在&lt;/span&gt;&lt;span&gt;其所在行业的现状以及潜在的未来，明确未来目标的重点，建立发现并捕捉人工智&lt;/span&gt;&lt;span&gt;能在本行业推广效益的引擎。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;获取报告 PDF 全文 (2MB)，请点击「阅读原文」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;作者诚挚感谢魏海, 朱虹, 韩赟儒和戈弋对本报告的贡献。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Christopher Thomas 为麦肯锡全球董事合伙人, 常驻北京分公司；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;梁刚为麦肯锡资深专家, 常驻台北分公司。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 19 Dec 2016 21:08:36 +0800</pubDate>
    </item>
    <item>
      <title>资源 | 贝叶斯神经网络简史</title>
      <link>http://www.iwgc.cn/link/3984751</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自NIPS2016&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：杜夏德、曹瑞&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;在刚刚过去的 NIPS 2016 会议上，剑桥大学信息工程学教授 Zoubin Ghahramani 为我们讲述了贝叶斯神经网络的发展历程。本文从研究背景和问题应用切入，介绍了贝叶斯神经网络的起源、黄金时期以及后来的复兴，并介绍了每个发展阶段的几篇关键研究，是一份简明扼要的学习资料，能够帮你快速深入理解贝叶斯神经网络。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBbH7aabjuhy57WmOezDAWxnHqkfZvCXpC2myx9NITLF3ribsYruLJ6qg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBHZDMVNMlAZHiaG1zc6IGDJibcibz406Da4krPjTs84G2Dibia6bDThFjwMA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P4：上世纪八十年代的研究背景&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;《玻尔兹曼机》于 1985 年出版，1986 年反向传播网络论文发表，接着 1987 年 PDP 大量出现。这一领域过去也被称为连接机制，NIPS 是该领域的主要学术会议。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P5-P7：神经网络与深度学习简介&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;神经网络与深度学习系统在很多基准任务的表现优异，但是它也有以下缺陷：&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;需要大量数据（常常是数百万样本）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;训练与部署的计算量大（云 GPU 资源）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;不确定性表征得不太好&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;常常被对抗样本欺骗&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;对于优化很挑剔：非凸+架构选择，学习程序（procedure），初始化等等，还需要专家知识（expert knowledge）和实验&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;过程黑箱，无法解释，缺少透明性，很难信任其结果。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBh5JyUWHWjfHVgH9Cr58sdZlA0RiaASq5u2XpBfuSzqGptSFsMD3Ec9g/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P8 -12：贝叶斯在这里有什么帮助&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;处理参数不确定性的所有来源&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;具备处理结构不确定性的能力&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;贝叶斯定理告诉我们要从数据（可衡量的量）当中做一些关于假设（不确定的量）的推理。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;学习和预测都可以看作是推理的形式。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;校正模型与预测不确定性：让系统知道它们何时不知道。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;自动模型复杂性控制与结构学习（(Bayesian Occam's Razor)）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;要清楚的一点是「贝叶斯」属于算法范畴，不是模型类。任何定义好的模型都可以用贝叶斯方法.&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBZiaeJyDAUqPlurOdQiczKJsEmEmy7qfHEFdqWB4oe9zyP60KkIErQiaUA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P13：贝叶斯神经网络&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P14-16：贝叶斯神经网络的早期历史&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;贝叶斯神经网络的早期历史可以从以下几篇论文中了解：&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;John Denker, Daniel Schwartz, Ben Wittner, Sara Solla, RichardHoward, Lawrence Jackel, and John Hopfield. Large automaticlearning, rule extraction, and generalization. Complex Systems,1(5):877-922, 1987.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Nafitali Tishby，Esther Levin，and Sara A Solla. Consistent inference of probabilities in layered networks: Prediction and generalization. In IJCNN,1989.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;......&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBa8icRhu7OMuWicnI5BsmaI81H9ib89N1GhfviaX75ABPBiaslRGXNDtwoaw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P17- 20 贝叶斯神经网络的黄金时期&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;David JC Mackay 发表在神经计算（Neural Computation）上的一篇文章：A Pratical Bayesian Framework For Backpropagation Networks 揭开了这一时期的序幕。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Neal, R.M. 1995 年在多伦多大学的博士论文：Bayesian learning for neural networks. 这篇论文也奠定了贝叶斯神经网络 (BNN) 和高斯过程（Gaussian processes）以及自动相关决策机制（automatic relevance determination ,ARD）之间的关系。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBkh41AAnibxr1QNc42Kg4xZw2gXgMc4kxN0bFM4WTVQtbGSHdnsBQneg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P21-24 高斯过程与贝叶斯神经网络&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;高斯过程可被用于回归、分类、排名等。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;将郎格文动力学（Langevin dynamics，一种 MCMC 的形式）与随机梯度下降（SGD）结合起来得到一个基于 minibatch SGD 的高度可扩展的近似 MCMC 算法。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;这样一来，贝叶斯推断就能像运行嘈杂的 SGD 那样简单。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;一个带有一层隐藏层和无数隐藏单元的神经网络和权重高斯先验&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;MacKay 和 Neal 的贡献将特征与架构选择与高斯过程联系起来&amp;nbsp;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P25- 28 贝叶斯神经网络中的变分学习（variational learning）&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Hinton 的一篇论文推导出一个贝叶斯网络权重的对角高斯变分近似，但是用最小描述长度信息理论语言进行描述。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBP69MrPBE9g5OKoaSk8qibRsGKAgYuN2ptDpqG13qPzeXzeRJrlzFGtQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P29 随机梯度朗格文动力学（Langevin Dynamics）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFB9wFiaCvr6zpicuuj2hJRTbbHqcbD28hMgknPykb3ON6kALNDfZ35JI9g/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P30：贝叶斯神经网络的复兴&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P31-32 概率方法什么时候变得非常重要？&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;学习的很多方面都非常依赖于不确定性的细致表征&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P33 结论&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;概率模型为建立能从数据中学习的系统提供了通用框架&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;贝叶斯神经网络有很长的历史并且正在经历着复兴的浪潮&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBKqkGJfqib9LvHHf0ompuzGJGmlr1PGQqpURbG81odVkRibGQv525qLew/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBcsicfEjQCt8QhUqBAFwjyrpGTKBpYdVoS3ibegJmrYpc3uItr5JTQIiaQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P35-36 模型比较及学习模型结构&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBNHoP2GSwrP6X3nrN4vMxHcJ2ibU8Xrxibrq5p81ZOUSaj1Yibf0gibZ2jQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P37-39 贝叶斯奥卡姆剃刀（Bayesian Occam's Razor）&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;模型类别太过简单就可能无法生成数据集。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;模型类别较复杂可以生成很多可能的数据集，所以它们也不太可能随机生成某个特定的数据集。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBibNHc0dibXTNicT14FTZHJPZOxWsjB1AP7Y0lib3ibZdxqP0iatMBLS9iahwg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P40 模型比较和奥卡姆剃刀&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBibdcPqhQaxzsSFa7oicSUl02ZrtnvvUQYr836w2YegAR7APm4GyCE0nQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;P41-42 边缘似然 (marginal likelihood) 和后验（posteriors）的近似方法（Approximation Methods）&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;拉普拉斯近似（Laplace Approximation）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;贝叶斯信息准则（Bayesian Information Criterion，BIC）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;变分近似（Variational approximations）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;期望传播 (Expectation Propagation，EP)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;马尔科夫蒙特卡洛方法（Markov chain Monte Carlo methods，MCMC）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;序列蒙特卡洛方法（Sequential Monte Carlo，SMC）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;精确抽样（Exact Sampling）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;……&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;点击阅读原文即可阅读完整PPT&lt;/span&gt;&lt;/strong&gt; &lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 19 Dec 2016 21:08:36 +0800</pubDate>
    </item>
    <item>
      <title>开源 | OpenAI 的 PixelCNN++实现：基于 Python3 和 TensorFlow</title>
      <link>http://www.iwgc.cn/link/3984753</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Github&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：朱思颖、蒋思源&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBrmb8RFIicuMuCu9PKM04QgDTsgotCkAN0GXWQ5wIQY7MickOKegNiaaMA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今年 6 月 DeepMind 的一条官方推文里，公布了他们当时运用 PixelCNN 所生成的条件自然场景合成图，并称这种方法将艺术生成模型提升到一个新的水准。DeepMind 运用 PixelCNN 实现条件图像生成的论文也被今年的 NIPS 所收录（见文末附录）。6 个月之后，近日，OpenAI 在 GitHub 公开了 TensorFlow 框架里用 Python3 实现的 PixelCNN 优化版——PixelCNN++的源码，其论文已被 ICLR 2017 接收。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所公开的源码是 PixelCNN++的具体代码实现，是在 TensorFlow 框架里用 Python3 编写的。PixelCNN++的具体阐述在以下论文：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;PixelCNN++：A PixelCNN Implementation with Discretized Logistic Mixture Likelihood and Other Modifications, by Tim Salimans, Andrej Karpathy, Xi Chen, Diederik P. Kingma, and Yaroslav Bulatov.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们的研究是建立在 van der Oord 等人今年 6 月份最初提出来的 PixelCNN（所附论文一）上。PixelCNN 是一类强大的生成模型，它有易处理似然性（tractable likelihood）从而容易进行抽样。其核心的卷积神经网络计算在一个像素值上的概率分布，且受左侧和上侧的像素值约束。下面是在 CIFAR-10 上训练的模型里面的示例样本，其实现了每维度 2.92 bits（van der Oord 等人的 PixelCNN 是 3.03 bits）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;来自模型（左）的样品和来自以 CIFAR-10 类标签为约束的模型的样本（右）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBvRPXMujfQYj3gT6nnYibOibrkW6jlCKdU3UFGoszbYe4icbRero76M02g/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此代码支持将我们改进的 PixelCNN 在 CIFAR-10 和 Small ImageNet 上进行多 GPU 训练，并很容易适应额外的数据集。在具有 8 个 Maxwell TITAN X GPU 的机器上进行训练在大约 10 小时内能实现每个维度 3.0 bits，并且需要大约 5 天才能收敛到 2.92 bits。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;开源地址：&lt;em&gt;https://github.com/openai/pixel-cnn&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;设置&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你需要以下环境运行该代码:&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: circle;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;多 GPU 计算机&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Python3&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Numpy, TensorFlow&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;训练模型&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使用 train.py 脚本进行模型的训练，在 CIFAR-10 上训练默认模型只需要简单键入：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;python3 train.py&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你可能希望至少可更改 --data_dir 和 --save_dir，它们指向系统下载数据的路径（如果是无效的）和保存点的位置。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我想使用更少的 GPU 进行训练。为了在更少的 GPU 上训练，我们建议使用 CUDA_VISIBLE_DEVICES 缩小 GPU 可用（the visibility of GPUs）数量，然后再运行脚本。不要忘记相应地调制 flag： --nr_gpu。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我想训练自己的数据集。看看 data/ 文件夹中的 DataLoader 类，必须为你自己的数据集写一个类似的数据迭代器，然后代码才能从那边正常运行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;预训练模型检查点（checkpoint）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你可以下载（http://alpha.openai.com/pxpp.zip）(http://alpha.openai.com/pxpp.zip%EF%BC%89) 中我们已训练的模型（TensorFlow），它在 CIFAR-10 上实现了 2.92bpd。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;引用&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你发现代码很有用，请在你的研究中引用我们：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;@inproceedings{Salimans2016PixeCNN,&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;title={PixelCNN++: A PixelCNN Implementation with Discretized Logistic Mixture Likelihood and Other Modifications},&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;author={Tim Salimans and Andrej Karpathy and Xi Chen and Diederik P. Kingma and Yaroslav Bulatov},&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;booktitle={Submitted to ICLR 2017},&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;year={2016}&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;}&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;附录：&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;论文：Conditional Image Generation with PixelCNN Decoders&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBSqSLkEUFbkibaawwJhobnI8YxjgMLRUn1R0zkNgYwxpctOqImxrSE2g/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本研究探索了使用条件图像生成与基于 PixelCNN 架构的新的图像密度模型。该模型可以以任何矢量为条件，包括描述性标签或标签，或由其他网络创建的隐嵌入。当使用来自 ImageNet 数据库的类标签时，该模型能够生成表示不同动物，对象，风景和结构的多样化、形象逼真的场景。当对由未知的面部的单个图像给出的卷积网络产生的嵌入进行调节时，它可以生成不同面部表情，姿势和光照条件下同一个人的各种新肖像。我们还展示了条件 PixelCNN 可以作为图像自动编码器中的强大的解码器。此外，提出的模型中的门控卷积层提高了 PixelCNN 的对数似然度，以匹配 ImageNet 上的 PixelRNN 的最新性能，大大降低了计算成本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;论文：PIXELCNN++: A PIXELCNN IMPLEMENTATION WITH DISCRETIZED LOGISTIC MIXTURE LIKELIHOOD AND OTHER MODIFICATIONS&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Pvo5licNRic0OtuO2XgsDFBqauqJZM45yZgmD77Hib4cFbOczGOEhpfDNyTxFxNhnicibSnOocaF9ib6Q/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;PixelCNN 是最近提出的一类具有易处理似然性（tractable likelihood）的强大生成模型。本文将讨论我们怎样实现 PixelCNN，同时在 Github 上开源。我们的实现方法包含对原始模型的多个修改，不仅精简了结构，还提高了性能。主要从以下几个角度完成：1. 我们使用像素上的离散逻辑混合似然（discretized logistic mixture likelihood），而不是 256 阶的 softmax 回归（256-way softmax），这能大大加快训练。2. 我们对整个像素而不是 R/G/B 子像素进行约束，从而简化模型结构。3. 我们使用下采样（downsampling）有效地捕获多种分辨率结构。4. 我们引入额外的快捷连接，以进一步加速优化。5. 我们使用 dropout 对模型进行正则化。最后，我们在 CIFAR-10 上呈现最先进的对数似然（log likelihood）结果，以证明这些改进的有用性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Mon, 19 Dec 2016 21:08:36 +0800</pubDate>
    </item>
    <item>
      <title>机器之心独家对话吴恩达：很多技术其实是中国最先开始应用的</title>
      <link>http://www.iwgc.cn/link/3966674</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;吴恩达，百度首席科学家、百度大脑项目负责人。在最近的百度语音开放平台三周年主题活动上，机器之心对这位与 Geoffrey Hinton、Yoshua Bengio、Yann LeCun 齐名的人工智能专家进行了专访，深度了解了百度的人工智能研究、吴恩达的人工智能之路，以及更多的有关人工智能技术的话题。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;一、在百度的人工智能研究&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2014 年 5 月 16 日，百度官方宣布建立硅谷实验室并任命吴恩达作为首席科学家，领头百度北京与硅谷的实验室。当时，百度投入了 3 亿美元在硅谷建起专注人工智能的实验室。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但吴恩达来到百度，并非重头开始建立深度学习。在 2013 年，百度就已建立深度学习研究院（IDL），并在图像识别、基于图像的搜索、语音识别、自然语言处理与语义智能、机器翻译等领域做出重大进展。当时，IDL 由余凯（2012 年加入百度，2015 年离职）组建，百度 CEO 李彦宏任院长，余凯任常务副院长。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;加入百度之后，吴恩达做了一件事。「他订购了 1000 个 GPU，并在 24 小时内得到。而在谷歌，他可能几周或几个月才能得到。」当时深度学习创业公司 SkyMind 的联合创始人 Adam Gibson 在一次采访中曾这么说道。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;百度之前从未买过这样的硬件。在这样的支持下，吴恩达在百度建立了一个进行深度学习的 GPU 集群，使得百度成为了世界上第一个建立深度学习 GPU 集群的公司。几年来，百度不断在 GPU 和超级计算机方向做投入，加大深度学习的研究。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在加入百度之后，曾帮助谷歌建立 Google Brain 的吴恩达也在百度建起了「大脑」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW97Eu3kQ28xCXnW6b2iagC06aJ5JbdzicYLg8nIsUXIQRMFuF31tw1kj7kcVXsPwpwENvL2LFAvp0QA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图片：百度大脑官网&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从百度大脑的官网，我们就可以明晰的看到吴恩达在百度的人工智能研究：机器学习、语音技术、图像、自然语言处理、用户画像。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;机器学习&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今年 9 月份，吴恩达在百度世界大会上宣布开源深度学习平台 PaddlePaddle。PaddlePaddle 的前身是百度于 2013 年自主研发的深度学习平台 Paddle（Parallel Distributed Deep Learning，并行分布式深度学习），一直为百度内部工程师研发使用，并且已经做出了一些实际的产品，较为成熟。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;据介绍，PaddlePaddle 是一个云端托管的分布式深度学习平台，支持 GPU 运算，支持数据并行和模型并行。对于序列输入、稀疏输入和大规模数据的模型训练有着良好的支持，仅需少量代码就能训练深度学习模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是在谷歌宣布开源 TensorFlow 之后，又一科技巨头开源的深度学习平台。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不到一个月，百度再次宣布开源基准工具 DeepBench，可对硬件平台的深度学习性能进行评估，帮助硬件开发人员优化深度学习硬件，从而加快深度学习研究。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW97Eu3kQ28xCXnW6b2iagC06hiaY6xxibqE9fllXc5YlWVML3MwtJr9GhFjEGtBETb1mMr5queCuCPiaQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;语音技术&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「百度大脑已经有好几种不同的人工智能技术，其中比较成熟的就是我们的语音技术。」吴恩达在百度语音开放平台三周年的主题活动上说。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW97Eu3kQ28xCXnW6b2iagC06Gwpq19nK1qqaLcT1jKPV8icR0UlhuhbKyefHqtMON0J0FcWCI4CYgzw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;长久以来，人与机器交谈一直是人机交互领域内的一个梦想。最近几年来，随着深度神经网络的应用，计算机理解自然语音的能力也有了彻底革新。但人机的自然交互，涉及到语音方面的多项技术。在此次主题活动上，吴恩达谈到了百度在语音识别、语音合成、语音输入方面的研究。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「这几年来，我们的团队在不断地优化语音识别系统，在 2012 年开始使用 DNN 模型，后来有比较好的特征，之后开始用 Sequence Discriminative Training，也开始使用 LSTM 模型，加上 CTC，今年我们的团队开发了 Deep CNN 模型，效果在不断进步，这就是我们的语音识别系统。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;百度于 2015 年 11 月发布的 Deep Speech 2 已经能够达到 97% 的准确率，并被麻省理工科技评论评为 2016 年十大技术突破之一。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;语音识别的记录不断在被刷新，今年微软在英语语识别上准确率的突破也几乎媲美人类。但是，使用计算机生成语音——这个过程通常被称为语音合成（speech synthesis）或文本转语音（TTS）——仍在很大程度上基于所谓的拼接 TTS（concatenative TTS），其中有一个由单个人录制的大量短语音片段构成的非常大的数据库，然后再将这些短语音组合起来构成完整的话语。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今年 9 月份的时候，谷歌 DeepMind 爆出在语音合成上的突破性研究——WaveNet，将机器语音合成的表现与人类之间水平的差距至少缩减了 50%。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们的语音合成模型也变得越来越好。这几年来我们在好几个技术方面有比较大的突破，语音合成效果变得越来越好。现在百度在中国语音合成的能力达到业界领先的水平。」据百度讲，百度情感合成技术主要聚焦在为合成语音「加入情感」，目前可达到接近真人发声效果。它们在今年早些时候曾利用此技术，复原已逝明星张国荣的声音。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2016 年，我们也看到了深度学习在图像（识别准确率、风格迁移）、自然语言处理、机器翻译（谷歌神经机器翻译系统）等其他领域取得的最新进展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;比如在自然语言处理任务上，序列到序列模型的注意实现了很大的进展。在后续的专访中，吴恩达表达了自己的看法，「从研究者的角度来看，未来几年有非常多有可能带来突破的思想，它们有可能能够以全新的方式创造出更好的自然语言处理系统。比如说，在词嵌入（word embedding）上，我们可以看到仍有很大的进展。在跨模型学习上，也有一些研究成果。当你同时学习计算机视觉和自然语言处理的时候，那是非常激动人心的。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在研究上，吴恩达认为迁移学习和多任务学习是很好的研究方向。他拿百度的 NLP 团队在 2015 年研究举例说，「如果同时学习多个语言对之间的翻译，效果会比同时学习一个语言对的效果好。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当时，谷歌的神经机器翻译的出现引起了业内的极大关注。但在机器之心之前对百度 NLP 团队的专访中，我们了解到百度的在线翻译系统一年前就应用了基于神经网络的翻译方法。去年百度在 ACL 会议上发表论文《Multi-Task Learning for Multiple Language Translation》，探讨用 NMT 技术解决多语言翻译及语料稀疏的问题，这也就是吴恩达上面所说的多任务学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;说到谷歌的神经机器翻译，我们依此为例向吴恩达追问技术到产品的部署问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;吴恩达回应说，「中国、美国和其它地方的公司在实现先进人工智能的产品部署上都动作很快。但很多人并不知道很多部署实际上是中国的公司最先开始的，虽然不是全部，但也不少。就拿使用神经网络来为机器翻译进行序列学习的特定例子来说吧。实际上，百度比谷歌更早搞明白如何开发和部署它。除此之外，我们还能找到很多首先在中国被开发出来或产品化的技术。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他还提到，「中国科技行业的发展速度是激动人心的。然而现在却有一个令人吃惊的事实摆在我们面前：很多东西是最先在中国实现的，可能一年之后才传入美国，但人们首先想到的还是美国的例子，而不是中国的。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;也许这是对中国人工智能研究实力的一次很好回应。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今年 10 月份的时候，白宫发布的《国家人工智能研究与发展策略规划》报告中称中国的人工智能研究已经走在了美国前面。在提及「深度学习」或「深度神经网络」的期刊论文数量上，中国在 2013 年就超越了美国。而且有媒体称，中国的相关论文不仅数量上远超其他国家，质量上的表现也毫不逊色。这一消息受到了业内许多人士的质疑，认为数量不谈，质量上肯定还有很大差距。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;众说纷纭，难以有一基准评出高低。但高盛近期的一份调查报告认为，人工智能前沿的参与者可能会继续来自美国和中国。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;人工智能之路&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1976 年初生，吴恩达今年刚好 40 岁，不惑之年。他与 Geoffrey Hinton、Yoshua Bengio、Yann LeCun 合称为深度学习「四大天王」，但有人曾质疑吴的人气为何这么高？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 VB 较早的一篇专访中是这样评论吴恩达的，「Bengio 在训练神经网络上取得很大进展，LeCun 开发了卷积神经网络，Hinton 普及了受限玻尔兹曼机。而吴采用最好的，并进行部署与改进。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谈起吴恩达，我们会想到他做过哪些事？取得过哪些成就？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;吴恩达出生于伦敦，父亲是一位香港医生。吴恩达年轻时候是在香港和新加坡度过的，父亲对人工智能在医疗领域的应用的兴趣影响到了他。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他告诉我们，「当时我还在新加坡，我的父亲是一位医生，他对人工智能在医疗领域的应用很感兴趣。所以当时我就很幸运地有些人工智能方面的书。我很小就开始学习人工智能，确切地说，是我 12 岁的时候。我 16 岁时，很幸运地进入新加坡国立大学做实习。在那里，我开始研究神经网络，甚至和教授一起写了一篇小的研究论文。那篇论文今天看来不怎么样，所以我也就不推荐你们读了。不过打那时起，我就对神经网络以及它们从数据中学习的能力，非常着迷。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;21 岁时，吴恩达获得了卡内基梅隆大学的计算机科学学士学位。之后他在 1998 年获得了麻省理工学院的硕士学位，并于 2002 年获得了加州大学伯克利分校的博士学位，导师是 Michael I. Jordan。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在拿到博士学位后，吴恩达开始了在斯坦福大学的工作。后来，他成为了斯坦福大学计算机科学系和电子工程系副教授，人工智能实验室主任。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2010 年，时任斯坦福大学教授的吴恩达加入谷歌开发团队 X Lab，作为顾问。他是较早从学界加入产业界的研究人员之一。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从 2010 年到今年，随着人工智能、深度学习的兴起，越来越多优秀的学术界人才被企业所拉拢——Geoffrey Hinton、Russ Salakhutdinov、李飞飞。这一现象的加剧引起了业内的一阵恐慌，害怕优秀学者的流失会影响人工智能人才的造血。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谈到这一现象吴恩达观察到了不一样的角度，他认为近期的另一个变化就是公司也在创造人工智能人才，可能创造人才的规模要比学校更大：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「因为极大的缺乏人才，所以百度这样的公司的招聘部门都投入很大。这也是为什么百度里有无数关于深度学习、计算机视觉、自然语言处理、语音识别的课程，我们会常规性的训练职员，从而让他们更有所长。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;事实上，百度硅谷办公室已经有了这样的荣誉：硅谷学习人工智能的地方。所以，我认为除了大学之外公司成为创造更多人工智能人才的地方来帮助我们做激动人心的工作，这是一个非常有前景的发展，这就是我们所面临的。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;教学课程，是吴恩达的另一荣誉。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2008 年，吴恩达发起了「Stanford Engineering Everywhere」（SEE）项目，把斯坦福的许多课程放到网上，供免费学习。他自己也教了一些课程，如机器学习课程，包含了他录制的视频讲座和斯坦福 CS299 课程的学生材料。2011 年 8 月时，Coursera 作为一家公益创业公司正式成立，并逐渐成为了世界上最大的 MOOC 平台之一。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;同样是 2011 年，吴恩达与 Jeff Dean、Greg Corrado 联合创立了谷歌大脑。当时，吴恩达向谷歌 Jeff Dean 提及了自己在 X 内部实验的项目 Project Marvin，然后他们用自己的空余时间催生出了谷歌大脑（后来拉来了有神经科学背景的 Greg Corrado）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在谷歌大脑期间，最出名的案例就是他们所开发的人工神经网络通过观看 YouTube 视频，自主学会识别哪些是关于猫的视频。这个案例为人工智能领域翻开崭新一页。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从2002年博士毕业任教到现在成为百度首席科学家，吴恩达 14 年中在谷歌、斯坦福、百度都带领、扶持过一些成功的人工智能团队。基于这些经验，他近期曾在哈佛商业评论上撰文呼吁大部分有数据但缺乏深度人工智能知识的公司来&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720432&amp;amp;idx=2&amp;amp;sn=83ae4ce687079fe40c273abad7a34603&amp;amp;chksm=871b0cceb06c85d8d48047e61a3782dbea3e926a4282e50986cb2fb3014e4dc23cb7ec031d0c&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720432&amp;amp;idx=2&amp;amp;sn=83ae4ce687079fe40c273abad7a34603&amp;amp;chksm=871b0cceb06c85d8d48047e61a3782dbea3e926a4282e50986cb2fb3014e4dc23cb7ec031d0c&amp;amp;scene=21#wechat_redirect"&gt;设立首席人工智能官&lt;/a&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他对我们解释说，「我们都知道人工智能意味着什么，在目前的发展环境下，公司需要重新考虑自身业务如何与新技术相结合以获得竞争优势。越来越多的公司雇佣了熟悉人工智能的高管，我认为这很快就会形成一个特定的职位。我认为有专人来从事这一工作会使公司的运转效率更高，这个人需要拥有足够的技术知识，对人工智能的发展有独到的见解。所以首席人工智能官需要通晓人工智能的运行方式，而不仅仅是具有技术知识，它需要有开阔的眼界，明白如何将技术用于促进商业发展，为公司带来效益。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心原创文章，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 18 Dec 2016 10:36:44 +0800</pubDate>
    </item>
    <item>
      <title>学界 | OpenAI MiniWoB环境介绍：与网站交互的强化学习代理基准</title>
      <link>http://www.iwgc.cn/link/3966676</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自OpenAI&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Mini World of Bits，简称 MiniWoB，是一个用于与网站交互的强化学习代理的基准。其代理可以感知小网页（210x160 像素）的原始像素和产生键盘和鼠标动作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;iframe class="video_iframe" data-vidtype="2" style="   z-index:1; " height="375" width="500" frameborder="0" data-src="https://v.qq.com/iframe/preview.html?vid=g1311y86ym2&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0" allowfullscreen=""&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该环境用 HTML/Javascript/CSS 写成，设计的目的是为了测试代理与常见网页浏览器元素的交互能力，这些元素包括按钮、文本框、滑块、日期选择器等等。这个基准的环境可以通过 OpenAI Universe 获取。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;发布地址：&lt;span&gt;http://alpha.openai.com/miniwob/index.html&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;环境预览地址：&lt;span&gt;http://alpha.openai.com/miniwob/preview/index.html&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;OpenAI Universe：&lt;span&gt;https://universe.openai.com&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;MiniWoB 环境&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中的每一个环境都是一个 210 像素高、160 像素宽的 HTML 网页（即与 ATARI ALE 模拟器的尺寸相同）。其最顶上的 50 个像素（黄色背景）包含了任务查询——一个关于代理应该在坏境所做的事情的描述。该环境的逻辑是用 Javascript 编写的，其会监控事件并分配奖励（reward）。我们认为 MiniWoB 就类似于是视觉识别领域的 MNIST 数据集，其中的这些环境很小、是自包含的（self-contained）、并且含有许多代理在浏览互联网时需要克服的挑战。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该基准中的任务包含许多常见的 UI 元素，范围涵盖从简单（比如点击取消按钮）到复杂（比如，搜索从 SFO 到 LAX 的 2016 年 12 月 5 日的航班并预定最便宜的机票）等各种难度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9kibMYlPbZoY8fPoWnM3PWaSXwdRPsP44sE7mDkthfnibBFMXmFn5sgC20rBSDLBq0QKXqgM0o1t3g/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;基准&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;MiniWoB 基准包含了一系列训练/测试分开的环境。其终极目标是在无需太多交互步骤的情况下在测试环境上良好地执行任务。被测试的模型可以在训练环境中进行不限次数的预训练。我们也计划发布训练环境的演示，因为许多模型如果仅靠强化学习，可能难以取得良好的效果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;12/05/2016, Version 0&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;80 environments&lt;/span&gt;&lt;/td&gt;&lt;td style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);" align="center" valign="middle"&gt;&lt;span&gt;train/test split COMING SOON&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;贡献环境。因为该环境目前还非常小，而且也很容易通过 Javascript/HTML/CSS 书写，所以我们也鼓励社区为未来该基准的发行版提供贡献。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;MiniWoB 的完整源代码将在未来几周通过 GitHub 发布，所以贡献也将变得非常方便。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;启动代码&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些环境都被整合到了 OpenAI Universe 之中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了训练强化学习代理，我们调整了运行 MiniWoB 环境的 Universe 指令。下面的简单代码可以用来创建一个可以以 5 FPS 的速度在 MiniWoB 的 160x160 像素的「游戏」区域随机点击的代理：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9kibMYlPbZoY8fPoWnM3PWaSrXQXmy9Fg0nmhqDeTNSAiaoWicMmOjkt799icYTeqhts0RRcKLnPMjdw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;原文链接：http://alpha.openai.com/miniwob/index.html&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;br/&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;br/&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 18 Dec 2016 10:36:44 +0800</pubDate>
    </item>
    <item>
      <title>专栏 | 当AI遇上AR ——从微软HoloLens Processing Unit (HPU)说起</title>
      <link>http://www.iwgc.cn/link/3966677</link>
      <description>&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心专栏&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：痴笑&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;AI+AR&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能（AI）与增强现实（AR）的概念在最近乃是当红炸子鸡，火遍大江南北。AI 与 AR 的概念区别不小，但是也有不少交集。目前，AI 最热门的应用就是在计算机视觉（Computer Vision，CV）领域，而 AR 的实现（图像渲染）自然也离不开 CV 。举个例子吧！《龙珠》想必大家都看过（如果你没看过说明你很年轻！大叔很羡慕你！），里面的战斗力探测眼镜就是 AI + AR 的一个极好例子：战斗力探测眼镜用基于 CV 的 AI 首先做物体识别，把眼镜视野里面的战斗对象与背景区分开，然后用一套AI算法去评估该对象的战斗力，最后把战斗力标注到眼镜视野里的目标周围（什么？战斗力只有5？），从而实现 AR 。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW97Eu3kQ28xCXnW6b2iagC06hc1lYdnJHWPic1nEf4GOYicVhaDtNoRmRQ2flnp95ickTGJWq6GsqtxMw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;《龙珠》里的战斗力探测眼镜是AI+AR应用的一个极好例子&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;HoloLens 与 HPU&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如今，实现战斗力探测的 AI + AR 技术已经不再为赛亚人所独有，地球人也拥有了这项技术！例如，微软的 HoloLens 在已公布的 AI + AR 设备中可谓佼佼者，凭借微软的金字招牌以及酷炫的演示动画吸引了无数科技爱好者的眼球。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前，用于 AI / AR 的处理器架构该如何设计仍然处于探索阶段，Intel 想借机推自己基于 CPU 的方案，Nvidia 想利用 GPU 弯道超车，而 Qualcomm 也拼接 Snapdragon 平台在一边虎视眈眈。在今年的商用芯片峰会 HotChips 上，微软公布了应用在 HoloLens 中的处理器芯片（HoloLens Processing Unit, HPU）。HPU 的架构和 CPU 以及 GPU 都不相同，可谓是开创了 AI / AR 领域芯片的新范式。我们采访了 UCLA 从事人工智能芯片和硬件研究的 Li Du, Yuan Du 以及 Yilei Li 博士，接下来将详细分析 HPU 芯片架构并展望未来 AI / AR 芯片设计中的范式转换。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW97Eu3kQ28xCXnW6b2iagC060A0S4Jtoic6M4ls2LfO8KzvegU8ghALZCoOlc38VMZ67EDibFUd3wHuw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;em&gt;&lt;span&gt;HoloLens可以实现众多AI/AR应用&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微软公布的 HoloLens 系统架构如下图所示。就在绝大多数移动设备的处理器都基于 ARM 结构的今天，HoloLens 的主处理器使用的仍然是 Intel 的 Cherry Trail SoC（包括CPU与集成的GPU），让人感叹维持了二十余年的 Wintel 联盟坚不可破。微软最新公布的 HPU 也可以在图上看到，HPU 严格来说是一款协处理器，其作用是协助主处理器加速运算一些专门的运算（如用于 CV 的矩阵运算，用于 CNN 的卷积运算等）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 UCLA 有多年异构运算与互联研究经验的 Yuan Du 博士表示，「由于 CPU 必须要考虑通用性而无法对一些 AR / VR 运算进行优化，因此在应用场景中会大量遇到的专门运算如果都交给 CPU 做会使系统的整体性能变得很差，于是我们需要设计一款专用的加速器来协助加速这些运算，微软在这里的加速器就是 HPU 。HPU 通过 PCIe 高速接口与主处理器所在的 SoC 通信，不过 PCIe 的功耗其实是比较大的，未来可望会用上更先进的互联技术。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微软公布的 HPU 处理能力达到每秒 1T（10^12）次像素运算，功耗则小于 4W。HPU 能够融合来自 5 个摄像头、一个深度传感器以及运动传感器的输入信息，将信息压缩并传送到主处理器。此外 HPU 还能实现 AI 手势识别。据说微软曾评估了来自于各大厂商的商用芯片，却没有找到任何一款产品能满足系统算法对性能的要求。这款微软自己开发的 HPU 是采用台积电 28nm 工艺，内含 24 颗可重配置的 Tensilica 数字信号处理器（DSP）核心以及高达 8MB 的 Cache。除此以外，还有专用加速器用于给各类专门任务加速。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW97Eu3kQ28xCXnW6b2iagC06Uc41aickmPqtI5lrRAFNaCF7rXSz2KBZJ4e5q3FCtvheJ6xIicBqGDzQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;HoloLens 系统架构，HPU 与显示设备紧密耦合并且和主处理器 Intel Cherry Trail SoC 由高速 PCIe 接口互联&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;HPU 有何不同&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果仔细观察 HPU 架构，会发现它与目前借着 AI / AR 及人工智能风口飞地很高的 GPU 有点像，但并不相同。说它们“有点像”是因为 HPU 和 GPU 都有不少计算核心，这样可以实现数据的并行处理。HPU 和 GPU 要处理的都是画面中的一个个像素，而像素之间其实并没有关联性，因此可以由并行处理来提高执行效率。与之相对的是 CPU，为了照顾通用性 CPU 无法放置大量的计算核心来实现大规模并行运算，因此完全用 CPU 来处理 AI / AR 操作会导致速度很慢。另一方面，HPU 与 GPU 之间也有很大的不同。首先，HPU 上的计算核心是可配置 DSP 而非类似 Nvidia GPU 里面的 CUDA core。另外，HPU 的片上Cache（用于快速存取数据）高达 8MB，远大于 GPU 的片上 Cache 容量（Tegra X1 上Cache 仅有 2 MB）。这是为什么呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Du Li 和 Yilei Li 博士表示，「归根到底，这些都是因为应用的区别。GPU 就像一艘巨轮，设施豪华（运算精度高），耗油巨大（功耗巨大），在处理海量的数据时可以实现非常高的吞吐率，但是实时性并不好：你可以想象巨轮在行驶前需要做许多准备工作，并不是指令一下说走就走（延迟较大）。当然在需要处理的数据量足够大时，这些准备时间相对于计算时间来说可以忽略不计。HPU 就像一艘小船，轻便而省油（功耗较小），而且指令一下可以说走就走（延迟较小），虽然运算的吞吐量不能和 GPU 相比但是实时性很好。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 HoloLens 中，实时性非常重要：例如，在你的头部移动时，你显示的内容也要相应改变，如果在你头部移动和现实内容改变之间存在明显延迟则使用者会感到晕眩（这也是为什么很多人在玩 3D 游戏时会头晕的原因）。另外，由于 HoloLens 是移动设备，因此芯片的功耗需要严格控制，功耗巨大的 GPU 架构并不适合。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW97Eu3kQ28xCXnW6b2iagC06NxbjiaMpOSe90lusPmNAejnVjtwub9QKkFEZgSaJVr98GL7Djk07PLA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;HPU 芯片结构，可见 DSP 计算核心以及大容量片上 Cache（SRAM）&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;让我们来看看 HPU 和 GPU 的几点不同是如何对应应用场合的要求的。首先，HPU 选择了可重配置的 DSP。使用可重配置的 DSP 可以根据应用场合切换配置来实现性能－功耗的最优折衷，可以说 HPU 使用可配置 DSP 是为了实现在给定功耗下的最佳性能。其次，HPU 使用很大的片上 Cache。使用片上 Cache 可以实现低延迟数据存取，从而满足HoloLens 对于实时性的要求。HPU 与显示设备紧密耦和也能帮助降低延迟。与之相反，通常 GPU 的片上 Cache 都较小，而绝大部分数据都存在片外 DRAM 中并使用高速 GDDR 接口实现数据传送。这样做既增大了数据存取延时又消耗了很大的功耗，并不适合 HoloLens 这样的应用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，值得注意的是，HPU 还集成了许多专用加速器。这些专用加速器可以帮助 HPU 快速执行一些算法（单靠 DSP 往往无法满足这些算法的性能需求）。这使得 HPU 又有点像 Qualcomm 的 Snapdragon SoC，因为 Snapdragon 也是在芯片上会集成许多特定算法（如视频编解码，AES 加密）的加速器。这些加速器的功耗往往很低，但是使用这些加速器也是要付出代价的：专用加速器在不需要使用的时候会处于闲置状态无法用做其他用途，这部分用于专用加速器的芯片面积在加速器闲置的时候相当于是浪费了。因此，专用加速器就能量而言效率非常高（即完成运算需要的能量很小），但是就芯片面积而言效率很差（即增加了芯片成本）。因此集成哪些专用加速器需要经过性能－功耗－成本三方面的仔细折衷。HPU 集成的这些专用加速器相信会在一些关键的应用中起很大的加速作用，从而保证 HoloLens 能以很高的性能实现算法同时消耗很低的功耗。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;根据微软的数据，使用专用加速器配合 DSP 可以实现 200 倍以上的性能改善，效果可谓惊人。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;芯片 IP 随着 AI / AR 概念变得更重要&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;近来 AI / AR 技术发展非常快。为了实现新的算法以及满足新的应用需求，往往要速度更快功耗更低的硬件，这就需要相应的芯片也能快速迭代以满足算法和应用的需求。另一方面，许多传统只在软件领域活动的巨头（如 Google，Facebook）在这波风潮里也在向着硬件领域蠢蠢欲动，为了使自己的 AI / AR 硬件性能达标，使用通用的 CPU / GPU 很困难，必须有定制芯片。以往的先三年技术积累再开始量产芯片的做法根本无法跟上现在的高速节奏，必须有能从头开始在一年内就交付的快速芯片设计方法。为了满足这两个需求，使用芯片 IP 几乎是必须的。当使用购买的芯片 IP 时，设计者只需把精力集中在整体架构设计上，所有没有时间或者资源做具体设计的芯片模块都可以向第三方购买。相比从头设计所有模块，基于 IP 的芯片设计方法大大加快了设计速度，而整个芯片中第三方 IP 所占的比例也会越来越多。在之前的芯片巨头靠出售芯片盈利，而芯片中每一个第三方 IP 都要付出权利金，因此高通这类公司不到万不得已不会使用第三方 IP，而是会倾向于自己做模块。举例来说，高通芯片面积中使用第三方 IP（不包括ARM的架构授权）的比例通常小于 5%。然而，这些从软件领域过来做硬件的巨头制造芯片并不指望靠芯片盈利，而是要用在自家硬件里。对于它们来说，硬件是否能盈利甚至都不重要，它们需要的是营造自己的生态圈抢占市场。因此，对它们来说芯片最关键的是性能要强，而且上市速度要快，所以它们完全不介意买许多第三方 IP。前面讨论的微软 HPU 就是一个极好的例子。微软的芯片设计团队相对于 Intel 和高通等半导体业界巨头来说非常小，但是借助于从 Cadence 购买的 Tensillica DSP IP，微软仍然能够在短时间内快速完成高性能大型芯片的设计，而且第三方 IP 占的芯片面积高达 60% 以上。可以说，随着 AI / AR 概念越来越普及，相应的芯片 IP 也会越来越热门。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除了 Tensillica 之外，也有其他公司在提供 AI / AR 方面的芯片 IP。老牌 DSP 和通讯 IP 供应商最近发布了针对 AI 和 CV 的 XM6 DSP 平台。该 DSP 平台为深度学习优化，从而可以较高效地完成 AI / AR 运算。在各大高校和科研机构，AI IP 的开发也是一个热点，例如 MIT 由 Yu-Hsin Chen 开发的 Eyeriss 深度学习加速器 IP 可以以很低的功耗完成高速卷积运算，自从在 2015 年的 ISSCC（国际固态半导体电路会议）上发表后收到了巨大的关注。此外，UCLA 的 Yilei Li，Li Du 和 Yuan Du 所在的团队也在积极开发一种新架构的 AI 加速器，这种加速器采用类似乐高积木的形式，每一块芯片完成一层网络的部分运算，通过把不同的芯片用封装内互联连接起来，可以实现任意大小的网络，同时可以减小因访问内存造成的性能损失。我们预期在不久的将来，AI/AR IP 领域会越来越红火。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;结语&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;作为 AI / AR 处理器芯片的先锋，HPU 的架构与 GPU 相似（多核并行运算）但又有很大不同（使用定点 DSP 和大容量片上 Cache），另一方面它又从用于手机的多媒体 SoC（如 Snapdragon）借鉴了集成专用加速器的方法，可谓是博采众长又不拘泥于一家之说。另外，为了追上算法和应用的发展，AI / AR 芯片可能会大量使用第三方芯片 IP。我们预期在未来的 AI / AR 处理器芯片架构中看到如下的设计范式转移：GPU 追求高吞吐量-&amp;gt; AI / AR 芯片追求低延时；CPU／GPU 追求通用性-&amp;gt; AI / AR 处理器为特定应用集成大量专用加速器；CPU / GPU 模块多为自己设计-&amp;gt; AI / AR 处理器大量使用第三方 IP。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心发布，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 18 Dec 2016 10:36:44 +0800</pubDate>
    </item>
    <item>
      <title>前沿 | 源于自然高于自然：MIT正在打造生物启发式机器人</title>
      <link>http://www.iwgc.cn/link/3966678</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自MIT&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;机械工程师 Sangbae Kim 打造了可用于灾难响应的类似动物的机器。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;也许不久的将来，灾难地区的应急响应就可能会包含四条腿的、狗一样的机器人，它们可以穿过火灾区域或地雷区域，然后以后腿支撑立起来转动门把手或打穿墙壁。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这样的机器人救护员可能已经准备好在未来 5 到 10 年内实现部署了，MIT 机械工程副教授 Sangbae Kim 说。他与 Biomimetic Robotics Laboratory（仿生机器人实验室）的同事们正在向着这个目标而努力——借鉴生物力学的原理、人类决策和机械设计，打造 Kim 所说的能够执行开门、打穿墙壁或关闭阀门等「真实的物理工作」的机器人。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9kibMYlPbZoY8fPoWnM3PWaMVBPgPMD5uRLjwgZKJicG3oa463Zfic2FN3LwWlJc9zXtbR6DrNX9qfA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt; Sangbae Kim，图片来源：Ian MacLellan&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「假设在一栋建筑里面出现了毒气泄漏，你需要去关闭里面的一个阀门，但是让人进去关闭会太过危险。」Kim 说，「目前，还没有什么单个机器人能够完成这个任务。我希望能够打造有希望比人类做到更多并且能在我们的生活中提供帮助的应急响应机器人。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了做到这一点，今年刚获得终身职位的 Kim 正在试图将其实验室的两个主要项目融合到一起：MIT Cheetah（一种重 70 磅的四腿机器人，它可以自动奔跑和越过障碍）和 HERMES（一种远程操控的两腿机器人，需要一个人类操作员进行远程控制，类似于机器人「阿凡达」）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我想象会有一种能够做一些体力的、动态的工作的机器人，」Kim 说，「对于研究中你感到兴奋的部分，每个人都在尝试寻找重叠区域。很多人喜欢看体育节目，因为有假说认为，当你看到别人那么劲爆地运动时，你大脑里面的『镜像神经元（mirror neurons）』会激活，同时你也会感受到那种兴奋感。对于我来说，当我的机器人能够动态地执行任务和保持平衡时，我也会感到真正地兴奋。这样的感觉激励着我的研究。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;一个军队教官变成的机器人学家&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Kim 出生于韩国首尔，他说他母亲记得他从小就是一个爱思考的人。「只要是有螺丝的东西，都会被我拆开，」Kim 说，「而且她说刚开始的时候，几乎所有东西都被我弄坏了。后来，情况就开始好转了。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;后来他进入了首尔的延世大学学习机械工程。在大学第二年，依照韩国的强制兵役制度，他和他的其他男性同学加入了韩国军队，他在那里担任了两年半的演习军官。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们教新兵了解成为一名军人的所有细节，比如如何穿衬衫和裤子、扣腰带、以及甚至在走路的时候该如何握拳，」Kim 回忆道，「早上 5:30 就要起床，直到晚上 10:30 所有人都快累得睡着了才结束，中间没有任何休息。教官是出了名的刻薄，我觉得这是有原因的——他们必须要跟得上安排得很紧的日程。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;服完兵役之后，Kim 回到延世大学继续学习，并开始被机器人学所吸引，尽管当时该校还没有这个学科的正式项目。他最后参加了一个学生比赛制造能执行特定任务的机器人的班级项目，这些任务包括：夺旗、比赛、机器人对抗，这有点类似于 MIT 受欢迎的 Course 2.007 (Design and Manufacturing)——现在 Kim 也是这门课的教员之一。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Kim 说：「这个班级真的给了我的事业很大的激励，让我在机器人学领域扎下了根。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;iframe class="video_iframe" data-vidtype="1" style="   z-index:1; " height="375" width="500" frameborder="0" data-src="https://v.qq.com/iframe/preview.html?width=500&amp;amp;height=375&amp;amp;auto=0&amp;amp;vid=e035686ormu" allowfullscreen=""&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;仿生机器人的梦想&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在他大学的最后一年，Kim 开发了一种相对廉价的 3D 扫描器，然后他和另外三位同学一起创立了一家商业化这个设备的公司 Solutionix，其产品是在 Kim 的设计上的扩展。但是当该公司开始进入融资的早期阶段时，Kim 又有了新想法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Kim 说：「当我把它做出来以后，我就失去了兴奋感，因为我已经完全搞懂它了。我喜欢把事情搞明白。在公司起步一年后我意识到了这一点：我应该从事开发早期阶段的研究，而不是改进成熟的产品。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这款产品首批发货后不久，他就离开了韩国来到了斯坦福大学，他就读了一个机械工程研究生项目。在那里，他首次尝到了自由设计的滋味。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「那真是一次改变人生的经历，」Kim 说，「和环境非常保守的韩国比起来，这里有更自由、更有创造性的环境。这是一个相当大的文化冲击。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Kim 加入了 Mark Cutkosky 的实验室，这位工程学教授一直在致力于寻找设计生物启发的机器人的方法。特别值得一提的是，该团队当时正在试图开发一款模仿壁虎攀爬的机器人，其使用了一种特殊的毛来帮助机器人停留在竖直的墙面上。Kim 对这种毛机制（hairy mechanism）进行了调整，发现它真的有效。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「那是凌晨 2 点半，我正在实验室里，我睡不着，我已经尝试了很多东西，我的心在怦怦直跳。」Kim 回忆说，「在一些带有大窗户的门上，（这个机器人）爬得非常顺滑，它使用了世界上第一种定向粘合剂，那是我发明的。我很高兴地将其展示给其他人看，那天晚上我给他们全都发了一段视频。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他和他的同事成立了一家创业公司来进一步开发壁虎机器人。但再一次，Kim 失去了在实验室里的那种快感。不久之后他就离开了这家公司，进入哈佛大学开展博士后研究。在哈佛大学，他帮助设计了 Meshworm——一种柔性的自动机器人，能够像蚯蚓一样扭曲地爬过地面。然后，Kim 将自己的目光放到了更大型的设计上。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我开始不再研究小型机器人，因为它们很难做到一些真实的体力上的工作。」Kim 说，「所以我决定开发一款更大的四足机器人来执行人类水平的任务——这是一个长期的梦想。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;寻找设计原理&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2009 年，Kim 接受了 MIT 机械工程系的助理教授职位，然后他成立了自己的仿生机器人实验室（Biomimetic Robotics Lab）并设定了一个特别的研究目标：设计和制造一个四足猎豹机器人。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们选择猎豹，因为它是最快的陆地动物，所以我们了解它的特征是最好的，但也有很多动物与猎豹有相似之处。」Kim 说，「它们有一些微妙的差别，但你可能不能从这些特征中了解到设计原理。」事实上，Kim 快速研究了其中一些案例，发现在机器人上重现特定的动物行为可能不是最好的选择。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们的案例中一个很好的例子是马的奔跑。」Kim 说，「在一匹骏马上，这是很美的，你还能听到哒哒的马蹄。我们对此很着迷，想要重现它。但事实证明马的奔跑方式对机器人来说用处不大。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;动物往往都会偏爱各自特定的步态，因为这涉及到肌肉、关节和骨头的复杂相互作用。然而，Kim 发现，由电机驱动的猎豹机器人表现出了与其灵感来源非常不同的动力学（kinetics）。比如说，在高功率情况下，该机器人能够以 14 英里每小时的速度稳定前进——比自然界的任何动物都快得多。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们必须理解什么是我们所需的主导原理，并且要问：那是生物系统的一个局限性吗，或者我们能否在工程领域实现它？」Kim 说，「找到能够囊括动物和机器之间的差异的有用原理是一个非常复杂的过程。有时候执迷于动物的特征和特性会妨碍你在机器人领域取得进步。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;一个「秘方」&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除了在实验室打造机器人，Kim 也在 MIT 任教，包括他已经任教了 5 年的 2.007。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「这仍然是我最喜欢的班级，这里的学生真正已经脱离了『家庭作业-考试』的模式，他们有机会自己亲自上手创造自己的项目。」Kim 说「今天的学生在使用 3D 打印和乐高的创客运动中成长起来，他们在等待 2.007 这样的东西。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Kim 还教授着一门他在 2013 年创立的课程——生物启发机器人学（Bioinspired Robotics），参加这个课程的 40 位学生 4 人一组根据生物力学和动物运动方式设计和制造机器人。过去的一年，学生们在 Lobby 7 上展示了他们的设计，包括一台投掷机、一个轨迹优化的踢球机和一个跳跃在跑步机上的袋鼠机器。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「在许多人类的运动中存在一些秘方，因为肌肉有非常特别的性质，如果你没有很好地了解它们，你就会表现很糟，让自己受伤。」Kim 说，「这全部都基于肌肉运动，而我在努力弄懂世界中的这些事物，并将它们用在机器人世界中。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文链接：http://news.mit.edu/2016/faculty-profile-sangbae-kim-1216&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 18 Dec 2016 10:36:44 +0800</pubDate>
    </item>
    <item>
      <title>一周论文 | 提高seq2seq方法所生成对话的流畅度和多样性</title>
      <link>http://www.iwgc.cn/link/3966679</link>
      <description>&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em;"&gt;&lt;span&gt;&lt;strong&gt;引言&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对话系统是当前的研究热点，也是风险投资的热点，从2016年初开始，成立了无数家做chatbot、语音助手等类似产品的公司，不管是对用户的，还是对企业的，将对话系统这一应用推到了一个新的高度。seq2seq是当前流行的算法框架，给定一个输入，模型自动给出一个不错的输出，听起来都是一件美好的事情。seq2seq在对话系统中的研究比较多，本期PaperWeekly分享4篇的paper notes，涉及到如何提高所生成对话的流畅度和多样性，使得对话系统能够更加接近人类的对话。4篇paper如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1、Sequence to Backward and Forward Sequences: A Content-Introducing Approach to Generative Short-Text Conversation, 2016&lt;br/&gt;2、A Simple, Fast Diverse Decoding Algorithm for Neural Generation, 2016&lt;br/&gt;3、DIVERSE BEAM SEARCH: DECODING DIVERSE SOLUTIONS FROM NEURAL SEQUENCE MODELS, 2016&lt;br/&gt;4、A Diversity-Promoting Objective Function for Neural Conversation Models, 2015&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em; margin-bottom: 10px;"&gt;&lt;span&gt;&lt;strong&gt;Sequence to Backward and Forward Sequences: A Content-Introducing Approach to Generative Short-Text Conversation&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Lili Mou, Yiping Song, Rui Yan, Ge Li, Lu Zhang, Zhi Jin&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em;"&gt;&lt;span&gt;&lt;strong&gt;单位&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Key Laboratory of High Confidence Software Technologies (Peking University), MoE, China&lt;br/&gt;Institute of Software, Peking University, China&lt;br/&gt;Institute of Network Computing and Information Systems, Peking Univerity, China&lt;br/&gt;Institute of Computer Science and Technology, Peking University, China&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em;"&gt;&lt;span&gt;&lt;strong&gt;关键词&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;content-introducing approach&lt;br/&gt;neural network-based&lt;br/&gt;generative dialogue systems&lt;br/&gt;seq2BF&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em;"&gt;&lt;span&gt;&lt;strong&gt;文章来源&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;arXiv, 2016&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em;"&gt;&lt;span&gt;&lt;strong&gt;问题&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;使用引入内容方法，用于处理基于神经网络的生成式对话系统&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em;"&gt;&lt;span&gt;&lt;strong&gt;模型&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglDIqGiccAGHDDzliawRIHnnAvA8jnQzrQwczgSoE8ATkkbtLzujgaK1Yah29QLxaicELx3G5n1ibhLXA/640?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该模型由两部分组成：&lt;br/&gt;1、use PMI to predict a keyword for the reply&lt;br/&gt;使用逐点互信息(PMI)进行预测，选取PMI值最大的单词作为回答中的关键词，该关键词可以出现在回答语句中的任意位置。&lt;br/&gt;&lt;/span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglDIqGiccAGHDDzliawRIHnnA65mrbuO9DfLfp72jVsTzFSboRcCUPcib7cic0ECJGaibGqWfu6iaPRDPpw/640?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2、generate a reply conditioned on the keyword as well as the query&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使用sequence to backward and forward sequences(seq2BF)模型来生成包含关键词的回答。以该关键词为基点，将回答语句划分为两个序列：&lt;br/&gt;(1) 反向序列：关键词左侧的所有单词以逆序排列&lt;br/&gt;(2) 正向序列：关键词右侧的所有单词以顺序排列&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;seq2BF 模型具体工作如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;(1) 使用 seq2seq 神经网络将问题编码，仅对关键词左侧的单词进行解码，逆序输出每个单词&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;(2) 使用另一个seq2seq模型将问题再次编码，在给定上步中解码后的逆序单词序列下，对回答中的剩余单词进行顺序解码，输出最终单词序列&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglDIqGiccAGHDDzliawRIHnnAkk8wGystS3cEGjUZ6lkL2icoq4HRCCf41gndnvX4qjBUALxawKzrA0w/640?wx_fmt=png"/&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em;"&gt;&lt;span&gt;&lt;strong&gt;资源&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Dataset：&lt;/span&gt;&lt;a target="_blank" rel="external" style="color: rgb(67, 149, 245); max-width: 100%; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important; text-decoration: underline;"&gt;&lt;span&gt;http://tieba.baidu.com&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em; margin-bottom: 10px;"&gt;&lt;span&gt;&lt;strong&gt;相关工作&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;1、 Dialogue Systems&lt;br/&gt;(1) (Isbell et al., 2000; Wang et al., 2013) retrieval methods&lt;br/&gt;(2) (Ritter et al., 2011) phrase-based machine translation&lt;br/&gt;(3) (Sordoni et al., 2015; Shang et al., 2015) recurrent neural networks&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2、 Neural Networks for Sentence Generation&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;(1) (Sordoni et al., 2015) bag-of-words features&lt;br/&gt;(2) (Shang et al., 2015) seq2seq-like neural networks&lt;br/&gt;(3) (Yao et al., 2015; Serban et al., 2016a) design hierarchical neural networks&lt;br/&gt;(4) (Li et al., 2016a) mutual information training objective&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;简评&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本文的创新点在于，不同与目前普遍存在的从句首到句尾顺序生成目标单词的方法，引入逐点互信息方法来预测回答语句中的关键词，使用seq2BF机制确保该关键词可以出现在目标回答语句的任意位置之中并确保输出的流利度，相比于seq2seq的生成方法显著地提升了对话系统的质量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em; margin-bottom: 10px;"&gt;&lt;span&gt;&lt;strong&gt;A Simple, Fast Diverse Decoding Algorithm for Neural Generation&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em;"&gt;&lt;span&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Jiwei Li, Will Monroe and Dan Jurafsky&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em;"&gt;&lt;span&gt;&lt;strong&gt;单位&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Stanford&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em;"&gt;&lt;span&gt;&lt;strong&gt;关键词&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;seq2seq, diversity, RL&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em;"&gt;&lt;span&gt;&lt;strong&gt;文章来源&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;arXiv, 2016&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em;"&gt;&lt;span&gt;&lt;strong&gt;问题&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;seq2seq模型decoder时改进beam search，引入惩罚因子影响排序结果，并加入强化学习模型来自动学习diversity rate，使得解码出的结果更具多样性&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em;"&gt;&lt;span&gt;&lt;strong&gt;模型&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglDIqGiccAGHDDzliawRIHnnAVtIkYTCbksM2PXu0u6gRgOeibsJePM1zaSuc6OHlMQKGv0kR6s1zBbw/640?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对比标准beam search，本模型引入惩罚因子，公式如下&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglDIqGiccAGHDDzliawRIHnnASpdHCExQevcBq87OTvbWP8LgAibZaX8L3uYbQ0AB7s9UePCk2A9Mwtw/640?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中$\gamma$称为diversity rate，k’范围为[1,k]，K为beam size&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;强化学习模型中，策略为&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglDIqGiccAGHDDzliawRIHnnAGQJiap4ETOibsxjqCe3cJ1myEodt59X9A5VEHpsxwXLV7GlQv3VfelZw/640?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;reward为评价指标，例如机器翻译中的BLEU值等&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em;"&gt;&lt;span&gt;&lt;strong&gt;资源&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;1、回复生成实验数据集：OpenSubtitles&amp;nbsp;&lt;/span&gt;&lt;a target="_blank" rel="external" style="color: rgb(67, 149, 245); max-width: 100%; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important; text-decoration: underline;"&gt;&lt;span&gt;https://github.com/jiweil/mutual-information-for-neural-machine-translation&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;span&gt;（代码模型可从作者另外一篇文章的源码稍加改动）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2、机器翻译数据集：WMT’14&amp;nbsp;&lt;/span&gt;&lt;a target="_blank" rel="external" style="color: rgb(67, 149, 245); max-width: 100%; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important; text-decoration: underline;"&gt;&lt;span&gt;http://www.statmt.org/wmt13/translation-task.html&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em;"&gt;&lt;span&gt;&lt;strong&gt;相关工作&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglDIqGiccAGHDDzliawRIHnnA0UzpFpbxTbA8SSIicqkRA4pvrUQbCRjuCNiadjsILicDKT1iaWZcBMg8Nw/640?wx_fmt=png"/&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em;"&gt;&lt;span&gt;&lt;strong&gt;简评&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;本模型的创新点在于引入惩罚因子，使得decoder时对standard beam search算法进行重排序，并引入强化学习模型，自动学习diversity rate。作者分别在三个实验上进行验证，机器翻译、摘要抽取与对话回复生成，实验表明在不同的实验上有不同的表现，但是总体而言本方法能够在一定程度上解码出更具有多样性的句子。（思路简明清晰，对于传统的beam search稍加改动，原文中作者提到在Matlab代码中只改动一行即可）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em; margin-bottom: 10px;"&gt;&lt;span&gt;&lt;strong&gt;DIVERSE BEAM SEARCH: DECODING DIVERSE SOLUTIONS FROM NEURAL SEQUENCE MODELS&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em;"&gt;&lt;span&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Ashwin K Vijayakumar, Michael Cogswell, Ramprasath R. Selvaraju, Qing Sun1 Stefan Lee, David Crandall &amp;amp; Dhruv Batra&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em;"&gt;&lt;span&gt;&lt;strong&gt;单位&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Virginia Tech, Blacksburg, VA, USA&lt;br/&gt;Indiana University, Bloomington, IN, USA&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em;"&gt;&lt;span&gt;&lt;strong&gt;关键词&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Beam Search; Diversity; Image Caption; Machine Translation; Visual Question Answer; Chatbot&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em;"&gt;&lt;span&gt;&lt;strong&gt;文章来源&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;arXiv, 2016.10&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em;"&gt;&lt;span&gt;&lt;strong&gt;问题&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;如何改进beam search解码算法，使其在seq2seq模型中可以生成更加丰富的结果？&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em;"&gt;&lt;span&gt;&lt;strong&gt;模型&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;经典的beam search算法以最大后验概率作为优化目标函数，每一个time step只保留B个最优的状态，是一种典型的贪心算法，这个经典算法常常被用于解码可选状态数量多的情形，比如生成对话、生成图片描述、机器翻译等，每一步都有词表大小的可选状态集。seq2seq模型的流行，让这种解码算法的研究变得热门。在生成对话任务时，用经典的beam search会生成类似“我不知道”等这种没有营养的对话，虽然没有语法上的错误，而且可能在一定的评价体系内会得到不错的分数，但实际应用效果太差，因此diversity的研究变得热门。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本文针对diversity的问题，提出了一种改进版的beam search算法，旨在生成更加多样性的话。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglDIqGiccAGHDDzliawRIHnnAR7AS1iaHMC9yu58tPAQcQ8iayGOKiboIVgVt1gPt7GeIdF68oKJ309MqA/640?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;新算法的主要思路是将经典算法中的Beam进行分组，通过引入一个惩罚机制，使得每一组的相似度尽量低，这一项保证了生成的话相互之间差异更大一些，即满足了多样性的需求，在每一组Beam中，用经典的算法进行优化搜索。具体的算法流程如下图：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglDIqGiccAGHDDzliawRIHnnAYOaicnxWKPjp4657WOu0mOTEwmyFsZh8BicbH69JNF2B7tTiarZRHPxCQ/640?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;实验中，用了Image Caption、Machine Translation和VQA三个任务进行了对比，验证了本文算法的有效性，并且对算法中的几个参数进行了敏感度分析，分析了分组数对多样性的影响。&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em;"&gt;&lt;span&gt;&lt;strong&gt;资源&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;1、本文算法torch实现&amp;nbsp;&lt;/span&gt;&lt;a target="_blank" rel="external" style="color: rgb(67, 149, 245); max-width: 100%; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important; text-decoration: underline;"&gt;&lt;span&gt;https://github.com/ashwinkalyan/dbs&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;span&gt;2、本文在线demo dbs.cloudcv.org&lt;br/&gt;3、neuraltalk2实现&amp;nbsp;&lt;/span&gt;&lt;a target="_blank" rel="external" style="color: rgb(67, 149, 245); max-width: 100%; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important; text-decoration: underline;"&gt;&lt;span&gt;https://github.com/karpathy/neuraltalk2&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;span&gt;4、机器翻译开源实现dl4mt&amp;nbsp;&lt;/span&gt;&lt;a target="_blank" rel="external" style="color: rgb(67, 149, 245); max-width: 100%; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important; text-decoration: underline;"&gt;&lt;span&gt;https://github.com/nyu-dl/dl4mt-tutorial&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em;"&gt;&lt;span&gt;&lt;strong&gt;相关工作&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;相关的工作主要分类两类：&lt;br/&gt;1、Diverse M-Best Lists&lt;br/&gt;2、Diverse Decoding for RNNs&lt;br/&gt;之前Jiwei Li将解码算法的目标函数换成了互信息进行优化解码，对diversity进行了研究。&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em;"&gt;&lt;span&gt;&lt;strong&gt;简评&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;本文研究的问题是一类基础问题，beam search算法作为一种经典的近似解码算法，应用的场景非常多。但在实际应用中，尤其是具体到生成对话、生成答案等任务上，存在一些适应性的问题，比如diversity。只是生成简单而又安全的话对于实际应用没有太多的意义，所以本文的研究非常有意义。本文的实验从三个不同的任务上对改进后的beam search都做了对比验证，非常扎实的结果验证了算法的有效性，并且对几个关键参数进行了敏感度分析，有理有据。同时在github上开源了代码，并且给出了一个在线demo。在评价方面，不仅仅设计了几个自动评价指标，而且用了人工评价的方法对本文算法进行了验证，是一篇非常好的paper，值得学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em; margin-bottom: 10px;"&gt;&lt;span&gt;&lt;strong&gt;A Diversity-Promoting Objective Function for Neural Conversation Models&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em;"&gt;&lt;span&gt;&lt;strong&gt;作者&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Jiwei Li, Michel Galley, Chris Brockett, Jianfeng Gao, Bill Dolan&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em;"&gt;&lt;span&gt;&lt;strong&gt;单位&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Stanford University, Stanford, CA, USA&lt;br/&gt;Microsoft Research, Redmond, WA, USA&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em;"&gt;&lt;span&gt;&lt;strong&gt;关键词&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Sequence-to-sequence neural network models, conversational responses, Maximum Mutual Information(MMI)&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em;"&gt;&lt;span&gt;&lt;strong&gt;文章来源&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;arXiv, 2015&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em;"&gt;&lt;span&gt;&lt;strong&gt;问题&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;使用MMI训练sequence-to-sequence model for conversational responses generation&lt;br/&gt;传统的ML(最大似然估计)在训练sequence-to-sequence model的时候，易产生与输入无关的’safe’ responses(最大似然估计的弊病—-always try to cover all mode of input data)&lt;br/&gt;作者通过使用MMI, 最大化输入与输出的互信息，能够有效避免与输入无关的responses，得到更为diverse的responses.&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em;"&gt;&lt;span&gt;&lt;strong&gt;模型&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;MMI最早在speech recognition中提出并应用(discriminative training criteria). 语音识别中，通常先用ML训练声学模型，然后再接MMI和语言模型，对声学模型进一步调优。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在本文中，作者通过提出MMI用于seq-to-seq model的优化。作者提出了MMI-antiLM和MMI-bidi 两个不同的MMI的formulations. MMI在seq-to-seq的应用中存在decoding的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;MMI-antiLM中，作者通过使用带有权重的LM以生成更为diverse的responses by penalizing first word。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;MMI-bidi中，搜索空间的数目过大，导致expolring所有的可能性在实际中无法实现。作者首先产生N-best list, 然后根据相应的准则函数 re-rank得到的N-best list。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在MMI不同的formulation中，作者通过启发式的设计，使得decoding更为容易且产生的response更为diverse，在相关的数据集上取得了较好的BLEU且产生的response更为diverse。&lt;/span&gt;&lt;/p&gt;&lt;h2 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em; margin-bottom: 5px;"&gt;&lt;span&gt;&lt;strong&gt;简评&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;最大后验概率通常作为优化的目标函数，但很多应用场景中得到的结果并不理想。本文采用了一个新的而且也是其他领域中比较常见的目标函数来替换最大后验概率，在生成对话时得到了更加丰富的结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;h1 style="max-width: 100%; color: rgb(62, 62, 62); text-align: justify; line-height: 1.75em; margin-bottom: 5px;"&gt;&lt;span&gt;&lt;strong&gt;总结&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;对话系统是一个相对高级的、综合性很强的任务，所依赖的基础任务比较多，比如分词、命名实体识别、句法分析、语义角色标注等等。对于规范的中文表达而言，句法分析仍是一个没有解决好的问题，更何况是不那么规范的人话，句法分析的准确性又要下一个level了，随之语义角色标注也得不到好的效果。经典的、基础的任务还有很长的路要走，对话系统这种更难、更复杂的任务相信不是一年、两年就可以突破的事情，虽然现在大热，做的人很多，但就目前的研究水平来看，应该还有很长的路要走。seq2seq是个逃避这些问题的好方法和好思路，但相对来说更加不成熟，而且存在着很多的问题，想通过大量的数据来覆盖所有的问题，是一种不太科学的思路。我想，seq2seq是个好方法，但传统的NLP方法也是必不可少的，而且两者应该是相互补充的。越多的人关注对话系统，就会越快地推动这个领域的发展，希望早日看到靠谱的、成熟的解决方案。感谢@Penny、@tonya、@zhangjun和@皓天 四位童鞋完成的paper notes。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;关于PaperWeekly&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;PaperWeekly是一个分享知识和交流学问的学术组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;微信公众号：PaperWeekly&lt;/span&gt;&lt;/strong&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkSMlEJFo90NY8rCXr3mJMBibduVHxMKSHzQtVkHz8kNwpjCKBiccGuqLE0WpPuAbdtEs6cTF5iabpAQ/640?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微博账号：PaperWeekly（&lt;/span&gt;&lt;a target="_blank" rel="external" style="color: rgb(67, 149, 245); max-width: 100%; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important; text-decoration: underline;"&gt;&lt;span&gt;http://weibo.com/u/2678093863&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&amp;nbsp;）&lt;br/&gt;微信交流群：微信+ zhangjun168305（请备注：加群交流或参与写paper note）&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Sun, 18 Dec 2016 10:36:44 +0800</pubDate>
    </item>
    <item>
      <title>重磅 | 微软发布数据集MS MARCO，打造阅读理解领域的「ImageNet」</title>
      <link>http://www.iwgc.cn/link/3955978</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自微软&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote style="color: rgb(62, 62, 62); font-size: 16px; white-space: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/blockquote&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;今天早些时候，微软在其官方博客上宣布发布了一个包含 10 万个问题和答案的数据集，研究者可以使用这个数据集来创造能够像人类一样阅读和回答问题的系统。此外，微软计划效仿 ImageNet，与其他人合作、最终创办正式的竞赛等。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个数据集名叫 MS MARCO，表示 Microsoft MAchine Reading COmprehension（微软机器阅读理解）。其背后的团队声称这是目前这一类别中最有用的数据集，因为这个数据集是基于匿名的真实数据构建的。通过将该数据集免费开放给更多的研究者，该团队希望能够促进机器阅读领域的研究突破，就像之前研究者已经在图像识别和语音识别领域所取得颠覆性突破一样。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;MS MARCO 数据集地址：http://www.msmarco.org&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW97Eu3kQ28xCXnW6b2iagC06ibp0qu0Ig59mjrEboib6TvfYhF2yR9fuZ4JOWKwAGIIfdzzprAb52Dfw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他们也希望这次开放能够促进「人工通用智能（AGI/artificial general intelligence）」的长期目标的实现，即创造出能够像人类思考的机器。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW97Eu3kQ28xCXnW6b2iagC06u8rCNjRukHX5liaEqwToQ2xz3HyAicjk3UyRmXunjExkiafv7gh9ticF0g/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Rangan Majumder，微软 Bing 搜索引擎部门合作伙伴组的程序经理&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微软 Bing 搜索引擎部门合作伙伴组的程序经理（partner group program manager）Rangan Majumder 是这个项目的领导者，他说：「为了实现人工通用智能的目标，我们首先需要机器能够像人类一样阅读和理解文档。这个数据集是向这个方向迈出的一步。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Majumder 说，目前回答复杂问题的系统仍然还处在婴儿阶段。Bing 这样的搜索引擎和小娜那样的虚拟助手还只能回答一些基本的问题，比如「光明节那天开始？」或「2000 乘以 43 等于多少？」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Majumder 说，但在许多案例中，搜索引擎和虚拟助手只会将用户引导至一些搜索结果。&lt;/span&gt;&lt;span&gt;当然用户仍然会获得他们想要的信息，但那也需要用户在搜索结果列表中寻找所需的答案链接。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了实现更好的自动问答系统，研究者需要更强大的训练数据。这样的训练数据需要能够教会人工智能系统识别问题和组织答案，并最终能够根据它们之前从未见过的特定问题构建出自己的答案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Majumder 及其团队（包括微软的一些研究者和从事产品开发的人）表示，MS MARCO 数据集是非常有用的，因为该数据集的问题基于来自 Bing 搜索引擎和小娜虚拟助手的真实的、匿名的查询。该团队根据研究者所认为的更有趣的查询而对这些问题进行了选择。除此之外，这些问题的答案都是根据真实的网页而人工书写的，准确性已经过了验证。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过提供真实的问题和答案，这些研究者表示他们可以训练出能更好地应对人们常问问题的细微差别和复杂性的系统，其中包括那些没有明确答案或有多个可能答案的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;比如说，这个数据集中包含了这样一个问题：「What foods did ancient Greeks eat?（古希腊人吃什么食物？）」要正确回答这个问题，他们需要检索多个文档中的信息，最后给出谷物、蛋糕、牛奶、橄榄、鱼、大蒜和卷心菜等食物作为答案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微软首席人工智能科学家、深度学习技术中心（Deep Learning Technology Center）合作伙伴研究经理（partner research manager）邓力说之前的数据集在设计上都有一些特定的限制和局限性。这能让研究者可以更轻松地创造出可以被机器学习研究者形式化为所谓的「分类问题（classification problem）」的解决方案，但却不能帮助机器理解问题的实际文本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW97Eu3kQ28xCXnW6b2iagC06FI7Kefq1AjkyPZteCDyp4Us9hFxxOJH4dIFl9U210svLUD9mNbyTGA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;微软深度学习技术中心合作伙伴研究经理邓力&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;邓力说 MS MARCO 的设计目的是为了帮助研究者实验更先进的深度学习模型，从而推动人工智能研究的进一步发展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;他说：「我们的数据集不只是为了使用真实世界数据，也是为了移除这些限制，以使新一代的深度学习模型能够在它们回答问题之前先理解数据。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Majumder 说系统回答复杂问题的能力能够帮助人们更有效地获取信息，从而增强人类的能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;让我们举个例子，假设一个加拿大学生需要了解她是否满足一个贷款项目的申请资格。搜索引擎可能会将该用户引导至一系列的相关网站，然后她需要自己阅读那些条条款款然后才能得出结论。但如果她有更好的工具，她的虚拟助手就能帮助她扫描这些信息，然后给出一个更细致的、甚至个性化的答案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Majumder 说：「鉴于世界上的许多知识都是以书写的形式存在的，如果我们能让机器像人类一样阅读和理解文档，我们就为所有各种各样可能的情形开启了大门。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;长期目标：「人工通用智能（artificial general intelligence）」&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;至少就目前而言，研究者还仍然远远不能创造出能够理解人类所说的、看见的或写出的内容的系统——很多人将其称为「人工通用智能」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在过去几年，微软与其它地方的机器学习和人工智能研究者在创造识别对话中单词的系统上已经取得了极大的进步，在准确识别图像组成上也是如此。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Majumder 说，「微软在语音识别和图像识别上已经起着领头作用，现在我们也打算带领阅读理解的研究。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是，他提到这不是任何单独一家公司就能解决的难题。Majumder 说他们团队开放这个数据集的一个原因就是想要与领域内的其他人合作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;MS MARCO 类似于机器学习和人工智能的其它领域的训练集，包括 ImageNet 数据集——它被认为是测试图像识别进展的第一数据集。微软的一个研究团队曾使用 ImageNet 来测试自己的首个深度残差网络，在图像识别的准确率上有了巨大的提升。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;MS MARCO 团队也打算效仿 ImageNet，创建一个取得最好研究成果的团队排行榜。最终，他们可能会像 ImageNet 年度挑战赛一样创造一个更正式的比赛。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;任何想要下载并将其用于非商业应用的研究人员都可以免费使用 MS MARCO 数据集。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文：https://www.microsoft.com/en-us/research/publication/ms-marco-human-generated-machine-reading-comprehension-dataset/&amp;nbsp;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Sat, 17 Dec 2016 11:07:24 +0800</pubDate>
    </item>
  </channel>
</rss>
