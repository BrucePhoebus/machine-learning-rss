<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>专访 | Gigaom对话吴恩达：迁移学习是未来五年的重要研究方向</title>
      <link>http://www.iwgc.cn/link/4307211</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Gigaom&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;吴恩达，百度首席科学家、百度大脑项目负责人，一位与 Geoffrey Hinton、Yoshua Bengio、Yann LeCun 齐名的人工智能专家。近日，吴恩达接受了技术研究和分析公司 Gigaom 的专访，谈及了未来五年人工智能重要研究领域、中国人工智能研究以及人工智能与经济、社会关系等问题。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWicGoT9PibokMOzrKptgycI8EIqjkgvkWyqibk1kLGg2jbziaeaibX39t6QJOUTMpjJcnp95QS5jjXm87w/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;问：谈谈你在百度的日常工作吧。你们的人工智能团队在做什么？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：我们从事基础人工智能技术的开发工作。所有技术，从语音识别到计算机视觉、自然语言处理、数据仓库、用户理解，我们用人工智能技术支持很多百度国际业务并孵化新业务方向。比如，在百度，所有主要业务线都已经转型使用了人工智能。从网页搜索、广告到机器翻译、给用户推荐饭馆等。所以，人工智能在百度很普遍了。除此之外，我们也看到了人工智能所带来的许多新机遇，比如改善基于对话的（基于聊天窗口）的医疗助理，或使用面部识别打造自动开门的十字转门。我们所有团队也在追求那些新的垂直领域里的机遇。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;问：在基础研究领域，你有没有什么想做的事情？比如，那些或许有用但我们却搞不清楚其所以然的事情？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：我们在基础研究领域做了很多工作，有趣的是，成功的基础研究一开始会以基础研究的面貌出现，但是，一旦你看到了它的应用价值，过一段时间后就会变得不那么基础了。我们做了很多这样的研究。可以说，在百度，早期的面部识别是以基础研究的面貌起步的，但是，这个服务如今融入产品中了，也服务着产品的百万用户。神经机器翻译最初也是一项基础研究。实际上，这个故事有着不广为人知的另一面：神经机器翻译是在中国开创、研发和使用的。美国公司的研发和使用是在百度之后。中国团队在某个研究领域领先其他国家，这只是例子之一。我们在计算机视觉方面的基础研究，比如，面部识别，也一直处于领先位置。今天，我们正在会学习的机器人和机器学习领域进行广泛的基础研究。我们的研究覆盖了从非常基础的研究到非常应用的研究的所有阶段。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;问：百度团队是什么样子？通常你的团队的都是小规模的吗？团队以开发人员为重？你找到了一个成功的分配有限资源的办法了吗？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：这个问题比较复杂。很多项目开始时是小规模的。比如，一年前，自动驾驶团队有 22 个人。但是在团队展现了自己的实力、初步显示出前景并制定一个深思熟虑过的商业计划后，公司就有理由为其团队建设注入庞大资源，如今团队可能有几百个成员。团队从最初的一个基础研究项目变成一个崭新的业务分支。所以很多项目都是从相对小的团队开始的，不过，在其迈入正轨而且价值也清晰了后，我们就能将其嵌入一个拥有很多成员（几十人甚至几百人）的团队中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;问：如今人工智能领域，你认为五年内可以解决的难题之一是什么? 也就是今天很难解决但是五年后就会普遍加以实现的事情？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：从研究角度出发，我认为迁移学习和多任务学习是我想试着解决的问题之一。今天，机器学习全部经济价值都是应用学习，从针对特定任务的标记数据中学习，比如通过大量标记数据人脸数据库学习识别面部。对于很多任务来说，特定垂直领域的数据并不足以支持系统建构。因此，迁移学习会是一个很有活力的领域，机器机器可以学会一个不同的任务。比如，学会大体上识别物体。学会大体上识别物体后，这个知识中有多少会对识别面部的特定目的有用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从研究角度看，我认为这个非常非常有前途，现在也有广泛使用着的用于这类迁移学习的技术，不过有关如何实现的理论和最佳实践仍然处于相当早期阶段。我们之所以对迁移学习感到兴奋，其原因在于现代深度学习的巨大价值是针对我们拥有海量数据的问题。但是，也有很多问题领域，我们没有足够数据。比如语音识别。在一些语言中，比如普通话，我们有很多数据，但是那些只有少数人说的语言，我们的数据就不够庞大。所以，为了针对数据量不那么多的中国少数人所说的方言进行语音识别，能将从学习普通话中得到的东西进行迁移吗？我们的技术确实可以做到这一点，我们也正在做，但是，这一领域的进步能让人工智能有能力解决广泛得多的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;问：人工智能可以告诉我们任何有关人类智能的有用信息吗？或者，反过来，从人工智能那里获取的线索能帮助 AI 更好地工作吗？亦或是这种情形，人工智能和人类智能只是都用了「智能」这个词而已，两者没有任何相似之处？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：从神经科学中获取的知识对当前人工智能的发展只有一丁点用。现实一点说，尽管神经科学研究了几个世纪，今天我们对人类大脑的工作方式几乎还是完全不了解，对大脑工作原理那点极为少量的知识仅能为人工智能提供一些并不可靠的灵感，不过，实际一点说，今天人工智能取得的成绩更多的是受计算机科学原理驱动的，而不是神经科学原理。我已经说过，在自动化人类所能的事情上，人工智能已经变得非常擅长了。比如，人非常善于语音识别，但是人工智能在语音识别上表现不好。人非常善于人脸识别，人工智能正在人脸识别上进展迅速。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;事实证明，当我们试着将人类可以做的一件事情自动化而不是解决人类都无法完成的任务时，用于推进该人工智能技术的工具也会更好地发挥作用。原因很多，但是原因之一在于，当我们试着选择一个人类也可以胜任的任务，让人工智能参与进来时，我们就能深入找出人类怎么可以迅速完成这一任务原因。因此，在展望很多人工智能垂直领域时，我们当然可以做一些甚至人类自己都不很擅长的事情。我认为，现在亚马逊向我推荐的书目甚至比我妻子推荐的还要好。我妻子当然非常了解我，但是亚马逊能做到这个程度是因为它积累了大量有关我的浏览和阅读书目数据，这些数据远远多于被妻子看到的阅读书目。我大致认为，有了几个类似这样的例外，当人工智能试着自动化至少人类也能做到的事情时，就会进展神速。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;问：您总是在预测人工智能将实现这个问题持保守意见，我认为您这样做的部分原因是因为担心公众狂热的期望会对人工智能研究科学造成灾难性后果，特别是关乎资金方面，我这样说对吗？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：我很倾向实用性，并努力成为一名实用主义者。但是在这一点上我想提出一个略有不同的观点。如果我开始组建一个团队来治疗所有人的疾病，这是非常值得庆祝的事，因为这听起来简直就像是一个伟大的使命。但是坦率地说，在硅谷有时候目标太高就会不受欢迎并一定会有反对的观点出现。我们比较喜欢讨论怎么锚定月亮那样的话题，因为即使我们失败了还能锚定星星。但我认为实际上目标太高会存在一个成本，所以如果你的目标是解决疟疾而不是组建团队解决世界所有的疾病，那么它可能会更有成效，对世界产生更大更好的影响。所以我认为，将人工智能应用于世界会产生更有意义的影响。我认为我们不仅可以通过自动驾驶汽车、人工智能物流改变交通运输，还可以通过人工智能完全地改变医疗。我们可以通过人工智能在世界上做出重大的改进。所以我所做的很多努力都是在为这些具体的、可行的事情做准备。因为我认为这对世界实际上更有成效，我们不会花时间去研究也几百年都不会到来的科幻小说场景。我认为这种为科幻小说花时间的事在硅谷是不受欢迎的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;话虽如此，但作为一个社会，我们需要从事做各种各样的事情。所以我认为有一些人努力解决疟疾，并希望通过盖茨基金会（Gates Foundations）和世界卫生组织（World Health Organization）帮助工作，而另外一些人努力解决人类所有疾病会让社会变得更好。我认为社会以不同的方式分配资源是一件好事。但我也认为这对我们领域的进步也是十分有帮助的。当我们思考「什么是我们有信心可以实现的任务？」对抗「什么是我们应该投资的进一步梦想？」，我们团队有一部分人在做这个，不过那只是我们整体努力的一个小方向。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;问：你相信人工通用智能（AGI）的可能性吗？如果是的话，如果是的话，那你认为它是沿着我们已知技术的进化路径实现么，背后的摩尔定律，或者 AGI 是不是需要一个整体的根本性突破，而这个突破甚至是不能预料到的东西？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：我认为实现 AGI 肯定需要多个突破，但这很可能会发生。因为有软件算法的突破和硬件可能的突破。然而，我发现很难预测这一突破是在十年后还是千年后出现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;问：您认为人类的创造力，如编写剧本或小说的能力是否需要另外一个 AGI，或者就是现在我们掌握的技术？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：我认为很多创造力其实是我们不太了解我们创造它的过程。例如，Garry Kasparov 说他看到了深蓝（Deep Blue）创造性的下棋。作为技术专家，我知道国际象棋程序是如何运行的，在任务中通过投入惊人的计算量，深蓝能够下一步妙棋，而这一步妙棋可能在象棋大师眼里就是一种创造性的举措。我自己也研究过创造性过程，创造力是十分困难的工作，因为创造力是增加许多小模块并拼合到一起，然后建立起一个好像是从无到有的巨大事物。但是，如果有人没有看到所有的小模块，或拼合这些小模块成为创造性的物体有多难，那么我认为创造力的实质比它外表上看起来更加神奇。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我的艺术家朋友一遍又一遍地练习单个画笔，并一遍又一遍地画出类似的画，然后他就逐渐取得了进步。我的祖母是一个画家，她在完成一幅惊人的作品前都是一点点进步的，当你只看到最终的成果，而没有看到在完成最终成果之前做所的努力，那么你就会感到神奇。我认为你所做的所有工作都是通过一点点小增量达成的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;问：所以如果你回顾刚才所谈的内容，人类的创造力是可以计算化和可实现的，在合理的时间范围内。人类的创造力不是什么非常神秘的东西，或者说是超出我们能实现的范围的。您同意吗？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：是的。要么通过偶然的绝佳的棋子移动，寻求一个人类还未想到的句子的解释，创造一个简单的艺术作品，我认为我们正在见证机器行为具有某种程度的创造性。我们很可能会继续看到这样循序渐进的进展，机器在今后几年内逐渐变得更有「创造性」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;问：您的团队在地理分布上是怎样的？大部分团队成员在哪里？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：主要在北京。我们在美国有一个 100 人的团队，在北京也有一个大的团队，同时在上海和深圳也有一些小团队。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;问：在机器人技术领域，你能看到不同国家和地区的发展重点。例如在日本，能明显看到将更多重心放在制造友好机器人上，去制造与人情感化连接的机器人，而不是与世界上其他部分所连接的机器人。那么在人工智能里面，是不是也有类似的情况？因为刚才您提到脸部识别来自中国。在人工智能领域，不同的公司、不同的地区或者是不同的国家是不是会对有些事情的看法也不同？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：首先我认为在中国，语音识别是经济和商业模式带动发展的一个很好的例子。从产品层面来讲，我认为不同的商业压力和产品优先性会导致不同的国家在不同领域的投资更多或者是更少。在中国就有这样一些例子。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在中国，用手机键盘打中文字要比打英文更加痛苦。所以这反过来也推动了更好的移动端手机语音识别的发展。因此我觉得百度领先在语音识别领域取得的突破也是由于要为用户带来语音识别体验的强大产品压力的驱使。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;至于机器翻译，你知道美国有很多关于神经机器翻译的 PR。很多人都不知道的一点是，神经机器翻译其实是在中国首次开创并得到发展的，之后又成为了产品。美国的一些大型公司都在这之后，我认为导致这个现象的其中一个原因是因为在中国，对将一些公开的内容翻译成中文的需求很大，而在美国这样一个说英语国家中，英语的内容非常多。当然中文的内容也很多，但是外国的内容译成中文会特别快，这是一种文化现象。然而世界上的英语内容已经非常多，所以说英语的人寻求对外语内容的翻译没有那么紧需。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人脸识别作为一种商业在中国发展迅猛，因为作为移动优先的社会，中国人习惯了在移动端进行大笔的金融交易。例如，你可以通过百度获得教育贷款，我们会基于你的贷款批给你一大笔钱，而这个申请你在手机上就可以完成。在我们通过手机给某个人发一大笔钱的时候，我们对确认这个人的身份就会产生强烈的兴趣。所以人脸识别就成为了要实现这一目标的关键技术。那些压力也意味着中国的人脸识别是另外一个发展迅猛的领域，其发展势头比其他国家都要快。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不管是在美国还是中国，在人工智能方面都有很多的创新。我猜还有其他的一些领域。英国在人工智能玩视频游戏方面进行了大量的投资。我个人不会在这一方面进行投资，但是我想不同的组织有不同的兴趣和优先性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我认为如今人工智能的进步成为了一个全球化现象，而且中国有很多的创新正在发生，而英语世界国家还没有意识到这一点。这并不是因为保密的问题，我认为这是因为缺乏语言的流畅性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;例如，几周前我去参加 NIPS 大会，在不到一天的时间之内，所有会议上最重要的演讲都被总结或者是转写为中文 ，并发布在中国的网络上。所以说巴塞罗那一个英语会议转变成中文的知识，中国做的非常快并且非常高效。在不到一天的时间之内，很多中国的研究者就可以阅读我们&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721081&amp;amp;idx=1&amp;amp;sn=d557968703d4af879b5cf6461069dacd&amp;amp;chksm=871b0f47b06c865185865fcd5ef92af7726e84ae9e689b7ced9986a08c9fe3113df296a8469a&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721081&amp;amp;idx=1&amp;amp;sn=d557968703d4af879b5cf6461069dacd&amp;amp;chksm=871b0f47b06c865185865fcd5ef92af7726e84ae9e689b7ced9986a08c9fe3113df296a8469a&amp;amp;scene=21#wechat_redirect"&gt;&lt;strong&gt;在西班牙演讲的中文版&lt;/strong&gt;&lt;/a&gt;。我认为正是很多中国人熟练的英语口语和写作能力才让这成为可能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不幸的是，逆向的知识转换要慢得多。因为从全球范围来看，当前中国之外很多的研究者不说中文。所以当人们发明了很多东西，甚至已经在中国广泛传播，一些英语观众都浑然不知，有时候甚至是在一年之后，一个英语国家的公司发明了类似的东西之后这些技术才能传播开来。所以我希望自己能做的其中一件事情就是帮助提高相反方向知识转换的速度，因为如果我们能够让研究社区更加的全球化，那么全球的研究社区就会进步的越快。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我想有一些具体的例子。首先是在中国，普通话短句的语音识别在一年前超越了人类水平，但是这一成果在全球范围的知名度并不广，直到最近才被很多人熟知。我可以看到很多的例子，从语音识别领域取得的进步到神经机器翻译领域所取得的进步，再到中国率先建立了深度学习 GPU 处理器，但是我希望能够在中国初次发明之后，在美国也能够尽快看到这些成就。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;问：您有没有一些网站或者是期刊可以推荐给我们的读者，以便让他们能够更加容易地查找信息？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：在中国，传播知识的方式和美国不太相同。在中国，人工智能在社交媒体上传播特别快，而是传播的方式特别强大，如果不是亲身经历的话可能无法理解。另外，相关的网站非常多，但是很多都是中文网站。你们可以在 Twitter/微博上关注我，我会看看该怎么帮助大家。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;问：在你看来人类意识是什么？或者更确切地说，你相信人类意识从根本上来说是可计算的吗？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;答&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：我不知道意识到底是什么。在哲学领域，对周围的人是否真正具有意识，或者说他们像是僵尸一样，以及机器人通过计算表现得好像它们具有意识一样等这些问题一直存在着争论。总而言之，我们如何知道除了我们之外的其他人都真正具有意识？还是说他们是机器人？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我并不认为意识是计算机从根本上来说无法实现的，确切地说，是我们应该如何去实现，而实现这一点是需要几十年还是几百年，我们还不清楚。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 12 Jan 2017 12:48:06 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 搜狗知音引擎再进一步，实现语音实时翻译</title>
      <link>http://www.iwgc.cn/link/4307212</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：赵云峰&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;搜狗在乌镇互联网大会上发布了实时翻译技术，此后，搜狗语音交互中心技术负责人陈伟详细介绍了背后的技术框架和搜狗的多项核心技术。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这次的语音实时翻译技术是在&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718178&amp;amp;idx=2&amp;amp;sn=39eb3ad0c5e67c5a1d93a88fe381a935&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718178&amp;amp;idx=2&amp;amp;sn=39eb3ad0c5e67c5a1d93a88fe381a935&amp;amp;scene=21#wechat_redirect"&gt;搜狗知音引擎&lt;/a&gt;这个大框架下，通过知音引擎搜狗希望提供从听到说，能理解会思考的能力，涵盖了语音识别、语义理解和语音合成三个主要的能力，而知音引擎提出的口号是「更自然的语音交互」。「其中『更自然』分为三个层次，在识别这块，我们希望在人机使用语音进行交互的过程中，更加自然，接近人和人交互的方式。同时也希望我们的引擎更多理解人语言上的需求，而在合成上则希望表达更加自然。」陈伟表示。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodcPHlfTSUnm3mPSwOTU5Uiat6LvISLaxviaKTicTlPIE2aTQicOHiaEh58tJg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;搜狗知音引擎图示&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从 8 月份首次发布开始，搜狗知音引擎有了新的进展。基于已有的深度学习平台和技术搭建了自身的语音实时翻译技术。整个技术框架包括了语音识别、机器翻译两个大的方向，整个系统并不是简单的技术堆砌，而需要做非常多的细节优化以及系统调优，主要包括了语音断句、语音识别、文本断句以及机器翻译。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodcS5QDZJvk32vuPb7LtLibTrhs0Aa1zeF7h3L7ib3EYNAqFBKFUHEBx5kA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;搜狗语音实时翻译&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先是语音断句，会通过能量检测和基于深度学习模型的方式进行断句，通过对语音信号中每一帧进行语音 (用 1 表示) 和静音 (用 0 表示) 的判断，生成一个很长的包含 0 和 1 的判决序列。之后要对判决序列进行平滑处理，最终生成的序列中在 0 和 1 交界的地方就可以认为是一个语音的边界，作为后面断句非常重要的依据。陈伟表示：「语音断句有几个好处，静音片段不进行语音识别，大大提升解码效率。同时语音片断可以分割成多句并行识别，大大提高了语音识别的效率。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodcGxIA4XdSPxrLAYpdRaDaJ83GNUswMcvlaEAYU7fdlG3u2Pob3cmdUA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;语音断句&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其次就是语音识别，就是把语音转化成文本，其中语音识别会非常依赖两个模型，一个是声学模型，描述了发音单元对应的模型和声音信号之间的相似性。另一个是语言模型，描述了识别结果中词和词之间连接的可能性，从而保证了识别输出结果更加通顺、流畅，符合正常的发言习惯。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodca0Ddg5KuVMrMicAk5ZA5qo9t9uILBRkCFn3ge9Y8XNthBcmLgkcr1KA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从 2012 年开始，搜狗开始组建语音团队，使用的声学建模技术一直在演进，目前比较稳定的线上系统是 CLDNN 系统，陈伟说：「它集合了三种不同结构，是一个复合的神经网络结构。CNN 可以对变换起到不变性的作用，因此它能够比较稳定地提取出一些恒定的特征。第二块是长短时记忆模型，能够把非常长的上下文，历史或者未来的信息融入到当前的识别中来。还有一块是 DNN，可以提取深层的抽象的特征。这三层复合式结构融合在一起，形成了目前我们使用的主流结构。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深度学习技术的不断发展，声学模型训练流程逐渐从复杂变的简单，端到端的技术被逐步使用，比如 CTC 的引入，声学建模的单元从之前的共享状态扩大到了 cdphone、音节或者字，CTC 的引入可以省去之前烦琐的模型训练过程。「我们线上主要在用的结构就是 CLDNN+CTC，目前这个模型的准确率无论从第三方的评测、还是厂商对比评测都已经证明了目前我们在语音识别技术方面的领先性。」陈伟表示。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodcHtCnibPgvn3gbfb3xcKbW4qyZGRpHVwHx95xHDQKGF0CAAiaDEf7ECPw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;语音识别的声学模型&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除了声学模型，在语言模型方面，ngram 模型使用了固定窗长的方式，当前词只和前面固定长度的历史词有关系，而搜狗在语言模型上使用了 RNNLM 模型，思考建立当前词和历史所有词之间的联系，通过对声学模型和语言模型的共同优化，语音识别效果得到了比较大的提升。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodcxZSUKU8r5KsG40hib5p5HFCDIRtHzTjUTDIqWHza04cuSC9Iiak6XAPg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;语音识别的语言模型&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在语音断句、语音识别之后的第三个阶段是文本断句。首先通过内容平滑把一些没有具体意思的词去掉使句子变得比较通顺。然后通过规则和模型两种方法进行语句划分和加标点。陈伟认为，在语音识别和翻译之间，最为关键的一个桥梁就是文本断句，这个模块是搜狗的语音同传技术可以应用的重要原因。而另外一个保证翻译做到实时的技术是输出判断，用户一直在说话，系统需要决定语音识别输出结果中哪部分可以送给翻译，哪一部分需要暂时缓存下来暂时不进行翻译，这也是搜狗语音同传在今后需要着重优化和改善的功能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第四部分是机器翻译，以前的方法更多是把整个的翻译切分成单词、短语，把中文、英文短语之间的映射关系建立起来，对应关系建立起来以后，使用语言模型再对译文进行词序或者短语顺序的调整，保证译文尽可能的通顺，这就是统计机器翻译的技术。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;近三年来基于神经网络的机器翻译技术逐渐成为主流，通过端到端的方法将翻译平行语料进行了映射，整个框架分为了编码器-注意力机制-解码器的结构，在同传技术里，搜狗用到了双向 GRU 技术构建编码端的结构。通过 attention 机制在源端和目标端文本间进行对齐并生成当前时刻的句子级向量表示，并送至解码端，解码端逐词解码输出翻译结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodcCAQhCjoUV9IUAPW97LJWu6sj0a3hLvg5Zjicdy31PXmuZdkKEOrowbA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;搜狗的NMT&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「从翻译本身来讲，之前大家用的那套翻译模型，跟我们以前在输入法上用的打字模型差不多，你打一堆拼音，拼音怎么转化成中文，而翻译就是你打一个英文，这个英语怎么转化成汉字，用到的技术就叫统计机器翻译 SMT」，搜狗语音交互技术中心负责人王砚峰表示，「现在的方法是基于神经网络，和以前的统计机器翻译是完全不同的技术流派。我们所说的深度学习改进比较大的三个领域，第一是图像识别，第二是语音识别，第三很有希望的就是机器翻译」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于和谷歌不久前发布的神经机器翻译技术，搜狗和谷歌使用的模型区别不大，但谷歌的神经网络比较深，做到了 8 层，而搜狗最多做到 5 层。陈伟对此的解释是「我们主要完成的任务是语音实时翻译，因此在保证翻译精度的同时，要兼顾速度，我们展现的是语音识别加翻译连在一起的效果，因此需要整体进行评估，这毕竟是实时的翻译，不是输入一个文本，输出翻译文本，任务就结束了，而是演讲者一直在讲，他的中文识别结果实时展现，同时英文译文也需要快速地输出，因此我们要尽量把时延降低。完成这个产品要在速度和精度上做一个折衷。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而深度学习技术中，最终的效果不仅和算法相关，还和数据密不可分。「真正的模型是需要跟数据结合非常紧密，你只有有了大的数据才能学习出复杂的模型，刚才的模型结构非常的复杂，我会觉得对目前机器翻译而言，搜索公司在语料上面的积累，非常有助于我们在很多领域取得很好的机器翻译效果。」陈伟表示。搜狗每天语音请求次数在 1.9 亿次，代表每天都可以收回来大概 16 万小时的数据，这些数据再加上搜狗自身在深度学习技术的积累，使得其在语音识别取得比较好的效果，从而带来更加准确的翻译结果。陈伟说：「语音实时翻译技术中，翻译对接在识别后面，因此只有识别提供非常准确、可靠的结果以后，翻译的威力才能发挥出来。错误较多的结果是无法准确翻译出来的，这也是其他家没有把翻译推到现实场景中的原因之一。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谷歌神经机器翻译推出后，宣布将 GNMT 投入到了非常困难的汉语-英语语言对的翻译生产中，这引起了业内的极大的关注。微软也发布了万能翻译器，支持语音识别、拍照识别、直接输入翻译功能，官方表示它也可以实现多达 100 人间实时翻译交谈。而搜狗领先的机器翻译技术也已经开始了应用，目前，根据此前在乌镇的实际效果评比，以及一些人工判断，搜狗语音实时翻译的准确率在 90% 左右。搜狗表示会上线翻译产品，用户输入文本时会自动翻译成英文。此外，也会和一些电视厂商进行一些合作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;据维基百科介绍，人类目前大概有 6000 多种语言。自人类在未建成的「巴别塔」下不欢而散以来，实现全人类之间的顺畅交流一直是我们的梦想。现在，人工智能方法让我们看到了真正实现这一梦想的希望。这也是我们机器翻译让大众持续兴奋、让技术公司和研究人员保持动力的最大原因。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;正如王小川所说，语言上是我们最需要做的，因为我们主页做输入法和搜索都是和文字信息打交道，但文字信息是人工智能里最难的一件事，我们还专注在这件事情上，文字领域的人工智能怎么发展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心原创，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 12 Jan 2017 12:48:06 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 任何人都可以开发量子计算软件：D-Wave开源开发工具Qbsolv</title>
      <link>http://www.iwgc.cn/link/4307213</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Wired&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWicGoT9PibokMOzrKptgycI8EPZ2yhHaKd1eza2Xscy3MMgdTnVSj5y9MQBSQLVHe9CY9iaK4G7uRcVA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;量子计算是可以实现的，但难度也非常大，因此目前仅有几位开发者（通常接受过量子物理和高等数学训练）实际上能够真正操作世界上仅有的几台量子计算机。现在 D-Wave 这家加拿大公司想要通过开源软件之力让量子计算变得更加容易简单——这家公司从 2013 年开始就已经向谷歌和美国航天局（NASA）提供了测试用的量子计算机。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;传统计算机将信息以「比特」的形式进行存储和计算，这些「比特」要么表示 0，要么就只能表示 1。但量子计算机却并非如此，借助量子粒子的一种被称为「叠加态」的奇怪状态（即粒子的自旋同时有两个方向），量子计算机的比特（被称为「量子比特（qubit）」可以同时处于 0 和 1 两种状态。D-Wave 这样的公司希望能够通过将这样的量子比特连接在一起而创造出能够在性能上远远超过当前计算机的新型计算设备。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;IBM 在 2000 年就展示了一台可工作的量子计算机，并自此之后就一直在不断改进其技术。谷歌也在研究自己的量子计算机，该公司在 2013 年还与 NASA 一起对 D-Wave 的系统进行了测试。洛克希德·马丁公司和洛斯阿拉莫斯国家实验室也在使用 D-Wave 的机器。但是今天的量子计算机仍然并不适用于大多数真实世界任务。量子比特本身也还很脆弱，一不小心就会脱离叠加态。另外，目前我们还很难对量子计算机进行编程，因为这需要高度专业的知识。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「D-Wave 正在推动硬件的发展，」D-Wave International 总裁 Bo Ewald 说，「但我们需要更多聪明的人来思考其应用，还需要另一些人来思考其软件工具。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这就是该公司推出的新软件 Qbsolv 的用武之地。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Qbsolv 是为帮助没有量子物理背景的开发者开发 D-Wave 量子计算机程序而设计的。D-Wave 的一些合作伙伴已经在使用这个工具了，但今天该公司宣布将其开源了！这意味着以后任何人都可以免费使用、分享和修改这个软件了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Qbsolv 开源地址：https://github.com/dwavesystems/qbsolv&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「在计算机科学领域，不是每一个人都认识到了量子计算机的潜在影响。」科罗拉多大学博尔德分校的数学家 Fred Glover 说，他一直在使用 Qbsolv。「Qbsolv 通过让研究者和实践者参与进来共同描绘量子计算开发的未来方向，从而提供了一种可以使这种影响为更多人所认知的工具。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;人人都有量子比特&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Qbsolv 是未来的量子计算机程序员工具库的新成员——虽然目前这个库还很小，但它也在不断增长。去年，洛斯阿拉莫斯国家实验室的 Scott Pakin（他也是 Qbsolv 的最早用户之一）就曾发布了另一款免费工具 Qmasm（https://github.com/losalamos/qmasm），这也是一款帮助开发者无需忧心底层的硬件就能开发 D-Wave 计算机程序的工具。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Ewald 说，这些软件的目标是推动形成一个量子计算软件工具生态系统和培养一个解决量子计算问题的开发者社区。在最近几年，开源软件已经成为了构建社区的最佳方式，这能让独立开发者和大型企业都参与进来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然，要想实际地运行你用这些工具所开发出来的软件，你还需要能够使用上世界上仅有的非常少量的 D-Wave 机器。不过你也可以在你的传统计算机上下载 D-Wave 的模拟器来测试软件。当然，模拟和实际运行并不是一回事，但聊胜于无。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此外，IBM 还在去年推出了一个基于云的量子计算服务，让人们可以在该公司的量子计算机上运行自己的程序，体验地址：http://www.research.ibm.com/quantum&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;D-Wave 尚未推出类似的云服务——目前而言，Qbsolv 和 Qmasm 还只能让开发者为 D-Wave 机器开发应用而已。实际上，D-Wave 的机器不仅采用了一种和传统计算机决然不同的方法，而且和其它量子计算原型设备也有很大的差异。大部分计算机（从你的智能手机到 IBM 的量子计算机）都是为通用目的设计的，也就是说它们可以被编程用来执行各种不同的任务，但 D-Wave 的机器只是为单一用途设计的：解决优化问题（solving optimization problems）。这个问题的典型案例是旅行商问题（traveling salesman problem）：计算经过一些特定目标位置的最短路径。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;早期的时候，有很多批评认为 D-Wave 的昂贵机器根本算不上是量子计算机，但现在似乎大多数研究者已经认同这些机器确实展现出了量子行为。「关于其中是否有量子效应以及量子效应是否发挥了有意义的计算作用，现在只有非常少的怀疑了。」南加州大学研究者 Daniel Lidar 在 2015 年这么说，那时候谷歌和 NASA 刚发布了一篇研究论文《What is the Computational Value of Finite Range Tunneling?》，详细阐释了他们使用 D-Wave 的研究成果。D-Wave 现在所面临的质疑是：D-Wave 的计算机真的能比传统计算机更快吗、该公司所使用的独特方法比 IBM 或其它研究者的方法更好吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Pakin 说他的团队相信 D-Wave 的潜力，尽管他们也承认：除了一些范围非常狭窄的案例，D-Wave 的系统可能尚未带来性能上的提升。他也解释说 D-Wave 的计算机并不必要为一个优化问题提供最有效的答案——甚至不必要是正确的。相反，其目标是给出一个可能很好也许完美的答案，并且做到非常快。这就将 D-Wave 计算机的应用范围压缩到了需要快速解决但不求完美的优化问题上，这其中包括许多人工智能应用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是，如果进展顺利，随着硬件和软件的继续提升，也许其它类型的计算问题也可以被转化成优化问题进行处理，Qbsolv 和 Qmasm 的目标就在于此。但要实现这一目标，他们所需的将不仅仅是开源软件，他们还将需要一整个开源社区。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 12 Jan 2017 12:48:06 +0800</pubDate>
    </item>
    <item>
      <title>专栏 | 需要什么样的智能助理，是《棋魂》中的佐为还是蜡笔小新？</title>
      <link>http://www.iwgc.cn/link/4307214</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;机器之心专栏&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：袁峻峰&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote style="color: rgb(62, 62, 62); font-size: 16px; white-space: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;对于闲聊机器人来说，如果告诉其你失恋了，能回个「蓝瘦，香菇」。那这聊天机器人挺牛。一定是经常更新训练数据，与时俱进。但回过来一想，求之不得的忧伤，恒久远已，天下之才独占八斗并且贵不可言的陈思王曹植，不也因为求不得写了篇《洛神赋》。诗经中也有「汉有游女 不可求思」,」求之不得 寤寐思服」的句子。王菲的歌词中也有」思念是一种很玄的东西，如影随形，无声又无息出没在心底，转眼吞没我在寂默里，我无力抗拒，特别是夜里，想你到无法呼吸」。这么多样的表达。情感是难以描述的，「我们的精神状态是如此复杂，只能以类比的方式来描述」[1]，中国历来的文人墨客最是擅长比兴手法，我们不排除「蓝瘦，香菇」是一种表达，但中文中那么更优美的表达也不该忽略。而按目前基于大量聊天样本，当客户反馈时既为正样本，通过深度学习 RNN 之类的模型解决 Sequence2Sequence 的问题。如能学到一个机智对话的蜡笔小新已是很赞，而且目前也还有很长的路。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那我们如将特定领域的问题答案做成样本，同样将其看做 Sequence2Sequence 映射问题。通过深度学习模型去拟合这个复杂映射函数。且不说这是个有多少人工就有多少智能的方案。可以想象这种方式《棋魂》中的佐为肯定也是训练不出来的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;一 理想中的智能助理&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「人工智能助理：这里指的是 Intelligent personal assistant/agent (IPA)，指帮助个人完成多项任务或多项服务的虚拟助理」[2], 如何帮助？在文章 [2] 中，提出对话式助理至少满足这几点功能：」具备基于上下文的对话能力，具备理解口语中的逻辑，所有能理解的需求，都要有能力履行。」[2] 但这样帮助就够了吗？能不能像 YY 玄幻小说中的深山偶获老法师灵体，之后在你修行中的方方面面问题中提供指导。乔布斯在一次访谈中提到」我认为展望未来 50 至 100 年，如果我们真能开发出一款设备，它可以捕捉潜在精神，或者一套潜在的原则，或者是潜在的看待世界的方式，这样当下一个亚里士多德出现的时候……也许他可以随身携带这款设备，将所有东西都输入其中。这样当这个人死后，我们就可以问这款设备『喂，对此亚里士多德会怎么说？』，我们得到的答案或许是错误的，或许是正确。但是想到此我就已经很激动了。」这应该也是指通过人工智能借助于大师、领域专家的经验为各样的决策提供建议。那是不是理想中的智能助理定位是在收集各样信息的基础上，结合其强大的计算能力和人类已有的决策样本数据提供预测与决策建议呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;前几天，AlphaGo 升级版 Master 最终以 60 胜 0 负的成绩在快棋战横扫中日韩三国顶尖棋手。聂卫平赛后说：「Master 颠覆了多年的定式。而且最后证明它的选择都成立。」柯洁九段也表示：「从来没见过这样的招法，围棋还能这么下？看 Master 的招法，等于说以前学的围棋都是错误的，原来学棋的时候要被骂的招法现在 Master 都下出来了。」李喆在赛后总结「每盘棋里，AI 大部分的招，都和人类棋手的想法接近。体现了人类经验仍然具有有效性。。。人无法完全做全局运算，因此会因经验局限性而错失对当前盘面的针对性」。可想而知，结合了人类经验（样本数据），加上计算机强大的计算能力，在围棋这样的完全信息博弈游戏领域必然横扫顶尖棋手。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那在非完全信息博弈领域呢?「扑克这类不完全信息扩展式博弈以其随机性、信息不完全可见性、博弈规模大等特征」[4] 是不是可以阻挡人工智能的脚步。答案是乎也是否定的。「由卡耐基梅隆大学（CMU）开发的名为 Libratus 的人工智能系统即将开始一场新的挑战：试图在一对一、无限制投注的规则下击败世界最强的人类德州扑克玩家。」[5] 借助于博弈论与强化学习等模型以及专业玩家的样本数据，结合计算的强大计算能力，在这一领域的游戏中人工智能终也将完胜人类。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;二 理想中的提供预测与决策建议智能助理的可行吗？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如此看来，是乎是可行的。不过还是先听听人工智能领域先驱马文·明斯基等人的意见。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;莫拉维克悖论&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;百度百科中描述：莫拉维克悖论（Moravec's paradox）是由汉斯·莫拉维克、布鲁克斯、马文·明斯基等人于 1980 年代所阐释。人类所独有的高阶智慧能力只需要非常少的计算能力，例如推理，但是无意识的技能和直觉却需要极大的运算能力。如莫拉维克所写「要让电脑如成人般地下棋是相对容易的，但是要让电脑有如一岁小孩般的感知和行动能力却是相当困难甚至是不可能的。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;马文·明斯基在其著作《情感机器》[1] 中讨论了人类大脑思维运行方式，尝试设计能理解、会思考的人工智能，也讨论为什么会有莫拉维克悖论。书中明斯基提出「所有的现代程序都不具备常识性知识 (Commonsense Knowledge)」[1] 所以会给人感觉有时不够智能。这些常识性知识和推理包括 [1]：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;正面经验 (Positive Expertise)：知道在哪种情况下该使用哪种类型知识。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;负面经验 (Negative Expertise)：知道不该采取哪种行动，因为可能会使事情变得更糟。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;调试技能 (Debugging Skills)：当常规方法不再适用时，还有其他可供选择的方法。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;适应技能 (Adaptive Skills)：知道这样把原有知识应用到新情况之中。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;明斯基提出了框架表示常识的结构化知识表示。这属于机器学习中的符号主义（Symbolists），不同与当前联结主义（Connectionists）的深度学习。目前该领域还在探索期，已有一些基于知识图谱方面应用。并且这些常识性知识和推理难以在深度学习模型中得到解决。迁移学习也是试图在联结主义框架下将通用领域的训练结果迁移到特定领域，目前也还在探索期。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicGoT9PibokMOzrKptgycI8EWfRD9KUCE86nCg7GemdMxK80FJRT0mWV5BT6J54BwTTtqy5FDZgm2Q/0?wx_fmt=png"/&gt;&lt;/span&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;（来源：情感机器 [1]）&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「专家是一位无须思考就知道结果的人」[1], 所谓常识可以认为是一种直觉。爱迪生说过「天才就是 99% 的汗水+1% 的灵感，但没有这 1% 的灵感那 99% 的汗水也是徒劳」，灵感既大师在决策时的直觉。「郝伯特·西蒙对比过国际象棋世界冠军十年间不同的下法，认为这是这是全部职业强选手的集体经验而积累起来的知识的结果。专家和新手区分不仅仅是前者具有大量和多样的信息，而且是他的直觉经验使他能发现他所面对的形势中的熟悉模式，长期记忆中储存大量的棋子的共同模式，通过识别这些模式，从长期记忆中重新找到大量相关信息。」[5], 这些并不需要大量复杂的全局计算，而「AlphaGo 中使用蒙特卡罗树搜索（Monte Carlo Tree Search，MCTS) 结合估值网络（Value Network）来做可选方案集合选取。」[6] 两者完全是不同的途径。目前要让人工智能有如小孩般的学习能力与通用常识都很遥远。更别说像大师、领域专家为各样的决策提供建议。扎克伯格在搭建他的智能助理 Jarvis 时也说「我们距离了解学习的本质仍然很遥远…我们仍然不知道将从一个领域中获得的想法应用到另一个完全不同的领域中去。「[7]&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;数据，样本在哪里？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一个问题是，目前的深度学习需要端到端的样本数据。AlphaGo 是使用段位以上围棋专业棋手对弈样本，并通过自我对弈扩大样本数。而智能助理面对个人方方面面的任务、事件，更加无法得到那些专业的正样本数据。并且每个助理面对客户的情况都是不同的，个体都是独立的，不可能得到训练所需的样本数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;不可能获得实质理性所需的全局信息&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;罗振宇在跨年演讲中说道「在人工智能逻辑里，它不关心人类对一件事情的定义，但是它可以输出你要的答案。只要有大量的数据，它就能用跟人完全不同的思路，达到同样的结果。」真是如此吗？笔者并不认同，人工智能是和人的思维不同，但不等于有大量数据就能得到同样效果或更好效果。因为「我们知道，通过深度学习和大数据，一定能得到一个更优的模式识别效果。但前提是我们假设未来和历史特征向量是符合同一概率分布。未来当然不会和历史是同一概率分布，就像彼得·林奇说的『你无法从后视镜中看到未来。』哈耶克也说过『我们做出的预测有可能被否定，因为他们只具有经验的意义。』」[6] 哈耶克举过一个例子，对一场足球比赛，如果我们熟悉球赛，了解球队，并可以监测赛场上每一刻球员状态包括心肺、肌肉等等，但球赛的结果还是超出了科学预测的范围。因为我们的基于经验的预测能力也仅限于事件的一般特点，并不包括预测每个具体事件的能力。所以即使有足够的数据，机器也不一定能得出比从 1990 年起每次国足比赛都押输更牛逼的策略。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外一点是，智能助理能得到每个具体事件决策所需要的所有信息吗？即使人类生活在《黑客帝国》电影中的 Matrix，其中的机器人主宰也不是能掌控所有信息，如电影所说总有些自由意志是不可知。哈耶克说过「社会的经济问题就是一个知识利用的问题，而这种知识并没有完整的给予任何一个人」。所以即使在大数据时代也不可能获得全局知识与信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;三 智能助理该做什么&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;既然智能助理定位不是在收集各样信息的基础上，结合其强大的计算能力和人类已有的决策样本数据提供预测与决策建议。那是不是可以退一步，定位在收集各样信息，并辅助人类决策呢？根据诺贝尔经济学奖，图灵奖获得者郝伯特·西蒙的不确定性环境下决策理论：应当是有限的理性，而不是全知全能的理性；应当是过程合理性，而不是本质合理性。过程理性决策步骤可以参考文章 [6] 中描述。再结合智能助理的定位，我们可以设想智能助理需要实现如下功能：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="list-style-type: decimal;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;前提：客户信息收集以及相关领域信息收集&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;「具备基于上下文的对话能力，具备理解口语中的逻辑」[2].&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;提供决策相关信息以及可选方案集。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在特定领域辅助履行。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;决策后跟踪相关信息，获得新数据，是持续优化决策的过程。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;前提：客户信息收集以及相关领域信息收集&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;智能助理需要收集客户的个人信息，这不只是千人千面的客户标签画像，而是认为每个人都是独立的个体。电影《Her》中人工智能萨曼莎是位称职的智能助理，她被启动后立即申请是扫描主人公的硬盘。在扎克伯格的 Jarvis 不但控制了他家的全部家电、门禁，还包括收集个人生活偏好。「一个 AI 系统就能越好地处理开放式问题。我经常只对 Jarvis 说『播放音乐』，它会查看我过去的听歌习惯」[7]。授权智能助理收集个人信息的前提是信任，使用者必须相信电影《Her》中智能助理萨曼莎同时和 8316 个人沟通同时，每个智能助理都是独立的并能保护每位使用者个人隐私。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些天北京又持续爆表雾霾，是否要让孩子离开北京，是很多家长非常纠结的问题。吴晓波在文章 [8] 中为卖房去大理的宽宽做了一个财务规划。如果这个问题提给智能助理，其需要收集宽宽当前财务以及房产情况，并以宽宽的名义询问各银行二手房按揭利率信息，以及了解大理房价信息，是否有购房限制等等。这些都是智能助理需要收集领域知识与信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;提供决策相关信息以及可选方案集&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;参考文章 [8], 在宽宽提出移居大理后，智能助理应该根据之前收集的信息给出以下两个方案：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1）卖房 530 万，购大理房一次性付款 130 万元。400 万理财。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2）抵押房子给最优贷款条件的银行，贷款利率 5.4%，拿到 159 万元买大理房。每年需支出利息 8.58 万元，房屋租金 9.6 万元。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如何抉择并不是智能助理的职责。宽宽可以听从吴晓波基于他的专家经验，认为「人民币正处在一个不可逆转的贬值周期中…最保守的计算，未来 M2 维持年均 10% 的增速」[8] 得出结论是「所以，请你「抛弃」北京的时候，尽量不要抛弃北京的房子。」[8]。但宽宽也可以认为既然人民币正处在一个不可逆转的贬值周期中，那将 400 万换成美元理财、基金。如果房价未来以美元计价跌了，那么她再买回来。又或是她在大理找到更加明确的人生的真谛，选择了新的生活方式，不愿再回北京，那北京房价再高也和她没有关系。这些都是她的决定，无法让智能助理代其抉择，但智能助理可以提供方案以及可能的后果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;在特定领域辅助履行&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在电影《Her》智能助理萨曼莎在评价主人公文章的价值后，将其文章发给出版社编辑从而得以出版。忽略其中代替决策的部分，能知道如何在特定领域辅助履行决策已是很难。就和知道特定领域收集什么信息一样困难。目前这方面多是基于专家经验的模板实现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;决策后相关信息跟踪，获得新数据，是持续优化决策的过程&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;持续跟踪相关信息，再有新的重要信息告知用户。比方如果北京房价跌了，宽宽的美元理财、基金涨了，北京空气持续优化。这时可以让宽宽抉择是否购回北京房产。如果相反那就不用说了，免得添堵。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;预测重要，但也没那么重要&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在上面买房辅助决策中，并没有预测十年后房价，也没有预测利率、汇率，或他们未来可能的生活方式。而是提供当前事实性的信息，可贷款信息，房价信息等，以及可选的方案。当然，如果能准确预测未来房价，那就是个规划问题。目前看来，未来之眼的机器并不存在。而且如果人人都一个完美预测的机器，那就引入新的变量，原有的预测都又不准了。另外一点，目前也不可能每人都有 AlphaGo 的计算能力，有篇报道称在 2015 年 10 月的公布的版本, AlphaGo 使用一千多块 CPU 及一百多块 GPU，围棋还只是完全信息博弈游戏。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;既然无法准确预测，那就提供可选方案对当前决策缓冲预测误差影响。如用 400 万换套小些、远些的房子。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;四 总结&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本文认为，基于端到端样本数据的深度学习模型并不是智能助理的唯一模型。智能助理的定位不是提供各领域问题的专家建议与预测。而是在收集相关信息的基础上，结合其强大的计算能力为决策提供合适的事实信息以及可选的方案。应该是需符合郝伯特·西蒙的不确定性环境下决策理论，以过程理性解决问题的持续优化的过程。不只是预测。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;参考文献：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;[1] 马文·明斯基. 情感机器 [M]. 浙江人民出版社.2015,12.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;[2] Mingke. 为什么现在的人工智能助理都像人工智障？[OL].S 先生.2016-11-21.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;[3] 袁峻峰. 投资版 AlphaGo 系统探讨 [OL]. 蚂蚁金服评论 (公众号). 2016-03-14.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;[4] 机器之心编译. 业界 | 人工智能将挑战德州扑克，与人类争夺 20 万美元奖金 [OL]. 机器之心. 2017-01-06.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;[5] 胡裕靖，高阳. 扑克游戏中的不完美信息博弈 [OL].&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;[6] 袁峻峰. 结合 AlphaGo 算法和大数据的量化基本面分析法探讨 [OL]. 大数据文摘.2016-11-25.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;[7] 扎克伯格. 扎克伯格开发笔记：打造 Jarvis 的日子，我庆幸自己从未停止过编程 [OL]. 雷锋网.2016-12-22.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;[8] 吴晓波. 在大理的你，请好好呵护北京的房子 [OL]. 吴晓波频道.2016-11-30.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;作者介绍：&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;袁峻峰，花名观妙，蚂蚁金服人工智能部，复旦金融学硕士，FRM 金融风险管理师。10 年以上从事金融 IT 相关领域工作经验，包括国内银行间市场金融产品（包括衍生产品）的量化分析、市场风险管理以及相关系统实现等。目前从事并关注于金融领域机器学习相关主题与应用，欢迎探讨, 邮箱 yuanjunfeng_fr@163.com , 微信 jake-80。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心专栏文章，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 12 Jan 2017 12:48:06 +0800</pubDate>
    </item>
    <item>
      <title>学界 | OpenAI Universe加入GTA5，在游戏大作中训练人工智能</title>
      <link>http://www.iwgc.cn/link/4307215</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自OpenAI&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李泽南、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;昨天，OpenAI 宣布旗下的开源人工智能测试环境 Universe 加入了游戏大作《侠盗猎车手 5》。用户只需购买正版游戏，即可使用 Universe 中的人工智能在 Los Santos 中的 3D 环境中纵横驰骋。此次开源的项目让自动驾驶模拟测试平台 DeepDrive 在 GTA 世界中进行测试变得更加简便易行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如何收集用于训练人工智能的数据一直是各家科技公司面临的难题。在通过各种方法收集真实世界数据的同时，一些公司也在致力于构建虚拟环境——它们可以提供近乎无限的可能性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;OpenAI 一直视图构建各种不同类型的人工智能训练环境。目前，Universe 中包括了大约 2600 种 Atari 游戏，1000 种 flash 游戏和 80 种浏览器环境，可供所有人用于训练人工智能系统。GTA5 的引入是该项目的最新举措，它为训练用于自动驾驶汽车的人工智能打开了又一扇大门。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;GTA5 的游戏世界是一个内容丰富的 3D 世界。在以下视频中你们会看到，在 Universe 的新测试环境中，人工智能获取视频信息的帧数被限制在了 8FPS，环境信息和视角管理齐备。同时，在 Universe 中的 GTA5 已经将原版游戏中的所有暴力元素去除。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;iframe class="video_iframe" data-vidtype="1" allowfullscreen="" frameborder="0" height="418" width="557" data-src="https://v.qq.com/iframe/preview.html?vid=m03657867as&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0"&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;开始游戏&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;想让人工智能体进入 GTA5 的世界，你需要安装 Universe 的 Python 库（你不需要为此特意升级到最新版本）。你可以通过加入以下代码来嵌入人工智能体。与其他游戏类似，人工智能收集信息的渠道是基于游戏视频输出的。除键盘和鼠标之外，在此游戏中人工智能体可以使用模拟游戏手柄进行操纵。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相关链接：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Universe GTAV： https://github.com/openai/universe-windows-envs/blob/master/vnc-gtav/README.md#using-the-prebuilt-ami&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Universe： https://github.com/openai/universe#install-universe&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicGoT9PibokMOzrKptgycI8EMpEUaCjqanYSdNoznXPgibbhm9rSkKr5saKNgq8NxNsZJIpbM60dDuA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;在 GTA5 中，人工智能看到的游戏画面&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;DeepDrive&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;DeepDrive 是一个用于开发人工智能自动驾驶系统的开放平台。DeepDrive 使用定制框架和内存检查技术在 GTA5 中的模拟环境测试自动驾驶汽车系统。在本次发布中，OpenAI 同时提供了预先训练好的自动驾驶人工智能，以及用于训练这个系统的数据集以供参考。新的 DeepDrive 环境和人工智能都构建在 Universe 基础之上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 DeepDrive 与 Universe 整合之前，这个自动驾驶开放平台已经展现了与现代大型 3D 游戏良好的兼容性。但这次开源的系统使用起来更加方便。原始版本的 DeepDrive 应用需要使用 Windows 系统的电脑在本地运行，需要花费大约一整天的时间调试游戏和人工智能接口。而在新的 DeepDrive 中，人们只需花费大约 20 分钟来进行设置，新的系统也支持在 Linux 和 OS X 平台上运行，同时这一新的功能也与之前已有的 Universe 人工智能互相兼容（当然，使用模拟游戏手柄比键盘鼠标效果更好）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;发布&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今天发布的内容包括：&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GTA V 环境的源代码和 AMI&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;一个预训练驾驶智能体，在 Caffe 和 TensorFlow 上的实现。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相关链接：&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;源代码： https://github.com/openai/universe-windows-envs/tree/master/vnc-gtav&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;AMI：https://github.com/openai/universe-windows-envs/blob/master/vnc-gtav/README.md#using-the-prebuilt-ami&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;用于 GTA5 的自动驾驶人工智能： https://github.com/deepdrive/deepdrive-universe&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;GTA5 的集成环境支持选择视角与自定义视野。同时也拥有用于强化学习训练的奖励机制，包含避免碰撞、与目的地距离和停留在路面上等等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;环境&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 Universe 之前，DeepDrive 使用一个 DirectX 进行屏幕捕捉，且需要在 Windows 中使用 C++ 接入 Caffe 来写智能体。现在该游戏在云中的 Windows 虚拟机上运行，并通过 websockets 和 VNC 与 Universe 通信。因此该智能体可在 Linux 或 Mac 上运行，也可被写入任何机器学习框架中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWicGoT9PibokMOzrKptgycI8E0ZpmfMDicfYlGibTCHtreSibJW8Nibib5adZ0Yfib3uNvibSnDnjicxbaicP3eQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Universe&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Universe 在 VNC 上迁移画面（pixel）、键盘和鼠标，在 websockets 上迁移其他信息。为了支持转向与减速的操纵杆控制，我们把操纵杆控制行为放入了 websockets 的环境。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;就像刚发布 Universe 时所说的那样，在公共互联网络上用户能维持到 20 FPS。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;GTA V 为研究人员测试、开发人工智能提供了丰富、多样的环境。它的地图设置几乎是洛杉矶的 1/5 大小，为测试系统提供了广阔的范围。还有 257 种不同的车辆、7 种自行车和 14 类天气环境，使用单个模拟器探索大量的不同排列变化也是有可能的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWicGoT9PibokMOzrKptgycI8Ex3zpkH7X93jmEeUIYfemHQCrYw2cpCcXZeJFaQI1LibNj26ULv3aXNw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;GTA V 中圣安地列斯 49 平方英里的岛城使得研究人员有能力在忙乱的大都市中、蜿蜒的山路、平坦的沙漠以及高速公路上训练人工智能&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在该环境中，也能收集大量的标记数据：你能使用底层 GTA V 引擎来收集 2D 或 3D 边界盒（bounding boxes），并且为汽车、人行道、自行车、动物、路面、交通标志以及其他 GTA V 中超过 7000 类的物体进行标记。该环境也能通过 mods 延展到现实世界的汽车、道路建筑，甚至是整个城市。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;预训练智能体&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此次发布包括一个基线智能体，通过在人工智能玩游戏的 21 小时的数据集（大约 60 万张图片）上进行模仿学习得以训练。（内建游戏人工智能是个非常好的初始目标：它要比典型的人类玩家表现更好，因为它能获取游戏内部状态，即使它仍然会犯在高速公路上 180 度掉头这样的错误）。该基线智能体能干在多种不同的天气环境中进行驾驶、应对交通环境，遵守交通规则。它也只是个开始，我们诚邀社区其他人对它进行改进。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;iframe class="video_iframe" data-vidtype="1" allowfullscreen="" frameborder="0" height="418" width="557" data-src="https://v.qq.com/iframe/preview.html?vid=j0365dqfv4v&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0"&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其他研究人员已经证明我们能够在 GTA V 上训练视觉系统，并使用它在现实世界中分类图片。Universe GTA V 融合体使得在模拟自动驾驶系统上尝试强化学习技术变得很轻松。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;GTA V 融合进 Universe 自动地继承了所有的工具和语义，Universe 提供了可比性和可共享性，也使得在 GTA V 上评估智能体的表现变得更容易。它可被单独使用，或者作为获取通用 Universe 智能体的另一环境。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 12 Jan 2017 12:48:06 +0800</pubDate>
    </item>
    <item>
      <title>资源 | TensorFlow版本号升至1.0，正式版即将到来</title>
      <link>http://www.iwgc.cn/link/4292352</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自github&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote style="color: rgb(62, 62, 62); font-size: 16px; white-space: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/blockquote&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;2015 年 11 月份，谷歌宣布开源了深度学习框架 TensorFlow，一年之后，TensorFlow 就已经成长为了 GitHub 上最受欢迎的深度学习框架（参见机器之心文章《&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720407&amp;amp;idx=1&amp;amp;sn=768d7248e0ab5fa469dbae86d11152e1&amp;amp;chksm=871b0ce9b06c85ffefa2e0c8f6fb7ae4cc1c0500cda7bad008fe68ed6b87d7c8765d138e1fd1&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720407&amp;amp;idx=1&amp;amp;sn=768d7248e0ab5fa469dbae86d11152e1&amp;amp;chksm=871b0ce9b06c85ffefa2e0c8f6fb7ae4cc1c0500cda7bad008fe68ed6b87d7c8765d138e1fd1&amp;amp;scene=21#wechat_redirect"&gt;深度 | TensorFlow 开源一周年：这可能是一份最完整的盘点》&lt;/a&gt;），尽管那时候 TensorFlow 的版本号还是 v0.11。现在，TensorFlow 的一岁生日之后两个月，TensorFlow 社区终于决定将 TensorFlow 的版本号升至 1.x，并也已于昨日发布了 TensorFlow 1.0.0-alpha，其新增了实验性的 Java API，并且提升了对 Android 的支持。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;发布地址&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;官网：https://www.tensorflow.org/versions/r1.0/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GitHub：https://github.com/tensorflow/tensorflow/releases&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;主要特性和提升&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;TensorFlow Debugger (tfdbg)：命令行接口和 API&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;增加新的 python 3 docker 镜像&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;使 pip 包兼容 pypi。现在可以通过 pip install tensorflow 命令来安装 TensorFlow 了&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Android：人员检测+跟踪演示，是通过使用了深度神经网络的可扩展目标检测实现的&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Android：预构建的 libs 现在每晚（nightly）构建&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;新的（实验性的）Jave API：https://github.com/tensorflow/tensorflow/tree/master/tensorflow/java&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;API 的重要更改&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;TensorFlow/models 被移到了一个单独的 GitHub repository.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;除法和取模运算符（/, //, %）现已匹配 Python（flooring）语义。这也适用于 tf.div 和 tf.mod。为了获取强制的基于整数截断的行为，你可以使用 tf.truncatediv 和 tf.truncatemod.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;tf.divide 现在是推荐的除法函数。tf.div 还将保留，但其语义将不会响应 Python 3 或 from future 机制.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;tf.reverse 现在是将轴的索引反转。例如，tf.reverse(a, [True, False, True]) 现在必须写成 tf.reverse(a, [0, 2])。tf.reverse_v2() 暂时保留，直到 1.0 final 版.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;tf.mul、tf.sub 和 tf.neg 被弃用，现在使用的是 tf.multiply、tf.subtract 和 tf.negative.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;tf.pack 和 tf.unpack 被启用，现在使用的是 tf.stack 和 tf.unstack.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;TensorArray.pack 和 TensorArray.unpack 将被启用，取而代之的是 TensorArray.stack 和 TensorArray.unstack.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;以下 Python 函数有参数修改，以在引用特定维度时使用 axis. 我们目前基于兼容性的考量而保留了原来的关键词参数，但我们将在 1.0 final 版中移除它们。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: circle;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;tf.argmax: dimension 变成 axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;tf.argmin: dimension 变成 axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;tf.count_nonzero: reduction_indices 变成 axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;tf.expand_dims: dim 变成 axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;tf.reduce_all: reduction_indices 变成 axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;tf.reduce_any: reduction_indices 变成 axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;tf.reduce_join: reduction_indices 变成 axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;tf.reduce_logsumexp: reduction_indices 变成 axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;tf.reduce_max: reduction_indices 变成 axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;tf.reduce_mean: reduction_indices 变成 axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;tf.reduce_min: reduction_indices 变成 axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;tf.reduce_prod: reduction_indices 变成 axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;tf.reduce_sum: reduction_indices 变成 axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;tf.reverse_sequence: batch_dim 变成 batch_axis, seq_dim 变成 seq_axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;tf.sparse_concat: concat_dim 变成 axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;tf.sparse_reduce_sum: reduction_axes 变成 axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;tf.sparse_reduce_sum_sparse: reduction_axes 变成 axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;tf.sparse_split: split_dim 变成 axis&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;tf.listdiff 已被重命名为 tf.setdiff1d 以匹配 NumPy 命名.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;tf.inv 已被重命名为 tf.reciprocal（分量互逆）以避免和矩阵求逆的 np.inv 混淆&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;tf.round 现在使用了四舍六入五留双规则语义，以匹配 NumPy.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;tf.split 现在以相反的顺序取参数，并使用了不同的关键词。特别地，我们现在将 NumPy 顺序匹配成了 tf.split(value, num_or_size_splits, axis).&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;tf.sparse_split 现在以相反的顺序取参数，并使用了不同的关键词。特别地，我们现在将 NumPy 顺序匹配成了 tf.sparse_split(sp_input, num_split, axis). 注意：现在我们暂时让 tf.sparse_split 需要关键词参数.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;启用 tf.concat 运算符，现在请暂时切换成 tf.concat_v2 . 在 Beta 版中，我们将更新 tf.concat 以匹配 tf.concat_v2 的参数顺序.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;tf.image.decode_jpeg 默认使用更快的 DCT 方法. 速度的提升牺牲了一点保真度。你可以通过特定属性 dct_method='INTEGER_ACCURATE'来恢复原来的行为.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;tf.complex_abs 已被从 Python 接口移除. 应该使用 tf.abs，它支持复数张量.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;模板.var_scope 属性重命名为 .variable_scope&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;SyncReplicasOptimizer 被移除，SyncReplicasOptimizerV2 重命名为 SyncReplicasOptimizer.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;tf.zeros_initializer() 和 tf.ones_initializer() 现在返回一个 callable，其必须用 initializer 参数调用，在你的代码中用 tf.zeros_initializer() 替代 tf.zeros_initializer.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;SparseTensor.shape 重命名为 SparseTensor.dense_shape. SparseTensorValue.shape 也一样.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;移除了原来的 tf summary 运算符，比如 tf.scalar_summary 和 tf.histogram_summary. 取而代之的是 tf.summary.scalar 和 tf.summary.histogram .&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;移除 tf.train.SummaryWriter 和 tf.train.SummaryWriterCache.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;从公共 API 中移除 RegisterShape . 现在使用 C++ 形状函数注册.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;从 Python API 弃用 _ref dtypes .&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;漏洞修复和其它更改&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;新指令： parallel_stack.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;为 RecordReader/RecordWriter 引入常见的 tf io 压缩选项常量.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;添加 sparse_column_with_vocabulary_file，其能指定一个将字符串特征转换为 ID 的特征列（feature column），其中的映射是通过一个词汇表文件定义的.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;添加 index_to_string_table，其返回一个将索引映射到字符串的查找表.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;添加 string_to_index_table，其返回一个将字符串匹配到索引的查找表.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;添加一个 ParallelForWithWorkerId 函数.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;支持从 contrib/session_bundle 中的 v2 中的检查点恢复会话.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;添加了一个用于任意角度的 tf.contrib.image.rotate 函数.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;添加了 tf.contrib.framework.filter_variables，这是一个用于基于正则表达式过滤变量列表的方便函数.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;make_template() 加入了一个可选的 custom_getter_ param.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;添加了关于现有目录如何被 recursive_create_dir 处理的注释.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;添加了用于 QR 因式分解的指令.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Python API 中的除法和取模现在使用 flooring (Python) 语义.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Android：在 contrib/android/cmake 下，用于 TensorFlow Inference 库的 cmake/gradle build&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Android：远远更加稳健的会话初始化代码.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Android：当 debug 模式激活时，TF stats 直接出现在演示和日志中.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Android：新的更好的 README.md 文档.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;致谢我们的贡献者&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个版本包含了来自谷歌很多人的贡献，此外还有以下贡献者：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodcFhyvB9uT3y2lmKnQMWVbYEqhup3T2KSyGSxN0w7K4NuGaECYbl4vGA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们也非常感激所有提交了问题或帮助解决它们的所有人——提出和回答问题也是激发讨论的一部分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;下载源代码&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;zip ：https://github.com/tensorflow/tensorflow/archive/v1.0.0-alpha.zip&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;tar.gz：https://github.com/tensorflow/tensorflow/archive/v1.0.0-alpha.tar.gz&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 11 Jan 2017 13:40:32 +0800</pubDate>
    </item>
    <item>
      <title>深度 | 自然语言处理领域深度学习研究总结：从基本概念到前沿成果</title>
      <link>http://www.iwgc.cn/link/4292347</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自adeshpande3&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote style="color: rgb(62, 62, 62); font-size: 16px; white-space: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/blockquote&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;每隔几周，加利福尼亚大学洛杉矶分校（UCLA）的 Adit Deshpande 就会在其博客上发表一篇深度解读的深度学习研究回顾博客。今天这篇是 Adit 的这一系列的第三篇博客，将主要介绍深度学习在自然语言处理当中的应用。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;自然语言处理简介&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自然语言处理（NLP）是创造能够处理或是「理解」语言以完成特定的任务的系统。这些任务可能包括：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;问答系统（也就是Siri、 Alexa和小娜所做的事情）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;情感分析（判断一句话隐含的积极或消极意义）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;图片题注（为输入的图像生成一个标题）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;机器翻译（将一段文本翻译成另一种语言）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;语音识别&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;词性标注&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;命名实体识别&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;传统的自然语言处理方法涉及到了很多语言学本身的知识。理解诸如音素（phonemes）和语素（morphemes）等术语都是非常必须的，为了学习这些专业知识，还要学习完整的语言学课程。接下来让我们看一些传统的自然语言处理是如何理解下面这一单词的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodcw7c2XFRMfcoMre0rn9PRcS64WX0Y2M32JdWLamnrxicCCibUt10BpDLg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;假设我们的目标是要收集关于这一单词的一些信息（描述它的情感、寻找它的定义等）。&lt;/span&gt;&lt;span&gt;利用我们在语言上的专业知识，我们把这个单词分为三部分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodchL8vGuGopjlrVibIq6wfdYBgXEvc4UonWdP8kmnjlg1aJJyIDibDnLJA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们知道这个单词的前缀「un」表示的是一种相对立的或是相反的概念，「ed」能够限定这个单词的时态（过去时）。通过对这个单词主干部分「interest」的理解，我们能够很容易地推断出整个单词的意思和情感。看起来是不是非常地简单？但是，当你要考虑到英语中所有不同的前缀和后缀的时候，可能就需要一位非常有技巧的语言学家才能理解所有可能的组合和意义。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodczSicfFZcOI878pT4ian7fPStBtCiakJzIsjGTyvAEY6tSmDHM6kDe9mwQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;如何将深度学习应用其中&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深度学习，从其最基本的层面来说，是表征学习（representation learning）的一种方法。利用卷积神经网络，我们可以看到用来对事物进行分类的不同过滤器的组成。在这里，我们将要采取一种类似的方法，利用大数据集为词汇创造表征。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;本文概述&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这篇文章中，首先我们将了解为自然语言处理建立深度网络的基本构建模块，之后将对最近研究论文的一些应用进行讨论。大多数人都不明确了解为什么我们要使用循环神经网络（RNN）或者是长短期记忆（LSTM）为什么会有用，但是我希望在我们讨论完研究论文之后，你可以对为什么深度学习会为自然语言处理提供这么大的帮助有更好的理解。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;词向量&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因为深度学习和数学密不可分，我们将要把每一个单词都表征为一个d维向量。我们将d设定为6。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodcVIjxUbGUJ5zu3ibTnibJjGnSGWxEJZH3ZfX9Sl5aBSMCvSgaRkf2DKhg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在让我们想一想该如何填写值。我们希望填写值的方式可以让向量表征词，以及词的语境、意思或语义。一种方法就是建立一个共生矩阵（coocurence matrix）。以下面这一句话为例。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodcVWdHbfvJD5IdwXqvp43iagHIsxysj8GCcJgBAbGIUN9Hth8foOG1dvg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这一句话中，我们想要给每一个词都建立一个词向量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodclRP8K1sM9vbeYicvQq79W8t5P0fJlKXSGSWsQQ8JdiaceU10gM8iaapbg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;共生矩阵中包含了在语料库（或是训练集）中每一个词出现在其他词语旁边的次数。让我们看看下面这个矩阵。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodcF3jtnozXaCeZB6jnZmX3xJwdmruCGaMiaoGRs7TKOoxn5OPJ0bJBKWw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;将这个矩阵的行提取出来能够让我们对词向量有一个简单的初始化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodcTYsmKicSiadyicgB8FtJj6PcRYL31XWv8tib3GScGmX5R0HTFiaw741cZdg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;注意，通过这个简单的矩阵，我们将能收获非常有用的见解。例如，注意「love」和「like」，这两个词与名词（NLP 和dogs）相连的次数都是1。和「I」相连的次数也是1，所以这表明这两个单词一定是动词。如果说我们拥有更大的数据集，而不是简单的一句话，你可以想象，这种相似性就会变得越来越明显，就像是「love」和「like」一样，其它的一些同义词也会开始拥有相似的词向量，因为它们一般都会在相似的语境下使用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在，虽然我们的起点很好，但是我们也注意到每一个词的维度都会随着语料库的扩大直线上升。如果我们有100万个词（在自然语言处理的标准中不算多），我们就会有100万乘以100万大小的矩阵，而且这一矩阵会非常的稀疏（有很多的0）。从存储效率来看这一定不是最好的。在寻找表征这些词向量的最优方法中也存在着很多的先进技术。其中最著名的就是Word2Vec。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Word2Vec&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;词向量初始化技术的基本思路就是要在词向量中储存尽可能多的信息，同时也要将维度控制在一个可以管理的范围之内（25 – 1000维是理想的）。Word2Vec让我们可以预测每一个单词周围的单词。还是以我们之前提到的句子「I love NLP and I like dogs.」为例。我们首先来看一看这句话的前三个单词，因此我们就要把我们的窗口大小m设置为3.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodcAUXxdlUBH2XgIehoY52nviaAfL6ZxEQ2rFgGicqqhlia57lZuXzZ9B14A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在，我们的目标是提取中心词「love」，然后预测可能在这个词之前或之后出现的词。我们应该怎么做呢？通过将一个函数最大化/最优化！一般来说，我们的函数都会将现有中心词的上下文单词的对数概率最大化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodcTORicKntvexQDU1fhuj16SguqMud76cylt1IlqqzoFT7k3yRCO74aiaA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;让我们再做一些更深入的了解。上文中的成本函数基本上是在说我们要增加「I」和「love」以及「NLP」和「love」的对数概率（love在两种情形当中都是中心词）。变量T代表的是训练句子的数量。让我们再来了解一下对数概率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodcyIibtnrX8XoePniaTjhtI8aehypvpSnVIcyVdORdeXibk40lBQ08B2rBQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Vc是中心词的词向量。每一个单词都有两次向量表征（Uo 和 Uw），其中一个是当单词作为中心词时，另一个是当单词用作外部词语时。这些向量都经过随机梯度下降法的训练。这一定是令人困惑的方程式之一，也是我们需要理解的，所以如果你还是难以想象正在发生的事情，你可以查看更多的资源加以了解。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一言以蔽之：在给定一个中心词的情况下，Word2Vec 通过最大化上下文单词的对数概率并通过随机梯度下降（SGD）来修改向量，试图找到不同词的向量表征。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;注：论文《Distributed Representations of Words and Phrases and their Compositionality》谈到了更多细节：常见词的负采样和子采样能如何被用于获取更精确的词向量。）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Word2Vec 的最有趣的贡献在于展现出不同词向量之间的线性关系。训练后，词向量似乎捕捉到了不同语法和语义概念。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodc2u7tHictUWd5m9M6exI2fv3l8VRMIO3SBT0iciaO5t6jnc7JJdCF5Z0uA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;难以置信的是，这些线性关联可以如何通过一个简单的目标函数和优化技巧得以形成。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;福利&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：另一个很酷的词向量初始化方式：GloVe（将共生矩阵与Word2Vec结合起来）:http://nlp.stanford.edu/pubs/glove.pdf&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;循环神经网络（RNN）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在我们已经拥有词向量了，然后看看它们是如何拟合循环神经网络的。循环神经网络现在已是大多数自然语言处理（NLP）的必需品。循环神经网络最大的优点是它能有效地使用先前时间步骤的数据。这就是一小块循环神经网络大概的样子。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodcrZhHdfo9upzE5eBbHFKNQBChsMJJlGSx6WrvE0vuPuR6ibdxyJFCMfg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在底部我们有词向量（xt，xt-1，xt+1）。每一个向量在同一时间步骤（ht， ht-1，ht+1）有一个隐藏状态向量（hidden state vector）。我们称这些为一个模块。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodcwq4uNCt4iaySHvibhhpibiauVlhwGaibagg4ricDW3tUgpsOfROPLNsPEU0A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;循环神经网络每个模块中的隐藏状态是前一时间步骤（previous time step）的隐藏状态向量和词向量的函数：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodcIAj75AAHG3Tic3kp7TWIZiaajgHLf99KWPicoa76SzdAThVdh95jc5PLw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;span&gt;如果仔细看看上标，你会发现有一个权重矩阵Whx，我们会将Whx矩阵与输入相乘，并且会有一个循环权重的矩阵（recurrent weight matrix）Whh乘以在前一时间步骤的隐藏状态向量。切记这些循环权重矩阵在所有时间步骤都是相同的，这也是循环神经网络的关键点。仔细想想，这和传统两层神经网络有很大的不同。传统情况下，我们每一层（W1和W2）通常会有不同的权重矩阵W，而这里的循环权重矩阵在整个网络中都是相同的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;要得到特定模块的输出（Yhat），就需要将h乘以WS，这是另外一个权重矩阵。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodcJHUmFGZH85vP0ecD54U22XibTDTiaZ6t2YRibGKyePS79AH9lmDicuiaVcQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在我们退一步，了解循环神经网络的优点在哪。与传统神经网络最大的不同就是循环神经网络可以接收输入序列（我们例子中的词）。你可以将其与典型的卷积神经网络对比，其只能是将单一图片作为输入。然而使用循环神经网络，输入可以小到短句，大到有 5 个段落的文章。此外，该输入的序列顺序能极大地影响到权重矩阵和隐藏向量在训练中如何改变。隐藏状态在训练后期望能从过去（前面的时间步骤）获取信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;门控循环单元（GRU）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在让我们看一个门控循环单元（gated recurrent unit/GRU）。这个单元的目标是提供一种更复杂的方法来计算我们在循环神经网络中的隐藏状态向量（hidden state vectors ）。这种方法将允许我们储存信息并捕获长距依赖性（long distance dependencies）。让我们想象下为什么长期依赖性（long term dependencies）在传统的循环神经网络构架中存在问题。在反向传播中，误差将流经循环神经网络，从最近的时间步骤到最早的时间步骤。如果初始梯度是较小的数字（如小于0.25），那么在通过第三或第四模块时，梯度实际上会消失（链式规则与梯度一起乘积），因此较早时间步骤的隐藏状态将不会更新 。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在传统循环神经网络中，隐藏状态向量是通过该公式计算的：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodcmexQ6WjHpquam5xgV0iaNrkt7sbCOiceK5VyIRQ8hutYLAHe36ja5H2g/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;GRU提供了一个不同的方式计算隐藏状态向量h(t)，该计算分为三个分量，一个更新门（update gate）、一个重置门（reset gate）和一个新的记忆存储器（memory container）。两个门都是输入词向量和在前时间步骤的隐藏状态函数：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodcluMBuLlTbfibHpmuOvcgRJV3DSDT1cz7dywlAibCeUM8ksWL70uvkASA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关键区别是每个门使用不同的权重，这由不同上标来表示。 更新门（update gate）使用Wz和Uz，而重置门（reset gate）使用Wr和Ur。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在，新的记忆存储器（memory container）就是通过以下方式来计算的：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodcAicaBsf4KhhaI6olpxDAa8kBGHAib0liaMV0ibUnndgHU5L6WzIibsnicoSA/0?wx_fmt=png"/&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;（空心点指的是Hadamard 积）&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在，如果仔细看看公式，你会发现如果重置门的值接近0，那么这整个项也会变成0，因此忽略了在先前时间步ht-1的信息。在这种情况下，计算单元仅仅只是新词向量xt的函数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;h(t)的最终公式如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodcic9YUrm86D8WWDjliccUdmFibRDnVQh4xENk1HZyIvNGFVd1QkrmEaY2A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;ht 是一个有三个部分的函数：重置门、更新门以及记忆存储器。理解这一点的最佳方式就是当 zt 接近1 以及 0 的时候，视觉化所发生的情况。当 zt 靠近1，新的隐藏层向量 ht 几乎取决于之前的隐藏层，而且因为(1-zt) 变成 0，我们忽略了当前记忆存储。当 zt 接近 0 时，新的隐藏层向量几乎取决于当前记忆存储，我们忽略了之前的隐藏层状态。以一种直觉的方式观察这三个组成部分，可以归纳为以下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1.更新门（Update Gate）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如果zt趋向于1，ht就完全忽略现在的词向量，仅仅只是复制前隐藏状态（如果不是太理解，请查看ht方程并注意当zt趋向于1时，1-zt有什么改变）。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如果zt趋向于0，ht就完全忽略前一时间步骤的隐藏状态，仅仅只依赖于新的记忆存储器。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;此门控能让模型控制前一隐藏状态的信息多大程度上影响现在的隐藏状态。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2.重置门（Reset Gate）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如果rt趋向于1，记忆存储器将保持前一隐藏状态的信息。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如果rt趋向于0，记忆存储器将忽略前一隐藏状态的信息。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;此门控能允许模型在丢弃一些对未来不相干的信息。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3.记忆存储器（Memory Container）： 依赖于重置门。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个通常用来说明 GRU 有效的例子如下：假设你遇到下面一段话&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodcaNyfibXciaLmTxhvd2sSNqfRWppgSia72vgAOL2zNm977Rzkf99qnzNYQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以及相关问题 What is the sum of the 2 numbers 。既然中间句子对手边问题绝对没有影响，但是，重置和刷新门会让网络在某种意义上“忘记”中间的句子，并学会只有特定信息（这个例子中的数字）才应修改隐藏状态。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;长短期记忆单元（LSTM）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你对GRU 已经很了解了，那理解LSTM对你一定不会太难 。一个LSTM也是由一连串的门（gate）组成。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodcTL9OPdp4JtIf0GPRO0yWic2ubbsZQrviaC0h0V1lSg6ZkIIdtEib85kGQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然， 这里面涉及到更多的知识。 不过因为LSTM可以理解为GRU的衍生物，我将不会过多的分析，但如果你想更深入的了解每个门， 每个计算，你可以点击查看Chris Olah 写的一篇超棒的博文：http://colah.github.io/posts/2015-08-Understanding-LSTMs/ 。这篇文章是目前关于LSTM最受欢迎的教程，并且一定对你们这些想要知道其背后的工作原理的人提供很大的帮助。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;比较和对比 LSTM 与 GRU&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;让我们先从相似点出发。 两者的单元组件都有一个能够记录长时间的词与句子之间依赖关系的特殊函数。 这种长期依赖性， 指的是在一些情况下， 两个词或者词组可能在不同的时间点出现，但两者间的关系对实现最终目标十分关键。 LSTM 和GRU 能够通过一些门（gate）来忽略或者保留语句中的某种信息，从而捕捉这些依赖性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;两者基本单元的不同处在于， 它们拥有的门（gate）的数量（GRU有两个， LSTM有三个）。这一点将影响到输入能够传递的非线性关系个数， 并且最终影响到总体的计算。 另外，GRU并没有和LSTM的记忆单元（C_t）一样的记忆单元。&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;在阅读论文之前&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这部分只是想快速做个提示：还有其它的深度模型对NLP有用。在实践中有时使用循环神经网络和CNN，但却不像RNN 这么流行，它是大部分深度学习NLP系统的支柱。现在，我们已经对NLP与深度学习的关系有了足够了解，接下来看几篇论文。由于NLP领域有不同的问题（从机器翻译到问答系统），所以圈内有大量可以看的论文，但我在此文章中发现了3篇很有洞见的论文。2016年NLP领域有了极大的发展，但我们先从2015年的一篇论文开始说起。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;记忆网络（Memory Networks）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;论文：https://arxiv.org/pdf/1410.3916v11.pdf&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;介绍&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们首先要讨论的第一篇论文， 在问答系统这一子领域很有影响力。 这篇论文由Jason Weston, Sumit Chopra以及 Antoine Bordes撰写，介绍了一类名为memory networks 记忆网络的模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这一想法来自于当你想要精准地回答一个关于一篇文本的问题， 你必须要记住该文本大致的内容。如果我来问你一个问题“RNN表示什么’”（在你已经完全阅读了这篇博文的前提下） 你就一定能告诉我答案。 这是因为你通过阅读、存储记忆，已经吸收了这些知识。你只需要简单的花几秒钟去定位这条信息， 然后把它用通顺的语言表达出来。 目前， 我并不知道大脑是如何做到的， 但需要地方去存储信息的这一想法一定是存在的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这篇论文描述的记忆网络有些特别，因为它含有一个联想记忆（associative memory ）。这种联想记忆能够读写。 值得注意的是我们在CNN或者Q网络（用于强化学习）或者其它的传统网络中并不能找到这种类型的网络。这有部分是因为问答任务很大程度上依赖于系统能够建模或者追踪长期的依赖关系，比如在一个完整的故事中记录一个人物的进展，或者记录时间轴上的重要事件。在CNN或者Q网络中， 记忆模块被植入在网络的权重体系中，因为网络需要能够学习不同的滤波器或者将状态映射到动作上。 初看， RNN和LSTM可能能用来实现这一记忆功能， 但它们通常不能记住来自过去的输入， 而这对于问答系统是至关重要的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;网络架构&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;好的，让我们看看这个网络是如何处理给定的最初文本的。和几乎所有的机器学习算法一样，首先将输入转变成一个特性表征。这需要用到词向量、词性标注、解析等，这些是由程序员决定的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodcaOF60zLJnoyuiaJuHqwy1Z94dOvznK1uAeRhO0J9TJo8vqbXsvbCOAQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下一步就是提出特征表征I(x)，并允许我们的记忆 m 进行更新，从而反映出我们已经接收到的新输入 x。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodc9d2o0ibFell3zRlbKWnrfPCy8ibo6icziaPDzTOPZIVsxd9jvGuIyx4HwA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你可以将记忆 m 视为由单个的记忆 mi 构成的一个序列。这些单个记忆 mi 的每一个都能成为整个记忆 m &amp;nbsp;的一个函数，特征表征 I(x)，和\或其自身。函数 G 能简单到在单个记忆单元 mi 中仅存储整个表征 I(x)。你能基于新输入修改函数 G ，更新过去的记忆。第三、四部包括根据问题读取记忆，获得一个特征表征 o, &amp;nbsp;然后将其解码输出一个最终答案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodcziaSU9Z2JS9IVeOgyxryxmUKbXFcBD1eJPEibibZZRtu1scQ4uiat6ictWQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;函数 R 可以是个 RNN，被用来将来自记忆的特征表征转化为一个可读的、准确的问题答案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在，进一步看看第三步。我们希望 Ｏ模块能输出一个特征表征，将可能的答案最好匹配给一个给定问题 x。现在，这个问题会与每一单个的记忆单元进行比较，也会根据记忆单元能否好好支持问题来打分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodcmezR5Yicc45GTmcicCicbGdFtQOR3ZKY7EDFxvVKjrjzx9zGz6ZpkiaTfw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们求评分函数的 argmax，找到能最好支持问题的输出表征（你也可以取多个最高得分单元，不必限于1个）。评分函数就是计算不同问题嵌入和选中记忆单元之间的矩阵积。（欲知详情，请阅读论文）。当你乘以两个词向量以求其相似性时，你会想到这个。然后，这一输出表征 o 会被输入一个 RNN 或者 LSTM ，或者输入另一个会输出可读结果的评分函数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;训练方式是监督训练，训练数据包括原始文本、问题、支撑句（ supporting sentences）以及基底真实答案。这里是目标函数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodcmacA4YfiagTHuY9s2hwOHosic9FcdJBluQQrn4cibVhZlmURbGv6OQeXA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;感兴趣的读者，下面这些论文谈到了构建这类记忆网络的方法：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;End to End Memory Networks (https://arxiv.org/pdf/1503.08895v5.pdf) &lt;/span&gt;&lt;span&gt;(仅需监督输出，不支持句子）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Dynamic Memory Networks (https://arxiv.org/pdf/1506.07285v5.pdf)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Dynamic Coattention Networks (https://arxiv.org/pdf/1611.01604v2.pdf)&lt;/span&gt;&lt;span&gt;（2个月前才发布，斯坦福问答数据组中获最高得分&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;情感分析的树LSTMs&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;论文：https://arxiv.org/pdf/1503.00075v3.pdf&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;介绍&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下一篇论文分析了情感分析领域取得的进展，情感分析就是判定某个短语的语气/意义是积极的还是消极的。更正式一点的说法，情感可以被定义为对某一状况或时间的观点或态度。这时，LSTMs就是情感分析网络中最常用到的部件。这篇由Kai Sheng Tai, Richard Socher, and Christopher Manning 合作的论文介绍了一种将LSTMs 链入非线性结构的有趣方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种非线性安排背后的想法在于：自然语言具有这样的特质，亦即单词按某种顺序排列后就变成短语。这些依据单词顺序构成的短语所表达的意思和构成短语的单词的意思是不同的。为了能表征出这一特点，一个LSTM的网络单元就必须被安排进一个树结构，其中 ，不同的单元会受它们的子节点（ children nodes）影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;网络架构&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Tree LSTM 和 标准 LSTM 的一个不同之处在于，后者隐藏状态是一个关于当前输入和之前时间步骤上的隐藏状态的函数。不过，有了这个结构，它的隐藏状态就是关于当前输入及其子单元隐藏状态的函数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodcdpiariaYD4tzWwfBbcp2vRCKlGq1GSxiaPBwyUgiaSVicDciaqk0l3sD07ww/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;新的树结构会带来一些数学上的变化，包括子单元忽略掉门。那些对细节感兴趣的读者，可以研读这篇论文。不过我的焦点是理解这些模型会比线性的LSTM效果更好的原因。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个Tree-LSTM，一个单独的单元就可以吸收所有子节点的隐藏状态。这很有趣，因为一个单元可以分别评估其子节点。训练过程中，网络能意识到一个特定的单词（或许是情感分析中的“not”或者“very”）对句子整体情感分析的极端重要性。能给予那个节点更高一点的估值，这一能力让网络具有了很大的灵活性，也提升了网络表现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;神经机器翻译&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;论文：https://arxiv.org/pdf/1609.08144v2.pdf&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;介绍&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后一篇论文讲述了解决机器翻译任务的方法。作者来自谷歌机器学习那些颇有远见的学者们 ：Jeff Dean、Greg Corrado、Orial Vinyals 等。这篇文章介绍了一种机器翻译系统，也是谷歌翻译服务背后的支柱。较之谷歌之前使用的产品系统，该系统平均降低了60%的翻译误差。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自动翻译的传统解决方案包括基于短语的变量匹配。这一方法需要大量语言领域的知识而且这一设计最终也被证实太脆弱也缺乏泛化能力。传统解决方案的问题之一就是一点一点地翻译输入句子。结果，更有效的解决方法是一次翻译整个句子，这种方法让更广泛的上下文以及更加自然的语词再安排成为可能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;网络架构&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该论文的作者介绍了一个深度 LSTM 网络，能够用 8个解码器和编码器层进行端到端的训练。我们能把该系统分解成3个组件：编码器RNN、解码器RNN、注意模块。从高层级来看，编码器要做的任务是将输入语句转换成向量表征，然后解码器产生输入表征，然后注意模块提示解码器在解码的过程中应该注意什么（这是利用输入语句全部语境的思路所在）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodcaVOqJ9kYiaD4KsFq5ZoepcfH9yEIibxXda3CicCzEwuBMd8whRz9HpgHA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;论文的其他部分主要专注于规模化该服务的挑战上。计算资源量、时延、高容量部署这样的话题都进行了长篇介绍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;结论&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在此博客中，我们总结了深度学习如何帮助了自然语言处理任务。在我的认识中，该领域内的一些未来目标包括：改进消费者服务聊天机器人、完美的机器翻译，并且希望能让问题回答系统掌握对无结构文本或长文本（比如 wikipedia 文本页）更深的理解能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;em style="max-width: 100%; color: rgb(136, 136, 136); font-size: 16px; white-space: normal; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;原网址：https://adeshpande3.github.io/adeshpande3.github.io/Deep-Learning-Research-Review-Week-3-Natural-Language-Processing&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em style="max-width: 100%; color: rgb(136, 136, 136); font-size: 16px; white-space: normal; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;em style="max-width: 100%; color: rgb(136, 136, 136); font-size: 16px; white-space: normal; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 11 Jan 2017 13:40:32 +0800</pubDate>
    </item>
    <item>
      <title>深度 | 构建好奇的机器，Maluuba的通用人工智能探索（附论文）</title>
      <link>http://www.iwgc.cn/link/4292348</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Maluuba&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李泽南、朱思颖&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote style="color: rgb(62, 62, 62); font-size: 16px; white-space: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;人类具有对认识和理解的天生欲望。从学习骑自行车到学习在线课程，我们通过与周遭环境互动来获得信息。最近，我们受到人类学习方式的启发，开发了一套任务，让人工智能体学会了如何通过提出问题来寻找有效信息。同时，我们也设计了一个基于深层神经网络的人工智能系统，它可以通过高效的信息搜索完成这些任务。我们相信，这些研究让人类向通用人工智能迈出了重要一步。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;问正确的问题&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;假如你在和朋友聚餐，在饭桌上玩起了「20 个问题」游戏。现在轮到你了，你决定让大家来猜「猫」。他们开始从大范围问题切入：「它/他是活物吗？」，「它/他是一个人吗？」，「它/他是一种动物吗？」，「它是否生活在水下？」。首先猜出正确答案的人会成为胜利者，所以你的朋友们不仅需要找出正确的答案，而且还要尽量少问问题。基于简单的是或不是的回答方式，你的朋友们可以很快地缩小寻找范围，最终猜出正确的答案「猫」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个例子说明了人类寻找信息的过程具有的迭代性质：你正在寻找的信息永远基于你已经获得的信息。同样，为了保持效率，寻找信息的智能体必须在某种意义上理解它已经获得的信息。它必须知道自己已经知道了什么，从而可以知晓如何达成自己真正需要完成的任务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「20 个问题」的例子也表明了交流通常是在受限的条件下进行的：每个答案都是简单的是或否（仅仅传递 1bit 信息），而且问题的数量也是有限的。在现实世界中我们对于信息的搜索往往面临同样的困局——我们通过有限的语言在有限的时间内交流。比如在网上搜索，思考为朋友挑选哪件礼物，你一开始会随便搜搜——以对方的年龄、性别和自己的钱包为导向——随后再在缩小的范围内以兴趣和推荐等条件为依据找到最终目标。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由于这种方式构建了智能行为的基础，人们对人工智能寻找信息的方法已经进行了广泛的研究，认知科学、心理学、神经科学和机器学习的角度都已被涉足。例如，在神经科学中，信息寻找策略通常被解释为对新奇，令人惊讶或不确定的事件的偏见（Ranganath 和 Rainer，2003）。信息寻找是乐趣和创造力等概念的一个关键组成部分（Schmidhuber，2010）和内在动机（Oudeyer 和 Kaplan，2007）。也有一些研究认为注意力机制是人类寻找信息的策略，通过忽略不相关的特征提高了处理问题的效率（Mnih 等人，2014）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;信息搜索的新任务&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;研究人员会使用各种工具和系统用来训练人工智能，从数据集到定制学习环境。人工智能已经在国际象棋、围棋、Atari 游戏中取得了令人瞩目的成就。同样，许多人类热衷的游戏看起来正是为了训练信息搜索而设计的，也许人类能从信息搜索的过程中得到快感。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此，我们设计了一套信息搜索的任务集来训练和评估人工智能的信息搜索能力。在这里我们展示了三种任务（其他的任务详见我们的论文）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;iframe class="video_iframe" data-vidtype="1" allowfullscreen="" frameborder="0" height="418" width="557" data-src="https://v.qq.com/iframe/preview.html?vid=g03641k0wol&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0"&gt;&lt;/iframe&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在任务集中，最有意思的任务就是「刽子手」，「面部识别」和「战船」。这些任务中，每一个都有自己的独特规则和获胜目标。更重要的是，每个任务都需要人工智能可以在已有信息的基础上寻找更多信息。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_gif/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodcraiaxKm3BKaolfPTOa3yzgkseFP0uzZvH0KsZs85Zw3xhSqu4rNRmibA/0?wx_fmt=gif"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;刽子手：西方经典游戏，给出一个单词，人工智能必须在指定轮次内猜出该单词的每一个字母。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_gif/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodc43VYFoicJSUvviaoG40yzqyV00Zj8UOocxL99Y1wZlzkhiboGeZXThDQQ/0?wx_fmt=gif"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;面部识别：人工智能需要在这个游戏中回答诸如：「这个人是否戴着帽子？」「这个人是否有胡子？」这类的问题。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_gif/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodc0tjnY0SFhBRraPmTicia6z4bohZMu9kTWKsg78abfkBgtOLBH6xPWxgg/0?wx_fmt=gif"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;战船：人工智能需要击沉地方战船，它们会随机出现在网格中，事先处于隐藏状态，选择正确的网格意味着敌方被「击中」。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;训练模型来获取信息&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在我们任务中人工智能的行为表现可以理解为对其周围环境进行提问，如「这个短语包涵字母'a'吗？」或者「这部分的像素块看起来像什么？」为了成功获取信息，一个人工智能体必须学会提出有效问题并消化由此获取的信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们开发了一个模型，这一模型被训练用来完成上述任务。在完成某一任务的每一步里，模型都会提出一个其所认为当前情形下最有效的问题，然后从环境中获取相应的回复，并进一步将所获取的回复与其既有的知识（knowledge）整合。这个模型是一个深度神经网络，通过把强化学习的技巧（具体是：广义优势估计——Generalized Advantage Estimation，Schulman 等人，2016）和反向传播结合起来的方式训练得到。详细内容请参阅该研究的论文。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodc6NHXW7jBOVg84eicOfGL4lAKpEUOrEoU0tBefZ4S9RdwIkf330C9XxA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;span&gt;在训练中，人工智能会寻求奖励最大化，这个最大化奖励包涵多个特定任务的外部奖励和一个任务无关的内部奖励。外部奖励促使人工智能体通过尽量多的问题来获取有效回复，内部奖励促使模型提出能获取环境最新信息的问题。具体来说，我们对每个问题的奖励设置是依据这个问题的回复能多大程度增加模型的认知与世界真实状态之间的相似度。因此，人工智能学会了如何高效的对周围环境构建一个与之对应的精确内部图。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;目标：通用人工智能&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;就如在 demo 里展示的那样，我们的方法所训练出的人工智能体能够成功完成较广泛领域内的任务。同样的方法可以用于语言处理问题、图像处理问题以及决策问题。在我们的任务中，所训练出来的人工智能的行为是具备可解释性的，且这些系统具有智能化的信息获取能力，它们的效率经常超过人类的水平。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们希望这些研究能为通用智能的发展奠定基础。我们当下的工作只是朝实现这一宏伟目标所迈出的一小步。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;相关论文：TOWARDS INFORMATION-SEEKING AGENTS&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9K3eH3ibZZyTecPlBXyGodcUtMpbHOCagsEia3RbojtP5wAQo4P8v1q6QxHVeFdwTPWiawbDicpHEFuA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：我们开发了一种通用问题集用于训练和测试人工智能体收集有效信息的能力。具体来说，它是一系列任务的集合，完成这些任务需要在给定环境中寻找有效信息。同时，我们将深层架构和强化学习技术整合到一起，构建了用于处理此类问题的人工智能系统。我们通过组合内部和外部奖励机制来塑造人工智能体的行为。我们的研究表明，这些人工智能体可以学会积极、智能化地搜索信息以减少不确定性，并在这个过程中不断利用已有信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 11 Jan 2017 13:40:32 +0800</pubDate>
    </item>
    <item>
      <title>专栏 | 旷视(Face++)孙剑：创业公司里的研究之美</title>
      <link>http://www.iwgc.cn/link/4292350</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心专栏&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：孙剑&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;孙剑博士 2003 年毕业于西安交通大学，随后在 Microsoft Research&amp;nbsp;Asia (MSRA)工作，曾担任 MSRA Principal Research Manager。2016 年 7 月，&lt;span&gt;孙剑博士加入旷视科技(Face++)，出任该公司首席科学家，负责Megvii Research。最近，孙剑本人撰文向大家阐述了自己从科技巨头到创业公司的心路旅程，并简要介绍了自己最近的研究。&lt;/span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2016 年，就我个人来讲，所做出的最重大抉择，就是在已经工作了十三年的微软研究院（以下简称 MSR），和一个成立不过几年的创业公司——Face++旷视科技（以下简称 Face++）之间，选择了后者，并且以首席科学家身份加入。当时我还住在西雅图，当真是「身未动，消息已远」，各种报道从国内外朋友圈向我强势袭来，让我体会到了媒体的力量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;时至今日，我已搬回北京，在 Face++ 上班近半年了，依然时常被问及：「过的怎么样？」，「Face++ 和 MSR 的研究部门一样吗？」，「Face++ 是如何开展研究工作的？……」等等。问题或大或小，但大多诸如此类。值此新年之际，我想把自己这半年来的观察与思考与大家分享一下，权且当作对各位关心的答谢。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;接下来，我将围绕大家关注的一些典型问题，逐一说明：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Face++ 与 MSR 的研发部门有什么异同？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;就我的观察与体验，两家公司研发部门的本质是几乎没有差别的。什么叫一个公司的研发部门本质呢？我认为有三个要素极其关键：使命定位、人员组成和研发方式。坦白来讲，从这三点审视，我在两边看到了惊人的一致性，也就是说：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1）他们都同样有着既基于产品，又探索前沿技术的使命定位；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2）他们都同样聚集着一群追求极致，有 Geek 精神，且高自我驱动的精英；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3）他们都用同样的套路推进研究工作：确定问题--&amp;gt;实现、研究和理解既有方法--&amp;gt;进行持续改进或创新。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这其中，最令人有现场触动感的还是「人」。举个最近让我感动的例子： 下面这张我在 2016 年最后一天发的朋友圈最好的诠释了 Face++ 的核心价值观「追求、极致、简单、可靠」中的前两点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9rD6KzMuKBaJJEmtibaiciaXJ3I32qOlB16tMWaicsUdBvonThTwictiaDSHKJaicfCK4SPKbCkd7vPQAiaw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然，即便两边研究部门的本质相同，也必然会存在着不同之处，毕竟每个公司都有其特定的文化与管理模式。当我身边的战友们从平均年龄三十多岁直降十岁的那一天突然来临时，我一方面感觉自己好像在瞬间迈入中老年的行列中（讲个梗：今天一名同事问我为什么把手机字体调的那么大），另一方面觉得自己充满了干劲，同时还有一份沉甸甸的责任感。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Face++ 的研究部门在研究什么？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在众多场合下问，这个问题是被提及次数最多的。为什么会有这样的疑问呢，我想不外乎两方面的思考，一是想知道公司具体研究哪些领域，长期课题与目标是什么，二是想了解一家创业公司里的研发部门，到底能不能推进真正意义上的研究工作，还是打着研究的旗号做着产品开发。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里还隐含着一个认识上的误区，就是在我们公司被广泛称为 Face++ 之后，越来越多的人误以为 Face++ 嘛，只是在做人脸技术。人脸，目前确实是一个商业前景广阔，玩法花样不断翻新的应用。但是，Face++ 从创立第一天就聚焦在人工智能的三大应用领域之——计算机视觉，是以一系列视觉识别（人脸、人、物体、文字、场景、行为等）问题为中心，研发核心算法，打造能落地的产品。消除了这样一个误区，你会比较好理解，为什么 Face++ 要用「Power Human with AI」作为使命，用「人工智能技术造福大众」，来发愿。毕竟公司的全名是叫旷视（英文叫 Megvii, 取自 Mega Vision )，也就是大的视觉。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;回到问题本身，目前我们主要在集中研究四个视觉理解核心问题（见下图）：图像分类、物体检测、语义分割、和序列学习。研究的技术路线是彻彻底底的深度学习：1）使用深度神经网络；2）尽最大可能使用端到端（end-to-end）学习。Face++ 应该说是这波儿人工智能创业公司当中最早研究并应用深度学习的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9rD6KzMuKBaJJEmtibaiciaXJXfLMmISC8vCGo5p72FUkkmIJXVDM2HzE7Rj4DL0ibXicjI9HXZBicAc0A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;图像分类是最基础的问题&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个问题自身就有广泛的应用（例如人脸识别和场景分类），也是研究其他问题的根基。深度学习的出现使得我们从以往的特征设计走向了网络结构设计，这里包含很多对问题的深刻理解、实践中总结的经验和原理、优化算法的探索、和对下一步技术发展的判断。我们的研发部门里有一个专门的小组负责研究如何训练最好的基础神经网络，并沿着以下三个子问题深入：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1）针对不同计算复杂度下设计最优的神经网络；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2）针对不同计算平台的实际要求，来设计最高效的网络；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3）针对不同问题设计最合适的网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外对神经网络模型的压缩和低比特化表示也是我们研究的重点之一。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;物体识别是解决感知图像中哪里有什么物体的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;典型的应用包括手机上的人脸检测，无人车中的车辆/行人/交通标志的检测，视频分析中的各类物体检测。这个问题是图像理解中研究内容最丰富的核心问题，也是一个非常复杂的感知智能问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们关心的若干子问题是：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1）如何有效地解决遮挡问题。这个问题对人来说好像是很容易的，但其实涉及到了人脑中对不可见部分自动做联想和补充的能力，已经部分属于人类的认知智能能力范畴；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2）如何有效的利用图像或视频的上下文（context）信息或我们的常识（common sense）。上下文和常识对我们避免一些明显错误和小物体检测十分重要。目前的物体对小物体检测的性能非常不理想，和人眼的能力差距还是非常大的。如果我们单独把小物体从图像中裁剪出来，人也很难识别。但是当小物体放回整副图像中，人却做得非常出色。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我个人认为对这个两个子问题的深入研究真的可以对理解认知智能提供有意义指导，甚至是突破。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;语义分割就是对每个像素分类，这是一个更为精细的分类任务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;比如说把识别出来的人体分割成具体部位，把人脸分割成五官，把场景分成蓝天、建筑、道路和物体等。目前在这个问题上统治性的方法是 Berkeley 在 2014 年提出的全卷积网络（FCN）。这个方法使得神经网络具有了有强大的结构化输出能力，进而将深度学习有效地推进到很多中期和初期视觉理解（例如立体匹配和光流计算）问题上。我当年博士论文就是在研究初期视觉中的立体匹配问题，十几年后的方法发生了根本性的变化，当年是想也不敢想的。我们研发部门的一名实习生在最近的 CVPR 投稿中设计了一个简单有效的 FCN 模型，在公开评测集上取得了非常好的效果。（顺便插个广告，Face++ 一直面向全国招收实习生、兼职或全职均可，欢迎来我司对众多有意思、有难度的视觉理解问题进行深入理解和有效解决。）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;序列学习是最有趣的问题，它的形式多样，可以输入一个序列（视频或音频）进行分类，也可以针对一副图像输出一个描述性的文字序列，或输入输出都是序列（例如识别图像中的多行文字）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;解决这三类问题的算法在 Face++ 的产品中都有应用。目前解决这个问题的主流方法是递归神经网络（RNN），也是现在在语音识别和自然语言处理中的大杀器。由于人的智能本质是在实时的「处理」连续不断感知到的信号流，这使得序列学习成为当下的最热的研究方向之一。尤其是最近引入外部记忆读写机制和执行单元的 RNN，让我看到了解决人工智能不少难题的一丝曙光。Face++ 的研究员们也正在这方面积极思考，积极实践。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;我们在旷视如何开展研究？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;推进研究部门的工作，核心是培养人做事的能力，并给予最好的研发环境。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;培养什么人才。人才是研发的生命线。创造一个良好的环境吸引人才，培养人才，留住人才是我们的第一优先级。信息学竞赛 ( NOI/IOI ) 和大学生程序设计竞赛 ( ACM/ICPC ) 的选手们构成了研究部门的第一批战士。我们后续更多的战士来自五湖四海，拥有相当不同的背景：既有以前做视觉的，也有以前做机器学习的，既有研究基本问题的，也有专注特定应用的。一个多样性的环境也使得我们看问题的角度更全面。在这样的基因下，我们大致将人才向两个方向培养：研究科学家，和全栈人工智能工程师。研究科学家主要聚焦在算法上，寻求对问题的本质解，我们的培养目标是成为能独挡一面领域专家；全栈人工智能工程师是我们内部的叫法，目的是培养即能上九天揽月（算法设计和训练），又能下五洋捉鳖（算法的工程化，研究问题和方式系统化）的全能战士，他们既能做 research , 又懂 system，能建系统、造轮子。针对目前 AI 发展的趋势，我们需要大量的全能人才来将 AI「+」到不同的行业上，解决实际问题。这就对人才提出了更高的要求。我们相信即便没有 AI 背景的工程师，在这里工作 1-2 年后就能成为独当一面的人才。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;怎么做事。有了一帮志同道合的小伙伴们，就要围绕这上面介绍的四个视觉理解核心问题开展研究、并将研究成果应用在具体的视觉识别场景中。Face++ 的研发团队扁平化，每个研究小组由 2-4 人组成，聚焦一个课题。课题可以是短期的，例如对已经应用的某个产品线上的算法的改进；课题也可以是长期的，例如持续提升识别的精度和性能。我们的每个研究员都可以在不同的课题之间自由切换，这样能最大程度发挥个人的长处和积极性，同时也让大家有机会短时间了解更多的问题，有更丰富的经历，能更快的成长。套用现在深度学习的精髓，每个人的学习也需要输入大数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;研发环境。做深度学习研究需要一个非常高效的训练引擎/平台和充沛的计算资源。Face++ 内部使用了近两年的「MegBrain」是一个全自主研发的训练引擎，它与目前流行的 TensorFlow（Google 一年前发布）设计相似，同属基于 Computing Graph 的新一代训练引擎。为什么非要自研系统呢？公司研究深度学习开展得非常早，当时还没有很好用的系统，并且 MegBrain 在同时满足灵活性及精简性的基础上，能最大限度提升工作效率。目前在 AI 创业公司中完全使用自研深度学习训练引擎的，可能只有 Face++。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除了核心引擎，我们的体系结构组还搭建了一个强大的深度学习平台 Brain++ 来管理我们庞大的 GPU 集群，来完成从数据标注和管理、模型训练、 GPU 集群中心化管理、到产品化发布的「一条龙」自动化流程，从而使得我们的研发人员将宝贵的精力集中在问题上。这也使得来 Face++ 的实习生非常容易上手，即便对深度学习系统零基础，一套简单的教程读过后 2-3 个星期就可以开始思考问题了。这些系统能够建立得益于我们团队内部的有不少「全栈人工智能工程师」，他们不仅是深度学习方面的专家，更是系统和分布式计算方面的专家。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后针对深度学习很大程度上得益于大规模训练数据，我们还设有专门的团队负责标注工具开发和完成大量数据标注任务。以前读书时开玩笑的一个讲法是「没有不好的算法，只有不好的数据」，Data is King。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文由机器之心发布，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 11 Jan 2017 13:40:32 +0800</pubDate>
    </item>
    <item>
      <title>观点 | 芯片架构换血！如何评价微软在数据中心使用FPGA？</title>
      <link>http://www.iwgc.cn/link/4292351</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;机器之心授权转载&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;作者：李博杰&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;编者按&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;FPGA，一种全新的古老计算机芯片，正在悄然改变着全球的芯片市场。知乎问题“如何评价微软在数据中心使用FPGA代替传统CPU的做法？”的下面，来自微软亚洲研究院的实习生李博杰的回答在很短的时间内就收获了近2000的点赞数。这篇文章转载自他在知乎上的回答，看看他眼中微软的FPGA布局和FPGA的研究前景吧！&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;问题「用 FPGA 代替 CPU」中，这个「代替」的说法不准确。我们并不是不用 CPU 了，而是&lt;strong&gt;用 FPGA 加速适合它的计算任务，其他任务仍然在 CPU 上完成，让 FPGA 和 CPU 协同工作&lt;/strong&gt;。&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;本回答将涵盖三个问题：&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;1.为什么使用 FPGA，相比 CPU、GPU、ASIC（专用芯片）有什么特点&lt;span&gt;？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;2.微软的 FPGA 部署在哪里？FPGA 之间、FPGA 与 CPU 之间是如何通信的？&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;3.未来 FPGA 在云计算平台中应充当怎样的角色？仅仅是像 GPU 一样的计算加速卡吗？&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;一、为什么使用 FPGA？&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;众所周知，通用处理器（CPU）的摩尔定律已入暮年，而机器学习和 Web 服务的规模却在指数级增长。&lt;strong&gt;人们使用定制硬件来加速常见的计算任务，然而日新月异的行业又要求这些定制的硬件可被重新编程来执行新类型的计算任务&lt;/strong&gt;。FPGA (Field Programmable Gate Array) 正是一种硬件可重构的体系结构，常年来被用作专用芯片（ASIC）的小批量替代品，然而近年来在微软、百度等公司的数据中心大规模部署，以&lt;strong&gt;同时提供强大的计算能力和足够的灵活性&lt;/strong&gt;。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPfr5SQnVztOjxotF9OzaewalUGdONiaoTOcOL7uIicfnY99AfLAh31NPmZCjMuZS6wc2JMy1ajDpng/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;不同体系结构性能和灵活性的比较&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;FPGA 为什么快？「都是同行衬托得好」。&lt;strong&gt;CPU、GPU 都属于冯·诺依曼结构，指令译码执行、共享内存。&lt;/strong&gt;FPGA 之所以比 CPU 甚至 GPU 能效高，本质上是无指令、无需共享内存的体系结构带来的福利。&lt;br/&gt;&lt;br/&gt;冯氏结构中，由于执行单元（如 CPU 核）可能执行任意指令，就需要有指令存储器、译码器、各种指令的运算器、分支跳转处理逻辑。由于指令流的控制逻辑复杂，不可能有太多条独立的指令流，因此 GPU 使用 SIMD（单指令流多数据流）来让多个执行单元以同样的步调处理不同的数据，CPU 也支持 SIMD 指令。而&amp;nbsp;&lt;strong&gt;FPGA 每个逻辑单元的功能在重编程（烧写）时就已经确定，不需要指令。&lt;/strong&gt;&lt;br/&gt;&lt;br/&gt;冯氏结构中使用内存有两种作用。一是保存状态，二是在执行单元间通信。由于内存是共享的，就需要做访问仲裁；为了利用访问局部性，每个执行单元有一个私有的缓存，这就要维持执行部件间缓存的一致性。&lt;strong&gt;对于保存状态的需求，&lt;/strong&gt;&lt;strong&gt;FPGA&lt;/strong&gt;&amp;nbsp;中的寄存器和片上内存（BRAM）是属于各自的控制逻辑的，&lt;strong&gt;无需不必要的仲裁和缓存&lt;/strong&gt;。&lt;strong&gt;对于通信的需求，FPGA&lt;/strong&gt;&amp;nbsp;每个逻辑单元与周围逻辑单元的连接在重编程（烧写）时就已经确定，&lt;strong&gt;并不需要通过共享内存来通信&lt;/strong&gt;。&lt;br/&gt;&lt;br/&gt;说了这么多三千英尺高度的话，FPGA 实际的表现如何呢？我们分别来看计算密集型任务和通信密集型任务。&lt;br/&gt;&lt;br/&gt;&lt;strong&gt;计算密集型任务&lt;/strong&gt;的例子包括矩阵运算、图像处理、机器学习、压缩、非对称加密、必应搜索的排序等。这类任务一般是 CPU 把任务卸载（offload）给 FPGA 去执行。对这类任务，目前我们正在用的 Altera（似乎应该叫 Intel 了，我还是习惯叫 Altera……）Stratix V FPGA 的整数乘法运算性能与 20 核的 CPU 基本相当，浮点乘法运算性能与 8 核的 CPU 基本相当，而比 GPU 低一个数量级。我们即将用上的下一代 FPGA，Stratix 10，将配备更多的乘法器和硬件浮点运算部件，从而理论上可达到与现在的顶级 GPU 计算卡旗鼓相当的计算能力。&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPfr5SQnVztOjxotF9Ozaew95cvKDH1WDusxMcodskIcYcGluWxozzBsRDG1mgXEkE1xbNVyNhLHw/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;FPGA 的整数乘法运算能力（估计）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPfr5SQnVztOjxotF9OzaewDMbQsEsygMKib1u680vc2BrbTp0Z1FPes7qoicM6Vb927BxEkMRko3Pg/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;FPGA 的浮点乘法运算能力（估计）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;在数据中心，FPGA 相比 GPU 的核心优势在于延迟&lt;/strong&gt;。像必应搜索排序这样的任务，要尽可能快地返回搜索结果，就需要尽可能降低每一步的延迟。如果使用 GPU 来加速，要想充分利用 GPU 的计算能力，batch size 就不能太小，延迟将高达毫秒量级。使用 FPGA 来加速的话，只需要微秒级的 PCIe 延迟（我们现在的 FPGA 是作为一块 PCIe 加速卡）。未来 Intel 推出通过 QPI 连接的 Xeon + FPGA 之后，CPU 和 FPGA 之间的延迟更可以降到 100 纳秒以下，跟访问主存没什么区别了。&lt;br/&gt;&lt;br/&gt;FPGA 为什么比 GPU 的延迟低这么多？这本质上是体系结构的区别。&lt;strong&gt;FPGA 同时拥有流水线并行和数据并行，而 GPU 几乎只有数据并行（流水线深度受限）。&lt;/strong&gt;例如处理一个数据包有 10 个步骤，FPGA 可以搭建一个 10 级流水线，流水线的不同级在处理不同的数据包，每个数据包流经 10 级之后处理完成。每处理完成一个数据包，就能马上输出。而 GPU 的数据并行方法是做 10 个计算单元，每个计算单元也在处理不同的数据包，然而所有的计算单元必须按照统一的步调，做相同的事情（SIMD，Single Instruction Multiple Data）。这就要求 10 个数据包必须一起输入、一起输出，输入输出的延迟增加了。当任务是逐个而非成批到达的时候，流水线并行比数据并行可实现更低的延迟。因此&lt;strong&gt;对流式计算的任务，FPGA 比 GPU 天生有延迟方面的优势。&lt;/strong&gt;&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPfr5SQnVztOjxotF9OzaewKposOEn0oicNiaqibVZU6qfiahicShOhp8GrcHBNfngAGKZxtkaVsr4B4fg/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;计算密集型任务，CPU、GPU、FPGA、ASIC 的数量级比较（以 16 位整数乘法为例）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;ASIC 专用芯片在吞吐量、延迟和功耗三方面都无可指摘，但微软并没有采用，我认为出于两个原因：&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1.数据中心的计算任务是灵活多变的，而 ASIC 研发成本高、周期长。好不容易大规模部署了一批某种神经网络的加速卡，结果另一种神经网络更火了，钱就白费了。FPGA 只需要几百毫秒就可以更新逻辑功能。&lt;strong&gt;FPGA 的灵活性可以保护投资，事实上，微软现在的 FPGA 玩法与最初的设想大不相同。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2.数据中心是租给不同的租户使用的，如果有的机器上有神经网络加速卡，有的机器上有必应搜索加速卡，有的机器上有网络虚拟化加速卡，任务的调度和服务器的运维会很麻烦。&lt;/span&gt;&lt;strong&gt;使用 FPGA 可以保持数据中心的同构性。&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;接下来看通信密集型任务。相比计算密集型任务，通信密集型任务对每个输入数据的处理不甚复杂，基本上简单算算就输出了，这时通信往往会成为瓶颈。对称加密、防火墙、网络虚拟化都是通信密集型的例子。&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPfr5SQnVztOjxotF9OzaewaXHKb2Ob6Jwn4k7WX0Cbl7NwkicUYqGxda6AsIKcWfPWIxf5BeUEazw/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;通信密集型任务，CPU、GPU、FPGA、ASIC 的数量级比较（以 64 字节网络数据包处理为例）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;对通信密集型任务，FPGA 相比 CPU、GPU 的优势就更大了&lt;/strong&gt;。从吞吐量上讲，FPGA 上的收发器可以直接接上 40 Gbps 甚至 100 Gbps 的网线，以线速处理任意大小的数据包；而 CPU 需要从网卡把数据包收上来才能处理，&lt;strong&gt;很多网卡是不能线速处理 64 字节的小数据包的&lt;/strong&gt;。尽管可以通过插多块网卡来达到高性能，但 CPU 和主板支持的 PCIe 插槽数量往往有限，而且网卡、交换机本身也价格不菲。&lt;br/&gt;&lt;br/&gt;从延迟上讲，网卡把数据包收到 CPU，CPU 再发给网卡，即使使用 DPDK 这样高性能的数据包处理框架，延迟也有 4~5 微秒。更严重的问题是，&lt;strong&gt;通用 CPU 的延迟不够稳定&lt;/strong&gt;。例如当负载较高时，转发延迟可能升到几十微秒甚至更高（如下图所示）；现代操作系统中的时钟中断和任务调度也增加了延迟的不确定性。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPfr5SQnVztOjxotF9OzaewWqHC3Yz2XY7F2OiarlMiagTlC2pPNe84AlGgt98OrNR5icb0YBG9KjqmA/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;ClickNP（FPGA）与 Dell S6000 交换机（商用交换机芯片）、Click+DPDK（CPU）和 Linux（CPU）的转发延迟比较，error bar 表示 5% 和 95%。来源：[5]&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然 GPU 也可以高性能处理数据包，但 GPU 是没有网口的，意味着需要首先把数据包由网卡收上来，再让 GPU 去做处理。这样吞吐量受到 CPU 和/或网卡的限制。GPU 本身的延迟就更不必说了。&lt;br/&gt;&lt;br/&gt;那么为什么不把这些网络功能做进网卡，或者使用可编程交换机呢？&lt;strong&gt;ASIC 的灵活性仍然是硬伤&lt;/strong&gt;。尽管目前有越来越强大的可编程交换机芯片，比如支持 P4 语言的 Tofino，ASIC 仍然不能做复杂的有状态处理，比如某种自定义的加密算法。&lt;br/&gt;&lt;br/&gt;综上，&lt;strong&gt;在数据中心里 FPGA 的主要优势是稳定又极低的延迟，适用于流式的计算密集型任务和通信密集型任务。&lt;/strong&gt;&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;二、微软部署 FPGA 的实践&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2016 年 9 月，《连线》（&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;Wired&lt;/em&gt;）杂志发表了一篇《微软把未来押注在 FPGA 上》的报道 [3]，讲述了 Catapult 项目的前世今生。紧接着，Catapult 项目的老大 Doug Burger 在 Ignite 2016 大会上与微软 CEO Satya Nadella 一起做了 FPGA 加速机器翻译的演示。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPfr5SQnVztOjxotF9OzaewWNehneTIkz9QViaxTGTrLiaSSsWMwQL3s1ibqIQicM02H2NhVlNCN29r5A/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;Ignite 2016 上的演示：每秒 1 Exa-op (10^18) 的机器翻译运算能力&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里就给大家八一八这个每秒 1 Exa-op 的数字是怎么算出来的。每块生产环境中部署的 Stratix V FPGA 有 1.8 T ops 的计算能力，每台服务器上插一块 FPGA。实际使用时，每 8 台服务器为一组，一台服务器作为 FPGA 的控制节点。控制节点的 CPU 也可以做机器翻译的计算，但是每个 CPU 核只能做 0.1 T ops，相比 FPGA 是聊胜于无。非控制节点上的 FPGA 通过网络从其他 FPGA 收发数据，不需要本地 CPU 处理数据平面。&lt;br/&gt;&lt;br/&gt;截至演示时，微软 Azure 云有 46 万台服务器部署了 FPGA，必应有 1.5 万台，Exchange 服务有 9.5 万台，共计 57 万台。乘起来得到总的计算能力是 103 万 T ops，也就是 1.03 Exa-op，相当于 10 万块顶级 GPU 计算卡。一块 FPGA（加上板上内存和网络接口等）的功耗大约是 30 W，仅增加了整个服务器功耗的十分之一。&lt;br/&gt;&lt;br/&gt;微软部署 FPGA 并不是一帆风顺的。&lt;strong&gt;对于把 FPGA 部署在哪里这个问题，大致经历了三个阶段：&lt;/strong&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="max-width: 100%; color: rgb(62, 62, 62); font-size: 16px; font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); width: 527.778px; line-height: 28.4444px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;专用的 FPGA 集群，里面插满了 FPGA&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;每台机器一块 FPGA，采用专用网络连接&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;每台机器一块 FPGA，放在网卡和交换机之间，共享服务器网络&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPfr5SQnVztOjxotF9OzaewSAhibGfgCicnuMqtjADr5DmPKwEEm2iarXMWI9bj8UnEgHiaR6ics8Zv7hA/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;微软 FPGA 部署方式的三个阶段，来源：[3]&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一个阶段是专用集群，里面插满了 FPGA 加速卡，就像是一个 FPGA 组成的超级计算机。下图是最早的 BFB 实验板，一块 PCIe 卡上放了 6 块 FPGA，每台 1U 服务器上又插了 4 块 PCIe 卡。&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPfr5SQnVztOjxotF9Ozaew4ia4Yia7NnS8RG3YUYvSv2LTkHGx68XJGiaL2tDLgiaSRcq4ERBraoG0ZA/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;最早的 BFB 实验板，上面放了 6 块 FPGA。来源：[1]&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;只要规模足够大，对 FPGA 价格过高的担心将是不必要的。&lt;/strong&gt;&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPfr5SQnVztOjxotF9OzaewrBxLLV4H7QTyvK7QGKU7g6Cr2mAUFbnic4NAhvGepkPYiaE6gqR1Hb1g/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;最早的 BFB 实验板，1U 服务器上插了 4 块 FPGA 卡。来源：[1]&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;像超级计算机一样的部署方式，意味着有专门的一个机柜全是上图这种装了 24 块 FPGA 的服务器（下图左）。这种方式有几个问题：&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="max-width: 100%; color: rgb(62, 62, 62); font-size: 16px; font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); width: 527.778px; line-height: 28.4444px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;不同机器的 FPGA 之间无法通信，FPGA 所能处理问题的规模受限于单台服务器上 FPGA 的数量；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;数据中心里的其他机器要把任务集中发到这个机柜，构成了 in-cast，网络延迟很难做到稳定。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;FPGA 专用机柜构成了单点故障，只要它一坏，谁都别想加速了；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;装 FPGA 的服务器是定制的，冷却、运维都增加了麻烦。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;br/&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPfr5SQnVztOjxotF9OzaewDibXrD8FYK0GMDHtTcxdVlkKgIO9GpdV5h6Z3LlCqQiaQEpwpsn7GX6A/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;部署 FPGA 的三种方式，从中心化到分布式。来源：[1]&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一种不那么激进的方式是，在每个机柜一面部署一台装满 FPGA 的服务器（上图中）。这避免了上述问题 (2)(3)，但 (1)(4) 仍然没有解决。&lt;br/&gt;&lt;br/&gt;第二个阶段，为了&lt;strong&gt;保证数据中心中服务器的同构性&lt;/strong&gt;（这也是不用 ASIC 的一个重要原因），在每台服务器上插一块 FPGA（上图右），FPGA 之间通过专用网络连接。这也是微软在 ISCA'14 上所发表论文采用的部署方式。&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPfr5SQnVztOjxotF9OzaewRAGTUfW0FWJkJn6bibkXttt0Gpn6BLyaPeOzpCDNDIcjhiaC4ZkmzelQ/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;Open Compute Server 在机架中。来源：[1]&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPfr5SQnVztOjxotF9OzaewAq975KwklibBZbZoKYj8M9etWu1QhEUBS3e2u6kkLZoFvAyo0Jdwnzg/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;Open Compute Server 内景。红框是放 FPGA 的位置。来源：[1]&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPfr5SQnVztOjxotF9OzaewqC187f4LIyGlDwy4NMOAxM0TXv7hD9Xw7Sg6NzocEqVQRs95uqk7UQ/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;插入 FPGA 后的 Open Compute Server。来源：[1]&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPfr5SQnVztOjxotF9OzaewOnpM8A2oojXGM1WZ3jEQICNGbjQbuOlt5icCV9mETHnq1Wh1Rz4Z8xw/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;FPGA 与 Open Compute Server 之间的连接与固定。来源：[1]&lt;/span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;FPGA采用Stratix V D5，有172K个ALM，2014个M20K片上内存，1590个 DSP。板上有一个8GB DDR3-1333内存，一个PCIe Gen3 x8接口，两个10 Gbps网络接口。一个机柜之间的FPGA采用专用网络连接，一组10G网口8个一组连成环，另一组10G网口6个一组连成环，不使用交换机。&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPfr5SQnVztOjxotF9OzaewAYyc9trdOFVuDWR7rXdKf5IxTgdpEibn4YXBmV0FfIH4zbIwfxicrkZg/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;机柜中 FPGA 之间的网络连接方式。来源：[1]&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这样一个 1632 台服务器、1632 块 FPGA 的集群，把必应的搜索结果排序整体性能提高到了 2 倍（换言之，节省了一半的服务器）。如下图所示，每 8 块 FPGA 穿成一条链，中间用前面提到的 10 Gbps 专用网线来通信。这 8 块 FPGA 各司其职，有的负责从文档中提取特征（黄色），有的负责计算特征表达式（绿色），有的负责计算文档的得分（红色）。&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPfr5SQnVztOjxotF9OzaewLPK7d5KKC1icD13JXUicTK2E0iaesSEDD8domTAxwZibr7HY693cXicY2Yg/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;FPGA 加速必应的搜索排序过程。来源：[1]&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除了加速搜索结果的排序（RaaS，Ranking as a Service），FPGA 还被用来加速从倒排索引中取出相关文档并译码的过程（SaaS，Selection as a Service）。为了加快文档数据结构的访问，FPGA 把服务器主存里常用的 4K 内存页面缓存在 FPGA 板上的 DDR 上。&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPfr5SQnVztOjxotF9OzaewcYicicWjzDqRwLwZcWOCul2G30SnkF0vWoewaVNKMoaT3icNrhic60LBsA/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;FPGA 不仅降低了必应搜索的延迟，还显著提高了延迟的稳定性。来源：[4]&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPfr5SQnVztOjxotF9OzaewibziarrPD4OA9vzH74UW8oxkYjiamZqap7rGK6Dp30ZQD3kI4AkfibXT0w/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;本地和远程的 FPGA 均可以降低搜索延迟，远程 FPGA 的通信延迟相比搜索延迟可忽略。来源：[4]&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;FPGA 在必应的部署取得了成功，Catapult 项目继续在公司内扩张。微软内部拥有最多服务器的，就是云计算 Azure 部门了。Azure 部门急需解决的问题是网络和存储虚拟化带来的开销。Azure 把虚拟机卖给客户，需要给虚拟机的网络提供防火墙、负载均衡、隧道、NAT 等网络功能。由于云存储的物理存储跟计算节点是分离的，需要把数据从存储节点通过网络搬运过来，还要进行压缩和加密。&lt;br/&gt;&lt;br/&gt;在 1 Gbps 网络和机械硬盘的时代，网络和存储虚拟化的 CPU 开销不值一提。随着网络和存储速度越来越快，网络上了 40 Gbps，一块 SSD 的吞吐量也能到 1 GB/s，CPU 渐渐变得力不从心了。例如 Hyper-V 虚拟交换机只能处理 25 Gbps 左右的流量，不能达到 40 Gbps 线速，当数据包较小时性能更差；AES-256 加密和 SHA-1 签名，每个 CPU 核只能处理 100 MB/s，只是一块 SSD 吞吐量的十分之一。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPfr5SQnVztOjxotF9OzaewX3icpjVGfWN8XIeI3zPHZkYuH57nl3ia23XufxQibtBWlMXtGBZpvYCKg/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;网络隧道协议、防火墙处理 40 Gbps 需要的 CPU 核数。来源：[5]&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;为了加速网络功能和存储虚拟化，微软把 FPGA 部署在网卡和交换机之间。&lt;/strong&gt;如下图所示，每个 FPGA 有一个 4 GB DDR3-1333 DRAM，通过两个 PCIe Gen3 x8 接口连接到一个 CPU socket（物理上是 PCIe Gen3 x16 接口，因为 FPGA 没有 x16 的硬核，逻辑上当成两个 x8 的用）。物理网卡（NIC）就是普通的 40 Gbps 网卡，仅用于宿主机与网络之间的通信。&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPfr5SQnVztOjxotF9OzaewhHR1tRr1TkFMs2T8jlkI1KfwnRntZK1tI94HkB5mlkaHV4ibErTgP9Q/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;Azure 服务器部署 FPGA 的架构。来源：[6]&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;FPGA（SmartNIC）对每个虚拟机虚拟出一块网卡，虚拟机通过 SR-IOV 直接访问这块虚拟网卡。原本在虚拟交换机里面的数据平面功能被移到了 FPGA 里面，虚拟机收发网络数据包均不需要 CPU 参与，也不需要经过物理网卡（NIC）。这样不仅节约了可用于出售的 CPU 资源，还&lt;strong&gt;提高了虚拟机的网络性能（25 Gbps），把同数据中心虚拟机之间的网络延迟降低了 10 倍&lt;/strong&gt;。&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPfr5SQnVztOjxotF9Ozaewcb6FibZt2AAMhB5QtBCl4lvFz10TMQ6XulXGjz2PJhLRrfBWxjiaOxDw/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;网络虚拟化的加速架构。来源：[6]&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这就是微软部署 FPGA 的第三代架构，也是目前「每台服务器一块 FPGA」大规模部署所采用的架构。&lt;strong&gt;FPGA 复用主机网络的初心是加速网络和存储，更深远的影响则是把 FPGA 之间的网络连接扩展到了整个数据中心的规模&lt;/strong&gt;，做成真正 cloud-scale 的「超级计算机」。第二代架构里面，FPGA 之间的网络连接局限于同一个机架以内，FPGA 之间专网互联的方式很难扩大规模，通过 CPU 来转发则开销太高。&lt;br/&gt;&lt;br/&gt;第三代架构中，FPGA 之间通过 LTL (Lightweight Transport Layer) 通信。同一机架内延迟在 3 微秒以内；8 微秒以内可达 1000 块 FPGA；20 微秒可达同一数据中心的所有 FPGA。第二代架构尽管 8 台机器以内的延迟更低，但只能通过网络访问 48 块 FPGA。为了支持大范围的 FPGA 间通信，第三代架构中的 LTL 还支持 PFC 流控协议和 DCQCN 拥塞控制协议。&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPfr5SQnVztOjxotF9Ozaew2pfsh7Pn7wOT2ibeyP9WCiaU8lX62viaCyqqTFadCJSjJ7QOeUS8OYMIg/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;纵轴：LTL 的延迟，横轴：可达的 FPGA 数量。来源：[4]&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPfr5SQnVztOjxotF9OzaewKZT5AeuZ3uB0Hv5jESvO8rCTqDbdiaTFXblmuZIGicnvrvd7KOib0BKrQ/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;FPGA 内的逻辑模块关系，其中每个 Role 是用户逻辑（如 DNN 加速、网络功能加速、加密），外面的部分负责各个 Role 之间的通信及 Role 与外设之间的通信。来源：[4]&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPfr5SQnVztOjxotF9OzaewDQ1iay2HkiaDkN7h1SdcFKyfk6UWXmJAOUbyGtE5JZpZgSUzeXLWgP9w/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;FPGA 构成的数据中心加速平面，介于网络交换层（TOR、L1、L2）和传统服务器软件（CPU 上运行的软件）之间。来源：[4]&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;通过高带宽、低延迟的网络互联的 FPGA 构成了介于网络交换层和传统服务器软件之间的数据中心加速平面。&lt;/strong&gt;除了每台提供云服务的服务器都需要的网络和存储虚拟化加速，FPGA 上的剩余资源还可以用来加速必应搜索、深度神经网络（DNN）等计算任务。&lt;br/&gt;&lt;br/&gt;&lt;strong&gt;对很多类型的应用，随着分布式 FPGA 加速器的规模扩大，其性能提升是超线性的。&lt;/strong&gt;例如 CNN inference，当只用一块 FPGA 的时候，由于片上内存不足以放下整个模型，需要不断访问 DRAM 中的模型权重，性能瓶颈在 DRAM；如果 FPGA 的数量足够多，每块 FPGA 负责模型中的一层或者一层中的若干个特征，使得模型权重完全载入片上内存，就消除了 DRAM 的性能瓶颈，完全发挥出 FPGA 计算单元的性能。当然，拆得过细也会导致通信开销的增加。&lt;strong&gt;把任务拆分到分布式 FPGA 集群的关键在于平衡计算和通信。&lt;/strong&gt;&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPfr5SQnVztOjxotF9OzaewBvdltTEqL0rALbhpia6Yiay9hcvJW7etrYwV2Yty18xDHPIKm7dtukFg/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;从神经网络模型到 HaaS 上的 FPGA。利用模型内的并行性，模型的不同层、不同特征映射到不同 FPGA。来源：[4]&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 MICRO'16 会议上，微软提出了&amp;nbsp;&lt;strong&gt;Hardware as a Service (HaaS)&lt;/strong&gt;&amp;nbsp;的概念，即把硬件作为一种可调度的云服务，使得 FPGA 服务的集中调度、管理和大规模部署成为可能。&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPfr5SQnVztOjxotF9OzaewFj1LMk3FiaUg6obiaJDTe85E0Mibq4uNCria6bRjibibxcLiaOg3fwvjpicerw/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;Hardware as a Service (HaaS)。来源：[4]&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从第一代装满 FPGA 的专用服务器集群，到第二代通过专网连接的 FPGA 加速卡集群，到目前复用数据中心网络的大规模 FPGA 云，三个思想指导我们的路线：&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="max-width: 100%; color: rgb(62, 62, 62); font-size: 16px; font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); width: 527.778px; line-height: 28.4444px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;硬件和软件不是相互取代的关系，而是合作的关系；&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;必须具备灵活性，即用软件定义的能力；&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;必须具备可扩放性（scalability）。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;三、FPGA 在云计算中的角色&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后谈一点我个人对 FPGA 在云计算中角色的思考。作为三年级博士生，我在微软亚洲研究院的研究试图回答两个问题：&lt;br/&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="max-width: 100%; color: rgb(62, 62, 62); font-size: 16px; font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); width: 527.778px; line-height: 28.4444px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;FPGA 在云规模的网络互连系统中应当充当怎样的角色？&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如何高效、可扩放地对 FPGA + CPU 的异构系统进行编程？&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我对 FPGA 业界主要的遗憾是，FPGA 在数据中心的主流用法，从除微软外的互联网巨头，到两大 FPGA 厂商，再到学术界，大多是把 FPGA 当作跟 GPU 一样的计算密集型任务的加速卡。然而 FPGA 真的很适合做 GPU 的事情吗？前面讲过，&lt;strong&gt;FPGA 和 GPU 最大的区别在于体系结构，FPGA 更适合做需要低延迟的流式处理，GPU 更适合做大批量同构数据的处理。&lt;/strong&gt;&lt;br/&gt;&lt;br/&gt;由于很多人打算把 FPGA 当作计算加速卡来用，两大 FPGA 厂商推出的高层次编程模型也是基于 OpenCL，模仿 GPU 基于共享内存的批处理模式。CPU 要交给 FPGA 做一件事，需要先放进 FPGA 板上的 DRAM，然后告诉 FPGA 开始执行，FPGA 把执行结果放回 DRAM，再通知 CPU 去取回。&lt;strong&gt;CPU 和 FPGA 之间本来可以通过 PCIe 高效通信，为什么要到板上的 DRAM 绕一圈？&lt;/strong&gt;也许是工程实现的问题，我们发现通过 OpenCL 写 DRAM、启动 kernel、读 DRAM 一个来回，需要 1.8 毫秒。而通过 PCIe DMA 来通信，却只要 1~2 微秒。&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPfr5SQnVztOjxotF9OzaewQ4ibDebSOt5cgBGx7116GYjHXMZyWXePEGTuKF93lvsh7DPDoRz7d5Q/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;PCIe I/O channel 与 OpenCL 的性能比较。纵坐标为对数坐标。来源：[5]&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;OpenCL 里面多个 kernel 之间的通信就更夸张了，默认的方式也是通过共享内存。本文开篇就讲，FPGA 比 CPU 和 GPU 能效高，体系结构上的根本优势是无指令、无需共享内存。使用共享内存在多个 kernel 之间通信，在顺序通信（FIFO）的情况下是毫无必要的。况且 FPGA 上的 DRAM 一般比 GPU 上的 DRAM 慢很多。&lt;br/&gt;&lt;br/&gt;因此我们提出了 ClickNP 网络编程框架 [5]，&lt;strong&gt;使用管道（channel）而非共享内存来在执行单元（element/kernel）间、执行单元和主机软件间进行通信&lt;/strong&gt;。需要共享内存的应用，也可以在管道的基础上实现，毕竟 CSP（Communicating Sequential Process）和共享内存理论上是等价的嘛。ClickNP 目前还是在 OpenCL 基础上的一个框架，受到 C 语言描述硬件的局限性（当然 HLS 比 Verilog 的开发效率确实高多了）。理想的硬件描述语言，大概不会是 C 语言吧。&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPfr5SQnVztOjxotF9OzaewSGbg6vQ7MUbgiaNY4y6MgEia1ES83Mh5d9PyZ5sGkxvxhpx8o2HDN0oQ/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;ClickNP 使用 channel 在 elements 间通信，来源：[5]&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/HkPvwCuFwNPfr5SQnVztOjxotF9OzaewW6mf6gIvjZlMWF9SEkVlweX3aLRsicJBibzm1VGic4nSRntXicR0gvb5icg/640?wx_fmt=png"/&gt;&lt;br/&gt;&lt;span&gt;ClickNP 使用 channel 在 FPGA 和 CPU 间通信，来源：[5]&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;低延迟的流式处理，需要最多的地方就是通信。然而&amp;nbsp;&lt;strong&gt;CPU 由于并行性的限制和操作系统的调度，做通信效率不高，延迟也不稳定&lt;/strong&gt;。此外，&lt;strong&gt;通信就必然涉及到调度和仲裁&lt;/strong&gt;，CPU 由于单核性能的局限和核间通信的低效，调度、仲裁性能受限，硬件则很适合做这种重复工作。因此我的博士研究把 FPGA 定义为通信的「大管家」，不管是服务器跟服务器之间的通信，虚拟机跟虚拟机之间的通信，进程跟进程之间的通信，CPU 跟存储设备之间的通信，都可以用 FPGA 来加速。&lt;br/&gt;&lt;br/&gt;成也萧何，败也萧何。缺少指令同时是 FPGA 的优势和软肋。每做一点不同的事情，就要占用一定的 FPGA 逻辑资源。如果要做的事情复杂、重复性不强，就会占用大量的逻辑资源，其中的大部分处于闲置状态。这时就不如用冯·诺依曼结构的处理器。数据中心里的很多任务有很强的局部性和重复性：&lt;strong&gt;一部分是虚拟化平台需要做的网络和存储，这些都属于通信；另一部分是客户计算任务里的，比如机器学习、加密解密&lt;/strong&gt;。我们首先把 FPGA 用于它最擅长的通信，日后也许也会像 AWS 那样把 FPGA 作为计算加速卡租给客户。&lt;br/&gt;&lt;br/&gt;不管通信还是机器学习、加密解密，算法都是很复杂的，如果试图用 FPGA 完全取代 CPU，势必会带来 FPGA 逻辑资源极大的浪费，也会提高 FPGA 程序的开发成本。更实用的做法是&amp;nbsp;&lt;strong&gt;FPGA 和 CPU 协同工作，局部性和重复性强的归 FPGA，复杂的归 CPU。&lt;/strong&gt;&lt;br/&gt;&lt;br/&gt;当我们用 FPGA 加速了必应搜索、深度学习等越来越多的服务；当网络虚拟化、存储虚拟化等基础组件的数据平面被 FPGA 把持；当 FPGA 组成的「数据中心加速平面」成为网络和服务器之间的天堑……似乎有种感觉，FPGA 将掌控全局，CPU 上的计算任务反而变得碎片化，受 FPGA 的驱使。以往我们是 CPU 为主，把重复的计算任务卸载（offload）到 FPGA 上；以后会不会变成 FPGA 为主，把复杂的计算任务卸载到 CPU 上呢？随着 Xeon + FPGA 的问世，古老的 SoC 会不会在数据中心焕发新生？&lt;br/&gt;&lt;br/&gt;「跨越内存墙，走向可编程世界」&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;(&lt;/em&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;Across the memory wall and reach a fully programmable world.&lt;/em&gt;)&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;参考文献：&lt;/p&gt;&lt;p&gt;&lt;br/&gt;[1] Large-Scale Reconfigurable Computing in a Microsoft Datacenterhttps://www.microsoft.com/en-us/research/wp-content/uploads/2014/06/HC26.12.520-Recon-Fabric-Pulnam-Microsoft-Catapult.pdf&lt;/p&gt;&lt;p&gt;&lt;br/&gt;[2] A Reconfigurable Fabric for Accelerating Large-Scale Datacenter Services, ISCA'14https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/Catapult_ISCA_2014.pdf&lt;/p&gt;&lt;p&gt;&lt;br/&gt;[3]&amp;nbsp;Microsoft Has a Whole New Kind of Computer Chip—and It’ll Change Everything&lt;/p&gt;&lt;p&gt;&lt;br/&gt;[4] A Cloud-Scale Acceleration Architecture, MICRO'16&amp;nbsp;https://www.microsoft.com/en-us/research/wp-content/uploads/2016/10/Cloud-Scale-Acceleration-Architecture.pdf&lt;/p&gt;&lt;p&gt;&lt;br/&gt;[5]&amp;nbsp;ClickNP: Highly Flexible and High-performance Network Processing with Reconfigurable Hardware - Microsoft Research&lt;/p&gt;&lt;p&gt;&lt;br/&gt;[6] Daniel Firestone, SmartNIC: Accelerating Azure's Network with. FPGAs on OCS servers.&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;span&gt;作者简介&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/HkPvwCuFwNPfr5SQnVztOjxotF9OzaewoO9InWWNbrSUUNpyRuAQibgWd3wMHpw0ibhYuboHMfOrnKnIrH1mmZxg/640?wx_fmt=jpeg"/&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;/section&gt;&lt;section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;我叫李博杰，本科毕业于中国科学技术大学少年班学院，2014年加入中国科学技术大学与微软亚洲研究院的联合培养博士生项目。我的研究方向是数据中心网络和可重构硬件（FPGA）上的编程。&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心转载文章，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系作者获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 11 Jan 2017 13:40:32 +0800</pubDate>
    </item>
  </channel>
</rss>
