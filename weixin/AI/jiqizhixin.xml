<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>波士顿动力正式发布「汽车人」Handle：具备双足轮动能力</title>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650723729&amp;idx=1&amp;sn=3d01459b5d24a064ee72698a573b740e&amp;chksm=871b11efb06c98f97a1d71b4f072bec414d7e89016b618bea1abd06194bf8bda38b7be7f7e7e&amp;scene=0#rd</link>
      <description>
&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自IEEE Spectrum&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Steve Crowe 等&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：微胖&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;昨天，波士顿动力官方发布了用于研究的机器人 Handle，它结合了轮子的高效与腿部的灵活。在上个月，曾有一个泄露出来的 Handle 机器人测试片段在网上传播，不过，这一次波士顿动力公布了这款机器人的新细节，还有才艺表演视频。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;iframe allowfullscreen="" class="video_iframe" data-vidtype="1" frameborder="0" height="417" src="https://v.qq.com/iframe/preview.html?vid=p0379yfdaoc&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0" width="556"&gt;&lt;/iframe&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「（Handle）约 6.5 英尺高，行进速度为每小时 9 英里，垂直跳跃高度为 4 英尺。电力运行电子和液压驱动器，一次充电的续航能力约为 15 英里。Hand 使用的许多动力学、平衡、移动控制原理，也是我们之前打造四足和双足机器人采用过的，只不过这款机器人只有 10 个驱动关节，很明显，比起之前的机器人，它没那么复杂。轮子可以在水平面上快速滑行，但是机器人可以使用腿部去任何地方，兼具轮子和腿部功能的 Handle 能博采两家之长。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;正如波士顿动力的其他机器人，Handle 目前也没有任何商业打算。目前严格用于研究，看看打造机器人时，将腿部和轮子结合起来主意会有多惊艳。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;波士顿动力的创始人 Marc Raibert 称呼 Handle 是「会让人做噩梦的机器人。」我们表示赞同，特别是如果 Handle 和我们一起在库房工作或者为我们送披萨。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以下是 IEEE Spectrum 对波士顿动力创始人 Marc Raibert 的简短采访：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;IEEE Spectrum：&lt;/span&gt;怎么会想到轮子的？打造这台机器人花了多长时间？&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Raibert：&lt;/span&gt;&lt;span&gt;将轮子和腿结合起来的想法早就有了，不过还没有机会加以研究。去年夏天，我们开始实现这个想法，大概花了六个月的时间。我们加快了项目进程，因为使用了原先为 Atlas 设计的能源、手臂以及上半身的设计。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;IEEE Spectrum：在腿式机器人中，你们成功使用了基于生物学启示的控制策略，可以将这一策略再次（或调整后）用到 Handle 身上吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;Raibert：&lt;/span&gt;Handle 所用到的控制，很多得益于之前四足和双足机器人的经验。不过软件不尽相同，但是，平衡、动力学控制原理都是很多共同之处，物理学根据是一样的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;IEEE Spectrum：&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;Handle 的上半身是不完全的 Atlas，还是一个全新设计？它是全电动的吗？使用了液压技术？&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;Raibert：&lt;/span&gt;是的。它用的是 Atlas 的上半身，手臂根据 Atlas 手臂做了轻微改动。电力（电池）驱动，不过，它有电力和液压驱动。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/271d6307e6f89a6b0caa85767d9d78a6481b2dcd"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;br&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;IEEE Spectrum：&lt;/strong&gt;&lt;/em&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;这么长的时间里，你们一直在研究设计腿式机器人，你和团队对轮子有何感受？&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;Raibert：&lt;/span&gt;轮子是伟大的发明（可参见吴军的《文明之光》里的介绍。&amp;mdash;&amp;mdash;编译者注）。但是，轮子只适合平坦的地面，腿可以抵达任何地方。因此，结合腿和轮子，Handle 就能博采两家之长。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;原文链接：http://spectrum.ieee.org/automaton/robotics/humanoids/boston-dynamics-handle-robot&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;span&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Tue, 28 Feb 2017 12:17:03 +0800</pubDate>
    </item>
    <item>
      <title>第四范式专栏 | 首席科学家杨强教授：人工智能的下一个技术风口与商业风口</title>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650723729&amp;idx=2&amp;sn=b3a77f31cf1767769e8c0f37886d0b13&amp;chksm=871b11efb06c98f99e1c2d557bf467f9bc03a6b457a1ee9691342917899d2e2394da3c2aa8ef&amp;scene=0#rd</link>
      <description>
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;第四范式专栏&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;演讲者：杨强&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote style="color: rgb(62, 62, 62); font-size: 16px; white-space: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;作为华人界首个国际人工智能协会AAAI Fellow、至今为止唯一的AAAI 华人执委，以及IEEE Fellow、AAAS Fellow、IAPR Fellow，杨强教授在专注学术研究的同时，也更关注如何让人工智能技术落地转化为生产力的问题。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;作为第四范式首席科学家、范式大学的导师，杨强教授近日在第四范式公司内部进行了一场主题为&amp;ldquo;人工智能的下一个三年&amp;rdquo;的培训，深入浅出地分享了自己在人工智能产业推广上的经验，并预判了人工智能即将爆发的技术风口与商业风口。此前，杨强教授与第四范式曾提出人工智能的五个必要条件，为人工智能行业提供了权威的准入标准。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以下内容根据杨强教授主题演讲编写，略微有所删减。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;一、AlphaGo为我们带来了什么&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大家记得在2016年3月，AlphaGo横空出世对战李世乭，这对于人工智能的社会影响非常大。这里，我们问一下：AlphaGo到底为我们带来了什么？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在AlphaGo的搜索中，Deepmind团队引入了一个新概念&amp;mdash;&amp;mdash;即用深度学习和强化学习的结合来做两种任务的判别，即来&lt;strong&gt;判别&lt;/strong&gt;现在所在的棋盘是好是坏，同时来&lt;strong&gt;预测&lt;/strong&gt;未来有利的走向。&lt;strong&gt;讲到这里大家应该能看出AlphaGo的算法和未来商业模式的关联，即：通过对大数据的分析，让我们对&amp;ldquo;现在状态&amp;rdquo;有了一个靠谱的理解；&lt;/strong&gt;这个状态可以是棋盘、可以是足球运动中两队交锋的状态，也可以是当前营销的一个状态。同时，下围棋中的一步，可以理解成对未来走向的预判，在商业活动中，这可以是营销活动中的下一步。这里很重要的一点，是区分我们商业行为中的两个任务，即对现实的判断和对商业未来走向的预估。这两个任务同样重要，也同样都需要大数据的支持。 因为围棋是一个封闭式的游戏（即没有外界因素的干扰），为了得到更多的数据，AlphaGo也引入了自我博弈。&lt;strong&gt;所谓自我博弈就是自己玩游戏，你会得到不断的反馈，然后来更新自己的策略&lt;/strong&gt;，经过无数次这样的比赛，最后会得到一个好的策略，你的最终输出是一个行为的策略。所以AlphaGo 也告诉我们，在一个封闭场景中，可以用自我博弈的模拟方法得到更多的数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;从AlphaGo到人工智能的应用流程&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们如果沿着下围棋的步骤走，就要面对这些问题：你的人工智能算法的目标是什么？有没有数据？数据在哪里？问题的边界是否清晰？什么叫合理的走法、什么叫犯规的走法？你的特征在哪里？又如何得到这些特征？是否可以得到一个持续的反馈？这样的一个流程是AlphaGo设计团队所走过的路。不妨把这些步骤记下来，变成一个workflow，看看其他的领域是不是可以重复AlphaGo的成功。 比如，如果用AlphaGo治疗癌症，如何治疗呢？治疗癌症一般是用放射性来杀掉癌细胞，而每一个癌症患者需要的剂量、角度、频次可能都不一样，如果能把所有的这些信息都记录下来，再记录治疗结果，因为结果不是马上就知道的，而是经过一段时间才知道，这样就有了数据、有了特征、有了问题持续的反馈，并且有了非常清楚的目标，即在副作用最小的情况下杀死癌细胞。并且这个workflow是可以重复的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/4e5015ebd19a4725fe1f8928c5a4f828cbd1e23a"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;AI&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;的发展历史还有前30年，这些年的积累也很有用&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;刚刚我们说了AlphaGo的一路历程，&lt;strong&gt;但我们对人工智能的理解不应该片面地认为人工智能就是机器学习。&lt;/strong&gt;人工智能的发展历史还有前30年，前30年是从50年代中一直发展到80年代中。这30年AI是在干什么呢？是在做人工输入的规则型的知识表达研究，以及基于这些规则的符号空间的推理和搜索。我认为，这个人工规则型的知识表达在AI的应用当中也是必不可少的，因为在众多领域当中还会碰到冷启动的问题，以及如何规范一个领域的边界的问题。这就是说，逻辑推理，逻辑知识表达，以及在符号空间的搜索的人工智能这个分支，在今后几年会和统计学习相结合，会大有发展。 这种发展会也涉及技术和商业两个层面。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;二、AI的技术风口在哪？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们大家会关心的一个问题， 是人工智能的技术在哪些方向可能会有大的突破。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;深度学习&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/2247f1c9a460251e3211e0c706153c607b2fae0e"/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;首先，是深度学习会继续发展。这里的发展不仅是在层次的增加，还包括深度学习的可解释性、以及对深度学习所获的的结论的自我因果表达。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;例如，如何把非结构化的数据作为原始数据，训练出一个统计模型，再把这个模型变成某种知识的表达&amp;mdash;&amp;mdash;这是一种表示学习。这种技术对于非结构化数据，尤其对于自然语言里面的知识学习，是很有帮助的。另外，深度学习模型的结构设计是深度学习的一个难点。这些结构在今天都是非常需要由人来设计的。还有一个研究问题是如何让逻辑推理和深度学习一起工作，这样也可以增加深度学习的可解释性。比如，建立一个贝叶斯模型需要有很多的设计者的经验，到现在为止，基本上是由人来设定的。如果我们能从深度学习的学习过程中衍生出一个贝叶斯模型，那么，学习、解释和推理就可以统一起来了。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;迁移学习&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;迁移学习也是我和戴文渊（第四范式创始人、首席执行官）一直在做的工作。给定一个深度学习的网络，比如一个encoder网络和一个decoder网络，我们可以看它学习和迁移的过程，作为新的数据来训练另外一个可解释的模型，也可以作为一个新的迁移学习算法的输出。即一个学生A在观察另外一个学生B学习，A的目的是学习B的学习方法，B就不断地在学新的领域，每换一个领域就为A提供一个新的数据样本，A利用这些新的样本就能学会在领域之间做迁移。所以这种过程叫做观察网络。有了这种一边学习、一边学习学习方法的算法，就可以在机器学习的过程中，学会迁移的方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;自然语言的表示学习与机器阅读&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;表示学习是当数据和任务没有直接相关时也可以学，一个重要的例子叫做self-taught learning，即我们通过很多supervise的数据、图像，可以学出一种最好的表达。用这个表达加上任务，就可以很快地学会这种知识表示。这时非结构化的数据就相当有用了。比如，给出一段话让机器去阅读，机器学习可以自动地发现一些值得关注的点。比如，给定一个文章中的实体和一个未知变量有这样的关系，然后用户可以问你这个未知变量是什么。能够达到这样的效果是因为深度模型已经具有了一种关注（&lt;span&gt;Attention）&lt;/span&gt;，这种关注是可以通过观众的学习来表达。&lt;strong&gt;其结果就好像我们一目了然地看了一本书，我们会把关键词和它们的关系抓取出来&lt;/strong&gt;。这实际上是利用类似人的一种直觉来进行学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;人机对话系统&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;应该说有一个领域已经发展到了临界点，就是人机对话系统领域。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;现在在这个领域，某些相对垂直的方面已经收取了足够多的数据，一个是客服，一个是汽车（车内的人车对话）；还有一种是特定场景的特定任务，像Amazon Echo，你可以跟它讲话，可以说&amp;ldquo;你给我放个歌吧&amp;rdquo;或者&amp;ldquo;你播一下新闻&amp;rdquo;，Amazon Echo里面是围了一圈的8个麦克风，这个阵列可以探测到人是否在和它说话，比如我和别人说话的时候，脸转过去，它就不会有反应。这种唤醒功能是非常准确的。它的另外一个功能是当你的双手没办法去控制手机的时候，可以用语音来控制，案例场景是客厅和厨房，在美国Amazon Echo特别受家庭主妇的欢迎，所以像这种特定的场景，如果收集了足够的数据，是可以训练出这样强大的对话系统来的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;强化迁移学习&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;我们可以想象，未来深度学习、强化学习和迁移学习的结合，可以实现以下几个突破&amp;mdash;&amp;mdash;反馈可以延迟、可以个性化，把一个通用模型施加到任何个体上面，这样一个复合模型可以叫做强化迁移学习模型&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;人工智能的可靠性模型&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;AI as Reliable Services&lt;/span&gt;&lt;span&gt;是AAAI 前主席Thomas Dietterich在AAAI 2016上给出的一个主题，人工智能只能作为一些例证证明能够做哪些事情，比如下棋，无人驾驶，但很多时候它还是不可靠的。它不像现在的一个商用软件一样，能让你放心地去使用，以保证它的错误率肯定不会超过很小的比例。相反，AI 在犯错的时候可能错得非常厉害，所以用平均值来代表一个准确率是不恰当的，相反，应该更多地要考虑它的置信区间。换言之，小白用户拿一些人工智能的模块来搭一个系统，这个系统就应该能被搭出来，而且它的效果应该是在一个固定的范围以内的，所以人工智能应该像软件工程一样做出来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;第四范式核心产品&amp;ldquo;先知平台&amp;rdquo;一直就在往这个方向发展，先知把人工智能的模块工程化、并在一定程度上保证了可靠性，从而让普通用户用来搭建自己的人工智能系统。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;三、AI的商业风口在哪？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;上面我们考虑了人工智能的技术发展。下面我们看看商业领域。我们刚才列举了AI 成功的5大必要条件：高质量的大数据、清晰的问题定义和领域边界、懂人工智能且擅长应用和算法的跨界人才、足够的计算资源、持续的外部反馈。满足这五个条件的领域，才有可能在未来出现人工智能的爆发。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;智能客服&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人机交互的智能客服，产生了很多外界公开的数据以及内部的数据、知识库等，都可以用来制造机器人。尤其是可以用客服过去的数据来做训练，这个数据量现在在垂直领域是逐渐在增加的。现在的对话系统也已经逐渐成为深度学习和强化学习的焦点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;新闻领域&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外一个比较看好的领域是新闻领域，新闻的分发和自动写作。有很多编辑、解说、自动校对、作家等，其实是数据量足够多的，有这么多的文本，而且外界反馈也越来越多了。给一篇文章，可以用机器学习来做自动摘要。 这样一个工作的外部反馈来自哪里呢？实际上我们写的那些paper就是一个外部反馈，因为每篇paper都有摘要，如果一篇paper被收了，就说明摘要写的还不错，所以外部反馈还是可以实现的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里分享一个有趣的实验，是香港科大同学做的&amp;ldquo;自动写小说&amp;rdquo;项目。主要有两个步骤，一步是让它读很多书，一步是这样训练出一个模型，这个模型再让它变成一个生成式的模型，这样就能用来写小说了。举个例子，我们提供《射雕英雄传》和《笑傲江湖》，把这两个结合起来，就可以写一部新的小说了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;特定任务的智能机器人&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;例如Amazon 的KIVA机器人，大家可能知道Amazon一个很大的优势就是所有的仓储都是由机器人来完成的，但是它也有工人，被雇来用手做抓取，因为现在机器人的抓取是非常难的，那么人和机器的优点就结合起来了。此外，医疗机器人也是非常专业的一个领域，它可以给人开刀缝线，但它不是自动的，而是通过远程控制的，但控制的精密度非常高，如果它收集到足够量的数据，是可以达到自动的效果的，以后我们可能开刀就由机器人来代劳了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;在医护领域，&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;无障碍辅助的应用领域痛点特别强烈，现在数据量可能还不是特别多，因为毕竟这一群体还是少数人，但是痛点很强，所以未来也许会有数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;AI+&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;有机食品&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们在香港曾去访问过一个有机食品工厂，这个实验室里的每一株菜，周边的所有环境全都记录起来，比如湿度、温度、光照，然后就可以收集这样的数据训练一个机器学习的模型，最后用这个模型来做蔬菜。所以得来的蔬菜滋味可以控制，要脆感还是要甜的，都可以通过模型学习出来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;FINTECH&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;智能投顾&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后来说一说金融，其实金融是一个非常好的领域，第四范式在金融领域也积累了很多成功案例。&lt;strong&gt;金融领域里的任务都是非常清楚的&lt;/strong&gt;，而且每个任务的数据都有痕迹、有数据足迹，数据的维度也是多维度的数据，有外界的、也有内界的，非结构数据比较多，例如文本和报告。数据也是形成了孤岛，链条也非常长，并且链条里面都有衔接。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在金融领域现在美国比较时髦的一个概念叫投研、投顾和投资。投研是说研究整个市场的基本面，就好像我们研究舆情分析一样，但舆情只是其中的一部分；投顾是说在美国的银行给很多客户做理财分析，然后做理财的配置，这些工作可以由机器人来做；投资是说机器人自己就是一个客户，它可以去投资。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;四、多年后的AI社会&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后说一下我认为多年后的AI社会是怎么样的。&lt;strong&gt;我觉得未来应该是几个人在运行一个公司，每一个人都能率领成千上万个机器人，这些机器人在做不同的事情，&lt;/strong&gt;也是它被训练得很擅长的事情。我们现在在一个传统行业里，往往是20%的人在做80%的工作，那么这20%的人就是未来的运营公司的人，剩下80%的人所做的工作将交由机器来完成。一个公司的自动化，智能化程度，也代表了这个公司在商业上的反应速度和竞争力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能给人类带来的变革是非常深远的，人工智能不仅仅是一场比赛、一个应用，而是整个社会真正地彻底地在改变。机器和人将成为一个共同的&amp;ldquo;军队&amp;rdquo;不断地攻克堡垒，推动人类进程向更好的方向发展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/cf1552389fe466eb546c6283d2e4b68a1dd39440"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&amp;copy;本文为机器之心经授权转载，&lt;strong&gt;&lt;span&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Tue, 28 Feb 2017 12:17:03 +0800</pubDate>
    </item>
    <item>
      <title>开源 | 为Go语言设计的机器学习库Gorgonia：对标TensorFlow与Theano</title>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650723729&amp;idx=3&amp;sn=240a0d5fc1133a1b520042128e9511cc&amp;chksm=871b11efb06c98f9240f82ce753301e896e9c4ba0cd320ebfb260c163f8c950ae46fa0aeb007&amp;scene=0#rd</link>
      <description>
&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自GitHub&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：侯韵楚、黄小天、蒋思源&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Gorgonia 是一个促进在 Go 中进行机器学习的库，旨在更容易地编写与评估涉及多维数组的数学方程。如果这听起来很像 Theano 或者 TensorFlow，原因是三者的想法非常相似。具体而言，Gorgonia 像 Theano 一样相当低级；但又像 Tensorflow 一样具有更高目标。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;项目地址：https://github.com/chewxy/gorgonia&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;项目介绍：https://blog.chewxy.com/2016/09/19/gorgonia/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;可执行自动微分&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;可执行符号微分&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;可执行梯度下降优化&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;可执行数值稳定&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;提供了许多便利功能，以助于创建神经网络&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;非常快（与 Theano 和 Tensorflow 的速度相当）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;支持 CUDA / GPGPU 计算（OpenCL 尚不支持，需发送拉取请求）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;将支持分布式计算&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;为何选择&amp;nbsp;Gorgonia？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Gorgonia 的使用主要方便了开发者。如果你使用 Go 广泛地堆栈，便可以在熟悉而舒适的环境中创建生产就绪的机器学习系统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器学习／人工智能通常笼统地分为两个阶段：（a）建立多种模型并测试、再测试的试验阶段，（b）以及模型在测试与试用之后被部署的部署阶段。这两个阶段不可或缺且作用各异，就像数据科学家和数据工程师之间的区别。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;原则上这两个阶段使用的工具也不同：实验阶段通常使用 Python / Lua（使用 Theano，Torch 等），而后这个模型会使用性能更高的语言来重新编写，如 C++（使用 dlib、mlpack 等）。当然，如今差距正在慢慢缩短，人们也经常会进行工具共享，比如 Tensorflow 便可用来填补差距。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而 Gorgonia 的目的，却是在 Go 环境中完成相同的事情。目前 Gorgonia 性能相当高，其速度与 Theano 和 Tensorflow 相当（由于目前 Gorgonia 存在 一个 CUDA 缺陷，所以还未完成官方基准测试；另外，因为实现可能会稍有不同，所以很难去比较一个精确的以牙还牙模型）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;安装&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;安装包是 go-get 的: go get -u github.com/chewxy/gorgonia.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Gorgonia 所使用的依赖很少且都很稳定，所以目前不需要代管工具。下表为 Gorgonia 所调用的外部软件包列表，并按照它所依赖的顺序进行了排列（已省略子软件包）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/a21b1d5b732d206c0c85a57d4cb5310d91793418"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;保持更新&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Gorgonia 的项目有一个邮件列表和 Twitter 帐户，官方更新和公告会发布到这两个网站：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;https://groups.google.com/forum/#!forum/gorgonia&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;https://twitter.com/gorgoniaML&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;用法&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Gorgonia 通过创建计算图来工作，而后将其执行。请把它当作一种仅限于数学函数方面的编程语言；事实上，这应当作为用户思考的主要实例。它创建的计算图是一个 AST。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;微软 CNTK 的 BrainScript 可能是用来说明计算图的构建与运行并不相同的最佳实例，所以用户对于这二者，应当运用不同的思维模式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然 Gorgonia 的实现并不像 CNTK 的 BrainScript 那样强制性分离思维，但语法确实略有裨益。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此处举出一个实例&amp;mdash;&amp;mdash;若要定义一个数学表达式 z = x + y，应当这样做：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;package&lt;/span&gt; main&lt;span&gt;import&lt;/span&gt; ( &amp;nbsp; &amp;nbsp;&lt;span&gt;&lt;span&gt;"&lt;/span&gt;fmt&lt;span&gt;"&lt;/span&gt;&lt;/span&gt;
 &amp;nbsp; &amp;nbsp;&lt;span&gt;&lt;span&gt;"&lt;/span&gt;log&lt;span&gt;"&lt;/span&gt;&lt;/span&gt;

 &amp;nbsp; &amp;nbsp;. &lt;span&gt;&lt;span&gt;"&lt;/span&gt;github.com/chewxy/gorgonia&lt;span&gt;"&lt;/span&gt;&lt;/span&gt;)&lt;span&gt;func&lt;/span&gt; &lt;span&gt;main&lt;/span&gt;() { &amp;nbsp; &amp;nbsp;&lt;span&gt;g&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; &lt;span&gt;NewGraph&lt;/span&gt;() &amp;nbsp; &amp;nbsp;&lt;span&gt;var&lt;/span&gt; &lt;span&gt;x&lt;/span&gt;, &lt;span&gt;y&lt;/span&gt;, &lt;span&gt;z&lt;/span&gt; *Node &amp;nbsp; &amp;nbsp;&lt;span&gt;var&lt;/span&gt; &lt;span&gt;err&lt;/span&gt; &lt;span&gt;error&lt;/span&gt;

 &amp;nbsp; &amp;nbsp;&lt;span&gt;&lt;span&gt;//&lt;/span&gt; define the expression&lt;/span&gt;
 &amp;nbsp; &amp;nbsp;x = &lt;span&gt;NewScalar&lt;/span&gt;(g, Float64, &lt;span&gt;WithName&lt;/span&gt;(&lt;span&gt;&lt;span&gt;"&lt;/span&gt;x&lt;span&gt;"&lt;/span&gt;&lt;/span&gt;))
 &amp;nbsp; &amp;nbsp;y = &lt;span&gt;NewScalar&lt;/span&gt;(g, Float64, &lt;span&gt;WithName&lt;/span&gt;(&lt;span&gt;&lt;span&gt;"&lt;/span&gt;y&lt;span&gt;"&lt;/span&gt;&lt;/span&gt;))
 &amp;nbsp; &amp;nbsp;z, err = &lt;span&gt;Add&lt;/span&gt;(x, y) &amp;nbsp; &amp;nbsp;&lt;span&gt;if&lt;/span&gt; err != &lt;span&gt;nil&lt;/span&gt; {
 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;log.&lt;span&gt;Fatal&lt;/span&gt;(err)
 &amp;nbsp; &amp;nbsp;} &amp;nbsp; &amp;nbsp;&lt;span&gt;&lt;span&gt;//&lt;/span&gt; compile into a program&lt;/span&gt;
 &amp;nbsp; &amp;nbsp;&lt;span&gt;prog&lt;/span&gt;, &lt;span&gt;locMap&lt;/span&gt;, &lt;span&gt;err&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; &lt;span&gt;Compile&lt;/span&gt;(g) &amp;nbsp; &amp;nbsp;&lt;span&gt;if&lt;/span&gt; err != &lt;span&gt;nil&lt;/span&gt; {
 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;log.&lt;span&gt;Fatal&lt;/span&gt;(err)
 &amp;nbsp; &amp;nbsp;} &amp;nbsp; &amp;nbsp;&lt;span&gt;&lt;span&gt;//&lt;/span&gt; create a VM to run the program on&lt;/span&gt;
 &amp;nbsp; &amp;nbsp;&lt;span&gt;machine&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; &lt;span&gt;NewTapeMachine&lt;/span&gt;(prog, locMap) &amp;nbsp; &amp;nbsp;&lt;span&gt;&lt;span&gt;//&lt;/span&gt; set initial values then run&lt;/span&gt;
 &amp;nbsp; &amp;nbsp;&lt;span&gt;Let&lt;/span&gt;(x, &lt;span&gt;2.0&lt;/span&gt;) &amp;nbsp; &amp;nbsp;&lt;span&gt;Let&lt;/span&gt;(y, &lt;span&gt;2.5&lt;/span&gt;) &amp;nbsp; &amp;nbsp;&lt;span&gt;if&lt;/span&gt; machine.&lt;span&gt;RunAll&lt;/span&gt;() != &lt;span&gt;nil&lt;/span&gt; {
 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;log.&lt;span&gt;Fatal&lt;/span&gt;(err)
 &amp;nbsp; &amp;nbsp;}

 &amp;nbsp; &amp;nbsp;fmt.&lt;span&gt;Printf&lt;/span&gt;(&lt;span&gt;&lt;span&gt;"&lt;/span&gt;%v&lt;span&gt;"&lt;/span&gt;&lt;/span&gt;, z.&lt;span&gt;Value&lt;/span&gt;()) &amp;nbsp; &amp;nbsp;&lt;span&gt;&lt;span&gt;//&lt;/span&gt; Output: 4.5&lt;/span&gt;}&lt;/span&gt;&lt;/pre&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你可能会发现，它比其他类似的软件包更显冗长。如 Gorgonia 并未编译为可调用的函数，而是特地编译为需要TapeMachine 来运行的program；此外它还需要手动调用一个 Let（...）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;作者却认为这是好事&amp;mdash;&amp;mdash;能够将人的思维转变为机器的思维。它在我们想查清哪里出错的时候很有帮助。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;虚拟内存系统&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当前版本的 Gorgonia 有两个虚拟内存系统：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;TapeMachine&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;LispMachine&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;它们功能不同，采取的输入也不同。TapeMachine 通常更善于执行静态表达式（即计算图并不改变）；由于其静态特性，它适用于一次编写，多次运行的表达式（如线性回归，SVM 等）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;LispMachine 则是将图形设为输入，并直接在图形的节点上执行。如果图形有所改变，只需新创建一个轻量级 LispMachine 来执行便可。LispMachine 适于诸如创建大小不固定的循环神经网络这类的任务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 Gorgonia 发布之前存在第三个虚拟内存，它基于堆栈，且与 TapeMachine 相似，但能够更妥善地处理人工梯度。当作者解决了所有的问题后，它也许就能重见天日。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;微分&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Gorgonia 执行符号与自动微分，而这两个过程存在细微差别。作者认为这样理解是最合适的：自动微分是在运行时所做的微分，与图表的执行同时发生；符号微分是在编写阶段所做的微分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此处「运行时」当然是指表达式图的执行，而非程序的实际运行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过介绍这两个虚拟内存系统，便很容易理解 Gorgonia 如何执行符号与自动微分。使用与上文相同的示例，读者 能够发现此处并没有进行微分。这次用 LispMachine 做一次尝试吧：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;package&lt;/span&gt; main&lt;span&gt;import&lt;/span&gt; ( &amp;nbsp; &amp;nbsp;&lt;span&gt;&lt;span&gt;"&lt;/span&gt;fmt&lt;span&gt;"&lt;/span&gt;&lt;/span&gt;
 &amp;nbsp; &amp;nbsp;&lt;span&gt;&lt;span&gt;"&lt;/span&gt;log&lt;span&gt;"&lt;/span&gt;&lt;/span&gt;

 &amp;nbsp; &amp;nbsp;. &lt;span&gt;&lt;span&gt;"&lt;/span&gt;github.com/chewxy/gorgonia&lt;span&gt;"&lt;/span&gt;&lt;/span&gt;)&lt;span&gt;func&lt;/span&gt; &lt;span&gt;main&lt;/span&gt;() { &amp;nbsp; &amp;nbsp;&lt;span&gt;g&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; &lt;span&gt;NewGraph&lt;/span&gt;() &amp;nbsp; &amp;nbsp;&lt;span&gt;var&lt;/span&gt; &lt;span&gt;x&lt;/span&gt;, &lt;span&gt;y&lt;/span&gt;, &lt;span&gt;z&lt;/span&gt; *Node &amp;nbsp; &amp;nbsp;&lt;span&gt;var&lt;/span&gt; &lt;span&gt;err&lt;/span&gt; &lt;span&gt;error&lt;/span&gt;

 &amp;nbsp; &amp;nbsp;&lt;span&gt;&lt;span&gt;//&lt;/span&gt; define the expression&lt;/span&gt;
 &amp;nbsp; &amp;nbsp;x = &lt;span&gt;NewScalar&lt;/span&gt;(g, Float64, &lt;span&gt;WithName&lt;/span&gt;(&lt;span&gt;&lt;span&gt;"&lt;/span&gt;x&lt;span&gt;"&lt;/span&gt;&lt;/span&gt;))
 &amp;nbsp; &amp;nbsp;y = &lt;span&gt;NewScalar&lt;/span&gt;(g, Float64, &lt;span&gt;WithName&lt;/span&gt;(&lt;span&gt;&lt;span&gt;"&lt;/span&gt;y&lt;span&gt;"&lt;/span&gt;&lt;/span&gt;))
 &amp;nbsp; &amp;nbsp;z, err = &lt;span&gt;Add&lt;/span&gt;(x, y) &amp;nbsp; &amp;nbsp;&lt;span&gt;if&lt;/span&gt; err != &lt;span&gt;nil&lt;/span&gt; {
 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;log.&lt;span&gt;Fatal&lt;/span&gt;(err)
 &amp;nbsp; &amp;nbsp;} &amp;nbsp; &amp;nbsp;&lt;span&gt;&lt;span&gt;//&lt;/span&gt; set initial values then run&lt;/span&gt;
 &amp;nbsp; &amp;nbsp;&lt;span&gt;Let&lt;/span&gt;(x, &lt;span&gt;2.0&lt;/span&gt;) &amp;nbsp; &amp;nbsp;&lt;span&gt;Let&lt;/span&gt;(y, &lt;span&gt;2.5&lt;/span&gt;) &amp;nbsp; &amp;nbsp;&lt;span&gt;&lt;span&gt;//&lt;/span&gt; by default, LispMachine performs forward mode and backwards mode execution&lt;/span&gt;
 &amp;nbsp; &amp;nbsp;&lt;span&gt;m&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; &lt;span&gt;NewLispMachine&lt;/span&gt;(g) &amp;nbsp; &amp;nbsp;&lt;span&gt;if&lt;/span&gt; m.&lt;span&gt;RunAll&lt;/span&gt;() != &lt;span&gt;nil&lt;/span&gt; {
 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;log.&lt;span&gt;Fatal&lt;/span&gt;(err)
 &amp;nbsp; &amp;nbsp;}

 &amp;nbsp; &amp;nbsp;fmt.&lt;span&gt;Printf&lt;/span&gt;(&lt;span&gt;&lt;span&gt;"&lt;/span&gt;z: %v&lt;span&gt;\n"&lt;/span&gt;&lt;/span&gt;, z.&lt;span&gt;Value&lt;/span&gt;()) &amp;nbsp; &amp;nbsp;&lt;span&gt;xgrad&lt;/span&gt;, &lt;span&gt;err&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; x.&lt;span&gt;Grad&lt;/span&gt;() &amp;nbsp; &amp;nbsp;&lt;span&gt;if&lt;/span&gt; err != &lt;span&gt;nil&lt;/span&gt; {
 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;log.&lt;span&gt;Fatal&lt;/span&gt;(err)
 &amp;nbsp; &amp;nbsp;}
 &amp;nbsp; &amp;nbsp;fmt.&lt;span&gt;Printf&lt;/span&gt;(&lt;span&gt;&lt;span&gt;"&lt;/span&gt;dz/dx: %v&lt;span&gt;\n"&lt;/span&gt;&lt;/span&gt;, xgrad) &amp;nbsp; &amp;nbsp;&lt;span&gt;ygrad&lt;/span&gt;, &lt;span&gt;err&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; y.&lt;span&gt;Grad&lt;/span&gt;() &amp;nbsp; &amp;nbsp;&lt;span&gt;if&lt;/span&gt; err != &lt;span&gt;nil&lt;/span&gt; {
 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;log.&lt;span&gt;Fatal&lt;/span&gt;(err)
 &amp;nbsp; &amp;nbsp;}
 &amp;nbsp; &amp;nbsp;fmt.&lt;span&gt;Printf&lt;/span&gt;(&lt;span&gt;&lt;span&gt;"&lt;/span&gt;dz/dy: %v&lt;span&gt;\n"&lt;/span&gt;&lt;/span&gt;, ygrad) &amp;nbsp; &amp;nbsp;&lt;span&gt;&lt;span&gt;//&lt;/span&gt; Output:&lt;/span&gt;
 &amp;nbsp; &amp;nbsp;&lt;span&gt;&lt;span&gt;//&lt;/span&gt; z: 4.5&lt;/span&gt;
 &amp;nbsp; &amp;nbsp;&lt;span&gt;&lt;span&gt;//&lt;/span&gt; dz/dx: 1&lt;/span&gt;
 &amp;nbsp; &amp;nbsp;&lt;span&gt;&lt;span&gt;//&lt;/span&gt; dz/dy: 1&lt;/span&gt;}&lt;/span&gt;&lt;/pre&gt;&lt;p&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然，Gorgonia 同样支持更传统的的符号微分，比如在 Theano 中：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;package&lt;/span&gt; main&lt;span&gt;import&lt;/span&gt; ( &amp;nbsp; &amp;nbsp;&lt;span&gt;&lt;span&gt;"&lt;/span&gt;fmt&lt;span&gt;"&lt;/span&gt;&lt;/span&gt;
 &amp;nbsp; &amp;nbsp;&lt;span&gt;&lt;span&gt;"&lt;/span&gt;log&lt;span&gt;"&lt;/span&gt;&lt;/span&gt;

 &amp;nbsp; &amp;nbsp;. &lt;span&gt;&lt;span&gt;"&lt;/span&gt;github.com/chewxy/gorgonia&lt;span&gt;"&lt;/span&gt;&lt;/span&gt;)&lt;span&gt;func&lt;/span&gt; &lt;span&gt;main&lt;/span&gt;() { &amp;nbsp; &amp;nbsp;&lt;span&gt;g&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; &lt;span&gt;NewGraph&lt;/span&gt;() &amp;nbsp; &amp;nbsp;&lt;span&gt;var&lt;/span&gt; &lt;span&gt;x&lt;/span&gt;, &lt;span&gt;y&lt;/span&gt;, &lt;span&gt;z&lt;/span&gt; *Node &amp;nbsp; &amp;nbsp;&lt;span&gt;var&lt;/span&gt; &lt;span&gt;err&lt;/span&gt; &lt;span&gt;error&lt;/span&gt;

 &amp;nbsp; &amp;nbsp;&lt;span&gt;&lt;span&gt;//&lt;/span&gt; define the expression&lt;/span&gt;
 &amp;nbsp; &amp;nbsp;x = &lt;span&gt;NewScalar&lt;/span&gt;(g, Float64, &lt;span&gt;WithName&lt;/span&gt;(&lt;span&gt;&lt;span&gt;"&lt;/span&gt;x&lt;span&gt;"&lt;/span&gt;&lt;/span&gt;))
 &amp;nbsp; &amp;nbsp;y = &lt;span&gt;NewScalar&lt;/span&gt;(g, Float64, &lt;span&gt;WithName&lt;/span&gt;(&lt;span&gt;&lt;span&gt;"&lt;/span&gt;y&lt;span&gt;"&lt;/span&gt;&lt;/span&gt;))
 &amp;nbsp; &amp;nbsp;z, err = &lt;span&gt;Add&lt;/span&gt;(x, y) &amp;nbsp; &amp;nbsp;&lt;span&gt;if&lt;/span&gt; err != &lt;span&gt;nil&lt;/span&gt; {
 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;log.&lt;span&gt;Fatal&lt;/span&gt;(err)
 &amp;nbsp; &amp;nbsp;} &amp;nbsp; &amp;nbsp;&lt;span&gt;&lt;span&gt;//&lt;/span&gt; symbolically differentiate z with regards to x and y&lt;/span&gt;
 &amp;nbsp; &amp;nbsp;&lt;span&gt;&lt;span&gt;//&lt;/span&gt; this adds the gradient nodes to the graph g&lt;/span&gt;
 &amp;nbsp; &amp;nbsp;&lt;span&gt;var&lt;/span&gt; &lt;span&gt;grads&lt;/span&gt; Nodes
 &amp;nbsp; &amp;nbsp;grads, err = &lt;span&gt;Grad&lt;/span&gt;(z, x, y) &amp;nbsp; &amp;nbsp;&lt;span&gt;if&lt;/span&gt; err != &lt;span&gt;nil&lt;/span&gt; {
 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;log.&lt;span&gt;Fatal&lt;/span&gt;(err)
 &amp;nbsp; &amp;nbsp;} &amp;nbsp; &amp;nbsp;&lt;span&gt;&lt;span&gt;//&lt;/span&gt; compile into a program&lt;/span&gt;
 &amp;nbsp; &amp;nbsp;&lt;span&gt;prog&lt;/span&gt;, &lt;span&gt;locMap&lt;/span&gt;, &lt;span&gt;err&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; &lt;span&gt;Compile&lt;/span&gt;(g) &amp;nbsp; &amp;nbsp;&lt;span&gt;if&lt;/span&gt; err != &lt;span&gt;nil&lt;/span&gt; {
 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;log.&lt;span&gt;Fatal&lt;/span&gt;(err)
 &amp;nbsp; &amp;nbsp;} &amp;nbsp; &amp;nbsp;&lt;span&gt;&lt;span&gt;//&lt;/span&gt; create a VM to run the program on&lt;/span&gt;
 &amp;nbsp; &amp;nbsp;&lt;span&gt;machine&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; &lt;span&gt;NewTapeMachine&lt;/span&gt;(prog, locMap) &amp;nbsp; &amp;nbsp;&lt;span&gt;&lt;span&gt;//&lt;/span&gt; set initial values then run&lt;/span&gt;
 &amp;nbsp; &amp;nbsp;&lt;span&gt;Let&lt;/span&gt;(x, &lt;span&gt;2.0&lt;/span&gt;) &amp;nbsp; &amp;nbsp;&lt;span&gt;Let&lt;/span&gt;(y, &lt;span&gt;2.5&lt;/span&gt;) &amp;nbsp; &amp;nbsp;&lt;span&gt;if&lt;/span&gt; machine.&lt;span&gt;RunAll&lt;/span&gt;() != &lt;span&gt;nil&lt;/span&gt; {
 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;log.&lt;span&gt;Fatal&lt;/span&gt;(err)
 &amp;nbsp; &amp;nbsp;}

 &amp;nbsp; &amp;nbsp;fmt.&lt;span&gt;Printf&lt;/span&gt;(&lt;span&gt;&lt;span&gt;"&lt;/span&gt;z: %v&lt;span&gt;\n"&lt;/span&gt;&lt;/span&gt;, z.&lt;span&gt;Value&lt;/span&gt;()) &amp;nbsp; &amp;nbsp;&lt;span&gt;xgrad&lt;/span&gt;, &lt;span&gt;err&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; x.&lt;span&gt;Grad&lt;/span&gt;() &amp;nbsp; &amp;nbsp;&lt;span&gt;if&lt;/span&gt; err != &lt;span&gt;nil&lt;/span&gt; {
 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;log.&lt;span&gt;Fatal&lt;/span&gt;(err)
 &amp;nbsp; &amp;nbsp;}
 &amp;nbsp; &amp;nbsp;fmt.&lt;span&gt;Printf&lt;/span&gt;(&lt;span&gt;&lt;span&gt;"&lt;/span&gt;dz/dx: %v | %v&lt;span&gt;\n"&lt;/span&gt;&lt;/span&gt;, xgrad, grads[&lt;span&gt;0&lt;/span&gt;]) &amp;nbsp; &amp;nbsp;&lt;span&gt;ygrad&lt;/span&gt;, &lt;span&gt;err&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; y.&lt;span&gt;Grad&lt;/span&gt;() &amp;nbsp; &amp;nbsp;&lt;span&gt;if&lt;/span&gt; err != &lt;span&gt;nil&lt;/span&gt; {
 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;log.&lt;span&gt;Fatal&lt;/span&gt;(err)
 &amp;nbsp; &amp;nbsp;}
 &amp;nbsp; &amp;nbsp;fmt.&lt;span&gt;Printf&lt;/span&gt;(&lt;span&gt;&lt;span&gt;"&lt;/span&gt;dz/dy: %v | %v&lt;span&gt;\n"&lt;/span&gt;&lt;/span&gt;, ygrad, grads[&lt;span&gt;1&lt;/span&gt;]) &amp;nbsp; &amp;nbsp;&lt;span&gt;&lt;span&gt;//&lt;/span&gt; Output:&lt;/span&gt;
 &amp;nbsp; &amp;nbsp;&lt;span&gt;&lt;span&gt;//&lt;/span&gt; z: 4.5&lt;/span&gt;
 &amp;nbsp; &amp;nbsp;&lt;span&gt;&lt;span&gt;//&lt;/span&gt; dz/dx: 1 | 1&lt;/span&gt;
 &amp;nbsp; &amp;nbsp;&lt;span&gt;&lt;span&gt;//&lt;/span&gt; dz/dy: 1 | 1&lt;/span&gt;}&lt;/span&gt;&lt;/pre&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然人们在 Gorgonia 中，能嗅到支持 dualValue 存在条件下进行正向模式微分的旧版痕迹，但其目前仅执行反向模式自动微分（又名反向传播）。正向模式微分也许在将来能够回归。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;图表&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;确实存在许多计算图或表达式图的有关说法，但它究竟是什么？请将它想象成你想要的数学表达式的 AST。此处为上述示例的图形（但还有一个向量和一个标量加法）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/053df1295761cdbbcac2bfc656ec9c8995b945ac"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;顺便一提，Gorgonia 的图形打印能力很强。此处为方程式 y = x&amp;sup2; 及其导数的图形示例：&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/5e3ab4a15ed107d7ab6f792f262b6aa49c74ddba"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图形很容易阅读。表达式从下往上进行构建，而导数是由上向下构建的。因此每个节点的导数大致处于同一水平。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;红色轮廓的节点表示它们是根节点，而绿色轮廓则表示为叶节点，带有黄色背景的节点表示为输入节点，而虚线箭头则表示哪个节点是指向节点的梯度节点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;具体而言，比如 c42011e840 (dy/dx) 便表示输入 c42011e000（即 x）的梯度节点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;节点渲染&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;节点是这样渲染的：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/3c45d21ebbb2e3f64597a3b19bfdc9beb950dcb9"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;补充说明：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如果它是输入节点，则 Op 行不会显示。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如果没有绑定到节点的值，将显示为 NIL。但若有值和梯度存在，它将极尽所能显示绑定到节点的值。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;使用 CUDA&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此外，还存在附加要求：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 需要 CUDA toolkit 8.0。安装这个程序将会安装 nvcc 编译器，这是使用 CUDA 运行代码所必备的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. go install github.com/chewxy/gorgonia/cmd/cudagen。这是 cudagen 程序的安装网址。运行 cudagen 将生成与 Gorgonia 有关的 CUDA 相关代码。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 务必使用 UseCudaFor 选项，务必使代码中的 CUDA 操作能够手动启用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4. runtime.LockOSThread() 必须在虚拟内存正在运行的主函数中调用。CUDA 需要线程亲和性，因此必须锁定 OS 线程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;示例&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以，我们该如何使用 CUDA 呢？假设有一个文件 main.go：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;import&lt;/span&gt; ( &amp;nbsp; &amp;nbsp;&lt;span&gt;&lt;span&gt;"&lt;/span&gt;fmt&lt;span&gt;"&lt;/span&gt;&lt;/span&gt;
 &amp;nbsp; &amp;nbsp;&lt;span&gt;&lt;span&gt;"&lt;/span&gt;log&lt;span&gt;"&lt;/span&gt;&lt;/span&gt;
 &amp;nbsp; &amp;nbsp;&lt;span&gt;&lt;span&gt;"&lt;/span&gt;runtime&lt;span&gt;"&lt;/span&gt;&lt;/span&gt;

 &amp;nbsp; &amp;nbsp;&lt;span&gt;T&lt;/span&gt; &lt;span&gt;&lt;span&gt;"&lt;/span&gt;github.com/chewxy/gorgonia&lt;span&gt;"&lt;/span&gt;&lt;/span&gt;
 &amp;nbsp; &amp;nbsp;&lt;span&gt;&lt;span&gt;"&lt;/span&gt;github.com/chewxy/gorgonia/tensor&lt;span&gt;"&lt;/span&gt;&lt;/span&gt;)&lt;span&gt;func&lt;/span&gt; &lt;span&gt;main&lt;/span&gt;() { &amp;nbsp; &amp;nbsp;&lt;span&gt;g&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; T.&lt;span&gt;NewGraph&lt;/span&gt;() &amp;nbsp; &amp;nbsp;&lt;span&gt;x&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; T.&lt;span&gt;NewMatrix&lt;/span&gt;(g, T.&lt;span&gt;Float32&lt;/span&gt;, T.&lt;span&gt;WithName&lt;/span&gt;(&lt;span&gt;&lt;span&gt;"&lt;/span&gt;x&lt;span&gt;"&lt;/span&gt;&lt;/span&gt;), T.&lt;span&gt;WithShape&lt;/span&gt;(&lt;span&gt;100&lt;/span&gt;, &lt;span&gt;100&lt;/span&gt;)) &amp;nbsp; &amp;nbsp;&lt;span&gt;y&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; T.&lt;span&gt;NewMatrix&lt;/span&gt;(g, T.&lt;span&gt;Float32&lt;/span&gt;, T.&lt;span&gt;WithName&lt;/span&gt;(&lt;span&gt;&lt;span&gt;"&lt;/span&gt;y&lt;span&gt;"&lt;/span&gt;&lt;/span&gt;), T.&lt;span&gt;WithShape&lt;/span&gt;(&lt;span&gt;100&lt;/span&gt;, &lt;span&gt;100&lt;/span&gt;)) &amp;nbsp; &amp;nbsp;&lt;span&gt;xpy&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; T.&lt;span&gt;Must&lt;/span&gt;(T.&lt;span&gt;Add&lt;/span&gt;(x, y)) &amp;nbsp; &amp;nbsp;&lt;span&gt;xpy2&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; T.&lt;span&gt;Must&lt;/span&gt;(T.&lt;span&gt;Tanh&lt;/span&gt;(xpy)) &amp;nbsp; &amp;nbsp;&lt;span&gt;prog&lt;/span&gt;, &lt;span&gt;locMap&lt;/span&gt;, &lt;span&gt;_&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; T.&lt;span&gt;Compile&lt;/span&gt;(g) &amp;nbsp; &amp;nbsp;&lt;span&gt;m&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; T.&lt;span&gt;NewTapeMachine&lt;/span&gt;(prog, locMap, T.&lt;span&gt;UseCudaFor&lt;/span&gt;(&lt;span&gt;&lt;span&gt;"&lt;/span&gt;tanh&lt;span&gt;"&lt;/span&gt;&lt;/span&gt;))

 &amp;nbsp; &amp;nbsp;T.&lt;span&gt;Let&lt;/span&gt;(x, tensor.&lt;span&gt;New&lt;/span&gt;(tensor.&lt;span&gt;WithShape&lt;/span&gt;(&lt;span&gt;100&lt;/span&gt;, &lt;span&gt;100&lt;/span&gt;), tensor.&lt;span&gt;WithBacking&lt;/span&gt;(tensor.&lt;span&gt;Random&lt;/span&gt;(tensor.&lt;span&gt;Float32&lt;/span&gt;, &lt;span&gt;100&lt;/span&gt;*&lt;span&gt;100&lt;/span&gt;))))
 &amp;nbsp; &amp;nbsp;T.&lt;span&gt;Let&lt;/span&gt;(y, tensor.&lt;span&gt;New&lt;/span&gt;(tensor.&lt;span&gt;WithShape&lt;/span&gt;(&lt;span&gt;100&lt;/span&gt;, &lt;span&gt;100&lt;/span&gt;), tensor.&lt;span&gt;WithBacking&lt;/span&gt;(tensor.&lt;span&gt;Random&lt;/span&gt;(tensor.&lt;span&gt;Float32&lt;/span&gt;, &lt;span&gt;100&lt;/span&gt;*&lt;span&gt;100&lt;/span&gt;))))

 &amp;nbsp; &amp;nbsp;runtime.&lt;span&gt;LockOSThread&lt;/span&gt;() &amp;nbsp; &amp;nbsp;&lt;span&gt;for&lt;/span&gt; &lt;span&gt;i&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; &lt;span&gt;0&lt;/span&gt;; i &amp;lt; &lt;span&gt;1000&lt;/span&gt;; i++ { &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;span&gt;if&lt;/span&gt; &lt;span&gt;err&lt;/span&gt; &lt;span&gt;:=&lt;/span&gt; m.&lt;span&gt;RunAll&lt;/span&gt;(); err != &lt;span&gt;nil&lt;/span&gt; {
 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;log.&lt;span&gt;Fatalf&lt;/span&gt;(&lt;span&gt;&lt;span&gt;"&lt;/span&gt;iteration: %d. Err: %v&lt;span&gt;"&lt;/span&gt;&lt;/span&gt;, i, err)
 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;}
 &amp;nbsp; &amp;nbsp;}
 &amp;nbsp; &amp;nbsp;runtime.&lt;span&gt;UnlockOSThread&lt;/span&gt;()

 &amp;nbsp; &amp;nbsp;fmt.&lt;span&gt;Printf&lt;/span&gt;(&lt;span&gt;&lt;span&gt;"&lt;/span&gt;%1.1f&lt;span&gt;"&lt;/span&gt;&lt;/span&gt;, xpy2.&lt;span&gt;Value&lt;/span&gt;())
}&lt;/span&gt;&lt;/pre&gt;&lt;p&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果它正常运行：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;go run main.go&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;CUDA 不会被使用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果程序要使用 CUDA 运行，那么必须进行调用：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;go run -tags='cuda'&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;即便如此，也只有 tanh 函数使用 CUDA。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;解释&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使用 CUDA 的要求这么复杂，主要与其性能有关。正如 Dave Cheney 的名言：cgo 不是 Go。但不幸的是，使用 CUDA 必定需要 cgo；而若要使用 cgo，则需做出大量权衡。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此，解决方案是将 CUDA 相关代码嵌套于构建标记 cuda 中，以这样的方式默认未使用 cgo（好吧，只用了一点点，你仍然可以使用 cblas 或 blase）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;安装 CUDA toolkit 8.0 的原因是：存在许多 CUDA 计算能力，为它们生成代码将产生一个毫无益处的巨大二进制。相反，用户会倾向于为他们特定的计算能力编译。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，要求制定使用 CUDA 操作的明确规范，是由于 cgo 调用的成本问题。目前为了实现批量的 cgo 调用而在进行额外的努力，但是直到完成之前，该解决方案都会是特定操作的「升级」关键。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;CUDA 支持的操作&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;迄今为止，只有极基本的简单操作能够支持 CDUA：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;元素一元运算：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;abs&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;sin&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;cos&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;exp&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;ln&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;log2&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;neg&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;square&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;sqrt&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;inv (reciprocal of a number)（数字的倒数）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;cube&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;tanh&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;sigmoid&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;log1p&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;expm1&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;softplus&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;元素二进制操作&amp;mdash;&amp;mdash;只有算术运算支持 CUDA：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;add&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;sub&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;mul&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;div&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;pow&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;根据对作者个人项目的大量剖析，发现真正重要的是 tanh、sigmoid、expm1、exp 和 cube，即激活函数。其他使用 MKL + AVX 的操作正常运行，且并非造成神经网络缓慢的主因。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;CUDA 的改进&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在一项次要的基准测试中，CUDA 的谨慎使用（此情况通常调用 sigmoid）显示出非 CUDA 代码的大幅改进（考虑到 CUDA 内核十分朴素且未优化）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;code style=" box-sizing: border-box; ; ; ; ; ; ; ; ; ; ; ; ; ; "&gt;&lt;span&gt;BenchmarkOneMilCUDA-8 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;300 &amp;nbsp; &amp;nbsp; &amp;nbsp; 3348711 ns/op
BenchmarkOneMil-8 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 50 &amp;nbsp; &amp;nbsp; &amp;nbsp;33169036 ns/op&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;API 的稳定性&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Gorgonia 的 API 如今并不稳定，它将从 1.0 版本开始慢慢稳定。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1.0 版本是测试覆盖率达到 90％时所定义的，并且相关的 Tensor 方法已经完成。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;路线图&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是依照重要性排序所列出的 Gorgonia 的目标：&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: circle;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;80％以上的测试覆盖率。目前 Gorgonia 的覆盖率为 50％，tensor 为 80％。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;更高级的操作（如 einsum）。目前的 Tensor 操作符非常原始。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;软件包中的 TravisCI。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;软件包中的 Coveralls。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: circle;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;清除测试。测试是多年积累的结果，妥当地重构它们将大有裨益。若条件允许，使用表格驱动测试。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;提升性能，特别是应当重新分配，将系统类型的影响最小化。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;将 Op 界面从半输出公开／更改为全输出，以此提高 Op 的可扩展性（或者为扩展性创建一个 Compose 的 Op 类型）。这样每个人都可以制作自定义的 Op。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: circle;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;为了跟随 CUDA 的实现，重构 CuBLAS 以及 Blase 软件包。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;分布式计算。尝试多个机器上传播作业并彼此通信已至少 3 次，但无一成功。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;更好地记录做出某些决定的原因，并从宏观上对 Gorgonia 进行设计。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;高阶导数优化算法（LBFGS）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;无导数的优化算法&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;目标&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Gorgonia 的主要目标是成为一个基于机器学习/图形计算，能够跨多台机器进行扩展的高性能库。它应将 Go（简单的编译和部署过程）的呼吁带至机器学习领域。这条路还很漫长，然而我们已然迈出了第一步。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其次要目标是为非标准的深度学习和神经网络相关事物提供一个探索平台，其中包括 neo-hebbian 学习、角切割算法、进化算法等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;显然，由于你在 Github 上阅读的可能性最大，Github 将构建该软件包工作流程的主要部分以完善该软件包。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;参见：CONTRIBUTING.md&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;贡献者与重要贡献者&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们欢迎任何贡献。但还有一类新的贡献者，称为重要贡献者。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;重要贡献者是对库的运作方式和/或其周围环境有深刻理解的人。此处举出重大贡献者的例子：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;撰写了大量与特定功能／方法的原因／机制，及不同部分相互影响的方式的有关文档&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;编写代码，并对 Gorgonia 更复杂的连接的部分进行了测试&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;编写代码和测试，并且至少接受 5 个拉取请求&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;对软件包的某些部分提供专家分析（比如你可能是优化一个功能的浮点操作专家）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;至少回答了 10 个支持性问题&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;重要贡献者列表将每月更新一次（如果有人使用 Gorgonia）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;如何获得支持&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如今最好的支持方式，便是在 Github 上留言。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;常见问题&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为什么在测试中似乎出现了 runtime.GC() 的随机调用？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;答案非常简单：软件包的设计使其以特定的方式使用 CUDA：具体而言，一个 CUDA 设备及其景况会绑定一个虚拟内存，而不是软件包。这意味着对于每个创建的虚拟内存，其每一设备每一个虚拟内存都会创建不同的 CUDA 景况。因此在其他可能正在使用 CUDA 的应用程序中，所有操作都能够正常运行（然而这需要进行压力测试）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;CUDA 的景况只有在虚拟内存回收垃圾（经由终结器函数的帮助）时才会被销毁。在测试中大约会创建 100 个虚拟内存，并且大多数垃圾回收是随机的；当景况被使用过多时，会导致 GPU 内存耗尽。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此，在任何可能使用 GPU 的测试结束时，会调用 runtime.GC() 来强制垃圾回收，以释放 GPU 内存。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人们在生产过程中不太可能启动过多的虚拟内存，因此这并不是问题。若有问题，请在 Github 上留言，我们会想办法为虚拟内存添加一个 Finish() 方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;许可&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Gorgonia 根据 Apache 2.0 的变体授权。其所有意图与目的 Apache 2.0 的许可相同，除了重要贡献者（如软件包的商业支持者），其他人均不能直接从中获得商业利润。但从 Gorgonia 的衍生直接获利是可行的（如在产品中使用 Gorgonia 作为库）。所有人都可将 Gorgonia 用于商业目的（如用于业务软件）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;各类其他版权声明&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是在写 Gorgonia 的过程中有所启发和进行改编的软件包和库（使用的 Go 软件包已经在上文做出了声明）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/bf9708268494f15bb58125b7b38074bf4a45d9d6"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;span&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Tue, 28 Feb 2017 12:17:03 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 帮助视觉障碍者浏览社交网络，Facebook如何将用户反馈整合进人工智能系统？</title>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650723729&amp;idx=4&amp;sn=2d53dda8658809c4cb2a29a4a96ff9ca&amp;chksm=871b11efb06c98f945532dc5a77e89aca3f8122d25ff16dba52b4a84c479657dab6690ee05c8&amp;scene=0#rd</link>
      <description>
&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自research.facebook&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Julie Schiller 等&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀、微胖、曹瑞、黄小天&lt;br&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Automatic Alt-Text 服务让盲人可以更好地理解他们的动态消息（News Feeds）中的照片。用户通过采访、可用性测试和调查等研究而协助了对这一工具的开发。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你对这项成果感兴趣，可在本周在波特兰的 CSCW 2017 上与相关开发者联系讨论，本研究的主要作者、数据科学家 Shaomei Wu 将会在会上呈现相关的研究细节。此外，机器之心还曾编译过 Facebook 官方发布的另一篇相关的技术解读文章&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722844&amp;amp;idx=2&amp;amp;sn=b15ce8f19792e3ca2f7395a327cd1aae&amp;amp;chksm=871b1662b06c9f7409b2d5de918dc808a330e7f0135dd90240d8b8eace85e5cc54f18e432568&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722844&amp;amp;idx=2&amp;amp;sn=b15ce8f19792e3ca2f7395a327cd1aae&amp;amp;chksm=871b1662b06c9f7409b2d5de918dc808a330e7f0135dd90240d8b8eace85e5cc54f18e432568&amp;amp;scene=21#wechat_redirect" target="_blank"&gt;《深度 | 详解 Facebook 全新图像识别系统：无需依赖标记的自由搜索》&lt;/a&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;背景&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你也知道，你的 Facebook 动态消息常常排满了你的好友分享的图片和视频。手机上高品质相机越普及，人们分享的图片和视频就会越多。能够观看和讨论视觉媒体的内容一直是 Facebook 的一个关键组成。实际上，每天在 Facebook、Instagram、Messenger 和 WhatsApp 上分享的照片多达 20 亿张。听起来很赞吧？但并不是每个人都会这样想。对于那些有视觉障碍（比如：失明）的人来说，他们很难围绕一张图片来展开对话。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Facebook 的使命是创造一个更加开放和互联的世界，并赋予人们分享的能力。在整个世界，有大约 3900 万人是盲人，有超过 2.46 亿人有严重的视觉障碍。据报道，因为他们无法充分地参与到围绕图片和视频的对话中，他们会产生沮丧感和疏离感和被孤立排斥的感觉。为了让更多人参与到查看照片方面的社交活动中，Facebook 推出了 Automatic Alt-Text（AAT），让屏幕阅读器的用户也能够理解其动态消息中的大多数照片的内容（期待很快就能阅读所有照片）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/95ec7a0a2e3ce928a1e4f9a3ce0fa7d7fae543f1"/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;过去是什么，现在又怎样？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;应该从哪里开始来解决这个难题？对于这个计算机视觉模型之下 AAT 和 Lumos 技术的创造请参阅&lt;a data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722844&amp;amp;idx=2&amp;amp;sn=b15ce8f19792e3ca2f7395a327cd1aae&amp;amp;chksm=871b1662b06c9f7409b2d5de918dc808a330e7f0135dd90240d8b8eace85e5cc54f18e432568&amp;amp;scene=21#wechat_redirect" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650722844&amp;amp;idx=2&amp;amp;sn=b15ce8f19792e3ca2f7395a327cd1aae&amp;amp;chksm=871b1662b06c9f7409b2d5de918dc808a330e7f0135dd90240d8b8eace85e5cc54f18e432568&amp;amp;scene=21#wechat_redirect" target="_blank"&gt;《深度 | 详解 Facebook 全新图像识别系统：无需依赖标记的自由搜索》&lt;/a&gt;。本文我们将关注我们如何通过与盲人用户合作来为他们创造出色的用户体验。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从之前的研究中我们了解到，一些服务会使用定制化的服务（或使用好朋友）来描述照片，用户需要为每一张想要了解的照片提出请求。不幸的是，这种方法存在一些问题：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;速度太慢&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;需要其他人在场，而且他愿意接受这个任务&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;会打断使用动态消息的流动性&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;可能最重要的：难以大规模应用&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而，这种方式也有好的一面。一位朋友或一位代表为你翻译照片的准确度是非常高的。朋友还能根据你们的关系给出额外的语境信息（比如，增加描述的色彩或说一个你们才懂的笑话）。但是这种解决方案能够在扩展的同时还能避免那些缺陷吗？我们的目标是创造一种新的 Facebook 功能，使其成为这类思想的下一代革命。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;AAT 项目的目标是以一种大规模、无延迟的方式来通过算法生成有用且准确的照片描述。我们以 image alt-text 的方式提供这些描述，这是一种为文本替代图像的内容管理而设计的 HTML 属性。因为 alt-text 是 W3C 可访问性标准的一部分，所以当人们将任何屏幕阅读器软件上的阅读光标移动到一张图像上时，该阅读器就可以抓取其 alt-text 然后将其朗读出来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;研究&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了构建一个可扩展的人工智能系统，我们用了 10 个月的时间完成了 2 种类型的研究。我们在 Shaomei Wu 设计的原型上进行了定性调查和可用性测试。这些定性环节有助于找出这种系统的关键问题，从而让我们可以进行一些修改，得到让人惊喜和感激的结果，而不是最终让人失望和困惑。我们用于确定我们的发现的另一个方法是推出一个实验性版本，告知人们我们会为他们发布一些实验性的功能，然后对他们进行一些和没有使用这些实验功能的用户（我们的对照组）一样的调查。这两组都来自于 VoiceOver Facebook iOS 用户。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;访谈 &amp;amp; 可用性测试&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;正如我们在这个过程中了解到的一样，最大的难题是在人们想要了解其消息流中关于图像的更多信息的愿望与这些信息的质量和社会智能之间找到平衡。对视觉内容的解读可能是非常主观的，而且可以也很依赖于语境。比如说，尽管人们基本上关心的是照片中有什么人以及他们在做什么事，但有时候关于这张照片的背景才是有意思的或重要的。对于我们最终组织读给人们听的句子方面，这是一个关键的发现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此外，让人来寻找一张照片中最有意思的地方是一个相当微不足道的任务，但对机器而言，即使最智能的人工智能也会感到相当困难。想让这项服务的体验优质，必须要了解照片的社会背景以及确定合适的反馈量，我们希望最终能达成这一目标！根据我们的访谈，我们发现比起丢下我们不确定的项不管，给出图片的错误信息实际上会更加糟糕。比如说，如果该服务说一张照片中有一个小孩，而实际上那却是一个个子很小的女子。我们也思考了其它公司的人工智能系统出现严重错误的地方，比如误将人类识别为动物，这可能会导致所有人都不愿看到的情况。如果该用户不知道该朋友没有孩子，那么他就可能会给出会导致难堪和社交尴尬的评论。在与开发团队的合作中，我们一直牢记这一点，并对我们要创造的系统有以下要求：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;能大规模地识别内容&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;能从照片中选取用户感兴趣的概念和事物&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;能为用户提供有意义的反馈&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;能提供无缝交互的感觉&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在定性环节，最后一个大的教训就是：在人工智能确定图片中的内容时，不要谈论把握有多大，这很重要。从参与者那里，我们得知这会让系统感觉起来像机器人或者不吉利。还会慢慢让用户不信任该系统。这里，我们做出了修改，让系统可以对图片中的内容达到极度确信状态（高于某个人工智能准确度阈值标准）。我们也很快去除了复述人工智能评级的确定性（用来确定每个图片中的内容）的机器人特性。尽管将准确性的指标抬得更高了，但是，在识别所有传到 Facebook 中的图片中的某个内容时，准确率也仅是超过 50%。这个数字会随着技术的不断改进而日趋增高。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;总之，在参与者们的非常有用的帮助下，关于如何采访那些想要分享一些定性研究小技巧的盲人，我们学习到了很多。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个简单的经验就是要有盲人参与者携带他们自己的设备。这会让他们在研究中感觉更加舒服自然（在对任何参与者来说这都是非常好的一个技巧），但同时也要允许他们对他们自己携带的辅助设备进行预配置。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一个技巧是让屏幕阅读器的使用者将语速调慢一点，这样你就能跟着进行出声思考。用很多的方式进行出声思考是参与者将屏幕阅读器中的读出的东西解释出来的方法。如果你跟不上这两者（参与者和阅读器的声音），就会丢失一半的数据。在你开始之前，就尝试使用屏幕阅读器，这样你才能成为一名更加高效的主持。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，一些研究人员表示，仅仅是招募屏幕阅读器用户就很难，因为很多 UX Recruiters 并不熟悉这一类人群。我们发现和宣传组织（advocacy groups，比如，Lighthouse）合作或者联系专门的招募单位寻找参与者是很有效的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;调查&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在深度定性理解的帮助下，我们为了描绘一个更全、更泛化的 AAT 使用反馈而转向了调查。我们调查了 550 名具有轻度视觉损害或全盲的参与者。如上所述，我们收到了来自控制组（通常是 Facebook）或 AAT（实验组）的更新版本的 Facebook 的反馈，总样本大约 9000。参与者填写了几乎相同的调查，调查涉及了很多问题，唯一区别是如果参与者来自实验组，有几个问题是专门为 AAT 准备的。参与者还有机会参加抽奖活动并获得一张价值 100 美元的亚马逊礼物卡。与任何调查书写一样，针对目标受访者创建最为简洁、易于理解的调查至关重要。我们就创建针对盲人用户的调查提出了一些实际的建议：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;避免使用横向单选按钮，以及拖／放问题。前者比垂直选项更难以分页，后者则对屏幕使用者来说根本不可能。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;避免使用矩阵和星级评分问题，前者不总是在 HTML 旁边被正确标记，使得在矩阵中识别应答者变的不可能；后者应该被替换为非图形 HTML 元素以使不同的屏幕阅读器可以更通用地访问。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;为屏幕阅读器用户提供返回功能，因为无意的错误会更频繁地发生。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;做一项关于屏幕阅读器的调查比调查一个视力正常的用户通过鼠标使用 OS 更费时一点。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如果屏幕阅读器用户响应你的调查对你来说很重要，那么让屏幕阅读器的用户首先进行导航，这可能很重要。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;与传统的优秀调查设计一样，尽量在每页之中仅包含少量问题，以避免出现认知复杂化和导航问题。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;使用间距，确保单选按钮和复选框与其标签清楚相关，以防止模糊和混乱。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;首字母缩略词和缩写在调查中很常见。然而并不是所有的受访者都会熟悉或记住它们，屏幕阅读器可能难以读出首字母缩略词和缩写。虽然「acronym」和「abbr」标签可以缓解这一点，并且「标题」属性可以在需要时提供进一步的信息。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;调查／试验发现：亮点&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;测试组中的人对该 AAT 功能评价不错。这是通过与没有开启这一功能的控制组的比较而得出的结论。总体而言，测试组的参与者更有可能做以下事情：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;给他们的动态消息中的照片点赞或回复&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;相对于非 AAT 用户，认为 Facebook 更关心辅助功能&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;相对于非 AAT 用户，认为总体而言 Facebook 更有用&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;最重要的是，可以更容易地明白照片中的内容&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;来自调查的样本问题：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们让 AAT 用户确认在动态消息中一旦点击了一张图片是否会听到一句话。如果他们确实听到了以「图片可能包含&amp;hellip;」开始的一句话，接着我们会问一些问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;问题：（如果在测试组）听到这个替换文本你有什么感受（检查所有使用）？&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;测试组中的受访者被展示了一个随机分类的词集帮助他们描述听到图片之中的替换文本的感受。我们还启用了其他方法帮助受访者写下他们的想法。根据调查结果，我们发现受访者更强调积极词汇：快乐（29%）、惊喜（26%）和印象深刻（25%）分别排在前三名。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;问题：回想一下动态消息中你还记得的最后几张照片，以回答这个页面上的问题。对于那些照片，描述照片关于什么的难／易程度是多少？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「还算容易」与「很难」的答案有很大不同，前者是 23% 与 2%，后者是 42% 与 73%。这表明 AAT 提供了额外价值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/509aeec899d2f2f51019314b05f77c9fe4d9792d"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;接下来呢？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这项研究还处在婴儿期，有关改善建议主要关注以下两类问题：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;从图片中识别和提取文本（29% 推荐这个功能）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;就图片中的人物提供更多的细节（26% 推荐这个功能）&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其它要求包括扩大该算法的词汇，增加既有标签的重新调用，可以在更多语言以及平台语境下用到 AAT 等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;原文链接：https://research.fb.com/accessibility-research-developing-automatic-alt-text-for-facebook-screen-reader-users/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;span&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Tue, 28 Feb 2017 12:17:03 +0800</pubDate>
    </item>
    <item>
      <title>学界 | 日本研究者提出新算法：让机器人通过多模态深度强化学习获得社会智能</title>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650723729&amp;idx=5&amp;sn=ab594ca1178aadd40f4dd5877e4c48d2&amp;chksm=871b11efb06c98f991e3b81a6c4d92564e7e658b4ea0a8f4d1e5b5f1106959c7d1489ed1c81f&amp;scene=0#rd</link>
      <description>
&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自arXiv.org&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们一直在期待机器人能在我们的日常生活中发挥重要的作用，而作为机器人强国的日本也一直是这一领域的领导者之一。近日，日本大阪大学和日本科学枝术振兴机构（JST）ERATO ISHIGURO 共生人机交互项目（Symbiotic Human-Robot Interaction Project）的研究者在 arXiv 提交了一篇论文，介绍了他们在机器人的社会智能上的研究成果。另外值得一提的是，他们的实验用到了著名的 Pepper 机器人。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/f5fd3ea78f63af4e7c8202052ad854e06028eed3"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;摘要&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;要让机器人与人类在类似我们社会那样的社会世界中共存，它们需要掌握类似人类的社交技能，这是很关键的。通过编程的方式来让机器人掌握这些技能是很艰难的。在这篇论文中，我们提出了一种多模态深度 Q 网络（MDQN：Multimodal Deep Q-Network），可以让机器人通过试错的方法来学习类似人类的交互技能。这篇论文的目标是开发能够在与人类的交互过程中收集数据并且能够使用端到端的强化学习从高维度传感信息中学习人类交互行为的机器人。本论文表明，机器人在经过了与人类的 14 天交互之后，可以成功学会基本的交互技能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/f4b9278736b46500fd1d28f02a2779a91a555759"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;图 1：机器人向人学习社交技能&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;算法介绍&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里提出的算法由两个独立工作的流组成：一个用于处理灰度帧（grayscale frame），另一个用于处理深度帧（depth frame）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面的 Algorithm 1 概述了这个算法。因为该模型有两个流，因为其参数 &amp;theta; 和 &amp;theta;- 是由两个网络的参数构成的。和 DQN [10] 不同，我们将数据生成阶段和训练阶段分开了。每一天的实验都对应于一个 episode，在这期间，算法要么执行数据生成阶段，要么执行训练阶段。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/8c773a67a1e0877c3b3c0f3bc908340fd201f4da"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;本研究所提出的算法的伪代码&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以下是这两个阶段的简述：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据生成阶段（data generation phase）：在数据生成阶段，系统使用 Q 网络 Q(s, a; &amp;theta;) 来与其环境进行交互。该系统会观察当前场景（由灰度帧和深度帧构成），并使用 &amp;epsilon;-greedy 策略来采取行动。该环境又会反过来提供标量的奖励（reward）（请参阅 5(2) 节了解奖励函数的定义）。交互经历是&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/d12e8a240b4e1553a494dee9a05f73a9bef8ea6c"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其被存储在重放记忆 M 中。重放记忆 M 会保存 N 个最近的经历，然后这些经历会在训练阶段被用于更新该网络的参数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;训练阶段（training phase）：在训练阶段，该系统会利用存储在重放记忆 M 中的数据来对网络进行训练。超参数 n 表示经历重放的数量。对于每一次经历重放，都会从有限大小的重放记忆 M 中随机采样出一个包含 2000 次交互经历的迷你缓存器 B。该模型会在从缓存器 B 中采样出的 mini batch 上进行训练，该网络的参数会在 bellman targets 的方向上迭代式地更新。这个对重放记忆的随机采样会打破样本之间的相关性，因为标准的强化学习方法假定样本是独立的且完全分布式的。将该算法分成两个阶段的原因是为了避免延迟&amp;mdash;&amp;mdash;如果该网络在交互期间同时进行训练就会产生这种延迟。该 DQN [16] 代理在一个循环中工作，其中它首先会与环境进行交互，然后会将这个转变存储到重放记忆中，然后其会从该重放记忆中采样出 mini batch，并在这个 mini batch 上训练该网络。这个循环会不断重复，直到终止。这个交互和训练的顺序过程在 HRI 之外的领域也许是可以接受的。在 HRI 领域，代理必须基于社会规范来和人类进行交互，因此机器人的任何停顿和延迟都是不可接受的。因此，我们将该算法分成了两个阶段：在第一个阶段，机器人通过与人类进行有限时间的交互来收集数据；在第二个阶段，其进入阶段。在这个休息阶段，训练阶段激活从而对该多模态深度 Q 网路（MDQN）进行训练。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;实现细节&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个模型由两个流（stream）构成，一个用于灰度信息，另一个用于深度信息。这两个流的结构是完全相同的，每个流都由 8 个层组成（包括输入层）。整体模型架构如图 2 所示。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/8d0458a9ec1b73461b9552d792889625632f720f"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;图 2：双流式卷积神经网络&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该多模态 Q 网络的 y 信道和 depth 信道的输入分别是灰度图像（198 &amp;times; 198 &amp;times; 8）和深度图像（198 &amp;times; 198 &amp;times; 8）。因为每个流都使用 8 帧输入，因此，来自对应相机的最新的 8 帧是被预处理后堆叠到一起，构成该网络的每个流的输入。因为这两个流是完全一样的，所以我们在这里只讨论一个流的结构即可。198 &amp;times; 198 &amp;times; 8 的输入图像首先被传递给第一个卷积层（C1），其以 3 的步幅卷积计算 9&amp;times;9 的 16 个滤波器，后面则跟着一个整流线性单元（ReLU）函数并得到每个大小为 64&amp;times;64 的 16 个特征图（我们将其记为 16@64&amp;times;64）。这个来自 C1 的输出然后会被送入下采样层 S1，其以 2&amp;times;2 的步幅应用 2&amp;times;2 的最大池化（max-pooling）。第二（C2）和第三（C3）个卷积层分别卷积计算 32 和 64 个滤波器，其大小为 5&amp;times;5，使用了 1 的步幅。C2 和 C3 的输出通过非线性 ReLU 函数，然后分别被送入下采样层 S2 和 S3。最后的隐藏层是带有 256 个整流单元的全连接层。输出层则是一个全连接的线性层，带有 4 个单元，每一个单元对应一个合法动作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/44c6d63111c4bc660edb45d67a6a12af08e3560d"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;图 3：成功和不成功的握手示例&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/902d1dd9f18ce558d1703cd2e645314610c72693"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;图 4：在经过了一系列的 episode 之后，MDQN 在测试数据集上的表现&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;论文链接：https://arxiv.org/abs/1702.07492&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;span&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Tue, 28 Feb 2017 12:17:03 +0800</pubDate>
    </item>
    <item>
      <title>经验之谈：如何为你的机器学习问题选择合适的算法？</title>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650723704&amp;idx=1&amp;sn=5e791710b46502661e25ff6f7528003b&amp;chksm=871b1106b06c98107174c81401c1f7017b35939ab20bc83b305ecae8b503690518fd32d75bbd&amp;scene=0#rd</link>
      <description>
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自askaswiss&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Michael Beyeler&amp;nbsp;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：王宇欣、吴攀 、邵明&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随着机器学习越来越流行，也出现了越来越多能很好地处理任务的算法。但是，你不可能预先知道哪个算法对你的问题是最优的。如果你有足够的时间，你可以尝试所有的算法来找出最优的算法。本文介绍了如何依靠已有的方法（模型选择和超参数调节）去指导你更好地去选择算法。本文作者为华盛顿大学 eScience Institute 和 Institute for Neuroengineering 的数据科学博士后 Michael Beyeler。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/82662eaa74cd42c11c4067f2cf98904b0f6dafbc"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;步骤 0：了解基本知识&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在我们深入学习之前，我们先重温基础知识。具体来说，我们应该知道机器学习里面三个主要类别：监督学习，无监督学习和强化学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/604ad1d707eb18fc658c47d3cf066fc5572c6992"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在监督学习（supervised learning）中，每个数据点都会获得标注，如类别标签或与数值相关的标签。一个类别标签的例子：将图片分类为「猫」或「狗」；数值标签的例子如：预测一辆二手车的售价。监督学习的目的是通过学习许多有标签的样本，然后对新的数据做出预测。例如，准确识别新照片上的动物（分类）或者预测二手车的售价（回归）。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在无监督性学习（unsupervised learning）中，数据点没有相关的标签。相反，无监督学习算法的目标是以某种方式组织数据，然后找出数据中存在的内在结构。这包括将数据进行聚类，或者找到更简单的方式处理复杂数据，使复杂数据看起来更简单。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在强化学习（reinforcement learning）中，算法会针对每个数据点来做出决策（下一步该做什么）。这种技术在机器人学中很常用。传感器一次从外界读取一个数据点，算法必须决定机器人下一步该做什么。强化学习也适合用于物联网应用。在这里，学习算法将收到奖励信号，表明所做决定的好坏，为了获得最高的奖励，算法必须修改相应的策略。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;步骤 1：对问题进行分类&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;接下来，我们要对问题进行分类，这包含两个过程：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;根据输入数据分类：如果我们的数据有标签，这就是一个监督学习问题；如果数据没有标签而且我们想找出数据的内在结构，那这就是无监督学习；如果我们想通过与环境交互来优化目标函数，这是强化学习。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;根据输出结果分类：如果模型输出结果是一个数值，这是回归问题；如果输出结果是一个类别，这是分类问题；如果输出结果是一组输入数据，那这是聚类问题。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;就是这么简单！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;更一般地说，我们可以询问我们自己：我们的算法要实现什么目标，然后以此来找到正确的算法类别。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/c3e65b5eccdce6391fee2a1d42ad6d874221d2d4"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;上面的描述包括了几个我们还没有提到的专业术语：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;分类（classification）：当使用数据来预测类别时，监督学习也被叫做分类。比如将含有「猫」或「狗」的图片识别出来，分类为「猫」或「狗」，这就是二分类问题（two-class or binomial classification）。当存在更多类别时（例如预测下一届诺贝尔物理学家的获得者是谁），这就是所谓的多分类问题（multi-class classification）。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;回归（regression）：当要预测数值时（比如预测股价），监督学习也被称为回归。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;聚类（clustering）：聚类或聚类分析（cluster analysis）是无监督学习中最常见的方法之一。聚类是将一组对象以某种方式分组，使得同一组中的数据比不同组的数据有更多的相似性。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;异常检测（Anomaly detection）：有时我们需要找出数据点中的异常点。例如，在欺诈检测中，任何极不寻常的信用卡消费都是可疑的；欺诈具有大量不同的形式，而训练样本又非常少，使得我们不可能完全了解欺诈活动应该是什么样。异常检测所采取的方法就是了解正常情况下的表现行为（使用非欺诈交易的历史数据），并识别出显著不同的表现行为。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;步骤 2：寻找可用的算法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在我们已经将问题进行了分类，我们就可以使用我们所掌握的工具来识别出适当且实用的算法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Microsoft Azure 创建了一个方便的算法列表，其展示了哪些算法可用于哪种类别的问题。虽然该表单是针对 Azure 软件定制的，但它具有普遍的适用性（该表单的 PDF 版本可查阅 http://suo.im/3Ss2zW )：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/8c6bcd4e8399e43604ea97ff7a8b3e9e5a255e82"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一些值得注意的算法如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: circle;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;分类：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;支持向量机（SVM）可用于找到尽可能宽的分类的边界。当两个分类不能被清楚地分开时，该算法会找到其所能找到的最佳边界。其真正的亮点在于处理特征密集的数据，比如文本或者基因组（特征数量&amp;gt; 100）。在这些情况下，除了仅需要适量的记忆外，支持向量机（SVM）能够比其它大多数算法更快且更少过拟合地进行分类。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;人工神经网络是涵盖二分类、多分类和回归问题的脑启发式学习算法。它们有无限的种类，包括感知器和深度学习。它们需要很长时间来训练，但已知其在多种应用领域都实现了当前最佳的表现。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;logistic 回归：即便名字中有着「回归」，但 logistic 回归实际上是一种可用于二分类和多分类问题的强大工具。它快速且简单。事实上，它使用「S」形曲线而非直线，所以它自然适合用于数据分组。logistic 回归可以给出线性分类边界，所以如果你要使用它，你一定要确保你能接受线性的近似。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;决策树和随机森林：决策森林（decision forests）（回归、二分类、多分类），决策丛林（decision jungles）（二分类和多分类）和提升决策树（boosted decision trees）（回归和二分类）都基于决策树。这是一个基本的机器学习概念。决策树有许多不同的变体，但它们都在做同样的事情&amp;mdash;将特征空间（feature space）细分为具有大致相同标签的区域。这些区域可以是一致的类别或者恒定值，具体取决于你进行的是分类还是回归。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: circle;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;回归：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;线性回归是将一条线（或平面、或超平面）拟合到一个数据集上。这是一种主要的工具，简单且快速，但对于一些问题而言，它可能过于简单。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;贝叶斯线性回归有着非常理想的特性：它可以避免过拟合。贝叶斯方法通过事先对答案的可能分布做出一些假设来做到这一点。这种方法的另一个副产品是它们具有非常少的参数。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;提升决策树回归（Boosted decision tree regression）：如上所述，提升决策树（回归和二分类）均基于决策树，并通过将特征空间细分为具有大致相同标签的区域发挥效用。提升决策树通过限制其可以细分的次数以及每个区域中所允许的最少数据点来避免过拟合。该算法会构造一个树的序列，其中每棵树都会学习弥补之前的树留下来的误差。这能得到一个会使用大量的内存的非常精确的学习器。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: circle;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;聚类：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;层次聚类（Hierarchical Clustering）的目标是构建聚类的层次结构，它有两种形式。聚集聚类（agglomerative clustering）是一种「自下而上」的方法，其中每个观察（observation）在其自己的聚类中开始，随着其在层次中向上移动，成对的聚类会进行融合。分裂聚类（divisive clustering）则是一种「自上而下」的方法，其中所有的观察都从一个聚类开始，并且会随观察向下的层次移动而递归式地分裂。整体而言，这里的融合和分裂是以一种激进的方式确定的。层次聚类的结果通常表示成树状图（dendrogram）的形式。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;k-均值聚类（k-means clustering）的目标是将 n 组观测值分为 k 个聚类，其中每个观测值都属于其接近的那个均值的聚类&amp;mdash;&amp;mdash;这些均值被用作这些聚类的原型。这会将数据空间分割成 Voronoi 单元。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: circle;"&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;异常检测：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;k 最近邻（k-nearest neighbors / k-NN）是用于分类和回归的非参数方法。在这两种情况下，输入都是由特征空间中与 k 最接近的训练样本组成的。在 k-NN 分类中，输出是一个类成员。对象通过其 k 最近邻的多数投票来分类，其中对象被分配给 k 最近邻中最常见的类（k 为一正整数，通常较小）。在 k-NN 回归中，输出为对象的属性值。该值为其 k 最近邻值的平均值。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;单类支持向量机（One-class SVM）：使用了非线性支持向量机的一个巧妙的扩展，单类支持向量机可以描绘一个严格概述整个数据集的边界。远在边界之外的任何新数据点都是非正常的，值得注意。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;步骤 3：实现所有适用的算法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于任何给定的问题，通常有多种候选算法可以完成这项工作。那么我们如何知道选择哪一个呢？通常，这个问题的答案并不简单，所以我们必须反复试验。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;原型开发最好分两步完成。在第一步中，我们希望通过最小量的特征工程快速且粗糙地实现一些算法。在这个阶段，我们主要的目标是大概了解哪个算法表现得更好。这个步骤有点像招聘：我们会尽可能地寻找可以缩短我们候选算法列表的理由。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一旦我们将列表减少至几个候选算法，真正的原型开发开始了。理想情况下，我们会建立一个机器学习流程，使用一组经过仔细选择的评估标准来比较每个算法在数据集上的表现。在这个阶段，我们只处理一小部分的算法，所以我们可以把注意力转到真正神奇的地方：特征工程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;步骤 4：特征工程&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;或许比选择算法更重要的是正确选择表示数据的特征。从上面的列表中选择合适的算法是相对简单直接的，然而特征工程却更像是一门艺术。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;主要问题在于我们试图分类的数据在特征空间的描述极少。利如，用像素的灰度值来预测图片通常是不佳的选择；相反，我们需要找到能提高信噪比的数据变换。如果没有这些数据转换，我们的任务可能无法解决。利如，在方向梯度直方图（HOG）出现之前，复杂的视觉任务（像行人检测或面部检测）都是很难做到的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然大多数特征的有效性需要靠实验来评估，但是了解常见的选取数据特征的方法是很有帮助的。这里有几个较好的方法：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;主成分分析（PCA）：一种线性降维方法，可以找出包含信息量较高的特征主成分，可以解释数据中的大多数方差。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;尺度不变特征变换（SIFT）：计算机视觉领域中的一种有专利的算法，用以检测和描述图片的局部特征。它有一个开源的替代方法 ORB（Oriented FAST and rotated BRIEF）。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;加速稳健特征（SURF）：SIFT 的更稳健版本，有专利。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;方向梯度直方图（HOG）：一种特征描述方法，在计算机视觉中用于计数一张图像中局部部分的梯度方向的 occurrence。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;更多算法请参考：https://en.wikipedia.org/wiki/Visual_descriptor&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然，你也可以想出你自己的特征描述方法。如果你有几个候选方法，你可以使用封装好的方法进行智能的特征选择。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: circle;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;前向搜索：&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;最开始不选取任何特征。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;然后选择最相关的特征，将这个特征加入到已有特征；计算模型的交叉验证误差，重复选取其它所有候选特征；最后，选取能使你交叉验证误差最小特征，并放入已选择的特征之中。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;重复，直到达到期望数量的特征为止！&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: circle;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;反向搜索：&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;从所有特征开始。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;先移除最不相关的特征，然后计算模型的交叉验证误差；对其它所有候选特征，重复这一过程；最后，移除使交叉验证误差最大的候选特征。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;重复，直到达到期望数量的特征为止！&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使用交叉验证的准则来移除和增加特征！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;步骤 5：超参数优化&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，你可能想优化算法的超参数。例如，主成分分析中的主成分个数，k 近邻算法的参数 k，或者是神经网络中的层数和学习速率。最好的方法是使用交叉验证来选择。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一旦你运用了上述所有方法，你将有很好的机会创造出强大的机器学习系统。但是，你可能也猜到了，成败在于细节，你可能不得不反复实验，最后才能走向成功。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文地址：http://www.askaswiss.com/2017/02/how-to-choose-right-algorithm-for-your-machine-learning-problem.html&lt;/span&gt;&lt;/em&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;
</description>
      <pubDate>Mon, 27 Feb 2017 12:07:15 +0800</pubDate>
    </item>
    <item>
      <title>业界 |「平民轿跑」本田思域 700 美元变身自动驾驶，专家称改装合法</title>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650723704&amp;idx=2&amp;sn=a9240260e592180f56f7304ca46cac63&amp;chksm=871b1106b06c9810a03a8e9f52b0884da8bb693159c18ce63c643f71cce7ce74ceb7fdc88366&amp;scene=0#rd</link>
      <description>
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自sciencealert&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Brevan Jorgenson&amp;nbsp;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李泽南、晏奇&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/13e00ec3059f32d9449927cce41c8639a678259e"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不久之前，如果想拥有一辆自动驾驶汽车，你还需要购买一辆全新的特斯拉。现在不必了，最近来自内布拉斯加大学的几名学生已经找到了把新款本田思域改装成自动驾驶汽车的方法，最重要的是，这只需要 700 美元。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这一项目的发起者 Brevan Jorgenson 利用网上的开源代码构建了一个完整的自动驾驶系统，它可以控制汽车的油门、刹车和方向盘，并能通过加装的传感器使汽车可以感知路面上的情况。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Jorgenson 曾是 Comma.ai 的早期测试人员，这是一家位于旧金山的自动驾驶汽车初创公司，但在去年因道路安全法规等问题陷入了困境。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这个项目宣布成功以前，Jorgenson 已经对系统进行了一些测试，他声称改装后的第一次试驾是在今年 1 月份完成的。「那时我行进在黑暗的洲际公路上，车里只有我一个人，因为我不想在出现危险状况时会伤及他人，」他在接受采访时这样说道。「但这套系统工作的非常棒。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Jorgenson 使用的自动驾驶套件来自于 Comma.ai，这项技术在去年很遗憾地未能在公司承诺的时限内被推向市场，在计划失败后，公司将这一套件在线发布，人们只需要不到 1000 美元就可以购得它。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而，在线发布的方式并没有让这一被称为 Comma One 的自动驾驶套件打开市场。其中很大一部分原因是在兼容性上，目前 Comma One 只支持两种型号的汽车（本田思域 2016 款、讴歌 ILX2016 款）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此外，在去年 10 月，美国国家公路交通安全管理局（NHTSA）突然要求 Comma.ai 提供能够证明此项技术在日常驾驶期间能够保证安全的证据，否则不能上路，这一套件的销售随即被叫停。这一事件在 Comma.ai 创始人 George Hotz 的眼中，与 iPhone 和 PlayStation 的越狱权一样存在很大争议。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/878fdfbc9c583c63486370d10fe3be23c3b555e1"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随后，Comma.ai 将这一技术重命名为 Comma Neo 并在去年 11 月将其开源，所有人现在都可以在网上随意下载软件，硬件模块则被分开销售。「我们现在不再提供产品，」Hotz 表示。「我们只为开发者提供 Alpha 测试阶段的软件。我们不保证其可靠性。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于 Jorgenson 来说，幸运的是他的本田思域是 Comma Neo 兼容的车型，所以他立刻开始着手对自己的座驾进行自动驾驶模式的改造。在购买了价值 700 美元的硬件以后，他的计划看起来进展顺利。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Neo 的开源自动驾驶软件需要搭载在一加 3 手机上，手机通过有线方式链接汽车电子系统，所需零件都是通过 3D 打印的方式制造的。Jorgenson 通过在线 3D 打印服务制造了这些零件，并将其焊接在了一起。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 Comma.ai 协助修复了一些初始问题以后，整个系统开始正常运转起来，它看起来有点像是特斯拉汽车自动驾驶模式的早期版本，可以控制方向盘、油门和刹车，同时也可以对路面环境和其他车辆做出反应。「在把双手双脚从方向盘和踏板上松开的那一刻，我感觉有点奇怪，但是很快就适应了。」Jorgenson 说道。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/b724ec8c65141de376b6a8fcd4fc93c28aac272d"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是，将自己的座驾改装成自动驾驶汽车并在公路上行驶是否合法呢？南加州大学法律教授 Bryant Walker Smith 对此评论道：「尽管美国国家公路交通安全管理局可以对想要售卖自动驾驶汽车的厂商实施严格的规定，但是联邦与州立法律目前还并没有条款来限制想升级自己座驾的消费者。」&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Smith 就法律与自动化问题建议美国交通部，目前在使用自动驾驶技术来改装爱车上这个问题上，消费者可以享有很大程度上自由，至少是在美国，但是这不意味着当其对消费者造成麻烦时保险公司有必要为其承担相应的费用。「你能合法改装并不意味着你就不用负民事责任。」Smith 在去年一场新闻发布会上说道，这场发布会在网上发布了 Comma Neo 计划，Hotz 认为，让所有东西开源意味着人们再也不用面对 NHTSA（美国国家公路交通安全管理局）和加州 DMV（汽车部）的监管了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「NHTSA 仅 有权 管理被销售的实体产品，」Hotz 说，「他们不会去管理开源软件，最多就是口头警告。」值得一提的是，Jorgenson 的自动驾驶汽车还没有被独立测试过，所以对于这辆车的性能我们也只能暂时从他口中得知。但是，这正是问题所在&amp;mdash;&amp;mdash;Comma Neo 可以被任何人使用，而且他们不用一定要得到允许才能将自制自动驾驶汽车开到公路上测试。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管去年 Hotz 极力澄清说他们的技术更像一款「高级驾驶员辅助系统」，并且「不会把你的车变得可以自动驾驶。」但是至于车主怎么想我们就无从得知了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;所以，只能期望那些有能力使用这个东西的人不会拿它来干太过出格的事情了。&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文地址：http://www.sciencealert.com/this-college-student-made-his-honda-civic-a-self-driving-car-for-700&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Mon, 27 Feb 2017 12:07:15 +0800</pubDate>
    </item>
    <item>
      <title>观点 | 特朗普的阴影下，人工智能将如何变革华尔街？</title>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650723704&amp;idx=3&amp;sn=452124d54d3cef11b026d5019c6eed5e&amp;chksm=871b1106b06c981029acd8df0826f1d2a6f8585d331ce93bdb34e938dfad4a8d439e7a11153a&amp;scene=0#rd</link>
      <description>
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自Newsweek&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：KEVIN MANEY&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：微胖、黄小天 、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;过去的一年，整个社会在担忧人工智能夺去 300 万卡车司机的工作。结果证明比前者能更危险的是能买得起兰博基尼、雇得起 Elton John 参加其汉普顿之家派对的华尔街交易员和对冲基金经理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此，人们或许会为这个高呼人工智能万岁？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;像高盛这样的金融巨头以及其他大型对冲基金都正在切换至人工智能驱动的系统，以预测市场趋势，比人为交易更好。这些正在一步一步地发生，并已持续数年，但是一场人工智能飓风将席卷整个领域，纽约人工智能投资人和美国竞争力委员会（U.S. Council on Competitiveness）高级顾问 Mark Minevich 说。就像即将倒闭工厂是工人一样，高收入的华尔街交易员也面临着被非正式辞退的噩运。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Minevich 告诉我：「它会真的击中华尔街的要害，也将改变纽约。」&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;软件一直在学习&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;诸如旧金山创业公司 Sentient 和香港创业公司 Aidyia 正在打造人工智能交易系统中的一部分。2014 年，Goldman Sachs 投资并开始安装人工智能驱动的交易平台 Kensho。对冲基金创业公司 Walnut Algorithms，最开始就是研究人工智能的。臭名昭著且怪异的对冲基金公司 Bridgewater Associates 雇佣内部团队打造可自我运行实际操作的人工智能系统。David Ferrucci 主导 Bridgewater 的工作，它之前曾领导 Watson 计算机开发工作并赢得了Jeopardy!。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能交易软件通过吸取大量数据进行世界相关知识的学习，并对股票、债券、商品和其他金融工具做预测。人工智能可以获取书籍、推特、新闻报道、金融数据、收入数字、国际货币政策甚至周六夜现场概况等一切有助于其软件理解全球趋势的信息。人工智能可以 24 小时持续观察这些信息，从不疲倦，一直学习并不断优化预测。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一篇来自 Eurekahedge 的报道追踪了 23 家使用人工智能的对冲基金并发现它们优于人控基金。过去十年，设计了很赞的统计学模型的博士数学家 Quants 一直是对冲基金的宠儿，但是，他们依靠分析历史数据创建了一个可以预测市场趋势的模型。通过这种方式，Quant 模型就像一个静态的医学教科书，而人工智能学习机器就像一个追踪最新研究进行工作的医生。哪一个的诊断会更好？传统模型，对历史数据使用了回溯测试，通常不能实时提供好的回报。Eurekahedge 报道说。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/acf4ea960ba02de1d68de73bfcc0674761c23815"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;1 月 25 日，纽约，当道琼斯工业指数由于首次超过 20000 点而关闭时，纽约股票交易所的交易员在工作。SPENCER PLATT/GETTY&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人类交易员和对冲基金经理不再有机会，很大一部分原因在于他们是人。Sentient 联合创始人及苹果 Siri 研发计算机科学家 Babak Hodjat 说：人类有意或无意地充满偏见且敏感，有充分证据表明人类易于犯错。对我来讲，依赖于人类直觉和理性比纯粹依靠数据和统计学更可怕。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此，当金融从业人员发现自己站在正在驶来的人工智能快车之前时，会有什么后果？根据商业智能公司 Coalition Development 的报告，12 家最大投资银行的销售、交易与研究员工的平均补偿金是 50 万美元。许多交易员年薪是百万美元。根据一项产业调查，在 2015 年，5 个对冲基金经理的薪水加起来有 10 亿美元，甚至更多。如果你认为 Carl's Jr. 打算用机器人取代时薪 8 美元的快餐店工人，何不如取代这些年薪百万美元（时薪 500 美元）的交易员呢。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;交易员会遇到什么样的情况呢？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;高盛生动说明了自动化如何给交易员带来毁灭性的影响。2000 年，美国纽约的股票现金交易部门有 600 个交易员。如今，仅需两个股票交易员，机器包办剩余事宜。这还是人工智能全面冲击高盛之前的情况。Kensho CEO Daniel Nadler 告诉《纽约时报》，十年后，高盛员工肯定比今天还要少得多。每个主要金融公司的交易大厅也会是这种情况。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;很多美国人并不会同情《华尔街之狼》中描述的那些人，不过，从许多方面看，人工智能带来的新现实却是致命的。想象一下人工智能对纽约高端房地产业的影响吧，再想想 Southampton 夏天海边房子上挂着的「出售」牌子。以后，生活奢华的零售商们如何过得起这样的日子，动辄 2 千美元一套的西装，一磅 5,900 美元的白松露？或许特朗普会认为一些人移到了墨西哥而被敦促着要求这些人回到交易员的岗位。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;尽管如此，Minevich 看到了积极的一面，如果人工智能将金融领域的才俊赶到其他领域。作为实现百万年薪的捷径，华尔街交易和对冲基金管理工作长期吸引着大量美国最富头脑也最优秀的人才。顶级商学院的毕业生中，三分之一都会进入金融领域。只有少部分，约 5% 的人会进入保险领域。进入能源或制造业的就更少了。至于每年的非盈利组织的就业人数，两只手就可以数完。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所有剩下的社会成员会看到这些，看到自私。当然咯，我们需要高流通市场以及金融工具以及诸如此类的东西。不过，如果打算支付一些人高新，那么，如果这些人会发明出电动汽车，充电后行程达 1 千英里，或者健康的波兰熏肠以及不会再飞机上大哭的婴儿，我们才会生活得更富裕。对大众做些看得见摸得着的好事吧。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Minevich 说，「这些聪明人中，有一些会转移到科技创业公司，或帮助研发更多的人工智能平台，自动驾驶汽车或能源技术。」目前，这个或许真的有帮助，因为科技企业一直在为没有足够的高技术人才而焦虑，或许还会因为特朗普的禁令面临极客荒。如果 MBA 精英离开华尔街但不离开纽约，Minevich 补充说，「纽约或许能与硅谷竞争。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当数学博士发现对冲基金的招募不再让他们垂涎不已，或许会转而为气候变迁建模或者体内癌细胞的行为建模。国家安全局的网站上有消息表示，「正积极寻找数学家来解决一些最难的信号智能以及信息安全问题。」数学专家或许可以帮助抓捕恐怖分子！或自由主义分子！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;国家安全局给数学家的薪水大约为 10 万美元。这和对冲基金公司给的薪水比起来，意味着生活水平的严重下滑。不过，至少交易员和数量分析专家还有得选，比那些卡车司机以及其他工作受到人工智能威胁人的选择要多得多。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能机器掌管金融的有另外一个好处，Aidyia 的首席科学家 Ben Goertzel 说，「如果我们都死了，它会继续交易下去。」他的机器不需要人类的干预。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以，如果特朗普输入核弹密码，然后按下了发射按钮，至少一些人的养老金账户仍会有回报。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文地址：http://www.newsweek.com/how-artificial-intelligence-transform-wall-street-560637&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;span&gt;&lt;/span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Mon, 27 Feb 2017 12:07:15 +0800</pubDate>
    </item>
    <item>
      <title>资源 | 在TensorFlow 1.0上实现快速图像生成算法Fast PixelCNN++</title>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650723704&amp;idx=4&amp;sn=c6c4e45367f45fa859ce945c56dee499&amp;chksm=871b1106b06c9810da4433517e7f3e2a196706152bfc877bc3bdf41187d68c56a56066a6eae9&amp;scene=0#rd</link>
      <description>
&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;选自GitHub&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：PrajitR&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：Jane W、吴攀&amp;nbsp;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;近日，伊利诺大学香槟分校的研究者在 GitHub 上发布了一个快速图像生成算法 Fast PixelCNN++的实现，该算法的相关论文已被提交到 ICLR 2016。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;项目地址：https://github.com/PrajitR/fast-pixel-cnn&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;论文地址：https://openreview.net/pdf?id=rkdF0ZNKl&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们通过利用缓存避免冗余计算而实现了对图像生成算法 PixelCNN++ 的加速。原始的生成算法丢弃了可以重复利用的计算，并且还会占用不用于生成特定像素的附加计算资源。原始的算法在 Tesla K40 GPU 上生成 16 张 32x32 的图像可能需要长达 11 分钟。通过重新使用之前的计算并且仅执行所需的最小计算量，我们实现了相比原始生成算法高达 183 倍的加速。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/42361097d3169fa17ea6c11e7a8c877a023d2b64"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;如何运行&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们用 Python 3 和 TensorFlow 1.0 测试了我们的代码。对其它版本的 Python 或 TensorFlow 可能需要稍作更改。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;运行指南：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;安装 TensorFlow 1.0、Numpy 和 Matplotlib&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;下载并解压 OpenAI 预训练的 PixelCNN++ 模型（http://alpha.openai.com/pxpp.zip）。解压后，有一个名为 params_cifar.ckpt 的文件。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;设置参数 CUDA_VISIBLE_DEVICES = 0 运行脚本 python generate.py&amp;mdash;&amp;mdash;checkpoint = /path/to/params_cifar.ckpt&amp;mdash;&amp;mdash;save_dir = /path/to/save/generated/images&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该脚本将不断地循环生成图像，并将图像保存到&amp;mdash;&amp;mdash;save_dir。你可以随时通过使用 Control-C 中断退出该脚本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;算法原理&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;什么是 PixelCNN++，为什么要使用它？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;PixelCNN++ 是一个生成模型，它使用所有先前生成的像素作为信息生成下一个像素。也就是说，为了生成图像中的第 10 个像素，PixelCNN++ 将查看像素 1-9 来对像素 10 的输出分布建模：P(像素 10 |像素 1,..., 像素 9)。类似地，像素 11 将查看像素 1-10，继续这个过程直到对所有像素建模。这个特性使 PixelCNN 是一个自回归（autoregressive）模型，其中每个像素由先前像素的历史建模。使 PixelCNN 独一无二的是，该算法使用巧妙、快速的方法来集合来自先前像素的信息，这对于训练速度至关重要。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;PixelCNN 是由 DeepMind 最初开发的（https://arxiv.org/abs/1606.05328），并得到了 OpenAI 的改进而得到了 PixelCNN++（https://openreview.net/pdf?id=BJrFC6ceg）中进行了改进。这些模型已经在各种图像生成基准（image generation benchmark）上实现了当前最佳的结果。这些模型可以直接用来训练，有强大的应对复杂的输入建模的能力，并能够产生清晰，有吸引力的图像。例如，PixelCNN 最近已被用于图像超分辨率（superresolution）（https://arxiv.org/abs/1702.00783）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;与其它的生成模型（如生成对抗网络（Generative Adversarial Network）和变自编码器（Variational Autoencoder））相比，自回归模型的主要缺点之一是自回归模型必须一次产生一个像素，而其它方法可以一次产生整个图像。我们的方法加速了 PixelCNN 的生成过程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加速一个带有膨胀系数（dilation）的简单的 1 维例子&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在介绍加速 PixelCNN 的细节之前，让我们关注一个更简单的 1 维自回归模型：Wavenet（https://arxiv.org/abs/1609.03499）。这里提供的细节类似于 GitHub 上的 Fast Wavenet（https://github.com/tomlepaine/fast-wavenet），你可以参考更多的详细内容。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/e83339a9b21df8d912b56abc7b95e7c53f775b17"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Wavenet 图（左边）看起来像一个二叉树（binary tree）。一个节点与它之前的第 n 个的邻居计算卷积（convolve），其中 n 是 2 的幂。由于 n（膨胀系数/ dilation）每经过 2 层就会增加，组合在一起的节点的范围（感受野/ receptive field）也呈指数增长。在每个生成步骤，来自感受野中的所有节点（图片中的 8）的信息必须被组合。原始的生成算法在每个生成步骤简单地重复着整个计算树。这很容易实现，但是很慢。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你可能已经注意到，当生成连续输出时，树的大部分被重复使用。例如，调用图片 t 中的当前步骤，并假设生成 t+2 的输出。在这种情况下，第一隐藏层中的四个橙色节点中的三个可以被重复使用！重新计算它们纯属浪费时间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这启发了我们算法的核心：缓存以前计算的隐藏状态（hidden state）。如右图所示，我们为每个层保留以前计算的隐藏状态的缓存。缓存的大小等于隐藏层的膨胀系数，因为模型必须在隐藏层回溯 n 步。缓存像一个队列：最早的隐藏状态从队列的前面弹出，这完全等同于正常的膨胀卷积（dilated convolution）。在计算隐藏状态之后，必须将其推入队列的后面，因此从现在开始正好有 n 个步骤。重复这个过程给出了一个加速生成算法，它避免了原始方法的大量计算。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加速跨度卷积（strided convolution）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;前一部分使用了带有膨胀系数的卷积。在这种情况下，节点 t 与节点 t-n 计算卷积，节点 t+1 与节点 t+1-n 计算卷积。这意味着一个层中的隐藏状态的数量等于输入的数量，使得能够直接利用缓存。然而，使用跨度卷积使问题更加困难，因为隐藏层中的状态数量与输入数量不同。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;跨度卷积是下采样层（downsampling layer）。这意味着隐藏状态少于输入。典型的卷积在局部邻域（local neighborhood）上进行卷积计算，然后移动 1 个位置并重复该过程计算。例如，节点 t-1 和 t 将计算卷积，然后节点 t 和 t+1 将计算卷积。跨度会影响卷积移动经过的位置的数量。在前面的例子中，跨度为 1。然而，当跨度大于 1 时，输入将被下采样。例如，当跨度为 2 时，因为卷积移动 2 个位置，节点 t-1 和 t 将计算卷积，然后节点 t+1 和 t+2 将计算卷积。这意味着该层的每对输入仅产生一个输出，因此隐藏状态的数量小于输入的数量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;类似地，还有上采样层（upsampling layer），它是跨度转置卷积（strided transposed convolutions）。跨度记为 s，即上采样层将为该层的每个输入产生 s 个输出。与传入该层的输入数量相比，这增加了隐藏状态的数量。PixelCNN++ 先使用 2 个下采样层，然后使用 2 个上采样层，每个上采样层的跨度为 2，这意味着生成的像素的数量与输入像素的数量相同（即 D/2/2*2*2 = D）。关于跨度和转置卷积的详细解释可以在这两个链接中找到：https://github.com/vdumoulin/conv_arithmetic 和 https://arxiv.org/abs/1603.07285&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由于隐藏状态的数量不同，因此无法在每个时间步骤（timestep）中更新缓存。因此，每个缓存都有一个附加属性 cache every，缓存每次只在 cache every 的步骤更新。每个下采样层通过增加跨度来增加该层的 cache every 属性。相反，每个上采样层通过减少跨度来减少该层的 cache every 属性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/fcb8cbeddc151330eb7023c7d406410eccdaeda8"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;上图显示了一个具有 2 个上采样层和 2 个下采样层的模型示例，每个采样层的跨度为 2。橙色节点在当前的时间步骤计算，蓝色节点是先前的缓存状态，灰色节点不参与当前的时间步骤。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在第 1 个时间步骤 t=0，第 1 个输入用于计算和缓存所有节点，这里有足够的信息生成节点，包括前 4 个输出。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在 t=1 时，节点没有足够的信息用来计算，但是 t=1 的输出已经在 t=0 时算出。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在 t=2 时，有 1 个新节点有足够的信息来计算，虽然 t=2 的输出也在 t=0 时算出。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;t=3 的情形类似于 t=1。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在 t=4 时，有足够的信息来计算多个隐藏状态并生成接下来的 4 个输出。这类似于 t=0 的情形。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;t=5 类似于 t=1，并且该循环过程适用于所有未来的时间步骤。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在我们的代码中，我们还使用一个属性 run every，等同于下一层的 cache every 属性。这在如果下一层忽略输入时避免了计算。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加速 PixelCNN++&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在理解了前面的部分之后，我们将 1 维的例子直接推广到 2 维。事实上，我们的推广算法只有很少的变化。现在，每个层的缓存是 2 维的，缓存的高度（height）等于过滤器（filter）的高度，缓存的宽度（width）等于图像宽度。在生成整个行之后，将弹出缓存中最早的一行，并推送入新的一行。因为使用了大量的卷积，我们使用上一部分中详述的 cache every 的想法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;PixelCNN 有两个计算流：垂直流（vertical stream）和水平流（horizontal stream）。将细节稍微简化一下，垂直流查看当前像素上方的所有像素，而水平流查看当前像素的左边相邻的所有像素，它满足 2 维情况下的自回归属性（参见 PixelCNN 论文以获得更精确的解释）。水平流也能把垂直流作为输入。在我们的代码中，我们一次计算一行的垂直流，缓存并使用它来一次计算一个像素的水平流（和生成的输出）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有了这一点，我们能够实现 PixelCNN++ 生成的数量级加速！下图中增加的批处理大小（batch size）表明我们方法的可扩展性。虽然初始方法的实现结果随批处理大小呈线性扩展（由于 100％的 GPU 利用率），因为最小计算要求，我们的方法具有优越的扩展（scaling/时间复杂度）性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/1011499c76de618ae220daad5bcae5d620b5e146"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;PixelCNN++ 延伸&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里详述的核心概念很容易推广不同的模型。例如，直接运用于加速视频像素网络（https://arxiv.org/abs/1610.00527），并且由于更高的计算需求，可能会产生更好的加速效果。我们期待你对卷积自回归模型的快速生成的实际运用！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;作者&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Prajit Ramachandran (https://github.com/PrajitR)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Tom Le Paine (https://github.com/tomlepaine)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Pooya Khorrami (https://github.com/pkhorrami4)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Mohammad Babaeizadeh (https://github.com/mbz)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你觉得这个项目有用，请引用我们已提交 ICLR 2017 的论文《FAST GENERATION FOR CONVOLUTIONAL AUTOREGRESSIVE MODELS》：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;code style="box-sizing: border-box; font-family: SFMono-Regular, Consolas, 'Liberation Mono', Menlo, Courier, monospace; font-size: 13.6px; border-radius: 3px; word-break: normal; border: 0px; display: inline; overflow: visible; line-height: inherit; word-wrap: normal; background: transparent;"&gt;@article{ramachandran2017fastgeneration,
 &amp;nbsp;title={Fast Generation for Convolutional Autoregressive Models},
 &amp;nbsp;author={Ramachandran, Prajit and Paine, Tom Le and Khorrami, Pooya and Babaeizadeh, Mohammad and Chang, Shiyu and Zhang, Yang and Hasegawa-Johnson, Mark and Campbell, Roy and Huang, Thomas} 
 &amp;nbsp;year={2017}
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&amp;copy;本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Mon, 27 Feb 2017 12:07:15 +0800</pubDate>
    </item>
    <item>
      <title>学界 | 机器学习算法定制个性化营养</title>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650723704&amp;idx=5&amp;sn=faeac7ff8a03f8d467abec62b4af0a62&amp;chksm=871b1106b06c981090503766cdccb13a49b41c051fff567bd285e4f1ae30745866d6a8edad0c&amp;scene=0#rd</link>
      <description>
&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Genome Hunter&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;参与：高静宜、王灏&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/7299991ec9c303963c43c73d38ae2eb76c11749c"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在本论文中，作者们开发了一种机器学习算法，整合血液指标、饮食活动和肠道的微生物组数据来准确地预测个人饭后的血糖水平（临床医学称之为餐后血糖反应，PPGR）。这一研究表明，个人微生物组的组成和功能是如何有助于个性化营养学和疾病预防的。这一项目由 Eran Segal 和 Eran Elinav 教授领导，论文于 2015 年发布在 Cell 上。读者朋友也可以点击阅读原文下载此论文。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;肠道微生物组日益突显的作用&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们肠道中的细菌，也就是我们所知的肠道微生物组，对我们的健康与疾病风险起着很大的作用（图 1）。在肥胖与糖尿病的发展过程中，如今肠道微生物组被认为是个体之间存在差异的重要原因。个人微生物组一般由一种细菌占主要地位，且与年龄、性别、地理位置无关，并且受到长期的饮食习惯的影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/797980a9395882467e9e3bfc66a8902124386484"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 1. 营养的变化极大地影响近期的代谢&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由于近年来测序技术的发展，如今测量微生物组中的几乎每一种微生物基因也成为了可能。具有较低的微生物基因数（即更低的多样性）的人群易于患更严重的肥胖症，而且也要比有较高的微生物基因数（即更高的多样性）人群有更多的炎症。因此，微生物组既是生物标志物，也是在个性化营养中对饮食干预的作用靶标。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;个性化营养大数据&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前，预测一个人的 PPGR 值的常见方法是观察饮食中的碳水化合物的含量。或者，人们可以参考血糖指数（GI），这是一种根据食物中碳水化合物影响血糖水平的程度的相对排名。然而，作者认为 GI 数据只是基于单一的一种食物，并不能反映现实生活中的膳食。人们的基因、生活方式、肠道微生物以及膳食都会影响 PPGR。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这项研究中，作者结合了（i）可穿戴式连续性血糖检测仪对 PPGR 进行的纵向监测，（ii）肠道微生物组数据，（iii）包含 800 名非糖尿病志愿者身体信息的大型群组研究（图 2)。志愿者自己上报了超过大约 47000 顿饭中大约 1000 万卡路里的消耗，并且使用人体工程且微创的连续血糖监测仪自动捕捉了 150 万个血糖测量数据值。研究人员还整合各种数据类型，包括健康志愿者和糖尿病前期志愿者群组的各项信息如饮食摄入、人体测量数据、体育运动、睡眠觉醒周期、高分辨率的长期血糖监测和粪便微生物宏基因组。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img05.iwgc.cn/mpimg/b7be647ac774a2598f7673dfe73b119a484e5cee"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 2. 临床和微生物数据收集&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;利用机器学习算法创建适合你的饮食&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;作者首先证实了志愿者之间的巨大差异。同样的食物会给某些人带来巨大的血糖峰值，但是对于其他人只会造成微小的浮动。志愿者对于会引发尖锐峰值的食物也有所不同。例如，445 号参与者对香蕉反应强烈，而 644 号参与者则会对餐后饼干产生强烈的反应。（图 3）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/d503a82f42c76997989a79a84939e01abc65846c"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;图 3. 不同的人在用同样的餐后食用不同的餐后食物&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;之后，作者分析了每个人的人体测量数据、活动参数和肠道微生物组数据以预测针对各种食物的 PPGR 响应的预测。结果表明，每个人的 PPGR 可以通过计算方法来实现预测，而且个性化的饮食可能更成功有效地控制 PPGR。简单地说，作者采用了一个两阶段算法（图 4）。在第一阶段，他们开发了一种基于梯度提升回归方法的机器学习算法，其中派生了数以千计的决策树来优化整体模型的预测能力。梯度提升回归模型适用于 PPGR 与各种预测因子之间的非线性关系。研究人员利用留一交叉验证法（leave-one-out cross-validation）在 800 名个体群组中对他们的模型进行训练。在第二阶段，他们招募了 100 个志愿者的独立群组，并使用在 800 名志愿者的主要群组上训练好的模型来预测他们的 PPGR。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img03.iwgc.cn/mpimg/0143f846d71ca618491a24b08fe908f16b50c06c"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 4. 预测的方法&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;未来的方向&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这项工作是一项重要的概念验证研究，它在饮食反应预测中整合了微生物组的贡献。整合从大规模志愿者中得到的多维纵向数据可以使得机器学习算法的表现优于基于专家经验的 PPGR 预测。Eran Segal 教授打算进一步提升算法的效果。他们计划通过采集志愿者的体育运动、肠道细菌菌株甚至遗传学方面更详细的信息，来提升模型的准确率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最近，Eran Segal 和 Eran Elinav 两位教授成立了一家名为 DayTwo 的创业公司（https://www.daytwo.com），旨在提供个性化营养服务，从而让人们的生活更健康并维持正常的血糖水平。用户可以通过一个 APP 来调整膳食以防止 2 型糖尿病。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="http://img04.iwgc.cn/mpimg/2830464b85e7783802025ad05139d8b9fa10d58d"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 5. 一个帮助你区分食谱好坏的 APP&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Reference&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;Zeevi D et al. Personalized Nutrition by Prediction of Glycemic Responses. Cell, 2015.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;(link: https://www.ncbi.nlm.nih.gov/pubmed/26590418).&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&amp;copy;本文为机器之心原创，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@jiqizhixin.com&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
      <pubDate>Mon, 27 Feb 2017 12:07:15 +0800</pubDate>
    </item>
  </channel>
</rss>
