<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>机器之心</title>
    <link>http://www.iwgc.cn/list/670</link>
    <description>人与科技的美好关系</description>
    <item>
      <title>2016，那些被机器之心记录的人物和公司</title>
      <link>http://www.iwgc.cn/link/4494857</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心原创&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：老红&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2016 年，机器之心连续更新 365 天，共发布 1484 篇文章，总字数超过 612 万，约等于 15 本由 Ian Goodfellow、Youshua Bengio 和 Aaron Courville 合著的 &lt;em&gt;Deep Learning&lt;/em&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这些文章中，我们既报道了 Maluuba、ROSS Intelligence 和第四范式等明星创业公司和谷歌、微软这样的领先巨头，也对话了邓力、吴恩达、Richard Sutton、杨强、田渊栋和樊麾等炙手可热的行业变革者与参与者。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你可能对其中的某些文章印象深刻，也可能因故错过了一些值得被铭记的语录。感激于大家一年来持续的认可以及在后台对某些文章「关键字」的长期回复。我们特地精选了如下文章作为机器之心的年度贺礼。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;重要的不是文字，而是那些值得被我们记住的人物和公司。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;大佬眼中的人工智能&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2016 年，我们见证了诸多华人力量在人工智能领域的突出贡献，吴恩达固然是其中的优秀代表。在加入百度之后，吴恩达做了一件事：购了 1000 个 GPU，并在 24 小时内得到。而在谷歌，他可能几周或几个月才能得到。随即，曾帮助谷歌建立 Google Brain 的吴恩达也在百度建起了「大脑」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW888VbLHLu4h6xh9vLjzJqT3oQ3s8p51bWCjhml8eKuEc1cr45DicCmp2oBYBXibm4micpt9UTxVeZ7g/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721480&amp;amp;idx=1&amp;amp;sn=191cb46a8ebbb71519d5d668705aa81b&amp;amp;chksm=871b08b6b06c81a0265fc5de459f78cd5e1e887f3569f57a2e7ccb4ff7835d73c66699cc483a&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721480&amp;amp;idx=1&amp;amp;sn=191cb46a8ebbb71519d5d668705aa81b&amp;amp;chksm=871b08b6b06c81a0265fc5de459f78cd5e1e887f3569f57a2e7ccb4ff7835d73c66699cc483a&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;在接受机器之心采访时，吴恩达表示，在人工智能领域，很多技术其实是中国最先开始应用的。&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而在大洋的另一端，&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721789&amp;amp;idx=1&amp;amp;sn=bff9199914fa8127769d484a70e7bd20&amp;amp;chksm=871b0983b06c80959425726a5c80d9186329ab21bbce01f3a5ba4a03f6e789f9e2fbab46d8aa&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721789&amp;amp;idx=1&amp;amp;sn=bff9199914fa8127769d484a70e7bd20&amp;amp;chksm=871b0983b06c80959425726a5c80d9186329ab21bbce01f3a5ba4a03f6e789f9e2fbab46d8aa&amp;amp;scene=21#wechat_redirect"&gt;强化学习教父 Richard Sutton 在接受机器之心采访时&lt;/a&gt;也从一个不同的视角解读了他眼中的强化学习。他指出有些人认为强化学习只是人工智能问题的强化，但实际上强化学习问题是实现人工智能的一种抽象的方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不过，&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717709&amp;amp;idx=3&amp;amp;sn=da182ae323f2657135fad4d06791a4b6&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717709&amp;amp;idx=3&amp;amp;sn=da182ae323f2657135fad4d06791a4b6&amp;amp;scene=21#wechat_redirect"&gt;图灵奖得主 Joseph Sifakis&lt;/a&gt;，却对机器之心表示，人工智能在设计复杂性上还功力不足。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「人工智能可以学习知识，但是不会推理。推理和学习不一样。推理是用来解决问题的。现在的这些计算机做的还不好，我们需要其他种类的计算机需要一种新型的生物计算机和神经计算机。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720765&amp;amp;idx=2&amp;amp;sn=a7871565ed23d8389d0ea3cef47804ae&amp;amp;chksm=871b0d83b06c84950047799a1448ed082746a69bacb8386032603ff1a682f1c878e866cf1225&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720765&amp;amp;idx=2&amp;amp;sn=a7871565ed23d8389d0ea3cef47804ae&amp;amp;chksm=871b0d83b06c84950047799a1448ed082746a69bacb8386032603ff1a682f1c878e866cf1225&amp;amp;scene=21#wechat_redirect"&gt;美国通用人工智能协会主席 Ben Goertzel &lt;/a&gt;确认为，绕过大脑我们也能造出通用人工智能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;采访过程中，对于提出的问题，Ben 总是会给出远远超过问题本身答案，他很擅长把答案按照问题本身的逻辑延伸下去。有些让你恍然大悟，有些则会给你意外惊喜。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而除了这些行业变革的参与者，作为行业记录者的 &lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=401989481&amp;amp;idx=1&amp;amp;sn=8fbfd234f509e83ddbacffa7571cd7de&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=401989481&amp;amp;idx=1&amp;amp;sn=8fbfd234f509e83ddbacffa7571cd7de&amp;amp;scene=21#wechat_redirect"&gt;John Markoff 也为我们分享了他眼中的人工智能&lt;/a&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深得乔布斯信任的科技记者 John Markoff 职业生涯最遗憾的事情是什么？他在重磅新书《与机器人共舞》中表达了什么观点？机器人会让我们失业吗？除了人工智能，他最看好哪一个新兴科技领域？他对中国的科技进步又有怎样的观察？这些问题都能从机器之心对 John Markoff 的采访中得到解答。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;「跨界」的传奇经历&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2016 年初的「人机大战」，除了人工智能首次在人类最复杂的博弈游戏中战胜最高级别的人类选手的历史意义，也在更大范围上引发了业界对「人工智能」这个并不太新的概念的持续探讨与研究。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而拉开这一帷幕的是去年欧洲围棋冠军樊麾与 AlphaGo 的对战。在机器之心与樊麾老师的长谈中，&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=402655050&amp;amp;idx=1&amp;amp;sn=ce347e61a7012ece8866f775571e3ca9&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=402655050&amp;amp;idx=1&amp;amp;sn=ce347e61a7012ece8866f775571e3ca9&amp;amp;scene=21#wechat_redirect"&gt;他详细回顾了他与 AlphaGo 交战的精彩故事，畅谈了他对人工智能技术的感触，以及对围棋与人生的哲学思考。&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWicfJFax3rHUWXK8QUmf7aiaiasoOW01shreRdrTjjL7icpWgYb2WNbwbgxX8ZrKdfqxCbX20nufDibyCA/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;em&gt;樊麾&lt;/em&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;正如在采访中樊麾老师所言：「AlphaGo 可能会发现另外一种围棋的美，是我们想象不到的。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;已经加入 DeepMind 参与 AlphaGo 进一步研究的樊麾老师继续在跨界的领域贡献着自己的力量。而另一位长期从事人工智能研究并主导研发 Facebook 人工智能围棋项目（Dark Forest）的&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719794&amp;amp;idx=1&amp;amp;sn=89579fe1b5733a7b192d05646b80e8f9&amp;amp;chksm=871b024cb06c8b5ab2ea4065ba623cb114fea8281c4de560d9a50d35463b71db43f4552fd511&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719794&amp;amp;idx=1&amp;amp;sn=89579fe1b5733a7b192d05646b80e8f9&amp;amp;chksm=871b024cb06c8b5ab2ea4065ba623cb114fea8281c4de560d9a50d35463b71db43f4552fd511&amp;amp;scene=21#wechat_redirect"&gt;田渊栋博士则为我们分享了他的另一段独特「跨界」经历&lt;/a&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;卡耐基梅隆大学机器人系博士、前谷歌无人驾驶汽车项目组研究员、现 Facebook 人工智能组研究员，多重身份的加持和前沿、专业的研究为田渊栋吸引了相当多的目光。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除了前沿研究与技术创新，他还保持了长期的写作习惯。除了早期的个人博客和现今的知乎专栏，田渊栋甚至还完成过一部超过 30 万字的小说，这在以理工科为代表的前沿科技领域是极为罕见的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721022&amp;amp;idx=1&amp;amp;sn=cf228951da36bc490375d87e369b8d4f&amp;amp;chksm=871b0e80b06c87967e5c7f5d87a60192684705399cd7c5de8b4278f7a0326de1a14ca70682c7&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721022&amp;amp;idx=1&amp;amp;sn=cf228951da36bc490375d87e369b8d4f&amp;amp;chksm=871b0e80b06c87967e5c7f5d87a60192684705399cd7c5de8b4278f7a0326de1a14ca70682c7&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;不过相比于上面两位，Nick Pentreath 的跨界经历则要更为传奇。&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现任 IBM Spark 技术中心的首席工程师的 Nick Pentreath 专注于 Apache Spark 机器学习领域，著有一本《Spark 机器学习》。在进入 IBM 以前，他曾参与共同创立了 Graphflow，一家提供推荐系统和智能解决方案的初创公司。在进入计算机科学领域以前，他曾在高盛投行工作并亲历了利比亚卡扎菲政府 12 亿美元投资巨案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在机器之心对 Nick 的专访中，我们一起聊了聊 Spark 的新版本、IBM 的开源精神、不同平台的竞争关系，以及他在高盛的传奇经历，其中不乏爆料和精彩的观点分享。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;那些值得关注的国外初创公司&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Clarifai 是一家独立的图像识别初创公司，总部位于纽约。在 10 月 25 日，它刚刚收获了价值 3000 万美元的 B 轮融资。作为图像识别领域为数不多的独立玩家，Clarifai 已经在成立三年多的时间里率先将图形识别从静态图片带入了接近实时的级别，同时也收获了为数不少的企业客户。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这家公司的创始人和首席执行官 Matthew Zeiler 毕业于纽约大学，师从 Rob Fergus，也接受过 Yann LeCun 的指导。对于这家初创公司的领导者来说，他们面临着科技巨头的不对称竞争，但 &lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720472&amp;amp;idx=2&amp;amp;sn=26bd094744b16749e3665bdf4b34d543&amp;amp;chksm=871b0ca6b06c85b08605b3437ada45e8774b4da9c8617b55bd6209fe795e7181e1ee5e136669&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720472&amp;amp;idx=2&amp;amp;sn=26bd094744b16749e3665bdf4b34d543&amp;amp;chksm=871b0ca6b06c85b08605b3437ada45e8774b4da9c8617b55bd6209fe795e7181e1ee5e136669&amp;amp;scene=21#wechat_redirect"&gt;Zeiler 认为 Clarifai 也有着自己的优势，他们正在探索从图像识别到无限可能的实践。&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW888VbLHLu4h6xh9vLjzJqTM6SrotmcQ7s3vOk3sYSCKyNrzXw6CDMnqZof2h1v8LYNwicNMtJEfRA/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而今年 1 月已被微软收购的 NLP 明星公司 Maluuba 早已在机器理解方面的成绩超越谷歌等巨头。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW888VbLHLu4h6xh9vLjzJqT9gicN10vXAASV6tDLzcfvJ9NE0fqnX4AZ5qYZAL3838eDLmTic17Wytg/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Maluuba 关注机器学习中的两个细分研究领域：对话和机器理解。同时，像 Maluuba 也更关心研发解决通用问题的人工智能，对解决真实世界问题更感兴趣。他们相信自己能找出更好的人机交互方式，并与蒙特利尔大学教授、人工智能专家 Yoshua Bengio 和阿尔伯塔大学教授、强化学习专家 Richard Sutton 等展开合作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717691&amp;amp;idx=1&amp;amp;sn=5b29644a7a0a3225f8997bdc0ac1a792&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717691&amp;amp;idx=1&amp;amp;sn=5b29644a7a0a3225f8997bdc0ac1a792&amp;amp;scene=21#wechat_redirect"&gt;&lt;span&gt;在接受机器之心的采访时，该团队也为我们分享了 Maluuba 迅速成为最受关注的 NLP 公司的原因 。&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外一家明星公司则是位于硅谷的 ROSS Intelligence，全球第一家致力于法律服务的人工智能创业公司。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2015 年夏天，ROSS 得到全球最大律师事务所 Dentons 旗下的 NextLaw Labs 的投资，并正式成为了 Dentons 的业务伙伴。之后的一年内，ROSS 不仅成功上线，并且在 Dentons 之外逐渐获得了更多的客户，包括大型律所 Baker and Hostetler 等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2016 年，机器之心对 ROSS Intelligence 的 CTO、联合创始人 Jimoh Ovbiagele 进行了专访，&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720780&amp;amp;idx=2&amp;amp;sn=cc64372d82354d3212baf84fce230928&amp;amp;chksm=871b0e72b06c8764cfe09654fa457da0fd764c0684d83b7fcd887c19401b3b4d623a07ab2bb9&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720780&amp;amp;idx=2&amp;amp;sn=cc64372d82354d3212baf84fce230928&amp;amp;chksm=871b0e72b06c8764cfe09654fa457da0fd764c0684d83b7fcd887c19401b3b4d623a07ab2bb9&amp;amp;scene=21#wechat_redirect"&gt;他向国内的读者介绍了 ROSS 的创业历程、ROSS 所采用的技术以及未来 ROSS Intelligence 的发展方向 。&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;不容忽视的国内力量&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;作为微信创始团队成员之一的李明强在 2014 年创办了「图普科技」，这家公司为企业用户提供一个「图像识别云服务」，企业可以选择或者定制自己需要的各种图像识别服务，完成内容审核、场景识别等功能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图普科技创始人李明强是原腾讯资深项目经理和 T4 的技术专家，跟随张小龙一起参与了 QQ 邮箱和微信等产品的研发，拥有 7 年的互联网产品项目管理、团队管理、产品设计以及运营推广经验。在接受机器之心采访时，&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717202&amp;amp;idx=2&amp;amp;sn=31b6924db5eb4500fa4a57d9669878fc&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717202&amp;amp;idx=2&amp;amp;sn=31b6924db5eb4500fa4a57d9669878fc&amp;amp;scene=21#wechat_redirect"&gt;李明强详细介绍了用产品思维打造图像识别场景化应用的方法论 &lt;/a&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而作为国内语音企业的代表，云知声专注物联网人工智能服务，通过 AI 芯、AIUI、AI Service 三大解决方案支撑核心技术的落地和实现，目前已经在家居、汽车、医疗和教育等领域有广泛应用，形成了完整的「云端芯」生态闭环。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715927&amp;amp;idx=1&amp;amp;sn=818a7ef31a186c81f7a6dabfe00326c2&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650715927&amp;amp;idx=1&amp;amp;sn=818a7ef31a186c81f7a6dabfe00326c2&amp;amp;scene=21#wechat_redirect"&gt;在机器之心对云知声 CEO 黄伟的专访中，他介绍了云知声的技术研究、「云端芯」产品战略、在车载和医疗行业的应用，以及对人工智能看法。&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;同样，人工智能在金融领域的应用是一个很大的问题，一直以来也受到业界的广泛关注。璇玑公司就有一套这样的智能理财系统，既使用了传统的数据统计方法，也使用了支持向量机这样的机器学习模型。&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717365&amp;amp;idx=2&amp;amp;sn=41a53a35a2b1c915f16fb0139f585997&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650717365&amp;amp;idx=2&amp;amp;sn=41a53a35a2b1c915f16fb0139f585997&amp;amp;scene=21#wechat_redirect"&gt;机器之心在 2016 年也对璇玑公司的 CEO 郑毓栋进行了专访，探讨人工智能在金融领域的应用 。&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;作为国内人工智能企业的优秀代表，搜狗的产品和战略也一直吸引着业界关注的目光。2016 年 4 月，搜狗宣布与清华大学联合成立「清华大学天工智能计算研究院」，把人工智能作为重要战略发展方向，但一直没有透露太多关于具体人工智能研发和应用层面的信息。为此，机器之心对搜狗语音交互技术中心负责人王砚峰进行了专访，&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716160&amp;amp;idx=1&amp;amp;sn=871d9d398de5cf665265e5eeab3dc040&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650716160&amp;amp;idx=1&amp;amp;sn=871d9d398de5cf665265e5eeab3dc040&amp;amp;scene=21#wechat_redirect"&gt;王砚峰介绍了搜狗的人工智能研究历史，以及在人工智能方面的产品创新思路&lt;/a&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW888VbLHLu4h6xh9vLjzJqTWUGBKyzlYWmcib9HP4O3Bsb5Jxias5KjrOvLEwM1G3hYj2QXy5nayeFg/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;搜狗语音负责人王砚峰&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一家专注于机器学习的「独角兽」公司今日头条也不容忽视。在论文被 ACL 2016 收录后，机器之心也独家专访了头条实验室科学家李磊，在此篇专访中，&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718173&amp;amp;idx=2&amp;amp;sn=7afb370ac67b7879f165bda12e4357d9&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650718173&amp;amp;idx=2&amp;amp;sn=7afb370ac67b7879f165bda12e4357d9&amp;amp;scene=21#wechat_redirect"&gt;他向我们介绍了被收录的论文，还有他对概率程序语言、自然语言处理方面的理解。&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而作为世界顶级人工智能专家，在人工智能研究领域深耕三十年的杨强教授和他的第四范式也是 2016 值得被关注和记录的代表。在机器之心对杨强教授的专访中，&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719099&amp;amp;idx=1&amp;amp;sn=4ae231dc316baa288ad9884f1f3dd223&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719099&amp;amp;idx=1&amp;amp;sn=4ae231dc316baa288ad9884f1f3dd223&amp;amp;scene=21#wechat_redirect"&gt;他对迁移学习、人工智能行业与技术进行了深入讲解，并对人工智能从业者提供了众多有价值的建议，并指出「未来人工智能会让二流科学家失业」。&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;进击的谷歌与开放的未来&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;毫无疑问，2016 年谷歌在人工智能领域的各项突破和进展处于绝对领先的位置。9 月 27 日，在谷歌于 arXiv.org 上发表论文《Google`s Neural Machine Translation System: Bridging the Gap between Human and Machine Translation》介绍谷歌的神经网络翻译系统（GNMT）后，&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719511&amp;amp;idx=1&amp;amp;sn=88bbb6bb3d28b3f0f62c5c5929968444&amp;amp;chksm=871b0169b06c887f302dc791c67f19ce4ba49c43744e11341b7bb225d9e22443ebf9e3b70339&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719511&amp;amp;idx=1&amp;amp;sn=88bbb6bb3d28b3f0f62c5c5929968444&amp;amp;chksm=871b0169b06c887f302dc791c67f19ce4ba49c43744e11341b7bb225d9e22443ebf9e3b70339&amp;amp;scene=21#wechat_redirect"&gt;「机器之心」也受邀来到谷歌中国和来自 Google Brain 的软件工程师陈智峰聊了聊人机翻译、GNMT 和谷歌的技术创新等问题 。&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除了占尽各大媒体版面的各类事件和突破，谷歌最受人关注的话题之一也在于大公司垄断的尖锐话题。&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719786&amp;amp;idx=1&amp;amp;sn=b69b772a0118290637b2eaf3c2a0f209&amp;amp;chksm=871b0254b06c8b424c2480b96114b4738dd3539c482469f446d8f470a29ec1405f9bb75a6aaf&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719786&amp;amp;idx=1&amp;amp;sn=b69b772a0118290637b2eaf3c2a0f209&amp;amp;chksm=871b0254b06c8b424c2480b96114b4738dd3539c482469f446d8f470a29ec1405f9bb75a6aaf&amp;amp;scene=21#wechat_redirect"&gt;2016 年 10 月，在中国进行短暂停留的谷歌高级研究科学家 Greg S Corrado 也和机器之心进行了系列交流。&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWicfJFax3rHUWXK8QUmf7aiaia6tVI2ZA2fWbuT8kDkgIdiaI3nXKhC4vxD6a2V5HGHpvWDMd8a57d9Tg/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Greg S Corrado&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除了机器学习、量子计算和 TensorFlow，Greg 在大公司垄断的问题上也回应道，「一家从事某些小研究专注小范围的产品的公司逐渐壮大起来是一件很寻常的事情，就像当年 IBM 并没有想方设法阻止微软的成长，微软也没有阻止谷歌的成长，谷歌也没有阻止 Facebook 做大做强，这种情况会永远持续地发生下去。从好地方面看，目前我们的行业总是能以某种方式保持更迭并不断前行。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;正如他在评价 TensorFlow 开源时所提到的，未来这个领域相关的产品，谷歌打算把自己开发的平台也通过云服务共享给公众使用，通过这种云机器学习，其他开发者可以开发和实现自己的机器学习构想，就像在谷歌中研发一样。开发者可以通过 TensorFlow 使用谷歌提供的免费软件和工具，也可以用云服务运行他们自己构建的机器学习系统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;精耕细作的微软和它的秘密武器&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由于人类自然的语言语音交互方式，以及天生的情感和社交需求，我们对于能与我们进行语音交互和聊天的智能应用格外关注。近几年人工智能的迅速发展也带来了更多更加智能的智能语音助理，包括 Google Now、Facebook M、亚马逊 Echo、微软 Cortana 和小冰等，其中的大部分产品重点关注功能，比如、语音控制和信息查询等，而微软小冰却是走了另外一条路——从与用户的情感交流出发，在底层的深度学习技术越发通用的前提下，不同的产品理念就体现了各方对人工智能现状及未来的不同理解。就此，&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=401882267&amp;amp;idx=1&amp;amp;sn=eb5a4cf6e10b6dc3787303f421a8f77b&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=401882267&amp;amp;idx=1&amp;amp;sn=eb5a4cf6e10b6dc3787303f421a8f77b&amp;amp;scene=21#wechat_redirect"&gt;机器之心对微软（亚洲）互联网工程院院长王永东博士、小冰项目资深产品总监彭爽等人进行了深度专访。&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650714822&amp;amp;idx=1&amp;amp;sn=e56ee226cdacab228e1ad9fc40646adf&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650714822&amp;amp;idx=1&amp;amp;sn=e56ee226cdacab228e1ad9fc40646adf&amp;amp;scene=21#wechat_redirect"&gt;在微软研究院人工智能首席科学家邓力眼里，人工智能的成功在于将多种理论方法整合成一个完整系统。&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWicfJFax3rHUWXK8QUmf7aiaia7AlG2lvUIqLFOwOicu6LYtxKJu3ryscZEH83fV7vwr8d8kv0JPkJrJA/0?wx_fmt=jpeg"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;微软研究院人工智能首席科学家邓力&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在机器之心对邓力的专访中，他介绍了自己和微软研究院在做的关于人工智能的数项研究，回顾了自己在人工智能和语音识别领域的研究历程，并深入分析了人工智能领域的研究现状和未来发展，针对无监督学习等人工智能难题提出了自己的研究思路和解决方法。相信邓力的精彩分享将会给人工智能从业者带来巨大收获，其对人工智能的深入思考和研究理念也会给大家带来宝贵的灵感和启发。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2016 年 9 月中旬，微软报告了在语音识别方面取得的新里程碑：新系统的识别词错率降至 6.3%；一个月后，微软又公布了在这一领域成功实现了历史性突破：他们的语音识别系统实现了和专业转录员相当甚至更低的词错率（WER），达到了 5.9%&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;带领团队取得这一成果的正是微软首席语音科学家黄学东。在对黄学东博士的专访中，&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719843&amp;amp;idx=2&amp;amp;sn=4611f810734df8a72286567e90c65a92&amp;amp;chksm=871b021db06c8b0b283ac93f267d95365392be02b3cde5d2fe6df85b359aa96368f25318e2f5&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719843&amp;amp;idx=2&amp;amp;sn=4611f810734df8a72286567e90c65a92&amp;amp;chksm=871b021db06c8b0b283ac93f267d95365392be02b3cde5d2fe6df85b359aa96368f25318e2f5&amp;amp;scene=21#wechat_redirect"&gt;我们共同探讨了词错率降低背后的秘密、这一成就的意义，以及他对语音识别的思考&lt;/a&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此后，机器之心也有幸专访了顶级语音专家、MSR 首席研究员俞栋。在专访中，&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720189&amp;amp;idx=1&amp;amp;sn=10a3630e7f65d7b845c1fd032970d46e&amp;amp;chksm=871b03c3b06c8ad527a7dffd215be5b128a7aaf88ec09a131d68a249e9ff77c3edff6204d3d2&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720189&amp;amp;idx=1&amp;amp;sn=10a3630e7f65d7b845c1fd032970d46e&amp;amp;chksm=871b03c3b06c8ad527a7dffd215be5b128a7aaf88ec09a131d68a249e9ff77c3edff6204d3d2&amp;amp;scene=21#wechat_redirect"&gt;俞栋老师除了谈论深度学习与语音识别相辅相成的发展以及相关领域的现状和未来，还为我们详细介绍了语音识别的四大前沿研究。&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然，除了突破和进展，我们还面临着诸多的难题。如何在增加 CPU 或 GPU 数量的同时，保证训练的线性加速以及性能？这是并行训练中存在的一个矛盾问题。&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650714905&amp;amp;idx=2&amp;amp;sn=ad19a7e003ecdb48b0ffc524e8c2c94b&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650714905&amp;amp;idx=2&amp;amp;sn=ad19a7e003ecdb48b0ffc524e8c2c94b&amp;amp;scene=21#wechat_redirect"&gt;微软亚洲研究院首席研究员霍强博士的研究团队就较好地解决了这个经典的两难问题，&lt;/a&gt;让大规模并行训练在增加 GPU 的条件下几乎实现了线性加速并保证了模型性能，这一突破对大数据机器学习的效率提升意义重大。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心原创，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 26 Jan 2017 12:55:07 +0800</pubDate>
    </item>
    <item>
      <title>学界 | 斯坦福Nature论文宣布新突破：深度学习皮肤癌诊断达专家水平</title>
      <link>http://www.iwgc.cn/link/4494858</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自斯坦福&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;为了让人们能获得更好的医疗，斯坦福大学的研究者已经成功训练了一个可以诊断皮肤癌的算法。该研究的相关论文《Dermatologist-level classification of skin cancer with deep neural networks》已经发表在 Nature 上。本文编译自斯坦福大学的官方介绍新闻，读者可在文末查看论文摘要和点击「阅读原文」查阅原论文。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;预约一个医生帮你检查一颗痣是否会癌变已经非常可怕了，但想像一下，如果你住的地方又离最近的医生非常远，没有时间做检查或者没有钱跑那么远去做检查该怎么办？在这种情况下，通过手机诊断疾病会是一种救急的选择。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通常，皮肤科医生使用皮肤镜（dermatoscope）来观察皮肤，这是一种手持显微镜。斯坦福的计算机科学家创造了一个可以进行皮肤癌诊断的人工智能诊断算法，表现可媲美通过职业认证的皮肤科医生。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在计划创造皮肤癌人工智能诊断算法的时候，斯坦福的计算机科学家想的是能让治疗普遍可及。他们做了一个包含近 13 万张皮肤疾病图像的数据集，然后训练算法能在视觉上诊断潜在的癌症。在首次测试中，它就展现出了惊人的准确率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们意识到这是可行的，而且可以做得很好，」斯坦福人工智能实验室副教授 Sebastian Thrun 说。「那时我们的思想改变了。那时我们会说，‘看，这不仅仅是一个学生的课堂项目，而是为人类做伟大事情的一个机会’。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW888VbLHLu4h6xh9vLjzJqTSciazJweFDcNMQKXBdKH7AmDWIWczM9GLawIRmY4h7BAggZEOicuNp1Q/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该项目最终的成果论文发表在 1 月 25 日的 Nature 杂志上，该结果已经过了 21 位认证皮肤科医生的对比测试。在该论文中的最常见的和最致命的皮肤癌的诊断上，该算法的表现已能媲美皮肤科医生。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;为什么选择皮肤癌？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;美国每年都有 540 万人患皮肤癌，在早期检测到的黑色素瘤的 5 年生存率在 97% 左右，如果晚期查出 5 年生存率将会下降 14%，皮肤癌的早期发现可能会对其结果产生巨大的影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;皮肤癌的诊断始于视觉检查。医生通常用肉眼观看皮肤镜来检查可疑的病变。皮肤镜是一种手持式显微镜，可低倍率放大皮肤表面。如果这些方法都是不确定的，或者无法让皮肤科医生确定病变是癌变，那么下一步就要用到活检。将该算法纳入检测过程迎合了当下将视觉处理与深度学习相结合的计算趋势——深度学习是一种对大脑神经网络建模的人工智能。深度学习在计算机科学中已有几十年的历史，但最近才被应用到视觉处理任务上，并取得了巨大的成功。包括深度学习在内的机器学习的本质就是训练计算机来解决问题，而不是把答案编进程序。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们做了一个非常强大的机器学习算法，它能从数据中学习，」该研究相关论文的合作者、Thrun 实验室的研究生 Andre Esteva 说，「你让算法找出答案，而不是把要找的东西写入计算机代码。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW888VbLHLu4h6xh9vLjzJqTG766JNJKEpuib7BF5m3joWpR8CwD9jTBeNwLY1bdfSTg4PQMYQMJia8g/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;该研究相关论文的合作者、Thrun 实验室的研究生 Andre Esteva&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该算法处理的是带有一个相关疾病标签的图像的原始像素。与其他训练算法的方法相比，该方法需要的处理非常少，也不需要在分类之前对图像进行分组，这允许算法处理种类更广泛的数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;从猫狗识别到黑素瘤和癌症的诊断&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;研究人员并没有从头开始构建算法，而是从谷歌已经训练识别了 128 万张 1 千种类目标的算法基础上进行开发的。虽然谷歌这套系统是为识别猫和狗设计的，不过研究员需要它能学会区分良性脂溢性角化病（benign seborrheic keratosis）和恶性肿瘤。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这篇论文的主要联合作者，Thrun 实验室的研究生 Brett Kuprel 说：「现在情况是没有巨大的皮肤癌数据集来训练我们的算法，所以我们只能自己做了，我们从互联网收集数据，并与医学院合作对混乱数据（标签就含有多种语言，如德语、阿拉伯语、拉丁语等）进行良好的分类。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW888VbLHLu4h6xh9vLjzJqTAKbaOoJxuOibkjyYVwsSpzodBEysx6VmSFCl6nPltBT2gX5KssAPViag/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Thrun 实验室的研究生 Brett Kuprel&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;经过必要翻译后，研究人员与斯坦福医学院皮肤科医生以及本论文的联合作者、斯坦福微生物学和免疫学教授 Helen M. Blau 合作处理影像资料。这个跨学科的团队一起对互联网上混乱的影像进行分类。其中很多影像资料并不像医疗专业人员拍摄的那样专业，而是从各个角度、焦距和照明下拍的。最后，他们累积了约 130,000 张皮肤病变的图像，这些图像展示了超过 2000 种不同的皮肤疾病。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在测试期间，研究者只使用了由爱丁堡大学和国际皮肤影像合作项目（International Skin Imaging Collaboration Project）提供的高质量和活组织检测证实（biopsy-confirmed）的影像，其代表着最常见最致命的皮肤癌：恶性肿瘤和恶性黑素瘤。这需要询问 21 个皮肤科医生他们通过每一张影像决定是进行活组织检测（biopsy）或治疗还是判断不是恶性疾病。因此研究人员评估了皮肤科医生在超过 370 张影像中能够正确诊断癌性和非癌性病变的准确程度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;算法的性能是通过构建敏感性（特异性曲线）进行衡量的，其中敏感性（sensitivity）代表着正确识别恶性病变的能力，特异性（specificity）代表着正确识别良性病变的能力。其是通过三个关键性诊断任务进行评估的：角化细胞癌的分类、黑素瘤的分类和通过皮肤镜检查的黑素瘤分类。在所有的三个任务中，该算法的表现媲美皮肤科医生，灵敏度曲线之下的区域达到整个曲线图区域的 91%。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该算法另外的优点是它的敏感性能进行调整，研究者可以根据他们想要评估的东西从而调整其响应度。这种改变敏感性的能力暗示着该算法的深度与复杂性。看似无关照片中潜藏的架构——包括猫和狗的图像，都有助于算法更好地评价皮肤病变影像。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;通过智能手机实现的医疗&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管该算法目前用于计算机，但团队希望未来它能够兼容于智能手机，让可靠的皮肤癌诊断触手可及。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我意识到用在智能手机是多么的独特，那是我灵光乍现的一刻」Esteva 说，「每个人口袋中都有一个超级计算机，上面有大量的传感器，包括摄像头。如果我们把它用来筛查皮肤癌会怎么样？或其他疾病呢？」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然该团队相信把算法过渡到移动设备会相对简单，但仍需要在现实世界的临床试验上进行进一步的测试。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;计算机辅助分类良性和恶性皮肤疾病的发展能够极大地帮助皮肤科医生改进对高难度疾病的诊断，并向病人提供更好的管理选择。」该论文的合作者、斯坦福癌症研究所 Pigmented Lesion &amp;amp; Melanoma 项目的负责人 Susan Swetter 教授说，「然而，在算法用于临床实践之前，还需要从业者与病人等进行严格的验证。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;即使面临着如此多的挑战，研究人员依然感觉很有希望：深度学习某天能够在多种医疗领域为视觉化诊断做出贡献。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该研究的其他合作者包括：皮肤病学、病理学临床助理教授 Robert Novoa，皮肤病学临床副教授 Justin Ko。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;论文：用深度神经网络实现皮肤科医生水平的皮肤癌分类（Dermatologist-level classification of skin cancer with deep neural networks）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW888VbLHLu4h6xh9vLjzJqTGIL98N8HgyC3ghwY75VqmqQEQOG5zZj3kcibwdcYUu2jMI2NhRkggpg/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：皮肤癌是人类最常见的恶性肿瘤，目前主要是通过视觉诊断的。一般首先是临床筛查，之后可能需要皮肤镜分析、活检和组织病理学检查。使用图像的皮肤病变自动分类是一个具有挑战性的任务，因为皮肤病变的外观是一种细粒度的变化。深度卷积神经网络（CNN）在多种细粒度对象分类的通用的及高度可变的任务中都显示出了潜力。在这里，我们展示了使用一个单一的深度卷积神经网络进行皮肤病变分类的过程，该网络仅使用像素和疾病标签作为输入，直接从图像中端到端地训练出来。我们使用 129450 个临床图像的数据集——大于以前的数据集两个数量级，包含了 2032 种不同的疾病——训练了一个深度卷积网络。我们使用两个关键的二进制分类用例：角质形成细胞癌（keratinocyte carcinomas）vs 良性脂溢性角化病（benign seborrheic keratoses）；恶性黑色素瘤 vs 普通的痣，在 21 位经过认证的皮肤科医生的监督下，测试了它在活检证实的临床图像上的性能。第一例代表最常见的癌症的识别，第二例代表了最致命的皮肤癌的识别。深度卷积神经网络在这两个任务上的表现都达到了所有测试的专家的水平，证明了该人工智能的皮肤癌鉴定水平达到了媲美皮肤科医生的水平。配备该深度神经网络的移动设备可以让皮肤科医生的诊断拓展到临床之外。据预测，到 2021 年，将有 63 亿智能手机订阅该功能，实现低成本的重要诊断。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文链接：http://news.stanford.edu/2017/01/25/artificial-intelligence-used-identify-skin-cancer/&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 26 Jan 2017 12:55:07 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 减少开发障碍，Petuum要使人工智能和机器学习民主化</title>
      <link>http://www.iwgc.cn/link/4494859</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自chatbotslife&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;作者：Mike Barlow&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：侯韵楚、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本文关键要点：&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;若想克服人工智能/机器学习成功部署所遇到的障碍，需要一个用户友好的解决方案开发平台。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;标准化、可重复的过程能消除对「人工的」一次性解决方案持续不断的需求。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关于人工智能是否真实的辩论已经尘埃落定。人工智能是真实的，它不会消失； 但其最终命运仍未可知，充满了未解之谜、盲目的歪曲与错误的假设。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前，有几个宏观趋势似乎十分清晰：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;人工智能解决方案愈发被用于创造或增加价值；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;现实中实现人工智能解决方案不仅困难，而且成本很高；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;人工智能的成功实施通常取决于机器学习和其他先进分析技术方法的实践知识；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;人工智能的更广泛采用需要用户友好型系统，其要能减少不必要的成本，并可以缩短开发周期。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前存在一个典型挑战：你的组织需要分析一些大数据，例如数千个道路摄像机的视频馈送、数百万患者的电子病历、数百家银行的金融交易、石油行业获取的地震数据或从哈勃太空望远镜传来的天文图像。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你已经拥有一个尊重并理解先进分析（advanced analytics）的组织文化，那么你就已经准备好通过实施人工智能/机器学习而实现迅速发展了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是，如果你的组织还未对数据科学家、软件开发人员、人工智能/机器学习专家和系统管理员的人员配置与团队培训进行培训，那么你的道路将会漫长而艰辛。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但仅仅雇用更多的人并不一定会解决你的问题，因为在人工智能/机器学习方面的成功高度依赖知识和经验。你所雇用的数据科学家可能并不了解如何为运行分析的硬件系统编写高效的代码；所雇用的软件开发人员也可能并不了解数据科学的数学概念；并且很可能他们都不知道如何优化各种所需的计算资源来浓缩数据并生成可用结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;实际上，你的新员工很可能成为你为大数据努力的瓶颈。比起变成资产，你的数据科学家和软件开发人员更可能成为负债，使你本就充满艰辛的道路更添磨难。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;大多数大数据从未被使用&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;根据定义，大数据是笨重而混乱的。大多数大数据并没有方便地被存储在单个数据库中，它通常分布于多个数据库中，并且有许多不同的来源，如社交媒体、消费者资料、电子病历、来自物联网设备的传感器日志、来自金融系统的事务日志以及来自制造设备的机器日志。由于在异构环境中不易执行大规模的分布式计算，所以大多数大数据从未被利用过或未被充分利用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管 TensorFlow 等工具确实能够使更多的开发人员接触到深度学习，但深度学习只是机器学习技术「大宇宙」的一个方面。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;卡内基梅隆大学计算机科学学院机器学习系的教授兼副研究负责人邢波（Eric Xing）博士说：「如果你使用 TensorFlow，便会知道它并不是为初学者设置的。它虽然免费，但你需要知道你在做什么并且必须愿意投入相当多的时间来得到你可信任的结果。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;邢波是美国人工智能协会（AAAI）的 Fellow，拥有来自罗格斯大学的分子生物学和加州大学伯克利分校的计算机科学的两个博士学位，他也是 Petuum Inc. 的创始人、首席执行官和首席科学家。该公司是一家创建人工智能（AI）和机器学习（ML）解决方案开发平台的创业公司。Petuum 最近完成了一项由 Advantech Capital 领投的，腾讯、Northern Light Venture Capital 和 Oriza Ventures 参投的 1500 万美元的 A 轮融资。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;邢波说，Petuum 的目标是建立下一代全方位机器学习平台，该平台可用于深度学习（如 CNN / RNN）、预测分析（如回归）、知识提取（如主题模型）、内容概括（如稀疏编码）和集合方法（如梯度增强树）；也可具有广泛的应用领域，如自然语言处理、图像与视频理解、以及交易数据中的异常检测。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除了作为通用机器学习开发平台，它还是一种机器学习计算管理和操作系统，并且还是一种企业型机器学习系统解决方案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;邢波说：「从我们的角度来看，该平台的多重功能使用户能够进行更大范围的创造与创新。开发人员拥有更多的选择与更大的灵活性——他们并不囿于单一的编程语言与特定的计算环境，并且平台会自动将他们的代码编译为通用格式。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在代码被编译为通用格式之后，它将进一步被转换为可执行文件，并安装到不同的硬件平台——从数据中心规模的分布式计算系统到移动设备中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;邢波说：「由于其参数服务器架构、管理通信、自适应调度与负载平衡、弹性资源管理以及最重要的开发与操作接口将这样的系统细节抽象了出来并同时无缝利用了它们先进的功能，Petuum 将为开发人员提供一个十分灵活的环境。Petuum 将在不影响精度和输出质量的前提下，允许人工智能或机器学习程序快速运行并扩展到多种设备中。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Petuum 更广泛的功能使其比其它解决方案的效率高 10 至 100 倍。比如，与 TensorFlow 不同，Petuum 能够完成图像分析和语音识别以外的广泛任务。Petuum 将能够安装在各种硬件配置上，并且它是多租户的（multi-tenant）——支持多个程序同时运行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;邢波说：「我们通过计算，发现在运行机器学习驱动的应用方面，Petuum 的技术比 Hadoop / Spark 框架的效率高出多达 800 倍。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Petuum 技术除了速度更快与更具扩展性，所需的能源与计算资源也比其它类型的大数据分析系统更少。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Petuum 的独特设计还允许更多资源进行共享，使多个程序能够在单一集群上运行。这与整体式系统（monolithic systems）的局限性形成鲜明对比——在整体式系统中，程序通常部署于单个设备上，且不能够共享。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;高效人工智能和机器学习的更广泛影响&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于经验丰富的开发商和运营商而言，Petuum 平台所提供的效率将大放异彩，但不一定在所有方面都具有革命性。但对用户而言，这些效率很容易转化为更快的发现与创新周期。而从我们的角度来看，更快的周期便意味着以更少的时间去实施，并将更多的时间用于提供价值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那么具体是什么价值呢？对一些组织而言，这个价值就是金钱；而对其他人而言，该价值将在如糖尿病和癌症等疾病的更安全有效的治疗中得到体现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;复杂的计算任务很难，但建立处理复杂任务的系统更难。Petuum 能减少创建将人工智能和机器学习应用于现实问题的可用系统所需的时间和精力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;值得注意的是，Petuum 将为新的人工智能和机器学习解决方案的创建提供一个急需的标准平台。目前几乎所有的人工智能和机器学习解决方案都是「人工的」。Petuum 更像是一个配有流水线的工业厂房，使开发人员能够使用透明且可重复的标准化流程来创建解决方案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;邢波说：「通过消除瓶颈、减少摩擦和提供标准过程，Petuum 将人工智能和机器学习的潜在优势推及至了你触手可及的位置。我们的目标不仅是使创建人工智能系统所基于的流程民主化——我们的目标是为所有需要的人提供实用的人工智能。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心发布，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 26 Jan 2017 12:55:07 +0800</pubDate>
    </item>
    <item>
      <title>回顾 | 谷歌翻译整合神经网络：机器翻译实现颠覆性突破（附论文）</title>
      <link>http://www.iwgc.cn/link/4494860</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Google Research&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：Quoc V. Le、Mike Schuster&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;2016 年是人工智能不断突破的一年。这一年，我们经历了语音识别的突破、风格迁移的繁盛、神经机器翻译的进步，等等。而这每一条消息的宣布机器之心都紧紧跟随。于是在岁末年关，机器之心将回顾过去一年中我们曾发布过的爆款文章。流量不代表文章质量，但选出的每一篇文章却代表了机器之心读者的关注点，以及我们自己的价值观。精彩的一年，我们一起见证，一起回顾。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;该系列回顾文章第一篇选择的是谷歌神经机器翻译的突破，统计时该篇文章的流量达到了 6 万多。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;十年前，我们发布了 Google Translate（谷歌翻译），这项服务背后的核心算法是基于短语的机器翻译（PBMT:Phrase-Based Machine Translation）。自那时起，机器智能的快速发展已经给我们的语音识别和图像识别能力带来了巨大的提升，但改进机器翻译仍然是一个高难度的目标。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今天，我们宣布发布谷歌神经机器翻译（GNMT：Google Neural Machine Translation）系统，该系统使用了当前最先进的训练技术，能够实现到目前为止机器翻译质量的最大提升。我们的全部研究结果详情请参阅我们的论文《Google`s Neural Machine Translation System: Bridging the Gap between Human and Machine Translation》（见文末）[1]。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;几年之前，我们开始使用循环神经网络（RNN：Recurrent Neural Networks）来直接学习一个输入序列（如一种语言的一个句子）到一个输出序列（另一种语言的同一个句子）的映射 [2]。其中基于短语的机器学习（PBMT）将输入句子分解成词和短语，然后很大程度上对它们进行独立地翻译，而神经机器翻译（NMT）则将整个输入句子视作翻译的基本单元。这种方法的优点是：相比于之前的基于短语的翻译系统，这种方法所需的工程设计更少。当其首次被提出时，NMT 在中等规模的公共基准数据集上就达到了可与基于短语的翻译系统媲美的准确度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自那以后，研究者已经提出了很多改进 NMT 的技术，其中包括模拟外部对准模型（external alignment model）来处理罕见词 [3]，使用注意（attention）来对准输入词和输出词 [4] 以及将词分解成更小的单元以应对罕见词 [5,6]。尽管有这些进步，但 NMT 的速度和准确度还没能达到成为 Google Translate 这样的生产系统的要求。我们的新论文 [1] 描述了我们怎样克服了让 NMT 在非常大型的数据集上工作的许多挑战，以及我们如何打造了一个在速度和准确度上都已经足够能为谷歌的用户和服务带来更好的翻译的系统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic8AYNx1rVQyUcIs8bbyDhYYnia3jZRmI5bMIIluWHibScueHom3bXNCS0rORlZiaEoRuzsvkGVYc2TA/0?"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;来自对比评估的数据，其中人类评估者对给定源句子的翻译质量进行比较评分。得分范围是 0 到 6，其中 0 表示「完全没有意义的翻译」，6 表示「完美的翻译」。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面的可视化图展示了 GNMT 将一个汉语句子翻译成英语句子的过程。首先，该网络将该汉语句子的词编码成一个向量列表，其中每个向量都表征了到目前为止所有被读取到的词的含义（「编码器（Encoder）」）。一旦读取完整个句子，解码器就开始工作——一次生成英语句子的一个词（「解码器（Decoder）」。为了在每一步都生成翻译正确的词，解码器重点注意了与生成英语词最相关的编码的汉语向量的权重分布（「注意（Attention）」，蓝色链接的透明度表示解码器对一个被编码的词的注意程度）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_gif/KmXPKA19gWic8AYNx1rVQyUcIs8bbyDhYKGC1GMI9FibcKU7hc2dia5qJzKVUg9B1FULZKcIs3wvxjCOsk7o57QfQ/0?"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使用人类评估的并排比较作为一项标准，GNMT 系统得出的翻译相比于之前的基于短语的生产系统实现了极大的提升。在双语人类评估者的帮助下，我们在来自维基百科和新闻网站的样本句子上测定发现：GNMT 在多个主要语言对的翻译中将翻译误差降低了 55%-85% 以上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic8AYNx1rVQyUcIs8bbyDhYoD35dMSt4n4vib0HZUT5k5xxh1ohicNClItTUycqMiaW7lahOJFBYzVMQ/0?"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;我们的系统产出一个翻译案例，其输入句子采样自一个新闻网站。这个地址（https://drive.google.com/file/d/0B4-Ig7UAZe3BSUYweVo3eVhNY3c/view?usp=sharing）可以看到更多随机采样自新闻网站和书籍的输入句子翻译样本。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今天除了发布这份研究论文之外，我们还宣布将 GNMT 投入到了一个非常困难的语言对（汉语-英语）的翻译的生产中。现在，移动版和网页版的 Google Translate 的汉英翻译已经在 100% 使用 GNMT 机器翻译了——每天大约 1800 万条翻译。GNMT 的生产部署是使用我们公开开放的机器学习工具套件 TensorFlow 和我们的张量处理单元（TPU：Tensor Processing Units），它们为部署这些强大的 GNMT 模型提供了足够的计算算力，同时也满足了 Google Translate 产品的严格的延迟要求。汉语到英语的翻译是 Google Translate 所支持的超过 10000 种语言对中的一种，在未来几个月，我们还将继续将我们的 GNMT 扩展到远远更多的语言对上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;机器翻译还远未得到完全解决。GNMT 仍然会做出一些人类翻译者永远不出做出的重大错误，例如漏词和错误翻译专有名词或罕见术语，以及将句子单独进行翻译而不考虑其段落或页面的上下文。为了给我们的用户带来更好的服务，我们还有更多的工作要做。但是，GNMT 代表着一个重大的里程碑。我们希望与过去几年在这个研究方向上有所贡献的许多研究者和工程师一起庆祝它——不管是来自谷歌还是更广泛的社区。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Google Brain 团队和 Google Translate 团队都参与了该项目。Nikhil Thorat 和 Big Picture 也帮助了该项目的可视化工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="max-width: 100%; color: rgb(62, 62, 62); font-size: 16px; font-variant-ligatures: normal; orphans: 2; white-space: normal; widows: 2; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;论文：Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic8AYNx1rVQyUcIs8bbyDhYT2r1HkDqWO8ianIib4y3rsKrCDj3oq8IicQMlqe2AkxEibuSfNp4D582gA/0?"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;摘要：神经机器翻译（NMT: Neural Machine Translation）是一种用于自动翻译的端到端的学习方法，该方法有望克服传统的基于短语的翻译系统的缺点。不幸的是，众所周知 NMT 系统的训练和翻译推理的计算成本非常高。另外，大多数 NMT 系统都难以应对罕见词。这些问题阻碍了 NMT 在实际部署和服务中的应用，因为在实际应用中，准确度和速度都很关键。我们在本成果中提出了 GNMT——谷歌的神经机器翻译（Google's Neural Machine Translation）系统来试图解决许多这些问题。我们的模型由带有 8 个编码器和 8 个解码器的深度 LSTM 网络组成，其使用了注意（attention）和残差连接（residual connections）。为了提升并行性从而降低训练时间，我们的注意机制将解码器的底层连接到了编码器的顶层。为了加速最终的翻译速度，我们在推理计算过程中使用了低精度运算。为了改善对罕见词的处理，我们将词分成常见子词（sub-word）单元（词的组件）的一个有限集合，该集合既是输入也是输出。这种方法能提供「字符（character）」-delimited models 的灵活性和「词（word）」-delimited models 的有效性之间的平衡、能自然地处理罕见词的翻译、并能最终提升系统的整体准确度。我们的波束搜索技术（beam search technique）使用了一个长度规范化（length-normalization）过程，并使用了一个覆盖度惩罚（coverage penalty），其可以激励很可能能覆盖源句子中所有的词的输出句子的生成。在 WMT' 14 英语-法语和英语-德语基准上，GNMT 实现了可与当前最佳结果媲美的结果。通过在一个单独的简单句子集合的人类对比评估中，它相比于谷歌已经投入生产的基于短语的系统的翻译误差平均降低了 60%。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;参考文献：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;[1] Google’s Neural Machine Translation System: Bridging the Gap between Human and Machine Translation, Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V. Le, Mohammad Norouzi, Wolfgang Macherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, Jeff Klingner, Apurva Shah, Melvin Johnson, Xiaobing Liu, Łukasz Kaiser, Stephan Gouws, Yoshikiyo Kato, Taku Kudo, Hideto Kazawa, Keith Stevens, George Kurian, Nishant Patil, Wei Wang, Cliff Young, Jason Smith, Jason Riesa, Alex Rudnick, Oriol Vinyals, Greg Corrado, Macduff Hughes, Jeffrey Dean. Technical Report, 2016.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;[2] Sequence to Sequence Learning with Neural Networks, Ilya Sutskever, Oriol Vinyals, Quoc V. Le. Advances in Neural Information Processing Systems, 2014.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;[3] Addressing the rare word problem in neural machine translation, Minh-Thang Luong, Ilya Sutskever, Quoc V. Le, Oriol Vinyals, and Wojciech Zaremba. Proceedings of the 53th Annual Meeting of the Association for Computational Linguistics, 2015.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;[4] Neural Machine Translation by Jointly Learning to Align and Translate, Dzmitry Bahdanau, Kyunghyun Cho, Yoshua Bengio. International Conference on Learning Representations, 2015.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;[5] Japanese and Korean voice search, Mike Schuster, and Kaisuke Nakajima. IEEE International Conference on Acoustics, Speech and Signal Processing, 2012.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;[6] Neural Machine Translation of Rare Words with Subword Units, Rico Sennrich, Barry Haddow, Alexandra Birch. Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, 2016.&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;延展阅读：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719511&amp;amp;idx=1&amp;amp;sn=88bbb6bb3d28b3f0f62c5c5929968444&amp;amp;chksm=871b0169b06c887f302dc791c67f19ce4ba49c43744e11341b7bb225d9e22443ebf9e3b70339&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719511&amp;amp;idx=1&amp;amp;sn=88bbb6bb3d28b3f0f62c5c5929968444&amp;amp;chksm=871b0169b06c887f302dc791c67f19ce4ba49c43744e11341b7bb225d9e22443ebf9e3b70339&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;"&gt;&lt;span&gt;专访 | 谷歌神经网络翻译系统发布后，我们和Google Brain的工程师聊了聊&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720582&amp;amp;idx=2&amp;amp;sn=06076c800c912622d8fa42665d7de1fc&amp;amp;chksm=871b0d38b06c842e3f6edaa5d36046b6702d26a0bcfb710c2010e5f0815389bf4f60077441ef&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720582&amp;amp;idx=2&amp;amp;sn=06076c800c912622d8fa42665d7de1fc&amp;amp;chksm=871b0d38b06c842e3f6edaa5d36046b6702d26a0bcfb710c2010e5f0815389bf4f60077441ef&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;"&gt;&lt;span&gt;深度 | 逐层剖析，谷歌机器翻译突破背后的神经网络架构是怎样的？&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720536&amp;amp;idx=2&amp;amp;sn=1617ed96796bba31f4d6c6749b7579db&amp;amp;chksm=871b0d66b06c8470e86bf243fab1b7710dd8b222ecbfa99d5ac61dac07694542e6d4b6846db8&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720536&amp;amp;idx=2&amp;amp;sn=1617ed96796bba31f4d6c6749b7579db&amp;amp;chksm=871b0d66b06c8470e86bf243fab1b7710dd8b222ecbfa99d5ac61dac07694542e6d4b6846db8&amp;amp;scene=21#wechat_redirect" style="font-size: 14px; text-decoration: none;"&gt;重磅 | 谷歌神经机器翻译再突破：实现高质量多语言翻译和zero-shot翻译（附论文）&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Thu, 26 Jan 2017 12:55:07 +0800</pubDate>
    </item>
    <item>
      <title>重磅 | Edge 2017年度人工智能话题预测：从算法、迁移学习到自产生程序</title>
      <link>http://www.iwgc.cn/link/4482149</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Edge&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Edge.org 为著名知识分子俱乐部 The Reality Club 的线上社区，自 1996 年上线，如今已有 20 年历史。在其创刊 20 周年之际，Edge.org 也推出了 2017 年度问题——2017 年，最值得关注的科学术语或概念是什么？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以下是我们从206个回答中精选的一部分：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Terrence J. Sejnowski，计算神经科学家；萨克生物研究学院（Salk Institute）弗朗西斯·克里克学院（Francis Crick Institute）教授；《The Computational Brain》联合作者&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;科学术语：算法（Algorithms）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 20 世纪，我们使用方程和连续变量的数学方法作为主要洞见来源，因此对物理世界有了一个深刻的认识。一个连续变量在空间和时间上的变化是平滑的。与火箭仅仅遵循牛顿运动定律不同，还没有一种简单的方法来描述。在 21 世纪，我们在算法的数学基础上——通常含有离散变量而非连续变量——在理解计算机科学和生物学中的复杂性质方面取得了进展。算法是一个按步骤进行以实现某个目标的方法，就像在烤一个蛋糕。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自相似分形（Self-similar fractals）产生自简单的递归算法，该算法能创建类似于灌木和树的模式。一个真正的树结构也是一个算法，由一系列决定着细胞分裂时基因的打开和关闭的决策所驱动。大脑的结构也许是宇宙中最苛刻的构造项目，它也受到嵌入 DNA 中的算法所支配，该算法能够调节大脑中数百个不同的部分的成千上万种不同类型的神经元之间的连接的发育。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大脑中的学习与记忆是由算法控制的，该算法根据神经元活动的历史来改变神经元之间突触的强度。学习算法最近也被用于训练深度神经网络模型来识别语音、翻译语言、为照片添加说明以及进行锦标赛水平的围棋对弈。获得这些惊人能力的方法就是将同一个简单的学习算法应用到不同类型的数据上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;生成复杂性的算法有多常见？「游戏人生（The Game of Life）」是一个元胞自动机，其生成对象似乎有自己的生命。Stephen Wolfram 想知道能够导致复杂行为的最简单的元胞自动机规则，因而对所有的规则开始了搜索。前 29 个规则产生的模式总是返回到无聊的行为：所有节点都以相同的值结束，陷入一个无限重复的序列或无尽的混乱变化中。但规则 30 却能产生不断演化的复杂模式。甚至可以证明，规则 30 能够进行一般计算——可以计算任何可计算函数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这一发现的启示之一是，我们在自然界中所发现的显著复杂性，可能来自对分子间最简单的化学作用空间的取样。复杂的分子应该是从进化中演化来而不应该被视为一种奇迹。然而，元胞自动机可能不是一个早期生命的良好模型，而对于何种简单化学系统能够创造出复杂分子的探讨还仍然是一个悬而未决的问题。也许只有特殊的生化系统才有这种特性，该特性或许有助于缩小生命起源中相互作用的可能范围。Francis Crick 和 Leslie Orgel 认为，RNA 可能会有这些特性，它们在 DNA 的概念于进化早期出现之前打开了一个 RNA 的世界。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有多少算法？想象所有可能的算法空间，空间中的每一点都是一个处理问题的算法。其中有些算法有用而多产得令人吃惊。在过去，这些有用的算法是由数学家和计算机科学家像工匠那样手工制作的。与此相反，Wolfram 发现元胞自动机通过自动搜索能产生高度复杂的模式。Wolfram 定理规定，你不必在算法空间中走得太远去寻找一个解决一类有趣问题的算法。这就像是让机器人在网上玩 StarCraft 之类的游戏，尝试所有可能的策略。根据 Wolfram 定理，在能够赢得游戏的算法宇宙中的某个地方，应该有一个办法可以找到该算法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Wolfram 专注于研究元胞自动机空间——所有可能算法空间中一个小的子空间——中最简单的算法。我们现在已确认了神经网络空间——人类所设计过的最复杂的一部分算法空间——中的 Wolfram 定理。每个深度学习网络是所有可能算法空间中的一个点，而且它们是通过自动搜索被发现的。对于一个大网络和一个大数据集，从不同起点进行的学习可以产生无限的网络，它们解决问题的能力大致相等。每个数据集产生自己的算法星系，而数据集还在激增。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;谁知道宇宙算法对我们来说会是什么样子？可能整个有用的算法星系还未被人类发现，但可以通过自动搜索实现。21 世纪才刚刚开始。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Peter Lee，微软全球资深副总裁&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;科学术语：迁移学习（Transfer Learning）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「你永远不能理解一种语言——除非你至少理解两种语言」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;任何一个学过第二语言的人，对英国作家杰弗里·威廉斯的这句话应该都会「感同身受」。但为什么这样说呢？其原因在于学习使用外语的过程会不可避免地加深一个人对其母语的理解。事实上，歌德也发现这一理念的强大威力，以至于他不由自主地做出了一个与之类似但更为极端的断言：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「一个不会外语的人对其母语也一无所知」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种说法极为有趣，但令人惊讶的是恐怕更在于其实质——对某一项技能或心理机能的学习和精进能够对其他技能或心理机能产生积极影响——这种效应即为迁移学习。它不仅存在于人类智能，对机器智能同样如此。如今，迁移学习已成为机器学习的基础研究领域之一，且具有广泛的实际应用潜力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今天的机器学习领域主要围绕着能力可随数据及经验的积累而提高的算法，且已取得惊人进步，并由此催生出可比肩甚至超越人类智能的计算系统，例如具有理解、处理及翻译语言能力的系统。近年来，机器学习研究多聚焦在深度神经网络（DNN）——一种通过从大量数据中推断异常复杂模式而进行学习的算法概念。例如，向一台基于 DNN 的机器输入数千个英文录音片段及其对应文本，机器便可从录音与文字的关联中推断出相关模式。伴随着关联模式的逐渐精确，系统最终将能「理解」英语语音。事实上，今天的 DNN 已经相当成熟，一台功能强大的计算机在学习过足够的训练样本后，完全可以对真人对话进行文字速记，并达到比专业速记员更高的准确率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一些人也许会很惊讶，计算机化的学习机器（computerized learning machines）展现出迁移学习的能力。我们可以通过一项涉及两套机器学习系统的实验来思考这个问题，为了简单起见，我们将它们称为机器 A 和机器 B。机器 A 使用全新的 DNN，机器 B 则使用已经接受训练并能理解英语的 DNN。现在，假设我们用一组完全相同的普通话录音及对应文本来对机器 A 和 B 进行训练，大家觉得结果会怎样？令人称奇的是，机器 B（曾接受英语训练的机器）展现出比机器 A 更好的普通话技能，因为它之前接受的英语训练将相关能力迁移到了普通话理解任务中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不仅如此，这项实验还有另一个令人更为惊叹的结果：机器 B 不仅普通话能力更高，它的英语理解能力也会提高！看来威廉斯和歌德确实说对了一点——学习第二语言确实能够加深对两种语言的理解，即使机器也不例外。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;迁移学习的理念至今仍是基础研究的课题之一，因此，许多根本性的问题仍然悬而未决。例如，并非所有的「迁移」都是有用的。要让「迁移」发挥作用，学习任务之间至少需要相互关联，而这种关联方式仍然缺乏精确定义或科学分析，且与其他领域相关概念之间的联系仍有待阐明，如认知科学和学习理论。诚然，对于任何一个计算机科学家而言，从事计算机系统的「拟人化（anthropomorphizing）」在理智层面都是危险的，但我们却不得不承认，迁移学习让人类学习和机器学习之间产生了强烈而诱人的相似性；当然，如果通用人工智能真能有朝一日成为现实，迁移学习恐怕将是这一过程中的决定性因素之一。对于善于哲学思考的人来说，迁移学习的正规模型可能会为知识和知识迁移带来新发现和分类方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;迁移学习同样具有极高的应用潜力。过去，机器学习在搜索和信息检索等领域中的实用价值较为单一，大多聚焦于通过万维网上大量数据集和人物信息进行学习的系统。但我们是否想过，经过网络训练的系统可以了解关于较小社区、组织甚至个人的信息么？未来智能机器可以学习与特定个人或小型组织相关的、高度专业化的任务么？迁移学习让我们可以想象这样一种可能性，让所有网络信息都成为机器学习系统的基础，而系统则可通过迁移学习获得更个性化的信息。实现这个愿景，我们将向人工智能普及化迈出又一大步。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Susan Blackmore，心理学家，《Consciousness: An Introduction》一书作者&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;科学术语：Replicator Power（复制体能力）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;宇宙中的一切设计都从何而来？无论在何处，我都能看见一系列事物——它们有的被设计过，而有的则没有——岩石、星星、水洼里的雨水，桌子、书本、草地、兔子乃至我的双手。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人们并非通过这样的方式来区分被设计的与未被设计的（事物）。通常人们将地上的书与岩石区分开来——因为书籍是为特定目的而设计的，但岩石则不是。书籍会有作者、出版商、印刷者、封面设计者等等，这代表着一种自上而下（译者注：由整体概念到具体细节）的设计模式，是「真正的」设计。但对于青草、兔子乃至双手，它们的确能够服务于特定的功能，但它们是通过一种无意识的、自下而上的过程演化的。因而，它们不是「真正的」设计。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于真正的设计与演化的「设计」之间的区别，偶尔被明确地说清。但在未被说清时，进化生物学家们往往对于将「设计」一词用在无意识的过程上会有某些畏惧的陈述。但它们真的「好像」是被设计的。它们并非是依据某种计划或意识的由上至下的模式，而是一种完全根据无意识过程的由下自上的模式。换句话说，我们大脑与「真正的」设计是不同的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果关于复制力（Replicator Power）的概念被更好的了解，那么这种错误的区分方法也许就会消除。因为我们会发现，所有的设计都基于一种相同底层过程。一个复制体（Replicator）是能够影响环境并能复制自身的信息（information）。基于变化与选择进行复制的进化算法，是一种能够无限制增加已有信息的过程。而复制体的能力，就从它在这种进化算法中扮演的信息载体的角色而来。基因就是最为明显的例子，它们带来了各种各样的生物作为它们（达到目的的）媒介或产物。而自然选择的作用则决定了复制体的成败。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「复制体」这个术语的价值在于它的普适性。这也是道金斯（英国演化生物学家）在撰写关于普适达尔文主义（Universal Darwinism，即将达尔文主义中最基本的想法应用到到所有的自复制信息中）时所强调的。当复制体存在并且环境适宜的情况下，「设计」将会随之发生。所以道金斯创造术语「文化基因（meme）」来说明世界上不止有一个复制体在进化。遵循关于进化的方式的思考，他也做出了这样的断言：复制体的有差别幸存（differential survival）导致了各个地方生命的进化。我则会补充认为：复制体的有差别幸存导致了各个地方智能的进化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这也就表明，人类设计从本质上与生物设计并无二致。两者都基于复制体被复制（的过程）——要不然是以 DNA 碱基对的分子顺序进行复制，要不然是以书本上字词的顺序进行复制。在分子复制的情况下，新的序列由复制过程的错误、突变或重组而产生。在撰写书籍的过程中，新的序列通过作者重组熟悉的词汇到新词组、句子乃至段落产生。在两个例子中，许多不同的序列被创造但很少的被保留被继续复制，而创造性设计的产品因复制力而出现。要理解人类以这种方式进行设计，就要放弃对于自上而下设计、智慧与规划对创造力必不可少这样的假设，要将那些能力及它们带来的设计视为进化的原因而非结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;接受这样的观点也许会带来不适，因为它意味着认同我们一切认为我们设计的东西实际上是一种从下到上、毫无头绪的过程利用我们作为一种复制机器（copy machinery）。这种不适也许就如同伯明翰主教之妻所说：这样知识贬低了人类自身，并且会消除我们的人性乃至能力。但我们已经能（或多或少在世界上的某些地方）学会拥抱而非畏惧这样的知识，我们的身体通过一种无意识的自下而上的过程进化。在相同方向上还有另一过程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;认识到复制力的意义在于认识到现在还有其他的复制体、以后还会有更多。这种无意识的过程将我们人类从猿猴转变为能讲话、能够复制文化基因（meme）的动物，让我们能生产桌子、书本、汽车、飞机以及复制机器——这是最重要的一步。这（复制机）包括了导致印刷过程的写作、产出家具的陶论、木头加工工具，以及导致现在信息爆炸的计算机技术。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;人工智能，无论是被造成桌上箱子的样子，还是分布在网络世界中的机器人，都被以复制能力的方式而创造，就如同我们的智慧被复制能力创造一般。它们以远超过我们的速度进化，并且会带来更深刻乃至更快的复制体。这种能力不停止，因为我们即希望如此。并且它的产物并不会臣服于我们的陈述，不会受我们的控制也不会按照（我们希望的）它兴盛的方式设计。这种智能会不断地成长，并且我们越快接受复制能力的概念，我们将会对有人工机器的未来生活的态度越现实。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Ursula Martin，牛津大学计算机科学教授&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;科学术语：抽象（Abstraction）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;翻开 Ada Lovelace 在 1843 年关于 Charles Babbage 未建成的分析引擎 (Analytical Engine) 的论文，如果你足够「极客」的话，你依然能够应付 19 世纪的长难句——令人惊讶的是，它们到如今仍然具有可读性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个分析引擎是完全机械的。设置一个具有十个齿的重金属盘来存储数字，五十个这样的盘堆叠后可以存储五十位数字，并且存储器将包含 100 个这样的堆叠。添加两个数字的基本指令将它们从存储器移动到 CPU 中，在那里它们将被添加在一起，而后移回到存储器中的新位置等待进一步使用，这些过程全都是机械的。它用冲孔卡来编程，代表了变量和操作，并进一步用精心设计的机制来移动冲孔卡，在需要循环时以组为单位重新使用。Babbage 估测认为这个巨大的机器将两个 20 位的数字相乘需要三分钟的时间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这篇论文可读性非常高，因为 Lovelace 所描述的机器使用抽象——存储、mill、变量、操作等，而非精心制作的铁器。这些抽象及它们之间的关系在识别主要组件和组件间传递的数据的过程中捕获了机器的本质。他们用当时的语言捕获当时和现在计算中的一个核心问题——使用不同的机器可计算和不可计算的内容。本文确定了「若所有智力执行的操作本身能够被精确定义，则重现这些操作以获得确定结果」所需的元素，并且算术、条件分支等恰恰是百余年后阿兰·图灵证明其关于计算力量的结果所需要的元素。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;仅在代表它们的机械行为中，你不能在 Babbage 的机器中指向一个变量或一个附加指令。在 20 世纪 60 年代，曾经 Lovelace 只能用来应对官方解释的抽象已被改进得更加精良。牛津大学的 Dana Scott 和 Christopher Strachey 等计算机科学家使用单一抽象来对机器和运行的程序建模，使得精确的数学推理能够预测其行为。这些概念已经进一步完善，如计算机科学家 Samson Abramsky 使用先进的逻辑和数学来捕获更微妙的抽象，不仅可以用于经典计算机，也可用于量子计算。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为实际问题确立一个优质的抽象不仅是一门科学，也是一门艺术。确立过程需要捕捉问题的构建块和连接它们的元素，这些元素应具有恰到好处的细节量；确立过程提取的是远离块内部复杂区域的部分，所以设计者只需关注与其他组件交互所需的元素即可。Jeannette Wing 将这些技能描述为计算思维，而这个概念可以在编程之外的许多情况下被指出。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Lovelace 发现了更广泛的抽象力，希望通过发展「利用法则建立大脑分子的相互作用」来理解神经系统，实现自己的理想。并且如今的计算机科学家确实在为此扩展技术开发并建立合适的抽象。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Samuel Arbesman，复杂性（Complexity）科学家；拉克斯资本公司（Lux Capital）住宅研究方面科学家；《Overcomplicated》一书作者&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;科学主题：自产生程式/奎因（Quines）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在计算机程序的无限空间中有一个特殊的代码子集：当执行程序时输出该程序本身。换句话说，这是一些自复制程序；当你运行它们时，它们会输出自身。这些短小的程序通常被称为「自产生程式/奎因（quines）」，来源于哲学家韦拉德·范·奥曼·奎因（Willard Van Orman Quine）的名字，基于侯世达（Douglas R. Hofstadter）所著的《哥德尔、埃舍尔、巴赫：一条永恒的金带（Gödel, Escher, Bach: an Eternal Golden Braid）》一书中的术语。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Quines 一词给人的第一印象往往显得不可思议。你要是曾经写过代码就更会有这种感觉，因为如果你不了解创建 quines 的技巧，便可能会觉得难以构建。它们往往是优雅的小东西，而现在有大量的计算机语言写出了各种各样的 quines 案例，从简短可爱型到不可思议之长。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不过它们为什么如此重要呢？quines 是计算机科学、语言学及其他学科思想的精华。简单点说，quines 可以被认为是定点，即数学中的 fixed point：一个输出自身而保持函数值不变的数学函数的值（想想 1 的平方根为什么仍然为是 1）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不过我们可以进一步地讨论一下。Quines 表明计算机所产生的语言既可以是操作符也可以是操作数——一个 quine 文本运行并通过一个向自身反馈的过程输出原始代码。文本可以是有意义的单词，也可以是「有意义的单词」，思考这个句子「This sentence has five words.」，我们很高兴地看到，此句中的单词不仅是在描述（充当一个操作符）也是在被描述（充当一个操作数）。不过这个文字游戏也很有用。文本和功能之间的这种关系是 Kurt Gödel 在不完备性数学研究中用到的一个基本组成部分，而这又与阿兰·图灵在解决停机问题时所用的方法有关。这些基本思想显示出数学和计算机科学中的某种局限性：我们不能证明某些陈述在一个给定系统中的对与错，并且也没有任何算法可以确定任何给定的计算机程序是否将会永远地终止运行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;更广泛地说，quines 还表明了复制（reproduction）行为不是生物领域所独有的。就像一个细胞利用物理及化学规律来生存和繁衍一样，一个 quines 会添加一门编程语言的规则来执行代码。虽然它并不完全复制自身，但其工作原理是相似的。你甚至可以进一步在某个「辐射硬化（radiation hardened）」quine 中发现这种生物性质的迹象：在这种 quine 中，任何字符都可以被删除，而它仍然可以进行复制！对我们中的许多人来说，辐射硬化 quine 听起来无疑就像基因的 DNA 序列那样令人费解。冗长与坚固——生物学的标志——在有机体与计算机中输出的是相似的结构。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;冯·诺依曼（John von Neumann）是计算机界的先驱之一，他在机器的自我复制方面做过大量的思考，把从计算早期开始研究的技术与生物学结合起来。我们仍然会在小段的 quine、小段的计算机代码中看到，它们通过其微小的努力将各个领域一个接一个地缝合起来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Sean Carroll，加州理工学院理论物理学家；《The Big Picture》一书作者&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;科学术语：贝叶斯定理（Bayes's Theorem）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你担心朋友生你的气。你设了一个晚宴而没有邀请他们；这就是那种会令他们不开心的事情。但你并不确定。所以你给他们发了一条短信：「今晚想出去吗？」二十分钟后你收到一个回复：「不能，忙。」我们怎么解释这条新信息？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然部分答案可以归结为人类心理学。但其中一部分是统计推理的一个基本原理，称为贝叶斯定理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当我们不确定某些命题的真假时就会寻求于贝叶斯定理，而新信息会影响该命题为真的概率。这个命题可以是朋友们的感受、世界杯结果、总统选举结果，或有关早期宇宙活动的特定理论。换句话说：我们真的一直在使用贝叶斯定理。可能是以某些正确或不正确的方式，但它无处不在。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该理论本身理解起来不是很难：给定一些新数据，一个命题为真的概率正比于其在数据出现之前就为真的概率乘以该命题为真时出现该新数据的可能性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此它有两个影响因素。第一个是先验概率（prior probability），即我们在收集任何新信息前就确定某一想法的概率。第二个是在该想法为真时所收集的一些特定数据的可能性。贝叶斯定理认为：不同命题在新数据收集过程之后的相对概率就是二者的乘积。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;科学家们总是以精确、定量的方法使用贝叶斯定理。但这个定理——或实际上是构成其基础的「贝叶斯推理」这个思想——无处不在。在你给朋友发短信之前，你已经知道他们有多大可能会生你的气。换句话说，你对「生气」与「不生气」的命题有一个先验预期。当你收到他们的回复时，你含蓄地对这些概率做了一个贝叶斯更新（Bayesian updating）。如果他们生气，那么他们有多大可能会发送这样的回复？要是他们不生气呢？乘以适当的先验概率，有了新信息后，现在你就可以明白他们生气的可能性有多大。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这一条纯统计学逻辑背后潜伏有两个伟大而深刻、足以塑造世界观的思想。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个是先验概率的概念。不管你承认与否，不管拥有什么样的数据，你都隐约会对所能想到的每一个命题持有一个先验概率。如果你说，「我不知道它是真是假，」那么其实你是在说「我的先验概率是 50%。」并且其设置过程不涉及客观的、事先准备好的步骤。人与人之间想法差别巨大。对某个人来说，一张看起来像是鬼魂的照片无疑是人死后生命的凭证；对另一个人来说，它更可能是伪造的。无论我们以何种先验概率开始思考，给定无限量的证据和完美的理性，我们都应该会趋于相似的信仰——但没有无限的证据，理性也并不完美。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一个伟大的思想是，你对一种思想的信仰程度将永远不可能是 0 或 1。对某些数据的收集永远不是绝对不可能的，无论真相是什么——即使最严格的科学实验也容易出错，而大多数日常数据的收集根本算不上严格。这就是为什么科学从来没有「证明」什么；我们只是增加了对某些思想的凭证，直到它们几乎（但不完全）达到 100%。贝叶斯定理提醒我们在面对新信息时应当保持思想的开放性，而且它会告诉我们到底需要什么样的新信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Ian Bogost，Ivan Allen 学院媒体研究名誉主席，乔治亚理工学院交互式计算教授；Persuasive Games LLC 创始合伙人；《The Atlantic》特约编辑&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;科学术语：概率空间（possibility space）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有些问题很容易，但大多数问题都很难。它们超越了人类掌握和推理可能答案的能力。不仅仅是复杂的科学与政治问题，例如制定复杂的经济决策或建立模型以应对气候变化，日常生活也是如此。「今晚去吃晚饭吧。」「好啊，但是去哪呢？」这样的问题很快就陷入了无结构形式的存在主义危机（existential crisis）。甚至是，「我是谁？」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数学家思考复杂问题的一种方法是利用可能解的概率空间（possible solutions，有时也称为解空间/solution space 或 probability space）在数学中，概率空间被用作一个寄存器或所有可能解的分类帐目。例如，掷一枚硬币的概率空间是头或尾。对于两枚硬币：正面-正面、正面-反面、反面-正面、反面-反面。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是一个相对简单的例子，因为任何概率空间的给定子集都可以被测量和记录下来。但在其他情况下，概率空间可能非常大，甚至无限大。例如宇宙中可能存在的生命形式，或可能的未来进化分支。或是可能的围棋游戏。甚至是你能够用一晚上的时间所能做到的所有事情。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这些情况下，要完整地描绘概率空间不仅很难或根本不可能做到，而且往往连尝试甚至都毫无意义。一个经济学家可能会依据某些行为的相关效益成本而从其净边际效益（net marginal benefit）中建立一个可能外出吃晚饭的模型，比如看一部电影、骑一次自行车或吃一份惠灵顿牛排，但这种做法假定了日常生活中所不存在的理性主义。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在游戏设计中，创作者经常将自己的工作看作是为玩家创造概率空间。在源自古代中国的围棋游戏中，棋子、棋子摆放规则以及一块棋盘为整个对弈提供了一个非常大的概率空间。但每个人的行动都会越来越受限——依赖于每位棋手的先前决策集。否则棋手就不能移动一步。任何人都不能在所有围棋比赛的全部数学概率空间之内下棋，却可以在——于给定的时间点、给定的棋盘上所进行的可能且合乎规则的移动步骤中——更窄的概率空间内下棋。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一些设计师尊崇围棋和象棋类游戏的数学帮助，希望用最少的元素创造出最大的概率空间。但更多时候，令一款游戏在美学上显得独特的东西不是数学上的大或深，而是其组成元素及其可能配置有多么有趣而独特。俄罗斯方块只有七个不同的元素，所有元素以相同方式运作。俄罗斯方块的乐趣来自于学习在各种情况下识别和操作这些元素。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;积极且慎重地去限制一个概率空间的练习效用远远超出了科学、数学和游戏设计。每种情况都可以通过确认或强加限制以产生一个可行的、可操作的可能行动领域而被更加慎重且卓有成效地解决。这并不意味着你每次启动洗碗机或与朋友进行通宵辩论时都必须制定效用图表。而是说，任何问题的第一步都得承认，现有的大量限制已经存在，正等待被确认和激活。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在面对巨大或无限大的概率空间时，科学家们试图强加一些限制以创造可测量且可记录的工作。例如，一个生物学家可以通过限制对一定规模和组成成分的恒星或行星的请求来建立一个可能存在外星生命的概率空间。当你为一顿晚饭的选址进行争论时也会这样做——即使你在正常情况下不这样想：你喜欢什么样的食物？你想花多少钱？你愿意跑多远？要决定其中的一两个问题往往会产生一些进步。而它在避免进入一个存在主义螺旋中时也是这样做的，向内心深处寻问你到底是谁，或人类选择的终极来源：你真正想要的是什么。在日常生活中，就像在科学中一样，答案已然存在于世，比它们在你头脑中被发明的都要多。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Scott Aaronson，德克萨斯大学奥斯汀分校计算机科学 David J. Bruton 的荣誉教授；《Quantum Computing Since Democritus》一书作者&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;科学术语：态（State）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在物理学、数学和计算机科学中，系统的状态是封装所有你所需要的预测它将做什么，或至少预测它做这件事而非另一件事的概率的信息，来响应任何可能的刺激。从某种意义上说，态是一个决定系统在表面外观下的行为的「隐藏现实」。但在另一种意义上，没有什么隐藏的态——对于从不重视观察的态的任何部分，都能够用奥卡姆剃刀原理（Occam』s Razor）将其切割，来产生更简单、优质的描述。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这样看来，「态」这个概念似乎很明显。那么，为何爱因斯坦，图灵和其他人还会在这个概念上，在走向人类最难得的知识胜利的道路上奋斗那么多年？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;一起来看几个迷题：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果要添加两个数字，计算机显然需要一个包含着添加说明的添加单元。但是，它还需要一些说明解释这些说明，而后它便需要说明来解释这些说明的说明……所以我们得出结论，添加数字对于任何范围有限的机器来说是不可能的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;根据量子重力的现代理念，空间（space）可能并不是根本，而是对普朗克量级自由度的量子位（qubit）网络的描述。我曾有过疑问：倘若宇宙是一个量子位的网络，那么这些量子位在哪里？它们是不是没有意义（例如，假设两个量子位是「邻居」，却没有预先存在的空间来使量子位成为邻居）？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;根据狭义相对论，可知光速最快。但假设我翻转一枚硬币，将结果写在两个相同的信封中，然后将一个信封放在地球上，另一个放到冥王星。接着，我打开地球上信封的瞬间，改变了冥王星上信封的状态，从「正面和反面可能性相同」变成「绝对是正面」或「绝对是反面」（我们可以看到，这种类型的量子纠缠甚至成为了经典谜题）！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关于计算机的谜题是我与非科学家知识分子进行无数次辩论的一个话题。我认为，分辨率可以指定计算机的状态，涉及到要添加（编码，如二进制）的数字，和横跨数字的添加和携带、由布尔逻辑操控并最终通过物理定律实现的有限控制单元。你可能会问：物理定律本身是什么？无论对于这个问题有什么答案，它的基础在哪里？这些都是我们的问题；同时，计算机工作所需要的一切都包含在它的态中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;这个关于量子位的问题是许多其他问题的附加问题：例如，如果宇宙正在扩张，那么它正扩张到哪里？这些问题未必不好。但从科学的角度来讲，一个人完全有理由回应：「你在建议我们在世界的态上创建新事物，比如扩张或寻找我们的第二个生存空间。那么这第二个空间对观察有什么影响？如果永远不会有影响，为什么不把它切割出去呢？」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关于信封问题，可以通过认为你在地球上决定是否打开信封不会影响观察者在冥王星上感知信封内容的概率分布来解决。如此便可以证明一个定理——即使地球和冥王星之间存在量子纠缠，类似的事实在量子情况下同样成立：在这里你选择做的任何事情都不会改变局部量子状态（即密度矩阵）。这就是与爱因斯坦的担忧相反，量子力学与狭义相对论相一致的原因。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;这种情况下，相对论、量子力学、计量理论、密码学、人工智能以及其他 500 个可能的领域都可以总结为「没有差异的区别不能算作区别」。这个总结可能会使一些读者想到 20 世纪早期的逻辑实证主义教义，或者想到波普尔所坚持的理论：从不冒险伪造预测的理论都是伪科学。然而我们没有必要冒险做出关于实证主义者或波普尔究竟是否正确的复杂辩论（或者实证主义本身是实证主义的还是可伪造的）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们只要记住一个简单的道理就足够了，那便是——世界真实存在于我们的感觉之外，但我们不能坐在扶手椅中便说出它的态由什么组成。我们的工作是围绕最优的科学理论创建本体，而不能本末倒置。也就是说，我们应实时修改对于「实际存在」的概念，将我们所发现的可以通过观察来区分的新事物包含进来，并排除不能区分的事物。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有些人发现把自己的本体限制在态的程度似乎远远不够，只达到解释观察的程度。但考虑到替代时，Charlatans 这个种族主义者的每个有说服力的忠告都在不断地激励我们超越系统的态，到达它隐藏的本质，并在没有要求的地方做出区分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;甚至在自由意志中的许多困惑也存在对「态」概念的不清晰。许多人认为，根据物理学，你未来的选择由宇宙的当前状态所「决定」。但这忽视了一个事实，即无论何种物理学都需要与该主体契合，宇宙的当前状态总会被认为秘密地决定未来的选择，而这确实是隐藏变量所解释的量子力学，如 Bohmian 力学。对我来说，这使得「决定（determination）」这一概念在这些讨论中几近空洞，而实际的可预测性更为重要。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;态是应当广为人知的科学概念，因为在我看来，这其中蕴含着全部的科学世界观。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Joshua Bongard，佛蒙特大学威诺德计算机科学教授，《How the Body Shapes the Way We Think》一书作者&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;科学术语：符号接地问题（The Symbol Grounding Problem）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;阿兰·图灵二战期间的合作者 I.J. Good 曾经写道，比人类更聪明的机器将是我们所做的「最后发明」。许多人认为社会将走到这一步，因为智能机器正愈加侵入我们的日常生活和想象力，而这种入侵正沿着两条战线前进。这些机器愈发被扣上诱发经济变革的帽子，导致一些人质疑工作的必要性。但更深层的是，我们不知道这样的超级智能机器是否会「和我们一样」：他们可能会思考，但他们有感觉吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;为了帮助锚定后面的问题，Stevan Harnad 提出了符号接地问题（symbol grounding problem）。对机器而言，通过将所听到的单词直接转换为口语来学习构成人类语言的符号的意思是有问题的。这就像试图使用词典学习埃及象形文字，其中每个象形文字是使用其他象形文字定义的。下面来看我刚刚与网络上功率最大的聊天机器的交流内容：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我：你好。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;它：你好，最近过得怎么样？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我：不错啊，你呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;它：我过得很好，谢谢。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我：我最近一直在思考。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;它：思考什么？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我：符号接地问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;它：你可以给我讲一个令人开心的故事吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;符号接地问题的解决方案是使符号在物理经验丰富的土壤中接地。例如，机器人可以知道符号「跳跃（jump）」与其脚底压力的突然消失有关。这个机器人可以通过让一个人跳跃，观察她的双脚离开地面，并推断这个人类的感觉与它在跳跃时的感觉相同来与人类共情。最后，这样的机器可以递归地将已接地的符号中越来越抽象的符号接地，直到最终它可以在第一次听到成语「don』t jump to conclusions」时理解为「三思而后行」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;公众理当关注这个看似神秘的认知科学角落，因为不以这种方式将符号接地的机器会很危险。来看我与这个聊天机器的交流：它不仅不知道它最后的回复是「错误的」，也没能预测我对于它的回复会感到沮丧还是开心。同样，另一台机器也可能无法预测我对于它的行为的恐惧反应。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如今机器可以在接收到一百万张包含人类的照片和另一百万张不含人类的照片之后，不必经历接地符号便可分辨新照片是否包含人类。但换成由两百万段对话组成的数据集：第一百万中，演讲者正在讨论如何最好地帮助 Bob; 在第二百万中，他们在密谋伤害他。就算目前最先进的机器也不能分辨一个新的对话中的发言者是想帮助还是伤害 Bob。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大多数人可以通过听一段谈话来预测被讨论的人是否处于危险之中。因为我们在现实生活、书籍和电影中听过足够的讨论，从而能够延伸至当前的谈话，而不像在之前未见到的照片中识别人类的计算机，所以我们也许可以对电脑也这样做。然而，我们也可以通过连接词，图像和亲身体验来感同身受：我们可以处于谈论 Bob 的人的立场中或 Bob 自己的立场中。如果一个人说「善有善报」，并伴以一个讽刺的嘲笑，我们可以提取这些语言符号（「一个」，「好」，...）且结合视觉提示，并做一些心理模拟。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先，我们可以回溯并假装自己是 Bob，并想象他/我们的行为减缓了讲话者的饥饿或消融了另一个身体或情感的痛苦。然后我们做回自己，想象她会说的话。我们不会像她那样做出讽刺的嘲笑，我们的预测失败了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以我们再次想象自己是 Bob，但这次精神上模拟在某种程度上想要伤害讲话者。在此行为期间，我们再转变为讲话者并遭受她的痛苦。回到现在，我们想象自己说同样的话，并且预期中报复的感觉出现了，于是我们做出冷笑来匹配讲话者的嘲笑。故而我们预测，讲话者想要伤害 Bob。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;神经科学越来越多的证据表明，听到的词点亮了大部分的大脑，而不仅仅是某些本地化的语言模块。这会不会表明一个人扭曲的话、行动、自己之前的感受经历和精神抢到了感官/行动/经历的编织电缆？这些电缆可以作为从他人的行为和感觉转到我们自己的行为和感觉，而后再返回去的桥梁吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些机器可能是有用的，甚至能够共情。但它们会有意识吗？意识是目前科学无法达到的，但我们可以思考。倘若我「感觉」你的痛苦，主体和客体是清晰的：我是主体，你是客体。但倘若我感到自己脚趾的疼痛，主体和客体的区分便不那么明显了。或者他们是一致的？如果两个人能够通过彼此的共情相连，当我伤害自己时，我的大脑的两个部分不能共情吗？也许感觉是动词而不是名词：它们可能是细胞群之间的特异性交换。那么，意识可以不仅仅是一个更小的上接接地符号的感觉/运动/经验的分支的分形安排吗？如果神话告诉我们地球是平的，并且放在一只巨龟的背面，我们可能会问什么拿着乌龟。答案当然是：一直都是乌龟。所以也许意识也一直只是细胞群之间的同感。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Roger Highfield，Science Museum Group 外事部门负责人、 Supercooperators 作者之一、复杂度前沿者&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;科学术语：可以采取行动的预测（Actionable Predictions）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;对显而易见的事根本不值一提的想法一般不会被怪罪，更不用说它即将成为一种文化越来越流行。毕竟，「pre」意味着「以前」，因此毫无疑问你应该在得到预测后采取行动来改变你的未来——举个例子，就像大雨要来了买伞一样。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;天气预报确实是一个促使你采取行动的预测的例子，是从卫星和各处传感器汇总过来的数据与模型的完美结合。但是当你的视线从物理科学转移到医学，这些预测却很难辨别。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;在医生能够针对每个患者做出规范的、可信并能够采取行动的预测上，我们仍有很长的路要走——哪种治疗会对患者的帮助最大，哪种药会对患者的副作用最小等等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;很遗憾，对于很多简单的问题，答案依然不易捉摸。我应该因为嗓子疼而吃抗生素吗？免疫疗法对我管用吗？那个长长的药品副作用清单中的哪部分应该引起我的注意？对我来说最好的食谱安排是什么？如果我们能像气象学家预测明天的天气那样预测出每个患者需要的答案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;今天很多人讲大数据可以提供所有答案。在生物学上，举个例子，曾经，人类基因工程所得到的数据曾经为我们带来了很大的希望和愿景——如果我们获得一段病人的 DNA 序列，我们可以预测它们最后的衰亡。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;抛开基因组的扩散、表观基因组、蛋白质组和转录物组不谈，情况已经比预想的糟糕了，最初有关个性化定制的基因药物的梦想已经降格成了精确药物，在这里我们假定一个特定的人会与之前研究过的基因相似的人群相同的药物反应。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;生物学领域里盲目地搜集大数据依然盛行，不过重点突出变换技术，比如机器学习—人工神经网络—来发现所有数据中有意义的特征。但不管它们多「深」多复杂，神经网络仅仅是尽可能适配了可用数据的变化曲线。它们也许能做插值，但对于超过训练范围的外扩，效果依然让人忧心忡忡。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;数据的量并不是能成为解决问题的全部。我们是收集了很多数据，但是我们收集到保质保量的数据了吗？我们能从一系列错误的关联关系中分辨出有用信号吗？假定身体是动态且不断变化的，数据的即时记录样本真的能记录下生命的全部复杂性吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;为了得到医学上有效的预测，我们同样要在生物学的数学建模中进行一个改变，这改变很好理解：细胞是非常复杂的，更不用说器官和身体了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;我们应该增加对复杂系统的研究兴趣，以使得我们能预测单个病人的后续发展。而不是从早期传播研究中推断应该存什么，谁开的新处方，谁没有，谁有严重的副作用。我们需要更深入的探究，至少不能到死后尸检的程度，这可以防止成千上万的人免于人为医疗事故的伤害。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;最终我们需要在医学理解的基础上更好的开展建模，只有这样，终有一天，你的医生可以在你的数字分身上做实验，而后才是你。现代医学需要更多的可操作的预测。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Daniel Rockmore，达特茅斯学院 Neukom 计算科学学院主任、数学教授、计算科学 William H. Neukom 1964 终身杰出教授&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;科学术语：电车问题（The Trolley Problem）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;科学的历史是由各种各样的「思想实验」堆成的。「思想实验」这个词是爱因斯坦想出来的，它的意思是针对一个虚构的场景，在这个场景中能够精精准的表达一些难于思考的问题症结，以这种方式能够激发一些就此问题的深度思考最终得到解决方法或者相关发现。这些「思想实验」中最著名的是爱因斯坦的「追光传说」，最终促使他发现了狭义相对论。还有薛定谔的猫，它被困在一个刻意严格设计的量子机械盒里，永远半生半死，这更加明晰地揭示了波动理论机理与测量间的复杂交互关系。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「电车问题」是另一个思想实验，它源自于道德哲学。它有许多的流传版本，这就是其中一个：一个有轨电车沿着铁轨行驶，遇到了一个铁轨分叉点，其左方向上，有一个人被困在铁轨上，右方向上则是五个人。你可以改变分叉点以使电车从朝向五个人的方向变为一个人的方向。你会怎么做？这个电车无法刹车。如果铁轨上的人中有我们的熟人我们会怎么办呢？也许如果其中一个是儿童而另外五个是成年人呢？又或者是其中一个有孩子而其他五个是单身呢？所有这些不同的场景如何来决定事情的发展变化呢？什么是至关重要的？你更珍视什么以及为什么？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是一个有趣的思想实验，但在很多时候远不是这样仅仅有趣而已。鉴于我们正逐渐将我们的决定赋予管理这些事情的机器和软件，开发人员和工程师将要做越来越多这样需要解析那些重要并很有可能潜在关乎生死的决策机制的事情，并把这些事情直接编码给机器。决策机制来源于一种价值评估系统，一种「效用方程」，在这种系统中我们决定做这件或那件事原因在于这样做比其他选择能获得更大的价值。有时这种价值评估看上去很平常且显而易见——推荐给你这个食物搅拌器而不是那个是因为你有更大的概率买这个，这是基于各种各样历史上的购买数据得出的结论。这双鞋比其他的更好卖（或者不算更好卖但起码因为它某些方面利润更高所以值得一试——这使得我们愿意计算概率和期望的回报）。这首歌对比那首歌等等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;但有时在紧要关头它会更重要：是这条新闻还是那条？更广泛意义上来说，是这件事的这条信息还是那条信息？嵌入价值评估体系的程序可以开始评估你的价值了，并以此类推以至于整个社会的价值。有一些是价值相当大的决策赌注了。电车问题告诉我们价值评估体系渗透在编程的方方面面，甚至有时关乎生命：很快我们会有无人驾驶的电车、汽车、卡车。当糟糕的事情发生了，决定就需要做：事故车道上的骑车少年还是停在前面车里的世界 500 强公司的 CEO 和他的助理？你的算法会怎么做以及为什么这么做？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们终将制造出无人驾驶汽车而它们也一定会具备道德指南。我们的机器人伴侣也是一样的情况。它们会有价值评估体系且必然是受道德约束的机器，而它的道德和伦理是由我们设计的。「电车问题」是我们时代的思想实验，它是我们新人机时代工程高度复杂的光辉体现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Bruno Giussani，TED 欧洲办事处主任及全球活动策划人&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;科学术语：指数（Exponential）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（有关指数的这一小故事）已经不清楚当时用来计数的是米粒还是麦粒了，由于故事有很多版本，我们对故事的起源也不太确定。但故事的内容大致是这样：国际象棋的发明者向国王展示了有趣的象棋游戏，国王甚是开心，便要求象棋发明者自己点名要奖赏。象棋发明者谦虚地要了些米粒（或者是麦粒），具体数量通过最简单的公式计算得出，即第一个格子 1 粒，第二个格子 2 粒，第三个格子 4 粒，依次往下格子中谷粒的数量翻倍，直至第 64 个也就是最后一个。国王欣然同意，直到发现自己已经受骗。到棋盘一半时，国王的城堡就几乎不够存放谷物了，但剩下棋盘中的第一个格子就会将谷粒数量再翻一倍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从 13 世纪的穆斯林学者到物理学家/作家卡尔·萨根（Carl Sagan），再到社会传媒界的电视录像制作人无不引用该故事来阐释指数序列的威力，事务起于微小，非常微小，但之后一旦开始增长，就增长地越来越快—按欧内斯特·海明威（Ernest Hemingway）的说法：成长缓慢，然后突然暴涨（they grow slowly, then suddenly）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;每个人都应该更深刻地知道并理解指数及其衍生（棋盘寓言是一个非常实用的比喻），因为我们生活在一个指数世界。实际上，这种情形已经存在一段时间了。但是，目前为止我们处在棋盘的上半部分，也就意味着由于我们即将进入棋盘的下半部分，事物将急剧加速发展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1999 年雷·库兹韦尔（Ray Kurzweil）在他的著作《灵魂机器的时代》（The Age of Spiritual Machine）中提出了「后半个棋盘」的概念。他指出，尽管指数在前半个棋盘时重要，但正是在进入后半个后其影响变得巨大，事情变得疯狂，其加速度开始远超人类的想象和控制。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;15 年后，Andrew McAfee 和 Erik Brynjolfsson 在《第二次机器时代》中通过对比摩尔定律来讨论库兹韦尔的观点。戈登·摩尔（Gordon Moore）是仙童公司（Fairchild）和英特尔公司（Intel）的联合创始人，这两个公司是硅谷很有开拓性的公司。回顾硅晶体管刚发展的前几年，在 1965 年摩尔做出了一个预测，在给定的成本下，大约每 18 至 24 个月，计算能力会翻一番。换句话说，也就是呈指数级增长。摩尔的预测已经维持了数十年，对科技与商业带来了巨大的影响，尽管近些年节奏有一点点放缓——需要指出的是摩尔定律是一个产业规律的洞察定律，而非物理定律，而且，我们很可能从晶体管时代迈进量子计算的时代，而后者依赖粒子来进行计算。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;McAfee 和 Brynjolfsson 认为，如果我们把摩尔定律的起始点定为 1958 年，即第一个硅晶体管商业化的时间，那么依指数曲线，从数字技术的角度看，我们进入棋盘第二部分的时间是 2006 年（这种观点是考虑到，人类基因组第一次绘制完成是在 2003 年，当前智能手机操作系统启动是在 2007 年，同一年 IBM 的 Deep Blue 在象棋比赛中打败了 Garry Kasparov，同时耶鲁大学的科学家开发出第一个固态量子处理器是在 2009 年。）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此，我们会发现我们自己正处于棋盘第二部分的第一个，可也能是第二个格子中。这有利于帮助我们理解我们所见的在科技领域发生的引人注目的高速进步，这些进步表现在从智能手机、语言翻译、区块链到大分析、自动驾驶和人工智能的领域，从机器人学到传感器，从太阳能电池到生物技术，再到基因组学和神经学及更多其他领域中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当这些领域中的每一个其自身都呈指数级增长时，它们的组合效应——每个对其他领域的加速性影响是巨大的。另外还要加上人工智能系统自我改进能力的空间以及我们正在聊的近乎不可思议的改变速度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;还是以最初的棋盘寓言作为比喻，进入棋盘的第二半部分意味着:到目前，谷粒是以越来越快的速度累积着，但还在国王城堡能容纳的限度内。但之后格子的谷粒就会淹没这座城市，然后淹没这片土地，这个世界。之后仍然有 32 个格子还要走，所以这将不是一个短暂的转变期，而将是一个长期、深度、史无前例的剧变。这种发展将带领我们进入一个物质丰富，并以技术为驱动的新兴时代，我们的权利和/或希望与坠入无法控制的黑洞等其他忧虑一样多。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然，我们仍然生活在一个对其大部分都不甚了解的世界，这部分也不适用于指数规律。基本上社会运行的每一结构和方法——政府机关、民主、教育和医疗系统、法律和规范性框架、出版业、公司、安全防范设施，甚至科学管理本身都被设计为在一个可预测的线性世界发挥作用，在此，猛然上升或下降被看作为危机。因此，我们几乎每天都在见证的各种指数级变化所带来的从政治到社会再到心理学方面的忧虑及压力也就不足为奇了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在没有深入思考，深思熟虑和细致入微关注的情况下，我们该如何以指数式思维思考问题？在棋盘第二半的现实条件下，社会该如何运行？在指数型社会中，政府治理与民主的意味着什么？我们又该如何重新审视从教育到法律框架再到伦理与道德理念的诸多事宜？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些事情都开始于对指数和「后半个棋盘」的比喻更好的理解，以及将这种「后半程思考」的思维方式施加到几乎所有事情上所带来的结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 25 Jan 2017 12:24:58 +0800</pubDate>
    </item>
    <item>
      <title>前沿 | D-Wave再度升级：研发出2000量子比特量子计算机</title>
      <link>http://www.iwgc.cn/link/4482150</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Nature&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;参与：微胖、朱思颖&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;要发掘出量子计算的真正潜力，我们可能还需要再等几十年，而 D-Wave 正在向着这个目标大步迈进，2016 年，这家公司承诺将在明年推出其已经得到了大幅改进的量子处理器。（&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719333&amp;amp;idx=1&amp;amp;sn=468fef3ccbeab4a270095b5dd635ea25&amp;amp;chksm=871b001bb06c890d14a1f254c517d1d6916e3cf69be9c79b8b4a9eb127b2eeda447edb063203&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650719333&amp;amp;idx=1&amp;amp;sn=468fef3ccbeab4a270095b5dd635ea25&amp;amp;chksm=871b001bb06c890d14a1f254c517d1d6916e3cf69be9c79b8b4a9eb127b2eeda447edb063203&amp;amp;scene=21#wechat_redirect"&gt;量子计算大跃进？D-Wave 将于明年推出 2000 量子比特芯片&lt;/a&gt;）。目前，公司发布的最新机器模型已达 2,000 量子比特。虽然有关 D-Wave 最终潜力的质疑不绝于耳，但是，研究人员已在寻找这一机器的用武之地。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicfJFax3rHUWXK8QUmf7aiaiaQLdXuOj0kCp67ltO5DIlPRwyU7BicfX0Byz3hciaLde9AXHI4FbGVQVQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;D - Wave 最新处理器可以处理 2,000 量子比特，远超之前的模型能力。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这家打造世界上唯一商用量子计算机的公司已经发布了到目前为止，公司最大的机器，而且研究人员也正在密切关注着。加拿大 D- Wave 公司用处理器的量子比特数命名的这台 2000Q，其能力远超之前模型。不同于其他尚出初期的量子计算机，长远来看，D-Wave 这类机器潜力如何，不少研究人员仍持怀疑态度。不过，也有其他研究人员已经认为用 D-Wave 解决机器学习、网络安全等难题已指日可待。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而且这次升级到 2000Q，亦即公司的第四代机器，已经大量吸取了研究人员反馈。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;NASA 阿姆斯研究中心的物理学家 Davide Venturelli 说，「我们正以科学家团体的身份对他们进行指导」。Davide Venturelli 正负责管理一个由非盈利组织——位于华盛顿的大学太空研究联合会（Universities Space Research Association，USRA）运营的计划，旨在让外部研究人员接触到一台 NASA 和谷歌共同拥有的 D-Wave 计算机。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;据悉，D-Wave 也正在研发第五代模型，有望解决诸如更大功能、更多连接性等问题，希望能更加满足科学家研究需求。这一模型的研发工作可能在两年内启动，并再度翻倍既有量子比特数，达至 4，000 量子比特。关键是，新模型还能提供更加复杂的量子比特连接，让机器具有解决更加复杂问题的能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;位于布拉格的 Charles University 物理学家 Mark Novotny 说，「改变底层连接会改变游戏规则，」他正在研究如何将 D- Wave 应用到网络安全上，「基本上，我很渴望实现这一点。这太激动人心了。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;六年前，当 D- Wave 上市后，这台机器不仅让众人惊喜，也招致了不少怀疑。到目前为止，研究人员已经证实，对于某个契合这台机器能力的问题来说，量子计算机会大大提升处理该问题的速度，力压传统算法（V. S. Denchev et al）。但是，这类机器并没有在每种传统算法上击败传统对手，人们还没有发现在解决哪个问题上，这类机器比所有传统对手表现更好。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;较之于在更加传统的量子计算中建造量子比特，D-wave 要容易多了，但是，其量子状态也更加脆弱，控制精确性也更弱些。因此，尽管科学家现在认为 D-Wave 确实在计算过程中利用了量子现象，但是，一些人仍然怀疑这个办法在解决真实世界难题上，其速度会快过传统计算机——无论许多量子如何协作，也不管其布局如何。不过，不确定性无法阻止用户数量增长：去年九月，大约 100 名科学家参加了 D-Wave 首批用户会议，大会在新墨西哥州的圣达菲举行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现有的 D-Wave 计算机都在美国，不过，全球研究人员都能远程接触到它们，包括参加诸如 USRA 这样的项目。计算机也正在吸引着新的研究人员，Venturelli 说，他正在尝试用 D-Wave 找到探测器自动安排运行时间、管理时间的最佳方法，他说，「现在，那些不涉及量子物理研究的大学也在尝试它们的算法。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;和其他量子计算机不同，D-Wave 仅用来解决某个问题，诸如优化问题。为了找到最优解决方案，研究人员首先将由超导回路（superconducting loops）打造的量子比特置入其最低能量状态，在这一状态下，每个都处于一个「开」、「关」叠加状态。然后，表征问题的磁场会轻轻将这一状态推进到一个新的状态下——亦即所谓的量子退货法。状态不断演进的同时也持维持着低能量状态，这样，当最终发生「坍塌」时，量子比特就能处在用来解决问题的最佳配置状态。因为系统会立刻筛选每个可能的答案，理论上，它就能以更快的方式解决难题，如果使用传统计算机解决这个难题，每增加一个变量，解决问题的难度会呈指数增长。但是，能以机器可以处理的方式提出研究问题意味着使用几个量子比特来表征某个单独变量，限制机器可以处理的问题的规模大小。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicfJFax3rHUWXK8QUmf7aiaia724sMwURZm46a9sM2cgu8cXEgTfYV2CF8lKzqA5lfvm68gfH5tAibRQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;一台 D-Wave 机器正在研究星球探测车如何能自动进行任务、时间管理。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Novotny 说，「量子计算是一个新工具，所以，我们目前工作的一部分就是试图找到新工具的使用方式。」他正在研究机器学习算法（波兹曼机），用它来研究在线浏览量模式，识别出网络攻击。到目前为止，他的团队已经可以证明，对于小型样本，在识别诸如可能的网络攻击等方面，D-Wave 要比传统对手更高效，也更快速。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;D-Wave 最新迭代包括一个 Novotny 呼吁过的升级。当不同量子比特组经历退火过程时，这一升级后的特征能增加过程的可控性。D-Wave 已经表明，至少在一个例子中，它将某次计算速度翻 1，000 番。对于 Novotny 来说，这一功能很关键，这样，他的团队就能在过程中「取样」量子比特，也为利用 D-Wave 探索不同类型的机器学习算法（识别更多复杂的网络攻击模式）打开了一扇门。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是，研究人员期待更大连接性。Scott Pakin 是位于新墨西哥洲的**洛斯阿拉莫斯国家实验室的计算科学家，也是 D-Wave 科学技术负责人，去年八月，他拥有了一台 D-Wave 计算机。他说，**目前，处理器只能实现每六个量子比特之间的对话，「连接越丰富，用 D-Wave 解决问题就更容易，也更快。所以，这也是我最期待的一点。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;D-wave 正在重新设计其第五代处理器来大幅提升联结度，D-wave 负责技术的高级副总 Jeremy Hilton 说道。同时因为这次的提升涉及到硬件的彻底检修，新一代处理器将具备一个额外的好处：允许公司超越当前处理器设计设置的 10，000 量子比特的限制，他补充说。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;距离 D-wave 倡导者所希望看到的——量子计算机运行速度是普通计算机运行速度的指数倍这一愿景，还有很长一段路要走。但是，一篇于 1 月 17 日发表的尚未进行同行评议的论文中，D-wave 的一个团队宣称其 2000Q 处理器解决问题的速度，是当前任一知名传统算法速度的 2600 倍（J. King et al. 2017）。现在轮到怀疑派们去找更快的传统算法了。德州大学奥斯汀分校的计算机科学家 Scott Aaronson 说，「据我所知，就这种情况，过去也遇到到两三次，结果，确实有一个不同的传统解决方法消除了所宣称的差距。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Hilton 认为，今年 D-wave 将证明完成即使是最强劲的传统超级计算机都不可能实现的计算，他们的这个目标被竞争对手称为「量子霸权」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「我们已经取得一些结果了，」他说，「我们正在与外部合作者一起审核这些结果，看看能否经得起检验。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相关链接：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720969&amp;amp;idx=1&amp;amp;sn=d5723c205f594616932624684d3a1327&amp;amp;chksm=871b0eb7b06c87a1d4d9809b35c361a4d8a4bf75315eaa9502a051058b184fb233e5b2d2695c&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650720969&amp;amp;idx=1&amp;amp;sn=d5723c205f594616932624684d3a1327&amp;amp;chksm=871b0eb7b06c87a1d4d9809b35c361a4d8a4bf75315eaa9502a051058b184fb233e5b2d2695c&amp;amp;scene=21#wechat_redirect"&gt;Science：实用量子计算机已近在咫尺&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721997&amp;amp;idx=2&amp;amp;sn=a7ae3e6f57d41c4c10464422f60fc7de&amp;amp;chksm=871b0ab3b06c83a58926ff6f313d63d94fa9f3afc9433f23047174cb78f99617b17699ac3322&amp;amp;scene=21#wechat_redirect" target="_blank" data_ue_src="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650721997&amp;amp;idx=2&amp;amp;sn=a7ae3e6f57d41c4c10464422f60fc7de&amp;amp;chksm=871b0ab3b06c83a58926ff6f313d63d94fa9f3afc9433f23047174cb78f99617b17699ac3322&amp;amp;scene=21#wechat_redirect"&gt;Nature：量子计算机或将在 2017 年走向实用化&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 25 Jan 2017 12:24:58 +0800</pubDate>
    </item>
    <item>
      <title>业界 | Quora 第一个开放数据集：相似问题对构建语义理解</title>
      <link>http://www.iwgc.cn/link/4482151</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Quora&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：蒋思源、朱思颖&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;Quora开放了第一个数据集，希望通过这40万行的问题对整合相同提问成同一页面，促进自然语言的语义理解，自动识别与整合，加强知识共享平台的建设。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今天我们很高兴地宣布过去计划发布的一系列公开数据集中的第一个成功开放。我们开放的数据集将面向与 Quora 相关的各种问题，并且旨在帮助在机器学习、自然语言处理、神经网络科学等领域的研究人员能够自行构建可扩展性的在线知识分享平台。我们第一个数据集与识别重复性问题相关。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Quora 一个重要的产品原则，即每一个逻辑独立的问题应该只需要一个单独的问题页面。简单地说，如询问「美国哪一个州人口最多？」和「在美国人最多的州是哪个？」，这两个问题不应该在 Quora 单独地存在，因为两个问题所要表达的意图是完全相同的。如果每一个页面都是一个逻辑独立的问题，那么就能在很多方面上让知识分享更加地高效。如知识查询者可以在一个位置查看问题的所有答案，并且如果读者群体因为不同的页面而分割，那么回答问题的作者可以获得更高的阅读量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了大规模减少低效的重复问题页面，我们需要一种自动化的方式来检测问题文本实际上是不是在语义上和其他问题相等。这在机器学习和自然语言处理上是很具挑战性的问题，并且也是我们一直在寻找更好解决方案的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们今天发布的数据集将让任何人可以根据实际的 Quora 数据来训练和测试语义等价模型。我们希望看到是解决这个问题的多样性方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们数据集所包含的潜在重复问题对（duplicate pairs）超过 40 万行。每一行包含问题对的问题 ID 编号、完整文本以及一个表明这一行是否真正含有重复问题对的二进制值。以下这张图是我们数据集中一些行的示例：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicfJFax3rHUWXK8QUmf7aiaiabcVQEX58LECeZ2uw6sbAJQJPBiaEx4icQiblWzUPibs91X4wXYn9PK3AYg/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关于这个数据集的必知要点说明：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;我们初始采样方法得到的是一个不均衡的数据集，即数据集中重复问题对（二进制值为真）的数量远远多于非重复问题对的数量。因此，我们补充了数据集中非重复问题对（二进制值为假）的数量。非重复问题对的一个来源是构建相关问题对，相关问题对中的问题尽管是属于相似的主题，但在语义上并不是完全等价的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;数据集中问题的分布情况并不能代表 Quora 里所问问题的分布情况。部分是因为抽样过程的系统性操作和运用了一些数据清洗方式（sanitization measures）来完成最终数据集的构建（例如：去除了包含细节描述的极长问题）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;真值标签（ground-truth labels）含有一定量的数据噪点：并不能保证所有的标注都完美无错。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们的数据集在 S3 上托管，只允许非商业使用且使用条件取决于我们的服务条款规定。你可以通过这个链接下载数据集：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;http://qim.ec.quoracdn.net/quora_duplicate_questions.tsv&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 25 Jan 2017 12:24:58 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 为推进科学研究，谷歌呼吁建立标准的数据生态系统</title>
      <link>http://www.iwgc.cn/link/4482152</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Google Research Blog&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：李泽南、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote style="max-width: 100%; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;谷歌希望在人们的努力之下，我们最终能够像搜索论文一样轻松找到自己想要的数据集，新的标准是努力的第一步。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前网络上有数百个数据库，它们提供了数以百万计的数据集。这些数据的提供者包括国家和地方政府、科学和出版机构、数据供应商等等，数据的涵盖面从社会科学、生命科学到高能物理、气候科学，几乎无所不包。这些数据对于促进研究结果的重现至关重要，能够让科学家在前人的基础上继续探索，让数据挖掘者可以更轻松地接触信息，探究它背后的意义。出于这些原因，很多出版者和资金提供者现在要求科学家们尽量公开他们的数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而，由于网络上数据存储的数量庞大，人们会发现难以寻找自己需要的数据集，同时无法核实信息的来源和真实性。搜索数据集本应该像搜索食谱、工作甚至电影一样简单——那些类型的搜索通常是开放式的，能够偶然的发现搜索空间中的某些结构。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了让书籍、电影、活动、食谱、评测和一系列其他类型的搜索在谷歌引擎上有更佳表现，我们依赖于各网站上嵌入 schema.org 词汇的结构数据。为了促进数据集实现类似的功能，我们最近发布了一个新的指导帮助数据提供商以标准的形式形容他们的数据集，让谷歌和其他的搜索引擎可以连接到这些结构化元数据描述的地理位置、出版商甚至知识图谱，以便被使用者发现。我们希望这些元数据可以帮助网上公开的信息能够更有效地被人们使用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Schema.org 上形容数据集的方式基于最近在 W3C（Data Catalog Vocabulary）上的标准化成果，我们认为它是在未来不断完善描述和改进数据集索引的第一步。虽然各领域还在不断讨论，但我们认为这一标准已经为构建数据生态系统打下了坚实基础。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;技术挑战&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然我们已经发布了元数据的索引指南，但在轻松搜索数据集之前我们还面临着很多技术挑战。这些挑战包括：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;数据集定义的一致性：例如，单一表格和大量表格的集合都算是一个数据集吗？如果都是，蛋白质序列呢？图片集合呢？用于链接数据的 API 呢？我们希望获得更多关于数据提供者的定义、解释以及使用方式。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;数据集的识别：在理想状况下，数据集应该拥有一些被所有人认可的永久标识，让数据集具有唯一性，但在一些情况下这还不现实。原数据界面的 URL 或许是作为标识符的不错选择，我们需要提供多种标识符吗？如果有多重标识的话，需要选择一个主要标识吗？&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;彼此间关联数据集：什么时候两种记录能够统一的描述一个数据集？（例如，万一 repository 从其他人那里复制来元数据呢）如果数据整合方（aggregator) 在一个数据集上加入了更多的元数据，或者以有益的方式清洁了数据呢？我们正在研究如何明晰、定义这些关系。但是，元数据的消费者不得不假定这些数据提供者不准确描述的数据，并忍受这种情况。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在相关数据集间传播元数据：在相关数据集之间我们能够传播多少元数据？例如，我们可能从合成数据集到它包含的子数据集来传播出处信息。但经过这样的传播，元数据有了多少的退化？我们预期根据不同的应用退化程度不同：搜索应用的元数据可能要比数据融合的精确度更低。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;描述数据集的内容：数据集要包含多少的描述内容，从而使得能够进行类似于 Explore for Docs, Sheets and Slides 中使用的查询，或者进行数据集的其他探索与重复使用（当然是在许可之下）？我们如何高效的使用供应商使用 W3C 标准已经描述的内容？&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除了我们已经列出来的技术和社会挑战，剩下的许多研究挑战涉及到长期的开放式研究：许多数据集是用无结构的方式描述的，包括科学论文形式的说明、图解、表格，以及其他文档。我们能建立提取元数据的其他有前途的方式。虽然我们有合理的排序网页搜索内容的方式，而排序数据集是个挑战：我们不知道排序网页的 signals 是否同样适用于数据集。在数据集内容是公开且可用的情况下，我们可能能够提取数据集中额外的语义，例如，学习不同领域的值类型。但是，我们是否能够足够了解内容，从而能够进行相关资源的数据融合于挖掘？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;呼吁行动&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对任何生态系统而言，一个数据系统只有在大量人员共同贡献的情况下才会繁荣，因此我们呼吁：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;个人和数据仓库提供者：使用 schema.org、DCAT、CSVW 等社区标准公布结构元数据，这能使得其他人发现、使用这些元数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据消费者（科学家到数据新闻更作者等）：更准确的引用数据，如同我们引用科学论文一样。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;开发者：为 schema.org (http://schema.org/) 元数据的数据集的拓展做出贡献，提供专业领域的词汇，以及研究使用这一丰富元数据的工具与应用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们最终的目标是帮助建立一个公布、使用、挖掘数据集的生态系统。如此以来，该生态系统将会包括数据发布者、整合者（大型数据仓储方提供数据清洗、调和元数据等价值）、挖掘数据的搜索引擎、以及更重要的数据消费者。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Wed, 25 Jan 2017 12:24:58 +0800</pubDate>
    </item>
    <item>
      <title>教程 | 没有博士学位，照样玩转TensorFlow深度学习</title>
      <link>http://www.iwgc.cn/link/4468818</link>
      <description>&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;选自Codelabs&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;参与：侯韵楚、王宇欣、赵华龙、邵明、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;本文内容由机器之心编译自谷歌开发者博客的 Codelabs 项目。据介绍，Google Developers Codelabs 提供了有引导的、教程式的和上手式的编程体验。大多数 Codelabs 项目都能帮助你了解开发一个小应用或为一个已有的应用加入新功能的过程。这些应用涉及到很多主题，包括 Android Wear、Google Compute Engine、Project Tango、和 iOS 上的 Google API。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;本项目的原文可参阅：https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/#13&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1、概述&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdO9nh6G6U3pVLCbOeUqDhb7FmXngMrVGicdQjKCicL42g3lfvr6eYvpjdQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 codelab 项目中，你将学习如何构建并训练出能够识别手写数字的神经网络。在这过程中，当这个神经网络的准确度提升至 99％时，你还会发现深度学习专业人士用来有效训练模型的贸易工具。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个 codelab 项目使用的是 MNIST 数据集，这个包含 60,000 个有标记数字的集合是几届博士努力近二十年的成果。你将会用不到 100 行的 Python/TensorFlow 代码来解决上述问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你将学到：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;①神经网络的定义及如何训练神经网络&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;②如何使用 TensorFlow 构建基本的 1 层神经网络&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;③如何添加多层神经网络&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;④训练提示和技巧：过拟合、dropout、学习速率衰减等...&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;⑤如何解决深度神经网络的问题&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;⑥如何构建卷积网络&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对此，你将需要：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;①Python 2 或 3（建议使用 Python 3）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;②TensorFlow&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&amp;nbsp;③Matplotlib（Python 的可视化库）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;安装说明会在下一步中给出。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2. 准备：安装 TensorFlow，获取示例代码&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在你的计算机上安装必要软件：Python、TensorFlow 和 Matplotlib。完整的安装说明如下：INSTALL.txt&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;克隆 GitHub 存储库：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;p&gt;$ git clone https://github.com/martin-gorner/tensorflow-mnist-tutorial&lt;/p&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;这个库包含了多个文件，而你将只在mnist_1.0_softmax.py中操作。其它文件是用于加载数据和可视化结果的解决方案或支持代码。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当你启动初始python脚本时，应当能够看到训练过程的实时可视化：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;p&gt;$ python3 mnist_1.0_softmax.py&lt;/p&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOdnYBxdmmHG4vX3OQgQvn6NGt0uhzibIk0paGTXTcEibibMsolGOn4lhcA/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;疑难解答：如果无法运行实时可视化，或者如果你只想要使用文本输出，则可以通过注释掉一行并取消另一行的注释来禁用可视化。请参阅文件底部的说明。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为 TensorFlow 构建的可视化工具是 TensorBoard，其主要目标比我们在这里所需的更宏大。它能使你能够跟踪你在远程服务器上的分布式 TensorFlow 工作。而对于我们的这个实验，matplotlib 将作为替代，并且我们还有额外收获——实时动画。但是如果你使用 TensorFlow 进行严谨的工作，你一定要试试 TensorBoard。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3、理论：训练一个神经网络&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们首先来观察一个正在训练的神经网络。其代码会在下一节解释，所以现在不必查看。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们的神经网络可以输入手写数字并对它们进行分类，即将它们识别为 0、1、2……9。它基于内部变量（「权重（weights）」和「偏差（bias）」，会在后面进行解释），需要有一个正确的值来分类才能正常工作。这个「正确的值」通过训练过程进行学习，这也将在后面详细解释。你现在需要知道的是，训练回路看起来像这样：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Training digits =&amp;gt; updates to weights and biases =&amp;gt; better recognition (loop)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;让我们逐个通过可视化的六个面板，了解训练神经网络需要什么。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdODmcm4QKaZDng3wwLkeibiamawibQcicyhaNAHz5GLGmIibN1W5UnnMibQ8lA/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你可以看到训练数字每次 100 个被送入训练回路；也可以看到当前训练状态下的神经网络是已将数字正确识别（白色背景）还是误分类（红色背景，左侧印有正确的标示，每个数字右侧印有计算错误的标示）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此数据集中有 50,000 个训练数字。我们在每次迭代（iteration）中将 100 个数字送入训练循环中，因此系统将在 500 次迭代之后看到所有训练数字一次。我们称之为一个「epoch」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOVEQLNmqgibCGDVcSE09IZ2oxCmz4icXcNZFWc7DIsEuGsemBCia7F2BibQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了测试在现实条件下的识别质量，我们必须使用系统在训练期间从未看过的数字。否则，它可能记住了所有的训练数字，却仍无法识别我刚才写的「8」。MNIST 数据集包含了 10,000 个测试数字。此处你能看到每个数字对应的大约 1000 种书写形式，其中所有错误识别的数字列在顶部（有红色背景）。左边的刻度会给你一个粗略的分辨率精确度（正确识别的百分比）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOzPxBLL5PPnnv2e57GHJVN9PEBK3afcHsCnlIiaBmI0gSLndIrSm2H0A/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了驱动训练，我们来定义损失函数，即一个展示出系统数字识别能力有多糟的值，并且系统会尽力将其最小化。损失函数（loss function，此处为「交叉熵」）的选择稍后会做出解释。你会看到，随着训练的进行，训练和测试数据的损失会减少，而这个现象是好的，意味着神经网络正在学习。X 轴表示了学习过程中的迭代。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOQPiaHohibpPRNuEhnibDEV4KZmen8ibE82RcXk6vLr5TksJv2t1e0BPTWg/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个准确度只是正确识别的数字的百分比，是在训练和测试集上计算出的。如果训练顺利，它便会上升。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdO5sAVy5w2AziaPMgf5tqgpjIblWuLnXWXneDbFgtwjWRn53YP0RdW2Dg/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOVgpWsytn7tSJicLGnibvibMPFvyTOTq5Y9WnqFBrmrdzVM7UriaI2wzaZQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后的两幅图表说明了内部变量所取的所有值的扩展，即随训练进行而变化的权重和偏置。比如偏置从 0 开始，且最终得到的值大致均匀地分布在-1.5 和 1.5 之间。如果系统不能很好地收敛，那么这些图可能有用。倘若你发现权重和偏差扩展到上百或上千，那么就可能有问题了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图中的条带为百分数。此处有 7 条带，所以每条带是所有值的 100/7，也就是 14%。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;用于可视化 GUI 的键盘快捷键&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1 ......... display 1st graph only 仅显示第 1 张图&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2 ......... display 2nd graph only 仅显示第 2 张图&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3 ......... display 3rd graph only 仅显示第 3 张图&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4 ......... display 4th graph only 仅显示第 4 张图&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;5 ......... display 5th graph only 仅显示第 5 张图&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;6 ......... display 6th graph only 仅显示第 6 张图&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;7 ......... display graphs 1 and 2 显示 1 和 2 图&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;8 ......... display graphs 4 and 5 显示 4 和 5 图&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;9 ......... display graphs 3 and 6 显示 3 和 6 图&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;ESC or 0 .. back to displaying all graphs 返回，显示所有图&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;空格 ..... pause/resume 暂停/继续&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;O ......... box zoom mode (then use mouse) 框缩放模式（然后使用鼠标）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;H ......... reset all zooms 重置所有缩放&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Ctrl-S .... save current image 保存当前图像&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;什么是“权重”和“偏置”？“交叉熵”又是如何被计算的？训练算法究竟是如何工作的？请到下一部分一探究竟。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;4、理论 : 单层神经网络&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOZkicgjjyjxtjQIfmXckY18Ca5BNCe24kiaDZxfIHsMSWWibclAibqYG4QA/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;MNIST 数据集中，手写数字是 28x28 像素的灰度图像。将它们进行分类的最简单的方法就是使用 28x28=784 个像素作为单层神经网络的输入。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOBam4JXCrGU4sCnBnEyLTRAMibRJfomUdt3icX24JoKh9yGPfFOrwqpjQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;神经网络中的每个「神经元」对其所有的输入进行加权求和，并添加一个被称为「偏置（bias）」的常数，然后通过一些非线性激活函数来反馈结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了将数字分为 10 类（0 到 9），我们设计了一个具有 10 个输出神经元的单层神经网络。对于分类问题，softmax 是一个不错的激活函数。通过取每个元素的指数，然后归一化向量（使用任意的范数（norm），比如向量的普通欧几里得距离）从而将 softmax 应用于向量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOwjPHhA5qHOn4vV1qIO86TqTwcS7BWKTn30HKUiazMaNkha65ib1icUibcQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那么为什么「softmax」会被称为 softmax 呢？指数是一种骤增的函数。这将加大向量中每个元素的差异。它也会迅速地产生一个巨大的值。然后，当进行向量的标准化时，支配范数（norm）的最大的元素将会被标准化为一个接近 1 的数字，其他的元素将会被一个较大的值分割并被标准化为一个接近 0 的数字。所得到的向量清楚地显示出了哪个是其最大的值，即「max」，但是却又保留了其值的原始的相对排列顺序，因此即为「soft」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOsc1iaUWm9iaowsZT8apdVvSIticX9yA0lG7tAaszNxaUR0t5KSic1eALYw/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们现在将使用矩阵乘法将这个单层的神经元的行为总结进一个简单的公式当中。让我们直接这样做：100 个图像的「mini-batch」作为输入，产生 100 个预测（10 元素向量）作为输出。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使用加权矩阵 W 的第一列权重，我们计算第一个图像所有像素的加权和。该和对应于第一神经元。使用第二列权重，我们对第二个神经元进行同样的操作，直到第 10 个神经元。然后，我们可以对剩余的 99 个图像重复操作。如果我们把一个包含 100 个图像的矩阵称为 X，那么我们的 10 个神经元在这 100 张图像上的加权和就是简单的 X.W（矩阵乘法）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;每一个神经元都必须添加其偏置（一个常数）。因为我们有 10 个神经元，我们同样拥有 10 个偏置常数。我们将这个 10 个值的向量称为 b。它必须被添加到先前计算的矩阵中的每一行当中。使用一个称为 "broadcasting" 的魔法，我们将会用一个简单的加号写出它。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「Broadcasting」是 Python 和 numpy（Python 的科学计算库）的一个标准技巧。它扩展了对不兼容维度的矩阵进行正常操作的方式。「Broadcasting add」意味着「如果你因为两个矩阵维度不同的原因而不能将其相加，那么你可以根据需要尝试复制一个小的矩阵使其工作。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们最终应用 softmax 激活函数并且得到一个描述单层神经网络的公式，并将其应用于 100 张图像：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOGZkKwmpUrRscOIzbso4YjUhEwicnicGMXu3wSYGassaosNUv4oRDlgww/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;顺便说一下，什么是「tensor（张量）」？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「张量（tensor）」像一个矩阵，但是却有着任意数量的维度。一个 1 维的张量是一个向量。一个二维的张量是一个矩阵。然后你可以有 3, 4, 5 或者更多维的张量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;5、理论：梯度下降&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在我们的神经网络从输入图像中产生预测，我们需要知道它们可以做到什么样的程度，即在我们知道的事实和网络的预测之间到底有多大的距离。请记住，我们对于这个数据集中的所有图像都有一个真实的标签。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;任何一种定义的距离都可以进行这样的操作，普通欧几里得距离是可以的，但是对于分类问题，被称为「交叉熵（cross-entropy）」的距离更加有效。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOUNDMfnZ1HG2frK0f9UFjPUiaH2DwAD0ehdJy8wOiaNDyerSyWY8YfcQw/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「one-hot」编码意味着你使用一个 10 个值的向量，其中除了第 6 个值为 1 以外的所有值都是 0。这非常方便，因为这样的格式和我们神经网络预测输出的格式非常相似，同时它也作为一个 10 值的向量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「训练」一个神经网络实际上意味着使用训练图像和标签来调整权重和偏置，以便最小化交叉熵损失函数。它是这样工作的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;交叉熵是一个关于权重、偏置、训练图像的像素和其已知标签的函数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果我们相对于所有的权重和所有的偏置计算交叉熵的偏导数，我们就得到一个对于给定图像、标签和当前权重和偏置的「梯度」。请记住，我们有 7850 个权重和偏置，所以计算梯度需要大量的工作。幸运的是，TensorFlow 可以来帮我们做这项工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;梯度的数学意义在于它指向「上（up）」。因为我们想要到达一个交叉熵低的地方，那么我们就去向相反的方向。我们用一小部分的梯度更新权重和偏置并且使用下一批训练图像再次做同样的事情。我们希望的是，这可以使我们到达交叉熵最小的凹点的低部。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOPic4LeNISGUVD9NSvUNbsAIEWt0hkJSic3b9RLZmh0Idv5kxsk1MYLbQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这副图片当中，交叉熵被表示为一个具有两个权重的函数。事实上，还有更多。梯度下降算法遵循着一个最陡的坡度下降到局部最小值的路径。训练图像在每一次迭代中同样会被改变，这使得我们向着一个适用于所有图像的局部最小值收敛。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;「学习率（learning rate）」： 在整个梯度的长度上，你不能在每一次迭代的时候都对权重和偏置进行更新。这就会像是你穿着七里靴却试图到达一个山谷的底部。你会直接从山谷的一边到达另一边。为了到达底部，你需要一些更小的步伐，即只使用梯度的一部分，通常在 1/1000 区域中。我们称这个部分为「学习率（Learning rate）」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;总结一下，以下是训练过程的步骤：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Training digits and labels =&amp;gt; loss function =&amp;gt; gradient (partial derivatives) =&amp;gt; steepest descent =&amp;gt; update weights and biases =&amp;gt; repeat with next mini-batch of training images and labels&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;训练数字和标签 =&amp;gt; 损失函数 =&amp;gt; 梯度（部分偏导数）=&amp;gt; 最陡的梯度 =&amp;gt; 更新权重和偏置 =&amp;gt; 使用下一个 mini-batch 的图像和标签重复这一过程&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为什么使用 100 个图像和标签的 mini-batch？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你当然也可以只在一个示例图像中计算你的梯度并且立即更新权重和偏置（这在科学文献中被称为「随机梯度下降（stochastic gradient descent）」）。在 100 个样本上都这样做可以得到一个更好地表示由不同样本图像施加约束的梯度并且可能更快地朝着解决方案收敛。mini-batch 的大小是可调整的参数。还有一个更加技术化的原因：使用批处理也意味着使用较大的矩阵，而这些通常更容易在 GPU 上优化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;常见问题&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为什么交叉熵是在分类问题中合适的定义距离？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;解答链接：https://jamesmccaffrey.wordpress.com/2013/11/05/why-you-should-use-cross-entropy-error-instead-of-classification-error-or-mean-squared-error-for-neural-network-classifier-training/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;6、实验：让我们来看看代码&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;单层神经网络的代码已经写好了。请打开 mnist_1.0_softmax.py 文件并按说明进行操作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你在本节的任务是理解开始代码，以便稍后对其改进。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你应该看到，在文档中的说明和启动代码只有微小的差别。它们对应于可视化的函数，并且在注释中被标记。此处可忽略。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;mnist_1.0_softmax.py：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://github.com/martin-gorner/tensorflow-mnist-tutorial/blob/master/mnist_1.0_softmax.py&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOtia4weAo34TUtWxxY9wEopFEAPobvdKO4LTCnvdYfyjZFBSOzXF8zVw/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们首先定义 TensorFlow 的变量和占位符。变量是你希望训练算法为你确定的所有的参数。在我们的例子中参数是权重和偏差。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;占位符是在训练期间填充实际数据的参数，通常是训练图像。持有训练图像的张量的形式是 [None, 28, 28, 1]，其中的参数代表：&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;28, 28, 1: 图像是 28x28 每像素 x 1（灰度）。最后一个数字对于彩色图像是 3 但在这里并非是必须的。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;None: 这是代表图像在小批量（mini-batch）中的数量。在训练时可以得到。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;mnist_1.0_softmax.py：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://github.com/martin-gorner/tensorflow-mnist-tutorial/blob/master/mnist_1.0_softmax.py&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOfMVLI9BQdgEia1kjzmicN4CnmhDRphQkd6XNPiaNics2nKsic9Un0b3PmRw/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一行是我们单层神经网络的模型。公式是我们在前面的理论部分建立的。tf.reshape 命令将我们的 28×28 的图像转化成 784 个像素的单向量。在 reshape 中的「-1」意味着「计算机，计算出来，这只有一种可能」。在实际当中，这会是图像在小批次（mini-batch）中的数量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然后，我们需要一个额外的占位符用于训练标签，这些标签与训练图像一起被提供。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在我们有模型预测和正确的标签，所以我们计算交叉熵。tf.reduce_sum 是对向量的所有元素求和。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后两行计算了正确识别数字的百分比。这是留给读者的理解练习，使用 TensorFlow API 参考。你也可以跳过它们。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;mnist_1.0_softmax.py：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://github.com/martin-gorner/tensorflow-mnist-tutorial/blob/master/mnist_1.0_softmax.py)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;optimizer = tf.train.GradientDescentOptimizer(0.003)&lt;/p&gt;&lt;p&gt;train_step = optimizer.minimize(cross_entropy)&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;才是 TensorFlow 发挥它力量的地方。你选择一个适应器（optimiser，有许多可供选择）并且用它最小化交叉熵损失。在这一步中，TensorFlow 计算相对于所有权重和所有偏置（梯度）的损失函数的偏导数。这是一个形式衍生（ formal derivation），并非是一个耗时的数值型衍生。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;梯度然后被用来更新权重和偏置。学习率为 0.003。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，是时候来运行训练循环了。到目前为止，所有的 TensorFlow 指令都在内存中准备了一个计算图，但是还未进行计算。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;TensorFlow 的 “延迟执行（deferred execution）” 模型：TensorFlow 是为分布式计算构建的。它必须知道你要计算的是什么、你的执行图（execution graph），然后才开始发送计算任务到各种计算机。这就是为什么它有一个延迟执行模型，你首先使用 TensorFlow 函数在内存中创造一个计算图，然后启动一个执行 Session 并且使用 Session.run 执行实际计算任务。在此时，图形无法被更改。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由于这个模型，TensorFlow 接管了分布式运算的大量运筹。例如，假如你指示它在计算机 1 上运行计算的一部分 ，而在计算机 2 上运行另一部分，它可以自动进行必要的数据传输。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;计算需要将实际数据反馈进你在 TensorFlow 代码中定义的占位符。这是以 Python 的 dictionary 的形式给出的，其中的键是占位符的名称。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;mnist_1.0_softmax.py：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://github.com/martin-gorner/tensorflow-mnist-tutorial/blob/master/mnist_1.0_softmax.py&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOD46e8viatjtbtvYPibFy9aVC11EDpIjib3qia7D2up4RrMDdwDrwzP7Ofw/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这里执行的 train_step 是当我们要求 TensorFlow 最小化交叉熵时获得的。这是计算梯度和更新权重和偏置的步骤。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最终，我们还需要一些值来显示，以便我们可以追踪我们模型的性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在训练回路中使用该代码来计算准确度和交叉熵（例如每 10 次迭代）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;p&gt;# success ?&lt;br/&gt;a,c = sess.run([accuracy, cross_entropy], feed_dict=train_data)&lt;/p&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过在馈送 dictionary 中提供测试而不是训练数据，可以对测试数据进行同样的计算（例如每 100 次迭代计算一次。有 10,000 个测试数字，所以会耗费 CPU 一些时间）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;p&gt;# success on test data ?&lt;br/&gt;test_data={X: mnist.test.images, Y_: mnist.test.labels}&lt;br/&gt;a,c = sess.run([accuracy, cross_entropy], feed=test_data)&lt;/p&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;TensorFlow 和 Numpy 是朋友：在准备计算图时，你只需要操纵 TensorFlow 张量和命令，比如 tf.matmul, tf.reshape 等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而，只要执行 Session.run 命令，它的返回值就是 Numpy 张量，即 Numpy 可以使用的 numpy.ndarray 对象以及基于它的所有科学计算库。这就是使用 matplotlib（基于 Numpy 的标准 Python 绘图库）为本实验构建实时可视化的方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个简单的模型已经能识别 92% 的数字了。这不错，但是你现在要显著地改善它。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOibE6mhmHev14JgswcB4wMnd5qXxqlfRjgicUYwluOFG7tGoUglMrLqQw/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;7、实验:增加层&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOCqnO54VTEZxPX6IzSXuiciaiaCWZib92gyUic9UmETCiblUt10bncHT8NpuA/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了提高识别的准确度，我们将为神经网络增加更多的层。第二层神经元将计算前一层神经元输出的加权和，而非计算像素的加权和。这里有一个 5 层全相连的神经网络的例子：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOuGfYSFT74kbFNvs4eWZMt9DL8hrzoH5MrDfELW5sFWusmLbC6bCMibQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们继续用 softmax 来作为最后一层的激活函数，这也是为什么在分类这个问题上它性能优异的原因。但在中间层，我们要使用最经典的激活函数：sigmoid：在这一节中你的任务是为你的模型增加一到两个中间层以提高它的性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOB4k0BWGoiaW2UF4dic0QsNpH0Rgap3ed508yIQthD8t9juRwOVqXI0uA/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;答案可以在 mnist_2.0_five_layers_sigmoid.py 中找到。只有当你实在想不出来的时候再使用它！为了增加一个层，你需要为中间层增加一个额外的权重矩阵和一个额外的偏置向量：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;p&gt;W1 = tf.Variable(tf.truncated_normal([28*28, 200] ,stddev=0.1))&lt;br/&gt;B1 = tf.Variable(tf.zeros([200]))&lt;br/&gt;&lt;br/&gt;W2 = tf.Variable(tf.truncated_normal([200, 10], stddev=0.1))&lt;br/&gt;B2 = tf.Variable(tf.zeros([10]))&lt;/p&gt;&lt;/pre&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对，就这么做。通过 2 个中间层以及例子中 200 个和 100 个神经元，你现在应该能够把你的神经网络的准确度推高到 97% 了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOBQPDQRdByiaeZjCeBJvnPgT7uamialK5OQ3w3nccMwMKuXuF6J4ocfCg/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;8、实验：深度网络需要特别注意的地方&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOAz0DeOvpRIo3FmjXthdgCkx0zcQ0zp6r1cdKThYBILcsNA9eWTFjIw/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随着层数的增加，神经网络越来越难以收敛。但现在我们知道如何控制它们的行为了。这里是一些只用 1 行就可以实现的改进，当你看到准确度曲线出现如下情况的时候，这些小技巧会帮到你：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdO0ibWQnsgUnI8KAHfqOshQE1dLV1XVnIfUmhStP5nwtft6yv3bjtkAtQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;修正线性单元（ReLU）激活函数&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在深度网络里，sigmoid 激活函数确实能带来很多问题。它把所有的值都挤到了 0 到 1 之间，而且当你重复做的时候，神经元的输出和它们的梯度都归零了。值得一提的是，出于历史原因，一些现代神经网络使用了 ReLU（修正线性单元），它大致是如下这个样子：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOdvfO7WTTNy8iaqgJuWTQAbE2FAFVXoYxOGcEWvnb3Xvvib2X36xAzicpw/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;升级 1/4：用 RELU 替换你所有的 sigmoid，然后你会得到一个更快的初始收敛并且当我们继续增加层的时候也避免了一些后续问题的产生。仅仅在代码中简单地用 tf.nn.relu 来替换 tf.nn.sigmoid 就可以了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个更好的优化器&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在一个特别多维的空间里，就像当前这个情况——我们有 10K 量级的权值和偏置值——「鞍点 (saddle points）」会频繁出现。这些点不是局部最小值点，但它的梯度却是零，那么梯度降的优化会卡在这里。TensorFlow 有一系列可以用的优化器，包括一些带有一定的惯性，能够安全越过鞍点的优化器。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;升级 2/4：现在将你的 tf.train.GradientDescentOptimiser 替换为 tf.train.AdamOptimizer。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随机初始化&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;准确性一直卡在 0.1？你把你的权值初始化成随机值了没？对于偏置值，如果用 ReLU 的话，最好的办法就是把它们都初始化成小的正值，这样神经元一开始就会工作在 ReLU 的非零区域内。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;p&gt;W = tf.Variable(tf.truncated_normal([K, L] ,stddev=0.1))&lt;br/&gt;B = tf.Variable(tf.ones([L])/10)&lt;/p&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;升级 3/4：现在检查是否你所有的权值和偏置值都被初始化好了。上图所示的 0.1 会作为偏置值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不定值（NaN）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOOnxOofUfcz3ephxl0UhxeqOB6s1OapSoZrlNUHRzTIu9c359vyqotA/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你看到你的精确曲线陡然下滑并且调试口输出的交叉熵是 NaN，不用感到头疼，你其实是正在尝试计算 log(0)，而这肯定是个不定值（NaN）。还记得吗，交叉熵的计算涉及到对 softmax 层的输出取对数。鉴于 softmax 基本上是一个指数，它肯定不是 0，我们如果用 32 位精度的浮点运算就还好，exp(-100) 基本上可以算作是 0 了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;很幸运，TensorFlow 有一个非常方便的函数可以在单步内计算 softmax 和交叉熵，它是以一种数值上较为稳定的方式实现的。如果要使用它，你需要在应用 softmax 之前将原始的权重和加上你最后一层的偏置隔离开来（在神经网络的术语里叫「logits」）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你模型的最后一行是这样的：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;p&gt;Y = tf.nn.softmax(tf.matmul(Y4, W5) + B5)&lt;/p&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你需要把它替换成：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;p&gt;Ylogits = tf.matmul(Y4, W5) + B5
Y = tf.nn.softmax(Ylogits)&lt;/p&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;并且你现在能以一种安全的方式计算交叉熵了：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;p&gt;cross_entropy = tf.nn.softmax_cross_entropy_with_logits(Ylogits, Y_)&lt;/p&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;同样加上下面这行代码使得测试和训练的交叉熵能够同框显示：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;p&gt;cross_entropy = tf.reduce_mean(cross_entropy)*100&lt;/p&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;升级 4/4：请把 tf.nn.softmax_cross_entropy_with_logits 加到你的代码里。你也可以跳过这一步，等你真在你的输出里看到 NaN 以后再来做这步。现在，你已经准备好实现「深度」了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;9、实验：学习速率衰退&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOBXiae4PSfty9lGiahnT8icSXVLZqCzulJicVNX2DAfuDqicwmp27o6LUicrA/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过两个、三个或者四个中间层，你现在可以将准确度提升至接近 98%，当然，你的迭代次数要达到 5000 次以上。不过你会发现你并不总是会得到这样的结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOfz5Jt3iaGqYJ1MUS2IFg9JfKJBYiaTZv8HBwcj6xE2Dsbzh4zpjo14Og/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些曲线很嘈杂，看看测试精确度吧：它在全百分比范围内跳上跳下。这意味着即使 0.003 的学习率我们还是太快了。但我们不能仅仅将学习率除以十或者永远不停地做训练。一个好的解决方案是开始很快随后将学习速率指数级衰减至比如说 0.0001。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个小改变的影响是惊人的。你会看到大部分的噪声消失了并且测试精确度持续稳定在 98% 以上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOibZOXe6pMQUaoxekhItByZ6XpxLgOdkzD3vBic8MT3bHqdFn6nqo0tjw/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;再看看训练精确度曲线。在好多个 epoch 里都达到了 100%（一个 epoch=500 次迭代=全部训练图片训练一次）。第一次我们能很好地识别训练图片了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;请把学习率衰退加到你的代码里。为了把一个不同的学习率在每次迭代时传给 AdamOptimizer，你需要定义一个新的占位符（placeholder）并在每次迭代时通过 feed_dict 赋给它一个新的参数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里是一个指数级衰减的方程：lr = lrmin+(lrmax-lrmin)*exp(-i/2000) 答案可以在这个文件里找到：mnist_2.1_five_layers_relu_lrdecay.py。如果你被卡住了可以用它。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdO6ibEW0PFjTz2o5vAKGS182t8KX4pYydL5CiaA89MQmG8R7gdtEWNkPvw/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;10、实验：dropout、过拟合&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOW3aDx7CC1MavglFrxicfoY8IKibMRlwoEqVJxicu1qcdw0KgOkXrwRUibQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你可能已经注意到在数千次迭代之后，测试和训练数据的交叉熵曲线开始不相连。学习算法只是在训练数据上做工作并相应地优化训练的交叉熵。它再也看不到测试数据了，所以这一点也不奇怪：过了一会儿它的工作不再对测试交叉熵产生任何影响，交叉熵停止了下降，有时甚至反弹回来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOFK4z7czD5rGCWNufmbCAiap36XmnMNWFpcIKT7dzPgYaX160DdJVI3Q/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;它不会立刻影响你模型对于真实世界的识别能力，但是它会使你运行的众多迭代毫无用处，而且这基本上是一个信号——告诉我们训练已经不能再为模型提供进一步改进了。这种无法连接通常会被标明「过拟合（overfitting）」，而且当你看到这个的时候，你可以尝试采用一种规范化（regularization）技术，称之为「dropout」。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOgqW2ZHGOGEvhibC0bPuGx4LksibJwGQdJuzrdm4RRLeTLrGXdlvrDY8Q/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 dropout 里，在每一次训练迭代的时候，你可以从网络中随机地放弃一些神经元。你可以选择一个使神经元继续保留的概率 pkeep，通常是 50% 到 75% 之间，然后在每一次训练的迭代时，随机地把一些神经元连同它们的权重和偏置一起去掉。在一次迭代里，不同的神经元可以被一起去掉（而且你也同样需要等比例地促进剩余神经元的输出，以确保下一层的激活不会移动）。当测试你神经网络性能的时候，你再把所有的神经元都装回来 (pkeep=1)。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;TensorFlow 提供一个 dropout 函数可以用在一层神经网络的输出上。它随机地清零一些输出并且把剩下的提升 1/pkeep。这里是如何把它用在一个两层神经网络上的例子。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;p&gt;# feed in 1 when testing, 0.75 when training&lt;br/&gt;pkeep = tf.placeholder(tf.float32)&lt;br/&gt;&lt;br/&gt;Y1 = tf.nn.relu(tf.matmul(X, W1) + B1)&lt;br/&gt;Y1d = tf.nn.dropout(Y1, pkeep)&lt;br/&gt;&lt;br/&gt;Y = tf.nn.softmax(tf.matmul(Y1d, W2) + B2)&lt;/p&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你现在可以在网络中每个中间层以后插入 dropout。如果你没时间深入阅读的话，这是本项目里的可选步骤。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该解决方案可以在 mnist_2.2_five_layers_relu_lrdecay_dropout.py：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;(https://github.com/martin-gorner/tensorflow-mnist-tutorial/blob/master/mnist_2.2_five_layers_relu_lrdecay_dropout.py)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;里找到。如果你被难住了，可以用它。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOyxN9yZ3yrdbVytBxsXycQhPfIz42BFIIqBInJ76J7aEGQKiav7U76Fw/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你会看到测试损失已经被搞回来了，已经在可控范围内了，不过至少在这个例子中噪声重新出现了（如果你知道 dropout 的工作原理的话，这一点也不奇怪）。测试的准确度依然没变，这倒是有点小失望。这个「过拟合」一定还有其它原因。在我们继续进行下一步之前，我们先扼要重述一下我们到目前为止用过的所有工具：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdO2QJiaBHKYTv46tchksDiauciarcnNmDWVZKfL6NvoByQicemibQwGAiaPRrw/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;无论我们做什么，我们看上去都不可能很显著地解决 98% 的障碍，而且我们的损失曲线依然显示「过拟合」无法连接。什么是真正的「过拟合」？过拟合发生在该神经网络学得「不好」的时候，在这种情况下该神经网络对于训练样本做得很好，对真实场景却并不是很好。有一些像 dropout 一样的规范化技术能够迫使它学习得更好，不过过拟合还有更深层的原因。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOPDUSb8c5dUQGsCo7mPsibNibfNCia51RDvd5LZ0rnUZmcpWIORcUEtZgw/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;基本的过拟合发生在一个神经网络针对手头的问题有太多的自由度的时候。想象一下我们有如此多的神经元以至于所组成的网络可以存储我们所有的训练图像并依靠特征匹配来识别它们。它会在真实世界的数据里迷失。一个神经网络必须有某种程度上的约束以使它能够归纳推理它在学习中所学到的东西。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你只有很少的训练数据，甚至一个很小的网络都能够用心学习它。一般来说，你总是需要很多数据来训练神经网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，如果你已经做完了所有的步骤，包括实验了不同大小的网络以确保它的自由度已经约束好了、采用了 dropout、并且训练了大量的数据，你可能会发现你还是被卡在了当前的性能层次上再也上不去了。这说明你的神经网络在它当前的形态下已经无法从你提供的数据中抽取到更多的信息了，就像我们这个例子这样。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;还记得我们如何使用我们的图像吗？是所有的像素都展平到一个向量里么？这是一个很糟糕的想法。手写的数字是由一个个形状组成的，当我们把像素展平后我们会丢掉这些形状信息。不过，有一种神经网络可以利用这些形状信息：卷积网络（convolutional network）。让我们来试试。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;11、理论：卷积网络&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOsics1Sdpp40BwcnX6wuY2SEfSQjEy51ib7a3HVyytJ7qH3OyZ9AUjVDA/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在卷积网络层中，一个「神经元」仅对该图像上的一个小部分的像素求加权和。然后，它通常会添加一个偏置单元，并且将得到的加权和传递给激活函数。与全连接网络相比，其最大的区别在于卷积网络的每个神经元重复使用相同的权重，而不是每个神经元都有自己的权重。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在上面的动画中，你可以看到通过连续修改图片上两个方向的权重（卷积），能够获得与图片上的像素点数量相同的输出值（尽管在边缘处需要填充（padding））。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;要产生一个输出值平面，我们使用了一张 4x4 大小的彩色图片作为出输入。在这个动画当中，我们需要 4x4x3=48 个权重，这还不够，为了增加更多自由度，我们还需要选取不同组的权重值重复实验。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdODjLZnxbJw0tUXQ8L0PuemMOpibdnDSRqAhgq3bvqrU8WnqxyCib4wYrg/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过向权重张量添加一个维度，能够将两组或更多组的权重重写为一组权重，这样就给出了一个卷积层的权重张量的通用实现。由于输入、输出通道的数量都是参数，我们可以开始堆叠式（stacking）和链式（chaining）的卷积层。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOPULsoCEKvD5glEjlx6nfrNnO0zicyeXKHiaFNS22jOboB4nE5EJgJnjA/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，我们需要提取信息。在最后一层中，我们仅仅想使用 10 个神经元来分类 0-9 十个不同的数字。传统上，这是通过「最大池化（max-pooling）」层来完成的。即使今天有许多更简单的方法能够实现这分类任务，但是，「最大池化」能够帮助我们直觉地理解卷积神经网络是怎么工作的。如果你认为在训练的过程中，我们的小块权重会发展成能够过滤基本形状（水平线、垂直线或曲线等）的过滤器（filter），那么，提取有用信息的方式就是识别输出层中哪种形状具有最大的强度。实际上，在最大池化层中，神经元的输出是在 2x2 的分组中被处理，最后仅仅保留输出最大强度的神经元。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里有一种更简单的方法：如果你是以一步两个像素移动图片上的滑块而不是以每步一个像素地移动图片上的滑块。这种方法就是有效的，今天的卷积网络仅仅使用了卷积层。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOGkibWblVcuxBusHNJicMS0YfjUB9W0WictqKoTnQ2B8FhQwmIqsszzW5g/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;让我们建立一个用于手写数字识别的卷积网络。在顶部，我们将使用 3 个卷积层；在底部，我们使用传统的 softmax 读出层，并将它们用完全连接层连接。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOw2YCBMDXTOmZVAa6xqVNTKibeYFEqUrCANiaWRhByCgsrw8fC4Uv9SdA/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;注意，第二与第三卷积层神经元数量以 2x2 为倍数减少，这就解释了为什么它们的输出值从 28x28 减少为 14x14，然后再到 7x7。卷积层的大小变化使神经元的数量在每层下降约为：28x28x14≈3000-&amp;gt;14x14x8≈1500 → 7x7x12≈500 → 200。下一节中，我们将给出该网络的具体实现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;12、实现：一个卷积网络&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOw2YCBMDXTOmZVAa6xqVNTKibeYFEqUrCANiaWRhByCgsrw8fC4Uv9SdA/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了将我们的代码转化为卷积模型，我们需要为卷积层定义适当的权重张量，然后将该卷积层添加到模型中。我们已经理解到卷积层需要以下形式的权重张量。下面代码是用 TensorFlow 语法来对其初始化：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOf8ytOJXpaOxhDdKvJCOYCdNYZN9UAuoCNwlicDvghIs8Tr6V3IuSVyg/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;p&gt;W = tf.Variable(tf.truncated_normal([4, 4, 3, 2], stddev=0.1))&lt;br/&gt;B = tf.Variable(tf.ones([2])/10) # 2 is the number of output channels&lt;/p&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 TensorFlow 中，使用 tf.nn.conv2d 函数实现卷积层，该函数使用提供的权重在两个方向上扫描输入图片。这仅仅是神经元的加权和部分，你需要添加偏置单元并将加权和提供给激活函数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;p&gt;stride = 1 &amp;nbsp;# output is still 28x28&lt;br/&gt;Ycnv = tf.nn.conv2d(X, W, strides=[1, stride, stride, 1], padding='SAME')&lt;br/&gt;Y = tf.nn.relu(Ycnv + B)&lt;/p&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不要过分在意 stride 的复杂语法，查阅文档就能获取完整的详细信息。这里的填充（padding）策略是为了复制图片的边缘的像素。所有的数字都在一个统一的背景下，所以这仅仅是扩展了背景，并且不应该添加不需要的任何样式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在该你了。修改你的模型并将其转化为卷积模型。你可以使用上图中的值来修改它，你可以减小你的学习速率但是务必先移除 dropout。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你的模型的准确率应该会超过 98%，并且最终达到约 99%。眼看目标就要实现，我们不能停止！看看测试的交叉熵曲线。在你的头脑中，此时，是否解决方案正在形成？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOMbUHpFafiarW1jfE9cyjSBSZw9nWic0FGRicKzrRQhTVZtAYjSM2qRbYg/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;13、99% 准确率的挑战&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;调整你的神经网络的一个好方法：先去实现一个限制较多的神经网络，然后给它更多的自由度并且增加 dropout，使神经网络避免过拟合。最终你将得到一个相当不错的神经网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;例如，我们在第一层卷积层中仅仅使用了 4 个 patch，如果这些权重的 patch 在训练的过程中发展成不同的识别器，你可以直观地看到这对于解决我们的问题是不够的。手写数字模式远多于 4 种基本样式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此，让我们稍微增加 patch 的数量，将我们卷积层中 patch 的数量从 4，8，12 增加到 6，12，24，并且在全连接层上添加 dropout。它们的神经元重复使用相同的权重，在一次训练迭代中，通过冻结（限制）一些不会对它们起作用的权重，dropout 能够有效地工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOSUDKaRejmOTlOBxOofAHtEXQ1RNQMv08iaX43293TuLQicQXu8a902uA/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;加油吧，去打破 99％的限制。增加 patch 数量和通道的数量，如上图所示，在卷积层中添加 dropout。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdO5gK1hCdfdOlmhc1Jwet6DQsecEYoaGeoicgABFJOk8MEXGia58LBRulQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;解决方案可以在文件 mnist_3.1_convolutional_bigger_dropout.py 中找到。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使用上图所示的模型，在 10000 个测试的数字中，结果仅仅错误了 72 个。你可以在 MNIST 网站上发现，数字识别准确率的世界纪录大约为 99.7%，这仅比我们用 100 行 Python/TensorFlow 代码构建的模型的准确率高 0.4%。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，不同的 dropout 使我们能够训练更大的卷积网络。增加神经网络的额外自由度，使模型的最终准确率从 98.9% 达到 99.1%。向卷积层中增加 dropout 不仅减少了测试误差，而且使我们模型的准确率突破 99%，甚至达到了 99.3%。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOFJnyJdibkIkWrnFic0OqfB7miab9ADhErO6feoRHvqVrafwibc7MNFQslQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;14、恭喜！&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你已经建立了你的第一个神经网络，并且训练精度达到了 99%。在这个学习过程中，你所学到的技术，并不局限于 MNIST 数据集。实际上，这些技术在训练神经网络的过程中被广泛使用。作为礼物，下面提供的内容可以用来帮助你回忆已经所学的内容。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdOWGSBND1vSh4DaMfFJQwQiazcapvHmbKAA2BMgo3kQHoOoueZoDkbcBg/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在完成了完全神经网络和卷积网络后，你应该学习循环神经网络：https://www.tensorflow.org/tutorials/recurrent/。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在本教程中，你已经学习了如何在矩阵层次构建 TensorFlow 模型。Tensorflow 还有更高级的 API，称为 tf.learn：https://www.tensorflow.org/tutorials/tflearn/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;要在云上的分布式框架上训练，我们提供 Cloud ML 服务：https://cloud.google.com/ml&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;最后，我们希望收到你的反馈。如果你在发现了本实验中的些许错误，或者你认为有什么需要改进的地方，请告诉我们。我们通过 GitHub 处理反馈。反馈链接：https://github.com/googlecodelabs/feedback/issues/new?title=[cloud-tensorflow-mnist]:&amp;amp;labels[]=content-platform&amp;amp;labels[]=cloud&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心编译，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 24 Jan 2017 12:32:21 +0800</pubDate>
    </item>
    <item>
      <title>业界 | 蚂蚁金服与UC Berkeley RISE实验室启动合作，加速数据人才培养</title>
      <link>http://www.iwgc.cn/link/4468819</link>
      <description>&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器之心报道&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：老红&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;近日，蚂蚁金服与美国加州伯克利大学近期新成立的 RISE 实验室达成合作意向。据悉，本次蚂蚁金服和 RISE 实验室的合作，是对海内外数据技术人才引进的布局。蚂蚁金服董事长彭蕾曾在内部讲话中表明蚂蚁金服对大数据技术的人才引进将&lt;span&gt;「&lt;/span&gt;不拘一格，不遗余力&lt;span&gt;」&lt;/span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;RISE 实验室的前身是著名伯克利 AMP 实验室，主导研发了当今大数据计算领域最前沿的开源系统：Apache Spark 和 Apache Mesos。以 Apache Spark 为例，作为大数据分析处理的计算引擎，它具备 DAG 执行引擎以及基于内存的多轮迭代计算等优势，使得其在数据分析等工作负载上表现优秀，成为大数据领域最活跃的开源项目之一。从 AMP 实验室在大数据领域取得成果可以看到，其升级版 RISE 实验室在大数据方面的技术基础以及人才培养与储备都是领域内领先的。此次蚂蚁金服和 RISE 实验室合作，除了对基础技术深度研究之外，更是对人才长期的持续投资。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://images.weserv.nl/?url=mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibyY7ZrDfwPgWUYjcyA1rdO5aWNPsPia4o3ncJ0SOIhbBZMCJzX8UziaGwNr7EoFl1BgOAkxmFkj9XQ/0?wx_fmt=png"/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此前，蚂蚁金服和清华大学、同济大学等高校就基础科研进行了合作。本次和 UC Berkeley 的合作向国际高校基础科研合作迈出了第一步，旨在结合双方资源优势，进一步拓展与升级合作的领域及范围，深化高科技人才的培养与合作交流，共同探索数据技术人才培养的新模式与新机制。该项合作的背后是对高科技人才尤其数据技术人才的极度渴望。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;RISE 实验室的成立，标志着世界顶级计算机科学系在大数据计算领域种下一个五年重大研究计划。这个新实验室专注于下一代大数据计算系统「Real-Time Intelligence &amp;nbsp;with Secure &amp;nbsp;Execution &amp;nbsp;(RISE)&lt;span&gt;」&lt;/span&gt;的研发，世界十一家顶级科技公司成为该实验室的创始成员：蚂蚁金服、谷歌、微软、亚马逊、CAPITAL ONE、英特尔、华为、爱立信、 IBM、VMWare 和通用电气。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;RISE 实验室主任 Ion Stoica 教授描绘了实验室的使命愿景：解决大规模数据计算中长期未能很好解决的世界难题，机器如何在实时数据环境中快速地做出智能决策。这项技术适用于许多未来场景，从地震监控，无人车／无人机指挥与导航、到网络安全等等，需要在复杂环境交互中做出实时计算决策。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Ion Stoica 教授评价本次与蚂蚁金服的合作：「基于最新的强安全数据的智能决策技术将开启一个与数十亿用户息息相关的新应用时代，提高用户的隐私性的同时提供更精准实时的建议。我们非常高兴能与蚂蚁金服合作开发新系统和算法来赋能更多应用和服务，这将从根本上改变人们消费行为并从一系列持续变化的金融、健康、消费、娱乐等数据流中获得价值。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;蚂蚁金服首席技术架构师胡喜说：「蚂蚁金服的核心愿景让全球数十亿普通人享受普惠而便利的金融服务。低成本的实时安全智能决策能力对我们提升客户体验和业务效率都具有极大的价值。我们将与 RISE 实验室合作共同应对某些基础研究的挑战，提供更创新和智能的金融服务。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;ISE 实验室的主要教授包括 Ion Stoica , Michael Jordan 等在内的涵盖了大数据系统及人工智能等领域的世界顶级专家。本次合作中实验室的初创成员都是各领域极具代表性的领先企业，RISE 实验室五年计划的启动将是来自世界各地代表不同产业的人才精英汇聚在一起共同合作创新的尝试。与蚂蚁金服的合作，建立在双方共同的使命和远景基础上，致力于用科技给人们带来智能、安全、低成本的数字普惠金融服务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;©本文为机器之心报道，&lt;strong&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <pubDate>Tue, 24 Jan 2017 12:32:21 +0800</pubDate>
    </item>
  </channel>
</rss>
