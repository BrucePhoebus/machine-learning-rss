<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>智能单元 - 知乎专栏</title><link>https://zhuanlan.zhihu.com/intelligentunit</link><description>面向通用人工智能和机器人学习，聚焦深度增强学习，可微神经计算机和生成对抗模型。</description><lastBuildDate>Thu, 26 Jan 2017 11:15:10 GMT</lastBuildDate><generator>Ricky</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>汉字生成模型的那些坑</title><link>https://zhuanlan.zhihu.com/p/24805121</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-56db09cd10a86d006257d0ff386dc2f7_r.jpg"&gt;&lt;/p&gt;&lt;h2&gt;引言&lt;/h2&gt;&lt;p&gt;人工智能技术目前仍处于技术积累期，人们真正希望看到的人工智能技术是要能够融入生活中的，真正为人们带来便利的技术，但目前能真正做到“实用化”的人工智能产品并不多。除了大家熟悉的，如机器翻译、聊天机器人、语音识别与生成、图像分类、路径规划、智能跟踪等，我认为汉字生成是最具有潜力、最早一批进入市场的人工智能产品，因为其领域相对较小（与Robot、NLP等比较），而且成本硬件较低，这两年汉字生成问题也确实受到了越来越多的关注。&lt;/p&gt;目前汉字生成模型主要应用场景包括&lt;b&gt;生成手写字体&lt;/b&gt;以及生&lt;b&gt;成手写汉字&lt;/b&gt;两个方面。生成手写字体主要是想解决中文字太多，设计一款新的字体需要巨大工程量的问题，如果设计师仅手工设计少量的字体文字，然后机器就能根据这些问题提取出其中的风格然后自动设计生成剩余文字，则可以极大减轻设计师的负担。生成手写汉字是指采集某人的书写笔迹，让计算机学会模仿他的风格进行书写，我认为这是汉字生成的最终目标，具体而言就是要让机械臂拿起笔帮我们处理手写任务，比如代替我们写亲笔信，或帮我们做手写试卷等。&lt;p&gt;汉字生成模型在技术上主要可以分为&lt;b&gt;基于笔迹的生成模型&lt;/b&gt;以及&lt;b&gt;基于图像的生成模型&lt;/b&gt;。二者的区别来源于应用场景的不同，若以设计一个会写字的机械臂为目标，则必须得到具体的笔画；若以生成新的中文字体为目标，则可以仅依赖文字的图像。&lt;/p&gt;&lt;p&gt;目前研究手写问题的文章并不是很多，但手写问题涉及到的领域非常广，不仅需要RNN而且若想真正做好还需要加入GAN、RL等人工智能技术。&lt;/p&gt;&lt;h2&gt;一、样本的表示方法&lt;/h2&gt;&lt;p&gt;样本的表示是一个值得探究的问题：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;如果样本是文字图像：&lt;/li&gt;&lt;ul&gt;&lt;li&gt;大家很容易理解，但这种方法会损失书写的笔画顺序、文字起点与终点、每一个笔画的起笔与落笔等信息。&lt;/li&gt;&lt;li&gt;该方法也是有优点的，比如容易用CNN处理，比较容易提取风格特征，生成速度较快（一次生成整张图片）等。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;如果样本是文字笔迹：&lt;/li&gt;&lt;ul&gt;&lt;li&gt;首先考虑是连续问题还是离散问题~&lt;/li&gt;&lt;li&gt;离散问题具体而言就是将文字投影到一个离散的画布上如100x100像素的画布，其中的每一个笔画由若干点组成，每一个点对应一个整数型坐标。更进一步，可以将每一个笔画分解为若干个关键点，关键点直接用直线连接，这样一条直线上就可以仅用起点与终点表示，可以省略掉中间的点。离散问题在生成文字时（每次生成一个点）可以看作一个&lt;b&gt;分类问题&lt;/b&gt;，因此比较容易训练，但其最大问题就是会损失一定精度。&lt;/li&gt;&lt;li&gt;连续问题就是将文字投影到（-1,1）的连续空间，用浮点数来精确表示每个点的坐标，这也是目前主流的方法，其本质上是一个&lt;b&gt;回归问题&lt;/b&gt;，也因此训练难度较高。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;样本是笔迹，在连续空间上，如何具体表示呢？&lt;/li&gt;&lt;ul&gt;&lt;li&gt;如果样本是笔迹，笔迹是由点组成的，每一个点&lt;equation&gt;p&lt;/equation&gt;可以用&lt;equation&gt;\{(x,y),(a,b,c)\}&lt;/equation&gt;这种形式来表示，其中&lt;equation&gt;(x,y)&lt;/equation&gt;是坐标，&lt;equation&gt;(a,b,c)&lt;/equation&gt;是一个分类向量，可以设&lt;equation&gt;a&lt;/equation&gt;是一个笔画的结束，&lt;equation&gt;b&lt;/equation&gt;是一般的点，&lt;equation&gt;c&lt;/equation&gt;是整个文字的结束。因此一个文字就可以用点的序列表示：&lt;equation&gt;S=(p_0,p_1,\cdots,p_n)&lt;/equation&gt;。&lt;/li&gt;&lt;li&gt;还有一个问题需要考虑，就是应该采用绝对坐标还是相对坐标呢？绝对坐标很容易理解，而相对坐标就是下一个点的&lt;equation&gt;(x,y)&lt;/equation&gt;并不是绝对位置，而是相对于上一个点的偏移。个人以为，两种方法皆可，但是相对表示表现更好，因为误差不会跃层向下传播。&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;h2&gt;二、用RNN完成最基本的生成任务&lt;/h2&gt;&lt;p&gt;我们首先考虑一个最简单的生成模型：给若干个汉字的训练样本（笔迹样本），然后训练神经网络来生成风格类似的文字。&lt;/p&gt;&lt;p&gt;具体而言，就是用一个RNN训练，RNN的输入是要书写文字的&lt;b&gt;高维特征向量&lt;/b&gt;和一个&lt;b&gt;开始标识&lt;/b&gt;。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;高维特征向量&lt;/b&gt;代表我需要生成哪一个文字，其实也可以用一个one-hot向量表示，但由于汉字的数量很多，用一太长的向量表示比不上用一个更有意义的维度较低的向量表示，这也是借鉴了NLP中的word2vec的思想，这个更有意义的向量应该可以反映出要生成的汉字的固有特征。另外高维特征向量需要预先训练，可以采用自编码技术，或截取一个已训练神经网络的特征提取部分。&lt;/li&gt;&lt;li&gt;&lt;b&gt;开始标&lt;/b&gt;&lt;b&gt;识&lt;/b&gt;类似于NLP中的一段话的开始标志，如&amp;lt;begin&amp;gt;Hello world&amp;lt;end&amp;gt;，中的&amp;lt;begin&amp;gt;，具体到文字生成中，开始标志是一个特殊的点如&lt;equation&gt;\{(0,0),(0,1,0)\}&lt;/equation&gt;。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;具体的生成方法采用一次生成一个点的方式进行，直到生成结束点为止，举例而言就是给出一个文字比如“宋”，然后一笔一划地生成一个手写的“宋”，生成流程如图所示：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-c226c2a454f216e8a4f0e803812e1fca.png" data-rawwidth="704" data-rawheight="381"&gt;&lt;p&gt;在训练中，Loss的定义至关重要，在连续空间中采用传统的L2损失函数可能会导致无法拟合多值函数的问题，因此建议采用Mixture Density Loss，具体可以参考&lt;a href="http://blog.otoro.net/2015/11/24/mixture-density-networks-with-tensorflow/" data-title="这篇文" class="" data-editable="true"&gt;这里&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;总体而言，做到这一步就算实现了一个简单的demo了，但是还有很多地方需要优化，离实用还有很多工作要做，我们将继续往前探索。&lt;/p&gt;&lt;h2&gt;三、风格提取与迁移&lt;/h2&gt;&lt;p&gt;风格提取与迁移问题最近比较热，比如生成风格化的图片，生成某人的声音等。风格提取主要是为了解决样本少的问题，我们希望我们设计的手写机器人能够仅训练某个用户的少量手写文字就能自动分析出该用户的手写风格，然后再根据先验知识（所有中文文字的书写规则）就可以生成训练集中未出现过的文字。&lt;/p&gt;&lt;p&gt;风格迁移就是强制神经网络学习到目标字体与参考字体间风格的异同，具体来说就是求出风格转移函数&lt;equation&gt;font_2=f(font_1)&lt;/equation&gt;，比如输入一个宋体的“我”字，输出楷体的“我”。最早的基于图像的风格迁移算法采用了传统的CNN模型，在训练时，输入参考字体（如宋体），输出目标字体（如楷体），训练完后在生成时输入新的参考字体，生成对应的目标字体，网络结构和生成示例如下：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-bf1bf0f9c01fec243cb94c814e9c5dab.png" data-rawwidth="960" data-rawheight="540"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-f239324798c56f061f1c2d8f6b2b1854.png" data-rawwidth="960" data-rawheight="540"&gt;&lt;p&gt;&lt;i&gt;（图片来源：&lt;/i&gt;Rewrite: Neural Style Transfer For Chinese Fonts）&lt;/p&gt;&lt;p&gt;这种仅采用CNN的基于图像的风格迁移算法整体表现并不是很好，在差异比较大的字体之间的迁移效果欠佳，这说明只通过字体的图像，神经网络难以学习到汉字风格的深度特征。&lt;/p&gt;&lt;p&gt;所以最近又有研究者将样本由图片表示替换为笔迹表示，现已较好地解决了风格迁移问题，风格迁移效果如下图所示：&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-4febf45a4a0b1dda8ea3662eaaa64271.png" data-rawwidth="385" data-rawheight="335"&gt;&lt;i&gt;（图片来源： Automatic Generation of Large-scale Handwriting Fonts via Style Learning）&lt;/i&gt;&lt;/p&gt;&lt;p&gt;这种算法首先对参考文字进行笔迹（点）的提取，然后再对目标字体也提取相等数量的点，然后求二者的误差，作为最终的Loss。但现有的这种基于笔迹的算法仍有改进空间，因为该算法在提取笔迹（关键点的个数）和loss的定义上都还是人为设定的，在这两个方面应该还有较大优化的空间，真正的人工智能应该尽可能地减少人为干预。&lt;/p&gt;&lt;p&gt;总之风格提取在文字生成算法中还有一段较长的路要走，其主要研究点应该包括如何更好地定义风格的异同，如何设计一种尽量少依赖人工干预的，鲁棒性更强的表示方法；以及如何优化存储风格的神经网络结构。&lt;/p&gt;&lt;h2&gt;四、更真实的文字&lt;/h2&gt;&lt;p&gt;我们人在书写的过程中，哪怕写100个“我”字，也不会出现两个完全相同的。但是传统的神经网络无法解决差异化输出的问题，我们用一个训练好的神经网络，输出的文字总是一模一样的，因此这样的手写机器人仍不能代替人来写字。&lt;/p&gt;&lt;p&gt;目前，尚未看到有关手写汉字领域的差异化输出相关研究。但是在图像生成领域有一些相关的解决方案，那就是对抗网络生成模型GAN。该模型包括生成器（G）和鉴别器（D），前者用一个随机的100维向量作为输入，目的是为了生成一个与训练集中的图像类似（风格相似）的一张图像，后者是一个二元分类器，用于鉴别该图像是否是在训练集中，每次训练时将生成的图像与训练集中的图像各取50%，进行有监督的学习，标签就是该图像是真实的还是伪造的。生成器需要尽可能生成具有类似风格的图片，而鉴别器要尽可能区分伪造的和真实的，具体公式可以表示为：&lt;/p&gt;&lt;equation&gt;\min \limits_G \max \limits_D D(x)-D(G(z)) &lt;/equation&gt;&lt;p&gt;该方法有些类似RL中的policy方法，两个网络同时训练，同时优化。训练完毕后，生成器可以看成是将训练样本的高维特征提取出来了，其输入的向量就是高维特征向量，根据该向量生成一张图片。&lt;/p&gt;&lt;p&gt;在手写问题上，我们可以采用该方法提取同一个文字的高维表示，然后在其中添加伪随机因子，由此生成各对应文字的不同副本。&lt;/p&gt;&lt;h2&gt;五、数据来源问题&lt;/h2&gt;&lt;p&gt;汉字生成模型由Demo到实用化还有较长的一段路要走，其中一个重要的问题就数据样本采集问题。目前表现最佳的算法主要采用具备更丰富信息的基于笔迹的样本数据，但是通常采集这种具有笔迹信息的样本是比较困难的，要么需要特制的手写笔，要么需要手写板，最经济的也需要装一个手机APP（用手写笔在手机屏幕上写）。但是实际上每个人都有大量的现成的写在纸上的字迹（图片样本），如果能够利用这些手写数据则可以获得更好的用户体验，同时也节约了人力物力。有些论文中提出了用人工的方法或一些特定的算法来提取笔迹但这显然不是良策，更好的方法应该是采用&lt;b&gt;增强学习&lt;/b&gt;的方法，让机器自己学习如何由图片样本提取笔迹，然后在此基础上进行进一步的训练，目前与这个点相关的研究较少，笔者也正在探索之中。&lt;/p&gt;&lt;p&gt;另外，若要尽一步减小人为干预，在增强学习之前还需要进行预处理，要有一个定位器和一个识别器，用于定位和识别已有图片样本中的每一个文字。（这些都是坑啊~~~）&lt;/p&gt;&lt;h2&gt;六、小结&lt;/h2&gt;&lt;p&gt;最后总结一下汉字生成模型的那些坑以及每个坑需要用什么土来填：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;如何表示文字：建议采用基于点的序列来表示，每个点可表示为&lt;equation&gt;\{(x,y),(a,b,c)\}&lt;/equation&gt;的形式。&lt;/li&gt;&lt;li&gt;如何生成文字：采用RNN网络每次生成一个点，直到生成具有结束标志的点。&lt;/li&gt;&lt;li&gt;如何提取文字风格：用已有的数据训练一个风格迁移网络，保存风格信息。&lt;/li&gt;&lt;li&gt;如何让生成的文字更真实（各不相同）：用对抗网络（GAN）提取每个文字的高维特征，并在此基础上加入伪随机因子。&lt;/li&gt;&lt;li&gt;如何充分利用已有的图片样本数据：采用增强学习（RL）的方法，让机器自己学习如何由图片样本提取笔迹。&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;参考文献：&lt;/h2&gt;&lt;ol&gt;&lt;li&gt;Generating Sequences with Recurrent Neural Networks.&lt;/li&gt;&lt;li&gt;Generating online fake Chinese characters with LSTM-RNN,” 2015. [Online]. Available: &lt;a href="http://blog.otoro.net/2015/12/28/recurrent-net-dreams-up-fake-chinese-characters-in-vector-format-with-tensorflow/" data-editable="true" data-title="Recurrent Net Dreams Up Fake Chinese Characters in Vector Format with TensorFlow" class=""&gt;Recurrent Net Dreams Up Fake Chinese Characters in Vector Format with TensorFlow&lt;/a&gt;&lt;/li&gt;&lt;li&gt;Automatic Generation of Personal Chinese Handwriting by Capturing the Characteristics of Personal Handwriting.&lt;/li&gt;&lt;li&gt;Drawing and Recognizing Chinese Characters with Recurrent Neural Network.&lt;/li&gt;&lt;li&gt;Automatic Generation of Large-scale Handwriting Fonts via Style Learning.&lt;/li&gt;&lt;li&gt;Learning Typographic Style.&lt;/li&gt;&lt;li&gt;Rewrite: Neural Style Transfer For Chinese Fonts [Online]. Available:&lt;a href="https://github.com/kaonashi-tyc/Rewrite" data-editable="true" data-title="kaonashi-tyc/Rewrite" class=""&gt;kaonashi-tyc/Rewrite&lt;/a&gt;&lt;/li&gt;&lt;li&gt;Generative Adversarial Nets.&lt;/li&gt;&lt;/ol&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/24805121&amp;pixel&amp;useReferer"/&gt;</description><author>Lonely.wm</author><pubDate>Mon, 23 Jan 2017 12:21:15 GMT</pubDate></item><item><title>Q&amp;A 知乎Live：从AlphaGo看人工智能前沿技术</title><link>https://zhuanlan.zhihu.com/p/24977176</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-3ce09841f5ec27b18afa2f741512b78e_r.jpg"&gt;&lt;/p&gt;&lt;h2&gt;1 前言&lt;/h2&gt;&lt;p&gt;在昨晚的 &lt;a href="https://www.zhihu.com/lives/802155571712253952?utm_campaign=zhihulive&amp;amp;utm_source=zhihucolumn&amp;amp;utm_medium=Livecolumn" data-title="知乎Live：从AlphaGo看人工智能前沿技术" class="" data-editable="true"&gt;知乎Live：从AlphaGo看人工智能前沿技术&lt;/a&gt; 中，大家提了很多问题，由于Live时间的限制，来不及一一回复。这里将一些在Live中没有回答到的问题回答在这里。&lt;/p&gt;&lt;h2&gt;2 Q&amp;amp;A&lt;/h2&gt;&lt;p&gt;（1）深度增强学习和深度学习有什么联系和区别？&lt;/p&gt;&lt;p&gt;答：深度增强学习是深度学习+增强学习，可以说是深度学习的拓展分支。深度增强学习的核心是在增强学习的框架下使用多层神经网络来表示策略网络Policy Network或价值网络Value Network&lt;b&gt;。增强学习为深度学习提供学习目标，深度学习则提供学习的机制。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;（2）深度增强学习这个技术在以后无法替代的人工领域或技能可能是哪些？&lt;/p&gt;&lt;p&gt;答：由于深度增强学习是一个面向通用人工智能的算法，这个算法的不断发展将会不断替代一些之前认为机器不可能做的人类工作。现在我们可见的是翻译，自动驾驶，监控等领域，接下来很多金融决策，医疗诊断，语音助理（语音客服）都会被取代。可能现阶段一些涉及人类感性因素的工作比如传媒行业，艺术创作等比较不好被取代，但是从深度增强学习的理论上来看，机器也有可能通过训练来理解人类的感性因素，比如什么是幽默，什么好笑，什么是爱。一旦机器也能解决这样的问题，恐怕就没有什么是不能被取代的了。当然，这还需要好多年。&lt;/p&gt;&lt;p&gt;（3）深度增强学习本身的逻辑是什么？&lt;/p&gt;&lt;p&gt;答：深度增强学习最基本的逻辑有两个：一是不断试错，二是根据试错的经验评估行为的好坏，调整不同行为输出的可能性。&lt;/p&gt;&lt;p&gt;（4）这个人工智能理论可以反过来对人类学习有借鉴作用吗？比如二语学习。&lt;/p&gt;&lt;p&gt;答：对深度增强学习的研究确实是可以反过来更好的理解人类的学习方式，从而反过来提升我们人类自身的学习水平。从AlphaGo看，人类可以根据AlphaGo的棋谱来研究新的思路。从深度增强学习的算法本身，我们会更清楚的知道，要勇于试错，并且不断调整自己，要认识到自身必然存在的固执的思维。&lt;/p&gt;&lt;p&gt;（5）想请教下是否深度学习能在金融市场这个多人参与的博弈市场发挥功效？&lt;/p&gt;&lt;p&gt;答：显然是可以的，深度增强学习是一套面向决策控制的算法，而金融博弈正是这样的一种决策问题。但是金融市场毕竟存在大量的外部信息，要使一个人工智能程序能处理所有这些信息并给出正确的决策需要巨量的训练，存在较大的挑战。目前深度增强学习的研究正在从简单到复杂，从最基本的游戏到复杂的真实场景。&lt;/p&gt;&lt;p&gt;（6）目前，深度增强学习在每个人的日常生活中的应用达到了什么程度，使用它需要的硬件的门槛高吗？硬件的门槛短期内能下降很多吗？&lt;/p&gt;&lt;p&gt;答：深度增强学习是近2-3年来才发展起来的最前沿人工智能技术，因此还没有达到能在日常生活中广泛应用的程度。它所需要的硬件门槛和深度学习的研究是一样的，都需要较高性能的计算，GPU是目前深度学习研究必备的硬件设备。硬件门槛恐怕短期内很难下降，神经网络芯片从推出到成熟还需要很长时间。而且由于数据越来越大，所需的硬件性能越来越高，一定程度上加大了门槛的降低。&lt;/p&gt;&lt;p&gt;（7）计算机&amp;amp;统计学双修本科在读，业余五段，希望走这条发展路线，想知道以后的高年级计算机选修课应该选哪个方向，谢谢！&lt;/p&gt;&lt;p&gt;答：多选人工智能方向的课，比如计算机视觉，机器学习等课程。当然，最佳的建议是学习网上名校名师的课程。比如Stanford的CS231n计算机视觉课程，UC Berkerley的CS294 深度增强学习课程，还有Coursera，Udacity上都有不错的人工智能课程。&lt;/p&gt;&lt;p&gt;（8）机器学习如何入门，有哪些基础知识，整体的学习流程应该是怎么样的？&lt;/p&gt;&lt;p&gt;答：机器学习的入门建议学习Andrew Ng的机器学习课程。主要需要一定的数学基础，包括概率论和矩阵，也就是大学的数学课程。学习了机器学习入门课之后，可以直接学习深度学习相关的课程，建议都学习网上名校的公开课程，见上一个问题。&lt;/p&gt;&lt;p&gt;（9）本科医疗专业想向人工智能方向转行有什么建议（知识技能储备，路线规划，就业前景等）。要考研究人工智能研究生，能否谈谈大学和专业。&lt;/p&gt;&lt;p&gt;答：学习详见前两个问题。就业前景是非常大的，未来多年人工智能算法工程师都会是稀缺的职位。考研的话国内推荐清华，南大，上交，中科院及国防科大。&lt;/p&gt;&lt;p&gt;（10）人们普遍认为高低电平的计算机不可能实现真正的人工智能，现在所谓的人工智能也只能在给定模式下运行。请问您认为普适的人工智能可能存在吗？&lt;/p&gt;&lt;p&gt;答：当然是存在的，人类的大脑的智能可能也就是神经元的数据传输。现在的通用人工智能才刚刚开始，未来的发展必然会出现能处理多种任务的人工智能程序。&lt;/p&gt;&lt;p&gt;（11）电算能力和感情会同时以高水平(计算机和普通人的情感)存在吗？&lt;/p&gt;&lt;p&gt;答：由于目前的人工智能水平还无法模拟人类的情感，所以很难回答这个问题。从个人理解上看，人类的情感也是能被模拟出来的。&lt;/p&gt;&lt;p&gt;（12）深度学习的ai在计算性能比较强的计算机上完成学习后，能否移植到性能较差的计算机上应用？&lt;/p&gt;&lt;p&gt;答：学习完成后，只要使用神经网络进行前向传播，所需的计算量相对来说少很多，是可以移植的。现在比如Tensorflow训练好的神经网络，可以移植到手机上运行。&lt;/p&gt;&lt;p&gt;（13）讲讲go怎么用的先验？&lt;/p&gt;&lt;p&gt;答：使用人类专家的数据进行监督学习（模仿学习）。&lt;/p&gt;&lt;p&gt;（14）除了replay.targat network还有哪些技巧呢？&lt;/p&gt;&lt;p&gt;答：还有Dueling Network，Prioritised Replay等。当然这些都是DQN发展出来的，现在最好的算法是A3C及其之后的发展算法，比如UNREAL。&lt;/p&gt;&lt;p&gt;（15）如何自己做一个初始的AlphaGo，有放出的源码吗？&lt;/p&gt;&lt;p&gt;答：可以按照AlphaGo的论文方法去复现，github有一些非官方的代码。但是最大的问题在于除非在大公司否则很难有那么高性能的分布式计算机器支持，还要收集大量数据，一个人很难做出来。&lt;/p&gt;&lt;p&gt;（16）对DRL应用到imperfect information games中比较感兴趣。&lt;/p&gt;&lt;p&gt;回答：对于DRL应用到不完全信息游戏的问题，2016年David Silver组出了一篇文章名为：Deep Reinforcement Learning from
Self-Play in Imperfect-Information Games。那么这篇文章面向多人零和游戏，比如扑克。那么idea比较简单，就是综合自身的判断和面对其他人的判断。稍微解释一下。自己的判断就是完全不管对手的策略，自己根据当前的状态（牌面）给出平均最佳选择。而面对其他人的判断，是指考虑当前对手的策略，根据当前情况作出一个最佳反应。Idea就是综合两者的选择给出一个结果，最后能够趋近于纳什均衡。比只用DQN效果好很多。 但是如果是对于星际争霸这样的环境，涉及的问题就多很多，仅仅用这个策略显然也很难达到好的效果。&lt;/p&gt;&lt;p&gt;（17）目前的drl通用框架，以及目前的implement用到的工具推荐～&lt;/p&gt;&lt;p&gt;答：DQN，A3C，UNREAL。推荐使用tensorflow。&lt;/p&gt;&lt;p&gt;（18）rl在机械臂、机器人平台上应用的潜在优势是什么？学术上rl算法往往以小游戏做算法验证，用到真实机械臂上问题很多，我没有想清楚随着rl发展，它在机械臂机器人上应用的潜在优势。请教一下。&lt;/p&gt;&lt;p&gt;答：rl在机器人上的最大优势是可以通过学习来掌握控制，并且是使用从感知到控制的端到端神经网络。Google之前已经放出了一些他们使用DRL做机械臂的进展，可以关注。我认为使用DRL是真正实现机器人灵活控制的方法。这个领域很新，很前沿，值得研究。&lt;/p&gt;&lt;p&gt;（19）求深度讲解算法，推荐一些相关论文，想编程实现一下这个算法？&lt;/p&gt;&lt;p&gt;答：&lt;a href="https://github.com/songrotek/Deep-Learning-Papers-Reading-Roadmap" data-editable="true" data-title="songrotek/Deep-Learning-Papers-Reading-Roadmap"&gt;songrotek/Deep-Learning-Papers-Reading-Roadmap&lt;/a&gt;&lt;/p&gt;&lt;p&gt;（20）读了好几遍论文，有些不太明白，想问些细节问题：&lt;/p&gt;1. rollout网络就是局部特征的线性组合么？这儿根本没用卷积网络吧？&lt;p&gt;2. 在做数据集时，相同局面下的相同走法要合并吗？&lt;/p&gt;&lt;p&gt;3. sutton 书里 REINFORCE算法里同时调整了值网络的参数，感觉alphago的在做强化学习的时候并没有，而是用生成对弈数据集再用监督学习做的。是这样理解的吗？&lt;/p&gt;&lt;p&gt;4. self-play时RLpolicy是每次初始化为SLpolicy，还是在前一个RLpolicy的基础上继续？&lt;/p&gt;&lt;p&gt;答：1. rollout也是一个神经网络，只不过这个神经网络比较小，使用的局部特征作为输入，但是很快。2. 一般很难出现完全相同的局面的，如果出现，也不需要合并，直接作为训练数据。3. AlphaGo的价值网络是单独训练的，没错。4. 是在之前的RLpolicy基础上继续，也只有这样才会不断进步。自学习时是不断用新版本取代旧版本，把旧版本作为对手进行训练。&lt;/p&gt;&lt;p&gt;（21）请问机器学习，深度学习包括深度增强学习等最近进展巨大的技术，对于机器人技术的影响和应用在什么地方？&lt;/p&gt;&lt;p&gt;答：有巨大潜力。欢迎阅读：&lt;a href="https://zhuanlan.zhihu.com/p/22758556?refer=intelligentunit" data-editable="true" data-title="知乎专栏" class=""&gt;最前沿之谷歌的机械臂&lt;/a&gt;&lt;/p&gt;&lt;p&gt;（22）从数据挖掘到机器学习再到深度学习，其中最关键的知识内核是什么？在该怎么深入学习？用tensorflow教程跑完一遍mnist，然后呢？&lt;/p&gt;&lt;p&gt;答：深度学习说白了就是三个部分：模型，数据及训练方法。要深入学习最好还是学习网上名校的公开课，然后自己尝试去复现代码。&lt;/p&gt;&lt;p&gt;最后，感谢所有参加本次Live的知友们！&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/24977176&amp;pixel&amp;useReferer"/&gt;</description><author>Flood Sung</author><pubDate>Sat, 21 Jan 2017 11:37:47 GMT</pubDate></item><item><title>Flood Sung的Live--从AlphaGo看人工智能前沿技术</title><link>https://zhuanlan.zhihu.com/p/24816290</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-3ce09841f5ec27b18afa2f741512b78e_r.jpg"&gt;&lt;/p&gt;&lt;p&gt;大家好！我是 Flood Sung ，研究通用人工智能与机器人学习，&lt;a href="https://zhuanlan.zhihu.com/intelligentunit" class="" data-editable="true" data-title="「智能单元」知乎专栏"&gt;「智能单元」知乎专栏&lt;/a&gt;作者之一。&lt;/p&gt;&lt;p&gt;        深度增强学习（ Deep Reinforcement Learning ） 2013 年就被 DeepMind 提出，然而被关注度非常低。直到去年的 AlphaGo ，才使得深度增强学习真正火起来。深度增强学习是 AlphaGo 的核心技术，是 AlphaGo 能够实现自我学习的关键。&lt;/p&gt;&lt;p&gt;        当前，深度增强学习已成为人工智能领域最重要的研究分支之一，该技术能够使计算机通过&lt;b&gt;深度神经网络&lt;/b&gt;处理&lt;b&gt;从感知到决策控制&lt;/b&gt;的问题，无论是&lt;b&gt;下棋&lt;/b&gt;、&lt;b&gt;金融决策&lt;/b&gt;、&lt;b&gt;医疗诊断&lt;/b&gt;还是&lt;b&gt;机器人控制&lt;/b&gt;，都能派上用场，具有超强的应用前景，是未来的&lt;b&gt;革命性技术&lt;/b&gt;，值得我们每一个人关注！&lt;/p&gt;&lt;h2&gt;2 Live主题与内容&lt;/h2&gt;&lt;p&gt;&lt;b&gt;&lt;a href="https://www.zhihu.com/lives/802155571712253952?utm_campaign=zhihulive&amp;amp;utm_source=zhihucolumn&amp;amp;utm_medium=Livecolumn" class="" data-editable="true" data-title="Live入口：请点击进入"&gt;Live入口：请点击进入&lt;/a&gt;&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;        Live时间：&lt;/b&gt;&lt;b&gt;2017-01-20 20:00&lt;/b&gt;&lt;/p&gt;&lt;p&gt;        本次Live的主题是 &lt;b&gt;AlphaGo&lt;/b&gt; 与&lt;b&gt;深度增强学习&lt;/b&gt;，想讲给对人工智能前沿技术感兴趣，对 AlphaGo 的核心技术感兴趣的朋友！&lt;/p&gt;&lt;p&gt;        在Live中我将从 AlphaGo 出发，为大家介绍 AlphaGo 的核心技术—深度增强学习的基本原理与方法，分析 AlphaGo 能够在自对弈中不断学习的原因，让大家了解深度增强学习这个方法的通用性和革命性！ &lt;/p&gt;&lt;p&gt;&lt;b&gt; 本次 Live 主要包括以下问题：&lt;/b&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;＊ AlphaGo 为什么能在围棋上取得如此重大的突破？ &lt;/p&gt;&lt;p&gt;＊ 深度增强学习是什么，有怎样的发展历史？&lt;/p&gt;&lt;p&gt; ＊ 深度增强学习与通用人工智能有什么关系？ &lt;/p&gt;&lt;p&gt;＊ 深度增强学习拥有怎样的核心思想？ &lt;/p&gt;&lt;p&gt;＊ AlphaGo 自对弈中不断学习的方法是什么？ &lt;/p&gt;&lt;p&gt;＊ 深度增强学习未来的应用和发展前景是什么？&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;b&gt;期待大家的参与！&lt;/b&gt;&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/24816290&amp;pixel&amp;useReferer"/&gt;</description><author>Flood Sung</author><pubDate>Tue, 10 Jan 2017 18:26:59 GMT</pubDate></item><item><title>吴恩达对于增强学习的形象论述（上）</title><link>https://zhuanlan.zhihu.com/p/24761972</link><description>&lt;b&gt;版权声明：本文&lt;a href="https://zhuanlan.zhihu.com/intelligentunit" data-editable="true" data-title="智能单元"&gt;智能单元&lt;/a&gt;首发，本人原创，禁止未授权转载。&lt;/b&gt;&lt;p&gt;&lt;b&gt;前言：&lt;/b&gt;吴恩达在2003年为完成博士学位要求做了专题论文：&lt;a href="http://rll.berkeley.edu/deeprlcourse/docs/ng-thesis.pdf" data-title="Shaping and policy search in Reinforcement learning" class="" data-editable="true"&gt;Shaping and policy search in Reinforcement learning&lt;/a&gt;，其第一、二章被&lt;a href="https://zhuanlan.zhihu.com/p/24721292?refer=intelligentunit" data-title="伯克利CS294：深度增强学习课程" class="" data-editable="true"&gt;伯克利CS294：深度增强学习课程&lt;/a&gt;作为推荐材料。本文基于笔者的理解，对第一章做有选择的编译与注释。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;第一章 简介&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在本章中，我们将对本论文中需要考虑的增强学习框架给出一个非正式的，不涉及数学形式的综述。同时还将描述一些增强学习中的问题，这些问题是我们需要尝试解决的。最后，给出整个专题论文的概要。&lt;/p&gt;&lt;h2&gt;1.1 对增强学习的介绍&lt;/h2&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-5e4cda0cb4d5455d8a410d10ed04b8fb.png" data-rawwidth="994" data-rawheight="678"&gt;&lt;i&gt;图 1.1 伯克利大学的无人直升机&lt;/i&gt;&lt;/p&gt;&lt;p&gt;给一个像图1.1中那样的直升机，我们如何才能学习，或者说自动地设计一个控制器，使得直升机能够正常飞行呢？&lt;/p&gt;&lt;p&gt;人工智能和控制中的一个基础问题就是在随机系统中进行序列决策。飞行中的直升机就是随机系统的一个很好例子，因为它展现出随机和不可预测的行为，而大风和其他类似的干扰可能导致它的运动偏离预期。直升机的控制也是一个序列决策问题，控制直升机需要连续地决策向着哪个方向推操纵杆。比起那些只需要针对一个情况及时作出一个正确决策的问题，本问题展现出了所谓的“&lt;i&gt;&lt;b&gt;延迟后果（delayed consequences）&lt;/b&gt;&lt;/i&gt;”性质，解决问题的难度可谓是大为增加。所谓延迟后果，就是说直升机的自动控制器的水平好坏是根据它的长期表现来决定的，比如假设它现在做出了一个错误的操作，直升机并不会马上坠毁，可能依然能够飞行很多秒。导致直升机控制问题难度增大的另一个方面是它的&lt;b&gt;局部可观测性&lt;/b&gt;。具体来说，就是我们不能够精确地观测到直升机的位置/状态；但是，即便是面对系统状态的不确定性，我们仍然在每一秒都需要计算出正确的控制指令，使得直升机能够在空中正常飞行。&lt;/p&gt;&lt;blockquote&gt;&lt;b&gt;译者注&lt;/b&gt;：吴恩达擅长将一个问题通过比喻和举例的方式讲得通俗易懂，这是教学者的金钥匙。无人机控制这个例子里面包含了好几个马尔科夫决策过程和增强学习里面的用数学公式表达起来比较抽象的性质，待看到公式的时候，回头想这个例子，可以很好地帮助理解记忆。&lt;/blockquote&gt;&lt;p&gt;我们将马尔科夫决策过程（MDP）框架的公式表达推迟到第二章再讲。简单地来说，有的系统（就好比无人直升机）的控制是在每个时间点都会处于某种“状态”，我们一般对于这种系统比较感兴趣，而马尔科夫决策过程就是对这种系统进行建模。例如直升机的状态也许就可以用它的位置和方向来表示。我们的任务就是选择动作，使得系统能够倾向于保持在“好”的状态中，比如保持悬停，并且能够避免“坏”的状态，比如坠机。数量巨大且不同的问题都可以用马尔科夫决策过程形式来进行建模。比如规划和机器人导航，库存管理，机器维护，网络路由，电梯控制和搭建推荐系统。&lt;/p&gt;&lt;p&gt;增强学习针对解决MDP形式的问题给出了一系列的工具。虽然它获得了巨大成功，但是在解决很多问题时仍面临困难，还存在很多问题和挑战。我们简要地描述其中一些问题，这些问题会让某些增强学习问题具有挑战性：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;首先，存在&lt;b&gt;高维度问题&lt;/b&gt;。具体说来，就是基于离散的简单增强学习算法，经常会遇到状态变量的数量成指数增长的情况。这个问题就是所谓的“维度诅咒”，我们将在第二章中更详细地讨论。我们能够设计出一个即能可证地有效运作，又能更好地扩展到搞维度问题的实用算法吗？&lt;/li&gt;&lt;/ul&gt;&lt;blockquote&gt;&lt;b&gt;译者注&lt;/b&gt;：现在高维度问题对深度增强学习已经基本上不是问题。&lt;/blockquote&gt;&lt;ul&gt;&lt;li&gt;同时，如何选择“&lt;b&gt;回馈函数（reward function）&lt;/b&gt;”也是一个问题。在增强学习中，设计者必须指明一个函数，该函数能够告诉我们直升飞机什么时候飞得好，什么时候是飞得不好。我们在选择这个函数的时候有很大的自由度，在第三章中还会看到，如果选择得当，某些函数能够成数量级地加速学习过程。当然同时也存在一些看起来不错，但是实际上让控制器的表现非常糟糕的函数。我们能够合理地选择回馈函数，既避免这种问题，又能让增强学习算法学习得又快又好吗？&lt;/li&gt;&lt;/ul&gt;&lt;blockquote&gt;&lt;b&gt;译者注&lt;/b&gt;：在后续的学习实践中会常常接触，现在不明白不用担心。&lt;/blockquote&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;局部可观测性&lt;/b&gt;（&lt;b&gt;Partial Observability&lt;/b&gt;）是指被控制的系统的状态不能被精确观察的情况，比如直升机上的传感器只能是近似地测量直升机的位置。局部可观测性让问题的解决更加困难了，许多标准的增强学习算法不能解决这种情况，有的即使能够解决，也非常艰难。那么，如果只能近似地观察系统在做什么，我们该如何选择正确的控制呢？&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在本论文中，我们提出了一些方法，尝试解决前两个问题。我们的最终算法在局部可观测的情况下也能很好地工作，算法被运用到了图1.1中的无人直升机控制中。在实践的过程中，我们还涉及了经典控制理论中的一些专题，比如系统识别与验证等。&lt;/p&gt;&lt;blockquote&gt;&lt;b&gt;译者注&lt;/b&gt;：看这篇论文的&lt;b&gt;目的是帮助我们熟悉增强学习和马尔科夫决策过程&lt;/b&gt;，为CS294的学习&lt;b&gt;做知识预习&lt;/b&gt;的，没必要看完整个论文（150多页）来搞明白当年吴恩达的算法是啥情况。&lt;/blockquote&gt;&lt;h2&gt;1.2 与有监督学习的比较&lt;/h2&gt;&lt;blockquote&gt;&lt;b&gt;译者注&lt;/b&gt;：其实个人不太愿意翻译这段，因为对于学习深度增强学习，这个学术和理论味儿比较浓的小节没有太大意义。类似的情况在增强学习的著作&lt;a href="http://webdocs.cs.ualberta.ca/~sutton/book/the-book.html" data-title="Reinforcement Learning: An Introduction" class="" data-editable="true"&gt;Reinforcement Learning: An Introduction&lt;/a&gt;中也有，作者花了很多篇幅去论证增强学习与有监督学习、无监督学习是不同的，应该与之并列什么的。&lt;b&gt;个人意见：虽然翻译了，可略过&lt;/b&gt;。&lt;/blockquote&gt;&lt;p&gt;有监督学习是人工智能领域中另一类标准问题。它可以看成是增强学习的某种特殊形式，在这种形式下，只需要对系统进行一次控制，因此我们只需要一次决策，而不是连续的序列决策。虽然看起来差别不是很大，但是实际上这让有监督学习变成了一个非常简单的问题。&lt;/p&gt;&lt;p&gt;举个具体例子，考虑根据给出的病人的多种检查数据或“特征”（比如心率、体温、多种医学检查结果），用有监督学习算法来预测一个病人是否患有心脏病。这里假设我们拥有一个训练集，其中包含有一些病人特征的样本，以及指明其中哪些病人是否患有心脏病的信息。我们可以用有监督学习算法来让一些函数（线性映射或者神经网络）来对数据进行拟合。当一个新的病人来就诊时，我们可以根据病人的特征，使用这个拟合的函数来预测他是否患有心脏病。而当这个一眼的诊断出来后，我们的病人就要去面对他的命运了。如果我们预测出错（比如我们决定赶紧对病人进行手术，而接下来的操作发现病人实际上没有任何问题，手术完全没有必要），那么我们也能马上观察到结果，并从这个结果中继续学习。&lt;/p&gt;&lt;p&gt;然而，在增强学习中，我们动作的结果通常是有延迟的，因此想要识别并从动作的长期效果中学习变得更加困难了。例如下棋，如果我们在第63手的时候输了（或者赢了），可能非常重要的一点是需要认识到我们在第17手的时候下的一记妙手奠定了胜局。这个“可信度分配（credit assignment）”问题让算法从过去的失误中吸取教训或从过去的成功中学习经验都更加困难了。&lt;/p&gt;&lt;p&gt;其次，在增强学习问题中的连续环境让算法重用（reuse）数据变得更加困难。在有监督学习中，如果我们预先收集并且存储了一些病人的样本数据集，并且想要测试一个新的神经网络在心脏病预测方面的性能，那么我们可以很容易地在这些数据集上进行测试，并分析结果与真实情况之间的差异，从而得出新模型的性能好坏。然而在增强学习中，假设我们也预先测试了一个控制直升机翻转飞行的控制器（或者举个更自然的例子，控制直升机稍微向右倾斜的控制器），在测试期间收集的数据是可以让我们知道直升机是如何翻转飞行的，但是如何使用这些数据来评价一个控制直升机稳定平飞的新控制器呢？目前还不清楚。因此，如果，新控制器控制直升机飞行的方式与之前的不同，那么对于每个新的控制器，我们都需要收集新的数据来进行测试。这个性质使得增强学习相较于有监督学习需要更多的数据。本论文的目标之一就是探索如何在增强学习中高效地重用数据，并且尝试在实用的学习算法中利用这些思想。&lt;/p&gt;&lt;p&gt;最后，增强学习一个常见主题是“不可知论学习（agnostic learning）”（在人工智能领域中，这和界限最优化（bounded optimality）联系紧密）。这个主题是指限制可能的分类器集合的思想，这一思想通常被采用。以上文的心脏病举例来说，相较于考虑所有的将病人的特征映射到{患病，没患病}的函数（这将会是一个巨大的函数空间），我们可以将注意力集中在更小一点的函数集中，比如所有的阈值线性函数，或者所有中等尺寸的神经网络。这样就可以显著地降低我们需要考虑的分类器的数量。如果分辨病人是否患病的“真实”的决策边界极端复杂，以至于没有神经网络能够准确预测分类，那么既然我们已经是将注意力限制在了用神经网络表达的函数上，这就说明我们没法找到一个好的分类器。但是如果决策边界不是那么复杂，那么我们限制的的分类器集合就允许一个分类器展示出只需要少量的训练数据就能够很好地拟合一个神经网络。具体来说，就是训练数据量的需求是由神经网络中“自由参数（free parameter）”的数量决定的，而不是以输入的病人和心脏病的发生的复杂度来决定的。基于在有监督学习中数据可以重用的事实，这些结果是可以证明的。在第四章中，我们将把这些结论一般化到增强学习中，观察针对增强学习问题，通过将我们的注意力限制到一个较小的控制器集合中，我们依旧可以得到类似的结论，即想要算法较好地学习，需要对样本尺寸做出限制。&lt;/p&gt;&lt;h2&gt;1.3 论文概要及贡献&lt;/h2&gt;&lt;blockquote&gt;译者注：意义不大，略过。感兴趣的知友请自行阅读。&lt;/blockquote&gt;&lt;p&gt;&lt;b&gt;第一章原文翻译完毕。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;小结&lt;/h2&gt;&lt;p&gt;翻译本章，主要面向对增强学习没有概念的知友。在第一章中，吴恩达使用无人直升机的例子比较形象直观地介绍了增强学习问题。&lt;b&gt;读者主要理解该例，其他部分适当了解即可&lt;/b&gt;。&lt;/p&gt;&lt;p&gt;&lt;b&gt;在下篇中&lt;/b&gt;，我将编译论文的第二章，其内容主要是用数学公式严谨地对马尔科夫决策过程和增强学习做出定义和讲解。&lt;/p&gt;&lt;h2&gt;读者反馈&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;持续有知友问如何获取cs231n的资源，逐个回复太累，我在“智能单元”微信公众号上做了自动回复，请有需求的知友对公众号回复cs231n或者CS231n即可，也算是给公众号涨点关注。&lt;/li&gt;&lt;li&gt;欢迎想要学习CS294：深度增强学习的知友根据课程推荐材料学习的同时，进行翻译或者编译，本专栏接受投稿。&lt;/li&gt;&lt;li&gt;一如既往地欢迎大家对内容进行批评指正，贡献者我都会在文末更新感谢：）&lt;/li&gt;&lt;/ul&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/24761972&amp;pixel&amp;useReferer"/&gt;</description><author>杜客</author><pubDate>Mon, 09 Jan 2017 11:24:14 GMT</pubDate></item><item><title>CS 294：深度增强学习，2017年春季学期</title><link>https://zhuanlan.zhihu.com/p/24721292</link><description>&lt;blockquote&gt;&lt;b&gt;译者注&lt;/b&gt;：本文编译自&lt;a href="http://rll.berkeley.edu/deeprlcourse/#syllabus" data-title="伯克利大学2017年春季学期课程CS294介绍页面" class="" data-editable="true"&gt;伯克利大学2017年春季学期课程CS294介绍页面&lt;/a&gt;。该课程主题选择深度增强学习，即紧跟当前人工智能研究的热点，又可作为深度学习的后续方向，&lt;b&gt;值得推荐&lt;/b&gt;。&lt;/blockquote&gt;&lt;h2&gt;课程时间&lt;/h2&gt;&lt;p&gt;2017年1月18日至5月3日。&lt;/p&gt;&lt;h2&gt;课程前置要求&lt;/h2&gt;&lt;p&gt;学习该课程，会假设学员对于增强学习，最优化方法和机器学习这些知识背景比较熟悉。要是学员对于这些内容不太了解，就需要根据提供的参考资料补习以下的知识点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;增强学习和马尔科夫决策过程（MDPs）&lt;/li&gt;&lt;ul&gt;&lt;li&gt;MDPs的定义&lt;/li&gt;&lt;li&gt;具体算法：策略迭代和价值迭代&lt;/li&gt;&lt;li&gt;搜索算法&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;数值最优化方法&lt;/li&gt;&lt;ul&gt;&lt;li&gt;梯度下降和随机梯度下降&lt;/li&gt;&lt;li&gt;反向传播算法&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;机器学习&lt;/li&gt;&lt;ul&gt;&lt;li&gt;分类和回归问题：用什么样的损失函数，如何拟合线性或非线性模型&lt;/li&gt;&lt;li&gt;训练/测试误差，过拟合&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;blockquote&gt;译者注：在2016年跟着专栏翻译的CS231n课程笔记学习的知友可以发现，缺少的知识点只有增强学习和马尔科夫决策过程，学习这门课的难度降低。&lt;/blockquote&gt;&lt;p&gt;&lt;b&gt;对于增强学习和MDPs的介绍材料有&lt;/b&gt;：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="http://ai.berkeley.edu/" data-editable="true" data-title="CS188 EdX course"&gt;CS188 EdX course&lt;/a&gt;，从马尔科夫决策过程第一部分开始。&lt;/li&gt;&lt;li&gt;&lt;a href="http://webdocs.cs.ualberta.ca/~sutton/book/the-book.html" data-editable="true" data-title="Sutton &amp;amp; Barto" class=""&gt;Sutton &amp;amp; Barto&lt;/a&gt;的著作，学习第3章和第4章。&lt;/li&gt;&lt;/ul&gt;&lt;blockquote&gt;译者注：该著作&lt;b&gt;重要&lt;/b&gt;，建议中文母语学习者打印该书，方便查阅、学习与装逼：）&lt;/blockquote&gt;&lt;ul&gt;&lt;li&gt;对MDPs的简洁介绍，可以参考&lt;a href="http://rll.berkeley.edu/deeprlcourse/docs/ng-thesis.pdf" data-editable="true" data-title="吴恩达这篇论文" class=""&gt;吴恩达这篇论文&lt;/a&gt;的第1章和第2章。&lt;/li&gt;&lt;/ul&gt;&lt;blockquote&gt;译者注：不想看大部头的著作就看这篇，简明扼要方便理解。&lt;/blockquote&gt;&lt;ul&gt;&lt;li&gt;David Silver的课程，下文有链接。&lt;/li&gt;&lt;/ul&gt;&lt;blockquote&gt;译者注：要是看完并基本掌握了David Silver的课程，这门课也就是看看了。&lt;/blockquote&gt;&lt;p&gt;&lt;b&gt;对于机器学习和神经网络的介绍材料有&lt;/b&gt;：&lt;/p&gt;&lt;li&gt;&lt;a href="http://cs231n.github.io/" data-editable="true" data-title="Andrej Karpathy的课程" class=""&gt;Andrej Karpathy的课程&lt;/a&gt;。&lt;/li&gt;&lt;blockquote&gt;译者注：也就是CS231n了，算成是AK的也不太妥当，毕竟老板是李大姐，讲师还有Justin 。&lt;/blockquote&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="https://www.coursera.org/course/neuralnets" data-editable="true" data-title="Coursera上Hinton大爷的课程"&gt;Coursera上&lt;b&gt;Hinton&lt;/b&gt;大爷的课程&lt;/a&gt;。&lt;/li&gt;&lt;/ul&gt;&lt;blockquote&gt;译者注：拜拜亨大爷总是安心些。&lt;/blockquote&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="https://www.coursera.org/learn/machine-learning/" data-editable="true" data-title="Coursera上吴恩达的课程"&gt;Coursera上吴恩达的课程&lt;/a&gt;。&lt;/li&gt;&lt;li&gt;&lt;a href="https://work.caltech.edu/telecourse.html" data-editable="true" data-title="Yaser Abu-Mostafa’s course" class=""&gt;Yaser Abu-Mostafa的课程&lt;/a&gt;。&lt;/li&gt;&lt;/ul&gt;&lt;blockquote&gt;译者注：本人没有看过这个课程，有学习过的知友可以在评论中简单谈谈感受。&lt;/blockquote&gt;&lt;h2&gt;课程安排&lt;/h2&gt;&lt;p&gt;如下图所示，课件和参考材料会随着课程进度发布。这篇翻译的内容也会同步更新。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-1c31c9c163da64f7d29f14d48965abbe.jpg" data-rawwidth="1938" data-rawheight="1406"&gt;&lt;h2&gt;课程视频&lt;/h2&gt;&lt;p&gt;原文展示了2015年的4个课程视频，在Youtube上，清晰度很低，这里就不放出了，感兴趣的知友自行查看原文。随着课程进展，本部分也更新2017年的课程视频链接。&lt;/p&gt;&lt;h2&gt;相关课程&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="http://www0.cs.ucl.ac.uk/staff/D.Silver/web/Teaching.html" data-editable="true" data-title="David Silver关于增强学习的课程及课程视频" class=""&gt;David Silver关于增强学习的课程及课程视频&lt;/a&gt;。&lt;/li&gt;&lt;/ul&gt;&lt;blockquote&gt;译者注：&lt;b&gt;重要&lt;/b&gt;。&lt;/blockquote&gt;&lt;li&gt;&lt;a href="https://www.cs.ox.ac.uk/people/nando.defreitas/machinelearning/" data-editable="true" data-title="Nando de Freitas关于机器学习的课程" class=""&gt;Nando de Freitas关于机器学习的课程&lt;/a&gt;&lt;/li&gt;&lt;blockquote&gt;译者注：没必要，看吴恩达的课程。&lt;/blockquote&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="http://cs231n.github.io/" data-editable="true" data-title="Andrej Karpathy的课程" class=""&gt;Andrej Karpathy的课程&lt;/a&gt;。&lt;/li&gt;&lt;/ul&gt;&lt;blockquote&gt;译者注：去年我们一直在推荐，不赘述了。&lt;/blockquote&gt;&lt;h2&gt;相关书籍&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="http://webdocs.cs.ualberta.ca/~sutton/book/the-book.html" data-editable="true" data-title="Sutton和Barto的《Reinforcement Learning: An Introduction》" class=""&gt;Sutton和Barto的Reinforcement Learning: An Introduction&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;blockquote&gt;译者注：&lt;b&gt;重要&lt;/b&gt;，系统学习的话就打印吧。&lt;/blockquote&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="http://www.ualberta.ca/~szepesva/RLBook.html" data-editable="true" data-title="Szepesvari, Algorithms for Reinforcement Learning" class=""&gt;Szepesvari, Algorithms for Reinforcement Learning&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="http://www.athenasc.com/dpbook.html" data-editable="true" data-title="Bertsekas, Dynamic Programming and Optimal Control, Vols I and II" class=""&gt;Bertsekas, Dynamic Programming and Optimal Control, Vols I and II&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="http://www.wiley.com/WileyCDA/WileyTitle/productCd-0471727822.html" data-editable="true" data-title="Puterman, Markov Decision Processes: Discrete Stochastic Dynamic Programming" class=""&gt;Puterman, Markov Decision Processes: Discrete Stochastic Dynamic Programming&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="http://adp.princeton.edu/" data-editable="true" data-title="Powell, Approximate Dynamic Programming" class=""&gt;Powell, Approximate Dynamic Programming&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;泛读链接&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="http://rll.berkeley.edu/deeprlcourse/#syllabus" data-editable="true" data-title="深度学习资源的集锦"&gt;深度学习资源的集锦&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;blockquote&gt;译者注：收藏了你也不会看的，但是可以装逼：）&lt;/blockquote&gt;&lt;h2&gt;之前课程&lt;/h2&gt;&lt;p&gt;2015年秋季开过同名课程，介绍链接&lt;a href="http://rll.berkeley.edu/deeprlcourse-fa15/" data-title="点击这里" class="" data-editable="true"&gt;点击这里&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;&lt;b&gt;课程简介翻译完毕&lt;/b&gt;。&lt;/p&gt;&lt;h2&gt;学习建议&lt;/h2&gt;&lt;p&gt;想要学习深度增强学习的知友，在我个人的看来，可能是以下几种情况：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;看到了深度增强学习的前景，想要提前布局，提高自身价值；&lt;/li&gt;&lt;li&gt;学完了深度学习，想要继续学习人工智能领域其他内容；&lt;/li&gt;&lt;li&gt;大公司或者拿了投资的创业公司的项目组想要搞相关应用，比如BetaGo或者GammaGo：）&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;都挺好的，学吧！专栏成立的初心之一，就是促进这个领域的学习和交流。个人也会以这次课程为抓手，再系统性地把深度增强学习给学扎实。后续会以该课程学习为主题，在专栏进行相关内容的写作，也欢迎大家针对课程学习内容进行讨论。&lt;/p&gt;&lt;p&gt;如果是因为近几年人工智能突然火热起来想要学习的知友，需要知道人工智能领域历史上起起落落好几次，入坑前想好自己是不是真的感兴趣。&lt;/p&gt;&lt;p&gt;如果上文中的课程前置要求中三方面知识点都不太熟悉，也不建议直接学习该课程。建议&lt;b&gt;先看吴恩达或者Hinton的课程，然后看CS231n，然后再来学习这门课程&lt;/b&gt;。&lt;/p&gt;&lt;p&gt;最后照例&lt;b&gt;打鸡血：&lt;/b&gt;虽说人工智能起起落落好几次，但是这次确实是解决了之前没有解决的问题，突破了之前没有突破的水平，不是吗？相较于“呵呵，根据历史规律，人工智能也就还能火几年，步子太大要扯到蛋”的态度，我个人更倾向：&lt;/p&gt;&lt;blockquote&gt;&lt;b&gt;I am looking at the future with concern, but with good hope&lt;/b&gt;. &lt;b&gt;-Albert Schweitzer&lt;/b&gt;&lt;/blockquote&gt;&lt;p&gt;----------------------------------------------------------------------------------------&lt;/p&gt;&lt;p&gt;PS：我们开通了&lt;b&gt;智能单元微信公众号&lt;/b&gt;，搜索“&lt;b&gt;智能单元&lt;/b&gt;”就能找到，内容上会和专栏差异化。可以的话请大家关注支持一个，算是对我的鼓励，先谢过啦：）&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/24721292&amp;pixel&amp;useReferer"/&gt;</description><author>杜客</author><pubDate>Thu, 05 Jan 2017 10:26:25 GMT</pubDate></item><item><title>Master 横扫围棋各路高手，是时候全面研究通用人工智能了！</title><link>https://zhuanlan.zhihu.com/p/24709235</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-eab9cfb4a3d814feb1e92cc1b69db9aa_r.png"&gt;&lt;/p&gt;在写这篇文章的时候，聂卫平将挑战Master，不出意外，老聂也只能扑街。&lt;p&gt;有的人说，汽车早就比人跑得快，人也不会惊慌，围棋AI战胜人类，也是迟早的事，同样不必惊慌。&lt;/p&gt;&lt;p&gt;是这样吗？&lt;/p&gt;&lt;p&gt;不是的。&lt;/p&gt;&lt;p&gt;猎豹本来就比人类跑得快，但人类仍然是地球的主宰。为什么？因为人类引以为傲的智慧！&lt;/p&gt;&lt;p&gt;因为人类拥有地球生物中最高的智能，所以虽然人的肉体机能很有限，但是不妨碍人类去创造各种辅助人类的工具。&lt;/p&gt;&lt;p&gt;然而，人工智能，却是一个和汽车，飞机完全不同的东西！我们人类在试图制造超越人类智慧的东西！&lt;/p&gt;&lt;p&gt;当AlphaGo战胜李世石，当Master豪取50连胜的时候，很多人会产生一种对智能的恐惧。相信那些真正和Master战斗的棋手们会更深有体会。&lt;/p&gt;&lt;p&gt;为什么？我们的智慧被超越！我们以前的认识被完全打破了。以至于当今围棋第一人柯洁说出“我们对围棋的理解都是错的”这样的话。&lt;/p&gt;&lt;p&gt;人们也很容易的想到《三体》中水滴入侵人类舰队的那一刻。&lt;/p&gt;&lt;p&gt;那种感觉是何曾的相同。&lt;/p&gt;&lt;p&gt;让人绝望而恐惧！&lt;/p&gt;&lt;p&gt;有人会说，n年前国际象棋就被攻克了，没什么大不了。&lt;/p&gt;&lt;p&gt;但是，&lt;b&gt;这次真的不一样！这次真的不一样！这次真的不一样！&lt;/b&gt;（重要的事情说三篇）&lt;/p&gt;&lt;p&gt;如果你懂深度学习，如果你懂AlphaGo，你就会明白，AlphaGo不再是依靠蛮力计算，而主要是靠深度神经网络，靠增强学习自我学习。&lt;/p&gt;&lt;p&gt;深度神经网络是个黑箱。输入棋局，通过神经网络，输出对棋局的判断。AlphaGo只要这么简单，智能就在神经网络当中。&lt;/p&gt;&lt;p&gt;这次是围棋，完全可观察，如果下次就是&lt;b&gt;星际争霸&lt;/b&gt;，那么大家会作何感想呢？&lt;/p&gt;&lt;p&gt;深度学习正在变革所有行业，AlphaGo则开启了通用人工智能的大门！&lt;/p&gt;&lt;h2&gt;通用人工智能是什么？&lt;/h2&gt;&lt;p&gt;通用人工智能（General Artificial Intelligence），是指能通过自我学习解决各种问题的智能算法。人类的大脑就是一种通用智能，因为人既可以学游泳，也可以学下棋。开发AlphaGo的DeepMind就是这么一家公司，以实现通用人工智能为目标。&lt;/p&gt;&lt;p&gt;通用人工智能并不是等价于类人智能。但解决了通用人工智能，类人智能也必然能够达到。&lt;/p&gt;&lt;p&gt;AlphaGo的算法就是典型的通用人工智能算法，核心使用了深度学习（Deep Learning），增强学习（Reinforcement Learning）。而深度增强学习（Deep Reinforcement Learning），就是通用人工智能算法的具体表现形式。什么叫通用？就是这个算法既可以训练用来下围棋，也可以训练用来开车，还可以训练用来股票交易。&lt;/p&gt;&lt;p&gt;有人说把围棋的路数从19路变成21路，AlphaGo就没辙了。这是没错。但是DeepMind很容易就可以训练一个适应多个路数的AlphaGo。都只是时间问题。&lt;/p&gt;&lt;p&gt;通用人工智能算法就是倚天剑，屠龙刀！算法在手，任何问题都可以尝试去解决！&lt;/p&gt;&lt;p&gt;目前国内的研究还相当少，但是，真的&lt;/p&gt;&lt;p&gt;&lt;b&gt;是时候全面研究通用人工智能了！&lt;/b&gt;&lt;/p&gt;&lt;p&gt;DeepMind和OpenAI正在大力发展，这个才是真正掀起人工智能革命的关键！中国在这一块如果落后的话会非常致命！必须庆幸DeepMind和OpenAI还一直公开他们的论文！&lt;/p&gt;&lt;p&gt;我们从DeepMind和OpenAI研究的方向就知道应该做什么了。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1 Deep Reinforcement Learning深度增强学习，用于构造学习机制&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;2 Deep Generative Model深度生成模型，用于理解信息，可以用于预测规划&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;3 Neural Memory神经网络记忆，用于存储信息和推理&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;4 One Shot Learning 一眼学习，用于快速学习&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;5 Deep Transfer Learning 深度迁移学习，用于移植知识&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;以上多点的综合运用，必将可以制造更强大的通用人工智能算法！而这些方向的研究，都越来越接近人类大脑的本质，或者说智能的本质！&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;要不畏惧人工智能，那只有理解并掌握人工智能！&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;（本文算作一种呼吁，呼吁更多的人工智能研究人员投入到通用人工智能当中。）&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;---------------------------------------&lt;/b&gt;&lt;/p&gt;&lt;p&gt;本专栏将全面聚焦通用人工智能算法！&lt;/p&gt;&lt;p&gt;最后，加一个推广！为了使关注通用人工智能的朋友们能够更及时获取通用人工智能的前沿资讯，我们开通了 &lt;b&gt;智能单元 微信公众号&lt;/b&gt;！第一时间为大家推送最新资讯，并且不定期推送纯原创最新通用人工智能进展的解读！&lt;/p&gt;&lt;p&gt;与大家一起学习，一起进步！&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-864ef735513a261c8140410e43436050.png" data-rawwidth="180" data-rawheight="320"&gt;欢迎在微信上搜索“智能单元” 公众号关注！&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/24709235&amp;pixel&amp;useReferer"/&gt;</description><author>Flood Sung</author><pubDate>Wed, 04 Jan 2017 15:05:39 GMT</pubDate></item><item><title>ICLR 2017 DRL相关论文</title><link>https://zhuanlan.zhihu.com/p/23807875</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-a583638767b7ef5d44ddc68d748af3a5_r.png"&gt;&lt;/p&gt;&lt;h2&gt;1 前言&lt;/h2&gt;&lt;p&gt;ICLR 2017中和Deep Reinforcement Learning相关的论文我这边收集了一下，一共有30篇（可能有漏），大部分来自于DeepMind和OpenAI，可见DRL依然主要由DeepMind和OpenAI把持。由于论文太多，时间有限，先把论文列出来。之后根据情况做一定分析。也欢迎大家一起补充。&lt;/p&gt;&lt;h2&gt;2 DeepMind的论文分析&lt;/h2&gt;&lt;p&gt;&lt;b&gt;[1] LEARNING TO COMPOSE WORDS INTO SENTENCES
WITH REINFORCEMENT LEARNING&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;推荐阅读指数：&lt;/b&gt;⭐️⭐️&lt;/p&gt;&lt;p&gt;&lt;b&gt;论文类型&lt;/b&gt;：应用型&lt;/p&gt;&lt;p&gt;&lt;b&gt;应用方向&lt;/b&gt;：自然语言理解&lt;/p&gt;&lt;p&gt;&lt;b&gt;论文基本内容介绍&lt;/b&gt;：&lt;/p&gt;&lt;p&gt;这篇文章面向一类自然语言理解问题，就是句子的理解，如何更好的输入一个句子的每一个词语，然后输出一个句子的表达。一种方式就是不管句子的结构，一个一个输入到RNN中，然后输出一个向量来表示这个句子的含义，一种就是探索句子的组成树结构（Tree Structure），基于树结构输入词语，然后输出句子的表达。比如“我喜欢打篮球”这句话，很显然，“我，喜欢，打，篮球”可以作为特定的结构输入，就类似于句子的分析，我们显然不会按照“我喜，欢打篮，球”来理解。下图就是两个树结构的范例，要按照不同的顺序组合词语然后输入到RNN中。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-c713955a4285122aece12058ac0acadc.png" data-rawwidth="1862" data-rawheight="514"&gt;&lt;p&gt;那么输入一个句子的每一个词语，输出句子的表达之后，就有用了，可以利用这个输出做很多事：比如判断这个句子是电影的正面评论还是负面平台，判断两个句子是否意思相近，判断两个句子是矛盾，中立还是相同立场，还可以基于句子预测下一个句子。所以句子的理解是自然语言理解的基础，这篇文章的目的也就是希望能够得到更好的句子的理解。&lt;/p&gt;&lt;p&gt;接下来这篇文章做的事情就是使用增强学习来探索句子的树形结构组成，就是说如何构建树结构的问题。如果构造了一个堆栈，然后有一个句子等待输入，那么每一次有两个动作，插入S和合并R。插入就是将一个词语word插入到堆栈，合并就是将两个词语合并。如下图所示：&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-1a21383e6e32c818b9c56985d077a171.png" data-rawwidth="1966" data-rawheight="472"&gt;那么本文使用REINFORCE算法（策略梯度算法）来训练这个树结构的动作选择网络。Reward是在每次生成完整个句子后获取（类似AlphaGo）。具体算法这里不详细介绍。效果是显然的，肯定能够学习到一定的组成句子的方法，从而比那种随便输入的句子理解更好。&lt;/p&gt;&lt;p&gt;&lt;b&gt;论文评价&lt;/b&gt;：一篇中规中矩的Paper，在NLP领域找到了一个不错的应用增强学习的问题，并且取得了一定的效果。但是这种效果并不具有大幅度的提高，也说明其实没必要采用树结构输入，一个一个词语输入其实也可以，只要神经网络能够理解就好。人类就可以做到，虽然人类也分析句子的结构。&lt;/p&gt;&lt;p&gt;&lt;b&gt;[2] LEARNING TO NAVIGATE IN COMPLEX ENVIRONMENTS&lt;/b&gt;&lt;/p&gt;&lt;p&gt;推荐阅读指数：⭐️⭐️⭐️⭐️⭐️&lt;/p&gt;&lt;p&gt;&lt;b&gt;[3] LEARNING TO PERFORM PHYSICS EXPERIMENTS VIA
DEEP REINFORCEMENT LEARNING &lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;[4] PGQ: COMBINING POLICY GRADIENT AND Q-
LEARNING&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;[5] Q-PROP: SAMPLE-EFFICIENT POLICY GRADIENT
WITH AN OFF-POLICY CRITIC&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;[6] REINFORCEMENT LEARNING WITH UNSUPERVISED
AUXILIARY TASKS&lt;/b&gt;&lt;/p&gt;&lt;p&gt;推荐阅读指数：⭐️⭐️⭐️⭐️⭐️&lt;/p&gt;&lt;p&gt;&lt;b&gt;[7] SAMPLE EFFICIENT ACTOR-CRITIC WITH
EXPERIENCE REPLAY&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;[8] THE PREDICTRON: END-TO-END LEARNING AND PLANNING &lt;/b&gt;&lt;/p&gt;&lt;h2&gt;3 OpenAI的论文分析（包含Sergey Levine的论文）&lt;/h2&gt;&lt;p&gt;&lt;b&gt;[9] #EXPLORATION: A STUDY OF COUNT-BASED EXPLORATION
FOR DEEP REINFORCEMENT LEARNING &lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;[10] GENERALIZING SKILLS WITH SEMI-SUPERVISED
REINFORCEMENT LEARNING  &lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;[11] LEARNING INVARIANT FEATURE SPACES TO TRANS-
FER SKILLS WITH REINFORCEMENT LEARNING &lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;[12] LEARNING VISUAL SERVOING WITH DEEP FEATURES
AND TRUST REGION FITTED Q-ITERATION &lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;[13] MODULAR MULTITASK REINFORCEMENT
LEARNING WITH POLICY SKETCHES &lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;[14] STOCHASTIC NEURAL NETWORKS FOR
HIERARCHICAL REINFORCEMENT LEARNING &lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;[15] THIRD PERSON IMITATION LEARNING &lt;/b&gt;&lt;/p&gt;&lt;p&gt;推荐阅读指数：⭐️⭐️⭐️⭐️⭐️&lt;/p&gt;&lt;p&gt;&lt;b&gt;[16] UNSUPERVISED PERCEPTUAL REWARDS
FOR IMITATION LEARNING &lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;[17] EPOPT: LEARNING ROBUST NEURAL NETWORK POLICIES USING MODEL ENSEMBLES &lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;[18] RL2: FAST REINFORCEMENT LEARNING VIA SLOW REINFORCEMENT LEARNING &lt;/b&gt;&lt;/p&gt;&lt;h2&gt;4 其他论文&lt;/h2&gt;&lt;p&gt;&lt;b&gt;[19] COMBATING DEEP REINFORCEMENT LEARNING’S
SISYPHEAN CURSE WITH INTRINSIC FEAR &lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;[20] COMMUNICATING HIERARCHICAL NEURAL
CONTROLLERS FOR LEARNINGZERO-SHOT TASK GENERALIZATION&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;[21] DESIGNING NEURAL NETWORK ARCHITECTURES
USING REINFORCEMENT LEARNING &lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;[22] LEARNING TO PLAY IN A DAY: FASTER DEEP REIN-
FORCEMENT LEARNING BY OPTIMALITY TIGHTENING&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;[23] LEARNING TO REPEAT: FINE GRAINED ACTION REPETITION FOR
DEEP REINFORCEMENT LEARNING &lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;[24] MULTI-TASK LEARNING WITH DEEP MODEL BASED
REINFORCEMENT LEARNING&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;[25] NEURAL ARCHITECTURE SEARCH WITH
REINFORCEMENT LEARNING&lt;/b&gt;&lt;/p&gt;&lt;p&gt;推荐阅读指数：⭐️⭐️⭐️⭐️⭐️&lt;/p&gt;&lt;p&gt;&lt;b&gt;[26] OPTIONS DISCOVERY WITH BUDGETED REINFORCE-
MENT LEARNING  &lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;[27] REINFORCEMENT LEARNING THROUGH ASYNCHRONOUS ADVANTAGE ACTOR-CRITIC ON A GPU &lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;[28] SPATIO-TEMPORAL ABSTRACTIONS IN
REINFORCEMENT LEARNING THROUGH
NEURAL ENCODING &lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;[29] SURPRISE-BASED INTRINSIC MOTIVATION FOR DEEP
REINFORCEMENT LEARNING&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;[30] TUNING RECURRENT NEURAL NETWORKS WITH REINFORCEMENT LEARNING&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;最后，我们开通了智能单元微信公众号，第一时间推送最前沿技术和资讯，欢迎在微信搜索“智能单元”关注。&lt;/b&gt;&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/23807875&amp;pixel&amp;useReferer"/&gt;</description><author>Flood Sung</author><pubDate>Tue, 03 Jan 2017 11:54:32 GMT</pubDate></item><item><title>干货和原创的智能单元微信公众号开启</title><link>https://zhuanlan.zhihu.com/p/24682204</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-8b8c855409438a124291382551cc0cac_r.jpg"&gt;&lt;/p&gt;&lt;p&gt;各位知友2017新年快乐！在新的一年，我们&lt;b&gt;推出智能单元微信公众号，提供有别于知乎专栏的差异化优质内容。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;智能单元微信公众号&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;智能单元微信公众号&lt;/b&gt;是一个致力于&lt;b&gt;推动通用人工智能（Artificial General Intelligence）发展&lt;/b&gt;的原创独立媒体。通过这个平台，我们会给大家：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;分享最有价值的实践：&lt;b&gt;会&lt;u&gt;分享我们的开源代码与软件；&lt;/u&gt;&lt;/b&gt;&lt;/li&gt;&lt;li&gt;分享最前沿的研究成果：会&lt;b&gt;广读领域内新论文并评估分量&lt;/b&gt;，&lt;b&gt;对高价值论文给出第一时间的有态度解读&lt;/b&gt;。详细解读和复现工作还是交给专栏吧！&lt;/li&gt;&lt;li&gt;分享最新鲜的资讯：会推送经我们挑选的有调性的领域内资讯，节约知友们的信息搜索时间。&lt;/li&gt;&lt;/ul&gt;智能单元微信公众号&lt;b&gt;&lt;u&gt;聚焦通用人工智能&lt;/u&gt;，将涉及当前最前沿的机器学习算法&lt;/b&gt;：包&lt;b&gt;括深度学习Deep Learning，增强学习Reinforcement Learning，迁移学习Transfer Learning，神经网络记忆Neural Memory（神经图灵机，DNC），无监督学习（主要是生成式对抗网络GAN）及一眼学习（One Shot Learning）&lt;/b&gt;等。将这些技术应用到机器人当中，将使机器人技术实现变革，使机器人具备学习能力，因此&lt;b&gt;机器人学习&lt;/b&gt;是通用人工智能核心应用方向，也是智能单元关注的核心。&lt;h2&gt;&lt;b&gt;公众号与专栏&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;智能单元专栏重在提供学习材料、展现深度思考&lt;/b&gt;，将专注于：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;通用人工智能相关技术原创教程，主要涉及深度增强学习，生成式对抗网络及神经网络记忆相关技术；&lt;/li&gt;&lt;li&gt;最前沿领域内论文的详细解读；&lt;/li&gt;&lt;li&gt;最前沿领域内技术的分析与总结。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;智能单元微信公众号重在时效性、分享优质内容&lt;/b&gt;，专注方向参见前文，这里不赘述。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;一个小目标&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;2017年，我们期望&lt;b&gt;智能单元知乎专栏&lt;/b&gt;和&lt;b&gt;智能单元微信公众号&lt;/b&gt;既一脉相承，又各有侧重，&lt;b&gt;能够给在人工智能领域的奋斗的知友们提供更多帮助&lt;/b&gt;！&lt;/p&gt;&lt;p&gt;PS：&lt;b&gt;欢迎知友们在评论中留下自己2017年在人工智能领域的小目标&lt;/b&gt;，这将帮助我们更好地提供优质内容。况且，大家相互祝福（&lt;b&gt;吐槽&lt;/b&gt;）难倒不是一件欢乐的事儿吗？&lt;/p&gt;PS2：&lt;b&gt;题图就是二维码，欢迎扫码关注！也可在微信中直接搜索“智能单元”关注我们&lt;/b&gt;！&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/24682204&amp;pixel&amp;useReferer"/&gt;</description><author>杜客</author><pubDate>Tue, 03 Jan 2017 11:27:11 GMT</pubDate></item><item><title>深度学习论文阅读路线图 Deep Learning Papers Reading Roadmap</title><link>https://zhuanlan.zhihu.com/p/23080129</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-6f589df38509d14f839737645322a011_r.jpg"&gt;&lt;/p&gt;&lt;h2&gt;1 前言&lt;/h2&gt;&lt;p&gt;相信很多想入门深度学习的朋友都会遇到这个问题，就是应该看哪些论文。包括我自己，也是花费了大量的时间在寻找文章上。另一方面，对于一些已经入门的朋友，常常也需要了解一些和自己研究方向不同的方向的文章。&lt;/p&gt;&lt;p&gt;因此，这里做了一个深度学习论文阅读路线图，也就是paper list，希望能够帮助大家对深度学习的全貌和具体的方向有一个深入的理解。&lt;/p&gt;&lt;h2&gt;2 路线图的构建原则&lt;/h2&gt;&lt;p&gt;有以下四个原则：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;从整体到局部。即从Survey的文章，影响大局的文章到具体子问题子领域的文章。&lt;/li&gt;&lt;li&gt;从过去到最前沿。即每个topic的文章是按照时间顺序排列的，这样大家就可以清楚的看到这个方向的研究发展脉络。&lt;/li&gt;&lt;li&gt;从通用到应用。即有些深度学习的文章是面向深度学习通用理论，比如Resnet，可以用在任意的神经网络中，而有些文章则是具体应用，比如Image Caption。&lt;/li&gt;&lt;li&gt;面向最前沿。收集的文章会有很多是最新的，甚至就是几天前出来的，这样能保证路线图是最新的。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;每一种topic只选择最有代表性的几篇文章，比如深度增强学习（Deep Reinforcement Learning），这个领域现在有几十篇文章，但只选择几篇，要深入了解甚至做为自己的研究方向，还需要进一步的阅读该领域的文章。&lt;/p&gt;&lt;h2&gt;3 说明&lt;/h2&gt;&lt;p&gt;这个论文阅读路线图选择的文章除了文章本身的影响力和重要性之外，也依赖于本人对文章的理解。因此会有一定的主观性，即我觉得这篇文章好，值得读，所以推荐。这方面需要大家的理解。也欢迎大家提出批评意见以改进。&lt;/p&gt;&lt;p&gt;这个路线图还在完善，会不断更新。&lt;/p&gt;&lt;p&gt;&lt;b&gt;欢迎大家pull requests！（基本要求：一个topic不超过10篇，并且包含当前最前沿和最有影响力的文章，也欢迎增加新的topic）&lt;/b&gt;&lt;/p&gt;&lt;p&gt;路线图在Github上，地址是：&lt;/p&gt;&lt;p&gt;&lt;a href="https://github.com/songrotek/Deep-Learning-Papers-Reading-Roadmap" data-editable="true" data-title="GitHub - songrotek/Deep-Learning-Papers-Reading-Roadmap: Deep Learning papers reading roadmap for anyone who are eager to learn this amazing tech!" class=""&gt;GitHub - songrotek/Deep-Learning-Papers-Reading-Roadmap: Deep Learning papers reading roadmap for anyone who are eager to learn this amazing tech!&lt;/a&gt;&lt;/p&gt;&lt;p&gt;以下是截图：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-eef22d5319df25855f056b2683df8ff3.png" data-rawwidth="2012" data-rawheight="98"&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-cccfd935d9e3f50f963046c3892b61ab.png" data-rawwidth="1880" data-rawheight="1366"&gt;希望对大家有所帮助！&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/23080129&amp;pixel&amp;useReferer"/&gt;</description><author>Flood Sung</author><pubDate>Thu, 20 Oct 2016 12:12:51 GMT</pubDate></item><item><title>深层学习为何要“Deep”（上）</title><link>https://zhuanlan.zhihu.com/p/22888385</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-b1c917b1f2616bc51c7d833fdcc0c05d_r.jpg"&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;2016年11月22日更新：&lt;a href="https://link.zhihu.com/?target=https%3A//yjango.gitbooks.io/superorganism/content/shen_ceng_wang_luo.html" class="" data-editable="true" data-title="深层神经网络为什么要"&gt;深层神经网络为什么要&lt;/a&gt;deep（下）&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;结合&lt;a href="https://yjango.gitbooks.io/superorganism/content/xue_xi.html" class="" data-editable="true" data-title="生物学习"&gt;生物学习&lt;/a&gt;与&lt;a href="https://yjango.gitbooks.io/superorganism/content/tong_ji_xue_xi.html" class="" data-title="机器学习" data-editable="true"&gt;机器学习&lt;/a&gt;一起来看&lt;/b&gt;&lt;/p&gt;&lt;p&gt;深层学习开启了人工智能的新时代。不论任何行业都害怕错过这一时代浪潮，因而大批资金和人才争相涌入。但深层学习却以“黑箱”而闻名，不仅调参难，训练难，“新型”网络结构的论文又如雨后春笋般地涌现，使得对所有结构的掌握变成了不现实。我们缺少一个对深层学习合理的认识。&lt;/p&gt;&lt;p&gt;本文就是通过对深层神经网络惊人表现&lt;b&gt;背后原因&lt;/b&gt;的思考，揭示&lt;b&gt;设计一个神经网络的本质&lt;/b&gt;，从而获得一个对“&lt;b&gt;如何设计&lt;/b&gt;网络”的全局指导。由于问题本身过于庞大，我们先把问题拆分成几部分加以思考。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1、神经网络为什么可以用于识别 （已回答）2、神经网络变深后我们获得了什么 &lt;/b&gt;（已回答）3、“过深”的网络的效果又变差的原因 4、“深浅”会影响神经网络表现的背后原因 5、RNN、CNN以及各种不同网络结构的共性是什么 6、设计神经网络的本质是什么 &lt;/p&gt;&lt;p&gt;文章分为&lt;b&gt;上下&lt;/b&gt;两部分。 &lt;b&gt;上篇&lt;/b&gt;涉及的内容是1,2两个问题，是为了理解“深层”神经网络的&lt;b&gt;预备知识&lt;/b&gt;。描述的是&lt;strong&gt;为何能识别&lt;/strong&gt;和&lt;strong&gt;如何训练&lt;/strong&gt;两部分。看完后能明白的是：1、为什么神经网络&lt;strong&gt;能够&lt;/strong&gt;识别，2、训练网络&lt;strong&gt;基本流程&lt;/strong&gt;，以及深层神经网络大家族中其他技术&lt;strong&gt;想要解决的问题&lt;/strong&gt;（并不需要知道具体的解决步骤）。 &lt;/p&gt;&lt;p&gt;文章的理解需要线性代数基础知识，数学零基础的请看&lt;/p&gt;&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/23361299?refer=YJango" class="" data-editable="true" data-title="串讲 线性代数、概率、熵 - 超有机体 - 知乎专栏"&gt;串讲 线性代数、概率、熵 - 超有机体 - 知乎专栏&lt;/a&gt;&lt;/p&gt;&lt;p&gt;对神经网络有了大致了解后，《深层学习为何要“Deep”（下）》会进一步围绕“深层”二字再次讨论深层学习为何要“Deep”，会讨论CNN、RNN、Transfer learning、distillation training等技术的共性，并解释&lt;strong&gt;设计网络结构的本质&lt;/strong&gt;是什么。&lt;/p&gt;目录&lt;ul&gt;&lt;li&gt;&lt;a href="http://blog.csdn.net/u010751535/article/details/52739803#%E4%B8%80%E5%9F%BA%E6%9C%AC%E5%8F%98%E6%8D%A2%E5%B1%82" data-editable="true" data-title="一基本变换层"&gt;一基本变换层&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="http://blog.csdn.net/u010751535/article/details/52739803#%E4%BA%8C%E7%90%86%E8%A7%A3%E8%A7%86%E8%A7%92" data-editable="true" data-title="二理解视角"&gt;二理解视角&lt;/a&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="http://blog.csdn.net/u010751535/article/details/52739803#%E6%95%B0%E5%AD%A6%E8%A7%86%E8%A7%92%E7%BA%BF%E6%80%A7%E5%8F%AF%E5%88%86" data-editable="true" data-title="数学视角线性可分"&gt;数学视角线性可分&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="http://blog.csdn.net/u010751535/article/details/52739803#%E7%89%A9%E7%90%86%E8%A7%86%E8%A7%92%E7%89%A9%E8%B4%A8%E7%BB%84%E6%88%90" data-editable="true" data-title="物理视角物质组成"&gt;物理视角物质组成&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="http://blog.csdn.net/u010751535/article/details/52739803#%E4%B8%89%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E8%AE%AD%E7%BB%83" data-editable="true" data-title="三神经网络的训练"&gt;三神经网络的训练&lt;/a&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="http://blog.csdn.net/u010751535/article/details/52739803#%E5%A6%82%E4%BD%95%E8%AE%AD%E7%BB%83" data-editable="true" data-title="如何训练"&gt;如何训练&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="http://blog.csdn.net/u010751535/article/details/52739803#%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E7%9A%84%E9%97%AE%E9%A2%98" data-editable="true" data-title="梯度下降的问题"&gt;梯度下降的问题&lt;/a&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="http://blog.csdn.net/u010751535/article/details/52739803#1%E5%B1%80%E9%83%A8%E6%9E%81%E5%B0%8F%E5%80%BC" data-editable="true" data-title="1局部极小值"&gt;1局部极小值&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="http://blog.csdn.net/u010751535/article/details/52739803#2%E6%A2%AF%E5%BA%A6%E7%9A%84%E8%AE%A1%E7%AE%97" data-editable="true" data-title="2梯度的计算" class=""&gt;2梯度的计算&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="http://blog.csdn.net/u010751535/article/details/52739803#%E5%9F%BA%E6%9C%AC%E6%B5%81%E7%A8%8B%E5%9B%BE" data-editable="true" data-title="基本流程图"&gt;基本流程图&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="http://blog.csdn.net/u010751535/article/details/52739803#%E5%9B%9B%E6%B7%B1%E5%B1%82%E7%9A%84%E6%80%9D%E8%80%83%E7%9C%9F%E7%9A%84%E5%8F%AA%E6%9C%89%E8%BF%99%E4%BA%9B%E5%8E%9F%E5%9B%A0%E5%90%97" data-editable="true" data-title="四深层的思考真的只有这些原因吗"&gt;四深层的思考真的只有这些原因吗&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;一、基本变换：层&lt;/h2&gt;&lt;p&gt;神经网络是由一层一层构建的，那么每&lt;strong&gt;层&lt;/strong&gt;究竟在做什么？&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;数学式子&lt;/strong&gt;：&lt;equation&gt;\vec{y}= a(W\cdot\vec{x} + {b})&lt;/equation&gt;，其中&lt;equation&gt;\vec{x}&lt;/equation&gt;是输入向量，&lt;equation&gt;\vec{y}&lt;/equation&gt;是输出向量，&lt;equation&gt;\vec{b}&lt;/equation&gt;是偏移向量，&lt;equation&gt;W&lt;/equation&gt;是权重矩阵，&lt;equation&gt;a()&lt;/equation&gt;是激活函数。每一层仅仅是把输入&lt;equation&gt;\vec x&lt;/equation&gt;经过如此简单的操作得到&lt;equation&gt;\vec y&lt;/equation&gt;。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;数学理解&lt;/strong&gt;：通过如下5种对输入空间（输入向量的集合）的操作，完成 &lt;strong&gt;输入空间 ——&amp;gt; 输出空间&lt;/strong&gt; 的变换 (矩阵的行空间到列空间)。 注：用“空间”二字的原因是被分类的并不是单个事物，而是&lt;strong&gt;一类&lt;/strong&gt;事物。空间是指这类事物所有个体的集合。&lt;ul&gt;&lt;li&gt;&lt;strong&gt;1.&lt;/strong&gt; 升维/降维&lt;/li&gt;&lt;li&gt;&lt;strong&gt;2.&lt;/strong&gt; 放大/缩小&lt;/li&gt;&lt;li&gt;&lt;strong&gt;3.&lt;/strong&gt; 旋转&lt;/li&gt;&lt;li&gt;&lt;strong&gt;4.&lt;/strong&gt; 平移&lt;/li&gt;&lt;li&gt;&lt;strong&gt;5.&lt;/strong&gt; “弯曲” 这5种操作中，1,2,3的操作由&lt;equation&gt;W\cdot\vec{x}&lt;/equation&gt;完成，4的操作是由&lt;equation&gt;+\vec{b}&lt;/equation&gt;完成，5的操作则是由&lt;equation&gt;a()&lt;/equation&gt;来实现。 (此处有动态图&lt;a href="http://colah.github.io/posts/2014-03-NN-Manifolds-Topology/img/1layer.gif" data-editable="true" data-title="5种空间操作" class=""&gt;5种空间操作&lt;/a&gt;，帮助理解)&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-1ebee9a3fb36a6d1502d517b24bfb5c3.jpg" data-rawwidth="239" data-rawheight="233"&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;&lt;blockquote&gt;&lt;p&gt;每层神经网络的数学理解：&lt;strong&gt;用线性变换跟随着非线性变化，将输入空间投向另一个空间&lt;/strong&gt;。&lt;/p&gt;&lt;/blockquote&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;物理理解&lt;/strong&gt;：对 &lt;equation&gt;W\cdot\vec{x}&lt;/equation&gt; 的理解就是&lt;strong&gt;通过组合形成新物质&lt;/strong&gt;。&lt;equation&gt;
a()&lt;/equation&gt;又符合了我们所处的世界都是非线性的特点。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;情景：&lt;/strong&gt;&lt;equation&gt;\vec{x}&lt;/equation&gt;是二维向量，维度是碳原子和氧原子的数量&lt;equation&gt; [C;O]&lt;/equation&gt;，数值且定为&lt;equation&gt;[1;1]&lt;/equation&gt;，若确定&lt;equation&gt;\vec{y}&lt;/equation&gt;是三维向量，就会形成如下网络的形状 (神经网络的每个节点表示一个维度)。通过改变权重的值，可以获得若干个不同物质。右侧的节点数决定了想要获得多少种不同的新物质。（矩阵的行数） &lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-69d03cf2b3677ad7dc3b0d9af58841b4.jpg" data-rawwidth="144" data-rawheight="164"&gt;&lt;strong&gt;1.&lt;/strong&gt;如果权重W的数值如（1），那么网络的输出y⃗ 就会是三个新物质，[二氧化碳，臭氧，一氧化碳]。 &lt;equation&gt;\left[
 \begin{matrix}
   CO_{2}\\
   O_{3}\\
   CO
  \end{matrix}
  \right]=
 \left[
 \begin{matrix}
   1 &amp;amp; 2 \\
   0 &amp;amp; 3\\
   1 &amp;amp; 1
  \end{matrix}
  \right] \cdot \left[
 \begin{matrix}
   C \\
   O \\
  \end{matrix}
  \right]&lt;/equation&gt; （1）&lt;/li&gt;&lt;li&gt;&lt;strong&gt;2.&lt;/strong&gt;也可以减少右侧的一个节点，并改变权重W至（2），那么输出&lt;equation&gt;\vec{y}&lt;/equation&gt; 就会是两个新物质，&lt;equation&gt;[ O_{0.3};CO_{1.5}]&lt;/equation&gt;。  &lt;equation&gt;\left[
 \begin{matrix}
    O_{0.3}\\
   CO_{1.5}\\
  \end{matrix}
  \right]=
 \left[
 \begin{matrix}
   0&amp;amp; 0.3 \\
   1 &amp;amp; 1.5\\
  \end{matrix}
  \right] \cdot \left[
 \begin{matrix}
   C \\
   O \\
  \end{matrix}
  \right]&lt;/equation&gt;（2）&lt;strong&gt;3.&lt;/strong&gt;如果希望通过层网络能够从[C, O]空间转变到&lt;equation&gt;[CO_{2};O_{3};CO]&lt;/equation&gt;空间的话，那么网络的学习过程就是将W的数值变成尽可能接近(1)的过程 。如果再加一层，就是通过组合&lt;equation&gt;[CO_{2};O_{3};CO]&lt;/equation&gt;这三种基础物质，形成若干更高层的物质。 &lt;strong&gt;4.&lt;/strong&gt;重要的是这种组合思想，组合成的东西在神经网络中并不需要有物理意义。 &lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;&lt;blockquote&gt;&lt;p&gt;每层神经网络的物理理解：&lt;strong&gt;通过现有的不同物质的组合形成新物质&lt;/strong&gt;。&lt;/p&gt;&lt;/blockquote&gt;&lt;h1&gt;二、理解视角：&lt;/h1&gt;&lt;p&gt;现在我们知道了每一层的行为，但这种行为又是如何完成识别任务的呢？&lt;/p&gt;&lt;h2&gt;数学视角：“线性可分”&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;一维情景&lt;/strong&gt;：以分类为例，当要分类正数、负数、零，三类的时候，一维空间的直线可以找到两个超平面（比当前空间低一维的子空间。当前空间是直线的话，超平面就是点）分割这三类。但面对像分类奇数和偶数无法找到可以区分它们的点的时候，我们借助 x % 2（取余）的转变，把x变换到另一个空间下来比较，从而分割。 &lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-92ff4b847ac5fa41d91d1e76a910c483.jpg" data-rawwidth="370" data-rawheight="63"&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;二维情景&lt;/strong&gt;：平面的四个象限也是线性可分。但下图的红蓝两条线就无法找到一超平面去分割。 &lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-b1bd0f75b46ed27daf27910f2a6b6e3f.jpg" data-rawwidth="197" data-rawheight="204"&gt;神经网络的解决方法依旧是转换到另外一个空间下，用的是所说的&lt;strong&gt;5种空间变换操作&lt;/strong&gt;。比如下图就是经过放大、平移、旋转、扭曲原二维空间后，在三维空间下就可以成功找到一个超平面分割红蓝两线 (同SVM的思路一样)。 &lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-8d7d1ef957ebbf8ba9bb9cf8ff2d87ff.jpg" data-rawwidth="197" data-rawheight="198"&gt;上面是一层神经网络可以做到的，如果把&lt;equation&gt;\vec{y}&lt;/equation&gt; 当做新的输入再次用这5种操作进行第二遍空间变换的话，网络也就变为了二层。最终输出是&lt;equation&gt;\vec{y}= a_{2}(W_{2}\cdot(a_{1}(W_{1}\cdot\vec{x} + {b}_{1})) + {b}_{2})&lt;/equation&gt;。 设想网络拥有很多层时，对原始输入空间的“扭曲力”会大幅增加，如下图，最终我们可以轻松找到一个超平面分割空间。 &lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-b7d47097d8f10e6baeb329e88e59b563.jpg" data-rawwidth="239" data-rawheight="233"&gt;当然也有如下图失败的时候，关键在于“如何扭曲空间”。所谓监督学习就是给予神经网络网络大量的训练例子，让网络从训练例子中学会如何变换空间。每一层的权重W就&lt;strong&gt;控制着如何变换空间&lt;/strong&gt;，我们最终需要的也就是训练好的神经网络的所有层的权重矩阵。。这里有非常棒的&lt;a href="http://cs.stanford.edu/people/karpathy/convnetjs//demo/classify2d.html" data-editable="true" data-title="可视化空间变换demo"&gt;可视化空间变换demo&lt;/a&gt;，&lt;strong&gt;一定要&lt;/strong&gt;打开尝试并感受这种扭曲过程。更多内容请看&lt;a href="http://colah.github.io/posts/2014-03-NN-Manifolds-Topology/" data-editable="true" data-title="Neural Networks, Manifolds, and Topology"&gt;Neural Networks, Manifolds, and Topology&lt;/a&gt;。 &lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-664c152ffc58a28a7f900f9a723cbb83.jpg" data-rawwidth="239" data-rawheight="233"&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;上面的内容有三张动态图，对于理解这种空间变化非常有帮助。可以在gitbook&lt;a href="https://yjango.gitbooks.io/-deep/content/wei_he_you_yong.html" class="" data-editable="true" data-title="深层学习为何要“deep”"&gt;深层学习为何要“deep”&lt;/a&gt;上感受那三张图。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;线性可分视角：神经网络的学习就是&lt;strong&gt;学习如何利用矩阵的线性变换加激活函数的非线性变换，将原始输入空间投向线性可分/稀疏的空间去分类/回归。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;增加节点数：增加维度，即增加线性转换能力。&lt;/strong&gt;&lt;strong&gt;增加层数：增加激活函数的次数，即增加非线性转换次数。&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;h2&gt;物理视角：“物质组成”&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;类比&lt;/strong&gt;：回想上文由碳氧原子通过不同组合形成若干分子的例子。从分子层面继续迭代这种组合思想，可以形成DNA，细胞，组织，器官，最终可以形成一个完整的人。继续迭代还会有家庭，公司，国家等。这种现象在身边随处可见。并且原子的内部结构与太阳系又惊人的相似。不同层级之间都是以类似的几种规则再不断形成新物质。你也可能听过&lt;strong&gt;分形学&lt;/strong&gt;这三个字。可通过观看&lt;a href="http://www.tudou.com/programs/view/o41zy0SeSS0" data-editable="true" data-title="从1米到150亿光年" class=""&gt;从1米到150亿光年&lt;/a&gt;来感受自然界这种层级现象的普遍性。 &lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-3ec7216f7ab84dac089836b166c0ae28.jpg" data-rawwidth="488" data-rawheight="340"&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;人脸识别情景&lt;/strong&gt;：我们可以模拟这种思想并应用在画面识别上。由像素组成菱角再组成五官最后到不同的人脸。每一层代表不同的不同的物质层面 (如分子层)。而每层的W&lt;strong&gt;存储着如何组合上一层的物质从而形成新物质&lt;/strong&gt;。 如果我们完全掌握一架飞机是如何从分子开始一层一层形成的，拿到一堆分子后，我们就可以判断他们是否可以以此形成方式，形成一架飞机。 附：&lt;a href="http://playground.tensorflow.org/" data-editable="true" data-title="Tensorflow playground"&gt;Tensorflow playground&lt;/a&gt;展示了数据是如何“流动”的。 &lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-82f05552fd2ddde28a0ef20814d7acbb.png" data-rawwidth="624" data-rawheight="218"&gt;&lt;/li&gt;&lt;/ul&gt;&lt;blockquote&gt;&lt;p&gt;物质组成视角：神经网络的学习过程就是&lt;strong&gt;学习物质组成方式的过程。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;增加节点数：增加同一层物质的种类，比如118个元素的原子层就有118个节点。&lt;/strong&gt;&lt;strong&gt;增加层数：增加更多层级，比如分子层，原子层，器官层，并通过判断更抽象的概念来识别物体。&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;h1&gt;三、神经网络的训练&lt;/h1&gt;&lt;p&gt;知道了神经网络的学习过程就是&lt;strong&gt;学习&lt;/strong&gt;控制着空间变换方式（物质组成方式）的&lt;strong&gt;权重矩阵&lt;/strong&gt;后，接下来的问题就是&lt;strong&gt;如何学习&lt;/strong&gt;每一层的权重矩阵W。&lt;/p&gt;&lt;h2&gt;如何训练：&lt;/h2&gt;&lt;p&gt;既然我们希望网络的输出尽可能的接近真正想要预测的值。那么就可以通过&lt;strong&gt;比较&lt;/strong&gt;当前网络的&lt;strong&gt;预测值&lt;/strong&gt;和我们真正想要的&lt;strong&gt;目标值&lt;/strong&gt;，再根据两者的差异情况来更新每一层的权重矩阵（比如，如果网络的预测值高了，就调整权重让它预测低一些，不断调整，直到能够预测出目标值）。因此就需要先&lt;strong&gt;定义“如何比较&lt;/strong&gt;预测值和目标值的&lt;strong&gt;差异&lt;/strong&gt;”，这便是&lt;strong&gt;损失函数或目标函数（loss function or objective function）&lt;/strong&gt;，用于衡量预测值和目标值的差异的方程。loss function的输出值（loss）越高表示差异性越大。那神经网络的训练就变成了尽可能的缩小loss的过程。 所用的方法是&lt;strong&gt;梯度下降（Gradient descent）&lt;/strong&gt;：通过使loss值向当前点对应梯度的反方向不断移动，来降低loss。一次移动多少是由&lt;strong&gt;学习速率（learning rate）&lt;/strong&gt;来控制的。&lt;/p&gt;&lt;h2&gt;梯度下降的问题：&lt;/h2&gt;&lt;p&gt;然而使用梯度下降训练神经网络拥有两个主要难题。&lt;/p&gt;&lt;h3&gt;1、局部极小值&lt;/h3&gt;&lt;p&gt;梯度下降寻找的是loss function的局部极小值，而我们想要全局最小值。如下图所示，我们希望loss值可以降低到右侧深蓝色的最低点，但loss有可能“卡”在左侧的局部极小值中。 &lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-00fe10bf8877137bc5957cf0cd7f9219.png" data-rawwidth="420" data-rawheight="250"&gt;试图解决“卡在局部极小值”问题的方法分两大类：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;调节步伐：&lt;/strong&gt;调节学习速率，使每一次的更新“步伐”不同。常用方法有：&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;随机梯度下降（Stochastic Gradient Descent (SGD)：每次只更新一个样本所计算的梯度&lt;/p&gt;&lt;/li&gt;&lt;li&gt;小批量梯度下降（Mini-batch gradient descent）：每次更新若干样本所计算的梯度的平均值&lt;/li&gt;&lt;li&gt;动量（Momentum）：不仅仅考虑当前样本所计算的梯度；Nesterov动量（Nesterov Momentum）：Momentum的改进&lt;/li&gt;&lt;li&gt;&lt;p&gt;Adagrad、RMSProp、Adadelta、Adam：这些方法都是训练过程中依照规则降低学习速率，部分也综合动量&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;优化起点&lt;/strong&gt;：合理初始化权重（weights initialization）、预训练网络（pre-train），使网络获得一个较好的“起始点”，如最右侧的起始点就比最左侧的起始点要好。常用方法有：高斯分布初始权重（Gaussian distribution）、均匀分布初始权重（Uniform distribution）、Glorot 初始权重、He初始权、稀疏矩阵初始权重（sparse matrix）&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;2、梯度的计算&lt;/h3&gt;&lt;p&gt;机器学习所处理的数据都是高维数据，该&lt;strong&gt;如何快速计算梯度&lt;/strong&gt;、而不是以年来计算。 其次如何更新&lt;strong&gt;隐藏层&lt;/strong&gt;的权重？ 解决方法是：计算图：&lt;strong&gt;反向传播算法&lt;/strong&gt;这里的解释留给非常棒的&lt;a href="http://colah.github.io/posts/2015-08-Backprop/" data-editable="true" data-title="Computational Graphs: Backpropagation" class=""&gt;Computational Graphs: Backpropagation&lt;/a&gt;需要知道的是，&lt;strong&gt;反向传播算法是求梯度的一种方法&lt;/strong&gt;。如同快速傅里叶变换（FFT）的贡献。 而计算图的概念又使梯度的计算更加合理方便。&lt;/p&gt;&lt;h3&gt;基本流程图：&lt;/h3&gt;&lt;p&gt;下面就结合图简单浏览一下训练和识别过程，并描述各个部分的作用。要&lt;b&gt;结合图解阅读以下内容。但手机显示的图过小，最好用电脑打开&lt;/b&gt;。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-af6c22793412bfc37e1428369a0e36e0.jpg" data-rawwidth="743" data-rawheight="345"&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;收集训练集（train data）：&lt;/strong&gt;也就是同时有input以及对应label的数据。每个数据叫做训练样本（sample）。label也叫target，也是机器学习中最贵的部分。上图表示的是我的数据库。假设input本别是x的维度是39，label的维度是48。&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;设计网络结构（architecture）：&lt;/strong&gt;确定层数、每一隐藏层的节点数和激活函数，以及输出层的激活函数和损失函数。上图用的是两层隐藏层（最后一层是输出层）。隐藏层所用激活函数a( )是ReLu，输出层的激活函数是线性linear（也可看成是没有激活函数）。隐藏层都是1000节点。损失函数L( )是用于比较距离MSE：mean((output - target)^2)。MSE越小表示预测效果越好。训练过程就是不断减小MSE的过程。到此所有数据的维度都已确定：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;训练数据：&lt;equation&gt;input \in R^{39} ;label \in R^{48}&lt;/equation&gt;&lt;/li&gt;&lt;li&gt;权重矩阵：&lt;equation&gt;W_{h1}\in R^{1000x39};W_{h2}\in R^{1000x1000} ;W_{o}\in R^{48x1000}&lt;/equation&gt;&lt;/li&gt;&lt;li&gt;偏移向量：&lt;equation&gt;b_{h1}\in R^{1000};b_{h2}\in R^{1000} ;b_{o}\in R^{48}&lt;/equation&gt;&lt;/li&gt;&lt;li&gt;网络输出：&lt;equation&gt;output \in R^{48}&lt;/equation&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;数据预处理（preprocessing）：&lt;/strong&gt;将所有样本的input和label处理成能够使用神经网络的数据，label的值域符合激活函数的值域。并简单优化数据以便让训练易于收敛。比如中心化（mean subtraction）、归一化（normlization）、主成分分析（PCA）、白化（whitening）。假设上图的input和output全都经过了中心化和归一化。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;权重初始化（weights initialization）&lt;/strong&gt;：&lt;equation&gt;W_{h1},W_{h2},W_{0}&lt;/equation&gt;在训练前不能为空，要初始化才能够计算loss从而来降低。&lt;equation&gt;W_{h1},W_{h2},W_{0}&lt;/equation&gt;初始化决定了loss在loss function中从哪个点开始作为起点训练网络。上图用均匀分布初始权重（Uniform distribution）。&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;训练网络（training）&lt;/strong&gt;：训练过程就是用训练数据的input经过网络计算出output，再和label计算出loss，再计算出gradients来更新weights的过程。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;正向传递：，算当前网络的预测值&lt;equation&gt;output =linear (W_{o} \cdot Relu(W_{h2}\cdot Relu(W_{h1}\cdot input+b_{h1})+b_{h2}) +b_{o})&lt;/equation&gt;&lt;/li&gt;&lt;li&gt;计算loss：&lt;equation&gt;loss = mean((output - target)^2)&lt;/equation&gt;&lt;/li&gt;&lt;li&gt;计算梯度：从loss开始反向传播计算每个参数（parameters）对应的梯度（gradients）。这里用Stochastic Gradient Descent (SGD) 来计算梯度，即每次更新所计算的梯度都是从一个样本计算出来的。传统的方法Gradient Descent是正向传递所有样本来计算梯度。SGD的方法来计算梯度的话，loss function的形状如下图所示会有变化，这样在更新中就有可能“跳出”局部最小值。 &lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-0c0e7f5ffa98c2c1eb87763dd5d1d9a3.png" data-rawwidth="469" data-rawheight="227"&gt;&lt;/li&gt;&lt;li&gt;更新权重：这里用最简单的方法来更新，即所有参数都 &lt;equation&gt;W = W - learningrate * gradient&lt;/equation&gt;&lt;/li&gt;&lt;li&gt;预测新值：训练过所有样本后，打乱样本顺序再次训练若干次。训练完毕后，当再来新的数据input，就可以利用训练的网络来预测了。这时的output就是效果很好的预测值了。下图是一张&lt;b&gt;实际值&lt;/b&gt;和&lt;b&gt;预测值&lt;/b&gt;的三组对比图。输出数据是48维，这里只取1个维度来画图。蓝色的是实际值，绿色的是实际值。最上方的是训练数据的对比图，而下方的两行是神经网络模型&lt;b&gt;从未见过&lt;/b&gt;的数据预测对比图。（不过这里用的是RNN，主要是为了让大家感受一下效果）&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-a675e692f7f7755d91bcdba5e988e910.jpg" data-rawwidth="2000" data-rawheight="1600"&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;注：此部分内容&lt;strong&gt;不是&lt;/strong&gt;这篇文章的&lt;strong&gt;重点&lt;/strong&gt;，但为了理解&lt;strong&gt;深层&lt;/strong&gt;神经网络，需要明白最基本的训练过程。 若能理解训练过程是通过梯度下降尽可能缩小loss的过程即可。 若有理解障碍，可以用python实践一下&lt;a href="http://www.wildml.com/2015/09/implementing-a-neural-network-from-scratch/" data-editable="true" data-title="从零开始训练一个神经网络" class=""&gt;从零开始训练一个神经网络&lt;/a&gt;，体会整个训练过程。若有时间则可以再体会一下计算图自动求梯度的方便&lt;a href="https://www.tensorflow.org/versions/r0.11/tutorials/mnist/beginners/index.html#mnist-for-ml-beginners" data-editable="true" data-title="利用TensorFlow" class=""&gt;利用TensorFlow&lt;/a&gt;。&lt;/p&gt;&lt;h2&gt;结合&lt;a href="https://link.zhihu.com/?target=http%3A//playground.tensorflow.org/" class="" data-editable="true" data-title="Tensorflow playground"&gt;Tensorflow playground&lt;/a&gt;理解&lt;b&gt;5种空间操作&lt;/b&gt;和&lt;b&gt;物质组成视角&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;打开网页后，总体来说，蓝色代表正值，黄色代表负值。拿&lt;b&gt;分类&lt;/b&gt;任务来分析。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;数据：在二维平面内，若干点被标记成了两种颜色。黄色，蓝色，表示想要区分的两类。你可以把平面内的任意点标记成任意颜色。网页给你提供了4种规律。神经网络会根据你给的数据训练，再分类相同规律的点。&lt;/li&gt;&lt;/ul&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-6d17d1fb77d3ae1838f5253193456317.png" data-rawwidth="173" data-rawheight="169"&gt;&lt;ul&gt;&lt;li&gt;输入：在二维平面内，你想给网络多少关于“点”的信息。从颜色就可以看出来，&lt;equation&gt;x_{1}&lt;/equation&gt;左边是负，右边是正，&lt;equation&gt;x_{1}&lt;/equation&gt;表示此点的横坐标值。同理，&lt;equation&gt;x_{2}&lt;/equation&gt;表示此点的纵坐标值。&lt;equation&gt;x_{1}^{2}&lt;/equation&gt;是关于横坐标值的“抛物线”信息。你也可以给更多关于这个点的信息。给的越多，越容易被分开。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-111e37e8479aa57bedbfb2dbcd8e5b63.png" data-rawwidth="92" data-rawheight="228"&gt;&lt;/li&gt;&lt;li&gt;连接线：表示权重，蓝色表示用神经元的原始输出，黄色表示用负输出。深浅表示权重的绝对值大小。鼠标放在线上可以看到具体值。也可以更改。在（1）中，当把&lt;equation&gt;x_{2}&lt;/equation&gt;输出的一个权重改为-1时，&lt;equation&gt;x_{2}&lt;/equation&gt;的形状直接倒置了。不过还需要考虑激活函数。（1）中用的是linear。在（2）中，当换成sigmoid时，你会发现没有黄色区域了。因为sigmoid的值域是(0,1)&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-2820b0562c8fcd7a49d57c4deb1e4f3c.png" data-rawwidth="315" data-rawheight="136"&gt;（1）&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-83fd9f01e2ea38c7f6b8aeaa308cf040.png" data-rawwidth="294" data-rawheight="123"&gt;（2）&lt;/li&gt;&lt;li&gt;输出：黄色背景颜色都被归为黄点类，蓝色背景颜色都被归为蓝点类。深浅表示可能性的强弱。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-dff3f6e72881ebd222414eabb9504671.png" data-rawwidth="1116" data-rawheight="363"&gt;上图中所有在黄色背景颜色的点都会被分类为“黄点“，同理，蓝色区域被分成蓝点。在上面的分类分布图中你可以看到每一层通过上一层信息的组合所形成的。权重（那些连接线）控制了“如何组合”。神经网络的学习也就是从数据中学习那些权重。Tensorflow playground所表现出来的现象就是“在我文章里所写的“物质组成思想”，这也是为什么我把&lt;a href="https://link.zhihu.com/?target=http%3A//playground.tensorflow.org/" class="" data-editable="true" data-title="Tensorflow playground"&gt;Tensorflow playground&lt;/a&gt;放在了那一部分。&lt;/li&gt;&lt;/ul&gt;不过你要是把Tensorflow的个名字拆开来看的话，是tensor（张量）的flow（流动）。Tensorflow playground的作者想要阐述的侧重点是“&lt;b&gt;张量如何流动&lt;/b&gt;”的。&lt;b&gt;5种空间变换的理解&lt;/b&gt;：Tensorflow playground下没有体现5种空间变换的理解。需要打开这个网站尝试：&lt;a href="http://cs.stanford.edu/people/karpathy/convnetjs//demo/classify2d.html" data-editable="true" data-title="ConvNetJS demo: Classify toy 2D data" class=""&gt;ConvNetJS demo: Classify toy 2D data&lt;/a&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-55811ac3d91f56f19543714b1b5abe49.png" data-rawwidth="841" data-rawheight="425"&gt;左侧是原始输入空间下的分类图，右侧是转换后的高维空间下的扭曲图。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-a81a10592b96a1d2b067e1d4ae3951e7.png" data-rawwidth="848" data-rawheight="417"&gt;最终的扭曲效果是所有绿点都被扭曲到了一侧，而所有红点都被扭曲到了另一侧。这样就可以线性分割（用超平面（这里是一个平面）在中间分开两类）&lt;h1&gt;四、“深层”的思考：真的只有这些原因吗？&lt;/h1&gt;&lt;p&gt;文章的最后稍微提一下深层神经网络。深层神经网络就是拥有更多层数的神经网络。&lt;/p&gt;&lt;p&gt;按照上文在理解视角中所述的观点，可以想出下面两条理由关于为什么更深的网络会更加容易识别，增加容纳变异体（variation）（红苹果、绿苹果）的能力、鲁棒性（robust）。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;数学视角&lt;/strong&gt;：变异体（variation）很多的分类的任务需要高度非线性的分割曲线。不断的利用那5种空间变换操作将原始输入空间像“捏橡皮泥一样”在高维空间下捏成更为线性可分/稀疏的形状。 &lt;strong&gt;物理视角&lt;/strong&gt;：通过对“&lt;strong&gt;抽象概念&lt;/strong&gt;”的判断来识别物体，而非细节。比如对“飞机”的判断，即便人类自己也无法用语言或者若干条规则来解释自己如何判断一个飞机。因为人脑中真正判断的不是是否“有机翼”、“能飞行”等细节现象，而是一个抽象概念。层数越深，这种概念就越抽象，所能&lt;strong&gt;涵盖的变异体&lt;/strong&gt;就越多，就可以容纳战斗机，客机等很多种不同种类的飞机。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;然而深层神经网络的惊人表现真的只有这些原因吗？&lt;/strong&gt;&lt;strong&gt;为什么神经网络过深后，预测的表现又变差？ 而且这时变差的原因是由于“过深”吗？&lt;/strong&gt;&lt;strong&gt;接下来要写的《深层学习为何要“Deep”（下）》是关于“深层”二字的进一步思考，找出所有网络结构的共性，并解释设计神经网络的本质是什么。&lt;/strong&gt;&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/22888385&amp;pixel&amp;useReferer"/&gt;</description><author>YJango</author><pubDate>Wed, 12 Oct 2016 02:33:48 GMT</pubDate></item></channel></rss>