<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>智能单元 - 知乎专栏</title><link>https://zhuanlan.zhihu.com/intelligentunit</link><description>面向通用人工智能和机器人学习，聚焦深度增强学习，可微神经计算机和生成对抗模型。</description><lastBuildDate>Thu, 05 Jan 2017 17:15:11 GMT</lastBuildDate><generator>Ricky</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>CS 294：深度增强学习，2017年春季学期</title><link>https://zhuanlan.zhihu.com/p/24721292</link><description>&lt;blockquote&gt;&lt;b&gt;译者注&lt;/b&gt;：本文编译自&lt;a href="http://rll.berkeley.edu/deeprlcourse/#syllabus" data-title="伯克利大学2017年春季学期课程CS294介绍页面" class="" data-editable="true"&gt;伯克利大学2017年春季学期课程CS294介绍页面&lt;/a&gt;。该课程主题选择深度增强学习，即紧跟当前人工智能研究的热点，又可作为深度学习的后续方向，&lt;b&gt;值得推荐&lt;/b&gt;。&lt;/blockquote&gt;&lt;h2&gt;课程时间&lt;/h2&gt;&lt;p&gt;2017年1月18日至5月3日。&lt;/p&gt;&lt;h2&gt;课程前置要求&lt;/h2&gt;&lt;p&gt;学习该课程，会假设学员对于增强学习，最优化方法和机器学习这些知识背景比较熟悉。要是学员对于这些内容不太了解，就需要根据提供的参考资料补习以下的知识点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;增强学习和马尔科夫决策过程（MDPs）&lt;/li&gt;&lt;ul&gt;&lt;li&gt;MDPs的定义&lt;/li&gt;&lt;li&gt;具体算法：策略迭代和价值迭代&lt;/li&gt;&lt;li&gt;搜索算法&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;数值最优化方法&lt;/li&gt;&lt;ul&gt;&lt;li&gt;梯度下降和随机梯度下降&lt;/li&gt;&lt;li&gt;反向传播算法&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;机器学习&lt;/li&gt;&lt;ul&gt;&lt;li&gt;分类和回归问题：用什么样的损失函数，如何拟合线性或非线性模型&lt;/li&gt;&lt;li&gt;训练/测试误差，过拟合&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;blockquote&gt;译者注：在2016年跟着专栏翻译的CS231n课程笔记学习的知友可以发现，缺少的知识点只有增强学习和马尔科夫决策过程，学习这门课的难度降低。&lt;/blockquote&gt;&lt;p&gt;&lt;b&gt;对于增强学习和MDPs的介绍材料有&lt;/b&gt;：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="http://ai.berkeley.edu/" data-editable="true" data-title="CS188 EdX course"&gt;CS188 EdX course&lt;/a&gt;，从马尔科夫决策过程第一部分开始。&lt;/li&gt;&lt;li&gt;&lt;a href="http://webdocs.cs.ualberta.ca/~sutton/book/the-book.html" data-editable="true" data-title="Sutton &amp;amp; Barto" class=""&gt;Sutton &amp;amp; Barto&lt;/a&gt;的著作，学习第3章和第4章。&lt;/li&gt;&lt;/ul&gt;&lt;blockquote&gt;译者注：该著作&lt;b&gt;重要&lt;/b&gt;，建议中文母语学习者打印该书，方便查阅、学习与装逼：）&lt;/blockquote&gt;&lt;ul&gt;&lt;li&gt;对MDPs的简洁介绍，可以参考&lt;a href="http://rll.berkeley.edu/deeprlcourse/docs/ng-thesis.pdf" data-editable="true" data-title="吴恩达这篇论文" class=""&gt;吴恩达这篇论文&lt;/a&gt;的第1章和第2章。&lt;/li&gt;&lt;/ul&gt;&lt;blockquote&gt;译者注：不想看大部头的著作就看这篇，简明扼要方便理解。&lt;/blockquote&gt;&lt;ul&gt;&lt;li&gt;David Silver的课程，下文有链接。&lt;/li&gt;&lt;/ul&gt;&lt;blockquote&gt;译者注：要是看完并基本掌握了David Silver的课程，这门课也就是看看了。&lt;/blockquote&gt;&lt;p&gt;&lt;b&gt;对于机器学习和神经网络的介绍材料有&lt;/b&gt;：&lt;/p&gt;&lt;li&gt;&lt;a href="http://cs231n.github.io/" data-editable="true" data-title="Andrej Karpathy的课程" class=""&gt;Andrej Karpathy的课程&lt;/a&gt;。&lt;/li&gt;&lt;blockquote&gt;译者注：也就是CS231n了，算成是AK的也不太妥当，毕竟老板是李大姐，讲师还有Justin 。&lt;/blockquote&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="https://www.coursera.org/course/neuralnets" data-editable="true" data-title="Coursera上Hinton大爷的课程"&gt;Coursera上&lt;b&gt;Hinton&lt;/b&gt;大爷的课程&lt;/a&gt;。&lt;/li&gt;&lt;/ul&gt;&lt;blockquote&gt;译者注：拜拜亨大爷总是安心些。&lt;/blockquote&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="https://www.coursera.org/learn/machine-learning/" data-editable="true" data-title="Coursera上吴恩达的课程"&gt;Coursera上吴恩达的课程&lt;/a&gt;。&lt;/li&gt;&lt;li&gt;&lt;a href="https://work.caltech.edu/telecourse.html" data-editable="true" data-title="Yaser Abu-Mostafa’s course" class=""&gt;Yaser Abu-Mostafa的课程&lt;/a&gt;。&lt;/li&gt;&lt;/ul&gt;&lt;blockquote&gt;译者注：本人没有看过这个课程，有学习过的知友可以在评论中简单谈谈感受。&lt;/blockquote&gt;&lt;h2&gt;课程安排&lt;/h2&gt;&lt;p&gt;如下图所示，课件和参考材料会随着课程进度发布。这篇翻译的内容也会同步更新。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-1c31c9c163da64f7d29f14d48965abbe.jpg" data-rawwidth="1938" data-rawheight="1406"&gt;&lt;h2&gt;课程视频&lt;/h2&gt;&lt;p&gt;原文展示了2015年的4个课程视频，在Youtube上，清晰度很低，这里就不放出了，感兴趣的知友自行查看原文。随着课程进展，本部分也更新2017年的课程视频链接。&lt;/p&gt;&lt;h2&gt;相关课程&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="http://www0.cs.ucl.ac.uk/staff/D.Silver/web/Teaching.html" data-editable="true" data-title="David Silver关于增强学习的课程及课程视频" class=""&gt;David Silver关于增强学习的课程及课程视频&lt;/a&gt;。&lt;/li&gt;&lt;/ul&gt;&lt;blockquote&gt;译者注：&lt;b&gt;重要&lt;/b&gt;。&lt;/blockquote&gt;&lt;li&gt;&lt;a href="https://www.cs.ox.ac.uk/people/nando.defreitas/machinelearning/" data-editable="true" data-title="Nando de Freitas关于机器学习的课程" class=""&gt;Nando de Freitas关于机器学习的课程&lt;/a&gt;&lt;/li&gt;&lt;blockquote&gt;译者注：没必要，看吴恩达的课程。&lt;/blockquote&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="http://cs231n.github.io/" data-editable="true" data-title="Andrej Karpathy的课程" class=""&gt;Andrej Karpathy的课程&lt;/a&gt;。&lt;/li&gt;&lt;/ul&gt;&lt;blockquote&gt;译者注：去年我们一直在推荐，不赘述了。&lt;/blockquote&gt;&lt;h2&gt;相关书籍&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="http://webdocs.cs.ualberta.ca/~sutton/book/the-book.html" data-editable="true" data-title="Sutton和Barto的《Reinforcement Learning: An Introduction》" class=""&gt;Sutton和Barto的Reinforcement Learning: An Introduction&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;blockquote&gt;译者注：&lt;b&gt;重要&lt;/b&gt;，系统学习的话就打印吧。&lt;/blockquote&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="http://www.ualberta.ca/~szepesva/RLBook.html" data-editable="true" data-title="Szepesvari, Algorithms for Reinforcement Learning" class=""&gt;Szepesvari, Algorithms for Reinforcement Learning&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="http://www.athenasc.com/dpbook.html" data-editable="true" data-title="Bertsekas, Dynamic Programming and Optimal Control, Vols I and II" class=""&gt;Bertsekas, Dynamic Programming and Optimal Control, Vols I and II&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="http://www.wiley.com/WileyCDA/WileyTitle/productCd-0471727822.html" data-editable="true" data-title="Puterman, Markov Decision Processes: Discrete Stochastic Dynamic Programming" class=""&gt;Puterman, Markov Decision Processes: Discrete Stochastic Dynamic Programming&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="http://adp.princeton.edu/" data-editable="true" data-title="Powell, Approximate Dynamic Programming" class=""&gt;Powell, Approximate Dynamic Programming&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;泛读链接&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="http://rll.berkeley.edu/deeprlcourse/#syllabus" data-editable="true" data-title="深度学习资源的集锦"&gt;深度学习资源的集锦&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;blockquote&gt;译者注：收藏了你也不会看的，但是可以装逼：）&lt;/blockquote&gt;&lt;h2&gt;之前课程&lt;/h2&gt;&lt;p&gt;2015年秋季开过同名课程，介绍链接&lt;a href="http://rll.berkeley.edu/deeprlcourse-fa15/" data-title="点击这里" class="" data-editable="true"&gt;点击这里&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;&lt;b&gt;课程简介翻译完毕&lt;/b&gt;。&lt;/p&gt;&lt;h2&gt;学习建议&lt;/h2&gt;&lt;p&gt;想要学习深度增强学习的知友，在我个人的看来，可能是以下几种情况：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;看到了深度增强学习的前景，想要提前布局，提高自身价值；&lt;/li&gt;&lt;li&gt;学完了深度学习，想要继续学习人工智能领域其他内容；&lt;/li&gt;&lt;li&gt;大公司或者拿了投资的创业公司的项目组想要搞相关应用，比如BetaGo或者GammaGo：）&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;都挺好的，学吧！专栏成立的初心之一，就是促进这个领域的学习和交流。个人也会以这次课程为抓手，再系统性地把深度增强学习给学扎实。后续会以该课程学习为主题，在专栏进行相关内容的写作，也欢迎大家针对课程学习内容进行讨论。&lt;/p&gt;&lt;p&gt;如果是因为近几年人工智能突然火热起来想要学习的知友，需要知道人工智能领域历史上起起落落好几次，入坑前想好自己是不是真的感兴趣。&lt;/p&gt;&lt;p&gt;如果上文中的课程前置要求中三方面知识点都不太熟悉，也不建议直接学习该课程。建议&lt;b&gt;先看吴恩达或者Hinton的课程，然后看CS231n，然后再来学习这门课程&lt;/b&gt;。&lt;/p&gt;&lt;p&gt;最后照例&lt;b&gt;打鸡血：&lt;/b&gt;虽说人工智能起起落落好几次，但是这次确实是解决了之前没有解决的问题，突破了之前没有突破的水平，不是吗？相较于“呵呵，根据历史规律，人工智能也就还能火几年，步子太大要扯到蛋”的态度，我个人更倾向：&lt;/p&gt;&lt;blockquote&gt;&lt;b&gt;I am looking at the future with concern, but with good hope&lt;/b&gt;. &lt;b&gt;-Albert Schweitzer&lt;/b&gt;&lt;/blockquote&gt;&lt;p&gt;----------------------------------------------------------------------------------------&lt;/p&gt;&lt;p&gt;PS：我们开通了&lt;b&gt;智能单元微信公众号&lt;/b&gt;，搜索“&lt;b&gt;智能单元&lt;/b&gt;”就能找到，内容上会和专栏差异化。可以的话请大家关注支持一个，算是对我的鼓励，先谢过啦：）&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/24721292&amp;pixel&amp;useReferer"/&gt;</description><author>杜客</author><pubDate>Thu, 05 Jan 2017 10:26:25 GMT</pubDate></item><item><title>Master 横扫围棋各路高手，是时候全面研究通用人工智能了！</title><link>https://zhuanlan.zhihu.com/p/24709235</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-eab9cfb4a3d814feb1e92cc1b69db9aa_r.png"&gt;&lt;/p&gt;在写这篇文章的时候，聂卫平将挑战Master，不出意外，老聂也只能扑街。&lt;p&gt;有的人说，汽车早就比人跑得快，人也不会惊慌，围棋AI战胜人类，也是迟早的事，同样不必惊慌。&lt;/p&gt;&lt;p&gt;是这样吗？&lt;/p&gt;&lt;p&gt;不是的。&lt;/p&gt;&lt;p&gt;猎豹本来就比人类跑得快，但人类仍然是地球的主宰。为什么？因为人类引以为傲的智慧！&lt;/p&gt;&lt;p&gt;因为人类拥有地球生物中最高的智能，所以虽然人的肉体机能很有限，但是不妨碍人类去创造各种辅助人类的工具。&lt;/p&gt;&lt;p&gt;然而，人工智能，却是一个和汽车，飞机完全不同的东西！我们人类在试图制造超越人类智慧的东西！&lt;/p&gt;&lt;p&gt;当AlphaGo战胜李世石，当Master豪取50连胜的时候，很多人会产生一种对智能的恐惧。相信那些真正和Master战斗的棋手们会更深有体会。&lt;/p&gt;&lt;p&gt;为什么？我们的智慧被超越！我们以前的认识被完全打破了。以至于当今围棋第一人柯洁说出“我们对围棋的理解都是错的”这样的话。&lt;/p&gt;&lt;p&gt;人们也很容易的想到《三体》中水滴入侵人类舰队的那一刻。&lt;/p&gt;&lt;p&gt;那种感觉是何曾的相同。&lt;/p&gt;&lt;p&gt;让人绝望而恐惧！&lt;/p&gt;&lt;p&gt;有人会说，n年前国际象棋就被攻克了，没什么大不了。&lt;/p&gt;&lt;p&gt;但是，&lt;b&gt;这次真的不一样！这次真的不一样！这次真的不一样！&lt;/b&gt;（重要的事情说三篇）&lt;/p&gt;&lt;p&gt;如果你懂深度学习，如果你懂AlphaGo，你就会明白，AlphaGo不再是依靠蛮力计算，而主要是靠深度神经网络，靠增强学习自我学习。&lt;/p&gt;&lt;p&gt;深度神经网络是个黑箱。输入棋局，通过神经网络，输出对棋局的判断。AlphaGo只要这么简单，智能就在神经网络当中。&lt;/p&gt;&lt;p&gt;这次是围棋，完全可观察，如果下次就是&lt;b&gt;星际争霸&lt;/b&gt;，那么大家会作何感想呢？&lt;/p&gt;&lt;p&gt;深度学习正在变革所有行业，AlphaGo则开启了通用人工智能的大门！&lt;/p&gt;&lt;h2&gt;通用人工智能是什么？&lt;/h2&gt;&lt;p&gt;通用人工智能（General Artificial Intelligence），是指能通过自我学习解决各种问题的智能算法。人类的大脑就是一种通用智能，因为人既可以学游泳，也可以学下棋。开发AlphaGo的DeepMind就是这么一家公司，以实现通用人工智能为目标。&lt;/p&gt;&lt;p&gt;通用人工智能并不是等价于类人智能。但解决了通用人工智能，类人智能也必然能够达到。&lt;/p&gt;&lt;p&gt;AlphaGo的算法就是典型的通用人工智能算法，核心使用了深度学习（Deep Learning），增强学习（Reinforcement Learning）。而深度增强学习（Deep Reinforcement Learning），就是通用人工智能算法的具体表现形式。什么叫通用？就是这个算法既可以训练用来下围棋，也可以训练用来开车，还可以训练用来股票交易。&lt;/p&gt;&lt;p&gt;有人说把围棋的路数从19路变成21路，AlphaGo就没辙了。这是没错。但是DeepMind很容易就可以训练一个适应多个路数的AlphaGo。都只是时间问题。&lt;/p&gt;&lt;p&gt;通用人工智能算法就是倚天剑，屠龙刀！算法在手，任何问题都可以尝试去解决！&lt;/p&gt;&lt;p&gt;目前国内的研究还相当少，但是，真的&lt;/p&gt;&lt;p&gt;&lt;b&gt;是时候全面研究通用人工智能了！&lt;/b&gt;&lt;/p&gt;&lt;p&gt;DeepMind和OpenAI正在大力发展，这个才是真正掀起人工智能革命的关键！中国在这一块如果落后的话会非常致命！必须庆幸DeepMind和OpenAI还一直公开他们的论文！&lt;/p&gt;&lt;p&gt;我们从DeepMind和OpenAI研究的方向就知道应该做什么了。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1 Deep Reinforcement Learning深度增强学习，用于构造学习机制&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;2 Deep Generative Model深度生成模型，用于理解信息，可以用于预测规划&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;3 Neural Memory神经网络记忆，用于存储信息和推理&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;4 One Shot Learning 一眼学习，用于快速学习&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;5 Deep Transfer Learning 深度迁移学习，用于移植知识&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;以上多点的综合运用，必将可以制造更强大的通用人工智能算法！而这些方向的研究，都越来越接近人类大脑的本质，或者说智能的本质！&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;要不畏惧人工智能，那只有理解并掌握人工智能！&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;（本文算作一种呼吁，呼吁更多的人工智能研究人员投入到通用人工智能当中。）&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;---------------------------------------&lt;/b&gt;&lt;/p&gt;&lt;p&gt;本专栏将全面聚焦通用人工智能算法！&lt;/p&gt;&lt;p&gt;最后，加一个推广！为了使关注通用人工智能的朋友们能够更及时获取通用人工智能的前沿资讯，我们开通了 &lt;b&gt;智能单元 微信公众号&lt;/b&gt;！第一时间为大家推送最新资讯，并且不定期推送纯原创最新通用人工智能进展的解读！&lt;/p&gt;&lt;p&gt;与大家一起学习，一起进步！&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-864ef735513a261c8140410e43436050.png" data-rawwidth="180" data-rawheight="320"&gt;欢迎在微信上搜索“智能单元” 公众号关注！&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/24709235&amp;pixel&amp;useReferer"/&gt;</description><author>Flood Sung</author><pubDate>Wed, 04 Jan 2017 15:05:39 GMT</pubDate></item><item><title>ICLR 2017 DRL相关论文</title><link>https://zhuanlan.zhihu.com/p/23807875</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-a583638767b7ef5d44ddc68d748af3a5_r.png"&gt;&lt;/p&gt;&lt;h2&gt;1 前言&lt;/h2&gt;&lt;p&gt;ICLR 2017中和Deep Reinforcement Learning相关的论文我这边收集了一下，一共有30篇（可能有漏），大部分来自于DeepMind和OpenAI，可见DRL依然主要由DeepMind和OpenAI把持。由于论文太多，时间有限，先把论文列出来。之后根据情况做一定分析。也欢迎大家一起补充。&lt;/p&gt;&lt;h2&gt;2 DeepMind的论文分析&lt;/h2&gt;&lt;p&gt;&lt;b&gt;[1] LEARNING TO COMPOSE WORDS INTO SENTENCES
WITH REINFORCEMENT LEARNING&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;推荐阅读指数：&lt;/b&gt;⭐️⭐️&lt;/p&gt;&lt;p&gt;&lt;b&gt;论文类型&lt;/b&gt;：应用型&lt;/p&gt;&lt;p&gt;&lt;b&gt;应用方向&lt;/b&gt;：自然语言理解&lt;/p&gt;&lt;p&gt;&lt;b&gt;论文基本内容介绍&lt;/b&gt;：&lt;/p&gt;&lt;p&gt;这篇文章面向一类自然语言理解问题，就是句子的理解，如何更好的输入一个句子的每一个词语，然后输出一个句子的表达。一种方式就是不管句子的结构，一个一个输入到RNN中，然后输出一个向量来表示这个句子的含义，一种就是探索句子的组成树结构（Tree Structure），基于树结构输入词语，然后输出句子的表达。比如“我喜欢打篮球”这句话，很显然，“我，喜欢，打，篮球”可以作为特定的结构输入，就类似于句子的分析，我们显然不会按照“我喜，欢打篮，球”来理解。下图就是两个树结构的范例，要按照不同的顺序组合词语然后输入到RNN中。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-c713955a4285122aece12058ac0acadc.png" data-rawwidth="1862" data-rawheight="514"&gt;&lt;p&gt;那么输入一个句子的每一个词语，输出句子的表达之后，就有用了，可以利用这个输出做很多事：比如判断这个句子是电影的正面评论还是负面平台，判断两个句子是否意思相近，判断两个句子是矛盾，中立还是相同立场，还可以基于句子预测下一个句子。所以句子的理解是自然语言理解的基础，这篇文章的目的也就是希望能够得到更好的句子的理解。&lt;/p&gt;&lt;p&gt;接下来这篇文章做的事情就是使用增强学习来探索句子的树形结构组成，就是说如何构建树结构的问题。如果构造了一个堆栈，然后有一个句子等待输入，那么每一次有两个动作，插入S和合并R。插入就是将一个词语word插入到堆栈，合并就是将两个词语合并。如下图所示：&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-1a21383e6e32c818b9c56985d077a171.png" data-rawwidth="1966" data-rawheight="472"&gt;那么本文使用REINFORCE算法（策略梯度算法）来训练这个树结构的动作选择网络。Reward是在每次生成完整个句子后获取（类似AlphaGo）。具体算法这里不详细介绍。效果是显然的，肯定能够学习到一定的组成句子的方法，从而比那种随便输入的句子理解更好。&lt;/p&gt;&lt;p&gt;&lt;b&gt;论文评价&lt;/b&gt;：一篇中规中矩的Paper，在NLP领域找到了一个不错的应用增强学习的问题，并且取得了一定的效果。但是这种效果并不具有大幅度的提高，也说明其实没必要采用树结构输入，一个一个词语输入其实也可以，只要神经网络能够理解就好。人类就可以做到，虽然人类也分析句子的结构。&lt;/p&gt;&lt;p&gt;&lt;b&gt;[2] LEARNING TO NAVIGATE IN COMPLEX ENVIRONMENTS&lt;/b&gt;&lt;/p&gt;&lt;p&gt;推荐阅读指数：⭐️⭐️⭐️⭐️⭐️&lt;/p&gt;&lt;p&gt;&lt;b&gt;[3] LEARNING TO PERFORM PHYSICS EXPERIMENTS VIA
DEEP REINFORCEMENT LEARNING &lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;[4] PGQ: COMBINING POLICY GRADIENT AND Q-
LEARNING&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;[5] Q-PROP: SAMPLE-EFFICIENT POLICY GRADIENT
WITH AN OFF-POLICY CRITIC&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;[6] REINFORCEMENT LEARNING WITH UNSUPERVISED
AUXILIARY TASKS&lt;/b&gt;&lt;/p&gt;&lt;p&gt;推荐阅读指数：⭐️⭐️⭐️⭐️⭐️&lt;/p&gt;&lt;p&gt;&lt;b&gt;[7] SAMPLE EFFICIENT ACTOR-CRITIC WITH
EXPERIENCE REPLAY&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;[8] THE PREDICTRON: END-TO-END LEARNING AND PLANNING &lt;/b&gt;&lt;/p&gt;&lt;h2&gt;3 OpenAI的论文分析（包含Sergey Levine的论文）&lt;/h2&gt;&lt;p&gt;&lt;b&gt;[9] #EXPLORATION: A STUDY OF COUNT-BASED EXPLORATION
FOR DEEP REINFORCEMENT LEARNING &lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;[10] GENERALIZING SKILLS WITH SEMI-SUPERVISED
REINFORCEMENT LEARNING  &lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;[11] LEARNING INVARIANT FEATURE SPACES TO TRANS-
FER SKILLS WITH REINFORCEMENT LEARNING &lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;[12] LEARNING VISUAL SERVOING WITH DEEP FEATURES
AND TRUST REGION FITTED Q-ITERATION &lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;[13] MODULAR MULTITASK REINFORCEMENT
LEARNING WITH POLICY SKETCHES &lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;[14] STOCHASTIC NEURAL NETWORKS FOR
HIERARCHICAL REINFORCEMENT LEARNING &lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;[15] THIRD PERSON IMITATION LEARNING &lt;/b&gt;&lt;/p&gt;&lt;p&gt;推荐阅读指数：⭐️⭐️⭐️⭐️⭐️&lt;/p&gt;&lt;p&gt;&lt;b&gt;[16] UNSUPERVISED PERCEPTUAL REWARDS
FOR IMITATION LEARNING &lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;[17] EPOPT: LEARNING ROBUST NEURAL NETWORK POLICIES USING MODEL ENSEMBLES &lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;[18] RL2: FAST REINFORCEMENT LEARNING VIA SLOW REINFORCEMENT LEARNING &lt;/b&gt;&lt;/p&gt;&lt;h2&gt;4 其他论文&lt;/h2&gt;&lt;p&gt;&lt;b&gt;[19] COMBATING DEEP REINFORCEMENT LEARNING’S
SISYPHEAN CURSE WITH INTRINSIC FEAR &lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;[20] COMMUNICATING HIERARCHICAL NEURAL
CONTROLLERS FOR LEARNINGZERO-SHOT TASK GENERALIZATION&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;[21] DESIGNING NEURAL NETWORK ARCHITECTURES
USING REINFORCEMENT LEARNING &lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;[22] LEARNING TO PLAY IN A DAY: FASTER DEEP REIN-
FORCEMENT LEARNING BY OPTIMALITY TIGHTENING&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;[23] LEARNING TO REPEAT: FINE GRAINED ACTION REPETITION FOR
DEEP REINFORCEMENT LEARNING &lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;[24] MULTI-TASK LEARNING WITH DEEP MODEL BASED
REINFORCEMENT LEARNING&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;[25] NEURAL ARCHITECTURE SEARCH WITH
REINFORCEMENT LEARNING&lt;/b&gt;&lt;/p&gt;&lt;p&gt;推荐阅读指数：⭐️⭐️⭐️⭐️⭐️&lt;/p&gt;&lt;p&gt;&lt;b&gt;[26] OPTIONS DISCOVERY WITH BUDGETED REINFORCE-
MENT LEARNING  &lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;[27] REINFORCEMENT LEARNING THROUGH ASYNCHRONOUS ADVANTAGE ACTOR-CRITIC ON A GPU &lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;[28] SPATIO-TEMPORAL ABSTRACTIONS IN
REINFORCEMENT LEARNING THROUGH
NEURAL ENCODING &lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;[29] SURPRISE-BASED INTRINSIC MOTIVATION FOR DEEP
REINFORCEMENT LEARNING&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;[30] TUNING RECURRENT NEURAL NETWORKS WITH REINFORCEMENT LEARNING&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;最后，我们开通了智能单元微信公众号，第一时间推送最前沿技术和资讯，欢迎在微信搜索“智能单元”关注。&lt;/b&gt;&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/23807875&amp;pixel&amp;useReferer"/&gt;</description><author>Flood Sung</author><pubDate>Tue, 03 Jan 2017 11:54:32 GMT</pubDate></item><item><title>干货和原创的智能单元微信公众号开启</title><link>https://zhuanlan.zhihu.com/p/24682204</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-8b8c855409438a124291382551cc0cac_r.jpg"&gt;&lt;/p&gt;&lt;p&gt;各位知友2017新年快乐！在新的一年，我们&lt;b&gt;推出智能单元微信公众号，提供有别于知乎专栏的差异化优质内容。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;智能单元微信公众号&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;智能单元微信公众号&lt;/b&gt;是一个致力于&lt;b&gt;推动通用人工智能（Artificial General Intelligence）发展&lt;/b&gt;的原创独立媒体。通过这个平台，我们会给大家：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;分享最有价值的实践：&lt;b&gt;会&lt;u&gt;分享我们的开源代码与软件；&lt;/u&gt;&lt;/b&gt;&lt;/li&gt;&lt;li&gt;分享最前沿的研究成果：会&lt;b&gt;广读领域内新论文并评估分量&lt;/b&gt;，&lt;b&gt;对高价值论文给出第一时间的有态度解读&lt;/b&gt;。详细解读和复现工作还是交给专栏吧！&lt;/li&gt;&lt;li&gt;分享最新鲜的资讯：会推送经我们挑选的有调性的领域内资讯，节约知友们的信息搜索时间。&lt;/li&gt;&lt;/ul&gt;智能单元微信公众号&lt;b&gt;&lt;u&gt;聚焦通用人工智能&lt;/u&gt;，将涉及当前最前沿的机器学习算法&lt;/b&gt;：包&lt;b&gt;括深度学习Deep Learning，增强学习Reinforcement Learning，迁移学习Transfer Learning，神经网络记忆Neural Memory（神经图灵机，DNC），无监督学习（主要是生成式对抗网络GAN）及一眼学习（One Shot Learning）&lt;/b&gt;等。将这些技术应用到机器人当中，将使机器人技术实现变革，使机器人具备学习能力，因此&lt;b&gt;机器人学习&lt;/b&gt;是通用人工智能核心应用方向，也是智能单元关注的核心。&lt;h2&gt;&lt;b&gt;公众号与专栏&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;智能单元专栏重在提供学习材料、展现深度思考&lt;/b&gt;，将专注于：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;通用人工智能相关技术原创教程，主要涉及深度增强学习，生成式对抗网络及神经网络记忆相关技术；&lt;/li&gt;&lt;li&gt;最前沿领域内论文的详细解读；&lt;/li&gt;&lt;li&gt;最前沿领域内技术的分析与总结。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;智能单元微信公众号重在时效性、分享优质内容&lt;/b&gt;，专注方向参见前文，这里不赘述。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;一个小目标&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;2017年，我们期望&lt;b&gt;智能单元知乎专栏&lt;/b&gt;和&lt;b&gt;智能单元微信公众号&lt;/b&gt;既一脉相承，又各有侧重，&lt;b&gt;能够给在人工智能领域的奋斗的知友们提供更多帮助&lt;/b&gt;！&lt;/p&gt;&lt;p&gt;PS：&lt;b&gt;欢迎知友们在评论中留下自己2017年在人工智能领域的小目标&lt;/b&gt;，这将帮助我们更好地提供优质内容。况且，大家相互祝福（&lt;b&gt;吐槽&lt;/b&gt;）难倒不是一件欢乐的事儿吗？&lt;/p&gt;PS2：&lt;b&gt;题图就是二维码，欢迎扫码关注！也可在微信中直接搜索“智能单元”关注我们&lt;/b&gt;！&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/24682204&amp;pixel&amp;useReferer"/&gt;</description><author>杜客</author><pubDate>Tue, 03 Jan 2017 11:27:11 GMT</pubDate></item><item><title>深度学习论文阅读路线图 Deep Learning Papers Reading Roadmap</title><link>https://zhuanlan.zhihu.com/p/23080129</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-6f589df38509d14f839737645322a011_r.jpg"&gt;&lt;/p&gt;&lt;h2&gt;1 前言&lt;/h2&gt;&lt;p&gt;相信很多想入门深度学习的朋友都会遇到这个问题，就是应该看哪些论文。包括我自己，也是花费了大量的时间在寻找文章上。另一方面，对于一些已经入门的朋友，常常也需要了解一些和自己研究方向不同的方向的文章。&lt;/p&gt;&lt;p&gt;因此，这里做了一个深度学习论文阅读路线图，也就是paper list，希望能够帮助大家对深度学习的全貌和具体的方向有一个深入的理解。&lt;/p&gt;&lt;h2&gt;2 路线图的构建原则&lt;/h2&gt;&lt;p&gt;有以下四个原则：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;从整体到局部。即从Survey的文章，影响大局的文章到具体子问题子领域的文章。&lt;/li&gt;&lt;li&gt;从过去到最前沿。即每个topic的文章是按照时间顺序排列的，这样大家就可以清楚的看到这个方向的研究发展脉络。&lt;/li&gt;&lt;li&gt;从通用到应用。即有些深度学习的文章是面向深度学习通用理论，比如Resnet，可以用在任意的神经网络中，而有些文章则是具体应用，比如Image Caption。&lt;/li&gt;&lt;li&gt;面向最前沿。收集的文章会有很多是最新的，甚至就是几天前出来的，这样能保证路线图是最新的。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;每一种topic只选择最有代表性的几篇文章，比如深度增强学习（Deep Reinforcement Learning），这个领域现在有几十篇文章，但只选择几篇，要深入了解甚至做为自己的研究方向，还需要进一步的阅读该领域的文章。&lt;/p&gt;&lt;h2&gt;3 说明&lt;/h2&gt;&lt;p&gt;这个论文阅读路线图选择的文章除了文章本身的影响力和重要性之外，也依赖于本人对文章的理解。因此会有一定的主观性，即我觉得这篇文章好，值得读，所以推荐。这方面需要大家的理解。也欢迎大家提出批评意见以改进。&lt;/p&gt;&lt;p&gt;这个路线图还在完善，会不断更新。&lt;/p&gt;&lt;p&gt;&lt;b&gt;欢迎大家pull requests！（基本要求：一个topic不超过10篇，并且包含当前最前沿和最有影响力的文章，也欢迎增加新的topic）&lt;/b&gt;&lt;/p&gt;&lt;p&gt;路线图在Github上，地址是：&lt;/p&gt;&lt;p&gt;&lt;a href="https://github.com/songrotek/Deep-Learning-Papers-Reading-Roadmap" data-editable="true" data-title="GitHub - songrotek/Deep-Learning-Papers-Reading-Roadmap: Deep Learning papers reading roadmap for anyone who are eager to learn this amazing tech!" class=""&gt;GitHub - songrotek/Deep-Learning-Papers-Reading-Roadmap: Deep Learning papers reading roadmap for anyone who are eager to learn this amazing tech!&lt;/a&gt;&lt;/p&gt;&lt;p&gt;以下是截图：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-eef22d5319df25855f056b2683df8ff3.png" data-rawwidth="2012" data-rawheight="98"&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-cccfd935d9e3f50f963046c3892b61ab.png" data-rawwidth="1880" data-rawheight="1366"&gt;希望对大家有所帮助！&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/23080129&amp;pixel&amp;useReferer"/&gt;</description><author>Flood Sung</author><pubDate>Thu, 20 Oct 2016 12:12:51 GMT</pubDate></item><item><title>深层学习为何要“Deep”（上）</title><link>https://zhuanlan.zhihu.com/p/22888385</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-b1c917b1f2616bc51c7d833fdcc0c05d_r.jpg"&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;2016年11月22日更新：&lt;a href="https://link.zhihu.com/?target=https%3A//yjango.gitbooks.io/superorganism/content/shen_ceng_wang_luo.html" class="" data-editable="true" data-title="深层神经网络为什么要"&gt;深层神经网络为什么要&lt;/a&gt;deep（下）&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;结合&lt;a href="https://yjango.gitbooks.io/superorganism/content/xue_xi.html" class="" data-editable="true" data-title="生物学习"&gt;生物学习&lt;/a&gt;与&lt;a href="https://yjango.gitbooks.io/superorganism/content/tong_ji_xue_xi.html" class="" data-title="机器学习" data-editable="true"&gt;机器学习&lt;/a&gt;一起来看&lt;/b&gt;&lt;/p&gt;&lt;p&gt;深层学习开启了人工智能的新时代。不论任何行业都害怕错过这一时代浪潮，因而大批资金和人才争相涌入。但深层学习却以“黑箱”而闻名，不仅调参难，训练难，“新型”网络结构的论文又如雨后春笋般地涌现，使得对所有结构的掌握变成了不现实。我们缺少一个对深层学习合理的认识。&lt;/p&gt;&lt;p&gt;本文就是通过对深层神经网络惊人表现&lt;b&gt;背后原因&lt;/b&gt;的思考，揭示&lt;b&gt;设计一个神经网络的本质&lt;/b&gt;，从而获得一个对“&lt;b&gt;如何设计&lt;/b&gt;网络”的全局指导。由于问题本身过于庞大，我们先把问题拆分成几部分加以思考。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1、神经网络为什么可以用于识别 （已回答）2、神经网络变深后我们获得了什么 &lt;/b&gt;（已回答）3、“过深”的网络的效果又变差的原因 4、“深浅”会影响神经网络表现的背后原因 5、RNN、CNN以及各种不同网络结构的共性是什么 6、设计神经网络的本质是什么 &lt;/p&gt;&lt;p&gt;文章分为&lt;b&gt;上下&lt;/b&gt;两部分。 &lt;b&gt;上篇&lt;/b&gt;涉及的内容是1,2两个问题，是为了理解“深层”神经网络的&lt;b&gt;预备知识&lt;/b&gt;。描述的是&lt;strong&gt;为何能识别&lt;/strong&gt;和&lt;strong&gt;如何训练&lt;/strong&gt;两部分。看完后能明白的是：1、为什么神经网络&lt;strong&gt;能够&lt;/strong&gt;识别，2、训练网络&lt;strong&gt;基本流程&lt;/strong&gt;，以及深层神经网络大家族中其他技术&lt;strong&gt;想要解决的问题&lt;/strong&gt;（并不需要知道具体的解决步骤）。 &lt;/p&gt;&lt;p&gt;文章的理解需要线性代数基础知识，数学零基础的请看&lt;/p&gt;&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/23361299?refer=YJango" class="" data-editable="true" data-title="串讲 线性代数、概率、熵 - 超有机体 - 知乎专栏"&gt;串讲 线性代数、概率、熵 - 超有机体 - 知乎专栏&lt;/a&gt;&lt;/p&gt;&lt;p&gt;对神经网络有了大致了解后，《深层学习为何要“Deep”（下）》会进一步围绕“深层”二字再次讨论深层学习为何要“Deep”，会讨论CNN、RNN、Transfer learning、distillation training等技术的共性，并解释&lt;strong&gt;设计网络结构的本质&lt;/strong&gt;是什么。&lt;/p&gt;目录&lt;ul&gt;&lt;li&gt;&lt;a href="http://blog.csdn.net/u010751535/article/details/52739803#%E4%B8%80%E5%9F%BA%E6%9C%AC%E5%8F%98%E6%8D%A2%E5%B1%82" data-editable="true" data-title="一基本变换层"&gt;一基本变换层&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="http://blog.csdn.net/u010751535/article/details/52739803#%E4%BA%8C%E7%90%86%E8%A7%A3%E8%A7%86%E8%A7%92" data-editable="true" data-title="二理解视角"&gt;二理解视角&lt;/a&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="http://blog.csdn.net/u010751535/article/details/52739803#%E6%95%B0%E5%AD%A6%E8%A7%86%E8%A7%92%E7%BA%BF%E6%80%A7%E5%8F%AF%E5%88%86" data-editable="true" data-title="数学视角线性可分"&gt;数学视角线性可分&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="http://blog.csdn.net/u010751535/article/details/52739803#%E7%89%A9%E7%90%86%E8%A7%86%E8%A7%92%E7%89%A9%E8%B4%A8%E7%BB%84%E6%88%90" data-editable="true" data-title="物理视角物质组成"&gt;物理视角物质组成&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="http://blog.csdn.net/u010751535/article/details/52739803#%E4%B8%89%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E8%AE%AD%E7%BB%83" data-editable="true" data-title="三神经网络的训练"&gt;三神经网络的训练&lt;/a&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="http://blog.csdn.net/u010751535/article/details/52739803#%E5%A6%82%E4%BD%95%E8%AE%AD%E7%BB%83" data-editable="true" data-title="如何训练"&gt;如何训练&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="http://blog.csdn.net/u010751535/article/details/52739803#%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E7%9A%84%E9%97%AE%E9%A2%98" data-editable="true" data-title="梯度下降的问题"&gt;梯度下降的问题&lt;/a&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="http://blog.csdn.net/u010751535/article/details/52739803#1%E5%B1%80%E9%83%A8%E6%9E%81%E5%B0%8F%E5%80%BC" data-editable="true" data-title="1局部极小值"&gt;1局部极小值&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="http://blog.csdn.net/u010751535/article/details/52739803#2%E6%A2%AF%E5%BA%A6%E7%9A%84%E8%AE%A1%E7%AE%97" data-editable="true" data-title="2梯度的计算" class=""&gt;2梯度的计算&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="http://blog.csdn.net/u010751535/article/details/52739803#%E5%9F%BA%E6%9C%AC%E6%B5%81%E7%A8%8B%E5%9B%BE" data-editable="true" data-title="基本流程图"&gt;基本流程图&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="http://blog.csdn.net/u010751535/article/details/52739803#%E5%9B%9B%E6%B7%B1%E5%B1%82%E7%9A%84%E6%80%9D%E8%80%83%E7%9C%9F%E7%9A%84%E5%8F%AA%E6%9C%89%E8%BF%99%E4%BA%9B%E5%8E%9F%E5%9B%A0%E5%90%97" data-editable="true" data-title="四深层的思考真的只有这些原因吗"&gt;四深层的思考真的只有这些原因吗&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;一、基本变换：层&lt;/h2&gt;&lt;p&gt;神经网络是由一层一层构建的，那么每&lt;strong&gt;层&lt;/strong&gt;究竟在做什么？&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;数学式子&lt;/strong&gt;：&lt;equation&gt;\vec{y}= a(W\cdot\vec{x} + {b})&lt;/equation&gt;，其中&lt;equation&gt;\vec{x}&lt;/equation&gt;是输入向量，&lt;equation&gt;\vec{y}&lt;/equation&gt;是输出向量，&lt;equation&gt;\vec{b}&lt;/equation&gt;是偏移向量，&lt;equation&gt;W&lt;/equation&gt;是权重矩阵，&lt;equation&gt;a()&lt;/equation&gt;是激活函数。每一层仅仅是把输入&lt;equation&gt;\vec x&lt;/equation&gt;经过如此简单的操作得到&lt;equation&gt;\vec y&lt;/equation&gt;。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;数学理解&lt;/strong&gt;：通过如下5种对输入空间（输入向量的集合）的操作，完成 &lt;strong&gt;输入空间 ——&amp;gt; 输出空间&lt;/strong&gt; 的变换 (矩阵的行空间到列空间)。 注：用“空间”二字的原因是被分类的并不是单个事物，而是&lt;strong&gt;一类&lt;/strong&gt;事物。空间是指这类事物所有个体的集合。&lt;ul&gt;&lt;li&gt;&lt;strong&gt;1.&lt;/strong&gt; 升维/降维&lt;/li&gt;&lt;li&gt;&lt;strong&gt;2.&lt;/strong&gt; 放大/缩小&lt;/li&gt;&lt;li&gt;&lt;strong&gt;3.&lt;/strong&gt; 旋转&lt;/li&gt;&lt;li&gt;&lt;strong&gt;4.&lt;/strong&gt; 平移&lt;/li&gt;&lt;li&gt;&lt;strong&gt;5.&lt;/strong&gt; “弯曲” 这5种操作中，1,2,3的操作由&lt;equation&gt;W\cdot\vec{x}&lt;/equation&gt;完成，4的操作是由&lt;equation&gt;+\vec{b}&lt;/equation&gt;完成，5的操作则是由&lt;equation&gt;a()&lt;/equation&gt;来实现。 (此处有动态图&lt;a href="http://colah.github.io/posts/2014-03-NN-Manifolds-Topology/img/1layer.gif" data-editable="true" data-title="5种空间操作" class=""&gt;5种空间操作&lt;/a&gt;，帮助理解)&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-1ebee9a3fb36a6d1502d517b24bfb5c3.jpg" data-rawwidth="239" data-rawheight="233"&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;&lt;blockquote&gt;&lt;p&gt;每层神经网络的数学理解：&lt;strong&gt;用线性变换跟随着非线性变化，将输入空间投向另一个空间&lt;/strong&gt;。&lt;/p&gt;&lt;/blockquote&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;物理理解&lt;/strong&gt;：对 &lt;equation&gt;W\cdot\vec{x}&lt;/equation&gt; 的理解就是&lt;strong&gt;通过组合形成新物质&lt;/strong&gt;。&lt;equation&gt;
a()&lt;/equation&gt;又符合了我们所处的世界都是非线性的特点。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;情景：&lt;/strong&gt;&lt;equation&gt;\vec{x}&lt;/equation&gt;是二维向量，维度是碳原子和氧原子的数量&lt;equation&gt; [C;O]&lt;/equation&gt;，数值且定为&lt;equation&gt;[1;1]&lt;/equation&gt;，若确定&lt;equation&gt;\vec{y}&lt;/equation&gt;是三维向量，就会形成如下网络的形状 (神经网络的每个节点表示一个维度)。通过改变权重的值，可以获得若干个不同物质。右侧的节点数决定了想要获得多少种不同的新物质。（矩阵的行数） &lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-69d03cf2b3677ad7dc3b0d9af58841b4.jpg" data-rawwidth="144" data-rawheight="164"&gt;&lt;strong&gt;1.&lt;/strong&gt;如果权重W的数值如（1），那么网络的输出y⃗ 就会是三个新物质，[二氧化碳，臭氧，一氧化碳]。 &lt;equation&gt;\left[
 \begin{matrix}
   CO_{2}\\
   O_{3}\\
   CO
  \end{matrix}
  \right]=
 \left[
 \begin{matrix}
   1 &amp;amp; 2 \\
   0 &amp;amp; 3\\
   1 &amp;amp; 1
  \end{matrix}
  \right] \cdot \left[
 \begin{matrix}
   C \\
   O \\
  \end{matrix}
  \right]&lt;/equation&gt; （1）&lt;/li&gt;&lt;li&gt;&lt;strong&gt;2.&lt;/strong&gt;也可以减少右侧的一个节点，并改变权重W至（2），那么输出&lt;equation&gt;\vec{y}&lt;/equation&gt; 就会是两个新物质，&lt;equation&gt;[ O_{0.3};CO_{1.5}]&lt;/equation&gt;。  &lt;equation&gt;\left[
 \begin{matrix}
    O_{0.3}\\
   CO_{1.5}\\
  \end{matrix}
  \right]=
 \left[
 \begin{matrix}
   0&amp;amp; 0.3 \\
   1 &amp;amp; 1.5\\
  \end{matrix}
  \right] \cdot \left[
 \begin{matrix}
   C \\
   O \\
  \end{matrix}
  \right]&lt;/equation&gt;（2）&lt;strong&gt;3.&lt;/strong&gt;如果希望通过层网络能够从[C, O]空间转变到&lt;equation&gt;[CO_{2};O_{3};CO]&lt;/equation&gt;空间的话，那么网络的学习过程就是将W的数值变成尽可能接近(1)的过程 。如果再加一层，就是通过组合&lt;equation&gt;[CO_{2};O_{3};CO]&lt;/equation&gt;这三种基础物质，形成若干更高层的物质。 &lt;strong&gt;4.&lt;/strong&gt;重要的是这种组合思想，组合成的东西在神经网络中并不需要有物理意义。 &lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;&lt;blockquote&gt;&lt;p&gt;每层神经网络的物理理解：&lt;strong&gt;通过现有的不同物质的组合形成新物质&lt;/strong&gt;。&lt;/p&gt;&lt;/blockquote&gt;&lt;h1&gt;二、理解视角：&lt;/h1&gt;&lt;p&gt;现在我们知道了每一层的行为，但这种行为又是如何完成识别任务的呢？&lt;/p&gt;&lt;h2&gt;数学视角：“线性可分”&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;一维情景&lt;/strong&gt;：以分类为例，当要分类正数、负数、零，三类的时候，一维空间的直线可以找到两个超平面（比当前空间低一维的子空间。当前空间是直线的话，超平面就是点）分割这三类。但面对像分类奇数和偶数无法找到可以区分它们的点的时候，我们借助 x % 2（取余）的转变，把x变换到另一个空间下来比较，从而分割。 &lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-92ff4b847ac5fa41d91d1e76a910c483.jpg" data-rawwidth="370" data-rawheight="63"&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;二维情景&lt;/strong&gt;：平面的四个象限也是线性可分。但下图的红蓝两条线就无法找到一超平面去分割。 &lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-b1bd0f75b46ed27daf27910f2a6b6e3f.jpg" data-rawwidth="197" data-rawheight="204"&gt;神经网络的解决方法依旧是转换到另外一个空间下，用的是所说的&lt;strong&gt;5种空间变换操作&lt;/strong&gt;。比如下图就是经过放大、平移、旋转、扭曲原二维空间后，在三维空间下就可以成功找到一个超平面分割红蓝两线 (同SVM的思路一样)。 &lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-8d7d1ef957ebbf8ba9bb9cf8ff2d87ff.jpg" data-rawwidth="197" data-rawheight="198"&gt;上面是一层神经网络可以做到的，如果把&lt;equation&gt;\vec{y}&lt;/equation&gt; 当做新的输入再次用这5种操作进行第二遍空间变换的话，网络也就变为了二层。最终输出是&lt;equation&gt;\vec{y}= a_{2}(W_{2}\cdot(a_{1}(W_{1}\cdot\vec{x} + {b}_{1})) + {b}_{2})&lt;/equation&gt;。 设想网络拥有很多层时，对原始输入空间的“扭曲力”会大幅增加，如下图，最终我们可以轻松找到一个超平面分割空间。 &lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-b7d47097d8f10e6baeb329e88e59b563.jpg" data-rawwidth="239" data-rawheight="233"&gt;当然也有如下图失败的时候，关键在于“如何扭曲空间”。所谓监督学习就是给予神经网络网络大量的训练例子，让网络从训练例子中学会如何变换空间。每一层的权重W就&lt;strong&gt;控制着如何变换空间&lt;/strong&gt;，我们最终需要的也就是训练好的神经网络的所有层的权重矩阵。。这里有非常棒的&lt;a href="http://cs.stanford.edu/people/karpathy/convnetjs//demo/classify2d.html" data-editable="true" data-title="可视化空间变换demo"&gt;可视化空间变换demo&lt;/a&gt;，&lt;strong&gt;一定要&lt;/strong&gt;打开尝试并感受这种扭曲过程。更多内容请看&lt;a href="http://colah.github.io/posts/2014-03-NN-Manifolds-Topology/" data-editable="true" data-title="Neural Networks, Manifolds, and Topology"&gt;Neural Networks, Manifolds, and Topology&lt;/a&gt;。 &lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-664c152ffc58a28a7f900f9a723cbb83.jpg" data-rawwidth="239" data-rawheight="233"&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;上面的内容有三张动态图，对于理解这种空间变化非常有帮助。可以在gitbook&lt;a href="https://yjango.gitbooks.io/-deep/content/wei_he_you_yong.html" class="" data-editable="true" data-title="深层学习为何要“deep”"&gt;深层学习为何要“deep”&lt;/a&gt;上感受那三张图。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;线性可分视角：神经网络的学习就是&lt;strong&gt;学习如何利用矩阵的线性变换加激活函数的非线性变换，将原始输入空间投向线性可分/稀疏的空间去分类/回归。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;增加节点数：增加维度，即增加线性转换能力。&lt;/strong&gt;&lt;strong&gt;增加层数：增加激活函数的次数，即增加非线性转换次数。&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;h2&gt;物理视角：“物质组成”&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;类比&lt;/strong&gt;：回想上文由碳氧原子通过不同组合形成若干分子的例子。从分子层面继续迭代这种组合思想，可以形成DNA，细胞，组织，器官，最终可以形成一个完整的人。继续迭代还会有家庭，公司，国家等。这种现象在身边随处可见。并且原子的内部结构与太阳系又惊人的相似。不同层级之间都是以类似的几种规则再不断形成新物质。你也可能听过&lt;strong&gt;分形学&lt;/strong&gt;这三个字。可通过观看&lt;a href="http://www.tudou.com/programs/view/o41zy0SeSS0" data-editable="true" data-title="从1米到150亿光年" class=""&gt;从1米到150亿光年&lt;/a&gt;来感受自然界这种层级现象的普遍性。 &lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-3ec7216f7ab84dac089836b166c0ae28.jpg" data-rawwidth="488" data-rawheight="340"&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;人脸识别情景&lt;/strong&gt;：我们可以模拟这种思想并应用在画面识别上。由像素组成菱角再组成五官最后到不同的人脸。每一层代表不同的不同的物质层面 (如分子层)。而每层的W&lt;strong&gt;存储着如何组合上一层的物质从而形成新物质&lt;/strong&gt;。 如果我们完全掌握一架飞机是如何从分子开始一层一层形成的，拿到一堆分子后，我们就可以判断他们是否可以以此形成方式，形成一架飞机。 附：&lt;a href="http://playground.tensorflow.org/" data-editable="true" data-title="Tensorflow playground"&gt;Tensorflow playground&lt;/a&gt;展示了数据是如何“流动”的。 &lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-82f05552fd2ddde28a0ef20814d7acbb.png" data-rawwidth="624" data-rawheight="218"&gt;&lt;/li&gt;&lt;/ul&gt;&lt;blockquote&gt;&lt;p&gt;物质组成视角：神经网络的学习过程就是&lt;strong&gt;学习物质组成方式的过程。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;增加节点数：增加同一层物质的种类，比如118个元素的原子层就有118个节点。&lt;/strong&gt;&lt;strong&gt;增加层数：增加更多层级，比如分子层，原子层，器官层，并通过判断更抽象的概念来识别物体。&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;h1&gt;三、神经网络的训练&lt;/h1&gt;&lt;p&gt;知道了神经网络的学习过程就是&lt;strong&gt;学习&lt;/strong&gt;控制着空间变换方式（物质组成方式）的&lt;strong&gt;权重矩阵&lt;/strong&gt;后，接下来的问题就是&lt;strong&gt;如何学习&lt;/strong&gt;每一层的权重矩阵W。&lt;/p&gt;&lt;h2&gt;如何训练：&lt;/h2&gt;&lt;p&gt;既然我们希望网络的输出尽可能的接近真正想要预测的值。那么就可以通过&lt;strong&gt;比较&lt;/strong&gt;当前网络的&lt;strong&gt;预测值&lt;/strong&gt;和我们真正想要的&lt;strong&gt;目标值&lt;/strong&gt;，再根据两者的差异情况来更新每一层的权重矩阵（比如，如果网络的预测值高了，就调整权重让它预测低一些，不断调整，直到能够预测出目标值）。因此就需要先&lt;strong&gt;定义“如何比较&lt;/strong&gt;预测值和目标值的&lt;strong&gt;差异&lt;/strong&gt;”，这便是&lt;strong&gt;损失函数或目标函数（loss function or objective function）&lt;/strong&gt;，用于衡量预测值和目标值的差异的方程。loss function的输出值（loss）越高表示差异性越大。那神经网络的训练就变成了尽可能的缩小loss的过程。 所用的方法是&lt;strong&gt;梯度下降（Gradient descent）&lt;/strong&gt;：通过使loss值向当前点对应梯度的反方向不断移动，来降低loss。一次移动多少是由&lt;strong&gt;学习速率（learning rate）&lt;/strong&gt;来控制的。&lt;/p&gt;&lt;h2&gt;梯度下降的问题：&lt;/h2&gt;&lt;p&gt;然而使用梯度下降训练神经网络拥有两个主要难题。&lt;/p&gt;&lt;h3&gt;1、局部极小值&lt;/h3&gt;&lt;p&gt;梯度下降寻找的是loss function的局部极小值，而我们想要全局最小值。如下图所示，我们希望loss值可以降低到右侧深蓝色的最低点，但loss有可能“卡”在左侧的局部极小值中。 &lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-00fe10bf8877137bc5957cf0cd7f9219.png" data-rawwidth="420" data-rawheight="250"&gt;试图解决“卡在局部极小值”问题的方法分两大类：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;调节步伐：&lt;/strong&gt;调节学习速率，使每一次的更新“步伐”不同。常用方法有：&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;随机梯度下降（Stochastic Gradient Descent (SGD)：每次只更新一个样本所计算的梯度&lt;/p&gt;&lt;/li&gt;&lt;li&gt;小批量梯度下降（Mini-batch gradient descent）：每次更新若干样本所计算的梯度的平均值&lt;/li&gt;&lt;li&gt;动量（Momentum）：不仅仅考虑当前样本所计算的梯度；Nesterov动量（Nesterov Momentum）：Momentum的改进&lt;/li&gt;&lt;li&gt;&lt;p&gt;Adagrad、RMSProp、Adadelta、Adam：这些方法都是训练过程中依照规则降低学习速率，部分也综合动量&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;优化起点&lt;/strong&gt;：合理初始化权重（weights initialization）、预训练网络（pre-train），使网络获得一个较好的“起始点”，如最右侧的起始点就比最左侧的起始点要好。常用方法有：高斯分布初始权重（Gaussian distribution）、均匀分布初始权重（Uniform distribution）、Glorot 初始权重、He初始权、稀疏矩阵初始权重（sparse matrix）&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;2、梯度的计算&lt;/h3&gt;&lt;p&gt;机器学习所处理的数据都是高维数据，该&lt;strong&gt;如何快速计算梯度&lt;/strong&gt;、而不是以年来计算。 其次如何更新&lt;strong&gt;隐藏层&lt;/strong&gt;的权重？ 解决方法是：计算图：&lt;strong&gt;反向传播算法&lt;/strong&gt;这里的解释留给非常棒的&lt;a href="http://colah.github.io/posts/2015-08-Backprop/" data-editable="true" data-title="Computational Graphs: Backpropagation" class=""&gt;Computational Graphs: Backpropagation&lt;/a&gt;需要知道的是，&lt;strong&gt;反向传播算法是求梯度的一种方法&lt;/strong&gt;。如同快速傅里叶变换（FFT）的贡献。 而计算图的概念又使梯度的计算更加合理方便。&lt;/p&gt;&lt;h3&gt;基本流程图：&lt;/h3&gt;&lt;p&gt;下面就结合图简单浏览一下训练和识别过程，并描述各个部分的作用。要&lt;b&gt;结合图解阅读以下内容。但手机显示的图过小，最好用电脑打开&lt;/b&gt;。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-af6c22793412bfc37e1428369a0e36e0.jpg" data-rawwidth="743" data-rawheight="345"&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;收集训练集（train data）：&lt;/strong&gt;也就是同时有input以及对应label的数据。每个数据叫做训练样本（sample）。label也叫target，也是机器学习中最贵的部分。上图表示的是我的数据库。假设input本别是x的维度是39，label的维度是48。&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;设计网络结构（architecture）：&lt;/strong&gt;确定层数、每一隐藏层的节点数和激活函数，以及输出层的激活函数和损失函数。上图用的是两层隐藏层（最后一层是输出层）。隐藏层所用激活函数a( )是ReLu，输出层的激活函数是线性linear（也可看成是没有激活函数）。隐藏层都是1000节点。损失函数L( )是用于比较距离MSE：mean((output - target)^2)。MSE越小表示预测效果越好。训练过程就是不断减小MSE的过程。到此所有数据的维度都已确定：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;训练数据：&lt;equation&gt;input \in R^{39} ;label \in R^{48}&lt;/equation&gt;&lt;/li&gt;&lt;li&gt;权重矩阵：&lt;equation&gt;W_{h1}\in R^{1000x39};W_{h2}\in R^{1000x1000} ;W_{o}\in R^{48x1000}&lt;/equation&gt;&lt;/li&gt;&lt;li&gt;偏移向量：&lt;equation&gt;b_{h1}\in R^{1000};b_{h2}\in R^{1000} ;b_{o}\in R^{48}&lt;/equation&gt;&lt;/li&gt;&lt;li&gt;网络输出：&lt;equation&gt;output \in R^{48}&lt;/equation&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;数据预处理（preprocessing）：&lt;/strong&gt;将所有样本的input和label处理成能够使用神经网络的数据，label的值域符合激活函数的值域。并简单优化数据以便让训练易于收敛。比如中心化（mean subtraction）、归一化（normlization）、主成分分析（PCA）、白化（whitening）。假设上图的input和output全都经过了中心化和归一化。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;权重初始化（weights initialization）&lt;/strong&gt;：&lt;equation&gt;W_{h1},W_{h2},W_{0}&lt;/equation&gt;在训练前不能为空，要初始化才能够计算loss从而来降低。&lt;equation&gt;W_{h1},W_{h2},W_{0}&lt;/equation&gt;初始化决定了loss在loss function中从哪个点开始作为起点训练网络。上图用均匀分布初始权重（Uniform distribution）。&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;训练网络（training）&lt;/strong&gt;：训练过程就是用训练数据的input经过网络计算出output，再和label计算出loss，再计算出gradients来更新weights的过程。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;正向传递：，算当前网络的预测值&lt;equation&gt;output =linear (W_{o} \cdot Relu(W_{h2}\cdot Relu(W_{h1}\cdot input+b_{h1})+b_{h2}) +b_{o})&lt;/equation&gt;&lt;/li&gt;&lt;li&gt;计算loss：&lt;equation&gt;loss = mean((output - target)^2)&lt;/equation&gt;&lt;/li&gt;&lt;li&gt;计算梯度：从loss开始反向传播计算每个参数（parameters）对应的梯度（gradients）。这里用Stochastic Gradient Descent (SGD) 来计算梯度，即每次更新所计算的梯度都是从一个样本计算出来的。传统的方法Gradient Descent是正向传递所有样本来计算梯度。SGD的方法来计算梯度的话，loss function的形状如下图所示会有变化，这样在更新中就有可能“跳出”局部最小值。 &lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-0c0e7f5ffa98c2c1eb87763dd5d1d9a3.png" data-rawwidth="469" data-rawheight="227"&gt;&lt;/li&gt;&lt;li&gt;更新权重：这里用最简单的方法来更新，即所有参数都 &lt;equation&gt;W = W - learningrate * gradient&lt;/equation&gt;&lt;/li&gt;&lt;li&gt;预测新值：训练过所有样本后，打乱样本顺序再次训练若干次。训练完毕后，当再来新的数据input，就可以利用训练的网络来预测了。这时的output就是效果很好的预测值了。下图是一张&lt;b&gt;实际值&lt;/b&gt;和&lt;b&gt;预测值&lt;/b&gt;的三组对比图。输出数据是48维，这里只取1个维度来画图。蓝色的是实际值，绿色的是实际值。最上方的是训练数据的对比图，而下方的两行是神经网络模型&lt;b&gt;从未见过&lt;/b&gt;的数据预测对比图。（不过这里用的是RNN，主要是为了让大家感受一下效果）&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-a675e692f7f7755d91bcdba5e988e910.jpg" data-rawwidth="2000" data-rawheight="1600"&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;注：此部分内容&lt;strong&gt;不是&lt;/strong&gt;这篇文章的&lt;strong&gt;重点&lt;/strong&gt;，但为了理解&lt;strong&gt;深层&lt;/strong&gt;神经网络，需要明白最基本的训练过程。 若能理解训练过程是通过梯度下降尽可能缩小loss的过程即可。 若有理解障碍，可以用python实践一下&lt;a href="http://www.wildml.com/2015/09/implementing-a-neural-network-from-scratch/" data-editable="true" data-title="从零开始训练一个神经网络" class=""&gt;从零开始训练一个神经网络&lt;/a&gt;，体会整个训练过程。若有时间则可以再体会一下计算图自动求梯度的方便&lt;a href="https://www.tensorflow.org/versions/r0.11/tutorials/mnist/beginners/index.html#mnist-for-ml-beginners" data-editable="true" data-title="利用TensorFlow" class=""&gt;利用TensorFlow&lt;/a&gt;。&lt;/p&gt;&lt;h2&gt;结合&lt;a href="https://link.zhihu.com/?target=http%3A//playground.tensorflow.org/" class="" data-editable="true" data-title="Tensorflow playground"&gt;Tensorflow playground&lt;/a&gt;理解&lt;b&gt;5种空间操作&lt;/b&gt;和&lt;b&gt;物质组成视角&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;打开网页后，总体来说，蓝色代表正值，黄色代表负值。拿&lt;b&gt;分类&lt;/b&gt;任务来分析。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;数据：在二维平面内，若干点被标记成了两种颜色。黄色，蓝色，表示想要区分的两类。你可以把平面内的任意点标记成任意颜色。网页给你提供了4种规律。神经网络会根据你给的数据训练，再分类相同规律的点。&lt;/li&gt;&lt;/ul&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-6d17d1fb77d3ae1838f5253193456317.png" data-rawwidth="173" data-rawheight="169"&gt;&lt;ul&gt;&lt;li&gt;输入：在二维平面内，你想给网络多少关于“点”的信息。从颜色就可以看出来，&lt;equation&gt;x_{1}&lt;/equation&gt;左边是负，右边是正，&lt;equation&gt;x_{1}&lt;/equation&gt;表示此点的横坐标值。同理，&lt;equation&gt;x_{2}&lt;/equation&gt;表示此点的纵坐标值。&lt;equation&gt;x_{1}^{2}&lt;/equation&gt;是关于横坐标值的“抛物线”信息。你也可以给更多关于这个点的信息。给的越多，越容易被分开。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-111e37e8479aa57bedbfb2dbcd8e5b63.png" data-rawwidth="92" data-rawheight="228"&gt;&lt;/li&gt;&lt;li&gt;连接线：表示权重，蓝色表示用神经元的原始输出，黄色表示用负输出。深浅表示权重的绝对值大小。鼠标放在线上可以看到具体值。也可以更改。在（1）中，当把&lt;equation&gt;x_{2}&lt;/equation&gt;输出的一个权重改为-1时，&lt;equation&gt;x_{2}&lt;/equation&gt;的形状直接倒置了。不过还需要考虑激活函数。（1）中用的是linear。在（2）中，当换成sigmoid时，你会发现没有黄色区域了。因为sigmoid的值域是(0,1)&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-2820b0562c8fcd7a49d57c4deb1e4f3c.png" data-rawwidth="315" data-rawheight="136"&gt;（1）&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-83fd9f01e2ea38c7f6b8aeaa308cf040.png" data-rawwidth="294" data-rawheight="123"&gt;（2）&lt;/li&gt;&lt;li&gt;输出：黄色背景颜色都被归为黄点类，蓝色背景颜色都被归为蓝点类。深浅表示可能性的强弱。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-dff3f6e72881ebd222414eabb9504671.png" data-rawwidth="1116" data-rawheight="363"&gt;上图中所有在黄色背景颜色的点都会被分类为“黄点“，同理，蓝色区域被分成蓝点。在上面的分类分布图中你可以看到每一层通过上一层信息的组合所形成的。权重（那些连接线）控制了“如何组合”。神经网络的学习也就是从数据中学习那些权重。Tensorflow playground所表现出来的现象就是“在我文章里所写的“物质组成思想”，这也是为什么我把&lt;a href="https://link.zhihu.com/?target=http%3A//playground.tensorflow.org/" class="" data-editable="true" data-title="Tensorflow playground"&gt;Tensorflow playground&lt;/a&gt;放在了那一部分。&lt;/li&gt;&lt;/ul&gt;不过你要是把Tensorflow的个名字拆开来看的话，是tensor（张量）的flow（流动）。Tensorflow playground的作者想要阐述的侧重点是“&lt;b&gt;张量如何流动&lt;/b&gt;”的。&lt;b&gt;5种空间变换的理解&lt;/b&gt;：Tensorflow playground下没有体现5种空间变换的理解。需要打开这个网站尝试：&lt;a href="http://cs.stanford.edu/people/karpathy/convnetjs//demo/classify2d.html" data-editable="true" data-title="ConvNetJS demo: Classify toy 2D data" class=""&gt;ConvNetJS demo: Classify toy 2D data&lt;/a&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-55811ac3d91f56f19543714b1b5abe49.png" data-rawwidth="841" data-rawheight="425"&gt;左侧是原始输入空间下的分类图，右侧是转换后的高维空间下的扭曲图。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-a81a10592b96a1d2b067e1d4ae3951e7.png" data-rawwidth="848" data-rawheight="417"&gt;最终的扭曲效果是所有绿点都被扭曲到了一侧，而所有红点都被扭曲到了另一侧。这样就可以线性分割（用超平面（这里是一个平面）在中间分开两类）&lt;h1&gt;四、“深层”的思考：真的只有这些原因吗？&lt;/h1&gt;&lt;p&gt;文章的最后稍微提一下深层神经网络。深层神经网络就是拥有更多层数的神经网络。&lt;/p&gt;&lt;p&gt;按照上文在理解视角中所述的观点，可以想出下面两条理由关于为什么更深的网络会更加容易识别，增加容纳变异体（variation）（红苹果、绿苹果）的能力、鲁棒性（robust）。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;数学视角&lt;/strong&gt;：变异体（variation）很多的分类的任务需要高度非线性的分割曲线。不断的利用那5种空间变换操作将原始输入空间像“捏橡皮泥一样”在高维空间下捏成更为线性可分/稀疏的形状。 &lt;strong&gt;物理视角&lt;/strong&gt;：通过对“&lt;strong&gt;抽象概念&lt;/strong&gt;”的判断来识别物体，而非细节。比如对“飞机”的判断，即便人类自己也无法用语言或者若干条规则来解释自己如何判断一个飞机。因为人脑中真正判断的不是是否“有机翼”、“能飞行”等细节现象，而是一个抽象概念。层数越深，这种概念就越抽象，所能&lt;strong&gt;涵盖的变异体&lt;/strong&gt;就越多，就可以容纳战斗机，客机等很多种不同种类的飞机。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;然而深层神经网络的惊人表现真的只有这些原因吗？&lt;/strong&gt;&lt;strong&gt;为什么神经网络过深后，预测的表现又变差？ 而且这时变差的原因是由于“过深”吗？&lt;/strong&gt;&lt;strong&gt;接下来要写的《深层学习为何要“Deep”（下）》是关于“深层”二字的进一步思考，找出所有网络结构的共性，并解释设计神经网络的本质是什么。&lt;/strong&gt;&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/22888385&amp;pixel&amp;useReferer"/&gt;</description><author>YJango</author><pubDate>Wed, 12 Oct 2016 02:33:48 GMT</pubDate></item><item><title>逻辑与神经之间的桥</title><link>https://zhuanlan.zhihu.com/p/22457562</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/fc658b76b2f0ed0c863953573cd5f462_r.jpg"&gt;&lt;/p&gt;这是我迄今为止最有成果的论文，欢迎讨论！&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-2860c7305704f8a9f47e3dec8c3f7cb0.jpg" data-rawwidth="963" data-rawheight="1509"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-1ab416079097690e31fa00c95c1b97ea.jpg" data-rawwidth="955" data-rawheight="1483"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-3eeb1d2483a14d86f38a4e750d623d08.jpg" data-rawwidth="955" data-rawheight="1495"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-68eb7652697f1969b0b4cf13f001d5e8.jpg" data-rawwidth="953" data-rawheight="1491"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-977f44c4f962b2f4b5bf630153ea2a3d.jpg" data-rawwidth="956" data-rawheight="1485"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-c2a24fb3f29db902b505acc436480404.jpg" data-rawwidth="954" data-rawheight="1489"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-1ba6dc1c99e604b25733b52d620ef12a.jpg" data-rawwidth="956" data-rawheight="1491"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-109ad8458276933f1195ccde55a638c4.jpg" data-rawwidth="951" data-rawheight="1488"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-f6451264e7924fd973676972a7f6e49b.jpg" data-rawwidth="962" data-rawheight="349"&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/22457562&amp;pixel&amp;useReferer"/&gt;</description><author>甄景贤</author><pubDate>Thu, 15 Sep 2016 12:55:35 GMT</pubDate></item><item><title>最前沿 之 谷歌的协作机械臂</title><link>https://zhuanlan.zhihu.com/p/22758556</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-6f589df38509d14f839737645322a011_r.jpg"&gt;&lt;/p&gt;&lt;p&gt;本文由我和&lt;a href="https://www.zhihu.com/people/li-yi-ying-73" data-editable="true" data-title="李艺颖" class=""&gt;李艺颖&lt;/a&gt;共同撰写。&lt;/p&gt;&lt;h2&gt;1 前言&lt;/h2&gt;&lt;p&gt;前几天也就是2016年10月3号，Google Research Blog上发表了最新的Blog，介绍他们在机器人上的工作：&lt;a href="https://research.googleblog.com/2016/10/how-robots-can-acquire-new-skills-from.html" data-editable="true" data-title="googleblog.com 的页面" class=""&gt;https://research.googleblog.com/2016/10/how-robots-can-acquire-new-skills-from.html&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-6bbe8af2dbc2e7e7036c00aac03a5917.png" data-rawwidth="1898" data-rawheight="1228"&gt;现在Google们都喜欢发文章+写博客的套路，似乎不太需要我们做面向大众的解读了。因此，本文决定不介绍他们基本的工作了，我们来研究一下他们的具体工作，来点干货。&lt;/p&gt;&lt;p&gt;这次Google联合了Google Brain和DeepMind一起搞，一次发了四篇文章（够狠，链接转自官方博客）：&lt;/p&gt;&lt;p&gt;【1】&lt;a href="https://arxiv.org/abs/1610.00633" data-editable="true" data-title="Deep Reinforcement Learning for Robotic Manipulation" class=""&gt;Deep Reinforcement Learning for Robotic Manipulation&lt;/a&gt;. &lt;i&gt;Shixiang Gu, Ethan Holly, Timothy Lillicrap, Sergey Levine.&lt;/i&gt; [&lt;a href="https://sites.google.com/site/deeproboticmanipulation/" data-editable="true" data-title="video" class=""&gt;video&lt;/a&gt;]【2】&lt;a href="https://arxiv.org/abs/1610.00696" data-editable="true" data-title="Deep Visual Foresight for Planning Robot Motion" class=""&gt;Deep Visual Foresight for Planning Robot Motion&lt;/a&gt;. &lt;i&gt;Chelsea Finn, Sergey Levine.&lt;/i&gt; [&lt;a href="https://www.youtube.com/watch?v=CKRWJEVSXMI" data-editable="true" data-title="video"&gt;video&lt;/a&gt;] [&lt;a href="https://sites.google.com/site/brainrobotdata/home" data-editable="true" data-title="data"&gt;data&lt;/a&gt;]【3】&lt;a href="https://arxiv.org/abs/1610.00673" data-editable="true" data-title="Collective Robot Reinforcement Learning with Distributed Asynchronous Guided Policy Search" class=""&gt;Collective Robot Reinforcement Learning with Distributed Asynchronous Guided Policy Search&lt;/a&gt;. &lt;i&gt;Ali Yahya, Adrian Li, Mrinal Kalakrishnan, Yevgen Chebotar, Sergey Levine.&lt;/i&gt;  [&lt;a href="https://youtu.be/ZBFwe1gF0FU" data-editable="true" data-title="video"&gt;video&lt;/a&gt;]【4】&lt;a href="https://arxiv.org/abs/1610.00529" data-editable="true" data-title="Path Integral Guided Policy Search" class=""&gt;Path Integral Guided Policy Search&lt;/a&gt;. &lt;i&gt;Yevgen Chebotar, Mrinal Kalakrishnan, Ali Yahya, Adrian Li, Stefan Schaal, Sergey Levine. &lt;/i&gt;[&lt;a href="https://www.youtube.com/watch?v=ncp1kY5JV90" data-editable="true" data-title="video"&gt;video&lt;/a&gt;]&lt;/p&gt;&lt;p&gt;所以，今天我们来以快速的分析一下这四篇文章。&lt;/p&gt;&lt;h2&gt;2 Deep Reinforcement Learning for Robotic Manipulation &lt;/h2&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-4a8ecedc83c7b64c450d760978316c0b.png" data-rawwidth="1234" data-rawheight="660"&gt;&lt;p&gt;这篇文章的题目弄得很大，用深度增强学习来解决机器人的操纵问题。具体一点就是让机器人从零开始学会开门。&lt;/p&gt;&lt;p&gt;文章中表示实现让机械臂自己学会开门就是他们的贡献，他们是第一个做出这个demonstration的。当然，这么说也是ok的。&lt;/p&gt;&lt;p&gt;对于理论上的创新，他们表示他们拓展了NAF算法，变成异步NAF。我表示异步的思想早就有了，而且他们的异步NAF的实现方式实在是太太太简单了。就是&lt;/p&gt;&lt;blockquote&gt;&lt;b&gt;用多个线程收集不同机器人的数据，然后用一个线程去训练，并且训练线程在服务器上，训练后不断把最新的神经网络参数传递给每一个机器人用于新的采样&lt;/b&gt;。&lt;/blockquote&gt;&lt;p&gt;可能让机器人自己开门这个任务在我看来是本来就能实现的，所以其实并没有太多震撼的地方。而且，在这篇文章中，并&lt;b&gt;不使用视觉输入！&lt;/b&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;b&gt;不使用视觉输入，声称能让机器人学会开门有多大意义呢?&lt;/b&gt;&lt;/blockquote&gt;&lt;p&gt;从文章中可以看到，对于开门这个任务，门把手的位置的给定的：&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;In addition, we append a target position to the
state, which depends on the task: for the door
opening, this is the handle position when the door is closed and the quaternion measurement of the sensor attached to
the door frame.&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;大家看到了吧，不但门把手的位置，连门的姿态也就是四元数quaternion也是有传感器来测量的。那么，这样号称做了一个很屌的Demonstration真的有意思吗？比较&lt;b&gt;质疑这篇文章的贡献&lt;/b&gt;。这里使用的神经网络也只是两个200的全连接神经网络。某种程度上讲，其实这个任务的状态输入是低维而不是高维的。我觉得如果这篇文章能够完全使用图像输入来实现端到端自学习的话，那么就很厉害！虽然该团队之前有&lt;a href="https://arxiv.org/abs/1603.02199" data-editable="true" data-title="一篇文章"&gt;一篇文章&lt;/a&gt;就是用视觉输入，但是用了十几台机器人，并且训练几个月来收集数据。现在这个任务只要几小时，不过没有视觉，意义不够大。&lt;/p&gt;&lt;p&gt;关于NAF算法，可以参考本专栏的：&lt;a href="https://zhuanlan.zhihu.com/p/21609472?refer=intelligentunit" data-editable="true" data-title="DQN从入门到放弃7 连续控制DQN算法-NAF - 智能单元 - 知乎专栏" class=""&gt;DQN从入门到放弃7  连续控制DQN算法-NAF - 智能单元 - 知乎专栏&lt;/a&gt;&lt;/p&gt;&lt;p&gt;关于DDPG算法，可以参考本人的CSDN blog：&lt;a href="http://blog.csdn.net/songrotek/article/details/50917337" data-editable="true" data-title="Paper Reading 3:Continuous control with Deep Reinforcement Learning" class=""&gt;Paper Reading 3:Continuous control with Deep Reinforcement Learning&lt;/a&gt;&lt;/p&gt;&lt;p&gt;关于DDPG的源码复现，可以参考本人的github：&lt;a href="https://github.com/songrotek/DDPG" data-editable="true" data-title="GitHub - songrotek/DDPG: Reimplementation of DDPG(Continuous Control with Deep Reinforcement Learning) based on OpenAI Gym + Tensorflow" class=""&gt;GitHub - songrotek/DDPG: Reimplementation of DDPG(Continuous Control with Deep Reinforcement Learning) based on OpenAI Gym + Tensorflow&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;3 Deep Visual Foresight for Planning Robot Motion&lt;/h2&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-644e1a2ea1c79ff7492365e10044eb5a.png" data-rawwidth="1052" data-rawheight="744"&gt;这篇文章和深度增强学习没有直接关系，完全另外一个思路。为什么研究这个，我们先来说说&lt;b&gt;机器人学习之难难在哪？&lt;/b&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;b&gt;机器人学习之难难在环境不完全可见，难在没有Model！&lt;/b&gt;&lt;/blockquote&gt;&lt;p&gt;在控制领域，有一种任务相对比较好做，比如火箭发射！（当然也是很难的大工程），但是火箭发射上个世纪就解决了，人类甚至可以发射探测器到很远的地方，火星探测器也上了好几次了。Elon Musk前不久才提出他的火星登陆计划：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-df90f1f33f6539d183c3619d9a4f733e.png" data-rawwidth="2428" data-rawheight="1078"&gt;&lt;blockquote&gt;&lt;b&gt;为什么人类早早就能把探测器发送到那么远的地方，却连“简单”的让机器人开个门都那么难？&lt;/b&gt;&lt;/blockquote&gt;&lt;p&gt;因为对于航天工程，我们可以精确的计算探测器，火箭的运动模型（运动方程），我们可以精确的计算出火箭在怎样的推力下会达到的轨迹，因此我们可以精确的控制。我们有足够的人力，足够的资源来进行数学计算，我们也就能够实现很好的控制。但是&lt;b&gt;对于机器人开门这种事，我们没法算&lt;/b&gt;。&lt;/p&gt;&lt;p&gt;为什么？&lt;/p&gt;&lt;ol&gt;&lt;li&gt;每个门都可能不一样，门把手也不一样&lt;/li&gt;&lt;li&gt;机器人的位置不固定，门的位置也不固定。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;我们可以针对某个特定的门精确计算来实现控制，但是我们不可能遍历所有的门，更何况对于一个新的门怎么办？大家看到了，这里没有所谓的Model模型，我们无法建立模型，特别是如果我们只使用摄像头，类似人的第一视角，那么我们得到的信息更是有限。每时每刻的控制都将不一样。这就是机器人学习难的原因。&lt;/p&gt;&lt;p&gt;所以，深度增强学习的很多方式都是所谓的Model-Free的方法，也就是不需要模型，通过trial-and-error来学会整个过程。&lt;/p&gt;&lt;p&gt;可是，人类并不仅仅是通过trial-and-error来学习的。我们人类其实在大脑里能够构建一些基本的模型的，也就是比如门把手的位置，很多东西的位置，在我们大脑中是有概念的，我们也能够预测他们的位移。特别是足球的守门员，就需要掌握一项技能，那就是预判球的位置。&lt;/p&gt;&lt;p&gt;所以，问题就这么来了：我们能不能来预测一下物体的位置，从而帮助机器人抓取物品？&lt;/p&gt;&lt;p&gt;这篇文章也就做了这个事，弄了一个物体预测模型来预测物体的位置。本质上是未来研究model-based的方法。&lt;/p&gt;&lt;p&gt;个人看法：model-based和model-free方法结合起来用能使机器人学习发挥出更大威力。&lt;/p&gt;&lt;p&gt;关于预测模型，其实这篇文章也不新鲜了，之前就有文章研究预测atari游戏的画面的，也有文章预测汽车的运行轨迹的。只是这篇文章比较具体，面向机器人控制的具体问题，把预测模型和机器人控制MPC直接结合在一起，从而形成了一个确实的demo。&lt;/p&gt;&lt;p&gt;所以，重复一下，&lt;b&gt;这篇文章的关键不是弄成一个预测模型，而是真正把模型给用在机器人控制上。在文章中，作者也是说的很明确，没有夸大的成分：&lt;/b&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;The primary contribution of our paper is to demonstrate
that deep predictive models of video can be used by real
physical robotic systems to manipulate previously unseen
objects.&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;我们稍微来说一下这个深度预测模型：&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-a61c2f5dd46954bdd64d884fa7c1753a.png" data-rawwidth="2378" data-rawheight="842"&gt;结构上搞的比较复杂。先说输入输出。输入有三个，一个是当前帧，当前的状态state和动作action，然后输出下一帧图像（预测）。&lt;/p&gt;&lt;p&gt;中间的结构大致可以分成三部分：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;CNN+LSTM部分，用于提取图像特征信息，不过这里的输出很特别，并没有使用反卷积直接生成图像，而是输出一个图像的mask蒙版。这个蒙版可以认为是计算出里面的物体的移动流也就是pixel flow。&lt;/li&gt;&lt;li&gt;状态和动作输入部分，将状态和动作从卷积层的中间插入。&lt;/li&gt;&lt;li&gt;图像生成部分。首先是利用中间的卷积层抽取多个卷积核然后与原始图像做卷积，得到变化后的图像transformed images，然后和mask一起生成pixel flow map F，然后F与原始图像一起生成下一帧的图像。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;所以这个神经网络本质上是要学习出物体移动的像素流pixel flow，类似光流，从而计算出下一帧的图像。作者虽然限定了神经网络的结构，但是在学习训练时只使用视频，动作，状态数据做监督学习，也就是端到端的学习，中间的mask蒙版和像素流并没有单独的监督学习。&lt;b&gt;然而文章中并没有对mask和flow的具体表现形式做分析，是否就是产生出对物体运动的捕捉我比较怀疑。&lt;/b&gt;只能说通过训练，神经网络确实学习了捕捉物体的运动并能够根据输入加以预测。&lt;/p&gt;&lt;p&gt;接下来是这篇文章的区别其他文章的工作，直接使用这个预测模型与经典的MPC控制结合，来实现机械臂的控制。基本是思路就是利用预测模型预测不同动作未来的移动情况，从而选择最优的移动方式。这种方式取得成功说明利用预测模型进行机器人控制的可行性。&lt;b&gt;下一步进一步拓展深度预测模型将成为可能，&lt;/b&gt;这也是这篇文章最大的意义。&lt;/p&gt;&lt;h2&gt;4 Path Integral Guided Policy Search&lt;/h2&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-81ffccb38f7e3c8ca417bdb6949f3adc.png" data-rawwidth="1164" data-rawheight="488"&gt;&lt;p&gt;这篇文章以及下一篇文章是对Sergey Levine提出的GPS算法的拓展和改进。关于GPS（Guided Policy Search）这个算法，我一直觉得不是一个好的算法，至少未来这个算法我认为没有必要（为什么之后说），但是这个算法展示性比深度增强学习算法强，能够直接应用到真实的机器人上。先说一下深度增强学习应用到机器人上最大的困难，就是&lt;b&gt;采样！&lt;/b&gt;我们可以在仿真环境中千百万次的训练机器人，但是我们没办法在真实环境中这么做。时间不允许，机器人也不允许。以此同时，完全的高维输入，高维输出做机器人控制目前仍是困难很大的。&lt;/p&gt;&lt;p&gt;&lt;b&gt;那么GPS是什么呢？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;它的想法非常简单，就是把问题先分解成不同的初始条件，比如开门，有的是这个角度，有的是那个角度。然后，针对不同的条件单独训练一个局部策略Local Policy。那么这个训练方式他这里&lt;b&gt;不管了！！！也就是你想用什么传统的控制算法都可以！&lt;/b&gt;然后有了这些可以用的策略之后，就利用策略采集样本，只是把输入变了，比如变成视觉输入，然后利用样本训练一个网络来代替这些局部策略，也就是模仿学习Imitation Learning，通过这种方式实现视觉伺服。我表示&lt;b&gt;GPS很没意思。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;为什么没意思？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;就说机器人开门这件事吧。我们要实现视觉控制，也就是让机器人看着打开门，和人一样。我们希望即使门放在不同的角度位置机器人也可以开。按照深度增强学习做法，那必须是End-to-End啊，输入视觉信息，输出控制，然后训练。从Deep Reinforcement Learning for Robot Manipulation这篇我们大概可以猜测出，这样做失败了，所以那篇文章并没有使用视觉输入。但我现在就要视觉输入这么办？&lt;/p&gt;&lt;p&gt;&lt;b&gt;Imitation Learning！模仿学习&lt;/b&gt;&lt;/p&gt;&lt;p&gt;神经网络啥都能学习，因此只要我们能够收集到好的输入输出样本，我们就可以训练。模仿学习就是这么干。我们可以利用人类获取样本。比如人拿着机械臂做几百次开门动作，然后记录这些动作作为样本进行训练。但是只是用人比较麻烦，不用人就用机器人控制的算法，比如LQR，我们就有model怎么啦。我们先利用机械臂的model信息和门的精确信息来优化出一条最优轨迹，然后这不就是样本了吗？为了实现神经网络的通用性，我们面对不同的门的角度位置弄多条对应的最优轨迹，然后收集所有样本进行训练。在拓展一下，就是反过来利用训练的神经网络生成样本，然后反过来让控制算法进行优化。&lt;/p&gt;&lt;p&gt;&lt;b&gt;所以，虽然GPS能够实现视觉伺服控制，但是其中间过程一点也不单纯。使用了太多额外的信息来做训练。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在我看来，训练时也只使用视觉信息，不使用额外信息才是有用的算法。GPS最致命的地方也在这里，这个开门可以精确建模，可以有额外数据，但是很多其他任务可没有那么多额外数据可以弄。&lt;b&gt;GPS本质上不具备自学习能力，而只是传统方法的神经网络化。&lt;/b&gt;监督学习无法使机器人超越传统方法。&lt;/p&gt;&lt;p&gt;那么这篇文章又做了什么事呢？将LQR用一个model free的RL算法替代。PI2这个算法之前不是很了解，看了文章感觉就是一种进化算法。基本思想就是采用多种路径，然后让路径概率向着损失较小的方向靠。和CEM（交叉熵方法）也差不多。就是对于Cost，采样概率还有参数更新方式不一样。&lt;/p&gt;&lt;p&gt;有了PI2算法，GPS就可以做到model free了。但是训练过程还是一样。PI2算法的使用过程中并不使用视觉信息。只是因此采用的方法不一样（比起LQR），能够通过训练来解决开门这种间断连续控制问题（要先让机械臂移动到门把手那里，然后抓住，旋转，打开）。在我看来，直接用深度增强学习算法比如DDPG甚至REINFORCE来训练local policy不就完了，最后再综合所有样本监督学习一个，效果肯定好。&lt;/p&gt;&lt;p&gt;总的来说，GPS看似有用，实则鸡肋，改进它意义不大，还不如研究如何实现少样本学习。&lt;/p&gt;&lt;h2&gt;5 Collective Robot Reinforcement Learning with Distributed Asynchronous Guided Policy Search&lt;/h2&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-324517c941a6e509a94a369ad86dc97e.png" data-rawwidth="1654" data-rawheight="534"&gt;这篇文章其实和Deep Reinforcement Learning for Robot Manipulation很类似，只是针对的算法不一样，说白了就将Guided Policy Search拓展成并行异步的版本，从而可以实现多机器人协同训练。&lt;/p&gt;&lt;p&gt;----------------------&lt;/p&gt;&lt;p&gt;下面的分析来自&lt;a href="https://www.zhihu.com/people/li-yi-ying-73" data-editable="true" data-title="李艺颖" class=""&gt;李艺颖&lt;/a&gt;：&lt;/p&gt;&lt;p&gt;从架构方面，这十分契合云机器人的主旨，机器人可以将它们各自的经验通过网络传递给其它机器人。斯坦福人工智能百年报告之《人工智能与2030年的生活》中也指出以家用机器人为例，多机器人协同能够使机器人“共享更多家庭内收集的数据集，反过来能提供给云端进行机器学习，进一步改进已经部署的机器人。”本文就是鉴于考虑到真实世界中环境具有多样性和复杂性，所以想到让机器人将自身经历传递给彼此，使它们在环境中相互配合来学习技能，同时机器人也基于自身任务的特定样本改进局部的策略。实验采用4个机器人，任务是基于视觉学习开门，4个机器人对应的门的姿态和外观也都有所不同，采用的算法是GPS，在它们反复尝试和共享经历中不断提高任务执行水平。多机器人提高了样本的多样性，提高了学习的泛化能力和可使用能力。&lt;/p&gt;-----------------------&lt;p&gt;算法的做法依然是很简单。一句话就可以概括。就是几个机器人分别有一个local policy来优化，每个机器人面对的场景都不一样。然后训练，将样本上传服务器，在服务器上监督学习一个神经网络，然后用这个神经网络Global Policy来辅助采样优化local policy。&lt;/p&gt;&lt;p&gt;只能说多机器人协助必然能够提升学习训练速度，但是这种idea非常简单，算法的改进也是非常简单。当然，我们也不得不承认，Google的整个实验难度很大，要训练好很难，甚至这个训练用的机械臂都是Google自己造的（话说Google高层不让卖）。&lt;/p&gt;&lt;h2&gt;6 小结&lt;/h2&gt;&lt;p&gt;Google似乎想惊艳一下大家，一次发四篇文章说他们的机器人进展。但是很可惜，从具体文章的内容和贡献来看，并没有太多惊艳的思想和效果。多机器人协作是必然，核心还在于算法的改进。当然，我们也必须承认，Google能够实现让机器人完全使用视觉来开门是一个不错的Demo，只是这个Demo是在当前算法框架下必然可以实现的，不过也只有土豪的Google能这么做。&lt;/p&gt;&lt;p&gt;最后，大家也看到了，&lt;b&gt;让机器人学会开门竟然是21世纪的今天人类最前沿科技都还没很好解决的问题&lt;/b&gt;，可见人类的文明程度是有多低。但，这也就是我们研究机器人实现机器人革命的机会！&lt;/p&gt;&lt;h2&gt;声明：本文为原创文章，未经允许不得转载。另外本文的图片都来自于本文介绍的四篇paper和网络。&lt;/h2&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/22758556&amp;pixel&amp;useReferer"/&gt;</description><author>Flood Sung</author><pubDate>Fri, 07 Oct 2016 16:39:58 GMT</pubDate></item><item><title>最前沿：围棋之后，AI玩FPS游戏也能秀人类一脸了！</title><link>https://zhuanlan.zhihu.com/p/22604627</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-9b132a69e08ced90ec418e66699b2c3a_r.png"&gt;&lt;/p&gt;&lt;b&gt;版权声明：本文&lt;a href="https://zhuanlan.zhihu.com/intelligentunit" class="" data-editable="true" data-title="智能单元"&gt;智能单元&lt;/a&gt;首发，本人原创，禁止未授权转载&lt;/b&gt;。&lt;blockquote&gt;前言：9月23日，基于经典第一人人称射击游戏毁灭战士DOOM的AI挑战赛“&lt;a href="http://vizdoom.cs.put.edu.pl/competition-cig-2016" data-editable="true" data-title="Visual Doom AI Competition @ CIG 2016"&gt;Visual Doom AI Competition @ CIG 2016&lt;/a&gt;”尘埃落定，&lt;b&gt;Facebook团队和Intel团队的AI分别拿下两个赛制最佳&lt;/b&gt;，同时也涌现出若干优秀的学生参赛AI。本文根据最新的公开信息，对&lt;b&gt;赛事本身&lt;/b&gt;和&lt;b&gt;卡耐基梅隆大学参赛团队的AI&lt;/b&gt;做出简要介绍。&lt;/blockquote&gt;&lt;h2&gt;内容列表&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;背景介绍&lt;/li&gt;&lt;ul&gt;&lt;li&gt;放轻松，先看游戏视频&lt;/li&gt;&lt;li&gt;游戏毁灭战士DOOM简介&lt;/li&gt;&lt;li&gt;竞赛平台ViZDOOM简介&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;赛事介绍&lt;/li&gt;&lt;ul&gt;&lt;li&gt;赛制与规则&lt;/li&gt;&lt;li&gt;参赛队伍&lt;/li&gt;&lt;li&gt;赛事结果&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;卡耐基梅陇大学参赛AI介绍&lt;/li&gt;&lt;ul&gt;&lt;li&gt;基本模型与算法&lt;/li&gt;&lt;li&gt;遇到困难与解决问题的创新思路&lt;/li&gt;&lt;li&gt;算法评价&lt;/li&gt;&lt;li&gt;超越人类玩家的实验结果&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;感言&lt;/li&gt;&lt;li&gt;作者反馈&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;背景介绍&lt;/h2&gt;&lt;p&gt;&lt;b&gt;第一人称射击游戏&lt;/b&gt;，&lt;b&gt;杀红眼的死亡竞赛&lt;/b&gt;和&lt;b&gt;人工智能&lt;/b&gt;，每一个概念充满了话题性，当融合了这三个要素的基于游戏毁灭战士DOOM的AI挑战赛“&lt;a href="http://vizdoom.cs.put.edu.pl/competition-cig-2016" data-editable="true" data-title="Visual Doom AI Competition @ CIG 2016"&gt;Visual Doom AI Competition @ CIG 2016&lt;/a&gt;”尘埃落定，就是搞个大新闻的时候了：）&lt;/p&gt;&lt;blockquote&gt;&lt;b&gt;根据评论更新&lt;/b&gt;：这些人工智能算法与玩家们常见的游戏内置bot和外挂有本质区别，内置bot和外挂都是通过获取游戏内部数据来获得不对称优势，而这些算法，他们在测试时和人类一样，&lt;b&gt;只通过游戏屏幕的图像信息来玩游戏&lt;/b&gt;。&lt;/blockquote&gt;&lt;p&gt;&lt;b&gt;然而亮点中更有惊喜&lt;/b&gt;，本次赛事的两个亮点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Facebook和Intel均派出团队参数；&lt;/li&gt;&lt;li&gt;先前公布出“&lt;b&gt;已经超越人类玩家水平AI&lt;/b&gt;”的卡耐基梅隆团队&lt;b&gt;并！未！夺！冠！&lt;/b&gt;细思极恐哈哈&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;惊喜的是&lt;/b&gt;，在“有限制的死亡竞赛”赛制中夺冠的Facebook团队的成员，就是知乎上的两位&lt;a href="https://www.zhihu.com/people/9819f6938be0d3bb133ad0151eefd188" data-hash="9819f6938be0d3bb133ad0151eefd188" class="member_mention" data-editable="true" data-title="@田渊栋" data-hovercard="p$b$9819f6938be0d3bb133ad0151eefd188"&gt;@田渊栋&lt;/a&gt;和&lt;a href="https://www.zhihu.com/people/5c2b06e8ddc61687e42a1a64fb72bbaf" data-hash="5c2b06e8ddc61687e42a1a64fb72bbaf" class="member_mention" data-editable="true" data-title="@吴育昕" data-hovercard="p$b$5c2b06e8ddc61687e42a1a64fb72bbaf"&gt;@吴育昕&lt;/a&gt; 。其中田研究员已经在知乎问题&lt;a href="https://www.zhihu.com/question/50916351?from=profile_question_card" class="" data-editable="true" data-title="如何评价基于游戏毁灭战士（Doom）的AI死亡竞赛大赛结果？ - 人工智能"&gt;如何评价基于游戏毁灭战士（Doom）的AI死亡竞赛大赛结果？ - 人工智能&lt;/a&gt;，给出了参加比赛的一些经过，只是由于文章尚在撰写，暂时不公布技术细节。总之个人看到结果时，非常高兴，祝贺他们！&lt;/p&gt;&lt;h2&gt;看视频提问题&lt;/h2&gt;&lt;p&gt;欢乐起来，这里先卖关子，大家来看看下面三个游戏视频，猜猜看哪个视频是人类玩家在玩，哪个视频是AI玩家在玩？猜对了也没有奖励：）&lt;/p&gt;&lt;ul&gt;&lt;li&gt;视频A&lt;/li&gt;&lt;/ul&gt;&lt;video id="69686" data-swfurl="" poster="" data-sourceurl="http://v.youku.com/v_show/id_XMTczNjU3MTc2NA==.html#paction" data-name='猜一猜是人类玩家还是AI玩家1—在线播放—优酷网，视频高清在线观看" /&amp;gt;&amp;lt;meta name="irTitle" content="猜一猜是人类玩家还是AI玩家1" /&amp;gt;&amp;lt;meta  name="irAlbumName" content="猜一猜是人类玩'&gt;&lt;/video&gt;&lt;ul&gt;&lt;li&gt;视频B&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;video id="69687" data-swfurl="" poster="" data-sourceurl="http://v.youku.com/v_show/id_XMTczNjU4NDA1Ng==.html" data-name='猜一猜2—在线播放—优酷网，视频高清在线观看" /&amp;gt;&amp;lt;meta name="irTitle" content="猜一猜2" /&amp;gt;&amp;lt;meta  name="irAlbumName" content="猜一猜2" /&amp;gt;&amp;lt;meta name="keywords"'&gt;&lt;/video&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;视频C&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;video id="69688" data-swfurl="" poster="" data-sourceurl="http://v.youku.com/v_show/id_XMTczNjU4NjY1Ng==.html" data-name='猜一猜3—在线播放—优酷网，视频高清在线观看" /&amp;gt;&amp;lt;meta name="irTitle" content="猜一猜3" /&amp;gt;&amp;lt;meta  name="irAlbumName" content="猜一猜3" /&amp;gt;&amp;lt;meta name="keywords"'&gt;&lt;/video&gt;&lt;/p&gt;&lt;p&gt;正确答案在后文中，请大家带着疑问继续阅读吧！&lt;/p&gt;&lt;h2&gt;毁灭战士DOOM&lt;/h2&gt;&lt;p&gt;DOOM于1993年由id software发行，现在已经发行到了第四代。初代的画面是这样的：&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-9b132a69e08ced90ec418e66699b2c3a.png" data-rawwidth="1166" data-rawheight="656"&gt;DOOM4的游戏画面是这样的：&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-3131f28e046482d3283f763d188abe85.jpg" data-rawwidth="1805" data-rawheight="1023"&gt;作为硬核的古典派第一人称射击游戏，&lt;b&gt;就是突出一个“莽”一个“爽”&lt;/b&gt;。毁灭战士系列是一个伟大的系列，我个人认为&lt;b&gt;其初代&lt;/b&gt;和&lt;b&gt;重返德军总部&lt;/b&gt;，&lt;b&gt;毁灭公爵&lt;/b&gt;等都可以算是第一人称射击游戏上古时代的开山鼻祖。这一次AI们一起相互伤害的的游戏，是DOOM初代，也就是第一幅图中的游戏画面。&lt;/p&gt;&lt;p&gt;需要向领域外读者们指出的是：AI们在竞赛的时候，获取的信息比人类玩家更少，&lt;b&gt;只有游戏画面数据信息&lt;/b&gt;，&lt;b&gt;AI们的行动都仅仅基于图像输入后算法输出的决策控制&lt;/b&gt;，连声音也没有！这和游戏内置AI不同，游戏内置AI是能够通过游戏引擎获取所有的游戏内部信息的。&lt;/p&gt;&lt;h2&gt;ViZDOOM平台简介&lt;/h2&gt;&lt;p&gt;ViZDOOM的官网&lt;a href="http://vizdoom.cs.put.edu.pl" data-editable="true" data-title="在此"&gt;在此&lt;/a&gt;。ViZDOOM是什么，请允许我引用其官网的简介如下：&lt;/p&gt;&lt;blockquote&gt;ViZDoom is a Doom-based AI research platform for reinforcement learning from raw visual information. It allows developing AI bots that play Doom using only the screen buffer. ViZDoom is primarily intended for research in machine visual learning, and deep reinforcement learning, in particular.ViZDOOM是一个基于DOOM的AI研究平台，主要针对面向原始视觉信息输入的增强学习。它可以&lt;b&gt;让研究者开发出只利用游戏屏幕数据玩DOOM的AI机器人&lt;/b&gt;。ViZDOOM主要面向的是机器视觉学习，&lt;b&gt;更确切地说，就是深度增强学习&lt;/b&gt;。&lt;/blockquote&gt;关于ViZDOOM的详细情况，其作者们于2016年5月在arXiv上发布了论文：《&lt;a href="http://arxiv.org/abs/1605.02097" data-editable="true" data-title="ViZDoom: A Doom-based AI Research Platformfor Visual Reinforcement Learning" class=""&gt;ViZDoom: A Doom-based AI Research Platformfor Visual Reinforcement Learning&lt;/a&gt;》，可以通过阅读论文获取。&lt;p&gt;需要说明的是，&lt;b&gt;基于ViZDOOM，研究者是可以直接访问DOOM的游戏引擎的，可以拿到游戏内部的信息&lt;/b&gt;。甚至可以利用这些内部信息来训练自己的AI，但是，在测试阶段，是不能得到内部信息的，只能让AI根据游戏画面来自主决策和行动。&lt;/p&gt;&lt;p&gt;用大白话来说，就是训练AI你可以开上帝模式，我不管你。但是真刀真枪干的时候，你AI老老实实地只能用自己的眼睛看游戏画面玩游戏，作弊是休想的。&lt;/p&gt;&lt;h2&gt;赛事介绍&lt;/h2&gt;&lt;p&gt;赛事的全程是&lt;b&gt;Visual Doom AI Competition @ CIG 2016&lt;/b&gt;，赛事地址在&lt;a href="http://vizdoom.cs.put.edu.pl/competition-cig-2016" data-editable="true" data-title="这里"&gt;这里&lt;/a&gt;。比赛的核心目标就是要回答一个问题：&lt;/p&gt;&lt;blockquote&gt;&lt;b&gt;到底AI能不能只根据原始视觉信息高效地玩毁灭战士？&lt;/b&gt;&lt;/blockquote&gt;&lt;p&gt;现在答案已经很明显了，这里啰嗦一下&lt;b&gt;对自己的保守观念的鄙视和被打脸的过程&lt;/b&gt;。当时赛事出来，&lt;a href="https://www.zhihu.com/people/23deec836a24f295500a6d740011359c" data-hash="23deec836a24f295500a6d740011359c" class="member_mention" data-editable="true" data-title="@Flood Sung" data-hovercard="p$b$23deec836a24f295500a6d740011359c"&gt;@Flood Sung&lt;/a&gt;（&lt;b&gt;他现在玩《守望先锋》，正在前往多拉多.....&lt;/b&gt;）就给我说了这个事情，我当时就说：&lt;/p&gt;&lt;blockquote&gt;哎哟，你看deepmind也才把Atari那些游戏玩得差不多，那种偏策略的反馈比较延迟的游戏效果还不太好，这就大跃进地要搞FPS了？肯定效果不好！&lt;/blockquote&gt;&lt;p&gt;前几天，卡耐基梅隆大学参赛团队The Terminators（&lt;b&gt;终结者&lt;/b&gt;）的AI机器人Arnold（&lt;b&gt;阿诺德&lt;/b&gt;）（哎哟，兄弟们，你们&lt;b&gt;这么明目张胆地取名字&lt;/b&gt;，州长&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-09ef482c8355d212fef4e6661a719bc8.jpg" data-rawwidth="1920" data-rawheight="1080"&gt;会来找你们哟）的演示视频和论文（后文会解读）出来了，我一看，&lt;b&gt;直接承认自己被打脸&lt;/b&gt;，机器人玩得非常流畅，论文里面的结果显示&lt;b&gt;AI已经把20个卡耐基梅隆大学的学生玩家（平均水平）按在地上摩擦&lt;/b&gt;。当时我觉得，这个阿诺德是要发啊，&lt;b&gt;肯定能夺冠&lt;/b&gt;！&lt;/p&gt;&lt;p&gt;结果比赛结果出来，&lt;b&gt;阿诺德&lt;/b&gt;在第一个赛制里面败给了Facebook的F1机器人，在难度更大的第二个赛制里面败给了Intel的IntelAct。&lt;b&gt;我的脸又火辣辣的了&lt;/b&gt;......不过好在阿诺德两个赛制都参加了，而且都拿了第二，所以也算是很强了，所以我感觉稍微好些......&lt;/p&gt;&lt;p&gt;既然说到了赛制，那么接下来就介绍下：&lt;/p&gt;&lt;h2&gt;赛制与规则&lt;/h2&gt;&lt;p&gt;&lt;b&gt;赛制&lt;/b&gt;分两种：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;已知地图上的受限制死亡竞赛：&lt;b&gt;武器只有火箭炮，机器人可以捡血包和弹药；&lt;/b&gt;&lt;/li&gt;&lt;li&gt;未知地图上的的不受限制死亡竞赛：&lt;b&gt;机器人初始只有手枪，可以捡各种武器弹药和血包。&lt;/b&gt;提供了两张地图用于训练，3张未知地图用于测试。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;规则分为允许与禁止：&lt;/b&gt;相对比较细节，领域外同学随意看看即可&lt;b&gt;。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;允许：&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;加载自己的设置文件；&lt;/li&gt;&lt;li&gt;使用任意分辨率；&lt;/li&gt;&lt;li&gt;使用任意可获取的按钮；&lt;/li&gt;&lt;li&gt;使用任意可获取的游戏变量；&lt;/li&gt;&lt;li&gt;使用任意可获取的屏幕数据格式（深度信息不行）；&lt;/li&gt;&lt;li&gt;改变渲染设置；&lt;/li&gt;&lt;li&gt;设置机器人的名字与颜色；&lt;/li&gt;&lt;li&gt;使用doom2.wad或freedoom2.wad文件随你。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;禁止&lt;/b&gt;：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;在机器人根目录外修改文件系统；&lt;/li&gt;&lt;li&gt;网络通信；&lt;/li&gt;&lt;li&gt;使用send_game_command命令；&lt;/li&gt;&lt;li&gt;使用new_episode。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;奖金！！&lt;/h2&gt;&lt;p&gt;对了，大家可能会问有没有奖金呢？有奖金的哟！&lt;/p&gt;&lt;ul&gt;&lt;li&gt;在赛制1中的前三名能分别获取1000，300，200欧元；&lt;/li&gt;&lt;li&gt;在赛制2中的前三名能分别获得2000，1000，500欧元。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这个金额和前阵子的DOTA2奖金比起来确实是九牛一毛，但是对于科技的进步来说，意义则大不一样。&lt;/p&gt;&lt;h2&gt;参赛队伍&lt;/h2&gt;&lt;p&gt;我在&lt;a href="https://www.zhihu.com/question/50916351/answer/123272182?from=profile_answer_card" data-editable="true" data-title="如何评价基于游戏毁灭战士（Doom）的AI死亡竞赛大赛结果？ - 杜客的回答" class=""&gt;如何评价基于游戏毁灭战士（Doom）的AI死亡竞赛大赛结果？ - 杜客的回答&lt;/a&gt;中已经做了一些介绍，总得说来，除了&lt;b&gt;Facebook和Intel这两个明星团队&lt;/b&gt;，其他3各值得关注的团队是分别是&lt;b&gt;卡耐基梅隆大学的Arnold，埃塞克斯大学的Clyde和东芬兰大学的tuho。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;目前，公开了论文的只有卡耐基梅隆大学团队，Facebook的田研究员表示正在撰写文章，其他团队的情况尚未看到相关信息，欢迎知友补充。&lt;/p&gt;&lt;h2&gt;比赛结果&lt;/h2&gt;&lt;p&gt;这里让我偷个懒，直接从官网截图如下：&lt;/p&gt;&lt;p&gt;&lt;b&gt;赛制1：&lt;/b&gt;F1就是Facebook团队，第二名是阿诺德。&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-24b9939cd484f3d374a5c6efcddcffe4.png" data-rawwidth="2110" data-rawheight="862"&gt;&lt;b&gt;赛制2&lt;/b&gt;：第一名是Intel团队，第二名是阿诺德。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-1a5664433a5d69143b24a6a3385bd602.png" data-rawwidth="2116" data-rawheight="696"&gt;&lt;h2&gt;卡内基梅隆大学参赛AI介绍&lt;/h2&gt;&lt;p&gt;从上面的比赛结果中可以看出，卡耐基梅隆大学The Terminators团队的机器人Arnold综合实力不错，在两个赛制中都得到了亚军的好成绩，同时，他们也是目前唯一发布了论文《&lt;a href="http://arxiv.org/abs/1609.05521" data-editable="true" data-title="Playing FPS Games with Deep Reinforcement Learning"&gt;Playing FPS Games with Deep Reinforcement Learning&lt;/a&gt;》的团队，所以下面主要根据他们的论文做一个简要解读。&lt;/p&gt;&lt;h2&gt;基本模型与算法&lt;/h2&gt;&lt;p&gt;论文使用的模型的出发点还是DQN和DRQN模型，鉴于领域内的知友对于这两个模型都比较熟悉，而领域外的知友对数学公式也并不感兴趣，所以这里我还是采取了偷懒的办法：&lt;/p&gt;&lt;p&gt;&lt;b&gt;关于DQN模型&lt;/b&gt;，请阅读我们专栏&lt;a href="https://www.zhihu.com/people/23deec836a24f295500a6d740011359c" data-hash="23deec836a24f295500a6d740011359c" class="member_mention" data-editable="true" data-title="@Flood Sung" data-hovercard="p$b$23deec836a24f295500a6d740011359c"&gt;@Flood Sung&lt;/a&gt;的教程&lt;a href="https://zhuanlan.zhihu.com/p/21421729?refer=intelligentunit" class="" data-editable="true" data-title="DQN从入门到放弃5 深度解读DQN算法 "&gt;DQN从入门到放弃5 深度解读DQN算法&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;&lt;b&gt;关于DRQN模型&lt;/b&gt;，简单解释如下：DQN的模型是假设在每一步，机器人都能得到环境的全部观察st。但是在只能观察到部分环境的情况下，机器人只能得到部分观察&lt;equation&gt;o_t&lt;/equation&gt;，不足以来推断整个系统的状态。像DOOM这样的游戏就是这样。&lt;/p&gt;&lt;p&gt;为了解决这种情况，2015年，Hausknecht和Stone发布论文《&lt;a href="http://arxiv.org/abs/1507.06527" data-title="Deep recurrent q-learning for partially observable mdps" class="" data-editable="true"&gt;Deep recurrent q-learning for partially observable mdps&lt;/a&gt;》，引入了DRQN，它不去估计&lt;equation&gt;Q(s_t,a_t)&lt;/equation&gt;, 而是估计&lt;equation&gt;Q(o_t,h_{t-1},a_t)&lt;/equation&gt;。其中，&lt;equation&gt;h_t&lt;/equation&gt;是一个额外的输入，该输入是由前一状态的网络返回的，表达了机器人的隐藏状态。像LSTM那样的循环神经网络可以在普通的DQN模型之上来实现，在这种情况下，&lt;equation&gt;h_t=LSTM(h_{t-1},o_t)&lt;/equation&gt;，而我们则估计&lt;equation&gt;Q(h_t,o_t)&lt;/equation&gt;。&lt;/p&gt;&lt;h2&gt;困难与解决思路&lt;/h2&gt;&lt;p&gt;作者们在论文中坦率地指出，一开始他们是&lt;b&gt;用的标准的DRQN模型，结果效果很不好&lt;/b&gt;。算法只能在很简单的场景中有良好表现，到了死亡竞赛场景中，表现就很差了。&lt;/p&gt;&lt;p&gt;这是怎么回事呢？作者们通过与Sandeep Subramanian和Kanthashree Mysore Sathyendra讨论，得出以下结论：&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;We reason that the agents were not able to accurately detect
enemies.&lt;/p&gt;我们推出，算法表现不好的愿意是&lt;b&gt;机器人不能很准确地探测到敌人&lt;/b&gt;。&lt;/blockquote&gt;&lt;p&gt;有了原因，作者们就给出了新的解决思路，主要是以下几点：&lt;/p&gt;&lt;li&gt;&lt;b&gt;概念上&lt;/b&gt;：将游戏过程看做两个阶段，导航阶段和行动阶段。&lt;b&gt;导航阶段就是机器人探索地图，发现物品并捡起物品。行动阶段就是攻击敌人&lt;/b&gt;。&lt;/li&gt;&lt;li&gt;&lt;b&gt;框架上&lt;/b&gt;：对应不同阶段，使用两个独立的模型来进行训练。导航阶段使用的是原始的DQN，行动阶段是论文创新修改的融入了游戏特征信息的DRQN模型来训练。&lt;/li&gt;&lt;li&gt;&lt;b&gt;增加游戏特征信息的DRQN模型&lt;/b&gt;：这是论文的&lt;b&gt;核心创新点&lt;/b&gt;之一，说到底，就是将游戏高级信息（比如视野中是否出现敌人）融入到DRQN进行训练，值得仔细看看，图示如下：&lt;/li&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-bc9e23834bdd07662f5f2fe30a11b12a.png" data-rawwidth="1030" data-rawheight="366"&gt;在我的回答中，有知友说没有看到游戏状态信息的输入，想知道是怎么在training的时候加入的，我的回答是：有的。注意512维的layer4和后面k维的两个全连接层，CNN输入输入给他们，其中k就是想要探测的k个游戏特征信息，在训练的时候，网络的代价函数是把DRQN的代价函数和交叉熵损失合起来。虽然有很多游戏信息可以获取，但是论文&lt;b&gt;只用了当前画面中是否出现敌人的指示器&lt;/b&gt;。加入这个特征极大地提升了性能，对比图示如下：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-6baec594c6ec08c59a1aa546f2caa107.png" data-rawwidth="714" data-rawheight="486"&gt;&lt;p&gt;经过这么一改进，作者们非常开心，还做了一些其他的结构来融入游戏信息，但是效果都不太好。&lt;b&gt;说明分享卷积层对模型性能有决定性影响&lt;/b&gt;。&lt;b&gt;联合训练DRQN模型和游戏特征探测使得卷积核能够获取游戏的相关联信息&lt;/b&gt;。在他们的实验中，只花了几个小时就达到了最佳敌人探测水平，准确率0.9。在此之后，LSTM就能得到包含敌人及其位置的特征，使得训练进一步加速。&lt;/p&gt;&lt;p&gt;&lt;b&gt;将游戏分成两个阶段的思路也很重要&lt;/b&gt;：死亡竞赛可以分成两个阶段，探索梯度收集物品发现敌人，攻击敌人。称之为导航阶段和行动阶段。训练了两个网络，每个网络针对的是不同的阶段。当前的DQN模型不能将两个针对不同任务优化的网络合并在一起。但是，当前游戏的阶段可以通过预测敌人是否能被看见（行动阶段）或不被看见（探索阶段）来决定，这可以从游戏特征信息中推断。将任务分成两个阶段，每个阶段用不同网络训练的优势：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;框架模块化，不同阶段用不同网络训练测试；&lt;/li&gt;&lt;li&gt;两个网络可以并行训练，使得训练更快；&lt;/li&gt;&lt;li&gt;导航阶段只需要3个动作（前进，左右移），极大降低了Q函数需要学习的状态-动作对，使得训练更快；&lt;/li&gt;&lt;/ol&gt;&lt;b&gt;行动网络使用的是DRQN加游戏信息特征，探索网络使用的是DQN&lt;/b&gt;。在评价计算的时候，行动网络每一步都调用，如果视野中没有敌人，或者弹药用尽的时候，导航网络调用来决定行动。在&lt;b&gt;回馈（reward）设计&lt;/b&gt;上，作者们采取了&lt;b&gt;回馈共享（&lt;/b&gt;&lt;b&gt;reward shaping）&lt;/b&gt;的思路，即：修改回报函数，包含一些小的中间回报来加速学习过程。在击杀敌人给正向回报，自杀给负回报的基础上，向&lt;b&gt;行动网络&lt;/b&gt;引入了以下中间回报：&lt;ul&gt;&lt;li&gt;捡到东西加分；&lt;/li&gt;&lt;li&gt;掉血减分；&lt;/li&gt;&lt;li&gt;射击减少弹药减分；&lt;/li&gt;&lt;/ul&gt;&lt;b&gt;导航网络&lt;/b&gt;：&lt;ul&gt;&lt;li&gt;捡到东西加分；&lt;/li&gt;&lt;li&gt;走到岩浆减分；&lt;/li&gt;&lt;li&gt;走的距离越长加分越多，有助于走完整个地图。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;算法评价&lt;/h2&gt;&lt;p&gt;本质上讲卡内基梅隆大学的AI&lt;b&gt;为了简化AI的训练难度，通过人类的知识将游戏的环节设计成导航阶段和行动阶段，然后设计了三个网络&lt;/b&gt;（一个简单点的DQN网络用于导航阶段，一个特征识别网络用于选择不同的阶段，一个DRQN网络用于行动阶段），然后作者巧妙的将特征识别（有没有敌人）的网络和DRQN网络结合在一起训练。特征识别网络是一个典型的监督学习网络，而DRQN则是增强学习的范畴，两者在这里竟然同时合在一起训练，确实是有意思的事情。&lt;/p&gt;&lt;p&gt;最后这篇文章只使用DQN和DQN的变种DRQN，&lt;b&gt;并没有使用目前最强的深度增强学习算法A3C&lt;/b&gt;。A3C在Atari上的性能是Nature版本DQN的4倍，效果惊人。所以，这可能是Arnold只拿第二的原因吧。如果他们基于A3C来训练，相信效果会更好，但是整个模型基本都得改一下。我们显然也想提出这样的疑问：“能不能只使用一个网络来玩Doom达到这样的高水平？”在Arnold的基础上监督学习一个端到端网络算是一个办法，但是这样并不能更好的提升游戏AI的水平。最后的最后，Arnold在训练过程中利用了游戏内部的特征来训练，而据田渊栋的回答，他们的方法不怎么使用游戏内部的特征信息，很期待他们的思路。&lt;/p&gt;&lt;h2&gt;实验结果&lt;/h2&gt;&lt;p&gt;在论文结果中，显示AI水平已经超过了人类玩家，这些玩家是卡耐基梅隆大学的学生：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-8c3b0951fcd58a17af807c347f05eac7.png" data-rawwidth="884" data-rawheight="320"&gt;上面这个表格，显示的是论文对比AI算法和人类玩家游戏水平的结果，具体如下：&lt;ul&gt;&lt;li&gt;&lt;b&gt;K/D比例&lt;/b&gt;：击杀/死亡比例；&lt;/li&gt;&lt;li&gt;&lt;b&gt;单个玩家场景&lt;/b&gt;：机器人和玩家分别和10个游戏原内置AI对战3分钟；&lt;/li&gt;&lt;li&gt;&lt;b&gt;多玩家场景&lt;/b&gt;：人类玩家和机器人对抗5分钟。&lt;/li&gt;&lt;li&gt;&lt;b&gt;自杀数&lt;/b&gt;：火箭炮等武器过近的射击点会造成自我伤害。&lt;b&gt;注意&lt;/b&gt;：人类玩家自杀失误高于AI。&lt;/li&gt;&lt;/ul&gt;&lt;b&gt;人类得分是取所有人类玩家的平均值&lt;/b&gt;。在&lt;b&gt;两个场景中都有20名人类玩家参加&lt;/b&gt;。可以看到AI相对于学生玩家的水平。当然，你可以说职业玩家水平可以更高，但是我们只需要回忆一下围棋，回忆一下AlphaGO......AlphaGo也是基于深度增强学习哟。&lt;h2&gt;感言&lt;/h2&gt;&lt;p&gt;在我的回答的评论中，知友&lt;a href="https://www.zhihu.com/people/1b01e645e0b40fc30ae54d156e7558aa" data-hash="1b01e645e0b40fc30ae54d156e7558aa" class="member_mention" data-editable="true" data-title="@碧海居士" data-hovercard="p$b$1b01e645e0b40fc30ae54d156e7558aa"&gt;@碧海居士&lt;/a&gt;应该不是领域内人士，但是他的评论值得一看：&lt;/p&gt;&lt;blockquote&gt;如果说围棋是纯拼算法和计算量的话，游戏的实效性就决定了这东西离进入实用近了一步。毕竟战场是即时制而不是回合制的……想象一下这AI用在自动攻击的无人载具上是个多么恐怖的事情……&lt;/blockquote&gt;&lt;p&gt;我们虽然时刻都希望人工智能能够给人类带来共同利益（for the common good），然而现实总是现实，每一次人类科技的进步，总是被首先运用于军事，这点我们必须承认。我们将AI欢乐地在射击游戏上跑，环境仿真越真实，算法效果越好，那么其潜在军事价值就越大，这&lt;b&gt;实在不是一个让人感到欢乐的话题&lt;/b&gt;。&lt;/p&gt;&lt;p&gt;意识到这一点，我自己有了&lt;b&gt;两个想法&lt;/b&gt;：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;对于个人研究者来说，如果基于理想主义，可以不在类似射击的平台上进行算法应用研究，而在一些比较民用方向的平台上研究，比如&lt;a href="https://www.zhihu.com/people/23deec836a24f295500a6d740011359c" data-hash="23deec836a24f295500a6d740011359c" class="member_mention" data-editable="true" data-title="@Flood Sung" data-hovercard="p$b$23deec836a24f295500a6d740011359c"&gt;@Flood Sung&lt;/a&gt;在&lt;a href="https://zhuanlan.zhihu.com/p/22523121?refer=intelligentunit" data-editable="true" data-title="最前沿：深度增强学习再发力，家用机器人已近在眼前 - 智能单元 - 知乎专栏" class=""&gt;最前沿：深度增强学习再发力，家用机器人已近在眼前 - 智能单元 - 知乎专栏&lt;/a&gt;中介绍的斯坦福的室内机器人仿真。&lt;/li&gt;&lt;li&gt;为了国家安全，还是要有一批研究者要继续在军事方面的研究。毕竟这个世界不是康德的世界，&lt;a href="http://baike.baidu.com/link?url=6_8uJ7auA3XHl6BUClDwz5rJcFehxO1Pe0LmNB8FfIpJJJiABj9o6N23p7XReX5M"&gt;霍布斯的世界&lt;/a&gt;离我们并不遥远，只有相当的实力，才能确保和平。这个是我基于人生经历的个人观点，&lt;b&gt;不想争论&lt;/b&gt;，所以有不同意见的知友，我尊重，但也保留自己的观点，&lt;b&gt;不想花时间讨论&lt;/b&gt;。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;作者反馈&lt;/h2&gt;&lt;ol&gt;&lt;li&gt;等田研究员的文章出来后，&lt;a href="https://www.zhihu.com/people/23deec836a24f295500a6d740011359c" data-hash="23deec836a24f295500a6d740011359c" class="member_mention" data-hovercard="p$b$23deec836a24f295500a6d740011359c"&gt;@Flood Sung&lt;/a&gt;应该会做解析；&lt;/li&gt;&lt;li&gt;欢迎大家留言讨论，除了最后我特别指出的那个观点；&lt;/li&gt;&lt;li&gt;3个视频都是机器人在玩，你猜对了吗？哈哈！&lt;/li&gt;&lt;/ol&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/22604627&amp;pixel&amp;useReferer"/&gt;</description><author>杜客</author><pubDate>Sat, 24 Sep 2016 18:59:40 GMT</pubDate></item><item><title>看图说话的AI小朋友——图像标注趣谈（下）</title><link>https://zhuanlan.zhihu.com/p/22520434</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-7c2ef2d9f4d9244473a201b0b19318ec_r.jpeg"&gt;&lt;/p&gt;版权声明：本文&lt;a href="https://zhuanlan.zhihu.com/intelligentunit" class="" data-editable="true" data-title="智能单元"&gt;智能单元&lt;/a&gt;首发，本人原创，禁止未授权转载。&lt;blockquote&gt;前言：近来&lt;b&gt;图像标注（Image Caption）&lt;/b&gt;问题的研究热度渐高。本文希望在把问题和研究介绍清楚的同时行文通俗有趣，让非专业读者也能一窥其妙。&lt;/blockquote&gt;&lt;h2&gt;内容列表：&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;图像标注问题简介&lt;/li&gt;&lt;ul&gt;&lt;li&gt;图像标注是什么&lt;/li&gt;&lt;li&gt;当前水平&lt;/li&gt;&lt;li&gt;价值和意义&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;图像标注数据集&lt;/li&gt;&lt;ul&gt;&lt;li&gt;MSCOCO&lt;/li&gt;&lt;li&gt;Flickr8K和Flickr30K&lt;/li&gt;&lt;li&gt;PASCAL 1K&lt;/li&gt;&lt;li&gt;创建一个守望先锋数据集？&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;图像标注评价标准&lt;/li&gt;&lt;ul&gt;&lt;li&gt;人类判断与自动评价标准&lt;/li&gt;&lt;li&gt;Perplexity&lt;/li&gt;&lt;li&gt;BLEU&lt;/li&gt;&lt;li&gt;ROUGE&lt;/li&gt;&lt;li&gt;METEOR&lt;/li&gt;&lt;li&gt;CIDEr &lt;/li&gt;&lt;/ul&gt;&lt;li&gt;图像标注模型发展 &lt;i&gt;&lt;b&gt;注：下篇起始处&lt;/b&gt;&lt;/i&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;百度的m-RNN&lt;/li&gt;&lt;li&gt;谷歌的NIC&lt;/li&gt;&lt;li&gt;目前最高水平模型&lt;/li&gt;&lt;li&gt;模型的比较思考&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;代码实践&lt;/li&gt;&lt;ul&gt;&lt;li&gt;CS231n的LSTM_Captioning&lt;/li&gt;&lt;li&gt;基于Numpy的NerualTalk&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;图像标注问题展望&lt;/li&gt;&lt;ul&gt;&lt;li&gt;模型的更新&lt;/li&gt;&lt;li&gt;自动评价标注的更新&lt;/li&gt;&lt;li&gt;数据集的更新&lt;/li&gt;&lt;li&gt;小结&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;h2&gt;上篇回顾&lt;/h2&gt;&lt;p&gt;在上篇中，我们介绍了研究图像标注问题常用的&lt;b&gt;数据集&lt;/b&gt;和评价算法常用的&lt;b&gt;自动评价标准&lt;/b&gt;，并脑洞了一个&lt;b&gt;开源创建基于守望先锋游戏画面的中文图像标注数据集&lt;/b&gt;的想法。文章发布后，有不少感兴趣的知友表示愿意参与，并提出了意见和建议。对此我将单独分出一篇文章介绍相关情况，请感兴趣的知友注意。在下篇中，我们将对比较有代表性的图像标注方法进行介绍，展示一些代码实践。&lt;/p&gt;&lt;h2&gt;图像标注模型的发展&lt;/h2&gt;&lt;p&gt;说是发展，其实时间也并不长，将CNN和RNN结合的模型用于解决图像标注问题的研究最早也就从2014开始提出，在2015年开始对模型各部分组成上进行更多尝试与优化，到2016年CVPR上成为一个热门的专题。&lt;/p&gt;&lt;p&gt;在这个发展中，将RNN和CNN结合的核心思路没变，变化的是使用了更好更复杂的CNN模型，效果更好的LSTM，图像特征输入到RNN中的方式，以及更复合的特征输入等。正由于其发展时间跨度较短，通过阅读该领域的一些重要文章，可以相对轻松地理出大牛们攻城拔寨的思路脉络，这对我们自己从事研究的思路也会有所启发。&lt;/p&gt;&lt;h2&gt;m-RNN模型&lt;/h2&gt;&lt;p&gt;2014年10月，百度研究院的Junhua Mao和Wei Xu等人在arXiv上发布论文《&lt;a href="http://arxiv.org/abs/1410.1090" data-editable="true" data-title="Explain Images with Multimodal Recurrent Neural Networks"&gt;Explain Images with Multimodal Recurrent Neural Networks&lt;/a&gt;》，提出了&lt;b&gt;multimodal Recurrent Neural Network（即m-RNN）&lt;/b&gt;模型，创造性地将深度卷积神经网络CNN和深度循环神经网络RNN结合起来，用于解决图像标注和图像和语句检索等问题。通过14年的相关新闻可知，Wei Xu应该是百度研究院的徐伟，Junhua Mao是徐伟团队中的毛俊华，此外还有杨亿，王江等。&lt;/p&gt;&lt;p&gt;这篇论文是首先抓住这个想法并实现的文章，作者们在文中也当仁不让地说：&lt;/p&gt;&lt;blockquote&gt;To the best of our knowledge, this is the first work that incorporates the Recurrent
Neural Network in a deep multimodal architecture.&lt;/blockquote&gt;&lt;p&gt;在后续的几篇优秀论文中，m-RNN都被作为一个基准方法用于比较和超越。因此，&lt;b&gt;首先介绍百度研究院的m-RNN模型，在于其创造性工作。知友切莫遇百度即黑&lt;/b&gt;。&lt;/p&gt;&lt;p&gt;论文中，在对原始RNN结构进行简要说明后，提出了m-RNN模型如下：&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-32d251cf7486c257c030e3e5eaad93c3.png" data-rawwidth="1566" data-rawheight="352"&gt;其结构特点可以归纳如下：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;模型的&lt;b&gt;输入&lt;/b&gt;是图像和与图像对应的标注语句（比如在上图中，这个语句就可能是a man at a giant tree in the jungle）。其&lt;b&gt;输出&lt;/b&gt;是对于下一个单词的可能性的分布；&lt;/li&gt;&lt;li&gt;模型在&lt;b&gt;每个时间帧&lt;/b&gt;都有6层：分别是输入层、2个单词嵌入层，循环层，多模型层和最后的Softmax层；&lt;/li&gt;&lt;li&gt;输入单词本来是以独热码（one-hot）方式编码，但是经过两个单词嵌入层后，最终变换为稠密单词表达。在该文中，单词表达层是随机初始化并在训练过程中自己学习的。第二个嵌入层输出的激活数据，作为输入直接进入到多模型层（蓝色线条）；&lt;/li&gt;&lt;li&gt;循环层的维度是256维，在其中进行的是对&lt;b&gt;t&lt;/b&gt;时刻的单词表达向量&lt;equation&gt;w(t)&lt;/equation&gt;和&lt;b&gt;t-1&lt;/b&gt;时刻的循环层激活数据&lt;equation&gt;r(t-1)&lt;/equation&gt;的变换和计算，具体计算公式是：&lt;equation&gt;r(t)=f_2(U_r\cdot r(t-1)+w(t))&lt;/equation&gt;。其中，函数&lt;equation&gt;f_2(.)&lt;/equation&gt;是&lt;b&gt;ReLU&lt;/b&gt;，这个非线性激活函数在&lt;a href="https://zhuanlan.zhihu.com/p/21930884?refer=intelligentunit" data-editable="true" data-title="本专栏的CS231n笔记系列"&gt;本专栏的CS231n笔记系列&lt;/a&gt;中已经详细介绍过，这里略过。而&lt;equation&gt;U_r&lt;/equation&gt;是为了将&lt;equation&gt;r(t-1)&lt;/equation&gt;映射到和&lt;equation&gt;w(t)&lt;/equation&gt;同样的向量空间中所做的变换；&lt;/li&gt;&lt;li&gt;512维的&lt;b&gt;多模型层&lt;/b&gt;连接着模型的&lt;b&gt;语言部分&lt;/b&gt;和&lt;b&gt;图像部分&lt;/b&gt;。&lt;b&gt;图像部分&lt;/b&gt;就是上图中绿色虚线包围的部分，其本质是利用深度卷积神经网络来提取图像的特征。在该文中，使用的是大名鼎鼎的AlexNet的&lt;b&gt;第七层的激活数据&lt;/b&gt;作为特征数据输入到多模型层，如此就得到了图像特征向量&lt;equation&gt;I&lt;/equation&gt;。而&lt;b&gt;语言部分&lt;/b&gt;就是包含了单词嵌入层和循环层；&lt;/li&gt;&lt;li&gt;多模型层中所做的计算是：&lt;equation&gt;m(t)=g_2(V_w\cdot w(t)+V_r\cdot r(t)+I)&lt;/equation&gt;。其中，&lt;b&gt;m&lt;/b&gt;表示的是多模型层的特征向量，&lt;b&gt;I&lt;/b&gt;表示的是图像部分输入的特征向量，&lt;b&gt;w(t)&lt;/b&gt;和&lt;b&gt;r(t)&lt;/b&gt;的解释同上。至于&lt;equation&gt;V_w&lt;/equation&gt;和&lt;equation&gt;V_r&lt;/equation&gt;，依旧是一个矩阵变换。在这个公式中，&lt;b&gt;需要特！别！注！意！的&lt;/b&gt;是：&lt;b&gt;在每个t时刻，图像特征&lt;equation&gt;I&lt;/equation&gt;都作为输入进入了计算&lt;/b&gt;。这里向大家提问：&lt;b&gt;这样做好不好呢&lt;/b&gt;？先思考一下。后面会给出答案。最后，&lt;equation&gt;g_2(.)&lt;/equation&gt;函数是一个带参数的tanh函数：&lt;equation&gt;g_2(x)=1.7159\cdot tanh(\frac{2}{3}x)&lt;/equation&gt;。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;该网络在训练的时候，设计的&lt;b&gt;代价函数是基于语句的困惑度（Perplexity）&lt;/b&gt;的。关于困惑度，我们在&lt;a href="https://zhuanlan.zhihu.com/p/22408033?refer=intelligentunit" data-title="上篇中已经介绍" class="" data-editable="true"&gt;上篇中已经介绍&lt;/a&gt;，这里就不重复了。论文设计的代价函数为：&lt;/p&gt;&lt;equation&gt;C=\frac{1}{N}\sum^N_{i=1}L\cdot log_2PPL(w^{(i)}_{1:L}|I^{(i)})+||\theta||^2_2&lt;/equation&gt;&lt;p&gt;其中N是训练集中单词的数量，&lt;equation&gt;\theta&lt;/equation&gt;是模型的参数。所以&lt;equation&gt;||\theta||^2_2&lt;/equation&gt;实际上是一个正则化部分。而L是单词序列的长度。&lt;b&gt;训练的目标&lt;/b&gt;就是最小化代价函数值。可以看见，上述代价函数是可导的，由此就可以用反向传播来求梯度，而后用随机梯度下降方法来学习参数。&lt;/p&gt;&lt;p&gt;&lt;b&gt;模型的语句生成&lt;/b&gt;：模型从一个特殊的开始符号“##START##”或者任意个参考单词（这里的意思是，作者们可以输入参考语句中的前K个单词作为开始）开始，然后模型开始计算下一个单词的概率分布&lt;equation&gt;P(w|w_{1:n-1}|I)&lt;/equation&gt;。然后取概率最大的一个单词作为选取的单词，同时再把这个单词作为输入，预测下一个单词，循环往复，直到生成结束符号##END##。&lt;/p&gt;&lt;p&gt;&lt;b&gt;实验数据集和标注&lt;/b&gt;：该论文发表较早，使用的数据集有我们在上篇中介绍的&lt;b&gt;Flickr8K和30K&lt;/b&gt;，也有我们没有介绍的&lt;b&gt;IAPR TC-12&lt;/b&gt;。使用的自动评价标准也较少，有&lt;b&gt;Perplexity，BLUE1-3，没有BLUE4，其余评价都没有。&lt;/b&gt;与该方法对比的，也是一些相对传统的方法。因此在这里，就对其实验结果略过了，感兴趣的知友可以自行阅读论文。&lt;/p&gt;&lt;p&gt;&lt;b&gt;综上&lt;/b&gt;：该论文的主要贡献就是提出了将RNN和CNN结合起来的模型。模型中有一些设计在后续中被证明不是良好的设计，后续的论文在这个模型的基础上逐渐优化。&lt;/p&gt;&lt;h2&gt;NIC模型&lt;/h2&gt;&lt;p&gt;2014年11月，谷歌的Vinyals等人发布了论文《&lt;a href="http://arxiv.org/abs/1411.4555" data-title="Show and Tell: A Neural Image Caption Generator" class="" data-editable="true"&gt;Show and Tell: A Neural Image Caption Generator&lt;/a&gt;》，推出了&lt;b&gt;NIC（Neural Image Caption）模型&lt;/b&gt;。&lt;/p&gt;&lt;p&gt;相较于百度的m-RNN模型，NIC模型的主要不同点在于：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;抛弃RNN，使用了&lt;b&gt;LSTM&lt;/b&gt;；&lt;/li&gt;&lt;li&gt;CNN部分使用了一个比AlexNet&lt;b&gt;更好的卷积神经网络&lt;/b&gt;；&lt;/li&gt;&lt;li&gt;CNN提取的&lt;b&gt;图像特征数据只在开始输入一次&lt;/b&gt;。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;而从论文角度来看，该论文使用的图像标注数据集较为丰富，有Pascal VOC 2008，Flickr8K和30K，MSCOCO，SBU。其采用的自动评价标准也较为齐全，有BLEU-1，BLEU-4，METEOR和CIDEr。同时，就像我在上篇中提到的那样，论文还用人工方法客观地对NIC模型生成的标注语句进行了分级评价，展示了得分和实际效果之间的距离。下面我们主要对NIC模型本身进行一些讲解。&lt;/p&gt;&lt;p&gt;&lt;b&gt;NIC模型结构&lt;/b&gt;如下图所示：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-a5051f70a403c8284dae4fede8131bba.png" data-rawwidth="1056" data-rawheight="586"&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;图像特征部分&lt;/b&gt;是换汤不换药：我们可以看见，图像经过卷积神经网络，最终还是变成了特征数据（就是特征向量）出来了。唯一的不同就是这次试用的CNN不一样了，取得第几层的激活数据不一样了，归根结底，出来的还是特征向量；&lt;/li&gt;&lt;li&gt;&lt;b&gt;但是！&lt;/b&gt;图像特征只在刚开始的时候输入了LSTM，后续没有输入，这点和m-RNN模型是不同的！&lt;/li&gt;&lt;li&gt;&lt;b&gt;单词输入部分&lt;/b&gt;还是老思路：和m-RNN模型一样，每个单词采取了独热（one-hot）编码，用来表示单词的是一个维度是词汇表数量的向量。向量和矩阵&lt;equation&gt;W_e&lt;/equation&gt;相乘后，作为输入进入到LSTM中。&lt;/li&gt;&lt;li&gt;&lt;b&gt;使用LSTM来替换了RNN&lt;/b&gt;。LSTM是什么东西呢，简单地来说，可以把它看成是效果更好RNN吧。为什么效果更好呢？因为它的公式更复杂哈哈😝（并不是）。如果知友对LSTM的细节感兴趣，想要理解LSTM。&lt;b&gt;建议观看CS231n的视频课程第10课：Recurrent Neural Networks, Image Captioning, LSTM&lt;/b&gt;。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;以上模型所示的流程，可以用下列公式来概括：&lt;/p&gt;&lt;equation&gt;x_{-1}=CNN(I)&lt;/equation&gt;&lt;equation&gt;x_t=W_eS_t,\quad t\in\{0...N-1\}&lt;/equation&gt;&lt;equation&gt;p_{t+1}=LSTM(x_t),\quad t\in\{0...N-1\}&lt;/equation&gt;&lt;p&gt;那么，为什么在NIC模型中，只在第一次输入图像特征数据，而不是每次都输入了呢？论文中说：&lt;/p&gt;&lt;blockquote&gt;We empirically verified
that feeding the image at each time step as an extra input
yields inferior results, as the network can explicitly exploit
noise in the image and overfits more easily.我们从实践经验上证实如果在每一个时间点都输入图像数据，将会导致较差的结果。网络可能会放大图像数据中的噪音，并且更容易过拟合。&lt;/blockquote&gt;&lt;p&gt;后续的论文中，基本上都是采取在初始时输入一次图像特征数据，不再使用m-RNN每次都输入的方法了。&lt;/p&gt;&lt;p&gt;&lt;b&gt;模型的训练&lt;/b&gt;：NIC模型的损失函数和m-RNN模型却有不同，但基本思路还是一样的：一个可求导的损失函数，利用反向传播来求梯度，然后利用随机梯度下降来学习到最优的参数。其损失函数为：&lt;/p&gt;&lt;equation&gt;L(I,S)=-\sum^N_{t=1}logp_t(s_t)&lt;/equation&gt;&lt;p&gt;&lt;b&gt;实验结果&lt;/b&gt;：经过了以上这些改进后，NIC模型比起m-RNN模型还是有了较大进步：&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-a51e0c551ffce8b739942a3fb6a822a9.png" data-rawwidth="1100" data-rawheight="526"&gt;上图是不同算法在不同数据集上的BLEU-1得分的比较。可以看到NIC比起m-RNN还是有较大的进步的。当然，该论文值得深入学习的地方还有很多，但是本文主要聚焦于图像标注方面，对论文中其他任务（如图像检索等）的结果，在这里就不过多介绍了。&lt;/p&gt;&lt;p&gt;&lt;b&gt;综上&lt;/b&gt;：NIC模型相较于m-RNN模型，其重要的改进在于：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;首先，在语言模型部分将RNN替换为了实践证明在NLP方面效果更好的&lt;b&gt;LSTM&lt;/b&gt;。&lt;/li&gt;&lt;li&gt;其次，在图像模型部分使用了效果&lt;b&gt;更好的卷积神经网络模型&lt;/b&gt;来做图像特征数据的提取。&lt;/li&gt;&lt;li&gt;最后，改变了图像特征数据的输入方式，从m-RNN的每个时间点都输入变成了&lt;b&gt;只在初始时输入1次&lt;/b&gt;。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;目前最高水平模型&lt;/h2&gt;&lt;p&gt;在介绍完前面两个模型后，仍然有一些论文继续做出了更好水平的方法，但是没有选择介绍是因为他们的思路其实和NIC模型相较于m-RNN模型做出的改进思路是雷同的：更好的卷积神经网络模型，更好的语言模型，不同的图像输入方式，不同的单词嵌入方式等等。&lt;/p&gt;&lt;p&gt;那么为什么要选择这个模型呢？大家会说：当然咯，因为这是目前最好的嘛。其实并不完全是这个原因。关于如何看待论文，不久之前我看到了清华大学的&lt;a href="https://www.zhihu.com/people/45e79aed2c8b69623a57b4889414afe0" data-hash="45e79aed2c8b69623a57b4889414afe0" class="member_mention" data-editable="true" data-title="@肖寒" data-hovercard="p$b$45e79aed2c8b69623a57b4889414afe0"&gt;@肖寒&lt;/a&gt;博士在&lt;a href="https://www.zhihu.com/question/50508148/answer/121343083?from=profile_answer_card" data-editable="true" data-title="某个问题"&gt;某个问题&lt;/a&gt;下的回答，&lt;b&gt;个人认为说得非常好&lt;/b&gt;，这里&lt;b&gt;强力推荐&lt;/b&gt;：&lt;/p&gt;&lt;blockquote&gt;不过，一般注水的作者相对而言都是新手，因为比较有经验的研究者都知道：&lt;b&gt;&lt;i&gt;“论文的一切都在于贡献，不在于结果”&lt;/i&gt;&lt;/b&gt;你的结果只是一个说明你贡献的例证，多那么点少那么点，&lt;b&gt;大家看了毫无区别&lt;/b&gt;。你注水除了恶心我们这些后来实验的人，就没什么别的用处了。有那些&lt;b&gt;疯狂调参和使劲弄技巧&lt;/b&gt;的时间，真不如&lt;b&gt;拿来整理好你自己的思路，把论文的论述过程做到有理有据&lt;/b&gt;！&lt;i&gt;因为 80.2 和 80.3 正常人都没法记住其间区别，但你&lt;b&gt;循循善诱的精致论述会让所有人印象深刻&lt;/b&gt;。我希望新手不要本末倒置！&lt;/i&gt;&lt;/blockquote&gt;&lt;p&gt;所以，选择《&lt;a href="http://arxiv.org/abs/1506.01144" data-editable="true" data-title="What Value Do Explicit High Level Concepts Have in Vision to Language Problems?"&gt;What Value Do Explicit High Level Concepts Have in Vision to Language Problems?&lt;/a&gt;》这篇论文中的模型来讲，不仅仅是因为它效果好，还因为它的贡献：通过实验回答了论文题目本身提出的这个问题：&lt;b&gt;在视觉到语言问题（比如图像标注）中，明确的高等级概念到底有没有价值？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这个问题一旦我们对于现在流行的CNN+RNN模型比较熟练了，就会自然而然地产生疑问：话说这图像特征也不知道是啥，反正我卷积神经网络几个层一过，变成了激活数据，变成了一堆浮点数构成的向量，然后就往RNN初始状态里面一丢，诶，效果还可以。但是&lt;b&gt;为啥呢？！&lt;/b&gt;为啥效果会不错呢？这明明就是一堆说不清楚的特征啊啊！图像的信息并没有用更高级的语义信息表达，就这么稀里糊涂的扔进去了。&lt;/p&gt;&lt;p&gt;该论文在摘要中就一针见血地指明了这个问题：&lt;/p&gt;&lt;blockquote&gt;Much recent progress in Vision-to-Language (V2L) prob-
lems has been achieved through a combination of Convolutional Neural Networks (CNNs) and Recurrent Neural Net-
works (RNNs). This approach &lt;b&gt;does not explicitly represent
high-level semantic concepts, but rather seeks to progress
directly from image features to text&lt;/b&gt;. &lt;/blockquote&gt;这种直接把用CNN提取的图像特征数据扔进RNN的方法&lt;b&gt;寻求的是从图像特征直接到文本，而不是先将其用更高等级的语义概念进行表达&lt;/b&gt;。那么面对这个情况，作者们做了什么（也就是贡献）呢？&lt;blockquote&gt;In this paper we&lt;b&gt; investigate&lt;/b&gt; whether this direct approach succeeds due to, or
despite, the fact that it &lt;b&gt;avoids the explicit representation of
high-level information&lt;/b&gt;. We propose a method of &lt;b&gt;incorporating high-level concepts into the successful CNN-RNN approach&lt;/b&gt;, and show that it achieves a &lt;b&gt;significant improvement&lt;/b&gt;
on the state-of-the-art in both image captioning and visual
question answering. &lt;/blockquote&gt;&lt;p&gt;作者们说，我们就来调查一下，当前流行的这个方法它成功，到底是不是因为它就是避免了将图像信息表达为高等级的语义信息呢？于是作者们在当前的CNN+RNN模型中，增加了一个高等级的语义概念表达，结果发现这么一改，结果很好，出现了很大的提升。这就说明，&lt;b&gt;之前稀里糊涂地把图像特征直接扔进RNN并不是一个好办法，将图像特征用高等级的语义概念表达后再输入RNN会更好&lt;/b&gt;！&lt;/p&gt;&lt;p&gt;这篇论文解答了我同样存在的疑惑，并且通过改进和实验证明，我们存在疑惑的地方是可以有所作为的，改进后的方法有了较大提升。这就是我选择这篇论文的最主要原因。总之，看完摘要我就非常高兴，迫不及待地就开始跳进去想看看人家到底是怎么来做的了。&lt;/p&gt;&lt;p&gt;&lt;b&gt;模型结构&lt;/b&gt;：如下图所示，需要注意的特点有：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-40533b56d6cf861e3d96396cd15baba0.png" data-rawwidth="1122" data-rawheight="796"&gt;&lt;ul&gt;&lt;li&gt;在语言模型部分使用的是LSTM，这一点和之前的模型&lt;b&gt;没有太大区别&lt;/b&gt;。&lt;/li&gt;&lt;li&gt;针对3各不同的任务（图像标注、单个单词问答，语句问答）分别实际了3个语言模型部分，这里我们&lt;b&gt;只关注第一个图像标注任务&lt;/b&gt;。&lt;/li&gt;&lt;li&gt;&lt;b&gt;改进重在视觉部分&lt;/b&gt;：请知友们往上看看之前的m-RNN和NIC模型，在他们的视觉部分，图像的处理是相对简单的：图像输入CNN，然后从CNN靠后的层中取出激活数据，输入到RNN即可。然而在这里，我们看到情况变复杂了。&lt;/li&gt;&lt;li&gt;首先预训练一个的单标签的CNN（蓝色虚线中），然后把该CNN的参数迁移到下方多标签的CNN中（红色虚线中），并对多标签的CNN做精细调整（fine-tune）。&lt;/li&gt;&lt;li&gt;图像输入到红色虚线中的CNN，输出的是一个&lt;b&gt;有高等级语义概念和对应概率的向量&lt;/b&gt;，并将这个向量作为语言部分LSTM的输入。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;也就是说，&lt;b&gt;输入LSTM的不是一个不知道到底是什么的浮点数向量了，而是我们可以理解的语义概念的概率的向量&lt;/b&gt;。&lt;/p&gt;&lt;p&gt;论文介绍模型的时候说：我们的模型还是由图像分析和语句生成两个部分构成。&lt;b&gt;在图像分析部分，&lt;/b&gt;我们使用有监督学习来预测一个属性的集合，这些属性实际上就是图像的标注语句中常见的单词。这一步是如何做到的呢？我们把这一步&lt;b&gt;看做是一个多标签分类问题&lt;/b&gt;，训练了一个对应的深度卷积神经网络来实现。&lt;/p&gt;&lt;p&gt;图像经过模型的图像分析部分，输出的就是&lt;equation&gt;V_{att}(I)&lt;/equation&gt;，它是一个向量，其长度等于标签集合中标签的数量（也就是词汇表的数量），&lt;b&gt;每个维度上装的是某个标签对应的预测概率&lt;/b&gt;。然后这个&lt;equation&gt;V_{att}(I)&lt;/equation&gt;就要作为输入进入到LSTM，也就是语言生成部分了。&lt;/p&gt;&lt;p&gt;在针对图像标注问题的语言模型部分，该论文中简明扼要地说，我们就是按照《&lt;a href="http://arxiv.org/abs/1411.4555" data-title="Show and Tell: A Neural Image Caption Generator" class="" data-editable="true"&gt;Show and Tell: A Neural Image Caption Generator&lt;/a&gt;》论文中的方法来进行语句生成的，喏，就上面的NIC模型，所以这里也就不更多逼逼啦。&lt;/p&gt;&lt;p&gt;&lt;b&gt;属性预测部分&lt;/b&gt;：该论文，我个人感到最有价值的部分，还是在它的图像分析部分中&lt;b&gt;如何从图像到属性的实现，这是它的核心创新点，&lt;/b&gt;所以对该部分做一个比较细节的介绍。需要注意的要点有：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;属性词汇表的构建&lt;/b&gt;：语义属性是从训练集标注语句中提取出来的，可以是句子中的任何部分：物体名称（名词），动作（动词）或者性质（形容词）。使用了&lt;equation&gt;c&lt;/equation&gt;个最常用的单词来构建属性词汇表。在构建的时候，对复数和时态不区分，比如ride和riding，bag和bags被看做一个单词。这样就有效地缩小了词汇表数量，最后得到一个包含256个单词的属性词汇表；&lt;/li&gt;&lt;li&gt;&lt;b&gt;属性预测器的实现&lt;/b&gt;：有了词汇表，就希望给出一张图片，能够得到多个对应的在词汇表中的属性单词。将这个需求，&lt;b&gt;看做是一个多标签分类问题来解决&lt;/b&gt;。具体怎么做呢？如下图所示：&lt;/li&gt;&lt;/ul&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-9c5eee8af0ab6d2abd8e1bc0de6d20c5.png" data-rawwidth="1212" data-rawheight="676"&gt;&lt;ul&gt;&lt;li&gt;首先拿一个用ImageNet&lt;b&gt;预训练好的VGGNet模型作为初始模型&lt;/b&gt;。然后再用MS COCO这样的有&lt;b&gt;多标签的数据集来对这个VGGNet做精细调整&lt;/b&gt;（fine-tune）。精细调整具体怎么做呢？就是将最后一个全连接层的输出输入到c分类的softmax中。c=256代表的是词汇表的数量。然后使用逐元素的逻辑回归作为损失函数：&lt;/li&gt;&lt;li&gt;&lt;b&gt;损失函数&lt;/b&gt;：假设有&lt;equation&gt;N&lt;/equation&gt;个训练样例，&lt;equation&gt;y_i=[y_{i1},y_{i2},...,y_{ic}]&lt;/equation&gt;是第i个图像对应的标签向量，如果&lt;equation&gt;y_{ij}&lt;/equation&gt;=1，表示图像中有该标签，反之则没有。&lt;equation&gt;p_i=[p_{i1},p_{i2},...,p_{ic}]&lt;/equation&gt;是对应的预测概率向量，则损失函数为：&lt;equation&gt;J=\frac{1}{N}\sum^N_{i=1}\sum^c_{j=1}log(1+exp(-y_{ij}p_{ij}))&lt;/equation&gt;。在精细调整的训练过程中只需要最小化这个损失函数值即可；&lt;/li&gt;&lt;li&gt;然后对于一张输入的图像，要将其分割成不同的局部。刚开始的时候是计划分割出上百个局部窗口，后来感到计算起来太耗费时间，就采取了归一化剪枝的算法将所有的方框分从m个簇，然后每个簇中保留最好的k个方框，最后加上原图，得到m*k+1个建议方框，将对应的局部输入到网络中。在使用中，作者令m=10，k=5；&lt;/li&gt;&lt;li&gt;对于局部方框的生成，作者们使用的方法是Multiscale Combinatorial Grouping (MCG)方法。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;实验结果：通过将图像信息表达为高等级的语义信息输入LSTM，该方法得到了一个比较显著的性能提升：&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-505bc9a994886250e68e9f22e67a4fb3.png" data-rawwidth="1220" data-rawheight="736"&gt;这张表是论文方法在MSCOCO数据集上和其他很多方法，以及自己设定的基准模型之间的得分比较。注意除了困惑度（P）外，得分都是越高越好。&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-5c67701be4a5dae18ab97658c661ca7d.png" data-rawwidth="1192" data-rawheight="546"&gt;这张表示论文方法在MSCOCO的5个标注和40个标注语句测试集上与如m-RNN等方法和人类得分的比较，注意论文方法在14个对比中，有13个的得分都是超过人类得分，拿到最高。&lt;/p&gt;&lt;p&gt;&lt;b&gt;注意&lt;/b&gt;：就如同我在上篇中所说，自动评价标准得分高于人类的分，并不代表实际标注语句就比人类标注语句水平高。&lt;b&gt;该论文没有如同谷歌NIC模型论文中一样，设置人工对生成的标注语句的分级评价，是一大遗憾&lt;/b&gt;。&lt;/p&gt;&lt;h2&gt;模型的比较思考&lt;/h2&gt;至此，3个模型及其论文介绍完毕。原本还有LRCN模型和斯坦福的NeuralTalk模型，后将其精简掉了。从这三个模型的进化我们可以看到一个比较清晰的脉络：一个创新之后，对这个创新中的局部进行优化，对局部之间的协作方式进行优化，对创新中说得不清晰或者不合理的部分敢于反思并探索，往往大的提升就在这些模糊的区域中了。&lt;h2&gt;代码实践&lt;/h2&gt;&lt;p&gt;&lt;b&gt;光说不练假把式&lt;/b&gt;。机器学习本来就是一个实践性很强的领域，工程能力是非常重要的一环。因此在我们专栏里面，比较推崇的就是知行合一的协作理念。在这个小节，会对CS231n课程的第三个大作业中的RNN图像标注作业部分内容进行解析，并简要介绍开源的NeuralTalk项目。&lt;/p&gt;&lt;h2&gt;CS231n #A3 RNN_Captioning&lt;/h2&gt;&lt;p&gt;首先，需要说一下的关于CS231n的几个课程作业，个人都非常推荐。希望入门深度学习的同学如能完成，则入门扎实了。我后续也会在专栏进行相关的解析。作业3相关情况请看我们的介绍：&lt;a href="https://zhuanlan.zhihu.com/p/21946525?refer=intelligentunit" data-editable="true" data-title="斯坦福CS231n课程作业# 3简介 - 智能单元 - 知乎专栏" class=""&gt;斯坦福CS231n课程作业# 3简介 - 智能单元 - 知乎专栏&lt;/a&gt;。由于本文主要是介绍图像标注问题，所以作业相关背景就不多说了。&lt;/p&gt;&lt;p&gt;完成RNN_Captioning作业首先需要运行jupyter notebook，然后打开&lt;b&gt;RNN_Captioning.ipynb&lt;/b&gt;文件。然后就可以看到整个作业文件是由Markdown文字说明块（Cell）和python代码块组成的，基本上是手把手教你完成该实验，在某些代码块之前，实验要求你要实现某些核心函数。&lt;/p&gt;&lt;p&gt;&lt;b&gt;代码块1-3：&lt;/b&gt;这3个代码块都不需要我们做什么，他们依次是在进行一些文件导入，初始化设置，导入MS COCO数据，显示数据集中的某些图像和标注语句。在代码块-1的下方，有对MSCOCO数据集的介绍：&lt;/p&gt;&lt;blockquote&gt;在本练习中，我们将使用微软COCO数据集2014版，该数据集已经成为图像标注的标准数据库。数据集包含80000张训练图像，40000张验证图像，每张图都有5个描述句子，句子是利用亚马逊的土耳其机器人招募人工做的。要下载数据集，到cs231n/datasets目录中运行get_coco_captioning.sh脚本。我们已经为你对数据进行了预处理并从中提取出了特征。使用在ImageNet上预训练的VGG-16网络，我们从网络的 fc7层提取出了所有图像的特征。这些特征被分别存储在train2014_vgg16_fc7.h5 和val2014_vgg16_fc7.h5两个文件中。为了减少处理时间和内存需求，还使用PCA将维度从4096减少到了512，这些数据存在train2014_vgg16_fc7_pca.h5val201h和4_vgg16_fc7_pca.h5l两个文件中。原始图像有20G，所以没有包含在这次的下载中。然而所有的图像都是从Flickr中获取，训练和验证图像的url都存在train2014_urls.txt和val2014_urls.txt，这样你就可以通过网络下载图像了。处理字符串是很低效的，所以练习中使用的是编码版的标注。每个单词都分配了一个整数ID，这样就能用数字序列来表示标注语句了。单词和ID之间的映射在文件coco2014_vocab.json中。你可以使用cs231n/coco_utils.py中的decode_captions来将装着整数ID的numpy数组转化为字符串。我们向字符表中加入了一些特殊的标记，在每个标注的开头加入&amp;lt;START&amp;gt; 结尾加入&amp;lt;END&amp;gt;，很少见的单词用 &amp;lt;UNK&amp;gt;替换。还有，因为小批量数据中的标注句子长度不同，所有在短的句子结束 &amp;lt;END&amp;gt; 后后面加上了 &amp;lt;NULL&amp;gt;标记，并且对 &amp;lt;NULL&amp;gt;标记不计算损失值和梯度。因为处理起来有点痛苦，所以我们已经帮你搞定了这些特殊标记的实现细节。使用load_coco_datah函数将所有的COCO数据进行加载。&lt;/blockquote&gt;&lt;p&gt;从上面的说明中我们可以知道几个要点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;助教在设计实验的时候，已经将图像输入到卷积神经网络中，提取出了特征数据并将其文件化，我们可以直接用了；&lt;/li&gt;&lt;li&gt;单词都是用整数ID来表示的。打开json文件我们可以看到：&lt;/li&gt;&lt;/ul&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-487ddc0cafce573205084ef7218d1329.png" data-rawwidth="604" data-rawheight="276"&gt;&lt;ul&gt;&lt;li&gt;一些特殊的符号用来表示句子的开始和结束，以及不常见的单词。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;接下来，我们需要开始在作业文件夹中的&lt;b&gt;cs231n/rnn_layers.py&lt;/b&gt;文件中实现一些核心函数&lt;b&gt;rnn_step_forward&lt;/b&gt;，不然代码块4运行是会报错的。rnn_step_forward函数实现的就是RNN模型一个时间戳的前向传播。我们先来看看代码块4。&lt;/p&gt;&lt;p&gt;代码块4：其实就是在&lt;b&gt;检验rnn_step_forward函数有没有正确实现&lt;/b&gt;。&lt;/p&gt;&lt;pre&gt;&lt;code lang="python"&gt;N, D, H = 3, 10, 4

x = np.linspace(-0.4, 0.7, num=N*D).reshape(N, D)
prev_h = np.linspace(-0.2, 0.5, num=N*H).reshape(N, H)
Wx = np.linspace(-0.1, 0.9, num=D*H).reshape(D, H)
Wh = np.linspace(-0.3, 0.7, num=H*H).reshape(H, H)
b = np.linspace(-0.2, 0.4, num=H)

next_h, _ = rnn_step_forward(x, prev_h, Wx, Wh, b)
expected_next_h = np.asarray([
  [-0.58172089, -0.50182032, -0.41232771, -0.31410098],
  [ 0.66854692,  0.79562378,  0.87755553,  0.92795967],
  [ 0.97934501,  0.99144213,  0.99646691,  0.99854353]])

print 'next_h error: ', rel_error(expected_next_h, next_h)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;现在让我们用sublime text打开cs231n/rnn_layers.py文件找到rnn_step_forward函数：&lt;/p&gt;&lt;pre&gt;&lt;code lang="python"&gt;def rnn_step_forward(x, prev_h, Wx, Wh, b):
  """
  Run the forward pass for a single timestep of a vanilla RNN that uses a tanh
  activation function.

  The input data has dimension D, the hidden state has dimension H, and we use
  a minibatch size of N.

  Inputs:
  - x: Input data for this timestep, of shape (N, D).
  - prev_h: Hidden state from previous timestep, of shape (N, H)
  - Wx: Weight matrix for input-to-hidden connections, of shape (D, H)
  - Wh: Weight matrix for hidden-to-hidden connections, of shape (H, H)
  - b: Biases of shape (H,)

  Returns a tuple of:
  - next_h: Next hidden state, of shape (N, H)
  - cache: Tuple of values needed for the backward pass.
  """
  next_h, cache = None, None
  #######################################################################
  # TODO: Implement a single forward step for the vanilla RNN. Store the next  #
  # hidden state and any values you need for the backward pass in the next_h   #
  # and cache variables respectively.                                          
#######################################################################
# implemente the function   #######################################################################
 #                          END OF YOUR CODE                      #######################################################################
  return next_h, cache
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;回顾课程，该函数主要要实现的就是RNN模型的下面计算：&lt;/p&gt;&lt;equation&gt;h_t=tanh(W_{hh}h_{t-1}+W_{xh}x_t)&lt;/equation&gt;&lt;p&gt;在上述函数定义中，x就是该时间点的输入。prev_h就是RNN上一个隐藏状态，即&lt;equation&gt;h_{t-1}&lt;/equation&gt;。Wx对应的就是&lt;equation&gt;W_{xh}&lt;/equation&gt;，Wh对应的就是&lt;equation&gt;W_{hh}&lt;/equation&gt;，b是偏置量。于是实现如下：&lt;/p&gt;&lt;pre&gt;&lt;code lang="python"&gt;# stage computation
  # Step 1. mul1: Wh(H, H) dot prev_h(N, H) -&amp;gt; (N, H)
  mul1 = np.dot(prev_h, Wh)

  # Step 2. mul2: Wx(D, H) dot x(N, D) -&amp;gt; (N, H)
  mul2 = np.dot(x, Wx)

  # Step 3. add1: mul1 + mul2 -&amp;gt; (N, H)
  add1 = mul1 + mul2

  # Step 4. add2: add1(N, H) + b(H,) Broadcasting -&amp;gt; (N, H)
  add2 = add1 + b

  # Step 5. tanhed: apply tanh to add2 -&amp;gt; (N, H)
  tanhed = np.tanh(add2)
  next_h = tanhed

  # cache
  cache = (mul1, mul2, add1, add2, tanhed, x, Wx, Wh, prev_h.copy()) 
  # .copy is important!!!
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;大家看到这段实现可能会很奇怪，明明一行代码就能实现的事情，&lt;b&gt;为什么分成这么多步，还用了这么多中间变量&lt;/b&gt;？实际上，这种分段式的实现，是为了能够方便实现反向传播。为了说明这一点，接下来展示一下实现该步骤的反向传播函数rnn_step_backward。&lt;/p&gt;&lt;pre&gt;&lt;code lang="python"&gt;def rnn_step_backward(dnext_h, cache):
  """
  Backward pass for a single timestep of a vanilla RNN.
  
  Inputs:
  - dnext_h: Gradient of loss with respect to next hidden state
  - cache: Cache object from the forward pass
  
  Returns a tuple of:
  - dx: Gradients of input data, of shape (N, D)
  - dprev_h: Gradients of previous hidden state, of shape (N, H)
  - dWx: Gradients of input-to-hidden weights, of shape (N, H) ? maybe wrong -&amp;gt; (D, H)
  - dWh: Gradients of hidden-to-hidden weights, of shape (H, H)
  - db: Gradients of bias vector, of shape (H,)
  """
  dx, dprev_h, dWx, dWh, db = None, None, None, None, None
  #######################################################################
  # TODO: Implement the backward pass for a single step of a vanilla RNN.      #
  # HINT: For the tanh function, you can compute the local derivative in terms of the output value from tanh. 
#######################################################################
# implemente the function  
#######################################################################
  #                      END OF YOUR CODE                    
#######################################################################
  return dx, dprev_h, dWx, dWh, db
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;我对该函数的实现如下：&lt;/p&gt;&lt;pre&gt;&lt;code lang="python"&gt;# get the cache
  mul1, mul2, add1, add2, tanhed, x, Wx, Wh, prev_h = cache

  # backward pass
  # Back to step 5: backprop through tanh. dnext_h(N, H) taned(N, H)
  # d/dx (tanh x)^2 = 1 - (tanh x)^2
  dadd2 = (1.0 - tanhed * tanhed) * dnext_h

  # Back to step 4: z=x+y -&amp;gt; dz/dx(writted in dx) = 1, dz/dy(writted in dy) = 1
  dadd1 = 1.0 * dadd2 # -&amp;gt; (N, H)
  db = 1.0 * np.sum(dadd2, axis=0) # since db shape:(H,)

  # Back to step 3: z=x+y -&amp;gt; dz/dx(writted in dx) = 1, dz/dy(writted in dy) = 1
  dmul1 = 1.0 * dadd1 # -&amp;gt; (N, H)
  dmul2 = 1.0 * dadd1 # -&amp;gt; (N, H)

  # Back to step 2: x * y = z -&amp;gt; dx = y, dy = x
  # dWx = x * dmul2. x(N, D) dmul2(N, H) dWx should be (D, H)
  dWx = np.dot(x.T, dmul2)
  # dx = Wx * dmul2. Wx(D, H), dmul2(N, H) -&amp;gt; (N, D)
  dx = np.dot(dmul2, Wx.T)

  # Back to step 1: x * y = z -&amp;gt; dx = y, dy = x
  # dWh = prev_h * dmul1. prev_h(N, H), dmul1(N, H) -&amp;gt; (H, H)
  # which H is row ?
  dWh = np.dot(prev_h.T, dmul1)
  # dprev_h = Wh * dmul1. Wh(H, H), dmul1(N, H) -&amp;gt; (N, H)
  dprev_h = np.dot(dmul1, Wh.T)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;可以看见，这个反向传播求梯度和刚才前向传播的分步是一致的。&lt;/p&gt;&lt;p&gt;以上，就是CS231n作业3中用简单RNN来实现图像标注实验中RNN前向步进的实现，只是整个作业的一小部分，鉴于这个作业较长，且后续我会连载CS231n作业解析，所以就不全部讲解了。总体说来，完成作业后对于学习者对深度学习的理解，是很有帮助的。&lt;/p&gt;&lt;h2&gt;NeuralTalk项目&lt;/h2&gt;&lt;p&gt;在斯坦福计算机视觉实验室的论文《&lt;a href="http://arxiv.org/abs/1412.2306" data-editable="true" data-title="Deep Visual-Semantic Alignments for Generating Image Descriptions" class=""&gt;Deep Visual-Semantic Alignments for Generating Image Descriptions&lt;/a&gt;》中，作者&lt;a href="http://cs.stanford.edu/people/karpathy/" data-editable="true" data-title="Andrej Karpathy" class=""&gt;Andrej Karpathy&lt;/a&gt;给出了实验数据、代码和介绍：&lt;a href="http://cs.stanford.edu/people/karpathy/deepimagesent/" data-editable="true" data-title="Deep Visual-Semantic Alignments for Generating Image Descriptions"&gt;Deep Visual-Semantic Alignments for Generating Image Descriptions&lt;/a&gt;。现在去看页面，发现最初的基于Numpy的NerualTalk项目已经被废弃停止维护了，新的基于Torch的NerualTalk2已经发布。&lt;/p&gt;&lt;p&gt;鉴于&lt;a href="http://cs.stanford.edu/people/karpathy/" data-editable="true" data-title="Andrej Karpathy" class=""&gt;Andrej Karpathy&lt;/a&gt;已经从斯坦福计算机视觉实验室毕业，去了OpenAI，开始搞深度增强学习和tensorflow，所以这个项目是否会继续维护下去，还不得而知。&lt;/p&gt;&lt;p&gt;对于完成了CS231n作业的同学，建议可以先从老的基于Numpy的&lt;a href="https://github.com/karpathy/neuraltalk" data-editable="true" data-title="NerualTalk项目"&gt;NerualTalk项目&lt;/a&gt;入手学习。因为实际上作者自己也说：&lt;/p&gt;&lt;blockquote&gt; I am leaving it on Github for educational purposes.&lt;/blockquote&gt;&lt;p&gt;等对于老的NerualTalk项目比较熟悉了，可以考虑去阅读基于Torch的NerualTalk2，或者自己使用tensorflow来进行实现。&lt;/p&gt;&lt;h2&gt;图像标注问题展望&lt;/h2&gt;写到这里，其实我个人关于图像标注问题的看法已经比较清晰地包含在前面的文中了。想要更好地解决图像标注问题，需要：&lt;ul&gt;&lt;li&gt;更好的自动评价标准。这里个更好，是指的能够和人类评价相关性更高；&lt;/li&gt;&lt;li&gt;更大的数据集。图像更多，图像对应标注句子更多；&lt;/li&gt;&lt;li&gt;在图像分析部分，语言生成部分，或者两个部分的连接方式上出现新的模型或思路。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;总而言之，我个人对于图像标注问题比较乐观，在前面图像分类问题的深厚基础上，图像标注问题应该能够在1-2年内拿出一个接近或者达到人类标注水平的方法。&lt;/p&gt;&lt;h2&gt;作者反馈&lt;/h2&gt;&lt;ol&gt;&lt;li&gt;欢迎对文中不妥之处批评指正；&lt;/li&gt;&lt;/ol&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/22520434&amp;pixel&amp;useReferer"/&gt;</description><author>杜客</author><pubDate>Thu, 22 Sep 2016 16:40:31 GMT</pubDate></item></channel></rss>