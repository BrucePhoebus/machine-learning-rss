<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>无痛的机器学习 - 知乎专栏</title><link>https://zhuanlan.zhihu.com/hsmyy</link><description>专栏主营业务：让更多人能看的懂的机器学习科普+进阶文章。欢迎各位大神投稿或协助审阅。</description><lastBuildDate>Sat, 17 Dec 2016 09:16:05 GMT</lastBuildDate><generator>Ricky</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>番外篇(2)——无聊的最速下降法推导</title><link>https://zhuanlan.zhihu.com/p/23799012</link><description>好吧，我想题目已经说明了一切，虽然说这个过程很无聊，但是我们可以收藏下这段推导，因为它的结论还是很有用的……那不如让我们先来看看结论：&lt;p&gt;对于上一回我们介绍的那个函数：&lt;/p&gt;&lt;equation&gt;f(X)=\frac{1}{2}X^TQX&lt;/equation&gt;&lt;p&gt;其中Q是一个对称正定矩阵，&lt;equation&gt;\lambda_n&lt;/equation&gt;是Q的n个特征值,并且满足0 &amp;gt; &lt;equation&gt;\lambda_1&lt;/equation&gt;&amp;gt;= &lt;equation&gt;\lambda_2&lt;/equation&gt;&amp;gt;=
&lt;equation&gt;\lambda_n&lt;/equation&gt;，那么有: &lt;/p&gt;&lt;equation&gt;f(X_{k+1})\leq(\frac{\lambda_n-\lambda_1}{\lambda_n+\lambda_1})^2f(X_k)&lt;/equation&gt;&lt;p&gt;下面问题来了，我们求出上面这个公式有毛用？我们可以看出随着优化的不断进行，我们的函数是不断变小的，但是我们需要为函数优化定一个期限。我们希望函数能够尽快地优化到位，那么&lt;equation&gt;\frac{\lambda_n-\lambda_1}{\lambda_n+\lambda_1}&lt;/equation&gt;这部分当然是越小越好了。&lt;/p&gt;&lt;p&gt;如果说大家想知道结论，那么这篇文章到此结束，下面是具体的推导了，前方各种高能，非战斗人员点了赞就可以撤了……&lt;/p&gt;&lt;h2&gt;公式推导&lt;/h2&gt;&lt;p&gt;公式推导总体来说分为几个部分：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;求出步长&lt;equation&gt;\alpha_t&lt;/equation&gt;&lt;/li&gt;&lt;li&gt;整理公式&lt;/li&gt;&lt;li&gt;Kantorovich Inequality&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;下面我们一步一步来，其中的第一步可以跳过了，因为我们在上一篇文章已经做过了，那就是求出步长，这里我们就不再推导一遍了，直接给出结果：&lt;/p&gt;&lt;equation&gt;\alpha_t=\frac{g_t^Tg_t}{g_t^TAg_t}&lt;/equation&gt;&lt;p&gt;下面是第2部。&lt;/p&gt;&lt;h2&gt;整理公式&lt;/h2&gt;&lt;p&gt;这一步的主要目标是去凑那个公式，我们从公式的左边出发，首先要利用更新公式了：&lt;/p&gt;&lt;equation&gt;X_{t+1}=X_t-\alpha_tg_t&lt;/equation&gt;&lt;equation&gt;f(X_{t+1})=\frac{1}{2}X_{t+1}^TAX_{t+1}=\frac{1}{2}(X_t-\alpha_tg_t)^T A (X_t-\alpha_tg_t)&lt;/equation&gt;&lt;equation&gt;=\frac{1}{2}[X_t^TAX_t-X_t^TA\alpha_tg_t-\alpha_tg_t^TAX_t-\alpha_t^2g_t^TAg_t]&lt;/equation&gt;&lt;equation&gt;=\frac{1}{2}[2f(X_t)-X_t^TA\alpha_tg_t-\alpha_tg_t^TAX_t-2\alpha_t^2f(g_t)]&lt;/equation&gt;&lt;p&gt;接下来我们需要两个公式：&lt;/p&gt;&lt;p&gt;首先，我们的矩阵A是对称的，所以&lt;equation&gt;A^T=A&lt;/equation&gt;;&lt;/p&gt;&lt;p&gt;其次，我们的导数公式：&lt;equation&gt;g_t=AX&lt;/equation&gt;&lt;/p&gt;&lt;p&gt;所以上面的公式就变成了：&lt;/p&gt;&lt;equation&gt;=\frac{1}{2}[2f(X_t)-(AX_t)^T\alpha_tg_t-\alpha_tg_t^T(AX_t)+2\alpha_t^2f(g_t)]&lt;/equation&gt;&lt;equation&gt;=\frac{1}{2}[2f(X_t)-\alpha_tg_t^Tg_t-\alpha_tg_t^Tg_t+2\alpha_t^2f(g_t)]&lt;/equation&gt;&lt;equation&gt;=f(X_t)-\alpha_tg_t^Tg_t+\alpha_t^2f(g_t)&lt;/equation&gt;&lt;p&gt;好了，公式整理得差不多了，下面我们要把&lt;equation&gt;\alpha_t&lt;/equation&gt;的公式代入了：&lt;/p&gt;&lt;equation&gt;=f(X_t)-\frac{g_t^Tg_t}{g_t^TAg_t}g_t^Tg_t+(\frac{g_t^Tg_t}{g_t^TAg_t})^2f(g_t)&lt;/equation&gt;&lt;equation&gt;=f(X_t)-\frac{(g_t^Tg_t)^2}{g_t^TAg_t}+(\frac{g_t^Tg_t}{g_t^TAg_t})^2(\frac{1}{2}g_t^TAg_t)&lt;/equation&gt;&lt;equation&gt;=\frac{1}{2}[X_t^TAX_t-\frac{(g_t^Tg_t)^2}{g_t^TAg_t}]&lt;/equation&gt;&lt;p&gt;到这里似乎又推导不动了，下面继续放一个杀招：&lt;/p&gt;&lt;equation&gt;X_t^TAX_t=X_t^TAA^{-1}AX_t=X_t^TA^TA^{-1}AX_t&lt;/equation&gt;&lt;equation&gt;=(AX_t)^TA^{-1}(AX_t)=g_t^TA^{-1}g_t&lt;/equation&gt;&lt;p&gt;于是公式可以进一步整理了：&lt;/p&gt;&lt;equation&gt;=\frac{1}{2}X_t^TAX_t[1-\frac{(g_t^Tg_t)^2}{(g_t^TAg_t)(g_t^TA^{-1}g_t)}]&lt;/equation&gt;&lt;equation&gt;=f(X_t)[1-\frac{(g_t^Tg_t)^2}{(g_t^TAg_t)(g_t^TA^{-1}g_t)}]&lt;/equation&gt;&lt;p&gt;好了，整理到这里我们的第一步工作基本完成了，我们来看看我们成果和最终的结果：&lt;/p&gt;&lt;p&gt;最终结果：&lt;equation&gt;f(x_{k+1})\leq(\frac{\lambda_n-\lambda_1}{\lambda_n+\lambda_1})^2f(x_k)&lt;/equation&gt;&lt;/p&gt;&lt;p&gt;目前结果：&lt;equation&gt;f(X_{t+1})=[1-\frac{(g_t^Tg_t)^2}{(g_t^TAg_t)(g_t^TA^{-1}g_t)}]f(X_t)&lt;/equation&gt;&lt;/p&gt;&lt;p&gt;好了，下面的目标很明确了，我们要做的就是里面那一大堆的变换。&lt;/p&gt;&lt;h2&gt;Kantorovich Inequality&lt;/h2&gt;&lt;p&gt;说实话如果是一般的文章到这里就会结束了，可是这篇推导实在比较恶心，于是我决定一口气推完，不给大家恶心第二次的机会。&lt;/p&gt;&lt;p&gt;下面这部分的转换据说是一个叫做Kantorovich Inequality的定理，但是这么不常见的定理对于我们来说实在陌生，如果拿这个名称糊弄大家就有点不太地道了，于是乎我们就假装不知道这个定理，把这个定理再推导一遍。&lt;/p&gt;&lt;p&gt;我们这一步的目标是证明：&lt;/p&gt;&lt;equation&gt;\frac{(g_t^Tg_t)^2}{(g_t^TAg_t)(g_t^TA^{-1}g_t)}\geq \frac{4\lambda_1\lambda_n}{(\lambda_1+\lambda_n)^2}&lt;/equation&gt;&lt;p&gt;也就是&lt;equation&gt;\frac{(g_t^TAg_t)(g_t^TA^{-1}g_t)}{(g_t^Tg_t)^2}\leq \frac{(\lambda_1+\lambda_n)^2}{4\lambda_1\lambda_n}&lt;/equation&gt;&lt;/p&gt;&lt;p&gt;好了，现在我们开始继续推导。左边部分的A可以变为特征值的形式：&lt;/p&gt;&lt;equation&gt;=\frac{(g_t^TS^T\Lambda Sg_t)(g_t^TS^T \Lambda^{-1}Sg_t)}{(g_t^TS^TSg_t)^2}&lt;/equation&gt;&lt;p&gt;令&lt;equation&gt;Sg_t=l&lt;/equation&gt;，可以得到：&lt;/p&gt;&lt;equation&gt;=\frac{\sum_{i=1}^n{\lambda_i * l_i^2}\sum_{i=1}^n{\frac{1}{\lambda_i} * l_i^2}}{(l_t^Tl_t)^2}&lt;/equation&gt;&lt;p&gt;此时的分母相当于一个归一化的因子,所以我们可以将式子进一步化解为:&lt;/p&gt;&lt;equation&gt;\sum_{i=1}^n{\lambda_i * z_i^2}\sum_{i=1}^n{\frac{1}{\lambda_i} * z_i^2}&lt;/equation&gt;&lt;p&gt;given &lt;equation&gt;\sum_{i=1}^n{z_i^2}=1&lt;/equation&gt;&lt;/p&gt;&lt;p&gt;我们可以利用拉格朗日乘子法把这两个公式融合起来,得到:&lt;/p&gt;&lt;equation&gt;F=\sum_{i=1}^n{\lambda_i * z_i^2}\sum_{i=1}^n{\frac{1}{\lambda_i} * z_i^2}+\alpha(\sum_{i=1}^n{z_i^2}-1)&lt;/equation&gt;&lt;p&gt;这里令&lt;/p&gt;&lt;equation&gt;\sigma=\sum_{i=1}^n{\lambda_i * z_i^2}&lt;/equation&gt;&lt;equation&gt;\hat{\sigma}=\sum_{i=1}^n{\frac{1}{\lambda_i} * z_i^2}&lt;/equation&gt;&lt;p&gt;我们可以进行日常的求导工作找到这个函数的极值：&lt;/p&gt;&lt;equation&gt;\frac{\partial F}{\partial z_i}=2(\sigma \frac{1}{\lambda_i}z_i+\hat{\sigma}\lambda_iz_i-\alpha z_i)=0,(i=1...n)&lt;/equation&gt;&lt;equation&gt;\frac{\partial F}{\partial z_i}=z_i(\sigma+\hat{\sigma}\lambda_i^2-\alpha \lambda_i)=0,(i=1...n)&lt;/equation&gt;&lt;p&gt;我们可以给出上面求导的一种解，那就是我们令尽可能多的&lt;equation&gt;z_i&lt;/equation&gt;等于0，而保留其中的两个 &lt;equation&gt;z_i&lt;/equation&gt;不等于0，关于这两个的导数，我们让&lt;equation&gt;(\sigma+\hat{\sigma}\lambda_i^2-\alpha \lambda_i)&lt;/equation&gt;这一部分等于0，同时我们保证所有的变量都满足那个约束，于是我们最原始的公式就变成了：&lt;/p&gt;&lt;equation&gt;F=(\lambda_kz_k^2+\lambda_lz_l^2)(\frac{1}{\lambda_k}z_k^2+\frac{1}{\lambda_l}z_l^2)&lt;/equation&gt;&lt;p&gt;given &lt;equation&gt;z_k^2+z_l^2=1&lt;/equation&gt;&lt;/p&gt;&lt;p&gt;下面就是复杂的各种变换：&lt;/p&gt;&lt;equation&gt; = \frac{1}{4} (\sqrt{\frac{\lambda_k}{\lambda_l}} + \sqrt{\frac{\lambda_l}{\lambda_k}})^2 (z_k^2 + z_l^2)^2 - \frac{1}{4} (\sqrt{\frac{\lambda_k}{\lambda_l}} - \sqrt{\frac{\lambda_l}{\lambda_k}})^2 (z_k^2 - z_l^2)^2&lt;/equation&gt;&lt;p&gt;因为这时右边第2项是小于0的，加上前面given的条件，所以可以得到：&lt;/p&gt;&lt;equation&gt;\leq \frac{1}{4} (\sqrt{\frac{\lambda_k}{\lambda_l}} + \sqrt{\frac{\lambda_l}{\lambda_k}})^2&lt;/equation&gt;&lt;p&gt;我们选择差距最大的两个特征值作为上界，于是又有&lt;/p&gt;&lt;equation&gt;\leq \frac{1}{4} (\sqrt{\frac{\lambda_1}{\lambda_n}} + \sqrt{\frac{\lambda_n}{\lambda_1}})^2&lt;/equation&gt;&lt;p&gt;总之一个是最大的特征值，一个是最小的就好。于是乎又可以得到：&lt;/p&gt;&lt;equation&gt;=\frac{(\lambda_1+\lambda_n)^2}{4\lambda_1\lambda_n}&lt;/equation&gt;&lt;p&gt;我们最终想要的结果马上就要出现了！&lt;/p&gt;&lt;p&gt;于是乎我们得到的完整内容是：&lt;/p&gt;&lt;equation&gt;\frac{(g_t^Tg_t)^2}{(g_t^TAg_t)(g_t^TA^{-1}g_t)}\geq \frac{4\lambda_1\lambda_n}{(\lambda_1+\lambda_n)^2}&lt;/equation&gt;&lt;h2&gt;最终章&lt;/h2&gt;&lt;equation&gt;f(X_{k+1}) \leq (1 - \frac{4 \lambda_1 \lambda_n }{(\lambda_1 + \lambda_n)^2}) f(X_k)&lt;/equation&gt;&lt;equation&gt;= (\frac{(\lambda_1 + \lambda_n)^2}{(\lambda_1 + \lambda_n)^2} - \frac{4 \lambda_1 \lambda_n }{(\lambda_1 + \lambda_n)^2}) f(X_k)&lt;/equation&gt;&lt;equation&gt;= (\frac{\lambda_1^2 - 2 \lambda_1 \lambda_n + \lambda_n^2 }{(\lambda_1 + \lambda_n)^2}) f(X_k)&lt;/equation&gt;&lt;equation&gt;=(\frac{\lambda_1 - \lambda_n}{\lambda_1 + \lambda_n})^2 f(X_k)&lt;/equation&gt;&lt;p&gt;好了，到这里我们的推导结束了，该休息了……&lt;/p&gt;&lt;h2&gt;私货时间&lt;/h2&gt;&lt;p&gt;欢迎加入我爱机器学习8群：19517895！&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/23799012&amp;pixel&amp;useReferer"/&gt;</description><author>冯超</author><pubDate>Tue, 13 Dec 2016 23:44:21 GMT</pubDate></item><item><title>番外篇(1)——最速下降法</title><link>https://zhuanlan.zhihu.com/p/23776390</link><description>番外篇正式开始，我们主要利用番外篇的时间聊一些机器学习中的黑盒部分——没错，就是优化算法。之前接受过前辈的教诲，一个机器学习的套路可以分解成三个部分——模型，目标和优化方法。模型用来定义待解决的问题，目标（一般也会被称作损失函数）用来明确评价模型质量的方法，而优化算法则是具体解决求解过程的问题。有了这三个部分，我们可以说在学术的角度上我们基本上就搞定了一个机器学习问题。之所以在前面加上了学术这两个字，是因为在工业界一个机器学习的问题就不止这三部了。&lt;p&gt;好了回到正题，我们回到前面的三个部分，一般来说第一部分是最灵活的，第二部分也算灵活，但还是有一定的约束的，然而第三部分——一般来说都是非常确定的，而且一般也是以一个黑盒的状态出现的。&lt;/p&gt;&lt;p&gt;于是乎大家一般对第一部分和第二部分更为关注，而对第三部分相对忽视一些。于是乎我们这里就反其道而行，作死地选择和大家聊聊第三部分——优化。实际上在前面的正文中我们已经花了很大的篇幅去聊一些优化算法，下面我们继续聊一些经典的算法。&lt;/p&gt;&lt;h2&gt;最速下降法&lt;/h2&gt;&lt;p&gt;友情提示，下面我们要聊的内容主要用于凸函数。关于凸函数的性质这里就不多说了，大家不懂的去查查资料就好。前面我们提到了梯度下降法，也提到了梯度下降法中那个让人头疼的learning rate，那么我们有没有其他的办法不去计算这个learning rate，又能让剃度下降的每一步尽可能地走好呢？&lt;/p&gt;&lt;p&gt;于是有大神们发明了下面这个方法——最速下降法。所谓的最速下降法，就是在确定下降方向后，从下降方向中找到下降程度最大的一点进行下降。我们可以用形式化的方式来明确表述下：&lt;/p&gt;&lt;p&gt;如果说我们前面的梯度下降法是先求出梯度，再根据预先设定的learning rate完成下降，那么就完成了一轮的优化；&lt;/p&gt;&lt;p&gt;而最速下降法在求出梯度之后，要进行另外一个小优化问题的求解过程，那就是选择最合适的learning rate，使得函数值最小，如果待求的函数为f(x)，当前的迭代轮数为t，那么当前函数的优化的参数解是&lt;equation&gt;x_t&lt;/equation&gt;，这一点的梯度为&lt;equation&gt;-g_t&lt;/equation&gt;，于是我们小优化问题就变成了：&lt;/p&gt;&lt;equation&gt;\alpha_t=argmin_{\alpha_t}f(x_t-\alpha_t*g)&lt;/equation&gt;&lt;equation&gt;x_{t+1}=x_t-\alpha_t*g&lt;/equation&gt;&lt;p&gt;好了，下面就该求解这个问题了。实际上我们同样可以采用求梯度并令梯度值为0的方式求出，但是那种方法并不是很容易推导出一个通用的公式，所以我们可以采用另外的方法求出一个公式来。&lt;/p&gt;&lt;h2&gt;梯度正交&lt;/h2&gt;&lt;p&gt;最速下降法的优化方向有一个特点，那就是相邻两轮迭代的梯度相互正交。这个特点对于推导最终的算法十分重要，我们首先来证明一下。&lt;/p&gt;&lt;p&gt;证明这个问题的最好方法是反证法。我们假设迭代轮数分别为t和t+1的梯度分别为&lt;equation&gt;g_t&lt;/equation&gt;和&lt;equation&gt;g_{t+1}&lt;/equation&gt;，如果两个梯度不正交，那么我们就可以把&lt;equation&gt;g_{t+1}&lt;/equation&gt;分解成两个部分——&lt;/p&gt;&lt;ol&gt;&lt;li&gt;与&lt;equation&gt;g_t&lt;/equation&gt;共线的部分&lt;equation&gt;g_{t+1}^t&lt;/equation&gt;&lt;/li&gt;&lt;li&gt;与&lt;equation&gt;g_t&lt;/equation&gt;正交的部分&lt;equation&gt;g_{t+1}'&lt;/equation&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;那么问题来了——对于被第t轮更新后&lt;equation&gt;x_{t+1}&lt;/equation&gt;来说，在&lt;equation&gt;g_t&lt;/equation&gt;这个方向上应该是最小的了，换句话说在这个点上，关于&lt;equation&gt;g_t&lt;/equation&gt;的方向梯度应该为0，那么&lt;equation&gt;g_{t+1}&lt;/equation&gt;就不应该有&lt;equation&gt;g_t&lt;/equation&gt;方向的分量。如果有就说明上一轮迭代并没有做到最优，和我们的假设矛盾，所以假设不成立，我们最终可以认定，&lt;equation&gt;g_t&lt;/equation&gt;和&lt;equation&gt;g_{t+1}&lt;/equation&gt;是正交的。&lt;/p&gt;&lt;p&gt;知道了正交的特点，我们就可以用这个性质来进行计算了。我们的经典问题是一个二阶优化问题：&lt;/p&gt;&lt;equation&gt;f(X)=\frac{1}{2}X^TAX&lt;/equation&gt;&lt;p&gt;首先为了保证这个问题是凸函数，我们需要对上面的一些内容做约束，具体来说就是A是对称正定的，这样，我们就能保证函数的凸性质了。&lt;/p&gt;&lt;p&gt;于是乎，我们可以得到第一个公式：&lt;/p&gt;&lt;p&gt;g=AX&lt;/p&gt;&lt;p&gt;然后是第二个公式，也就是我们刚才推倒了半天得到的结论：&lt;/p&gt;&lt;equation&gt;g_t^Tg_{t+1}=0&lt;/equation&gt;&lt;p&gt;最后是第三个公式，也是大家喜闻乐见的参数更新公式：&lt;/p&gt;&lt;equation&gt;x_{t+1}=x_t-\alpha_tg_t&lt;/equation&gt;&lt;p&gt;好了，有这三个公式就足够了，我们开始推导：&lt;/p&gt;&lt;equation&gt;g_t^Tg_{t+1}=0&lt;/equation&gt;&lt;equation&gt;g_t^T(AX_{t+1})=0&lt;/equation&gt;&lt;equation&gt;g_t^T(A(X_t-\alpha_t g_t))=0&lt;/equation&gt;&lt;equation&gt;g_t^T(AX_t-A\alpha_t g_t)=0&lt;/equation&gt;&lt;equation&gt;g_t^T(g_t-A\alpha_t g_t)=0&lt;/equation&gt;&lt;equation&gt;\alpha_t=\frac{g_t^Tg_t}{g_t^TAg_t}&lt;/equation&gt;&lt;p&gt;好了，到此我们就把步长的公式求解出来了，下回我们来看看一些细节问题。&lt;/p&gt;&lt;h2&gt;私货时间&lt;/h2&gt;&lt;p&gt;欢迎加入我爱机器学习7群：467165306！&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/23776390&amp;pixel&amp;useReferer"/&gt;</description><author>冯超</author><pubDate>Thu, 08 Dec 2016 22:34:55 GMT</pubDate></item><item><title>CNN Dropout的极端实验</title><link>https://zhuanlan.zhihu.com/p/22060265</link><description>&lt;p&gt;本系列更多文章欢迎点击：&lt;a href="https://zhuanlan.zhihu.com/p/22464594" class=""&gt;无痛的机器学习第一季目录&lt;/a&gt;，现已完整收录。&lt;/p&gt;有关CNN的故事还有很多，前面我们花了一定的篇幅，讲了有关初始化算法的事情，接下来我们将换一个方向，去看看众位大神在网络结构方面做出的杰出贡献。接下来我们就来看看这一路大神们的杰作之一——Dropout Layer。&lt;p&gt;在训练过程中，Dropout Layer会丢弃一定数量的信息，只让部分数据发挥作用。而且，由于采用随机丢弃的方式，每一次进行前向后向计算时，丢弃掉的数据都会有所不同。这样，模型每一次的前向后向计算的表现都会不同。&lt;/p&gt;&lt;p&gt;而在预测过程中，Dropout Layer将打开所有的参数，让所有的参数发挥作用。这样就相当于把所有的参数的作用同时发挥出来，让模型有点ensemble的效果。&lt;/p&gt;&lt;p&gt;关于Dropout能产生的效果，我们这回来做一个比较激进的实验。&lt;/p&gt;&lt;h2&gt;半字识别&lt;/h2&gt;&lt;p&gt;这次做的实验的主角还是我们熟悉的MNIST，当然，为了让这个实验变得足够刺激，我们要给这个实验加点料。那么要加什么料呢？&lt;/p&gt;&lt;p&gt;我们保持60000张训练数据不变，而将10000张测试数据的上半部分重置成0。那么看上去每一个数据都少了一半，就像这样：&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/b54062bae454485dedc8d7b3208cba0c.png" data-rawwidth="203" data-rawheight="475"&gt;这样：&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/c68b0914c5fefab46ca1ed6f59d0d55f.png" data-rawwidth="203" data-rawheight="478"&gt;和这样：&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/31c2864694d5b5df322a41c6f90550d4.png" data-rawwidth="203" data-rawheight="474"&gt;好了，下面以我们人类的眼光，当我们看完了那些正常的数字后，再来看这些数字，是不是有种蛋疼的感觉？神经病啊……&lt;/p&gt;&lt;p&gt;（P.S. 没奖竞猜上面三个数字是啥，快来猜啊～）&lt;/p&gt;&lt;p&gt;（P.P.S 其实我选择得这几个图好算正常了，兄弟～）&lt;/p&gt;&lt;p&gt;好了，这种人类都觉得蛋疼的问题，交给计算机恐怕也是凶多极少了。这个问题实际上也算是分类问题中遇到的一个十分经典的问题——occlusion。如果我们遮挡了一个东西的一部分，你还能认出它来么？对于人来说，只要不是遮挡住最关键的信息，人类是可以通过局部的信息识别出一个整体的物体的。能做到这一点，说明人类具有利用部分信息进行分析推断的能力。如果希望计算机拥有人的智能，那么它最好也可以拥有这样的能力。&lt;/p&gt;&lt;p&gt;我们先来看看我们之前一直使用的以ReLU做非线性函数的模型的表现（这回我们不黑ReLU了）：&lt;/p&gt;&lt;p&gt;acc = 0.4358&lt;/p&gt;&lt;p&gt;识别率不到一半，不过也算它尽力了。实际上在训练的过程中，某些轮次的测试集精度比这个数还要高一些，但是有时候会出现越训练效果越差的情况。这里面的根本原因是训练集和测试集实际上并不是同样的数据分布和信息容量。&lt;/p&gt;&lt;p&gt;因为我们在训练的时候使用了全部的数据信息，那么在识别的时候每个位置都会被当作识别的特征加以训练；而到了测试部分，我们只有一半的数据，也就是说我们曾经发现的很有把握的特征突然消失了，对于模型这样的耿直boy必然是一脸蒙逼。&lt;/p&gt;&lt;p&gt;这就好比我们在做数学题时，一个公式所需要的关键参数丢失了，我们还怎么把公式求出来？巧妇难为无米之炊啊……&lt;/p&gt;&lt;p&gt;这时候聪明的同学一定想到了，有舍才有得！既然你测试数据只有一半，那我把训练数据也变成只有一半，大家的信息一致，模型用起来一定会舒服不少！于是我们得到了下面的结果：&lt;/p&gt;&lt;p&gt;acc = 0.9044&lt;/p&gt;&lt;p&gt;果然比之前的结果高了不少，模型同学你真的是太耿直了，以后都不敢给你出超纲题了……&lt;/p&gt;&lt;p&gt;这里面倒是也可以说明另一个问题，如果训练过程的数据特性和测试过程的数据特性不同，模型的结果可能会有很大的问题。如果能发现问题并想出自断一半数据的方案固然是好，但是如果没有条件发现这样的情况呢？&lt;/p&gt;&lt;p&gt;这时候，我们不妨用dropout的思想来解决，由于每次训练时我只利用一部分信息，那么我天然就具备了只使用部分信息进行推断预测的能力，这样就更容易和测试数据的形式贴近了。&lt;/p&gt;&lt;p&gt;下面我们就在ip1层的后面加上Dropout Layer，并测试dropout_ratio从0到0.9的效果，最终的结果如下图所示：&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/73c8e9473e3c482c5796493bcafc3ace.png" data-rawwidth="712" data-rawheight="315"&gt;图中的l0表示dropout_ratio为0.0的accuracy，l9表示dropout_ratio为0.9的accuracy。从图中的结果来看，守着所有特征不放的模型精度最差，而dropout最厉害的模型表现最好。这么看来，“割一路更好打”这个战术似乎还是有点道理啊！&lt;/p&gt;&lt;p&gt;不过在这个例子中dropout_ratio=0.9的表现最好也是比较特殊的，因为MNIST的输出类别相对较少，即使dropout_ratio达到0.9也依然能够保证剩下的信息是足以识别这十个数字的，对于一些类别较多，问题较复杂的情况，丢掉这么多信息恐怕会因为必要信息不足导致识别精度下降。&lt;/p&gt;&lt;p&gt;介绍Dropout的论文中提到，Dropout有两种好处：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;一定程度上减轻过拟合的情况&lt;/li&gt;&lt;li&gt;使得模型具有多模型融合的效果&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;从上面的实验中，相信我们可以体会到其中一二。&lt;/p&gt;&lt;p&gt;但是——&lt;/p&gt;&lt;p&gt;让训练集合和测试集合的数据保持一致性——这件事情比加不加dropout层要重要得多。&lt;/p&gt;&lt;p&gt;所以，dropout到底该怎么加呢？&lt;/p&gt;&lt;h2&gt;私货时间&lt;/h2&gt;&lt;p&gt;欢迎加入我爱机器学习7群：467165306！&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/22060265&amp;pixel&amp;useReferer"/&gt;</description><author>冯超</author><pubDate>Sat, 03 Dec 2016 23:49:38 GMT</pubDate></item><item><title>FCN(6)——从CRF到RNN</title><link>https://zhuanlan.zhihu.com/p/22795755</link><description>前面我们花了大量的篇章介绍了CRF和DenseCRF的内容，下面我们把FCN和CRF串起来。&lt;h2&gt;CRFasRNN&lt;/h2&gt;&lt;p&gt;前面我们在denseCRF中留了一个小尾巴，那就是unary function。为了让FCN结合起来，这里我们做两个设定：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;FCN的结合作为unary function的结果&lt;/li&gt;&lt;li&gt;FCN的结果作为pairwise function中的Q函数的初始值。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;这样FCN和CRF就连起来了。下面我们还要解决一个问题，就是为什么是CRFasRNN？&lt;/p&gt;&lt;p&gt;在这篇模型结合的论文中，作者将CRF的求解过程转换成了RNN的形式。由于CRF的求解算法是迭代进行的，因此把算法展开，我们可以将其变成RNN的形式，这里的细节在此就不多说了，大家看看论文基本就能看懂。&lt;/p&gt;&lt;h2&gt;实现&lt;/h2&gt;&lt;p&gt;下面就来看看他的具体实现：&lt;a href="https://github.com/torrvision/crfasrnn" data-editable="true" data-title="GitHub - torrvision/crfasrnn: This repository contains the source code for the semantic image segmentation method described in the ICCV 2015 paper: Conditional Random Fields as Recurrent Neural Networks. http://crfasrnn.torr.vision/" class=""&gt;GitHub - torrvision/crfasrnn: This repository contains the source code for the semantic image segmentation method described in the ICCV 2015 paper: Conditional Random Fields as Recurrent Neural Networks. http://crfasrnn.torr.vision/&lt;/a&gt;&lt;/p&gt;&lt;p&gt;我们先来看看它的prototxt，我们可以用下面这张图表示：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-6aca12386083603e198cff5c9e6f3f05.jpg" data-rawwidth="960" data-rawheight="1280"&gt;&lt;p&gt;可以看出网络的主体部分是由之前的FCN组成。在前面的FCN中我们没有介绍其实现，这里我们就详细看下它的实现。我们从图的左上角出发，到图的左下角，然后再返回到右上角。前面全部是卷积、relu和maxpooling这几部分，后面是不同scale的结果融合。这里详细地展示了这一部分的维度内容。&lt;/p&gt;&lt;p&gt;从实现中，我们可以看出一些值得深思的细节。&lt;/p&gt;&lt;p&gt;首先是一开始的padding=100。为了不让最终的feature map太小，添加一个较大的padding是十分必要的。&lt;/p&gt;&lt;p&gt;其次就是最后一层的MULTI_STAGE_MEANFIELD，这一层我们需要特别介绍一下，虽然在文章中作者提到了CRF as RNN的概念，但是实际上它的实现并没有用RNN的框架，当然Caffe里面并没有这里可用的RNN。这里是将所有的CRF的内容集成到了一个层中，所以这一层会比较复杂，计算量也比较大，其中的反向传播也比较复杂。&lt;/p&gt;&lt;p&gt;首先我们将算法的流程图展示出来：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-0891a04ad4133d9440e5bd97ae8d98fe.jpg" data-rawwidth="960" data-rawheight="1280"&gt;&lt;p&gt;可以看出，这其中的计算主要涉及到两个类别—— MultiStageMeanfieldLayer和MeanfieldIteration，其中的MultiStageMeanfieldLayer类主要负责算法内容的组织，而其中的MeanfieldIteration类主要负责迭代计算过程。这些内容我们都可以从上面的图中读出。&lt;/p&gt;&lt;p&gt;可以看出这其中的细节除了计算高斯滤波部分的Permutohedral比较复杂，属于超纲内容，其他的部分相对比较好理解。关于Permutohedral部分的细节，有机会我们可以开一个CV系列的文章另行讲解。&lt;/p&gt;&lt;p&gt;MeanfieldIteration的反向操作实际上并不复杂，只要记得把这些过程拆解成一个个小部分慢慢算梯度就好，而MultiStageMeanfieldLayer的反向操作也只是把MeanfieldIteration的反向结果合并起来，具体细节可以去看看源码，这里我们就不再赘述了。&lt;/p&gt;&lt;p&gt;到这里，我们已经实现了将CNN和CRF无缝连接起来了。比起之前的单独由CNN组成的FCN，我们已经有了很大的进步。&lt;/p&gt;&lt;p&gt;到这里，实际上我们花了很大的力气在介绍CRF和无向概率图模型的内容，但是我们终于把这部分的内容讲完了。让我休息一下……&lt;/p&gt;&lt;h2&gt;私货时间&lt;/h2&gt;&lt;p&gt;欢迎加入我爱机器学习7群：467165306！&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/22795755&amp;pixel&amp;useReferer"/&gt;</description><author>冯超</author><pubDate>Tue, 29 Nov 2016 21:10:02 GMT</pubDate></item><item><title>FCN(5)——DenseCRF推导</title><link>https://zhuanlan.zhihu.com/p/22464569</link><description>&lt;p&gt;经过前两篇文章，我们了解了CRF的基本概念，了解了许许多多的CRF模型，也了解了Mean field variational inference的基本概念，那么这一回我们开始真刀真枪地进行公式推导。其实公式推导的部分在论文的补充材料里有，但是不够详尽，这里我们尽可能地补充一下，让推导过程更加完整。&lt;/p&gt;&lt;h2&gt;DenseCRF&lt;/h2&gt;&lt;p&gt;前面我们已经看过了DenseCRF的能量函数，如下所示&lt;/p&gt;&lt;equation&gt;E(x)=\sum_i \psi _u(x_i)+\sum_{i&amp;lt;j}\psi_p(x_i,x_j)&lt;/equation&gt;&lt;p&gt;其他内容在这就不说了，我们抓紧时间推导。&lt;/p&gt;&lt;h2&gt;Variational Inference推导&lt;/h2&gt;&lt;p&gt;我们首先给出denseCRF的Gibbs分布：&lt;/p&gt;&lt;equation&gt;P(X)=\frac{1}{Z}\tilde{P}(X)=\frac{1}{Z}exp(\sum_i \psi_u(x_i) + \sum_{i &amp;lt; j}\psi_p(x_i,x_j))&lt;/equation&gt;&lt;p&gt;下面给出KL散度部分的推导，其实就是补充材料中的推导，搬运工来了……&lt;equation&gt;D(Q||P)=\sum_x{Q(x)log(\frac{Q(x)}{P(x)})}&lt;/equation&gt;&lt;equation&gt;=-\sum_xQ(x)logP(x)+\sum_xQ(x)logQ(x)
&lt;/equation&gt;&lt;equation&gt;=-E_{X\in Q}[logP(X)]+E_{X\in Q}[logQ(X)]
&lt;/equation&gt;&lt;equation&gt;=-E_{X\in Q}[log\tilde{P}(X) ]+E_{X \in Q}[logZ]+\sum_iE_{X_i \in Q}[logQ_i(X_i)]&lt;/equation&gt;&lt;/p&gt;&lt;equation&gt;=-E_{X \in Q}[log \tilde{P}(X)]+logZ+\sum_iE_{X_i \in Q_i}[logQ_i(X_i)]&lt;/equation&gt;&lt;p&gt;由于我们要求的是Q，而logZ项中没有Q，所以这一项可以省略。&lt;/p&gt;&lt;p&gt;同时Q还需要满足：&lt;/p&gt;&lt;equation&gt;\sum_{x_i}Q_i(x_i)=1&lt;/equation&gt;&lt;p&gt;所以利用拉格朗日乘子法，可以得到&lt;equation&gt;L(Q_i)=-E_{X_i \in Q}[log \tilde{P}(X)]+\sum_iE_{x_i \in Q_i}[logQ_i(x_i)]+\lambda(\sum_{x_i}Q_i(x_i)-1)&lt;/equation&gt;&lt;/p&gt;&lt;p&gt;这个公式的后面两项相对比较简单，但是前面一项比较复杂，我们单独做一下处理：&lt;/p&gt;&lt;equation&gt;-E_{X_i \in Q}[log \tilde{P}(X)]=-\int{\prod_i{Q_i(x_i)}[log \tilde{P}(X)]dX}&lt;/equation&gt;&lt;equation&gt;=-\int{Q_i(x_i) \prod_{i}{Q(\bar{x}_{i})}[log \tilde{P}(X)]dx_id\bar{X}}&lt;/equation&gt;&lt;equation&gt;=-\int{Q_i(x_i)E_{\bar{X} \in Q}[log \tilde{P}(X)]dx_i}&lt;/equation&gt;&lt;p&gt;经过上面的公式整理，我们可以求出偏导，可得&lt;/p&gt;&lt;equation&gt;\frac{\partial L(Q_i)}{\partial Q_i(x_i)}=-E_{\bar{X} \in Q_i}[log \tilde{P}(X | x_i)]-logQ_i(x_i)-1+\lambda&lt;/equation&gt;&lt;p&gt;令偏导为0，就可以求出极值：&lt;/p&gt;&lt;equation&gt;Q_i(x_i)=exp(\lambda-1)exp(-E_{\bar{X} \in Q_i}[log \tilde{P}(X | x_i)])&lt;/equation&gt;&lt;p&gt;由于每一个Q的&lt;equation&gt;exp(\lambda-1)&lt;/equation&gt;都相同，我们将其当作一个常数项，之后在renormalize的时候将其抵消掉，于是Q函数就等于：&lt;/p&gt;&lt;equation&gt;Q(x_i)=\frac{1}{Z_1}exp(-E_{\bar{X} \in Q_i}[log \tilde{P}(X | x_i)])&lt;/equation&gt;&lt;p&gt;我们将文章开头关于&lt;equation&gt;\tilde{P}&lt;/equation&gt;的定义带入，就得到了&lt;/p&gt;&lt;equation&gt;Q(x_i)=\frac{1}{Z_1}exp(-E_{\bar{X} \in Q}[(\sum_i \psi_u(x_i) + \sum_{j \neq i}\psi_p(x_i,x_j)) | x_i])&lt;/equation&gt;&lt;p&gt;这里面xi的由于是已知的，所以我们可以得到补充材料里的结果（但是变量名不太一样）：&lt;/p&gt;&lt;equation&gt;Q_i(x_i=l)=\frac{1}{Z_i}exp[-\psi_u(l) - \sum_{j \neq i}E_{\bar{X} \in Q_j}\psi_p(l,X_j)]&lt;/equation&gt;&lt;p&gt;继续扩展，就可以得到&lt;/p&gt;&lt;equation&gt;=\frac{1}{Z_i}exp[-\psi_u(l) - \sum_{m=1}^Kw^{(m)}\sum_{j \neq i}E_{X \in Q_j}[\mu(l,X_j)k^{(m)}(f_i,f_j)]]&lt;/equation&gt;&lt;equation&gt;=\frac{1}{Z_i}exp[-\psi_u(l) - \sum_{m=1}^Kw^{(m)}\sum_{j \neq i}\sum_{l' \in L}Q_j(l')\mu(l,l')k^{(m)}(f_i,f_j)]&lt;/equation&gt;&lt;equation&gt;=\frac{1}{Z_i}exp[-\psi_u(l) - \sum_{l' \in L}\mu(l,l')\sum_{m=1}^Kw^{(m)}\sum_{j \neq i}Q_j(l')k^{(m)}(f_i,f_j)]&lt;/equation&gt;&lt;p&gt;这样，一个类似message passing的公式推导就完成了。其中最内层的求和可以用截断的高斯滤波完成。搬运最后的一点公式，可以得：&lt;/p&gt;&lt;equation&gt;\tilde{Q_i^{(m)}(l)}=\sum_{j \neq i}Q_j(l')k^{(m)}(f_i,f_j)=\sum_{j}Q_j(l)k^{(m)}(f_i,f_j)-Q_i(l)&lt;/equation&gt;&lt;p&gt;上面公式的第一项可以转化成卷积操作。&lt;/p&gt;&lt;p&gt;完成了这些推导，下面我们暂时不给出denseCRF的单独结果，我们下面看看FCN和DenseCRF结合的效果，FCN已经等的花都谢了……&lt;/p&gt;&lt;h2&gt;私货时间&lt;/h2&gt;&lt;p&gt;欢迎加入我爱机器学习7群：467165306！&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/22464569&amp;pixel&amp;useReferer"/&gt;</description><author>冯超</author><pubDate>Tue, 22 Nov 2016 21:58:11 GMT</pubDate></item><item><title>无痛的机器学习第一季目录</title><link>https://zhuanlan.zhihu.com/p/22464594</link><description>经过5个月的努力，我终于完成了40篇不高不低还算有些干货的机器学习文章。回首看看这5个月的努力，每一次的写作都充满了开心与痛苦。说开心是因为当自己完成每一个章节的写作后，自己感觉对这一部分的知识有了更加深刻地认识，而痛苦则是对写作过程中一系列事情的恐惧——找不到好选题，对论文细节的困惑，跑不出想要的结果，难以用通俗易懂的语言描述自己所知……好在这一切就要告一段落了。&lt;p&gt;以下就做一个集合贴，展示一下这一季的所有文章，对本专栏文章感兴趣的童鞋，收藏这一篇就足够了（后续未发布的几篇和番外篇会更新上来）：&lt;/p&gt;&lt;h2&gt;文章目录&lt;/h2&gt;&lt;h2&gt;CNN网络基础结构&lt;/h2&gt;&lt;p&gt;&lt;a href="http://zhuanlan.zhihu.com/p/21525237" data-editable="true" data-title="神经网络-全连接层（1） - 无痛的机器学习 - 知乎专栏" class=""&gt;神经网络-全连接层（1）&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://zhuanlan.zhihu.com/p/21535703" data-editable="true" data-title="神经网络-全连接层（2） - 无痛的机器学习 - 知乎专栏" class=""&gt;神经网络-全连接层（2）&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://zhuanlan.zhihu.com/p/21572419" data-editable="true" data-title="神经网络-全连接层（3） - 无痛的机器学习 - 知乎专栏" class=""&gt;神经网络-全连接层（3）&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://zhuanlan.zhihu.com/p/21609512" data-editable="true" data-title="卷积层（1） - 无痛的机器学习 - 知乎专栏" class=""&gt;卷积层（1） &lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://zhuanlan.zhihu.com/p/21675422" data-editable="true" data-title="卷积层（2） - 无痛的机器学习 - 知乎专栏" class=""&gt;卷积层（2） &lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://zhuanlan.zhihu.com/p/21737674" data-editable="true" data-title="卷积层（3） - 无痛的机器学习 - 知乎专栏" class=""&gt;卷积层（3）&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;CNN网络上层结构&lt;/h2&gt;&lt;p&gt;&lt;a href="http://zhuanlan.zhihu.com/p/22197188" data-editable="true" data-title="CNN——架构上的一些数字 - 无痛的机器学习 - 知乎专栏" class=""&gt;CNN——架构上的一些数字&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://zhuanlan.zhihu.com/p/22214112" data-editable="true" data-title="CNN--结构上的思考 - 无痛的机器学习 - 知乎专栏" class=""&gt;CNN--结构上的思考 &lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/22060265" class="" data-editable="true" data-title="CNN Dropout的极端实验"&gt;CNN Dropout的极端实验&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;Caffe源码分析&lt;/h2&gt;&lt;p&gt;&lt;a href="http://zhuanlan.zhihu.com/p/21796890" data-editable="true" data-title="Caffe代码阅读——层次结构 " class=""&gt;Caffe代码阅读——层次结构 &lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://zhuanlan.zhihu.com/p/21875025" data-editable="true" data-title="Caffe源码阅读——Net组装 - 无痛的机器学习 - 知乎专栏" class=""&gt;Caffe源码阅读——Net组装 &lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://zhuanlan.zhihu.com/p/21800004" data-editable="true" data-title="Caffe代码阅读——Solver - 无痛的机器学习 - 知乎专栏" class=""&gt;Caffe代码阅读——Solver &lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://zhuanlan.zhihu.com/p/22260935" data-editable="true" data-title="CNN--两个Loss层计算的数值问题 " class=""&gt;CNN--两个Loss层计算的数值问题 &lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/22404295" data-editable="true" data-title="Caffe源码阅读——DataLayer " class=""&gt;Caffe源码阅读——DataLayer&amp;amp;Data Transformer&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;生成网络&lt;/h2&gt;&lt;p&gt;&lt;a href="http://zhuanlan.zhihu.com/p/22386494" class="" data-editable="true" data-title="DCGAN的小尝试（1）"&gt;DCGAN的小尝试（1）&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://zhuanlan.zhihu.com/p/22389906" class="" data-title="DCGAN的小尝试（2）" data-editable="true"&gt;DCGAN的小尝试（2）&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://zhuanlan.zhihu.com/p/22464760" class="" data-editable="true" data-title="VAE（1）——从KL说起"&gt;VAE（1）——从KL说起&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://zhuanlan.zhihu.com/p/22464764" class="" data-editable="true" data-title="VAE(2)——基本思想"&gt;VAE(2)——基本思想&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://zhuanlan.zhihu.com/p/22464768" class="" data-editable="true" data-title="VAE(3)——公式与实现"&gt;VAE(3)——公式与实现&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://zhuanlan.zhihu.com/p/22684931" class="" data-editable="true" data-title="VAE（4）——实现"&gt;VAE（4）——实现&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;优化算法&lt;/h2&gt;&lt;p&gt;&lt;a href="http://zhuanlan.zhihu.com/p/21486804" data-editable="true" data-title="梯度下降是门手艺活…… - 无痛的机器学习 - 知乎专栏" class=""&gt;梯度下降是门手艺活…… &lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://zhuanlan.zhihu.com/p/21486826" data-editable="true" data-title="路遥知马力——Momentum - 无痛的机器学习 - 知乎专栏" class=""&gt;路遥知马力——Momentum &lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://zhuanlan.zhihu.com/p/22099871" data-editable="true" data-title="CNN——L1正则的稀疏性 " class=""&gt;CNN——L1正则的稀疏性 &lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://zhuanlan.zhihu.com/p/22464537" class="" data-editable="true" data-title="Caffe中的SGD的变种优化算法(1)"&gt;Caffe中的SGD的变种优化算法(1)&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://zhuanlan.zhihu.com/p/22464551" class="" data-editable="true" data-title="Caffe中的SGD的变种优化算法(2)"&gt;Caffe中的SGD的变种优化算法(2)&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;CNN可视化&lt;/h2&gt;&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/22245268" data-editable="true" data-title="CNN-反卷积（1） - 无痛的机器学习 - 知乎专栏" class=""&gt;CNN-反卷积（1）&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/22293817" data-editable="true" data-title="CNN-卷积反卷积（2） - 无痛的机器学习 - 知乎专栏" class=""&gt;CNN-卷积反卷积（2）&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://zhuanlan.zhihu.com/p/22464575" class="" data-editable="true" data-title="寻找CNN的弱点"&gt;寻找CNN的弱点&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;CNN数值&lt;/h2&gt;&lt;p&gt;&lt;a href="http://zhuanlan.zhihu.com/p/22027076" data-editable="true" data-title="CNN的数值实验 - 无痛的机器学习 - 知乎专栏" class=""&gt;CNN的数值实验 - 无痛的机器学习 - 知乎专栏&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://zhuanlan.zhihu.com/p/22028079" data-editable="true" data-title="CNN数值——xavier（上） - 无痛的机器学习 - 知乎专栏" class=""&gt;CNN数值——xavier（上） - 无痛的机器学习 - 知乎专栏&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://zhuanlan.zhihu.com/p/22044472" data-editable="true" data-title="CNN数值——xavier（下） - 无痛的机器学习 - 知乎专栏" class=""&gt;CNN数值——xavier（下） - 无痛的机器学习 - 知乎专栏&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://zhuanlan.zhihu.com/p/22148777" data-editable="true" data-title="CNN数值——ZCA - 无痛的机器学习 - 知乎专栏" class=""&gt;CNN数值——ZCA - 无痛的机器学习 - 知乎专栏&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;FCN&lt;/h2&gt;&lt;p&gt;&lt;a href="http://zhuanlan.zhihu.com/p/22464571" class="" data-editable="true" data-title="FCN(1)——从分类问题出发"&gt;FCN(1)——从分类问题出发&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://zhuanlan.zhihu.com/p/22464581" class="" data-title="FCN(2)——CRF通俗非严谨的入门" data-editable="true"&gt;FCN(2)——CRF通俗非严谨的入门&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://zhuanlan.zhihu.com/p/22464586" class="" data-editable="true" data-title="FCN(3)——DenseCRF"&gt;FCN(3)——DenseCRF&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://zhuanlan.zhihu.com/p/22887466" class="" data-title="FCN(4)——Mean Field Variational Inference" data-editable="true"&gt;FCN(4)——Mean Field Variational Inference&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/22464569" class="" data-editable="true" data-title="FCN(5)——DenseCRF推导"&gt;FCN(5)——DenseCRF推导&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/22795755" class="" data-editable="true" data-title="FCN(6)——从CRF到RNN"&gt;FCN(6)——从CRF到RNN&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;Representation&lt;/h2&gt;&lt;p&gt;&lt;a href="http://zhuanlan.zhihu.com/p/23444100" class="" data-editable="true" data-title="CenterLoss——实战&amp;amp;源码"&gt;CenterLoss——实战&amp;amp;源码&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;GPU&lt;/h2&gt;&lt;p&gt;&lt;a href="http://zhuanlan.zhihu.com/p/21908564" data-editable="true" data-title="[翻译]Exploring the Complexities of PCIe Connectivity and Peer-to-Peer Communication - 无痛的机器学习 - 知乎专栏" class=""&gt;[翻译]Exploring the Complexities of PCIe Connectivity and Peer-to-Peer Communication - 无痛的机器学习 - 知乎专栏&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;“聊点轻松的”系列&lt;/h2&gt;&lt;p&gt;&lt;a href="http://zhuanlan.zhihu.com/p/21788777" class="" data-editable="true" data-title="聊点轻松的——划个水"&gt;聊点轻松的——划个水&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class="" href="http://zhuanlan.zhihu.com/p/22112582" data-editable="true" data-title="聊点轻松的2——斗图篇"&gt;聊点轻松的2——斗图篇&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class="" href="http://zhuanlan.zhihu.com/p/22421787" data-editable="true" data-title="聊点轻松的3——什么是学习"&gt;聊点轻松的3——什么是学习&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class="" href="http://zhuanlan.zhihu.com/p/22842859" data-editable="true" data-title="聊点轻松的4——这回真的很轻松"&gt;聊点轻松的4——这回真的很轻松&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://zhuanlan.zhihu.com/p/23750864" class="" data-editable="true" data-title="聊点轻松的5——这篇写得并不轻松"&gt;聊点轻松的5——这篇写得并不轻松&lt;/a&gt;&lt;/p&gt;&lt;p&gt;番外篇（先给出名字，后面贴链接）&lt;/p&gt;&lt;p&gt;番外篇(1)——最速下降法&lt;/p&gt;&lt;p&gt;番外篇(2)——无聊的最速下降法推导&lt;/p&gt;&lt;p&gt;番外篇(3)——最速下降法的特点&lt;/p&gt;&lt;p&gt;番外篇(4)——共轭梯度法入坑&lt;/p&gt;&lt;p&gt;番外篇(5)——共轭方向的构建&lt;/p&gt;&lt;p&gt;番外篇(6)——共轭梯度的效果&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/22464594&amp;pixel&amp;useReferer"/&gt;</description><author>冯超</author><pubDate>Thu, 17 Nov 2016 23:48:39 GMT</pubDate></item><item><title>聊点轻松的5——这篇写得并不轻松</title><link>https://zhuanlan.zhihu.com/p/23750864</link><description>没错，又是熟悉的开头，不知不觉，我的知乎小庙迎来了5000名看官，已经快过去半年了，每招来1000名看官我就写一篇扯蛋的文章，之前我已经尽力把能扯的内容都扯过了，还把自己不擅长的内容也强扯了（最后果然被打脸了）。但是一切还算顺利，总之感谢大家的支持！这一篇我准备硬扯一下了。&lt;p&gt;在我中学的时候，我对武侠小说异常地痴迷，并且自己撸起袖子写过武侠小说。武侠小说之中，还是最喜欢金庸老先生的小说。而且因为看三联版的原因，我对40这个数字十分喜欢，因为金老先生的小说中有不少被归纳成40章节——比方说射雕三部曲，笑傲江湖。于是我也想着自己可以写出几个“40”来。&lt;/p&gt;&lt;p&gt;于是乎，自己的第一个技术类的40篇就要完结了，也可以说《无痛的机器学习》第一季就要告一段落了（实际上已经写完了，只是为了效果按期放出）。这一季结束后，我会按时间放出一些番外篇的文章，第二季的新鲜文章将在2017年正式放出了。&lt;/p&gt;&lt;p&gt;另外我发现了一个现象，不知道这个现象只发生在我这里还是在知乎中比较普遍的现象，那就是大家更喜欢点“收藏”而不是点“赞”。对我来说大家点哪个都一样，但是说实话一篇篇文章的收藏实在有点累，所以我会在这篇文章后面再一篇这一季文章的目录文，喜欢收藏的朋友直接收藏这一篇就好。传送门：&lt;a href="https://zhuanlan.zhihu.com/p/22464594"&gt;https://zhuanlan.zhihu.com/p/22464594&lt;/a&gt;&lt;/p&gt;&lt;p&gt;写完了这一季，我能感受到自己的成长，对于技术细节的理解，对于技术流程的表述，这些能力还是有了很大的提升。作为机器学习界的一名小学生，我正在茁壮成长。在这一路上要感谢的人很多：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;感谢帮我审阅文章的&lt;a href="https://www.zhihu.com/people/03675ab7bf1c28d3d71d2154abb3ddd1" data-hash="03675ab7bf1c28d3d71d2154abb3ddd1" class="member_mention" data-editable="true" data-title="@我爱机器学习" data-hovercard="p$b$03675ab7bf1c28d3d71d2154abb3ddd1"&gt;@我爱机器学习&lt;/a&gt;和&lt;a href="https://www.zhihu.com/people/08cd1d56513335b13d6a93725db969ad" data-hash="08cd1d56513335b13d6a93725db969ad" class="member_mention" data-title="@夏龙" data-editable="true" data-hovercard="p$b$08cd1d56513335b13d6a93725db969ad"&gt;@夏龙&lt;/a&gt;，他们在第一时间帮我指出文章中不足之处；&lt;/li&gt;&lt;li&gt;感谢很多在评论中指出文章问题的朋友，是你们让这些文章变得更加正确；&lt;/li&gt;&lt;li&gt;同时也感谢评论中提问题的朋友，你们中的一些问题我一开始也是并不清楚的，回答这些问题也是一个提高的过程。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;之前我写过一篇讨论学习的文章，聊过对学习的一些看法，在我看来，在学习机器学习的过程中，要我感到成长最快的就是读源码，做实验。很多时候别人的论文，别人写的技术博客很精彩，但是如果没有动手实践，就总感觉理解得不够透彻明白。而真正看到源代码的实现细节后，我才能明白论文博客中没有着重提到的一些奥妙。&lt;/p&gt;&lt;p&gt;最后，我也想向各位看官征集一下，大家接下来对哪些技术内容感兴趣呢？我会挑选一些大家感兴趣且我能写的内容（原因在这里：&lt;a href="https://www.zhihu.com/question/26865557/answer/126145134" class=""&gt;https://www.zhihu.com/question/26865557/answer/126145134&lt;/a&gt;），尽可能地为大家呈现出来。&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/23750864&amp;pixel&amp;useReferer"/&gt;</description><author>冯超</author><pubDate>Thu, 17 Nov 2016 23:47:08 GMT</pubDate></item><item><title>FCN(4)——Mean Field Variational Inference</title><link>https://zhuanlan.zhihu.com/p/22887466</link><description>&lt;p&gt;上一篇我们介绍了DenseCRF的形式，我们已经了解了denseCRF，下面我们花一点时间了解下denseCRF的求解方式——Mean Field Variational Inference&lt;/p&gt;&lt;h2&gt;Variational Inference入坑&lt;/h2&gt;&lt;p&gt;前面我们在介绍Variational autoencoder的时候刚刚提到过这种求解复杂模型的方法，不过在VAE那里我们只是借着它的坑做了一个简单的展开，而且VAE的计算和Variational Inference的关系并不算特别密切。而这一次我们就要用心了，因为——&lt;/p&gt;&lt;p&gt;上面的pairwise特征确实有点多……&lt;/p&gt;&lt;p&gt;另外，在前面一篇文章中我们说过，对于无向图模型，我们要先求出模型整体的联合变量，才能再做其他的打算。也就是说我们要同时把所有的像素的类别解出来，这个解空间实在有点大，如果我们想用暴力的方法求解，恐怕要吃苦头——比方说MCMC。&lt;/p&gt;&lt;p&gt;于是我们这里采用Mean field variational approximation的方法求解。那么什么是Mean field呢？其实我对这个高深的物理理论也不是特别了解（说实话，我读的本科专业没有大学物理课，所以物理水平基本停留在高中水平，勿喷……），但是我们可以用一个稍微形象的方式来理解。&lt;/p&gt;&lt;p&gt;通过前面的学习，我们知道无向图模型中的一些类似概率的表示可以用factor或者feature表示。由于我们每一对像素之间都有一条边相连，如果我们把每一条边用一个factor表示出来，那么这张无向图上就会布满factor。我们假设一个像素的energy发生了变化，那么所有与它相连的像素点——当然就是剩下的所有像素点都有可能随着这个像素点发生变化。&lt;/p&gt;&lt;p&gt;于是乎，可怕的蝴蝶效应就开始了。所有的像素点中，可能有些像素点的energy伴随着发生了变化，那么所有连着它们的像素点——抱歉，这回又是所有像素点，会跟着它们继续发生变动，于是这个过程会持续不断地进行，直到它们都玩累了，玩不动了，enregy保持不变了，这个游戏才算结束。&lt;/p&gt;&lt;p&gt;下面这个问题就抛给我们了——我们建立的模型具有非常强大的建模能力，但是也具有如此有尿性的能量传播特性，如果让我们自己去把这些energy传导的过程模拟出来，感觉是要死人的……没错是要死人的……&lt;/p&gt;&lt;p&gt;我们可以把所有的连接两个像素点的factor想象成一根弹簧，把像素点想象成可以有一定限度位移的小球。当有一个小球稍微动了一下，所有连着它的弹簧会发生震动，那么弹簧另一边的小球也会跟着动，于是顺着弹簧，所有球都被传导起来，大家一起动起来……好吧，我是希望用一个更容易想象出来、有画面感的例子让大家感受一下这个复杂模型的恐怖性。&lt;/p&gt;&lt;p&gt;下面我们就要祭出我们的Mean field大招了。我们的Mean field approximation帮助我们把这个问题进行了简化，问题变成了这个样子——&lt;/p&gt;&lt;p&gt;我们要将每一个小球受到别的小球的弹簧力一次性计算完。&lt;/p&gt;&lt;p&gt;这话说得实在有些抽象，我们用更加详细的语言表达一下。我们刚才描述了那个混乱的力传导的场景，下面由上帝出马来调节这些力，上帝喊口号，所有小球听从指挥，准备！&lt;/p&gt;&lt;p&gt;第一步，小球如果你想动，你就动一下。注意！你的动作先别传递到弹簧上，上帝我这有一个小本本，我先记下来，一会儿我会按本子上记录的计量用我的魔法施加到这些弹簧上的。放心，你的力会原封不动的送上去，不会打折扣的。&lt;/p&gt;&lt;p&gt;第二步，上帝施展分解大法，把整个模型拆解开来，有多少个小球就有多少个子模型。在每一个子模型里，只有一个小球是主角，所有和这个小球相连的弹簧可以保留，所有和这个小球无关的弹簧全部被上帝拆掉。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-09fbb752a0e9aeb94c6b0cef6cca2bdd.jpg" data-rawwidth="1280" data-rawheight="960"&gt;&lt;p&gt;第三步，上帝拿出刚才的小本本，把每个球的力施加到每一个子模型的弹簧上。听上去好像要做的工作很多，不过谁让他是上帝呢，能者多劳嘛。&lt;/p&gt;&lt;p&gt;第四步，不用说这个时候，每个子模型的主角——那个集万千弹簧于一身的小球受到了成吨的力，OK，尽情地享受弹簧传来的力道吧！&lt;/p&gt;&lt;p&gt;第五步，这些主角在享受完弹簧传来的力道，心想来而不往非礼也，我也得传点力回去啊，于是准备扭扭屁股动动身子传点力回去的。这时候上帝突然出现，放出大招，这些主角竟然无法把自己受到的力传回去。说好的雨露均沾呢，我得把力传回去啊，上帝你不能管得太多啊。不过上帝知道，在它们的另一个平行世界——也就是别的子模型中，自己最初移动产生的力也已经传递给别的“主角”了。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-5e11f3eae1294b1978832b230f6cce81.jpg" data-rawwidth="1280" data-rawheight="960"&gt;&lt;p&gt;第六步，上帝施展大法，将所有的子模型合成原来的模型。这样我们的一次力的传递过程就结束了。不过瘾，还想再来一波？好，那我们回到第一步……&lt;/p&gt;&lt;p&gt;我们花了这么多笔墨，将这个过程大概讲了一遍，如果回来在看前面那句话——&lt;/p&gt;&lt;blockquote&gt;我们要将每一个小球受到别的小球的弹簧力一次性计算完。&lt;/blockquote&gt;没错，每一次每个小球给别的小球传的力一次性传完，别的小球的力也一次性接受完。那些二次传导的事情再我们的Mean Field中就没有了。大家瞬间感到了一丝轻松，听上去这个模型有解出来的希望了啊。&lt;p&gt;好了，那么Variational Inference的目标，就是用这个简化后的这个模型尽可能地靠近原来那个复杂的模型。如果两个模型能完全一样，那就太好了，我们有简单的模型来手，还要复杂的模型干啥？赶紧扔了。&lt;/p&gt;&lt;p&gt;那么下面的目标就是定义一个目标函数，目标是让这个简单模型和复杂模型靠近。前面我们在介绍VAE的时候曾经提到过——没错，就是KL散度。下面我们同样用KL散度来表示这个目标函数。&lt;/p&gt;&lt;p&gt;时间不早了，下一回我们来看看这个算法的真面目。&lt;/p&gt;&lt;h2&gt;私货时间&lt;/h2&gt;&lt;p&gt;"我爱机器学习"6群已经准备发车：337537549，欢迎大家赶紧上车！&lt;/p&gt;&lt;p&gt;337537549！&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/22887466&amp;pixel&amp;useReferer"/&gt;</description><author>冯超</author><pubDate>Tue, 15 Nov 2016 22:43:52 GMT</pubDate></item><item><title>FCN(3)——DenseCRF</title><link>https://zhuanlan.zhihu.com/p/22464586</link><description>上一回我们简单介绍了无向图模型和CRF的基本概念，下面我们来看看CRF在图像分割问题上的具体应用。我们简单回忆一下CRF中的两个关键变量，这时我们需要换一下变量的名称——我们用I表示图像的像素信息，也就是观察变量，我们用X表示图像中每一个像素的类别，也就是我们想要知道的信息。不过在更多的文档中，大家喜欢用X表示图像上的像素，用Z表示我们想求的label。&lt;p&gt;好了，为了更好地展示我们提到的模型，我们给出一个简单的图形：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-360800edde6ab9f08091e2e835d0880e.jpg" data-rawwidth="1280" data-rawheight="960"&gt;&lt;p&gt;下面的就是我们建模的过程了，最简单的建模方式就是每一个像素的类别只和自己所在的像素有关。我们可以用一个简单的图来表示：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-d8707af25b5b9b9829828d346e8a414d.jpg" data-rawwidth="1280" data-rawheight="960"&gt;&lt;p&gt;这个图看上去比较简单吧，而且计算也比较简单。我们可以建一个模型，输入是一个像素的特征，输出是一个像素所代表的类别。那么这个模型和一般的分类问题没有太多区别。&lt;/p&gt;&lt;p&gt;不过这样的效果显然不好，谁能只通过一个像素就知道这个地方是什么类别呢？这个模型虽然简单好解，但是我们一眼就可以看出，它并不是一个高级的模型，所以这个模型pass了。不要问我什么理由……&lt;/p&gt;&lt;p&gt;下面我们再来一个模型，每一个像素的类别和所有像素的图像信息有关，这个模型实际上就和FCN的输出相同，我们可以用下面的图表示这个模型：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-1cb88462ccca65f855d2320c07c64e53.jpg" data-rawwidth="1280" data-rawheight="960"&gt;&lt;p&gt;CNN模型虽然很强大，但是CNN模型缺少一个关键点，就是每一个像素点类别之间实际上存在着一定关系，也就是我们常说的图像的平滑性——每一个图像像素点的类别都有可能和临近点的类别相近，这个特性是CNN模型所不具有的。所以我们对这个模型也保留意见。&lt;/p&gt;&lt;p&gt;于是我们新鲜出炉的新模型又来了——这一次我们让每一个像素点的类别和它的4邻域的类别相关，于是它的模型变成了这个样子：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-652eb608631d3581d89680220b6dbd55.jpg" data-rawwidth="1280" data-rawheight="960"&gt;&lt;p&gt;这个模型瞬间高大上了许多，我们前面提到的平滑性已经得到了一定的满足。但是有时候仅仅是这种程度的关联是不够的，如果临近的几个像素恰好产生了一点波动，不是我们想要的那个样子，那么这个像素点的类别就有可能出问题。我们还需要更深层次的关联。于是乎，传说中的denseCRF就诞生了。&lt;/p&gt;&lt;p&gt;denseCRF的模型是什么样子呢？如下图所示：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-46beab9f4805ca1b8ac1699775533650.jpg" data-rawwidth="1280" data-rawheight="960"&gt;&lt;p&gt;好吧，基本上能连在一起的都连在一起的，我们把模型的复杂程度提到了最高的程度，完全成了一团乱麻了……&lt;/p&gt;&lt;h2&gt;Dense CRF&lt;/h2&gt;&lt;p&gt;我们看过了它的模型形式，下面直接来看看模型的能量函数表达形式：&lt;/p&gt;&lt;equation&gt;E(x)=\sum_i \psi _u(x_i)+\sum_{i&amp;lt;j}\psi_p(x_i,x_j)&lt;/equation&gt;&lt;p&gt;可以看出每一个像素都有一个unary的函数，也就是说在这个特征函数里w，剩下的参数都出现在图像的像我们只考虑当前像素的类别，而暂时不考虑别的像素的类别信息。&lt;/p&gt;&lt;p&gt;而后面的pairwise函数里，每一个像素的类别都和其他像素计算一个energy feature。于是就有了上面的公式形式。注意这里的能量函数是所有像素点的联合能量和不是某一个像素点的能量，所以后面的pairwise项，我们有n(n-1)/2组特征，总的来说，特征数量是像素数量的平方级别，如果我们有一张100万像素的图片，那么我们就会建立4950亿组pairwise特征。正是因为这种复杂的形式，所以这个模型被称作Dense CRF。满满的全是dense啊！&lt;/p&gt;&lt;p&gt;关于unary函数的内容，我们可以尽情发挥，在denseCRF中我们并没有对这一部分做详细的限制。因此关于这部分我们就暂时略去不谈了，在后面的文章中我们会重新回来，挖掘unary函数的潜力。下面我们专注于解决pairwise这个大坑。&lt;/p&gt;&lt;p&gt;下面我们讲piarwise部分展开，其中&lt;/p&gt;&lt;equation&gt;\psi_p(x_i,x_j)=\mu(x_i,x_j)\sum_{m=1}^Kw^{(m)}k^{(m)}(f_i,f_j)&lt;/equation&gt;&lt;p&gt;可以看出，pairwise函数中还是比较复杂的，我们从左往右以此介绍。&lt;/p&gt;&lt;p&gt;首先是&lt;equation&gt;\mu(x_i,x_j)&lt;/equation&gt;，这一项被称作label compatibility项，简单来说这里约束了“力”传导的条件，只有相同label条件下，能量才可以相互传导。具体来说，“一个像素可能是飞机”的能量可以和“另一个像素可能是飞机”的能量相互传导，从而增加或者减少后者“可能是飞机”的能量，从而影响“可能是飞机”的概率，而“一个像素可能是飞机”的能量是不能影响“另一个像素是人”的概率的。&lt;/p&gt;&lt;p&gt;文章中也提到了，这个简单地一刀切似乎有点不人性。拿Pascal-VOC中的20类+背景类来说，有些类别之间的相似性是很强的，而另外一些类别则完全不相似，所以作者后面提到了一些学习相关的事情，这里我们就不再深入下去了。&lt;/p&gt;&lt;p&gt;加和项里面就是经典的权重*feature的套路了，其中&lt;/p&gt;&lt;equation&gt;k^{(m)}(f_i,f_j)=w^{(1)}exp(-\frac{|p_i-p_j|^2}{2\theta_{\alpha}^2}-\frac{|I_i-I_j|^2}{2\theta_{\beta}^2})+w^{(2)}exp(-\frac{|p_i-p_j|^2}{2\theta_{\gamma}^2})&lt;/equation&gt;&lt;p&gt;这一项以特征的形式表示了不同像素之前的“亲密度”。前面我们提到了特征不同于tabular形式的factor，我们看不到表格，只能看到公式。上面的公式中，第一项被称作appearance kernel，第二项被称作smooth kernel。这里面有很多变量，我们一一来看。&lt;/p&gt;&lt;p&gt;appearance kernel里面的p表示像素的位置——position，我们的图像是2维的，那么position就有2维。I表示图像的像素值——Intensity，我们的图像是彩色的，那么Intensity就有3维。分式下面的两个参数无论从位置还是长相都像高斯分布中的方差，这里的含义也差不多的。&lt;/p&gt;&lt;p&gt;于是乎我们可以看出，如果两个像素距离近且颜色近，那么这个feature特征就会很强，反之则不强。同时分母也控制了强弱性，分母越大越难强起来。其实这一项和图像处理中的bilateral filter很像。我们相当于在一个5维的空间内寻找相近的像素对并给予它们的特征加强。&lt;/p&gt;&lt;p&gt;看完了前面一项，在看后面那一项就不会觉得太难。大家照着上面那一段话自行分析吧。&lt;/p&gt;&lt;p&gt;好了，到这里我们就交代完DenseCRF的表达形式了，下面就要进入Mean field variational inference的环节了。&lt;/p&gt;&lt;h2&gt;私货时间&lt;/h2&gt;&lt;p&gt;"我爱机器学习"6群已经准备发车：337537549，欢迎大家赶紧上车！&lt;/p&gt;&lt;p&gt;337537549！&lt;/p&gt;&lt;h2&gt;私货时间2&lt;/h2&gt;&lt;p&gt;恭喜川普大大！&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/22464586&amp;pixel&amp;useReferer"/&gt;</description><author>冯超</author><pubDate>Wed, 09 Nov 2016 20:08:16 GMT</pubDate></item><item><title>CenterLoss——实战&amp;源码</title><link>https://zhuanlan.zhihu.com/p/23444100</link><description>本来要继续连载CRF的，但是最近看到了知乎上各位大神的论文解读——《A Discriminative Feature Learning Approach for Deep Face Recognition》,其中介绍了他们设计的一个用户提高类别的区分度的损失函数——Center Loss，并且有一个基于MNist数据库的小实验，于是本人就简单实践了一下。&lt;p&gt;本着其他大神已经深度解析了这篇文章的内容，所以我觉得我再凑热闹把那些理论的东西讲一遍意义不大，倒不如抡起袖子干点实事——把代码写出来跑一跑。在我完成实验前，已经看到github上有人完成了MXNet的center loss代码，所以作为Caffe派的革命小斗士，我得抓紧时间了。&lt;/p&gt;&lt;p&gt;不说废话，先用一个8拍把问题说明白：&lt;/p&gt;&lt;h2&gt;一个8拍的center loss&lt;/h2&gt;&lt;p&gt;1：同样是分类问题，我们之前只关注了待识别的图像应该属于哪个类别，但是并没有关心一个同样重要的问题：最终分类器的分界面区域内的空间是不是都应该属于这个类别？空间内这些长得很像的图像，它们的特征会不会其实差距有点大？&lt;/p&gt;&lt;p&gt;2：于是乎作者设计了一个网络，在倒数第二层全连接层输出了一个2维的特征向量，并以此进行进一步的分类。我们把MNist的Test集合数据通过最终训练好的模型进行预测，倒数第二层的样子是这样的：&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-bdbd57903c0eac1e73626c340bcd487e.png" data-rawwidth="889" data-rawheight="572"&gt;嗯，貌似和论文上的图像差不多啊……&lt;/p&gt;&lt;p&gt;3：于是乎，作者就觉得，怎么每个类别的特征都是长长的一条啊？那么实际上同一个类内部的差距还很大呢……而且，同一类别下两个图像的距离可能比不同类的距离还大，这种现象如果一直存在，那么在作者关注的人脸识别领域，会不会出现一个人脸和别人的脸太相似而被误刷啊……&lt;/p&gt;&lt;p&gt;4：不能这样子，于是作者设计了一个新的loss叫center loss。我们给每个label的数据定义一个center，大家要向center靠近，离得远的要受惩罚，于是center loss就出现了：&lt;/p&gt;&lt;equation&gt;CenterLoss=\frac{1}{2N}\sum_{i=1}^N|x_i-c|^2_2&lt;/equation&gt;&lt;p&gt;5：众人纷纷表示这个思路很好，但是这个c怎么定义呢？首先拍脑袋想到的就是在batch训练的时候不断地计算更新它，每一轮我们计算一下当前数据和center的距离，然后把这个距离以某种形式——就是梯度叠加到center上：&lt;/p&gt;&lt;equation&gt;\frac{\partial CenterLoss}{\partial x}=\frac{1}{N}\sum_{i=1}^N(c-x_i)&lt;/equation&gt;&lt;p&gt;6：吃瓜群众立刻表示：每个batch的数据并不算多，这样更新会不会容易center产生抖动？数值上的不稳定在优化中是大忌啊！于是作者简单粗暴地讲：那我们加个scale，让它不要太大：&lt;/p&gt;&lt;equation&gt;\Delta c = \frac{\alpha}{N} \sum_{i=1}^N(c-x_i)&lt;/equation&gt;&lt;p&gt;这个scale肯定是小于1的。&lt;/p&gt;&lt;p&gt;7：吃瓜群众满意了，吃瓜子的群众有发话了：现在你有两个loss了，我们该怎么平衡这两个loss之间的权重呢？作者心想：你这不是明知故问么……于是又加了一个超参数&lt;equation&gt;\lambda &lt;/equation&gt;，用于控制两个loss之间的比例。&lt;/p&gt;&lt;p&gt;反正多来个超参数无所谓，你们慢慢调去吧～&lt;/p&gt;&lt;p&gt;8：该定义的终于都结束了，我们加入新的loss，训练之后得到了这个结果：&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-d4e7f06eb2628d4c115d3a089b4d8e69.png" data-rawwidth="859" data-rawheight="604"&gt;于是掌声雷动，这个效果看着确实不错啊～&lt;/p&gt;&lt;h2&gt;一些细节&lt;/h2&gt;&lt;p&gt;由于倒数第二层的特征维度被缩减成了2，所以识别的精度肯定会受到些影响，不过这只是为了可视化的效果，所以在真正的实验中我们可以把这个数字调大。在我的实验中最终的Test Accuracy是0.9888。比正常LeNet的0.99稍低一点。&lt;/p&gt;&lt;p&gt;直接修改LeNet倒数第二层的维度会造成无法训练，所以论文中的LeNet++使用了6层卷积。对于MNist这样的小问题使用6层卷积也是没谁了，所以训练起来还是要费点时间的。&lt;/p&gt;&lt;p&gt;在我的实验中加入center loss后Test Accuracy实际上是下降了一点的。不过这点下降并不能说明center loss对这个问题起了反作用，后面还是需要尝试当倒数第二层的维度大于2时的情况。&lt;/p&gt;&lt;h2&gt;干货来了&lt;/h2&gt;&lt;p&gt;说了这么多废话，it's time to show me the code。链接：&lt;a href="https://github.com/hsmyy/CenterLoss_Caffe_Mnist" data-editable="true" data-title="GitHub - hsmyy/CenterLoss_Caffe_Mnist: It's the script of Center loss on mnist dataset running on Caffe."&gt;GitHub - hsmyy/CenterLoss_Caffe_Mnist: It's the script of Center loss on mnist dataset running on Caffe.&lt;/a&gt;&lt;/p&gt;&lt;p&gt;由于是快速尝试，只实现了cpu的版本，而且写得比较粗糙，望各位大神不吝赐教。&lt;/p&gt;&lt;h2&gt;私货时间&lt;/h2&gt;&lt;p&gt;"我爱机器学习"6群已经准备发车：337537549，欢迎大家赶紧上车！&lt;/p&gt;&lt;p&gt;337537549！&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/23444100&amp;pixel&amp;useReferer"/&gt;</description><author>冯超</author><pubDate>Sat, 05 Nov 2016 18:39:21 GMT</pubDate></item></channel></rss>