<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>混沌巡洋舰 - 知乎专栏</title><link>https://zhuanlan.zhihu.com/c_29122335</link><description>跨界思考内容供应商，与微信公众号混沌巡洋舰同属于巡洋舰科技公司。</description><lastBuildDate>Sun, 15 Jan 2017 19:17:11 GMT</lastBuildDate><generator>Ricky</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>人工智能核心概念辨析</title><link>https://zhuanlan.zhihu.com/p/24891079</link><description>作者：&lt;em&gt;Haoskism 原人人网 百度资深交互设计师 现和创科技交互设计专家 &lt;/em&gt;&lt;p&gt;&lt;em&gt;我们首先要清楚人工智能（Artificial Intelligence）是一个计算机领域的技术，直译过来它泛指人通过机器实现的智能。那么传统的计算机技术与人工智能有什么区别？下图是现在所有计算机鼻祖的模型，打孔机。&lt;/em&gt;&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-4c0b001457291b97de5f5b6c4078be23.jpg" data-rawwidth="640" data-rawheight="480"&gt;&lt;p&gt;打孔机的原理很简单，在有关记忆的讨论中提到过：打孔机有一套基本的规则，根据不同的输入按照这个规则输出不同的结果，无论数据输入是什么样的，都不会影响基本的规则，那么现代计算机工作起来是什么样子的？&lt;/p&gt;&lt;p&gt;我们举个有趣的例子，如何判断一个人是不是秃头？&lt;/p&gt;&lt;p&gt;我们做一个基本的假设，一个人如果有5000根头发算不秃头，低于5000根算秃头，从现在的编程模式开始，写下的代码大致意思为：如果（if）头发大于等于5000根，那么不秃头；不然（else）小于5000根，那么秃头。&lt;/p&gt;&lt;p&gt;我们模拟遇到各种各样的问题，用语言模拟现在的编程方式解决问题的过程：&lt;/p&gt;&lt;p&gt;1 一个人如果掉了一根头发，那么算不算秃头？&lt;/p&gt;&lt;p&gt;为了弥补这个绝对化的答案，我们假设4900~4999的数据算不太秃。&lt;/p&gt;&lt;p&gt;2 如果掉的是脑袋后面的正面看不见怎么办？&lt;/p&gt;&lt;p&gt;为了弥补这个我们限定掉正面的算秃头。&lt;/p&gt;&lt;p&gt;3 如果是头顶很秃，外围很多的头发（谢顶）算不算秃头？&lt;/p&gt;&lt;p&gt;为了弥补这个我们把谢顶的算秃头。&lt;/p&gt;&lt;p&gt;4 如果一个人脑袋很大，5000根看起来很秃，如果脑袋很小，5000根头发看起来不少怎么办？&lt;/p&gt;&lt;p&gt;为了解决这一条，我们再加上一条，用头发除以头皮的面积，低于算秃头，高于不算。&lt;/p&gt;&lt;p&gt;5 狗的毛非常少，是不是有点秃?&lt;/p&gt;&lt;p&gt;计算机无法回答，因为基本预设是判定人的，我们得把狗的模型加进去，依次为了防止遗漏，还要把猫加进去，有毛的加进去，森林加进去......&lt;/p&gt;&lt;p&gt;这个过程中实际情况会发生各种超出简单预料的变化，程序员要不停的限制条件，给出解决的判定方法，计算机完全没有自主的智能，编程过程需要无穷无尽的补丁。&lt;/p&gt;&lt;p&gt;那么人是如何判断秃头还是不秃头？&lt;/p&gt;&lt;p&gt;第一点，输入的信息成为记忆，信息输入的同时改变处理信息的结构，参与我们对这个词的认知。我们小的时候看过几个秃头的图片或者真人，大人说这叫秃头，然后我们就知道头发少算秃。这样少一根头发，少正面的头发，谢顶，头脑大小的问题都通过记忆的对比得以解决。&lt;/p&gt;&lt;p&gt;第二点，我们将获得的概念进行迁移，用来形容其他事物。当语文课本里出现“山秃了”，我们自然而然明白秃是一个形容稀少的词，就学会了说“山秃了”，当然也就可以判断狗的毛是不是秃了。&lt;/p&gt;&lt;p&gt;第三点，潜意识中我们赋予秃方向性，而具有类似意义的“光”则没有，输入的视觉信息与文字“秃”相配合的场景，只有在从下而上生长的东西变得稀少时才可以使用，而这种相关性又是因为输入的视觉信息所携带的相关性导致的，“秃”与自下而上的相关性并未被意识察觉却被正确使用。可以说头发秃了，林秃了，但是不能说胡子秃了，树根秃了。&lt;/p&gt;&lt;p&gt;第四点，基于时间，我们可以根据记忆对未来进行推测和想象。我们看过春夏秋冬树叶的生长过程，就可以推测出秋天树会变秃。&lt;/p&gt;&lt;p&gt;人的智能可以非常灵活的处理各种疑问和问题，输入的信息本身带有特征，那么人的智能反过来用这个特征（信息中不同因素之间的相关性）处理这个信息，现在广为使用的人工智能技术就在这几点向人类的智能靠近，这种人工智能技术就是机器学习，这里的学习就是指通过数据学习，就像我们获得记忆的过程。人工智能既然是模拟生命的智能，那么最直接的方法就是模拟生物神经网络（Biological Neural Network，BNN），它形成的就是人工神经网络（Artificial Neural Network, ANN），简称神经网络。&lt;/p&gt;&lt;p&gt;&lt;b&gt; 构造一个人工神经网络     &lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们尝试用一个例子来说明生物神经网络和人工神经网络是怎么工作的，如何把苹果和香蕉识别出来？为了简化这个问题，我们从两个特征来描述苹果和香蕉，颜色和形状，限定为苹果是红色的圆形，香蕉为黄色的弯形。&lt;/p&gt;&lt;p&gt;这里有非常重要的一点，红色总是伴随圆形，黄色总是伴随弯形，这里存在一种相关性，当然这是由其生物性状决定的。&lt;/p&gt;&lt;p&gt;我们知道赫布的细胞集合，也了解了视觉感受野的基本原理。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-c7619ceae4fb5ebe49729ecc79fcd954.jpg" data-rawwidth="640" data-rawheight="806"&gt;&lt;p&gt;那么我们利用感受野的机制构造出一个识别苹果和香蕉的生物神经网络，如下图。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1.假象一个可以识别水果的生物神经网络&lt;/strong&gt;&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-ea418731c80fa9bce7af3a41179f642a.png" data-rawwidth="1163" data-rawheight="1046"&gt;&lt;p&gt;每个圆圈代表一部分工作的细胞或者细胞集合，深灰色的圆圈代表水平细胞，红色与圆形相当于感受野周边，黄色与方形相当于感受野中心，实线代表输入刺激，虚线代表抑制刺激，模拟的就是水平细胞的侧向抑制能力的结果，所以如果四个输入同时刺激的时候，刺激之和为0.&lt;/p&gt;&lt;p&gt;当出现红色并且为圆形的时候，刺激经过转换，这个网络会形成抑制刺激，判断为苹果；当出现黄色并且为弯形的时候，这个网络会汇合形成刺激，判断为香蕉。&lt;/p&gt;&lt;p&gt;当然，这是我们的大脑明白了什么是苹果和香蕉之后的结果，那么在我们很小的时候没有见过苹果和香蕉的时候，生物神经网络的初始状态是什么样子呢？如下图。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2.初始的生物神经网络&lt;/strong&gt;&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-491641ee6c3133f4f100fc4e10918806.png" data-rawwidth="360" data-rawheight="580"&gt;&lt;p&gt;每个颜色的输入与传递刺激的汇合点还是抑制刺激的细胞都是相连的，形状也是一样，但是经过长时间的刺激学习，红色和圆形长期同时出现，通过各种各样的强化联系的方式，如细胞间争夺营养因子，或者突触容量的增减及突触重排，红色与圆形的联系被加强了，同样，黄色与弯形的线与汇合点的联系也被加强了，那么这个竞争的原理怎么表现呢？我们知道在上图的网络中从红色刺激触发的连线是2条，假设这个就是起始的突触容量，而最终要求的是是只有1条突触可以保存下来，同时无论是将刺激转换为抑制刺激的细胞/细胞集合，还是刺激集合点，从初始的4个突触容量最终要变化为最多可以容留2个突触作为进入的刺激，那么这个网络会形成什么样的呢？我们以苹果作为例子说明。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3.生物神经网络的学习过程&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-b950377dbf8b378973db3bd0eb9793d4.jpg" data-rawwidth="640" data-rawheight="808"&gt;再加上香蕉的刺激，就会形成识别苹果和香蕉的生物神经网络，如下图。&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-bd9ddee892ff3470cec855652c535973.png" data-rawwidth="360" data-rawheight="580"&gt;假如一开始红色保留的是右侧的连线，那么形成的结果是正好相反的，但是并不影响区分二者的结果，这个过程省略，其结果如下图。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-a1f17860b5d0161bf425a68253197e71.png" data-rawwidth="360" data-rawheight="580"&gt;&lt;p&gt;同时被刺激的连线被大大加强，而不被刺激的连线被削弱，生物神经网络经过反复刺激，修改神经间连接的方式，最终形成了识别水果的能力。那么这个过程，如果用计算机的数学方式，应该怎么表达呢？看下图。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;4 假象一个可以识别水果的人工神经网络&lt;/strong&gt;&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-bf137a7103364763273314d418cc6131.jpg" data-rawwidth="360" data-rawheight="620"&gt;&lt;p&gt;假设神经网络最终的输出强度为S，根据S的值判定是苹果还是香蕉，顶层细胞输入的信号强度为P，网络的强度为W，那么S = P1 x W1 + P2 x W2 + P3 x W3 + P4 x W4 。&lt;/p&gt;&lt;p&gt;当我们看到苹果、红色和圆形刺激的时候，P1和P3为1，P2和P4的刺激为0，假设所有的网络强度一致，W1=W2=W3=W4=1，那么识别苹果的结果就是S = - ( 1 x 1 ) + ( 0 x 1 )  - ( 1 x 1 ) + ( 0 x 1 )  =  - 2，注意P1P3输入变为负号的过程，如下图。&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-205beeb1d8829fdf2ab835d52a11d7a6.jpg" data-rawwidth="360" data-rawheight="620"&gt;当我们看到香蕉、黄色和弯形刺激的时候，P2和P4为1，P1和P3为0，结果为+2，判定为香蕉，如下图。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-c139920d9497786f2e0b39e950e12a13.jpg" data-rawwidth="360" data-rawheight="620"&gt;&lt;p&gt;关键点来了，我们知道生物神经网络一开始并不是可以直接判断出来哪个是苹果哪个是香蕉的，那么人工神经网络起始也是一样，如下图。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;5 初始的人工神经网络&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-b70c7420fbdfd109115807d0a613eebf.jpg" data-rawwidth="360" data-rawheight="620"&gt;把转化刺激为抑制的细胞/细胞集合标记为绿色，把与它相连的线标记为绿色，用字母A表示与相关，网络强度为W1A=W2A=W3A=W4A=1；,把直接传递刺激的汇合点标记为蓝色，连线也标记为蓝色，用字母B表示相关，网络强度W1B=W2B=W3B=W4B=1，这样就是人工神经网络的起始样子。让我们计算一下不同刺激获得的值是多少，首先计算苹果，P1=P3=1,P2=P4=0不表示，如下图。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-d66bbfa18f781a3028bd0248e6f1a7a2.jpg" data-rawwidth="360" data-rawheight="620"&gt;&lt;p&gt;S1 = - ( P1 x W1A + P3 x W3A )  + P1 x W1B + P3 x W3B = - ( 1 x 1 + 1 x 1 ) + 1 x 1 + 1x1 = 0 , 计算完的结果是和事实不同的（应该得-2），正确的识别网络中蓝色的连线W1B和W3B的强度应该是0，那么这个网络就出现了误差。再计算香蕉，&lt;/p&gt;&lt;p&gt;P2 = P4 = 1,P1 = P3 = 0 不表示，如下图。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-f33f0360b2d3d39ff1986c3f2dafff0b.jpg" data-rawwidth="360" data-rawheight="620"&gt;&lt;p&gt;S2 = - ( P2 x W2A + P4 x W4A )  + P2 x W2B + P4 x W4B = - ( 1 x 1 + 1 x 1 ) + 1 x 1 + 1x1 = 0，计算的结果一样不对（应该得+2），获得这样的结果并不意外，因为所有的网络强度大小都是相等的，好比生物神经网络的初始状态，&lt;strong&gt;我们要用数学的方法纠正这两个误差，实际上就是如何修正网络连接强度的值，达到学习的目的，这与生物强化某些细胞间的联系而弱化另一些的方法一致。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;我们回到识别苹果的例子，假设识别苹果正确的值应该是-2，那么0的结果就出现了0 - （ -2 ） =  2 的误差（实际值减去正确值等于误差值），W1A为实际值，存在误差E1A，正确的W1A应该是W1A正确 = W1A - E1A（正确的等于实际值减去误差）= 1 - E1A，依此类推，W1B存在误差E1B，W3A存在误差E3A，W3B存在误差E3B。但是我们还是不能解决这个问题，能解决这个问题的关键是参照生物神经网络。&lt;/p&gt;&lt;p&gt;首先，对于S1正确的值而言，左侧细胞集合的输入在变号后是负数，而右侧节点的值为正数，那么左侧的绝对值一定要大于右侧的绝对值；第二点，无论左侧还是右侧获得的输入值是限定的最大值是2，这点是根据之前生物神经网络突触容量的假设所限定的；第三点，在这个设计的网络中，网络的强度不能是负值，但可以为0，所以W1B等的正确值大于等于0；那么我们用图来表示计算的过程，就会发现非常简单了。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-966ab67deca1c0d7faa3ef07d859ff27.jpg" data-rawwidth="385" data-rawheight="800"&gt;&lt;p&gt;最终的结果就是，与右侧相连的网络强度变为0，通过误差的反馈过程，数据训练了人工神经网络本身，当在此刺激P1，P3的时候，人工神经网络就可以正确识别出苹果来。在上述的例子中，为了模拟真实的生物神经网络中水平细胞的侧向抑制效果，特意加入了把左侧输入刺激变为负号的细胞集合，事实上当我们撤掉变号的过程，不限制刺激信号的正负，仍旧可以得到类似的结果。&lt;/p&gt;&lt;p&gt;我们并没有告诉人工神经网络什么是苹果或者香蕉，而只是输入数据和确定神经网络的基本连接规则（而非预先定义的直接规则），让人工神经网络自己学会识别出苹果，这就是人工神经网络与以往通过硬编码（如何识别秃头的例子）所不同的地方。&lt;/p&gt;&lt;p&gt;&lt;b&gt;概念图&lt;/b&gt;&lt;/p&gt;&lt;p&gt;上面介绍了最为简单的人工神经网络，那么它与机器学习和人工智能的关系是什么？&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-9140d103991c5ef07eb487c04563780f.png" data-rawwidth="480" data-rawheight="480"&gt;&lt;p&gt;&lt;strong&gt;人工神经网络是机器学习的一种技术&lt;/strong&gt;，有关人工神经网络的我们了解了，那么不是人工神经网络的机器学习是什么呢？大数据这个词大家都不陌生，大数据技术依赖的是数据中的数据关系，通过大数据训练的算法中很多就是机器学习中不是人工神经网络的部分，比如根据你购物的时候购买特定商品的频率推送相应的广告。&lt;/p&gt;&lt;p&gt;除了人工神经网络，深度学习也是经常被提起的名词，人工神经网络与深度学习又是什么关系？我们首先要对人工神经网络有一个粗浅的了解，如下图。&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-c369e201a4eabc1909d8b99edd5da287.jpg" data-rawwidth="640" data-rawheight="367"&gt;在识别苹果和香蕉的例子中，我们构建的其实是趋近于两层的单层神经网络，甚至形成了部分侧向抑制的能力，如果四个输入信号都被刺激，那么最终的刺激为0。&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-3cc07aa2bb2e6d0d4332919b916cd88f.png" data-rawwidth="480" data-rawheight="380"&gt;人工神经网络有一个非常重要的部分，深度神经网络，是指含有多个隐层的神经网络，如下图。&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-d4857e7ff31feaeef2ac8d63cece69c9.jpg" data-rawwidth="240" data-rawheight="244"&gt;依赖深度神经网络的机器学习被称为深度学习。深度神经网络本身有几个重要的类型：递归神经网络，卷积神经网络，前馈神经网络，这几种神经网络有不同的应用场景。深度学习又可以分为无监督学习和监督学习，如下图。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-3cc07aa2bb2e6d0d4332919b916cd88f.png" data-rawwidth="480" data-rawheight="380"&gt;&lt;p&gt;我们知道神经网络是要通过数据来训练（学习）的，所以如果先要通过具有相关性的标签化的数据训练网络，那么这部分数据就是通过人的监督来筛选的，比如我们构建的简单的识别水果的神经网络，就是先把苹果和香蕉的数据准备好，再输入进去，这就是监督学习。假如不去告诉人工神经网络什么是对，什么是错，什么是苹果，什么是香蕉，而是通过神经网络自己进行聚类学习，除了识别出一般的香蕉苹果，甚至发现特殊品种，这种就是无监督学习，或者叫非监督学习。&lt;/p&gt;&lt;p&gt;从人工智能到无监督学习，整体的概念联系图就是这样的。&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-3cc07aa2bb2e6d0d4332919b916cd88f.png" data-rawwidth="480" data-rawheight="380"&gt;人工神经网络的发展并非一帆风顺，从最早的单层神经网络到现在的多层神经网络经历了七十多年的研究，如下是人工神经网络的发展简史。&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-71ba90f49307d7948c7d65cbc4df48f6.jpg" data-rawwidth="640" data-rawheight="425"&gt;如下是人工神经网络所使用的算法。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-664870e3d2bea5c2e564c6bebc87d500.jpg" data-rawwidth="640" data-rawheight="401"&gt;&lt;p&gt;我们继续简单了解一下深度神经网络在两个·领域的应用.&lt;/p&gt;&lt;p&gt;深度神经网络的两个应用领域&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1.CNN—图像识别（参考 &lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651381959&amp;amp;idx=1&amp;amp;sn=1b920dd476849d88b67a2ef1cf3ed8fc&amp;amp;chksm=84f3ce86b3844790627d2f15256aff0753be1f0b0623da64aaa7357d73e8ed14c415061acb27&amp;amp;scene=21#wechat_redirect" data-editable="true" data-title="用CNN来识别鸟or飞机的图像"&gt;用CNN来识别鸟or飞机的图像&lt;/a&gt;）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在深度神经网络中，卷积神经网络（Convolutional Neural Network，简称CNN）是参考人的视觉形成规律所构建的，因此常常用于图像识别；循环神经网络，也被称为时间递归神经网络（Recurrent Neural network，简称RNN）是具有“记忆”的神经网络，因此常常用于联系上下文的语音识别，语义分析。&lt;/p&gt;&lt;p&gt;我们曾在讨论轮廓的时候见过下面的图片，它说的是人的视觉概念形成的过程。&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-cd68a34c68285b2739ceeb38881879e4.jpg" data-rawwidth="640" data-rawheight="1197"&gt;视觉首先在V1形成基本的方向判断，然后逐层整合继续抽象，变成基本的纹理和小轮廓，最后形成轮廓概念，卷积神经网络与之类似，如下图。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-939ff82ed723ec4381998e0da684ec72.jpg" data-rawwidth="640" data-rawheight="385"&gt;&lt;p&gt;在A部分神经网络形成一些简单的模式，比如其中的光条D，而在E部分神经网络形成了轿车的轮廓概念。图像识别的过程是通过数据集对神经网络进行训练，这包括监督学习和无监督学习，然后再用训练好的网络识别出轮廓概念。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2 RNN-语音/语义识别 （参考&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651381709&amp;amp;idx=1&amp;amp;sn=1697cba21960594b188cc5b53cbd108e&amp;amp;chksm=84f3f18cb384789a279a3c41e6d2c07fe7312f4bda82a1c0e5e1ff4243f34beea4ed0643056a&amp;amp;scene=21#wechat_redirect" data-editable="true" data-title="循环神经网络RNN打开手册"&gt;循环神经网络RNN打开手册&lt;/a&gt;）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;语音识别与图像识别有两点不同，第一点，语音基本是一维的信息，语音识别以语调中的基本语素（最小的语音的声波频率）为主要识别信息，声音的大小和语气（声波的振幅）为辅，而图像识别是二维的平面信息；第二点，语音识别需要语境，通过上下文联系识别，这就需要“记忆”，而图像识别基本是即刻处理。RNN的特点就是“循环”，系统的输出会以某种形式会保留在网络里， 和系统下一刻的输入一起共同决定下一刻的输出，此刻的状态包“记忆”，变成下一刻变化的依据，如下图是几时卷积神经网络（CNN）与循环神经网络（RNN）的对比。&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-1c835be7d8729a09941565604297d3dd.png" data-rawwidth="300" data-rawheight="500"&gt;一对一的CNN针对的是一次性的数据处理，多对一的RNN中b1、b2、b3是神经网络主体不同时刻的状态，而a1、a2、a3又是不同的数据，只有c作为输出，这个多对一的过程可以应用在对一句话的分析上“他的眼睛流下了眼泪”，“他的”、“眼睛”，“流下了眼泪”可以相当于a1、a2、a3，“他很难过”可以相当于结果，如果没有对“他的”，“眼睛”的“记忆”，我们就没办法得出“他很难过”的结果，而且这种词汇的限定可以是不限长度的，如下图的场景。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-1798c89e915c4381f1b4bedd6b50e22f.png" data-rawwidth="260" data-rawheight="380"&gt;&lt;p&gt;“他拾起手帕，擦了擦流泪的眼睛，然后微笑”，这实际描述的是一个喜极而涕的场景，甚至我们可以揣测流泪者文雅举动背后的身份，只有将前后文联系在一起才能生成准确的语义，如果只断成“他拾起手帕”或者“他拾起手帕擦了擦眼泪”都会扭曲本来的含义。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3 CNN与RNN的融合&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;对于人机交互而言，信息输入的实质是编码和解码的过程，在计算机的早期阶段是键盘与晦涩的计算机语言，在之后图形界面出现，普通大众可以通过鼠标的点击表达自己的需求，再之后是移动时代，拖曳和多点触控出现了。那么现在，各种基于循环伸进网络技术的语音识别软件出现了，人机交互似乎可以回到人人之间的语音交互。科大讯飞在锤子手机发布会上出尽了风头，其依赖的技术是大很多语音识别技术并未采用的CNN，下图为其DFCNN。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-3ec99a5721ae4abc6bbdc013c4984d94.jpg" data-rawwidth="600" data-rawheight="235"&gt;&lt;p&gt;简单的说，DFCNN就是把语音变成图形（将语音进行傅里叶变换后时间和频率作为维度），再用对图形处理更为熟练的CNN处理，获得更好的语音识别效果。&lt;/p&gt;&lt;p&gt;与之类似，搜狗语音识别也采用了CNN，如下图。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-8847dcb98f686e0ee6cbabb9bd852312.jpg" data-rawwidth="640" data-rawheight="388"&gt;&lt;p&gt;事实上，很多神经网络采用了复合结构，将CNN与RNN等神经网络模型整合之后进行应用。&lt;/p&gt;&lt;p&gt;&lt;b&gt;数据与建模&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们知道深度学习所采用的技术关键点之一是通过数据训练网络，那么究竟需要多少数据？在2016年初，互联网出现了一个引爆性的新闻，谷歌收购的Deep Mind公司通过以CNN为基础的神经网络形成的人工智能Alphago在围棋上击败了李世石，在这个网络开始训练的时候已经相当于下了三千万的棋谱，而与李世石下棋的时候这个数据达到一亿，当然人类完成一局要一小时，而Alphago只要一秒。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-e306011e548398190fa2a918aaec96bc.jpg" data-rawwidth="640" data-rawheight="413"&gt;&lt;/p&gt;&lt;p&gt;Alphago的示例是不是说一定要海量的数据才能训练神经网络？这样对于没有大量计算资源（分布式的Alphago调用了1202个CPU和176个GPU），以及庞大数据库（3000万棋谱）的小公司和个人是不是就意味着无法使用人工智能？&lt;/p&gt;&lt;p&gt;有另一家公司在Deep Mind公司被收购前与其齐名，Vicarious，该公司的特点是大量借鉴神经科学家和脑科学家的科研成果进入人工智能领域，在其科研人员中有20%来自相关领域。我们在上文中提到了神经细胞的侧向抑制作用对轮廓识别和马太效应的影响，那么如果把这种能力模拟成神经网络中的某些函数会是什么结果？&lt;/p&gt;&lt;p&gt;Vicarious在NIPS、神经信息处理系统大会(Conference and Workshop on Neural Information Processing Systems)上发表了这样一篇论文，利用了脑科学上非常成熟的成果：人类的神经系统系统普遍存在的侧向抑制的现象，在他们在模型上实现了侧向约束（Lateral Constraints），如下图。&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-232590bd3ccd1b0b34d846f0bed2e3d0.jpg" data-rawwidth="640" data-rawheight="200"&gt;注意右下角的放大小图中的灰色方块一元因子（Unary factor），这是与水平细胞相似的关键。在字母验证码识别这个具体问题上，Vicarious基于生成型形状模型的系统能够只用1406张图片作为训练集，就超越了利用深度学习的800万图片达到的效果。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-c2ad6c875b8c9c77ca781b3f5534446e.png" data-rawwidth="629" data-rawheight="100"&gt;&lt;p&gt;所以当模型足够优化的时候可以大大减少对数据的需求量，而借鉴神经科学的发展无疑是一个有效的途径。&lt;/p&gt;&lt;p&gt;&lt;b&gt;迁移学习&lt;/b&gt;&lt;/p&gt;&lt;p&gt;传统的深度学习是以海量数据作为基础的，那么其后出现的就是增强学习。周伯通的左右互搏就像自己陪自己训练，Aiphago在训练神经网络的时候就是自己与自己下棋，这个就是增强学习的意义。除了深度学习和增强学习，还有一种学习方法被称为迁移学习（Transfer Learning）。&lt;/p&gt;&lt;p&gt;我们在创造的讨论中涉及到了迁移的概念，人类智能的特点之一就是将已经理解的抽象概念应用在广泛的领域，那么人工神经网络是不是也存在这样的能力？谷歌在谷歌翻译上应用了一个名为谷歌神经机器翻译（Google Neural Machine Translation，GNMT）的技术，就实现了类似人类的迁移学习能力。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-d3dfbe61bc41bb399d01be8238ace3b8.jpg" data-rawwidth="640" data-rawheight="338"&gt;&lt;p&gt;我们知道翻译专业的人除了要学习第一外语，比如英语外，还要学习第二外语，比如日语，那么如果这个翻译是非常好的话，自然而然就可以充当日本人与英国人之间的翻译，尽管他的母语是汉语。这个翻译并没有直接学习日语翻译到英语的过程，但是他学习过中英与中日的翻译，在这个学习的过程中他形成了超越语言特征本身的抽象概念，然后这种概念在不同语言之间自由切换。&lt;/p&gt;&lt;p&gt;谷歌的翻译技术实现了部分迁移学习，而这种能力也是未来人工智能技术的必然之路。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-c3db45ce9dd4c133e294b4ee0679ce54.jpg" data-rawwidth="640" data-rawheight="462"&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/24891079&amp;pixel&amp;useReferer"/&gt;</description><author>许铁-巡洋舰科技</author><pubDate>Sun, 15 Jan 2017 19:14:46 GMT</pubDate></item><item><title>深度学习助力基因科技</title><link>https://zhuanlan.zhihu.com/p/24837137</link><description>&lt;p&gt;有可能改变未来的一项技术之一是基因科技，据麦卡锡去年发布的一份报告，预计到2025年，全球将会累计产生10亿人次的全基因组数据，而检测基因的成本将下降到接近为0。考虑到每一个人的全基因组数据将会达到100G， 如何对这些海量数据的解读，现有的生物信息方法基于统计学模型，而12月20日在bioRvix（生物领域的论文预印本）上，来自谷歌子公司Deep mind 的科学家发表了一篇论文[1]，提出一个名为DeepVariant 的检测工具，使用深度神经学习中的卷积神经网络CNN 来检查基因组上的单碱基突变(SNP)和小的插入缺失(Indel)，其准确性超越了当前主流的生物信息学软件GATK。而在12月30日，来自康奈尔大学的另一组研究者又独立的发表了一篇用类似方法检测基因变异的软件[2]。两篇论文的爆发式出现，彰显了深度学习在基因组数据挖掘领域的巨大潜力。&lt;/p&gt;&lt;p&gt;每个人的体内都包含着3亿对碱基，这些碱基的排列方式决定了我们从生老病死的方方面面， 找到了你的基因组的差异之处，可以帮助我们了解我们的疾病的易感性，也可以知道我们的个体特征。对基因数据的传统分析方法，基于贝叶斯统计和专家的经验，针对不同的检测物种，需要很多人工的调节和试错，并且针对不同的测序平台，也需要进行特异性的配置。而基于深度学习的方法，巧妙的利用了图像识别领域成熟的技术，不止可以以通用的学习流程达到了现行软件相同的水平，更获得了由美国FDA 监管的SNP检测算法比赛的第一名 。由于这两项研究都还处于初期，考虑到深度学习算法巨大的提升空间，在可以预见的未来，基于深度学习的基因检测算法将会有更大的施展空间。&lt;/p&gt;&lt;p&gt;而在表观遗传学上，深度学习工具DeepCpG [3] 则可以根据基因序列预测单细胞层面是否会出现甲基化。在小鼠的胚胎干细胞上验证后，DeepCpG的表现优于现有的其他软件。甲基化会影响基因是否表达，而诸多启动子和增强子(DNA 序列中的调控区)与其调控的基因之间的相互作用则会影响基因的表达数量。同样是基于深度学习的SPEID [4] 基于基因序列预测启动子和增强子之间的相互作用，这是第一个基于基因序列来预测 启动子和增强子的软件，其效果优于基于基因功能做出的预测。&lt;/p&gt;&lt;p&gt;传统的基因组关联分析（GWAS）大多只能检测一个点突变（SNP）与所研究疾病的关系，而DeepWAS[5]，这一新提出的框架则能够根据功能单元，选择出一组SNP 的集合，来更加综合的研究治病的基因突变,并能直接的寻找调控区域的基因突变。在一项针对抑郁症的研究中，使用DeepWAS 框架的新研究发现了一个新的控制抑郁症的主要基因MEF2C。&lt;/p&gt;&lt;p&gt;以上列出的5项研究，都来自与2016年下半年，而在2017年1月，又有一篇基于CNN 的文章[6]尝试预测HLA基因与多肽的相互反应。这些文章虽然都来自于论文预印本，没有经过正规的同行审查，但不同领域的大规模井喷式爆发，也显示了该领域的巨大潜力。随着基因组数据的大量积累，以及深度学习开源平台的普及，未来深度学习必将成为生物信息领域的“一股清流”，为人类的健康做出贡献。&lt;/p&gt;&lt;p&gt;参考文献&lt;/p&gt;&lt;p&gt;[1] Creating a universal SNP and small indel variant caller with deep neural networks&lt;/p&gt;&lt;p&gt;[2] Training Genotype Callers with Neural Networks&lt;/p&gt;&lt;p&gt;[3] Accurate prediction of single-cell DNA methylation states using deep learning&lt;/p&gt;&lt;p&gt;[4] Predicting Enhancer-Promoter Interaction from Genomic Sequence with Deep Neural Networks&lt;/p&gt;&lt;p&gt;[5] DeepWAS: Directly integrating regulatory information into GWAS using deep learning supports master regulator MEF2C as risk factor for major depressive disorder&lt;/p&gt;&lt;p&gt;[6] HLA class I binding prediction via convolutional neural networks&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/24837137&amp;pixel&amp;useReferer"/&gt;</description><author>许铁-巡洋舰科技</author><pubDate>Wed, 11 Jan 2017 22:52:23 GMT</pubDate></item><item><title>2017定一个小目标，比如读完机器学习科普书单</title><link>https://zhuanlan.zhihu.com/p/24836490</link><description>&lt;p&gt;关于机器学习的书单，可以分为给业内人士的入门书单，给有一定基础的进阶书单，以及针对外行的科普书籍。这类科普书籍，会展示机器学习与其他学科的关联，从而能够带给不同学科背景的读者诸多启发。对于不了解这个行业的读者，阅读这类书，可以避免阅读碎片化的科普小文带来的缺少系统性了解的问题；而对于从业者，由于这些书多是由大师写成，其语句中多包涵言外之音，会给读者带来如打通任督二脉的豁然贯通感。霍金曾说，他的时间简史，每多一个公式，销量就会降低一半，所以今天推荐的这些书中都不会包含公式。&lt;/p&gt;&lt;p&gt;首先推荐的是《终极算法：机器学习和人工智能如何重塑世界》[The Master Algorithm]&lt;/p&gt;&lt;p&gt;这本书的名字，显示着作者试图在机器学习的各个流派间进行整合，最终提出机器学习里的“牛顿三定律”的理想。作者在这本书里，介绍了当前常用的算法的发展历程，这些算法包括决策树，遗传算法，神经网络，朴素贝叶斯及贝叶斯网络，隐式马尔可夫链，K最近邻及支持向量机，作者还介绍了无监督学习的算法。在介绍算法时，作者还介绍了机器学习里最大的两个阻碍，过拟合及维度灾难。&lt;/p&gt;&lt;p&gt;对上面的这些名词看不懂，看过书你就明白了。这本书中，没有公式与代码，有的只是对机器学习中的算法本质一针见血的点破，有的只是依据这些算法而编出的日常生活中的故事，是对机器学习中核心算法的概念化的模型。一言以概之，这是一本所有有高中数学水平且无计算机背景的读者都能够读懂的科普书。如果你不想对控制着我们衣食住行方方面面的机器学习算法一无所知，那么这本书是你必读的书。&lt;/p&gt;&lt;p&gt;人工智能之父马文·明斯基经典作品：情感机器+心智社会&lt;/p&gt;&lt;p&gt;这两本书的作者被誉为人工智能之父，不是因为他发现了某一个特别NB的算法。而是因为其对人类的认知过程有着独特的见解，从而能利用对人类认知的洞察来指导机器学习算法的研发。其在70年代写成的心智社会一书，令当前的人工智能研究者还会常读常新。这本书虽然价格有些高，但考虑到读一遍根本不指望能看懂，要看三遍才能有些领悟，算算阅读单价，就不算高的。再加上这本书送朋友，那是多么有逼格的一件事啊。&lt;/p&gt;&lt;p&gt;这本书是人工智能之父集一生功力写成的集大成之作。如何让机器有感情，是在机器智能即将超越人之后的人工智能的下一个天花板。情感计算的概念，也随着Chatbot（聊天机器人）而火了起来。阅读这本书，会让读者认识到情感不一定是人类独有的特征。情况也可以被表示为一连串的计算。而赋予机器情感，我们也能造成有常识，有直觉的机器。如果你想打破人工智能的黑盒子，这本书也是一本需要反复研读的大作。&lt;/p&gt;&lt;p&gt;科学的极致 漫谈人工智能 集智俱乐部&lt;/p&gt;&lt;p&gt;集智俱乐部有一群有激情有实力的小伙伴，其中既有来自学术界的张江教授，也有基于深度学习开发了彩云天气，彩云翻译等APP的创业者。而这本书则是集智众人的智慧结晶。这本书由于是中国人写成，所以避免了翻译作品的语言障碍。杨澜曾经在她的博客中推荐过这本书，说她从这本书中收获甚多，可见这本书是很容易读懂的。正如书名所显示，这本书涉及诸多人工智能领域。而书中诸多的插图，例子和参考文献则让这本书赢在了细节上。&lt;/p&gt;&lt;p&gt;机器之心 雷·库兹韦尔&lt;/p&gt;&lt;p&gt;奇点临近，尤其是当Alpha Go横扫围棋界的时候，又会被人再一次提起。而这个词就来自于本书的作者，著名未来学家雷·库兹韦尔。这本书中的预言究竟会不会实现，读者需要保持批判性的判断，不可人云亦云。而要批判性的提问，就先要读读原文，看看作者做了哪些价值性的假设，从而阅读后不止是脑洞大开，还能提升自己在面临未来注定层出不穷的人工智能的新闻时的判别能力。&lt;/p&gt;&lt;p&gt;数学之美&lt;/p&gt;&lt;p&gt;这本书虽然叫做数学之美，其实由于作者是谷歌的搜索专家，所以写的多半是自然语言处理领域的发展。关于这本书，溢美之词已经太多了。而我这里想说的不是其将算法背后的原理讲述的多么清晰，而是作者讲述了其和诸位自然语言处理领域的先驱的个人故事，其中描述了诸多学者的风骨以及其背后的道德力量。这是这本书少有被人提起，但却能令人记忆深刻的地方。&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/24836490&amp;pixel&amp;useReferer"/&gt;</description><author>许铁-巡洋舰科技</author><pubDate>Wed, 11 Jan 2017 21:59:50 GMT</pubDate></item><item><title>关于什么是大数据的一点思考</title><link>https://zhuanlan.zhihu.com/p/24773653</link><description>&lt;p&gt;借用三体中一句名言“给岁月以文明，而非给文明以岁月”大数据的本质，不是将生命献给数据，而是给数据以生命。大数据不是一套routine,不应限制了你思考的方向，那里数据多就分析那里，而应是内化的一套价值观及处事方式，用以对抗无常。&lt;/p&gt;&lt;p&gt;科学的进步，商业的发展，得益于数据所统领的疆域的扩展，随着之前越来越不可量化的变得可以计量，但这并不是要我们的丢弃直觉，忽视心智模式的作用，大数据带领我们关注用户购买了什么，也要求我们关注用户没有购买什么，并从用会的行为推测出用户为什么没有购买，亚马逊会根据你点击而未曾购买的记录给你推出个性化的deal，大数据要求我们了解整个行业的趋势，更要求关注每一人个性化的需求，Netflix不止靠大数据拍出《纸牌屋》，还将无数的小众电影准确的推荐给了用户。而你的关注点，应该是能将数据统合的那根线，能使数据产生整体大于局部之和的上层结构。这里的关注点，说的是数据分析前的需求分析，你需要这些数据做什么，你对数据的直觉反应是否可以通过这些数据进行完整全面的验证，没有回答好这些问题，拥有再多的数据也不过是一堆数字，一如果组排列整齐的感光器，而不是一个能分别美丑的眼眸。&lt;/p&gt;&lt;p&gt;数据的扩大不会必然带来视野和格局的扩大，一个朋友说起她分析"降关税"的感悟，她说道，如果逗留在税率本身，思路变死，只能接受竞争对手增多局面；如果挖掘到贸易自由化层面，格局变大，处处即是机遇；格局大小，决定对策，大格局涵盖小格局，小格局看上去不可思议，在大格局下都显得理所当然，她在bloomberge数据端倒弄半小时之后，意识到，相比这些数据库，wind都弱爆了。仅仅有国际化视野是不够的，更需要有国际化数据。而数据来源一旦多元，就一定要有去伪存真的步骤，去除重复，剔除噪音，清洗缺失值，使数据做的同步，准确，完整。这是当前数据处理中最耗时的步骤，而如何避免在数据清洗时过度补偿，如何避免丢弃过多有用数据，则是最需要智慧的。&lt;/p&gt;&lt;p&gt;大数据不是指数据量的大，也不是指数据来源的广（数据的维数大），而是指数据间的关系复杂（复杂网络的涌现），数据中既包含有用的信号，也包含无用的噪音。但不同维度的数据可以互相验证，互为因果，从而带来数据间的有序性。数据在不断的变化中，而变化的趋势又受制于你观察数据之外的环境因素，这环境因素具有自我指称的特性，也许数据之所以变化，就是因为你观察数据这一行为造成的。有序性就是负熵，就满足薛定谔说的生命的特征。&lt;/p&gt;&lt;p&gt;若你能知道何时需要收集数据，何时收集的足够的数据足够做决策了，那么你就孕育了一组数据，如果你能坚持不懈的更新数据，不放过数据间的细微变化，你就养育了一组数据，如果你能让你的数据与大千世界中那些鱼龙混杂的数据对上号，然后会心一笑，或是发现不同维度的数据带来了不同的结论，然后追根追底，那么你的数据就通过成人礼，如果你能及时的发现你拥有的数据已发生了Bifurcation，不可能通过小修小补来描述现实，那么你就可以安排这组数据的葬礼。你若有这样的态度，不论你的数据量有多大，处理数据的模型有多简单，你都拥有了大数据的灵魂。若是你只知道管中窥豹，以偏概全，如盲人摸象一般，那么数据量，数据维数，数据处理能力的增长只能同比扩大你的知识与谬误。&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/24773653&amp;pixel&amp;useReferer"/&gt;</description><author>许铁-巡洋舰科技</author><pubDate>Sun, 08 Jan 2017 08:25:56 GMT</pubDate></item><item><title>如何高效的学习</title><link>https://zhuanlan.zhihu.com/p/24760820</link><description>本文内容来自与一本书 《高效工作的秘密》，作者 Peter&lt;p&gt;既然要高效，首先需要的是&lt;b&gt;避免去做重复的工作&lt;/b&gt;，这意味着要在学习的每一步把基础打结实。而这就牵涉到本文的题目-磨刀不误砍柴工，即通过有意的制造不那么流畅的信息流动来学习。&lt;/p&gt;&lt;p&gt;首先先看14年普林斯顿的Pam Mueller发表了一项研究，比较了UCLA和普林斯顿学生不同的上课记笔记的方式对学习成绩的影响。研究者排除了用传统方法记笔记的学生在课下用功更多等其他因素的影响后发现，使用传统的纸和笔做笔记的学生比用笔记本的学生得A的比例多一倍。&lt;/p&gt;&lt;p&gt;该如何解释这一现象了。一种解释是用电脑记笔记的时候会有更多的干扰，比如弹出的电邮和SMS，但考虑到14年智能手机的普及，这个因素也不能解释全部效应。在论文中，作者给出的解释是，用纸和笔记笔记不如电脑打字快，用电脑记笔记的学生记下的笔记数量会是用笔来记录学生的两倍，然而用笔来记录的学生的笔记是有背景信息的。也就是说，正因为用手写字不如在电脑上打字那么快捷，促使学生主动去思考那些需要做笔记，而正是这些思考使得学生取得了好成绩。&lt;/p&gt;&lt;p&gt;进一步的研究发现，用纸来做笔记的学生的笔记会有更多的问句。他们会记录下学到的概念和知识可以用来回答那些问题。他们的笔记也会包含更多的图，这可能是因为在纸上画图比用电脑画图要方便。这是这些特征使得研究者总结道他们的笔记起到将知识连接起来的作用。&lt;/p&gt;&lt;p&gt;描述这个实验，是为了引出《Smarter Faster Better》这本书提出的高效学习之策，&lt;b&gt;主动的构建一个不那么流畅的信息接收通路&lt;/b&gt;。流畅的信息接收会让学习者以为自己已经学会了，从而不深挖一个概念的内涵。而不那么流畅的信息接收意味着学习者要不时停下来去想想该怎么用自己的话来重述新知，（用电脑记笔记的学生打字速度快，可以完整的写下教授说的话，一字不差。而用笔来做记录的学生却不得不用自己的话对教授所讲的去做缩写。正是这个过程使得学生对知识掌握的更深）&lt;/p&gt;&lt;p&gt;按照这本书提出的建议，高效学习的秘诀是下面几条&lt;/p&gt;&lt;p&gt;1 &lt;b&gt;用自己的话把学到的知识讲出来&lt;/b&gt;，最好用不同的方式和视角，这里是需要头脑风暴和跨界思维的地方。&lt;/p&gt;&lt;p&gt;2 在介绍每个知识点之前，说&lt;b&gt;清楚这个知识点回答了那些问题&lt;/b&gt;，给出的答案是否能将问题完全解决，这里需要清晰的逻辑，避免答非所问&lt;/p&gt;&lt;p&gt;3 强迫自己&lt;b&gt;为所学的知识点找出应用具体的应用场景&lt;/b&gt;，应用的场景可以是真实存在的两难 （dilemma），也可以是虚构的。每个场景需要包含when where who 和what，和所学的知识将用来说明why 或者how。&lt;/p&gt;&lt;p&gt;书中还给出了一种可以用来高效学习的游戏，这个游戏我们也许在聚会玩过的&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-09e7beb0a9ab4310dc688fece045890d.png" data-rawwidth="566" data-rawheight="555"&gt;比如你新学了一些机器学习的算法，你就可以和你小伙伴玩这个游戏，给出一个算法的集合，你们轮流问对方一系列Yes or No 的问题来猜出到底是哪一个算法，这个游戏能帮你理清不同概念间的关系。如果你想用更少的问题就猜出来，你必须掌握一个概念间真正能将其区分开的是什么。只有找到了每个知识最独特的一点，你才能在需要用到知识时快速建立起索引（避免提取不相关的信息）。只有在多个维度上都将知识进行了划分，才能将所需全部的知识点一网打尽。而这正是体现高效学习的成果的时候。最后要指出的是，学习是一个持续不断的过程，将学习的过程可以看成产品的&lt;b&gt;迭代&lt;/b&gt;，如同书中的表格所画，高效的学习如同精益创业一样，也需要造出一些Proof of Concept 的产品。正如记笔记，最好的笔记应该是在课上记下问题，画出概述图，下课后再将笔记补齐。最初的笔记是原型产品，不追求面面俱到，但要求能形成闭环，即包含问题，也包括分析和解决方案。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-b3cd2edd62af70011abdf3dc60377840.png" data-rawwidth="566" data-rawheight="376"&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/24760820&amp;pixel&amp;useReferer"/&gt;</description><author>许铁-巡洋舰科技</author><pubDate>Sat, 07 Jan 2017 08:39:37 GMT</pubDate></item><item><title>大咖征集令，不限学科，用你的Coursera证书实现知识变现</title><link>https://zhuanlan.zhihu.com/p/24760399</link><description>&lt;p&gt;看完罗胖的跨年演讲精华，我越发相信古人的那句话“技多不压身”，有信息过载，却绝对不会有技能过载，智慧过载。罗胖说得到想做最好的内容分发商，而在我眼中，最好的内容提供方却是下面的这三家&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-75a70bf6d900c1604de8e2fe3efc2d23.jpg" data-rawwidth="570" data-rawheight="288"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-47fdb854cfb33a4028733012b7855809.jpg" data-rawwidth="400" data-rawheight="300"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-c9940b499c840ece71a2734423c1c93a.png" data-rawwidth="400" data-rawheight="300"&gt;&lt;p&gt;为什么这么说，不止是因为这里的课程是来自于全球顶尖高校的第一手科学家，更因为最好的东西都不是免费的，不是交钱就能够得到的，而是要你先去花时间和精力去投入。在这方面，每个人都有着相同的起点。 下图是 董飞老师 讲述 MOOC 转化率较低时用到的图。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-3f0d4ad82aef9c94ed7c1262bc7712e1.jpg" data-rawwidth="640" data-rawheight="360"&gt;&lt;p&gt;所以说，每一个在在线教育平台拿到了证书的同学，都是万里挑一的学霸。如果你也是这样一位学霸，那么你可以用你的知识来变现，怎么办，请听我细细说来。&lt;/p&gt;&lt;p&gt;首先请您将您的MOOC证书截图（不管是上述的3个平台，还是其他的MOOC 平台的证书）+ 你对你学过的这门课程（任何专业的课程都可以的）的介绍以及你的学习心得总结成一篇小文 （500 字以上，最好附带一些截图或思维导图） + 你的分答账号或微信号（如果你愿意） + 你的自我介绍 发到邮箱 guoruidong517@126.com 。 在通过基本的资质审核后，我们会在 微信/微博/今日头条/知乎 上发布你的学习心得。之后你会成为这门课的TA， 如果读者觉得你修过的课程足够有趣，也愿意学习，那么Ta 在学习中遇到任何问题，都可以通过分答向你提问，而回答问题，即是温故而知新的过程，也是知识变现的过程。&lt;/p&gt;&lt;p&gt;不过知识分享不止是为了变现，还是为了自我提升。如果你的投稿被接受，你将可以进入巡洋舰的社群 参考&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651380856&amp;amp;idx=1&amp;amp;sn=dab774c3fc102149fe2e4ce7acc0e0f8&amp;amp;scene=21#wechat_redirect" data-editable="true" data-title="巡洋舰群001号体验报告" class=""&gt;巡洋舰群001号体验报告&lt;/a&gt;，如果你的MOOC课程 与数据科学或者计算机编程相关，我们还会推荐你去集智AI学园去做讲师，从而录制视频课程，实现进一步的知识变现。当然，如果你想去找实习，巡洋舰的社群从来都不缺少机会。&lt;/p&gt;&lt;p&gt;好了，就说这么多，有MOOC 证书的伙伴是不是已经跃跃欲试了，哪怕只是向更多人炫耀一下自己的证书，这个动机就足够了。再说一遍投稿邮箱 guoruidong517@126.com 邮件标题请注明 MOOC 证书+学习心得分享。&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/24760399&amp;pixel&amp;useReferer"/&gt;</description><author>许铁-巡洋舰科技</author><pubDate>Sat, 07 Jan 2017 04:48:47 GMT</pubDate></item><item><title>今年，我们一起来做一边做慈善一边做一个知识社群</title><link>https://zhuanlan.zhihu.com/p/24739084</link><description>&lt;p&gt;知识值多钱？无价。既然如此，那知识变现应该很容易吧。可不是吗？罗辑思维得到APP上那么多专栏作者不都做到了吗？更多知乎大牛不也正在做吗？&lt;/p&gt;&lt;p&gt;若你是这么想的，你就没有看清楚事情的本质。信息爆炸的时代，知识作为一种公共商品，本身因为缺少稀缺性是很难变现的。大V们提供的服务，是帮我们甄别信息，从而让我们能够在碎片时间，用更高的性价比得到浓缩后的知识。&lt;/p&gt;&lt;p&gt;然而如果你的认知架构没有给新的观点留出位置，没有搭好相应的框架，那么即使你接受到了高性价比的知识，也无法改变自己的为人做事的习惯。&lt;/p&gt;&lt;p&gt;所以我在过去的一年通过坚持写作来深挖自己的大脑，把那些杂草，那些不符合现代科学研究成果，缺乏逻辑严密性的部分去除掉，从而为自己接受新的观点做好“预实验”，我觉得这就是个人的认知管理的起点。比如 &lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651381741&amp;amp;idx=1&amp;amp;sn=790f0bcd936def79845952693f90f18a&amp;amp;chksm=84f3f1acb38478ba102eafc69810cc3fbd6acc00d6e88ad3b741a65c025eeee1d722ff43489f&amp;amp;scene=21#wechat_redirect" data-editable="true" data-title="当看只干货成为一种本能，你进步了多少" class=""&gt;当看只干货成为一种本能，你进步了多少&lt;/a&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651381885&amp;amp;idx=1&amp;amp;sn=3a743abefeba751cfb313bb12a27b696&amp;amp;chksm=84f3ce3cb384472afeb791a1973993d6c11f05f0c798147b526783b9e628cee3655f67edc27b&amp;amp;scene=21#wechat_redirect" data-editable="true" data-title="读这本书不会让你变聪明，但会让你避免犯错"&gt;读这本书不会让你变聪明，但会让你避免犯错&lt;/a&gt; 和&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651381838&amp;amp;idx=1&amp;amp;sn=faa997b762fda40415d4c195c590b10a&amp;amp;chksm=84f3ce0fb384471961b7196a07776b7f1ac47fea6f5d6d12cdd6a1891716b0832b6c9a2fb754&amp;amp;scene=21#wechat_redirect" data-editable="true" data-title="绞杀榕，黏鸟树自然界的生存之道能教给我们什么" class=""&gt;绞杀榕，黏鸟树自然界的生存之道能教给我们什么&lt;/a&gt;&lt;/p&gt;&lt;p&gt;将这一过程分享，希望更多的人来参与，这是我做这个公众号的本心。也想搞和读者的互动，比如&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=401961224&amp;amp;idx=1&amp;amp;sn=1654f80860bade4dddae51a8301c5a8c&amp;amp;scene=21#wechat_redirect" data-editable="true" data-title="读好书，要我们不只是说说而已&amp;lt;交叉学科好书读书召集令&amp;gt;"&gt;读好书，要我们不只是说说而已&amp;lt;交叉学科好书读书召集令&amp;gt;&lt;/a&gt; 后来觉得，让读者读完一本书，再写读书笔记，这有些门槛太高。&lt;/p&gt;&lt;p&gt;最近看到了“小密圈“这个工具，又动了做分享知识社群的念头。这个工具操作很方便，你只需要在微信里关注“小密圈” 公众号，就可以看到自己加入圈子的内容，不需要打开额外的应用。&lt;/p&gt;&lt;p&gt;相比于微信群，小密圈除了人数更多，其优点还在于对文件，这种半衰期相比于语音和聊天更长的形式能进行更方便的管理。对于较大一些的文件，也可以在小密圈而不是微信群中分享。使用者可以对群中的文件进行留言，方便针对每一个文件的讨论，还可对文件加入标签，便于索引和搜索。&lt;/p&gt;&lt;p&gt;在我们设想的知识社群中，我们会：&lt;/p&gt;&lt;p&gt;1）不定期分享 混沌巡洋舰群 参考&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651380856&amp;amp;idx=1&amp;amp;sn=dab774c3fc102149fe2e4ce7acc0e0f8&amp;amp;scene=21#wechat_redirect" data-editable="true" data-title="巡洋舰群001号体验报告"&gt;巡洋舰群001号体验报告&lt;/a&gt;中讨论的精华，分享的链接（带标签，介绍），有一些我想发到朋友圈的内容，怕刷屏打扰到别人的，都会发到这，当然少不了铁哥的心灵砒霜 参考&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651381792&amp;amp;idx=1&amp;amp;sn=f3c1774033999fa8786e0dc7ec977ce0&amp;amp;chksm=84f3ce61b3844777b7abb4bacbae9aa79e63323a2dd6347fe63ad6d5366e35d10abfa90760b7&amp;amp;scene=21#wechat_redirect" data-editable="true" data-title="铁哥行思录"&gt;铁哥行思录&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;2） 每周至少1次分享1组“得到APP或混沌研习社”上的优质音频（选自多个专栏及读书解读，但不限于一个专栏），每组长度1小时以上，争取做到结合一个话题，连接多个专栏的优质内容。&lt;/p&gt;&lt;p&gt;3） 不定期分享电子书或有声书或视频资源。&lt;/p&gt;&lt;p&gt;4） 可能涌现的其他好玩的东东&lt;/p&gt;&lt;p&gt;至于收费，就定在52元，50是这个平台允许的最小的收费值了，而加入一个知识社群，多少是有点2的行为吧，就自嘲一次吧。&lt;/p&gt;&lt;p&gt;这是我一个月之前的想法，然而之后我的想法变化了，我觉得知识社群不该这么搞，不该只有线上的交流，还应该有些落到实处的地方。我很欣赏Better Read 公众号 做的好书漂流活动，但我觉得这样的活动还不够去中心化，我希望在我这里的知识社群中，我希望再加入我自己设计的两个活动。&lt;/p&gt;&lt;p&gt;假设你有一本你打算分享（多本书也可以，省邮费的），你可以在这个社群中分享，之后如果有人对这本书感兴趣，可以留下地址，书的主人会将书以&lt;em&gt;到付&lt;/em&gt;的形式寄给你，想读这本书的人只需要出邮费，就可以得到一本或多本书。不过读者拿到书之后，每本书有两月的阅读时间，需要在两月之内对一本书提交一篇不小于300字的&lt;strong&gt;读书笔记&lt;/strong&gt;，（收到多本书的人可以有更多的时间来写读书笔记，每两月一本书的要求不高）否则会被移除出社群。这里管理员只需要记录什么时候读者收到了书，然后提前以群公告提醒读者写读书笔记就好。至于在这之中产生的读书笔记，如果读者愿意，我们都会发到巡洋舰的公众号和知乎专栏中。&lt;/p&gt;&lt;p&gt;但如果读者不只想写读书笔记，还想对更多人以&lt;strong&gt;群讲座&lt;/strong&gt;的形式讲一讲，那也可以在群里通过公告的形式来做分享，时间不少于10分钟就好。提前2天在社群中通知，分享之后主讲可以贴出自己的微信收钱二维码。这里不止限于读书报告的群讲座，你可以讲讲你所在的行业，讲讲你的见闻，这就是上面所说的可能涌现的其他好玩的东东。巡洋舰也会对群里的分享进行整理，发布在公众号和知乎专栏中。&lt;/p&gt;&lt;p&gt;以上的两件事，都是需要门槛的，所以要收费吗？这个逻辑不是这样的。小额的收费是验证诚意，而上面的活动必须要参与者能做到相互信任，你付过钱的东西，多少会在乎一些。但由于这个社群是要尽可能去中心化的，所以收到的钱将不能分给某一位大牛，所以收到的钱去做慈善，是最公平，也是最体现去中心化意图的选择。既然要做的是知识社群，那怎么能忘记了缺少知识的弱势群体了。所以每一位参与社群的人，我们都会拿出你所付的52元中的49元来&lt;strong&gt;做慈善&lt;/strong&gt;。（为什么是49元，因为小密圈提现时会收管一定比例理费的）。&lt;/p&gt;&lt;p&gt;关于做慈善，这是一件需要说几句的事。不是像罗一笑那样，也不是捐给大的基金会，而是由一群前华为人一对一的捐给山里的孩子，给她们提供书籍和过冬的棉衣。至于这件事，可以在网上查找“前华为人慈善捐助基金”，笔者参与过他们的活动，志愿者做事很认真，一对一的将善款送到当地孩子的手上，该机构还会提供明晰的收据。&lt;/p&gt;&lt;p&gt;好了，就说这么多，最后放上二维码，长按（或扫描）二维码入群，现在群里已有400多小伙伴了。加入后别忘了关注 小密圈 公众号，点击我的圈子，就可以看到每天分享的连接和消息了。或者也可以下载小密圈的APP，也可以参与知识社区的建立。&lt;/p&gt;&lt;p&gt;https://wx.xiaomiquan.com/mweb/views/joingroup/join_group.html?group_id=1484248542&amp;amp;secret=twnncv0z2iipl7c7jbdr192833707f71&amp;amp;extra=2c360470c8b4bac041b74044a9ed1dcfc63ca0730a98c98dd8e3be45862725af (二维码自动识别)&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/24739084&amp;pixel&amp;useReferer"/&gt;</description><author>许铁-巡洋舰科技</author><pubDate>Thu, 05 Jan 2017 22:13:31 GMT</pubDate></item><item><title>【巡洋舰首发】有趣的机器学习 第六章:如何用深度学习进行【语音识别】？</title><link>https://zhuanlan.zhihu.com/p/24703268</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-9852cb5c6c0693428ceb483cd84297dc_r.jpg"&gt;&lt;/p&gt;&lt;p&gt;原文：Adam Geitgey&lt;/p&gt;&lt;p&gt;原文链接：&lt;a href="https://medium.com/@ageitgey/machine-learning-is-fun-part-6-how-to-do-speech-recognition-with-deep-learning-28293c162f7a#.42h1r63ev" data-editable="true" data-title="medium.com 的页面"&gt;https://medium.com/@ageitgey/machine-learning-is-fun-part-6-how-to-do-speech-recognition-with-deep-learning-28293c162f7a#.42h1r63ev&lt;/a&gt;&lt;/p&gt;&lt;p&gt;翻译：巡洋舰科技——赵95&lt;/p&gt;&lt;p&gt;你是不是看烦了各种各样对于深度学习的报导，却不知其所云？我们要来改变这个问题。&lt;/p&gt;&lt;p&gt;有趣的机器学习 前五章已更新！点此查看&lt;a href="https://zhuanlan.zhihu.com/p/24339995" class="" data-editable="true" data-title="第一章：最简明入门指南"&gt;第一章：最简明入门指南&lt;/a&gt;、&lt;a href="https://zhuanlan.zhihu.com/p/24344720" class="" data-editable="true" data-title="第二章：用机器学习制造【超级马里奥】的关卡"&gt;第二章：用机器学习【制造超级马里奥】的关卡&lt;/a&gt;、&lt;a href="https://zhuanlan.zhihu.com/p/24524583" class="" data-editable="true" data-title="第三章：图像识别【鸟or飞机】"&gt;第三章：图像识别【鸟or飞机】&lt;/a&gt;&lt;a href="https://zhuanlan.zhihu.com/p/24567586" class="" data-editable="true" data-title="第四章：用深度进行【人脸识别】"&gt;第四章：用深度进行【人脸识别】&lt;/a&gt;&lt;a href="https://zhuanlan.zhihu.com/p/24590838" class="" data-editable="true" data-title="第五章：使用深度学习进行【语言翻译】和 序列的魔力"&gt;第五章：使用深度学习进行【语言翻译】和 序列的魔力&lt;/a&gt;&lt;a href="https://zhuanlan.zhihu.com/p/24703268" data-title="第六章：如何用深度学习进行【语音识别】" class="" data-editable="true"&gt;第六章：如何用深度学习进行【语音识别】&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;语音识别正在“入侵”我们的生活。它内置在我们的手机，游戏主机和智能手表里。它甚至在自动化我们的家园。只需50美元，你可以买到一个Amazon Echo Dot -
一个能够让你订购比萨，获知天气预报，甚至购买垃圾袋的魔术盒——只要你大声说出你的需求：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-3ffa4aec52021655b172e93e11d88274.jpg" data-rawwidth="1000" data-rawheight="552"&gt;&lt;/h2&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-3ffa4aec52021655b172e93e11d88274.jpg" data-rawwidth="1000" data-rawheight="552"&gt;&lt;p&gt;&lt;i&gt;Alexa，订一个大号的比萨！&lt;/i&gt;&lt;/p&gt;&lt;p&gt;Echo Dot机器人在（2016年圣诞）这个假期太受欢迎了，以至于Amazon似乎都没货了！&lt;/p&gt;&lt;p&gt;然而语音识别已经出现了几十年了，为何它才刚刚成为主流呢？原因是，深度学习，终于让语音识别，能够在非严格可控的环境下也能准确的识别。&lt;/p&gt;&lt;p&gt;吴恩达教授(百度首席科学家，人工智能和机器学习领域国际上最权威的学者之一，也是在线教育平台Coursera的联合创始人)长期以来预测，随着语音识别从95％精确度上升到99％，它将成为我们与计算机交互的主要方式。这个想法是基于，4％的精确度实际就是“太不靠谱”与“极度实用”之间的差别。感谢深度学习，我们终于达到了顶峰。&lt;/p&gt;&lt;p&gt;让我们了解一下如何用深度学习进行语音识别吧！&lt;/p&gt;&lt;p&gt;&lt;b&gt;机器学习并不总是一个黑盒&lt;/b&gt;&lt;/p&gt;&lt;p&gt;如果你知道&lt;a href="https://zhuanlan.zhihu.com/p/24590838" data-editable="true" data-title="神经机器翻译"&gt;神经机器翻译&lt;/a&gt;是如何工作的，那么你可能会猜到，我们可以简单地将声音送入到神经网络中，并训练使之生成文本：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-d347c3fae5f4e2bdc78bfbcd9259cacd.png" data-rawwidth="1000" data-rawheight="285"&gt;&lt;/p&gt;&lt;p&gt;这就是用深度学习进行语音识别的核心，但目前我们还没有完全做到（至少在我写这篇文章的时候没做到——我打赌，在未来的几年我们可以做到）。&lt;/p&gt;&lt;p&gt;最大的问题是言速不同。一个人可能很快的说“hello!”而另一个人可能会非常缓慢说“heeeelllllllllllllooooo!”。这产生了一个更长的声音文件和更多的数据。这两个声音文件都应该被识别为完全相同的文本“hello！”而事实证明，把各种长度的音频文件自动对齐到一个固定长度的文本是很难的一件事情。&lt;/p&gt;&lt;p&gt;为了解决这个问题，我们必须使用一些特殊的技巧和一些除了深度神经网络以外的特殊处理。让我们看看它是如何工作的吧！&lt;/p&gt;&lt;p&gt;&lt;b&gt;将声音转换成“位（&lt;/b&gt;&lt;b&gt;Bit&lt;/b&gt;&lt;b&gt;）”&lt;/b&gt;&lt;/p&gt;&lt;p&gt;语音识别的第一步是很显而易见的——我们需要将声波输入到计算机当中。&lt;/p&gt;&lt;p&gt;在&lt;a href="https://zhuanlan.zhihu.com/p/24524583" data-editable="true" data-title="第3章"&gt;第3章&lt;/a&gt;中，我们学习了如何把图像视为一个数字序列，以便我们直接将其输入进神经网络进行图像识别：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-1a8437a32c108cfe01bfa868d82a380d.jpg" data-rawwidth="581" data-rawheight="580"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;图像只是图片中每个像素深度的数字编码序列&lt;/i&gt;&lt;/p&gt;&lt;p&gt;但声音是作为&lt;b&gt;&lt;i&gt;波&lt;/i&gt;&lt;/b&gt;&lt;b&gt;&lt;i&gt;(Waves)&lt;/i&gt;&lt;/b&gt; 的形式传播的。我们如何将声波转换成数字呢？让我们使用我说的“hello”这个声音片段我们例子：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-6aad3a0f2fac76e461a557346435cbcb.png" data-rawwidth="1250" data-rawheight="379"&gt;&lt;/p&gt;&lt;p&gt;我说“hello”的波形&lt;/p&gt;&lt;p&gt;声波是一维的。（译者注：其实是二维的，有时间，还有振幅）在每个时刻，基于波的高度，它们有一个值(译者注：叫做振幅)。让我们把声波的一小部分放大看看：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-72f469ef60c261b6ba6c51d5b67f7d32.png" data-rawwidth="1250" data-rawheight="370"&gt;&lt;/p&gt;&lt;p&gt;为了将这个声波转换成数字，我们只记录声波在等距点的高度：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-926cf143d810e67eb3614e4318223e72.jpg" data-rawwidth="1250" data-rawheight="482"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;给声波采样&lt;/i&gt;&lt;/p&gt;&lt;p&gt;这被称为&lt;b&gt;&lt;i&gt;采样&lt;/i&gt;&lt;/b&gt;&lt;b&gt;&lt;i&gt;Sampling&lt;/i&gt;&lt;/b&gt;。我们每秒读取数千次，并把声波在该时间点的高度用一个数字记录下来。这基本上就是一个未压缩的.wav音频文件。&lt;/p&gt;&lt;p&gt;“CD音质”的音频是以44.1khz（每秒44,100个读数）进行采样的。但对于语音识别，16khz（每秒16,000个采样）的采样率足以覆盖人类语音的频率范围。&lt;/p&gt;&lt;p&gt;让我们把“Hello”的声波每秒采样16,000次。这是前100个采样：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-f011f9c607f2d99cf05e33e6572649dc.png" data-rawwidth="1250" data-rawheight="79"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;每个数字表示在一秒钟的&lt;/i&gt;&lt;i&gt;16000&lt;/i&gt;&lt;i&gt;分之一处的声波的振幅&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;数字采样小助手&lt;/b&gt;&lt;/p&gt;&lt;p&gt;你可能认为采样只是对原始声波进行粗略近似估计，因为它只是间歇性的读取。我们的读数之间有间距，所以我们会丢失数据，对吗？&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-4381d449423b9e4079e02ebb594219e9.png" data-rawwidth="1250" data-rawheight="535"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;数字采样能否完美重现原始声波？那些间距怎么办？&lt;/i&gt;&lt;/p&gt;&lt;p&gt;但是，由于&lt;b&gt;&lt;i&gt;采样定理&lt;/i&gt;&lt;/b&gt;&lt;b&gt;&lt;i&gt;(Nyquist theorem)&lt;/i&gt;&lt;/b&gt;，我们知道我们可以利用数学，从间隔的采样中完美的重建原始模拟声波——只要以我们希望得到的最高频率的两倍来采样就可以。&lt;/p&gt;&lt;p&gt;我提到这一点，是因为&lt;a href="http://gizmodo.com/dont-buy-what-neil-young-is-selling-1678446860" data-editable="true" data-title="几乎每个人都会犯这个错误"&gt;几乎每个人都会犯这个错误&lt;/a&gt;，并误认为使用更高的采样率总是能获得更好的音频质量。其实并不是。&lt;/p&gt;&lt;p&gt;&lt;b&gt;预处理我们的采样声音数据&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们现在有一个数列，其中每个数字代表16000分之一秒的声波振幅。&lt;/p&gt;&lt;p&gt;我们&lt;i&gt;可以&lt;/i&gt;把这些数字输入到神经网络中，但是试图直接分析这些采样来进行语音识别仍旧是困难的。相反，我们可以通过对音频数据进行一些预处理来使问题变得更容易。&lt;/p&gt;&lt;p&gt;让我们开始吧，首先将我们的采样音频分组为20毫秒长的块儿。这是我们第一个20毫秒的音频（即我们的前320个采样）：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-6378f673fb49bc8b806ae6a7af1aaa15.png" data-rawwidth="1250" data-rawheight="270"&gt;&lt;p&gt;将这些数字绘制为简单折线图，图中给出了20毫秒时间内原始声波的粗略估计：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-a6383b8f598750acd6aa3e473e791603.png" data-rawwidth="1250" data-rawheight="338"&gt;&lt;/p&gt;&lt;p&gt;虽然这段录音只有&lt;i&gt;50&lt;/i&gt;&lt;i&gt;分之一&lt;/i&gt;秒的长度，但即使这样短暂的时长也是由不同频率的声音复杂的组合在一起的。一些低音，中音，甚至高音混在一起。但总的来说，就是这些不同频率的声音混合在一起，才组成了人类的语音。&lt;/p&gt;&lt;p&gt;为了使这个数据更容易被神经网络处理，我们将把这个复杂的声波分解成一个个组件部分。我们将一步步分离低音部分，下一个最低音部分，以此类推。然后通过将（从低到高）每个频带中的能量相加，我们就为各个类别（音调）的音频片段创建了一个&lt;i&gt;指纹&lt;/i&gt;&lt;i&gt;fingerprint&lt;/i&gt;。&lt;/p&gt;&lt;p&gt;想象你有一段某人在钢琴上演奏C大调和弦的录音。这个声音是由三个音符组合而成的 - C，E和G – 他们都混合在一起组成一个复杂的声音。我们想把这个复杂的声音分解成单独的音符，以此来发现它们是C，E和G。这和我们（语音识别）的想法一样。&lt;/p&gt;&lt;p&gt;我们使用被称为&lt;i&gt;傅里叶变换&lt;/i&gt;&lt;i&gt;Fourier Transform&lt;/i&gt;的数学运算来做到这一点。它将复杂的声波分解为简单的声波。一旦我们有了这些单独的声波，我们将每一个包含的能量加在一起。&lt;/p&gt;&lt;p&gt;最终结果是每个频率范围的重要程度，从低音（即低音音符）到高音。下面的每个数字表示我们的20毫秒音频剪辑中每个50Hz频带中有多少能量：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-183c59db1dab03f2470b361502423c69.png" data-rawwidth="1250" data-rawheight="253"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;列表中的每个数字表示在&lt;/i&gt;&lt;i&gt;50Hz&lt;/i&gt;&lt;i&gt;频带中有多少能量&lt;/i&gt;&lt;/p&gt;&lt;p&gt;但是当你绘制一个图表时，你很容易看到这些能量：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-e3b95b07ac52830dbd035e54279eb839.png" data-rawwidth="1250" data-rawheight="178"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;你可以看到，我们的&lt;/i&gt;&lt;i&gt;20&lt;/i&gt;&lt;i&gt;毫秒声音片段中有很多低频率能量，然而在更高的频率中并没有太多的能量。这是典型“男性”的声音。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;如果我们对每20毫秒的音频块重复这个过程，我们最终会得到一个频谱图（每一列从左到右都是一个20ms的块）：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-405c35d00e5e82e30e5dff7fbd39050f.png" data-rawwidth="1250" data-rawheight="442"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;“&lt;/i&gt;&lt;i&gt;hello&lt;/i&gt;&lt;i&gt;”声音剪辑的完整谱图&lt;/i&gt;&lt;/p&gt;&lt;p&gt;频谱图很酷，因为你可以从音频数据中实际&lt;i&gt;看到&lt;/i&gt;音符和其他音高模式。对于神经网络来说，相比于原始声波，它可以更加容易地从这种数据中找到规律。因此，这就是我们将实际输入到神经网络的数据表示方式。&lt;/p&gt;&lt;p&gt;&lt;b&gt;从短声音识别字符&lt;/b&gt;&lt;/p&gt;&lt;p&gt;现在我们有了一个易于处理的格式的音频，我们将把它输入到深度神经网络中去。神经网络的输入将会是20毫秒的音频块。对于每个小的音频切片(Audio Slice)，它将试图找出当前正在说的声音对应的&lt;i&gt;字母（&lt;/i&gt;&lt;i&gt;letter&lt;/i&gt;&lt;i&gt;）&lt;/i&gt;。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-450c92d19922fe3b9f81be163c632cdc.png" data-rawwidth="1000" data-rawheight="602"&gt;&lt;/p&gt;&lt;p&gt;我们将使用一个循环神经网络 - 即一个拥有记忆来影响未来预测的神经网络。这是因为它预测的每个字母都应该能够影响下一个字母的预测可能性。例如，如果我们到目前为止已经说了“HEL”，那么很有可能我们接下来会说“LO”来完成“Hello”。我们不太可能会说“XYZ”之类根本读不出来的东西。因此，具有先前预测的记忆有助于神经网络对未来进行更准确的预测。&lt;/p&gt;&lt;p&gt;当我们通过神经网络运行我们的整个音频剪辑（一次一块）之后，我们将最终得到每个音频块和其最可能被说出的那个字母的一个映射（mapping）。这是一个看起来说”Hello”的映射：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-5740ab153ac140af0d2809d3b0da1b58.png" data-rawwidth="1250" data-rawheight="797"&gt;&lt;/p&gt;&lt;p&gt;我们的神经网络正在预测我说的那个词很有可能是“HHHEE_LL_LLLOOO”。但它同时认为我说的也可能是“HHHUU_LL_LLLOOO”，或者甚至是“AAAUU_LL_LLLOOO”。&lt;/p&gt;&lt;p&gt;我们遵循一些步骤来整理这个输出。首先，我们将用单个字符替换任何重复的字符：&lt;/p&gt;&lt;p&gt;HHHEE_LL_LLLOOO变为HE_L_LO&lt;/p&gt;&lt;p&gt;HHHUU_LL_LLLOOO变为HU_L_LO&lt;/p&gt;&lt;p&gt;AAAUU_LL_LLLOOO变为AU_L_LO&lt;/p&gt;&lt;p&gt;然后，我们将删除所有空白处：&lt;/p&gt;&lt;p&gt;HE_L_LO变为HELLO&lt;/p&gt;&lt;p&gt;HU_L_LO变为HULLO&lt;/p&gt;&lt;p&gt;AU_L_LO变为AULLO&lt;/p&gt;&lt;p&gt;这让我们得到三种可能的转录 - “Hello”，“Hullo”和“Aullo”。如果你大声说出这些词，所有这些声音都类似于“Hello”。因为它每次只预测一个字符，神经网络会得出一些试探性的转录。例如，如果你说“He would not go”，它可能会给一个可能 “He wud net go” 的转录。&lt;/p&gt;&lt;p&gt;解决问题的诀窍是将这些基于发音的预测与基于书面文本（书籍，新闻文章等）大数据库的可能性得分相结合。你抛弃掉最不可能的转录，而保留住最现实的转录。&lt;/p&gt;&lt;p&gt;在我们可能的转录“Hello”，“Hullo”和“Aullo”中，显然“Hello”将更频繁地出现在文本数据库中（更不用说在我们原始的基于音频的训练数据中），因此它可能是正确的。所以我们会选择“Hello” 而不是其他作为我们的最后的转录。完成！&lt;/p&gt;&lt;p&gt;&lt;b&gt;等一下！&lt;/b&gt;&lt;/p&gt;&lt;p&gt;你可能会想“但是如果有人说Hullo”怎么办？这是一个有效的词。也许“Hello”是错误的转录！&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-1b6af94ac603955ad4532f75b2c846e7.jpg" data-rawwidth="700" data-rawheight="467"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;“&lt;/i&gt;&lt;i&gt;Hullo&lt;/i&gt;&lt;i&gt;！&lt;/i&gt;&lt;i&gt;Who dis&lt;/i&gt;&lt;i&gt;？&lt;/i&gt;&lt;/p&gt;&lt;p&gt;当然可能有人实际上说“Hullo”而不是“Hello”。但是这样的语音识别系统（基于美国英语训练）基本上不会产生“Hullo”作为转录。用户说“Hullo”，它总是会认为你在说“Hello”，无论你发“U”的声音有多重。&lt;/p&gt;&lt;p&gt;试试看！如果你的手机被设置为美式英语，尝试让你的手机助手识别单词“Hullo”。这不行！它掀桌子不干了(╯‵□′)╯︵┻━┻！它总是会理解为“Hello”。&lt;/p&gt;&lt;p&gt;不识别“Hullo”是一个合理的行为，但有时你会发现令人讨厌的情况:你的手机就是不能理解你说的有效的语句。这就是为什么这些语音识别模型总是被更多的数据训练来修复这些少数情况。&lt;/p&gt;&lt;p&gt;&lt;b&gt;我能建立自己的语音识别系统吗？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;机器学习最酷炫的事情之一就是它有时看起来十分简单。你得到一堆数据，把它输入到机器学习算法当中去，然后就能神奇的得到一个运行在你的游戏笔记本电脑的显卡上的世界级AI系统...&lt;i&gt;对吧&lt;/i&gt;？&lt;/p&gt;&lt;p&gt;这在某些情况下是真实的，但对于语音识别并不成立。语音识别是一个困难的问题。你必须克服几乎无限的挑战：质量差的麦克风，背景噪音，混响和回声，口音变化，还有很多很多。所有这些问题都需要存在于你的训练数据中，以确保神经网络可以应对它们。&lt;/p&gt;&lt;p&gt;这里有另外一个例子：你知不知道，当你在一个充满噪音的房间里说话时，你不自觉地提高你的音调，以便能够盖过噪音。人类在什么情况下都可以理解你，但神经网络需要训练来处理这种特殊情况。所以你需要人们对着噪音大声说话的训练数据！&lt;/p&gt;&lt;p&gt;要构建一个能在Siri，Google Now！或Alexa等平台上运行的语音识别系统，你将需要&lt;i&gt;大量&lt;/i&gt;的训练数据 -如果你不雇佣数百人为你录制的话，它需要的训练数据比你自己能够获得的数据要多得多。由于用户对低质量语音识别系统的容忍度很低，因此你不能吝啬。没有人想要一个只有80%的时间有效的语音识别系统。&lt;/p&gt;&lt;p&gt;对于像谷歌或亚马逊这样的公司，在现实生活中记录的数十万小时的人声语音就是&lt;i&gt;黄金&lt;/i&gt;。这就是将他们世界级语音识别系统与你自己的系统拉开差距的地方。让你免费使用&lt;i&gt;Google Now!&lt;/i&gt;或Siri或只要50美元购买Alexa而没有订阅费的意义就是：&lt;b&gt;&lt;i&gt;让你尽可能多的使用他们&lt;/i&gt;&lt;/b&gt;。你对这些系统所说的每一句话都会&lt;b&gt;&lt;i&gt;永远记录&lt;/i&gt;&lt;/b&gt;下来，并用作未来版本语音识别算法的训练数据。这才是他们的真实目的！&lt;/p&gt;&lt;p&gt;不相信我？如果你有一部安装了Google Now!的Android手机，请&lt;a href="https://myactivity.google.com/udc/vaa" data-editable="true" data-title="点击这里"&gt;点击这里&lt;/a&gt;收听你自己对它说过的每一句话：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-36f57014e18b8cb9968b9327fc7f0bc7.png" data-rawwidth="1000" data-rawheight="501"&gt;&lt;/p&gt;&lt;p&gt;你可以通过Alexa在Amazon上找到相同的东西。然而，不幸的是，苹果并不让你访问你的Siri语音数据。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;因此，如果你正在寻找一个创业的想法，我不建议你尝试建立自己的语音识别系统来与Google竞争。相反，你应该找出一种能让人们把他们说几个小时话的录音给予你的方法。这种数据可以是你的产品。&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;路在远方&lt;/b&gt;&lt;b&gt;…&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这个用来处理不同长度音频的算法被称为Connectionist Temporal Classification或CTC。&lt;a href="goog_970985545" data-editable="true" data-title="你可以阅读"&gt;你可以阅读&lt;/a&gt;&lt;a href="http://www.cs.toronto.edu/~graves/icml_2006.pdf" data-editable="true" data-title="2006年文章"&gt;2006年文章&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;百度的Adam Coates在湾区深度学习学校做了关于“深度学习语音识别”的精彩演讲。你可以在YouTube上&lt;a href="https://youtu.be/9dXiAecyJrY?t=13874" data-editable="true" data-title="观看这段视频"&gt;观看这段视频&lt;/a&gt;（他的演讲从3分51秒开始）。强烈推荐。&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/24703268&amp;pixel&amp;useReferer"/&gt;</description><author>九五要当学霸</author><pubDate>Wed, 04 Jan 2017 10:22:57 GMT</pubDate></item><item><title>【巡洋舰首发】有趣的机器学习 第五章：使用深度学习进行【语言翻译】 和 序列的魔力</title><link>https://zhuanlan.zhihu.com/p/24590838</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-14ed4f1b20aea7acc67d5ad1aeee408e_r.jpg"&gt;&lt;/p&gt;&lt;p&gt;原文：Adam Geitgey&lt;/p&gt;&lt;p&gt;原文链接：&lt;a href="https://medium.com/@ageitgey/machine-learning-is-fun-part-5-language-translation-with-deep-learning-and-the-magic-of-sequences-2ace0acca0aa#.t5upusfij" class="" data-editable="true" data-title="medium.com 的页面"&gt;https://medium.com/@ageitgey/machine-learning-is-fun-part-5-language-translation-with-deep-learning-and-the-magic-of-sequences-2ace0acca0aa#.t5upusfij&lt;/a&gt;&lt;/p&gt;&lt;p&gt;翻译：巡洋舰科技——赵95&lt;/p&gt;&lt;p&gt;你是不是看烦了各种各样对于深度学习的报导，却不知其所云？我们要来改变这个问题。&lt;/p&gt;&lt;p&gt;有趣的机器学习 前六章已更新！点此查看&lt;a href="https://zhuanlan.zhihu.com/p/24339995" class="" data-editable="true" data-title="第一章：最简明入门指南"&gt;第一章：最简明入门指南&lt;/a&gt;、&lt;a href="https://zhuanlan.zhihu.com/p/24344720" class="" data-editable="true" data-title="第二章：用机器学习制造【超级马里奥】的关卡"&gt;第二章：用机器学习【制造超级马里奥】的关卡&lt;/a&gt;、&lt;a href="https://zhuanlan.zhihu.com/p/24524583" class="" data-editable="true" data-title="第三章：图像识别【鸟or飞机】"&gt;第三章：图像识别【鸟or飞机】&lt;/a&gt;&lt;a href="https://zhuanlan.zhihu.com/p/24567586" class="" data-editable="true" data-title="第四章：用深度进行【人脸识别】"&gt;第四章：用深度进行【人脸识别】&lt;/a&gt;&lt;a href="https://zhuanlan.zhihu.com/p/24590838" class="" data-editable="true" data-title="第五章：使用深度学习进行【语言翻译】和 序列的魔力"&gt;第五章：使用深度学习进行【语言翻译】和 序列的魔力&lt;/a&gt;&lt;a href="https://zhuanlan.zhihu.com/p/24703268" data-title="第六章：如何用深度学习进行【语音识别】" class="" data-editable="true"&gt;第六章：如何用深度学习进行【语音识别】&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;我们都知道并且喜欢使用Google翻译，这个网站可以瞬时翻译100种不同的人类语言，就好像有魔法一样。他甚至存在于我们的手机和智能手表上面：（知乎无法上传太大的GIF，看图请戳原文）&lt;/h2&gt;&lt;p&gt;Google翻译背后的科技被称为机器翻译。它改变了世界，在本来根本不可能的情况下让(不同语言的)人们完成了沟通。&lt;/p&gt;&lt;p&gt;但我们都知道，在过去的15年里，高中学生已经使用Google翻译...额 ...&lt;i&gt;协助&lt;/i&gt;他们完成他们的西班牙语作业。这已经不是新闻了…？&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-a9fcbd775a70567a8d49ea73e42f4358.jpg" data-rawwidth="853" data-rawheight="192"&gt;&lt;/p&gt;&lt;p&gt;事实证明，在过去两年，深度学习已经完全改写了我们的机器翻译方法。那些对语言翻译一无所知的深度学习研究人员正在利用一个个相对简单的机器学习解决方案，来打败世界上最好的专家建造的语言翻译系统。&lt;/p&gt;&lt;p&gt;这一突破背后的技术被称为&lt;b&gt;序列到序列学习&lt;/b&gt;&lt;b&gt;sequence to sequence learnin&lt;/b&gt;g。这是一项非常强大的技术，被用于解决许多种类的问题。在我们看到它如何被用于翻译之后，我们还将学习这个算法是怎样用来编写AI聊天机器人和描述图片的。&lt;/p&gt;&lt;p&gt;我们开始吧！&lt;/p&gt;&lt;p&gt;&lt;b&gt;让计算机翻译&lt;/b&gt;&lt;/p&gt;&lt;p&gt;那么我们该如何编写代码，才能让计算机翻译人类的语言呢？&lt;/p&gt;&lt;p&gt;最简单的方法，就是把句子中的每个单词，都替换成翻译后的目标语言单词。这里有一个简单的例子，把西班牙语逐字翻译成英语：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-db380a8bf032afa9533d358389de99d6.png" data-rawwidth="1000" data-rawheight="180"&gt;&lt;/p&gt;&lt;p&gt;我们只是用匹配的英语单词替换每个西班牙单词。&lt;/p&gt;&lt;p&gt;这很容易实现，因为你所需要是一本字典来查找每个单词的翻译。但结果并不好，因为它忽略了语法和上下文的联系。&lt;/p&gt;&lt;p&gt;因此，下一件你可能要做的事，就是开始添加特定语言规则以改进结果。例如，你可能将两个常用词翻译为词组。你可能互换名词和形容词的顺序，因为他们在西班牙语中以相反的顺序出现：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-bed5ad249e62bea5ac3958c725dd0160.png" data-rawwidth="1000" data-rawheight="250"&gt;&lt;/p&gt;&lt;p&gt;这真的有效！如果我们就继续添加更多的规则，直到我们可以应对每一部分语法，我们的程序应该就能够翻译任何句子了，对吧？&lt;/p&gt;&lt;p&gt;这就是最早的机器翻译系统的工作原理。语言学家提出了许多复杂的规则，并逐一编程实现。一些世界上最聪明的语言学家在冷战期间辛勤努力了多年，才创建出了一些更容易理解俄罗斯人交流的翻译系统。&lt;/p&gt;&lt;p&gt;不幸的是，这种套路只对简单问题适用，比如说像天气预报这样结构简单的文档。它对于真实世界的文字来说并不可靠。&lt;/p&gt;&lt;p&gt;问题是，人类语言并不总是遵循固定的规则。人类语言充满了各种特殊情况，区域差异，或者干脆就不按套路出牌(#‵′)凸。我们说英语的方式更多地受到几百年前入侵的人的影响，而不是由坐下来定义语法规则的人。&lt;/p&gt;&lt;p&gt;&lt;b&gt;利用统计数据使计算机更好地翻译&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在基于规则的系统失效之后，一些新的翻译方法被开发出来了，他们基于概率和统计的模型而不是语法规则。&lt;/p&gt;&lt;p&gt;建造一个基于统计的翻译系统需要大量的训练数据，其中完全相同的文本被翻译成至少两种语言。这种双重翻译的文本称为&lt;b&gt;&lt;i&gt;平行语料库parallel corpora&lt;/i&gt;&lt;/b&gt;。18世纪的科学家以同样的方式在罗塞塔石碑上面从希腊语中找出埃及象形文字。(译者注：罗塞塔石碑，高1.14米，宽0.73米，制作于公元前196年，刻有&lt;a href="http://baike.baidu.com/view/8498.htm" data-editable="true" data-title="古埃及"&gt;古埃及&lt;/a&gt;国王&lt;a href="http://baike.baidu.com/view/192409.htm" data-editable="true" data-title="托勒密五世"&gt;托勒密五世&lt;/a&gt;登基的诏书。石碑上用&lt;a href="http://baike.baidu.com/view/11761660.htm" data-editable="true" data-title="希腊文字"&gt;希腊文字&lt;/a&gt;、&lt;a href="http://baike.baidu.com/view/138248.htm" data-editable="true" data-title="古埃及文字"&gt;古埃及文字&lt;/a&gt;和当时的通俗体文字刻了同样的内容，这使得近代的&lt;a href="http://baike.baidu.com/view/67249.htm" data-editable="true" data-title="考古学家"&gt;考古学家&lt;/a&gt;得以有机会对照各语言版本的内容后，解读出已经失传千余年的埃及象形文之意义与结构，而成为今日研究古埃及历史的重要里程碑)以同样的方式，计算机可以使用平行语料库猜测如何将文本从一种语言转换为另一种语言。&lt;/p&gt;&lt;p&gt;幸运的是，有很多双重翻译的文本已经存在在世界的各个角落。例如，欧洲议会将其诉讼程序翻译成21种语言。因此，研究人员经常使用这些数据来帮助建造翻译系统。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-8405085e2a71fe599a8a0365b8a61596.png" data-rawwidth="1000" data-rawheight="167"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;训练数据通常令人兴奋！但这只是无数条政府文件而已...&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;用概率的思维思考&lt;/b&gt;&lt;/p&gt;&lt;p&gt;统计翻译系统的根本不同，在于它们试图生成不止一个精确的翻译。相反，他们生成成千上万种可能的翻译，然后他们按照可能最正确的给这些翻译排名。他们通过与训练数据的相似性来估计有多“正确”。以下是它的工作原理：&lt;/p&gt;&lt;p&gt;&lt;b&gt;第1步：将原始句子分成块&lt;/b&gt;&lt;/p&gt;&lt;p&gt;首先，我们将我们的句子分成简单的块，每一块都可以轻松翻译：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-ec2cc836a5ae27ee35ed01a912036d31.png" data-rawwidth="1000" data-rawheight="87"&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;第2步：找到每一块的所有可能的翻译&lt;/b&gt;&lt;/p&gt;&lt;p&gt;接下来，我们将翻译每块文字，我们将通过寻找我们数据库中所有人类翻译过的相同词块来完成我们的翻译。&lt;/p&gt;&lt;p&gt;要着重注意的是，我们不只是在一本简简单单的翻译字典中查找这些词块。相反，我们看到是真实的人在真实的句子中如何翻译这些相同的词。这有助于我们捕获到在不同语境中所有不同的表达方式：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-4a56bab19fc10b4fd4f52cc2cf9351b5.png" data-rawwidth="1000" data-rawheight="471"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;即使最常见的短语也有很多种可能的翻译&lt;/i&gt;&lt;/p&gt;&lt;p&gt;这些可能的翻译中的有一些会比其他翻译更频繁地使用。根据我们训练数据中每个翻译出现的频率，我们可以给它设定一个分数。&lt;/p&gt;&lt;p&gt;例如，有人说“Quiero”更多的时候是指“我想要”而不是“我尝试”。所以，我们可以使用我们训练数据中 “Quiero”被翻译成“我想要”的频率，给“我想要”这个翻译更多的权重。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第3步：生成所有可能的句子，找到最有可能的那句&lt;/b&gt;&lt;/p&gt;&lt;p&gt;接下来，我们将使用这些词块的每种可能翻译来组合生成一堆可能的句子。&lt;/p&gt;&lt;p&gt;从第二步中列出的翻译过的词块中，我们可以通过不同组合方式生成将近2,500个不同的句子。下面是一些例子：&lt;/p&gt;&lt;p&gt;&lt;i&gt;I love | to leave | at | the seaside | more tidy.&lt;/i&gt;&lt;i&gt;I mean | to be on | to | the open space | most lovely.I like | to be |on | per the seaside | more lovely.I mean | to go | to | the open space | most tidy.&lt;/i&gt;&lt;/p&gt;&lt;p&gt;但在真实世界中，因为有不同的语序和词块分解方法，所以实际上有更多可能的词块组合：&lt;/p&gt;&lt;p&gt;&lt;i&gt;I try | to run | at | the prettiest | open space.&lt;/i&gt;&lt;i&gt;I want | to run | per | the more tidy | open space.I mean | to forget | at | the tidiest | beach.I try | to go | per | the more tidy | seaside.&lt;/i&gt;&lt;/p&gt;&lt;p&gt;现在需要扫描所有这些生成的句子，找到那个听起来“最像人话”的句子。&lt;/p&gt;&lt;p&gt;为此，我们将每个生成的句子与来自英语书籍和新闻故事的数百万个真实句子进行比较。我们拥有的英语文本越多越好。&lt;/p&gt;&lt;p&gt;我们采用这种可能的翻译：&lt;/p&gt;&lt;p&gt;&lt;i&gt;I try | to leave | per | the most lovely | open space.&lt;/i&gt;&lt;/p&gt;&lt;p&gt;很可能没有人用英语写过这样的句子，所以它不会与我们的数据库任何句子非常相似。我们给这个可能的翻译设定一个低概率的得分。&lt;/p&gt;&lt;p&gt;但看看下面这个可能的翻译：&lt;/p&gt;&lt;p&gt;&lt;i&gt;I want | to go | to | the prettiest | beach.&lt;/i&gt;&lt;/p&gt;&lt;p&gt;这个句子和我们的训练集中的句子很类似，所以它将获得一个高概率的得分。&lt;/p&gt;&lt;p&gt;在尝试过所有可能的句子之后，我们会选择那个，既是最有可能的词块翻译，又与真实英语句子最相似，的句子。&lt;/p&gt;&lt;p&gt;我们最后的翻译将是“&lt;i&gt;I want | to go | to | the prettiest | beach.&lt;/i&gt;&lt;/p&gt;&lt;p&gt;我想去最漂亮的海滩。”不错！&lt;/p&gt;&lt;p&gt;&lt;b&gt;有里程碑意义的统计机器翻译&lt;/b&gt;&lt;/p&gt;&lt;p&gt;当有足够多的训练数据的时候，统计机器翻译系统的性能要优于基于语言规则的系统。 Franz Josef Och基于这些想法并做出了改进，并在21世纪初使用它们构建了Google翻译。机器翻译终于可以被全世界使用。&lt;/p&gt;&lt;p&gt;早期的时候，基于概率翻译的“愚蠢”方法居然比语言学家设计规则系统做的更好，这让每个人都感到惊讶。这导致了80年代的时候，研究人员会(有点刻薄的)说：&lt;/p&gt;&lt;p&gt;“每当我炒了一个语言学家鱿鱼的时候，我的翻译准确度就会上升。” &lt;a href="https://en.wikipedia.org/wiki/Frederick_Jelinek" data-editable="true" data-title="Frederick Jelinek"&gt;&lt;i&gt;Frederick Jelinek&lt;/i&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;统计机器翻译的局限性&lt;/b&gt;&lt;/p&gt;&lt;p&gt;虽然统计机器翻译系统效果还不错，但是他们难于构建和维护。每一对需要翻译的新语言，都需要专业人士对一个全新的多步骤“翻译流水线”进行调试和修整。&lt;/p&gt;&lt;p&gt;因为构建这些不同的流水线需要做太多工作，所以我们必须进行权衡。如果你要用Google翻译把格鲁吉亚语翻译成泰卢固语（印度东部德拉维拉语言），那么作为一个中间步骤，它必须先翻译成英语。因为并没有太多格鲁吉亚到泰卢固语的翻译需求，所以在这一对语言上投入太多并没有太大意义。相比于英语翻译到法语，它可能会使用一个更低级的“翻译流水线”。&lt;/p&gt;&lt;p&gt;如果我们能让计算机为我们做所有令人讨厌的开发工作，这不更好么？&lt;/p&gt;&lt;p&gt;&lt;b&gt;让电脑翻译的更好——无需昂贵的专家们&lt;/b&gt;&lt;/p&gt;&lt;p&gt;机器翻译的核心是一个黑盒系统，它通过查看训练数据，自己就可以学习如何翻译。使用统计机器翻译，人们仍然需要建立和调整多步骤的统计模型。&lt;/p&gt;&lt;p&gt;2014年，KyungHyun Cho的团队取得了突破。他们发现了一种应用深度学习来构建这种黑盒系统的方法。他们的深度学习模型采用平行语料库，并使用它来学习如何在无任何人为干预的情况下在这两种语言之间进行翻译。&lt;/p&gt;&lt;p&gt;两个宏伟的方法使这成为可能 - 循 环神经网络和编码。通过巧妙地结合这两个想法，我们可以建立一个能够自学的翻译系统。&lt;/p&gt;&lt;p&gt;&lt;b&gt;循环神经网络&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们已经在第2章讨论过了循环神经网络，让我们快速回顾一下。&lt;/p&gt;&lt;p&gt;一个常规（非循环）神经网络是泛型机器学习算法，接收一序列数字并计算结果（基于先前的训练）。神经网络可以用作一个黑盒子，来解决很多问题。例如，我们可以基于房子的属性，使用神经网络来计算房屋的近似价格：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-6ea7212dd6e34f5ed60eec35acb7c756.png" data-rawwidth="860" data-rawheight="389"&gt;&lt;/p&gt;&lt;p&gt;但是像大多数机器学习算法一样，神经网络是无状态(Stateless)的。你输入一序列数字，神经网络计算并输出结果。如果再次输入相同的数字，它总是计算出相同的结果。它没有进行过的计算的记忆。换句话说，2 + 2总是等于4。&lt;/p&gt;&lt;p&gt;一个&lt;b&gt;循环神经网络（Recurrent Neural Network或简称RNN）&lt;/b&gt;是一个稍微改进过的神经网络的版本，区别是RNN先前的状态是可以被当做输入，再次带入到下一次计算中去。这意味着之前的计算结果会更改未来计算的结果！&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-d164b6165ed48bef689a837f6a70aca0.png" data-rawwidth="860" data-rawheight="556"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;人类痛恨他：一个黑科技就让机器变得更聪明！&lt;/i&gt;&lt;/p&gt;&lt;p&gt;我们为什么要这样做？无论我们上次计算结果是什么，2 + 2不应该总是等于4么？&lt;/p&gt;&lt;p&gt;这个技巧允许神经网络学习数据序列中的规律。例如，基于句子的前几个词，你可以使用它来预测句子中下一个最有可能的单词是什么：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-4c999bbcdf7e7ce9a691ce76438064de.jpg" data-rawwidth="887" data-rawheight="530"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;实现智能手机输入法的“自动更正”的方法之一&lt;/i&gt;&lt;i&gt;…&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;当你想要学习数据中的规律时，RNN将会非常有用。因为人类语言其实只是一个大而复杂的“规律”，自然语言处理的各个领域越来越多地使用RNN。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;如果你想了解更多关于RNN，你可以阅读第2章，我们使用了RNN来生成一本海明威写作风格的假书，然后使用同一个RNN生成了超级马里奥兄弟的游戏关卡。&lt;/p&gt;&lt;p&gt;&lt;b&gt;编码&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们需要回顾的另一个想法是&lt;b&gt;&lt;i&gt;编码Encoding&lt;/i&gt;&lt;/b&gt;。在第4章中作为脸部识别的一部分，我们谈到了编码。为了解释编码，让我们稍作调整，了解一下如何用电脑区分两个人。&lt;/p&gt;&lt;p&gt;当你试图用电脑区分两张脸时，你从每张脸收集不同的测量值，并与其他脸部比较这些测量值。例如，我们可以测量耳朵的大小或眼间的间距，比较两个图片的测量值以确定他们是否是同一个人。&lt;/p&gt;&lt;p&gt;你可能已经从观看热门影视剧CSI当中对这个想法耳熟能详了（知乎无法上传太大的GIF，看图请戳原文）。&lt;/p&gt;&lt;p&gt;把面部特征转换为一系列测量值的想法就是编码的例子之一。我们获取到原始数据（面部图片），并将其转换为代表这张脸的一系列测量值（编码）。&lt;/p&gt;&lt;p&gt;但是像我们在第4章中看到的，我们不必提出一个具体的面部特征列表来测量我们自己。相反，我们可以使用神经网络，让它自动从面部生成测量值。找出哪些测量值能够区分两个相似的人，计算机在这方面比我们做的更好：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-6e2b5cfcbd33b1105a4d8d40191c162d.png" data-rawwidth="1000" data-rawheight="499"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;这些是由神经网络产生的面部特征测量值，训练后的该神经网络可以保证不同的数字代表了不同人的面部。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;这是我们的&lt;i&gt;编码&lt;/i&gt;。它让我们用简单的东西（128个数字）代表非常复杂的东西（一张脸的图片）。现在比较两张脸更加容易了，因为我们只需要比较这128个数字而不是比较整张脸的图像。&lt;/p&gt;&lt;p&gt;你猜怎么着？我们可以用句子做同样的事情！我们可以把任何一个句子表达成一系列独特的编码：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-4fa1d6823b59d61bc84d290f4cf8adeb.png" data-rawwidth="1000" data-rawheight="479"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;这一序列数字代表的是英语句子“有趣的机器学习！”。不同的句子将由不同的数字集表示。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;为了生成这个编码，我们将句子输入到RNN中，一次一个词。最后一个词处理之后的最终结果，就将是表示整个句子的数值：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-520f649f58b1d522f1c38ff49153c590.jpg" data-rawwidth="877" data-rawheight="395"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;因为RNN具有记忆功能，能够记住处理过得每个词，所以它计算的最终编码表示句子中的所有词。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;棒极了，所以现在我们有一种方法来把一个整个句子表示成一组独特的数字！我们不知道编码中的每个数字是什么意思，但这并不重要。只要每一句话都能由一组独特的数字标识出来，那么我们就不需要准确地知道这些数字是如何生成的。&lt;/p&gt;&lt;p&gt;&lt;b&gt;让我们开始翻译吧！&lt;/b&gt;&lt;/p&gt;&lt;p&gt;好的，所以我们知道怎样使用RNN去个一句话编码并生成一组独特的数字。它有什么用呢？事情从这儿开始变得酷炫了！&lt;/p&gt;&lt;p&gt;如果我们使用两个RNNs并将它们首尾相连呢？第一个RNN可以给句子生成编码。然后，第二RNN遵循相反的逻辑，解码得到原始句子：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-473f0ea39bfa46879f0975c77272b8c8.png" data-rawwidth="1250" data-rawheight="336"&gt;&lt;/p&gt;&lt;p&gt;当然，编码然后再解码并得到原始语句并没有太大用处。但是如果（这里是问题的关键），我们训练第二个RNN，使它解码成西班牙语而不是英语，这会怎样？我们可以使用平行语料库训练数据来训练它：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-04ff81324066f8cc916e3b9773808cc9.png" data-rawwidth="1250" data-rawheight="334"&gt;&lt;/p&gt;&lt;p&gt;就像这样，我们有一个通用的方法，将一序列英语单词转换成同样的西班牙语单词序列！&lt;/p&gt;&lt;p&gt;这是一个强有力的想法：&lt;/p&gt;&lt;p&gt;l 这种方法主要受限于你拥有的训练数据量和你可以投入的计算机生产力。机器学习研究人员仅仅在在两年前发明了这个方法，但它已经表现的和统计机器翻译系统一样好了，而后者花了20年时间才开发完善。&lt;/p&gt;&lt;p&gt;l 这不依赖于任何关于人类语言规则的了解。算法自己计算出这些规则。这意味着你不需要专业人士来调整“翻译流水线”的各个步骤，计算机为你把这个做好了。&lt;/p&gt;&lt;p&gt;l 这种方法适用于几乎任何种类的&lt;b&gt;&lt;i&gt;序列到序列sequence-to-sequence&lt;/i&gt;&lt;/b&gt;问题！而且事实证明，许多有趣的问题都实际上是 序列到序列的问题。继续阅读了解其他你可以做的酷炫的事！&lt;/p&gt;&lt;p&gt;注意，我们忽略了一些处理真实数据会碰到的问题。例如，如何处理不同长度的输入和输出？这还需要一些额外的工作（请参见bucketing和padding）。非常用词翻译也是一个问题。&lt;/p&gt;&lt;p&gt;&lt;b&gt;构建你自己的序列到序列翻译系统&lt;/b&gt;&lt;/p&gt;&lt;p&gt;如果你想建立自己的语言翻译系统，这儿有一个包括可以在英语和法语之间翻译的TensorFlow的demo。然而，这并不是给胆小鬼或预算有限的人准备的。这仍然是一项新技术，并且资源有限。即使你有一台带有高级显卡的高级电脑，可能也需要连续一个月的时间来训练你自己的语言翻译系统。&lt;/p&gt;&lt;p&gt;此外，序列到序列语言翻译技术正在及快速地改进，以至于难以跟上。许多最近的改进（如添加注意机制attention mechanism或上下文跟踪tracking context）显着改善了翻译结果，但这些发展太过前沿，以至于他们甚至还没有维基百科页面。如果你想做认真的去做任何序列到序列学习，随着技术的发展，你需要持续保持更新，。&lt;/p&gt;&lt;p&gt;&lt;b&gt;序列到序列模型的无穷力量&lt;/b&gt;&lt;/p&gt;&lt;p&gt;那么，我们还能用序列到序列模型做什么呢？&lt;/p&gt;&lt;p&gt;大约一年前，Google的研究人员表示，你可以使用序列到序列模型来建造AI机器人。这个想法是如此简单，并且令人震惊的是，它真的有效。&lt;/p&gt;&lt;p&gt;首先，他们获取了一些Google员工和Google技术支持小组之间的聊天记录。然后他们训练了序列到序列模型，其中输入的句子就是雇员的问题，而技术支持团队的回复是该句子的“翻译”。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-b0e96c4e8b2853799ecc52ee39689f1a.png" data-rawwidth="1250" data-rawheight="341"&gt;&lt;/p&gt;&lt;p&gt;当用户与机器人进行交互时，他们将使用该系统“翻译”每个用户的消息以获得机器人的响应。&lt;/p&gt;&lt;p&gt;他们最终得到的是一个半智能机器人，（有时）可以回答真正的技术支持问题。下面是一部分用户和机器人之间的对话示例：&lt;/p&gt;&lt;p&gt;人：连接被拒绝或类似的东西&lt;/p&gt;&lt;p&gt;机器：我可以知道你连接的网络连接的版本吗？&lt;/p&gt;&lt;p&gt;人：我不确定我知不知道&lt;/p&gt;&lt;p&gt;机器：是网络连接提示任何用户证书？&lt;/p&gt;&lt;p&gt;人类：是的&lt;/p&gt;&lt;p&gt;机器：你现在在家还是在工作？办公室？&lt;/p&gt;&lt;p&gt;人：我在家&lt;/p&gt;&lt;p&gt;机器：试试这个。 goto &amp;lt;URL redacted&amp;gt;页面，然后输入您的姓名和密码&lt;/p&gt;&lt;p&gt;人类：完成&lt;/p&gt;&lt;p&gt;机器：尝试使用&amp;lt;NAME redacted&amp;gt;登录，然后检查其是否正常工作&lt;/p&gt;&lt;p&gt;人类：是的，现在它在工作！&lt;/p&gt;&lt;p&gt;机器：棒极了。还有什么我可以帮助你的？&lt;/p&gt;&lt;p&gt;他们还试图建立一个基于数百万部电影字幕的聊天机器人。他们的想法是，使用电影角色之间的对话作为一种训练机器人像人一样说话的方式。输入句子是一名角色的一句话，“翻译”是另一名角色在对话里回应他的内容：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-dffddd0667601ce5600454dfd82b5007.png" data-rawwidth="1250" data-rawheight="340"&gt;&lt;p&gt;他们得到了很有意思的结果。机器人不仅仅像一个人，更是显示出了一点点智能化：&lt;/p&gt;&lt;p&gt;人类：我的名字是david。我的名字是什么？&lt;/p&gt;&lt;p&gt;机器：david。&lt;/p&gt;&lt;p&gt;人：我的名字是约翰。我的名字是什么？&lt;/p&gt;&lt;p&gt;机器：约翰。&lt;/p&gt;&lt;p&gt;人类：你是领导还是追随者？&lt;/p&gt;&lt;p&gt;机器：我是领导者。&lt;/p&gt;&lt;p&gt;人类：你是追随者还是领导者？&lt;/p&gt;&lt;p&gt;机器：我是领导者。&lt;/p&gt;&lt;p&gt;这只是可能性的开始。我们将不局限于将一个句子转换成另一个句子，同样，我们制作一个图像到序列的模型，它可以将图像转换为文本！&lt;/p&gt;&lt;p&gt;Google的另一个团队通过将第一个RNN替换为卷积神经网络（如我们在第3章中所了解的那样）。这允许输入是图片而不是句子，其余的工作基本相同：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-9d899c93bdc3d566e6441d2e2a2f938e.png" data-rawwidth="1250" data-rawheight="341"&gt;&lt;/p&gt;&lt;p&gt;就像这样，（只要我们有很多很多的训练数据）我们就可以把图片变成单词！&lt;/p&gt;&lt;p&gt;Andrej Karpathy把这个想法进行了拓展，以构建一个通过分别处理图像的多个区域，来详细描述图像的系统：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-380c811bf4f9ffc0ebd1fa03427de50d.png" data-rawwidth="1000" data-rawheight="763"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;Andrej Karpathy论文中的图片&lt;/i&gt;&lt;/p&gt;&lt;p&gt;这个想法使得我们可以构建一个，能够按照奇怪的要求找到特定图片的图片搜索引擎：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-80cf134e8142811f9ba5f0f1561012a1.jpg" data-rawwidth="444" data-rawheight="356"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;例子来自&lt;a href="http://cs.stanford.edu/people/karpathy/deepimagesent/rankingdemo/" data-editable="true" data-title="image sentence ranking visualize"&gt;image sentence ranking visualize&lt;/a&gt;&lt;/i&gt;&lt;/p&gt;&lt;p&gt;甚至有研究人员正在研究相反的问题，仅仅基于文本描述产生一个完整的图片！&lt;/p&gt;&lt;p&gt;从这些例子，你可以开始想象的各种可能性。 到目前为止，序列到序列应用在从语音识别到计算机视觉各个领域。 我猜，明年会有更多的应用。&lt;/p&gt;&lt;p&gt;如果您想更深入地了解序列到序列模型和翻译，以下是一些推荐的资源：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=qGlmW2n4s1w" class="" data-editable="true" data-title="Richard Socher’s CS224D Lecture— Fancy Recurrent Neural Networks for Machine Translation"&gt;Richard Socher’s CS224D Lecture— Fancy Recurrent Neural Networks for Machine Translation&lt;/a&gt; (video)&lt;/li&gt;&lt;li&gt;&lt;a href="http://cs224d.stanford.edu/lectures/CS224d-Lecture15.pdf" class="" data-editable="true" data-title="Thang Luong’s CS224D Lecture — Neural Machine Transation"&gt;Thang Luong’s CS224D Lecture — Neural Machine Transation&lt;/a&gt; (PDF)&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.tensorflow.org/versions/r0.10/tutorials/seq2seq/index.html" class="" data-editable="true" data-title="TensorFlow’s description of Seq2Seq modeling"&gt;TensorFlow’s description of Seq2Seq modeling&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="http://www.deeplearningbook.org/contents/rnn.html" class="" data-editable="true" data-title="The Deep Learning Book’s chapter on Sequence to Sequence Learning"&gt;The Deep Learning Book’s chapter on Sequence to Sequence Learning&lt;/a&gt;(PDF)&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-c8693405235197b0a454b2c41cb432d6.png" data-rawwidth="1120" data-rawheight="808"&gt;&lt;/li&gt;&lt;/ul&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/24590838&amp;pixel&amp;useReferer"/&gt;</description><author>九五要当学霸</author><pubDate>Tue, 27 Dec 2016 17:03:08 GMT</pubDate></item><item><title>【巡洋舰首发】有趣的机器学习 第四章：用深度学习进行【人脸识别】</title><link>https://zhuanlan.zhihu.com/p/24567586</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-83f669a67c954c9331e03e5557bfc6eb_r.jpg"&gt;&lt;/p&gt;&lt;p&gt;原文：Adam Geitgey&lt;/p&gt;&lt;p&gt;原文链接：&lt;a href="https://medium.com/@ageitgey/machine-learning-is-fun-part-4-modern-face-recognition-with-deep-learning-c3cffc121d78#.asmzg3vx4" data-editable="true" data-title="medium.com 的页面"&gt;https://medium.com/@ageitgey/machine-learning-is-fun-part-4-modern-face-recognition-with-deep-learning-c3cffc121d78#.asmzg3vx4&lt;/a&gt;&lt;/p&gt;&lt;p&gt;翻译：巡洋舰科技——赵95&lt;/p&gt;&lt;p&gt;你是不是看烦了各种各样对于深度学习的报导，却不知其所云？我们要来改变这个问题。&lt;/p&gt;&lt;p&gt;有趣的机器学习 前六章已更新！点此查看&lt;a href="https://zhuanlan.zhihu.com/p/24339995" class="" data-editable="true" data-title="第一章：最简明入门指南"&gt;第一章：最简明入门指南&lt;/a&gt;、&lt;a href="https://zhuanlan.zhihu.com/p/24344720" class="" data-editable="true" data-title="第二章：用机器学习制造【超级马里奥】的关卡"&gt;第二章：用机器学习【制造超级马里奥】的关卡&lt;/a&gt;、&lt;a href="https://zhuanlan.zhihu.com/p/24524583" class="" data-editable="true" data-title="第三章：图像识别【鸟or飞机】"&gt;第三章：图像识别【鸟or飞机】&lt;/a&gt;&lt;a href="https://zhuanlan.zhihu.com/p/24567586" class="" data-editable="true" data-title="第四章：用深度进行【人脸识别】"&gt;第四章：用深度进行【人脸识别】&lt;/a&gt;&lt;a href="https://zhuanlan.zhihu.com/p/24590838" class="" data-editable="true" data-title="第五章：使用深度学习进行【语言翻译】和 序列的魔力"&gt;第五章：使用深度学习进行【语言翻译】和 序列的魔力&lt;/a&gt;&lt;a href="https://zhuanlan.zhihu.com/p/24703268" data-title="第六章：如何用深度学习进行【语音识别】" class="" data-editable="true"&gt;第六章：如何用深度学习进行【语音识别】&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;你有没有发现Facebook研发出了一种能够在你的照片中识别出你朋友的神之魔力？
之前，Facebook让你在照片里点击你的朋友，并输入他们的名字来标注出你的朋友。现在，只要你上传了一张照片，Facebook就魔力般的为你标注出你的每一个朋友：&lt;/h2&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-b414d836a7612bc12efc932b6a4b90bc.jpg" data-rawwidth="502" data-rawheight="346"&gt;&lt;p&gt;&lt;i&gt;Facebook&lt;/i&gt;&lt;i&gt;基于你之前的标注，自动标注出你照片中的人。我不确定这到底是有帮助性的还是非常阴险恐怖的。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;这种技术被称为人脸识别。你的朋友被标记了几次之后，Facebook的算法就能够识别你朋友的脸。
这是一项非常惊人的黑科技——Facebook的人脸识别准确率达到了98％，几乎与人类做的一样好！让我们来了解一下现代人脸识别是如何工作的！
但是，识别你的朋友这太容易了。
我们可以最大化扩展这项技术，来解决一个更具挑战性的问题——区分Will Ferrell（著名演员）和Chad Smith（著名摇滚音乐家）！&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-967774e47de559f90f39eb821b640f2c.jpg" data-rawwidth="1000" data-rawheight="562"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;一个是Will
Ferrell&lt;/i&gt;&lt;i&gt;，另一个是Chad Smith&lt;/i&gt;&lt;i&gt;。我保证他们不是同一个人！&lt;/i&gt;&lt;/p&gt;&lt;p&gt;如何用机器学习解决复杂问题？&lt;/p&gt;&lt;p&gt;到目前为止，在前三章，我们已经使用机器学习来解决了，一些只用一个步骤就可以解决的孤立问题——&lt;a href="https://zhuanlan.zhihu.com/p/24339995" data-title="第一章：估计房子的价格" class="" data-editable="true"&gt;第一章：估计房子的价格&lt;/a&gt;、&lt;a href="https://zhuanlan.zhihu.com/p/24344720" data-title="第二章：基于现有数据生成新数据" class="" data-editable="true"&gt;第二章：基于现有数据生成新数据&lt;/a&gt;（译者注：根据已有的超级马里奥的关卡生成新的关卡）、以及&lt;a href="https://zhuanlan.zhihu.com/p/24524583" data-title="第三章：判别图像当中是否包含某个物品" class="" data-editable="true"&gt;第三章：判别图像当中是否包含某个物品&lt;/a&gt;。
所有这些问题都可以通过下列步骤解决：选择一个机器学习算法，输入数据，并获得结果。&lt;/p&gt;&lt;p&gt;但是，人脸识别是由一系列的几个相关问题组成的：&lt;/p&gt;&lt;p&gt;首先，找到一张图片中的所有人脸&lt;/p&gt;&lt;p&gt;第二，对于每一张脸来说，无论光线明暗或面朝别处，它依旧能够识别出是同一个人的脸。&lt;/p&gt;&lt;p&gt;第三，能够在每一张脸上找出可用于与他人区分的独特之处，比如说眼睛有多大，脸有多长等等。&lt;/p&gt;&lt;p&gt;最后，将这张脸的特点与已知的所有人脸进行比较，以确定这个人的姓名。&lt;/p&gt;&lt;p&gt;作为人类，你的大脑总是在一瞬间自动做出了这些判断。实际上，人类在识别人脸这方面做得&lt;b&gt;&lt;i&gt;太好了&lt;/i&gt;&lt;/b&gt;，以至于他们会在日常物品中同样去“找脸”：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-ccb4dd22f6905c9825a7f369b3cd37dc.jpg" data-rawwidth="580" data-rawheight="250"&gt;&lt;/p&gt;&lt;p&gt;计算机不能进行这种高级泛化(generalization)（至少现在还不行...），所以我们必须分别教给他们，这个过程中的每一步是怎么做到的。&lt;/p&gt;&lt;p&gt;我们需要构建一个&lt;b&gt;流水线&lt;/b&gt;&lt;b&gt;(pipeline)&lt;/b&gt;，一个单独完成每个步骤并把结果发送给下一个步骤的流水线。换句话说，我们会将好几个机器学习算法连接到一起：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-7647e39242a7f7f7f5f0ec615eee3bf1.jpg" data-rawwidth="1000" data-rawheight="361"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;一个基础的探测人脸的流水线是怎样工作的&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;人脸识别——分步讲解&lt;/b&gt;&lt;/p&gt;&lt;p&gt;让我们一步一步地解决这个问题。
对于每个步骤，我们将学习一个不同的机器学习算法。
我并不会完全解释每一个的算法，否则这篇文章就变成了一本教科书。但你会学到每个步骤的精髓，以及如何在Python中使用&lt;a href="https://cmusatyalab.github.io/openface/" data-editable="true" data-title="OpenFace"&gt;OpenFace&lt;/a&gt;和&lt;a href="http://dlib.net/" data-editable="true" data-title="dlib"&gt;dlib&lt;/a&gt;来构建一个你自己的面部识别系统。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第一步：找出所有的面孔&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们流水线的第一步是面部检测。显然，在我们区分人脸之前，我们必须要照片中找到他们才行！&lt;/p&gt;&lt;p&gt;如果你在过去10年里使用过相机，你可能已经见过正在运行中的面部检测功能：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-bd16d8458af314c441f67c293f051f40.png" data-rawwidth="896" data-rawheight="459"&gt;&lt;/p&gt;&lt;p&gt;面部检测是相机很好的一个功能。
当相机可以自动拾取人脸时，它可以确保相机在拍摄时对焦到所有人脸。
不过，我们使用它另有其因——我们需要找到想要传递到流水线下一步的图像区域。&lt;/p&gt;&lt;p&gt;2000年初的时候， 当Paul
Viola和Michael
Jones 发明了一种能够快速在廉价相机上运行的一种脸部检测方法之后（译者注：这种算法也可以用来训练检测其他的物品，但是最经常还是被用于人脸的检测，其英文名称为Viola–Jones
object detection framework），面部检测在成为了主流。然而现在，更可靠的解决方案出现了。
我们将使用2005年发明的一种称为“&lt;b&gt;方向梯度直方图&lt;/b&gt;&lt;b&gt;(Histogram of Oriented Gradients)&lt;/b&gt;”的方法，或简称HOG。&lt;/p&gt;&lt;p&gt;要在一张图片中找到脸，我们首先将图像转换为黑白，因为我们并不需要颜色数据来找到脸：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-74fd08c6ce2f1c650a09272e7c7f7f57.jpg" data-rawwidth="511" data-rawheight="563"&gt;&lt;/p&gt;&lt;p&gt;然后，我们将查看图片中的每一个像素。
对于单个像素，我们要查看直接围绕着它的像素：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-bdc412d7dbe8c6f94becb144d21d3d1e.jpg" data-rawwidth="800" data-rawheight="282"&gt;&lt;/p&gt;&lt;p&gt;我们的目标是找出并比较当前像素与直接围绕它的像素的深度。
然后我们要画一个箭头来代表图像变暗的方向：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-8003fc861e178c2a4a65386d738e9634.jpg" data-rawwidth="500" data-rawheight="159"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;看这个像素和它周围的像素，图像向右上方变得越来越暗。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;如果你对图片中的&lt;b&gt;每一个像素&lt;/b&gt;重复这个过程，最终每个像素会被一个箭头取代。这些箭头被称为&lt;b&gt;梯度&lt;/b&gt;&lt;b&gt;gradients&lt;/b&gt;，它们能显示出图像上从明亮到黑暗的流动过程：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-a458e794e970703fd355f9a83aacf1ac.jpg" data-rawwidth="1000" data-rawheight="393"&gt;&lt;/p&gt;&lt;p&gt;这可能看起来非常随机，但其实我们有非常好的理由用梯度来代替像素。如果我们直接分析像素，同一个人明暗不同的两张照片将具有完全不同的像素值。但是如果只考虑亮度变化&lt;b&gt;&lt;i&gt;方向&lt;/i&gt;&lt;/b&gt;&lt;b&gt;&lt;i&gt;direction&lt;/i&gt;&lt;/b&gt;的话，明暗图像将会有同样的结果。这使得问题变得更容易解决！&lt;/p&gt;&lt;p&gt;但是保存每个像素的梯度太过细节化了，我们最终很有可能“一叶障目不见泰山missing the forest for the trees”。如果我们能从更高的角度上观察基本的明暗流动，我们就可以看出图像的基本规律，这会比之前更好。&lt;/p&gt;&lt;p&gt;为了做到这一点，我们将图像分割成一些16x16像素的小方块。在每个小方块中，我们将计算出每个主方向上有多少个梯度（有多少指向上，指向右上，指向右等）。然后我们将用指向性最强那个方向的箭头来代替原来的那个小方块。&lt;/p&gt;&lt;p&gt;最终的结果是，我们把原始图像变成了一个非常简单的表达形式，这种表达形式可以用一种简单的方式来捕获面部的基本结构：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-a2f4fde8df3dc047201f9add7850ca6f.jpg" data-rawwidth="800" data-rawheight="295"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;原始图像被表示成了HOG&lt;/i&gt;&lt;i&gt;形式，以捕获图像的主要特征，无论图像明暗度如何。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;为了在这个HOG图像中找到脸部，我们要所需要做的，就是找到我们的图像中，与已知的一些HOG样式中，看起来最相似的部分。这些HOG样式都是从其他面部训练数据中提取出来的：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-35e736853cc413f7d7d595ddb9bc56d9.png" data-rawwidth="1000" data-rawheight="697"&gt;&lt;/p&gt;&lt;p&gt;使用这种技术，我们现在可以轻松地在任何图片中找到脸部：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-83f669a67c954c9331e03e5557bfc6eb.jpg" data-rawwidth="1000" data-rawheight="563"&gt;&lt;/p&gt;&lt;p&gt;如果你想使用Python和dlib尝试这一步，&lt;a href="https://gist.github.com/ageitgey/1c1cb1c60ace321868f7410d48c228e1" data-editable="true" data-title="这些代码"&gt;这些代码&lt;/a&gt;显示了如何生成和查看HOG图像的表示。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第二步：脸部的不同姿势&lt;/b&gt;&lt;/p&gt;&lt;p&gt;哇，我们把图片中的脸部孤立出来了。
但现在，我们要处理的问题就是，对于电脑来说，面朝不同方向的同一张脸，是不同的东西：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-8cc2f0d8e403fa933a022a2d053b62d5.png" data-rawwidth="956" data-rawheight="389"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;人类可以很轻松地识别出到两个图片都是Will Ferrell&lt;/i&gt;&lt;i&gt;，但电脑会认为这两张图片是两个完全不同的人。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;为了解决这一点，我们将试图扭曲每个图片，使得眼睛和嘴唇总是在图像中的样本位置(Sample Place)。
这将使我们在接下来的步骤中，更容易比较脸部之间的不同。&lt;/p&gt;&lt;p&gt;为此，我们将使用一种称为&lt;b&gt;脸部标志点估计（&lt;/b&gt;&lt;b&gt;Face
Landmark Estimation&lt;/b&gt;&lt;b&gt;）&lt;/b&gt;的算法。 很多方法都可以做到这一点，但这次我们会使用由Vahid Kazemi和Josephine Sullivan在2014年发明的方法。&lt;/p&gt;&lt;p&gt;这一算法的基本思想是，我们找到人脸上普遍存在的68个特定点（称为Landmarks）——下巴的顶部，每只眼睛的外部轮廓，每条眉毛的内部轮廓等。接下来我们训练一个机器学习算法，能够在任何脸部找到这68个特定点：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-f7a513f83f2e4978e59f2becf43653a2.png" data-rawwidth="414" data-rawheight="394"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;我们将在每一张脸上定位的68&lt;/i&gt;&lt;i&gt;个Landmarks&lt;/i&gt;&lt;i&gt;。这张照片是由在OpenFace&lt;/i&gt;&lt;i&gt;工作的CMU&lt;/i&gt;&lt;i&gt;的Brandon Amos&lt;/i&gt;&lt;i&gt;创造的。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;这是在测试图片上定位68个标志点的结果：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-06fcc66230ba44b5533bcff134080209.jpg" data-rawwidth="1000" data-rawheight="871"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;友情提示：你也可以使用这一技术来实现自己的Snapchat&lt;/i&gt;&lt;i&gt;实时3D&lt;/i&gt;&lt;i&gt;脸部过滤器！ &lt;/i&gt;&lt;/p&gt;&lt;p&gt;现在，我们知道了眼睛和嘴巴在哪儿，我们将图像进行旋转，缩放和切变，使得眼睛和嘴巴尽可能靠近中心。我们不会做任何花哨的三维扭曲，因为这会让图像失真。我们只会使用那些能够保持图片相对平行的基本图像变换，例如旋转和缩放，（称为仿射变换）：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-962d576949169ea9618b8307fdca513a.png" data-rawwidth="1000" data-rawheight="280"&gt;&lt;/p&gt;&lt;p&gt;现在无论脸部怎样扭曲变形，我们都能将眼睛和嘴巴向中间挪动到大致相同的位置。这将使我们的下一步更加准确。&lt;/p&gt;&lt;p&gt;如果你想自己使用Python和dlib来尝试完成这一步的话，这里有一些代码帮你&lt;a href="https://gist.github.com/ageitgey/ae340db3e493530d5e1f9c15292e5c74" data-editable="true" data-title="寻找脸部标志点"&gt;寻找脸部标志点&lt;/a&gt;和&lt;a href="https://gist.github.com/ageitgey/82d0ea0fdb56dc93cb9b716e7ceb364b" data-editable="true" data-title="图像变形"&gt;图像变形&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第3步：给脸部编码&lt;/b&gt;&lt;/p&gt;&lt;p&gt;现在我们要面临最核心的问题了——如何区分脸部。这才是事情变得非常有趣的地方！&lt;/p&gt;&lt;p&gt;最简单的人脸识别方法，就是直接把我们在步骤2中发现的未知人脸，与我们已经标注了人脸图片作比较。当我们发现未知的面孔与一个以前标注过的面孔看起来及其相似的时候，它必须是同一个人。这似乎是一个很好的主意，对吗？&lt;/p&gt;&lt;p&gt;实际上这种方法有一个巨大的问题。像Facebook这种拥有数十亿用户和数万亿张照片的网站，是不可能去循环比较每张先前标记的脸的，这浪费的时间太长了。他们需要在毫秒内识别人脸，而不是几个小时。&lt;/p&gt;&lt;p&gt;我们需要的是一种从每张人脸上都可以提取一些基本特性的方法。然后，我们可以用同样的方式测量未知的面孔，并找到与已知的脸最相近的测量。例如，我们可以测量每个耳朵的大小，眼睛之间的间距，鼻子的长度等。如果你曾经看过像CSI这样的犯罪类型的电视剧，那么你就知道我在说什么了。&lt;/p&gt;&lt;p&gt;&lt;b&gt;测量人脸的最可靠的方法&lt;/b&gt;&lt;/p&gt;&lt;p&gt;好的，那么我们应该测量面部的哪些数值，来建立我们的已知脸部数据库呢？耳朵的大小？鼻子的长度？眼睛的颜色？还有什么？&lt;/p&gt;&lt;p&gt;事实证明，对于我们人类来说一些显而易见的测量值（比如眼睛颜色），并没有对计算机产生太大的影响。研究人员发现，最准确的方法是让计算机自己找出测量值并自己收集。深度学习比人类更好地了解脸部的哪些部分是重要的测量值。&lt;/p&gt;&lt;p&gt;所以，解决方案是训练一个深度卷积神经网络（就像我们在第3章做的那样）。但是，并不是像上次那样训练我们的网络来识别图片对象，我们将训练它为脸部生成128个测量值。&lt;/p&gt;&lt;p&gt;每次训练要观察3个不同的脸部图像：&lt;/p&gt;&lt;p&gt;1.加载一张已知的人的面部训练图像&lt;/p&gt;&lt;p&gt;2.加载同一个人的另一张照片&lt;/p&gt;&lt;p&gt;3.加载另外一个人的照片&lt;/p&gt;&lt;p&gt;&lt;b&gt;然后，算法查看它自己为这三个图片生成的测量值。再然后，它稍微调整神经网络，以确保它为第1&lt;/b&gt;&lt;b&gt;张和第2&lt;/b&gt;&lt;b&gt;章生成的测量值接近，而第2&lt;/b&gt;&lt;b&gt;张和第3&lt;/b&gt;&lt;b&gt;张生成的测量值略有不同。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-e504e8e72005e8d26b6cdfb89cb1834b.png" data-rawwidth="1000" data-rawheight="827"&gt;&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在为几千个不同的人的数百万图像重复该步骤数百万次之后，神经网络学习了如何可靠地为每个人生成128个测量值。同一个人的任何十张不同的照片应该给出大致相同的测量值。&lt;/p&gt;&lt;p&gt;机器学习专业人士把每个面孔上的128个测量值称为“嵌入（Embedding）”。将复杂的原始数据（如图片）缩减为可由计算机生成的一个数列的方法在机器学习（特别是语言翻译）中出现了很多次。我们正在使用的这种方法是由Google的研究人员在2015年发明的，但其实这是许多类似的方法之一。&lt;/p&gt;&lt;p&gt;&lt;b&gt;给我们的脸部图像编码&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这个通过训练卷积神经网络来输出脸部嵌入的过程，需要大量的数据和计算机应用。即使使用昂贵的Nvidia Telsa显卡，它也需要大约24小时的连续训练，才能获得良好的准确性。&lt;/p&gt;&lt;p&gt;但一旦网络训练完成，它可以生成任何面孔的测量值，即使它从来没有见过这些面孔！所以这种训练只需一次即可。幸运的是，OpenFace上面的大神已经做完了这些，并且他们发布了几个训练过可以直接使用的网络，。谢谢Brandon Amos和他的团队！&lt;/p&gt;&lt;p&gt;所以我们需要做的，就是通过他们的预训练网络来处理我们的脸部图像，以获得128个测量值。这是我们测试图像的一些测量值：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-6e2b5cfcbd33b1105a4d8d40191c162d.png" data-rawwidth="1000" data-rawheight="499"&gt;&lt;/p&gt;&lt;p&gt;那么，这128个数字到底测量了脸部的哪些部分？我们当然不知道，但是这对我们并不重要。我们关心的是，当看到同一个人的两张不同的图片时，我们的网络需要能得到几乎相同的数值。&lt;/p&gt;&lt;p&gt;如果你想自己尝试这个步骤，OpenFace提供了一个&lt;a href="https://github.com/cmusatyalab/openface/blob/master/batch-represent/batch-represent.lua" data-editable="true" data-title="lua脚本"&gt;lua脚本&lt;/a&gt;，它可以生成一个文件夹中所有图像的嵌入，并将它们写入csv文件。&lt;a href="https://gist.github.com/ageitgey/ddbae3b209b6344a458fa41a3cf75719" data-editable="true" data-title="点此查看如何运行"&gt;点此查看如何运行&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第4&lt;/b&gt;&lt;b&gt;步：从编码中找出人的名字&lt;/b&gt;&lt;/p&gt;&lt;p&gt;最后这一步实际上是整个过程中最简单的一步。我们要做的就是找到数据库中，与我们的测试图像的测量值最接近的那个人。&lt;/p&gt;&lt;p&gt;你可以通过任何基本的机器学习分类算法来达成这一目标。我们并不需要太花哨的深度学习技巧。我们将使用一个简单的线性SVM分类器，但实际上还有很多其他的分类算法可以使用。&lt;/p&gt;&lt;p&gt;我们需要做的是训练一个分类器，它可以从一个新的测试图像中获取测量结果，并找出最匹配的是哪个人。分类器运行一次只需要几毫秒，分类器的结果就是人的名字！&lt;/p&gt;&lt;p&gt;所以让我们试一下我们的系统。首先，我使用Will Ferrell, Chad Smith 和 Jimmy Falon每人20张照片的嵌入来训练分类器：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-61b8af810e1cacee40a634312bab6f11.jpg" data-rawwidth="1200" data-rawheight="266"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;嗯…就是这些训练数据！&lt;/i&gt;&lt;/p&gt;&lt;p&gt;接下来，我在YouTube著名的Will Ferrell和Chad Smith的视频的每一帧上运行这个分类器：&lt;/p&gt;&lt;p&gt;它真的有效！它在不同的姿势的脸部依然有效- 甚至是侧脸！&lt;/p&gt;&lt;p&gt;&lt;b&gt;你自己做一遍&lt;/b&gt;&lt;/p&gt;&lt;p&gt;让我们回顾一下我们的步骤：&lt;/p&gt;&lt;p&gt;1.使用HOG算法给图片编码，以创建图片的简化版本。使用这个简化的图像，找到图像中看起来最像通用HOG面部编码的部分。&lt;/p&gt;&lt;p&gt;2.通过找到脸上的主要标志点，找出脸部的姿态。一旦我们找到这些标志点，就利用它们把图像扭曲，使眼睛和嘴巴居中。&lt;/p&gt;&lt;p&gt;3. 把上一步得到的面部图像放入到神经网络中，神经网络知道如何找到128个特征点测量值。保存这128个测量值。&lt;/p&gt;&lt;p&gt;4.看看我们过去测量过得的所有脸部，找出哪个人的测量值和我们的脸部测量值最接近。这就是你要找的匹配的人！&lt;/p&gt;&lt;p&gt;现在你知道这一切都是如何运行的了，&lt;a href="https://cmusatyalab.github.io/openface/" data-editable="true" data-title="这里是如何使用OpenFace在你自己的电脑上运行整个人脸识别系统的说明"&gt;这里是如何使用OpenFace在你自己的电脑上运行整个人脸识别系统的说明&lt;/a&gt;.&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-c8693405235197b0a454b2c41cb432d6.png" data-rawwidth="1120" data-rawheight="808"&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/24567586&amp;pixel&amp;useReferer"/&gt;</description><author>九五要当学霸</author><pubDate>Mon, 26 Dec 2016 15:27:57 GMT</pubDate></item></channel></rss>