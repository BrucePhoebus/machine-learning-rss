<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>混沌巡洋舰 - 知乎专栏</title><link>https://zhuanlan.zhihu.com/c_29122335</link><description>跨界思考内容供应商，与微信公众号混沌巡洋舰同属于巡洋舰科技公司。</description><lastBuildDate>Thu, 12 Jan 2017 22:17:20 GMT</lastBuildDate><generator>Ricky</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>深度学习助力基因科技</title><link>https://zhuanlan.zhihu.com/p/24837137</link><description>&lt;p&gt;有可能改变未来的一项技术之一是基因科技，据麦卡锡去年发布的一份报告，预计到2025年，全球将会累计产生10亿人次的全基因组数据，而检测基因的成本将下降到接近为0。考虑到每一个人的全基因组数据将会达到100G， 如何对这些海量数据的解读，现有的生物信息方法基于统计学模型，而12月20日在bioRvix（生物领域的论文预印本）上，来自谷歌子公司Deep mind 的科学家发表了一篇论文[1]，提出一个名为DeepVariant 的检测工具，使用深度神经学习中的卷积神经网络CNN 来检查基因组上的单碱基突变(SNP)和小的插入缺失(Indel)，其准确性超越了当前主流的生物信息学软件GATK。而在12月30日，来自康奈尔大学的另一组研究者又独立的发表了一篇用类似方法检测基因变异的软件[2]。两篇论文的爆发式出现，彰显了深度学习在基因组数据挖掘领域的巨大潜力。&lt;/p&gt;&lt;p&gt;每个人的体内都包含着3亿对碱基，这些碱基的排列方式决定了我们从生老病死的方方面面， 找到了你的基因组的差异之处，可以帮助我们了解我们的疾病的易感性，也可以知道我们的个体特征。对基因数据的传统分析方法，基于贝叶斯统计和专家的经验，针对不同的检测物种，需要很多人工的调节和试错，并且针对不同的测序平台，也需要进行特异性的配置。而基于深度学习的方法，巧妙的利用了图像识别领域成熟的技术，不止可以以通用的学习流程达到了现行软件相同的水平，更获得了由美国FDA 监管的SNP检测算法比赛的第一名 。由于这两项研究都还处于初期，考虑到深度学习算法巨大的提升空间，在可以预见的未来，基于深度学习的基因检测算法将会有更大的施展空间。&lt;/p&gt;&lt;p&gt;而在表观遗传学上，深度学习工具DeepCpG [3] 则可以根据基因序列预测单细胞层面是否会出现甲基化。在小鼠的胚胎干细胞上验证后，DeepCpG的表现优于现有的其他软件。甲基化会影响基因是否表达，而诸多启动子和增强子(DNA 序列中的调控区)与其调控的基因之间的相互作用则会影响基因的表达数量。同样是基于深度学习的SPEID [4] 基于基因序列预测启动子和增强子之间的相互作用，这是第一个基于基因序列来预测 启动子和增强子的软件，其效果优于基于基因功能做出的预测。&lt;/p&gt;&lt;p&gt;传统的基因组关联分析（GWAS）大多只能检测一个点突变（SNP）与所研究疾病的关系，而DeepWAS[5]，这一新提出的框架则能够根据功能单元，选择出一组SNP 的集合，来更加综合的研究治病的基因突变,并能直接的寻找调控区域的基因突变。在一项针对抑郁症的研究中，使用DeepWAS 框架的新研究发现了一个新的控制抑郁症的主要基因MEF2C。&lt;/p&gt;&lt;p&gt;以上列出的5项研究，都来自与2016年下半年，而在2017年1月，又有一篇基于CNN 的文章[6]尝试预测HLA基因与多肽的相互反应。这些文章虽然都来自于论文预印本，没有经过正规的同行审查，但不同领域的大规模井喷式爆发，也显示了该领域的巨大潜力。随着基因组数据的大量积累，以及深度学习开源平台的普及，未来深度学习必将成为生物信息领域的“一股清流”，为人类的健康做出贡献。&lt;/p&gt;&lt;p&gt;参考文献&lt;/p&gt;&lt;p&gt;[1] Creating a universal SNP and small indel variant caller with deep neural networks&lt;/p&gt;&lt;p&gt;[2] Training Genotype Callers with Neural Networks&lt;/p&gt;&lt;p&gt;[3] Accurate prediction of single-cell DNA methylation states using deep learning&lt;/p&gt;&lt;p&gt;[4] Predicting Enhancer-Promoter Interaction from Genomic Sequence with Deep Neural Networks&lt;/p&gt;&lt;p&gt;[5] DeepWAS: Directly integrating regulatory information into GWAS using deep learning supports master regulator MEF2C as risk factor for major depressive disorder&lt;/p&gt;&lt;p&gt;[6] HLA class I binding prediction via convolutional neural networks&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/24837137&amp;pixel&amp;useReferer"/&gt;</description><author>许铁-巡洋舰科技</author><pubDate>Wed, 11 Jan 2017 22:52:23 GMT</pubDate></item><item><title>2017定一个小目标，比如读完机器学习科普书单</title><link>https://zhuanlan.zhihu.com/p/24836490</link><description>&lt;p&gt;关于机器学习的书单，可以分为给业内人士的入门书单，给有一定基础的进阶书单，以及针对外行的科普书籍。这类科普书籍，会展示机器学习与其他学科的关联，从而能够带给不同学科背景的读者诸多启发。对于不了解这个行业的读者，阅读这类书，可以避免阅读碎片化的科普小文带来的缺少系统性了解的问题；而对于从业者，由于这些书多是由大师写成，其语句中多包涵言外之音，会给读者带来如打通任督二脉的豁然贯通感。霍金曾说，他的时间简史，每多一个公式，销量就会降低一半，所以今天推荐的这些书中都不会包含公式。&lt;/p&gt;&lt;p&gt;首先推荐的是《终极算法：机器学习和人工智能如何重塑世界》[The Master Algorithm]&lt;/p&gt;&lt;p&gt;这本书的名字，显示着作者试图在机器学习的各个流派间进行整合，最终提出机器学习里的“牛顿三定律”的理想。作者在这本书里，介绍了当前常用的算法的发展历程，这些算法包括决策树，遗传算法，神经网络，朴素贝叶斯及贝叶斯网络，隐式马尔可夫链，K最近邻及支持向量机，作者还介绍了无监督学习的算法。在介绍算法时，作者还介绍了机器学习里最大的两个阻碍，过拟合及维度灾难。&lt;/p&gt;&lt;p&gt;对上面的这些名词看不懂，看过书你就明白了。这本书中，没有公式与代码，有的只是对机器学习中的算法本质一针见血的点破，有的只是依据这些算法而编出的日常生活中的故事，是对机器学习中核心算法的概念化的模型。一言以概之，这是一本所有有高中数学水平且无计算机背景的读者都能够读懂的科普书。如果你不想对控制着我们衣食住行方方面面的机器学习算法一无所知，那么这本书是你必读的书。&lt;/p&gt;&lt;p&gt;人工智能之父马文·明斯基经典作品：情感机器+心智社会&lt;/p&gt;&lt;p&gt;这两本书的作者被誉为人工智能之父，不是因为他发现了某一个特别NB的算法。而是因为其对人类的认知过程有着独特的见解，从而能利用对人类认知的洞察来指导机器学习算法的研发。其在70年代写成的心智社会一书，令当前的人工智能研究者还会常读常新。这本书虽然价格有些高，但考虑到读一遍根本不指望能看懂，要看三遍才能有些领悟，算算阅读单价，就不算高的。再加上这本书送朋友，那是多么有逼格的一件事啊。&lt;/p&gt;&lt;p&gt;这本书是人工智能之父集一生功力写成的集大成之作。如何让机器有感情，是在机器智能即将超越人之后的人工智能的下一个天花板。情感计算的概念，也随着Chatbot（聊天机器人）而火了起来。阅读这本书，会让读者认识到情感不一定是人类独有的特征。情况也可以被表示为一连串的计算。而赋予机器情感，我们也能造成有常识，有直觉的机器。如果你想打破人工智能的黑盒子，这本书也是一本需要反复研读的大作。&lt;/p&gt;&lt;p&gt;科学的极致 漫谈人工智能 集智俱乐部&lt;/p&gt;&lt;p&gt;集智俱乐部有一群有激情有实力的小伙伴，其中既有来自学术界的张江教授，也有基于深度学习开发了彩云天气，彩云翻译等APP的创业者。而这本书则是集智众人的智慧结晶。这本书由于是中国人写成，所以避免了翻译作品的语言障碍。杨澜曾经在她的博客中推荐过这本书，说她从这本书中收获甚多，可见这本书是很容易读懂的。正如书名所显示，这本书涉及诸多人工智能领域。而书中诸多的插图，例子和参考文献则让这本书赢在了细节上。&lt;/p&gt;&lt;p&gt;机器之心 雷·库兹韦尔&lt;/p&gt;&lt;p&gt;奇点临近，尤其是当Alpha Go横扫围棋界的时候，又会被人再一次提起。而这个词就来自于本书的作者，著名未来学家雷·库兹韦尔。这本书中的预言究竟会不会实现，读者需要保持批判性的判断，不可人云亦云。而要批判性的提问，就先要读读原文，看看作者做了哪些价值性的假设，从而阅读后不止是脑洞大开，还能提升自己在面临未来注定层出不穷的人工智能的新闻时的判别能力。&lt;/p&gt;&lt;p&gt;数学之美&lt;/p&gt;&lt;p&gt;这本书虽然叫做数学之美，其实由于作者是谷歌的搜索专家，所以写的多半是自然语言处理领域的发展。关于这本书，溢美之词已经太多了。而我这里想说的不是其将算法背后的原理讲述的多么清晰，而是作者讲述了其和诸位自然语言处理领域的先驱的个人故事，其中描述了诸多学者的风骨以及其背后的道德力量。这是这本书少有被人提起，但却能令人记忆深刻的地方。&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/24836490&amp;pixel&amp;useReferer"/&gt;</description><author>许铁-巡洋舰科技</author><pubDate>Wed, 11 Jan 2017 21:59:50 GMT</pubDate></item><item><title>关于什么是大数据的一点思考</title><link>https://zhuanlan.zhihu.com/p/24773653</link><description>&lt;p&gt;借用三体中一句名言“给岁月以文明，而非给文明以岁月”大数据的本质，不是将生命献给数据，而是给数据以生命。大数据不是一套routine,不应限制了你思考的方向，那里数据多就分析那里，而应是内化的一套价值观及处事方式，用以对抗无常。&lt;/p&gt;&lt;p&gt;科学的进步，商业的发展，得益于数据所统领的疆域的扩展，随着之前越来越不可量化的变得可以计量，但这并不是要我们的丢弃直觉，忽视心智模式的作用，大数据带领我们关注用户购买了什么，也要求我们关注用户没有购买什么，并从用会的行为推测出用户为什么没有购买，亚马逊会根据你点击而未曾购买的记录给你推出个性化的deal，大数据要求我们了解整个行业的趋势，更要求关注每一人个性化的需求，Netflix不止靠大数据拍出《纸牌屋》，还将无数的小众电影准确的推荐给了用户。而你的关注点，应该是能将数据统合的那根线，能使数据产生整体大于局部之和的上层结构。这里的关注点，说的是数据分析前的需求分析，你需要这些数据做什么，你对数据的直觉反应是否可以通过这些数据进行完整全面的验证，没有回答好这些问题，拥有再多的数据也不过是一堆数字，一如果组排列整齐的感光器，而不是一个能分别美丑的眼眸。&lt;/p&gt;&lt;p&gt;数据的扩大不会必然带来视野和格局的扩大，一个朋友说起她分析"降关税"的感悟，她说道，如果逗留在税率本身，思路变死，只能接受竞争对手增多局面；如果挖掘到贸易自由化层面，格局变大，处处即是机遇；格局大小，决定对策，大格局涵盖小格局，小格局看上去不可思议，在大格局下都显得理所当然，她在bloomberge数据端倒弄半小时之后，意识到，相比这些数据库，wind都弱爆了。仅仅有国际化视野是不够的，更需要有国际化数据。而数据来源一旦多元，就一定要有去伪存真的步骤，去除重复，剔除噪音，清洗缺失值，使数据做的同步，准确，完整。这是当前数据处理中最耗时的步骤，而如何避免在数据清洗时过度补偿，如何避免丢弃过多有用数据，则是最需要智慧的。&lt;/p&gt;&lt;p&gt;大数据不是指数据量的大，也不是指数据来源的广（数据的维数大），而是指数据间的关系复杂（复杂网络的涌现），数据中既包含有用的信号，也包含无用的噪音。但不同维度的数据可以互相验证，互为因果，从而带来数据间的有序性。数据在不断的变化中，而变化的趋势又受制于你观察数据之外的环境因素，这环境因素具有自我指称的特性，也许数据之所以变化，就是因为你观察数据这一行为造成的。有序性就是负熵，就满足薛定谔说的生命的特征。&lt;/p&gt;&lt;p&gt;若你能知道何时需要收集数据，何时收集的足够的数据足够做决策了，那么你就孕育了一组数据，如果你能坚持不懈的更新数据，不放过数据间的细微变化，你就养育了一组数据，如果你能让你的数据与大千世界中那些鱼龙混杂的数据对上号，然后会心一笑，或是发现不同维度的数据带来了不同的结论，然后追根追底，那么你的数据就通过成人礼，如果你能及时的发现你拥有的数据已发生了Bifurcation，不可能通过小修小补来描述现实，那么你就可以安排这组数据的葬礼。你若有这样的态度，不论你的数据量有多大，处理数据的模型有多简单，你都拥有了大数据的灵魂。若是你只知道管中窥豹，以偏概全，如盲人摸象一般，那么数据量，数据维数，数据处理能力的增长只能同比扩大你的知识与谬误。&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/24773653&amp;pixel&amp;useReferer"/&gt;</description><author>许铁-巡洋舰科技</author><pubDate>Sun, 08 Jan 2017 08:25:56 GMT</pubDate></item><item><title>如何高效的学习</title><link>https://zhuanlan.zhihu.com/p/24760820</link><description>本文内容来自与一本书 《高效工作的秘密》，作者 Peter&lt;p&gt;既然要高效，首先需要的是&lt;b&gt;避免去做重复的工作&lt;/b&gt;，这意味着要在学习的每一步把基础打结实。而这就牵涉到本文的题目-磨刀不误砍柴工，即通过有意的制造不那么流畅的信息流动来学习。&lt;/p&gt;&lt;p&gt;首先先看14年普林斯顿的Pam Mueller发表了一项研究，比较了UCLA和普林斯顿学生不同的上课记笔记的方式对学习成绩的影响。研究者排除了用传统方法记笔记的学生在课下用功更多等其他因素的影响后发现，使用传统的纸和笔做笔记的学生比用笔记本的学生得A的比例多一倍。&lt;/p&gt;&lt;p&gt;该如何解释这一现象了。一种解释是用电脑记笔记的时候会有更多的干扰，比如弹出的电邮和SMS，但考虑到14年智能手机的普及，这个因素也不能解释全部效应。在论文中，作者给出的解释是，用纸和笔记笔记不如电脑打字快，用电脑记笔记的学生记下的笔记数量会是用笔来记录学生的两倍，然而用笔来记录的学生的笔记是有背景信息的。也就是说，正因为用手写字不如在电脑上打字那么快捷，促使学生主动去思考那些需要做笔记，而正是这些思考使得学生取得了好成绩。&lt;/p&gt;&lt;p&gt;进一步的研究发现，用纸来做笔记的学生的笔记会有更多的问句。他们会记录下学到的概念和知识可以用来回答那些问题。他们的笔记也会包含更多的图，这可能是因为在纸上画图比用电脑画图要方便。这是这些特征使得研究者总结道他们的笔记起到将知识连接起来的作用。&lt;/p&gt;&lt;p&gt;描述这个实验，是为了引出《Smarter Faster Better》这本书提出的高效学习之策，&lt;b&gt;主动的构建一个不那么流畅的信息接收通路&lt;/b&gt;。流畅的信息接收会让学习者以为自己已经学会了，从而不深挖一个概念的内涵。而不那么流畅的信息接收意味着学习者要不时停下来去想想该怎么用自己的话来重述新知，（用电脑记笔记的学生打字速度快，可以完整的写下教授说的话，一字不差。而用笔来做记录的学生却不得不用自己的话对教授所讲的去做缩写。正是这个过程使得学生对知识掌握的更深）&lt;/p&gt;&lt;p&gt;按照这本书提出的建议，高效学习的秘诀是下面几条&lt;/p&gt;&lt;p&gt;1 &lt;b&gt;用自己的话把学到的知识讲出来&lt;/b&gt;，最好用不同的方式和视角，这里是需要头脑风暴和跨界思维的地方。&lt;/p&gt;&lt;p&gt;2 在介绍每个知识点之前，说&lt;b&gt;清楚这个知识点回答了那些问题&lt;/b&gt;，给出的答案是否能将问题完全解决，这里需要清晰的逻辑，避免答非所问&lt;/p&gt;&lt;p&gt;3 强迫自己&lt;b&gt;为所学的知识点找出应用具体的应用场景&lt;/b&gt;，应用的场景可以是真实存在的两难 （dilemma），也可以是虚构的。每个场景需要包含when where who 和what，和所学的知识将用来说明why 或者how。&lt;/p&gt;&lt;p&gt;书中还给出了一种可以用来高效学习的游戏，这个游戏我们也许在聚会玩过的&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-09e7beb0a9ab4310dc688fece045890d.png" data-rawwidth="566" data-rawheight="555"&gt;比如你新学了一些机器学习的算法，你就可以和你小伙伴玩这个游戏，给出一个算法的集合，你们轮流问对方一系列Yes or No 的问题来猜出到底是哪一个算法，这个游戏能帮你理清不同概念间的关系。如果你想用更少的问题就猜出来，你必须掌握一个概念间真正能将其区分开的是什么。只有找到了每个知识最独特的一点，你才能在需要用到知识时快速建立起索引（避免提取不相关的信息）。只有在多个维度上都将知识进行了划分，才能将所需全部的知识点一网打尽。而这正是体现高效学习的成果的时候。最后要指出的是，学习是一个持续不断的过程，将学习的过程可以看成产品的&lt;b&gt;迭代&lt;/b&gt;，如同书中的表格所画，高效的学习如同精益创业一样，也需要造出一些Proof of Concept 的产品。正如记笔记，最好的笔记应该是在课上记下问题，画出概述图，下课后再将笔记补齐。最初的笔记是原型产品，不追求面面俱到，但要求能形成闭环，即包含问题，也包括分析和解决方案。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-b3cd2edd62af70011abdf3dc60377840.png" data-rawwidth="566" data-rawheight="376"&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/24760820&amp;pixel&amp;useReferer"/&gt;</description><author>许铁-巡洋舰科技</author><pubDate>Sat, 07 Jan 2017 08:39:37 GMT</pubDate></item><item><title>大咖征集令，不限学科，用你的Coursera证书实现知识变现</title><link>https://zhuanlan.zhihu.com/p/24760399</link><description>&lt;p&gt;看完罗胖的跨年演讲精华，我越发相信古人的那句话“技多不压身”，有信息过载，却绝对不会有技能过载，智慧过载。罗胖说得到想做最好的内容分发商，而在我眼中，最好的内容提供方却是下面的这三家&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-75a70bf6d900c1604de8e2fe3efc2d23.jpg" data-rawwidth="570" data-rawheight="288"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-47fdb854cfb33a4028733012b7855809.jpg" data-rawwidth="400" data-rawheight="300"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-c9940b499c840ece71a2734423c1c93a.png" data-rawwidth="400" data-rawheight="300"&gt;&lt;p&gt;为什么这么说，不止是因为这里的课程是来自于全球顶尖高校的第一手科学家，更因为最好的东西都不是免费的，不是交钱就能够得到的，而是要你先去花时间和精力去投入。在这方面，每个人都有着相同的起点。 下图是 董飞老师 讲述 MOOC 转化率较低时用到的图。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-3f0d4ad82aef9c94ed7c1262bc7712e1.jpg" data-rawwidth="640" data-rawheight="360"&gt;&lt;p&gt;所以说，每一个在在线教育平台拿到了证书的同学，都是万里挑一的学霸。如果你也是这样一位学霸，那么你可以用你的知识来变现，怎么办，请听我细细说来。&lt;/p&gt;&lt;p&gt;首先请您将您的MOOC证书截图（不管是上述的3个平台，还是其他的MOOC 平台的证书）+ 你对你学过的这门课程（任何专业的课程都可以的）的介绍以及你的学习心得总结成一篇小文 （500 字以上，最好附带一些截图或思维导图） + 你的分答账号或微信号（如果你愿意） + 你的自我介绍 发到邮箱 guoruidong517@126.com 。 在通过基本的资质审核后，我们会在 微信/微博/今日头条/知乎 上发布你的学习心得。之后你会成为这门课的TA， 如果读者觉得你修过的课程足够有趣，也愿意学习，那么Ta 在学习中遇到任何问题，都可以通过分答向你提问，而回答问题，即是温故而知新的过程，也是知识变现的过程。&lt;/p&gt;&lt;p&gt;不过知识分享不止是为了变现，还是为了自我提升。如果你的投稿被接受，你将可以进入巡洋舰的社群 参考&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651380856&amp;amp;idx=1&amp;amp;sn=dab774c3fc102149fe2e4ce7acc0e0f8&amp;amp;scene=21#wechat_redirect" data-editable="true" data-title="巡洋舰群001号体验报告" class=""&gt;巡洋舰群001号体验报告&lt;/a&gt;，如果你的MOOC课程 与数据科学或者计算机编程相关，我们还会推荐你去集智AI学园去做讲师，从而录制视频课程，实现进一步的知识变现。当然，如果你想去找实习，巡洋舰的社群从来都不缺少机会。&lt;/p&gt;&lt;p&gt;好了，就说这么多，有MOOC 证书的伙伴是不是已经跃跃欲试了，哪怕只是向更多人炫耀一下自己的证书，这个动机就足够了。再说一遍投稿邮箱 guoruidong517@126.com 邮件标题请注明 MOOC 证书+学习心得分享。&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/24760399&amp;pixel&amp;useReferer"/&gt;</description><author>许铁-巡洋舰科技</author><pubDate>Sat, 07 Jan 2017 04:48:47 GMT</pubDate></item><item><title>今年，我们一起来做一边做慈善一边做一个知识社群</title><link>https://zhuanlan.zhihu.com/p/24739084</link><description>&lt;p&gt;知识值多钱？无价。既然如此，那知识变现应该很容易吧。可不是吗？罗辑思维得到APP上那么多专栏作者不都做到了吗？更多知乎大牛不也正在做吗？&lt;/p&gt;&lt;p&gt;若你是这么想的，你就没有看清楚事情的本质。信息爆炸的时代，知识作为一种公共商品，本身因为缺少稀缺性是很难变现的。大V们提供的服务，是帮我们甄别信息，从而让我们能够在碎片时间，用更高的性价比得到浓缩后的知识。&lt;/p&gt;&lt;p&gt;然而如果你的认知架构没有给新的观点留出位置，没有搭好相应的框架，那么即使你接受到了高性价比的知识，也无法改变自己的为人做事的习惯。&lt;/p&gt;&lt;p&gt;所以我在过去的一年通过坚持写作来深挖自己的大脑，把那些杂草，那些不符合现代科学研究成果，缺乏逻辑严密性的部分去除掉，从而为自己接受新的观点做好“预实验”，我觉得这就是个人的认知管理的起点。比如 &lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651381741&amp;amp;idx=1&amp;amp;sn=790f0bcd936def79845952693f90f18a&amp;amp;chksm=84f3f1acb38478ba102eafc69810cc3fbd6acc00d6e88ad3b741a65c025eeee1d722ff43489f&amp;amp;scene=21#wechat_redirect" data-editable="true" data-title="当看只干货成为一种本能，你进步了多少" class=""&gt;当看只干货成为一种本能，你进步了多少&lt;/a&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651381885&amp;amp;idx=1&amp;amp;sn=3a743abefeba751cfb313bb12a27b696&amp;amp;chksm=84f3ce3cb384472afeb791a1973993d6c11f05f0c798147b526783b9e628cee3655f67edc27b&amp;amp;scene=21#wechat_redirect" data-editable="true" data-title="读这本书不会让你变聪明，但会让你避免犯错"&gt;读这本书不会让你变聪明，但会让你避免犯错&lt;/a&gt; 和&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651381838&amp;amp;idx=1&amp;amp;sn=faa997b762fda40415d4c195c590b10a&amp;amp;chksm=84f3ce0fb384471961b7196a07776b7f1ac47fea6f5d6d12cdd6a1891716b0832b6c9a2fb754&amp;amp;scene=21#wechat_redirect" data-editable="true" data-title="绞杀榕，黏鸟树自然界的生存之道能教给我们什么" class=""&gt;绞杀榕，黏鸟树自然界的生存之道能教给我们什么&lt;/a&gt;&lt;/p&gt;&lt;p&gt;将这一过程分享，希望更多的人来参与，这是我做这个公众号的本心。也想搞和读者的互动，比如&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=401961224&amp;amp;idx=1&amp;amp;sn=1654f80860bade4dddae51a8301c5a8c&amp;amp;scene=21#wechat_redirect" data-editable="true" data-title="读好书，要我们不只是说说而已&amp;lt;交叉学科好书读书召集令&amp;gt;"&gt;读好书，要我们不只是说说而已&amp;lt;交叉学科好书读书召集令&amp;gt;&lt;/a&gt; 后来觉得，让读者读完一本书，再写读书笔记，这有些门槛太高。&lt;/p&gt;&lt;p&gt;最近看到了“小密圈“这个工具，又动了做分享知识社群的念头。这个工具操作很方便，你只需要在微信里关注“小密圈” 公众号，就可以看到自己加入圈子的内容，不需要打开额外的应用。&lt;/p&gt;&lt;p&gt;相比于微信群，小密圈除了人数更多，其优点还在于对文件，这种半衰期相比于语音和聊天更长的形式能进行更方便的管理。对于较大一些的文件，也可以在小密圈而不是微信群中分享。使用者可以对群中的文件进行留言，方便针对每一个文件的讨论，还可对文件加入标签，便于索引和搜索。&lt;/p&gt;&lt;p&gt;在我们设想的知识社群中，我们会：&lt;/p&gt;&lt;p&gt;1）不定期分享 混沌巡洋舰群 参考&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651380856&amp;amp;idx=1&amp;amp;sn=dab774c3fc102149fe2e4ce7acc0e0f8&amp;amp;scene=21#wechat_redirect" data-editable="true" data-title="巡洋舰群001号体验报告"&gt;巡洋舰群001号体验报告&lt;/a&gt;中讨论的精华，分享的链接（带标签，介绍），有一些我想发到朋友圈的内容，怕刷屏打扰到别人的，都会发到这，当然少不了铁哥的心灵砒霜 参考&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651381792&amp;amp;idx=1&amp;amp;sn=f3c1774033999fa8786e0dc7ec977ce0&amp;amp;chksm=84f3ce61b3844777b7abb4bacbae9aa79e63323a2dd6347fe63ad6d5366e35d10abfa90760b7&amp;amp;scene=21#wechat_redirect" data-editable="true" data-title="铁哥行思录"&gt;铁哥行思录&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;2） 每周至少1次分享1组“得到APP或混沌研习社”上的优质音频（选自多个专栏及读书解读，但不限于一个专栏），每组长度1小时以上，争取做到结合一个话题，连接多个专栏的优质内容。&lt;/p&gt;&lt;p&gt;3） 不定期分享电子书或有声书或视频资源。&lt;/p&gt;&lt;p&gt;4） 可能涌现的其他好玩的东东&lt;/p&gt;&lt;p&gt;至于收费，就定在52元，50是这个平台允许的最小的收费值了，而加入一个知识社群，多少是有点2的行为吧，就自嘲一次吧。&lt;/p&gt;&lt;p&gt;这是我一个月之前的想法，然而之后我的想法变化了，我觉得知识社群不该这么搞，不该只有线上的交流，还应该有些落到实处的地方。我很欣赏Better Read 公众号 做的好书漂流活动，但我觉得这样的活动还不够去中心化，我希望在我这里的知识社群中，我希望再加入我自己设计的两个活动。&lt;/p&gt;&lt;p&gt;假设你有一本你打算分享（多本书也可以，省邮费的），你可以在这个社群中分享，之后如果有人对这本书感兴趣，可以留下地址，书的主人会将书以&lt;em&gt;到付&lt;/em&gt;的形式寄给你，想读这本书的人只需要出邮费，就可以得到一本或多本书。不过读者拿到书之后，每本书有两月的阅读时间，需要在两月之内对一本书提交一篇不小于300字的&lt;strong&gt;读书笔记&lt;/strong&gt;，（收到多本书的人可以有更多的时间来写读书笔记，每两月一本书的要求不高）否则会被移除出社群。这里管理员只需要记录什么时候读者收到了书，然后提前以群公告提醒读者写读书笔记就好。至于在这之中产生的读书笔记，如果读者愿意，我们都会发到巡洋舰的公众号和知乎专栏中。&lt;/p&gt;&lt;p&gt;但如果读者不只想写读书笔记，还想对更多人以&lt;strong&gt;群讲座&lt;/strong&gt;的形式讲一讲，那也可以在群里通过公告的形式来做分享，时间不少于10分钟就好。提前2天在社群中通知，分享之后主讲可以贴出自己的微信收钱二维码。这里不止限于读书报告的群讲座，你可以讲讲你所在的行业，讲讲你的见闻，这就是上面所说的可能涌现的其他好玩的东东。巡洋舰也会对群里的分享进行整理，发布在公众号和知乎专栏中。&lt;/p&gt;&lt;p&gt;以上的两件事，都是需要门槛的，所以要收费吗？这个逻辑不是这样的。小额的收费是验证诚意，而上面的活动必须要参与者能做到相互信任，你付过钱的东西，多少会在乎一些。但由于这个社群是要尽可能去中心化的，所以收到的钱将不能分给某一位大牛，所以收到的钱去做慈善，是最公平，也是最体现去中心化意图的选择。既然要做的是知识社群，那怎么能忘记了缺少知识的弱势群体了。所以每一位参与社群的人，我们都会拿出你所付的52元中的49元来&lt;strong&gt;做慈善&lt;/strong&gt;。（为什么是49元，因为小密圈提现时会收管一定比例理费的）。&lt;/p&gt;&lt;p&gt;关于做慈善，这是一件需要说几句的事。不是像罗一笑那样，也不是捐给大的基金会，而是由一群前华为人一对一的捐给山里的孩子，给她们提供书籍和过冬的棉衣。至于这件事，可以在网上查找“前华为人慈善捐助基金”，笔者参与过他们的活动，志愿者做事很认真，一对一的将善款送到当地孩子的手上，该机构还会提供明晰的收据。&lt;/p&gt;&lt;p&gt;好了，就说这么多，最后放上二维码，长按（或扫描）二维码入群，现在群里已有400多小伙伴了。加入后别忘了关注 小密圈 公众号，点击我的圈子，就可以看到每天分享的连接和消息了。或者也可以下载小密圈的APP，也可以参与知识社区的建立。&lt;/p&gt;&lt;p&gt;https://wx.xiaomiquan.com/mweb/views/joingroup/join_group.html?group_id=1484248542&amp;amp;secret=twnncv0z2iipl7c7jbdr192833707f71&amp;amp;extra=2c360470c8b4bac041b74044a9ed1dcfc63ca0730a98c98dd8e3be45862725af (二维码自动识别)&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/24739084&amp;pixel&amp;useReferer"/&gt;</description><author>许铁-巡洋舰科技</author><pubDate>Thu, 05 Jan 2017 22:13:31 GMT</pubDate></item><item><title>【巡洋舰首发】有趣的机器学习 第六章:如何用深度学习进行【语音识别】？</title><link>https://zhuanlan.zhihu.com/p/24703268</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-9852cb5c6c0693428ceb483cd84297dc_r.jpg"&gt;&lt;/p&gt;&lt;p&gt;原文：Adam Geitgey&lt;/p&gt;&lt;p&gt;原文链接：&lt;a href="https://medium.com/@ageitgey/machine-learning-is-fun-part-6-how-to-do-speech-recognition-with-deep-learning-28293c162f7a#.42h1r63ev" data-editable="true" data-title="medium.com 的页面"&gt;https://medium.com/@ageitgey/machine-learning-is-fun-part-6-how-to-do-speech-recognition-with-deep-learning-28293c162f7a#.42h1r63ev&lt;/a&gt;&lt;/p&gt;&lt;p&gt;翻译：巡洋舰科技——赵95&lt;/p&gt;&lt;p&gt;你是不是看烦了各种各样对于深度学习的报导，却不知其所云？我们要来改变这个问题。&lt;/p&gt;&lt;p&gt;有趣的机器学习 前五章已更新！点此查看&lt;a href="https://zhuanlan.zhihu.com/p/24339995" class="" data-editable="true" data-title="第一章：最简明入门指南"&gt;第一章：最简明入门指南&lt;/a&gt;、&lt;a href="https://zhuanlan.zhihu.com/p/24344720" class="" data-editable="true" data-title="第二章：用机器学习制造【超级马里奥】的关卡"&gt;第二章：用机器学习【制造超级马里奥】的关卡&lt;/a&gt;、&lt;a href="https://zhuanlan.zhihu.com/p/24524583" class="" data-editable="true" data-title="第三章：图像识别【鸟or飞机】"&gt;第三章：图像识别【鸟or飞机】&lt;/a&gt;&lt;a href="https://zhuanlan.zhihu.com/p/24567586" class="" data-editable="true" data-title="第四章：用深度进行【人脸识别】"&gt;第四章：用深度进行【人脸识别】&lt;/a&gt;&lt;a href="https://zhuanlan.zhihu.com/p/24590838" class="" data-editable="true" data-title="第五章：使用深度学习进行【语言翻译】和 序列的魔力"&gt;第五章：使用深度学习进行【语言翻译】和 序列的魔力&lt;/a&gt;&lt;a href="https://zhuanlan.zhihu.com/p/24703268" data-title="第六章：如何用深度学习进行【语音识别】" class="" data-editable="true"&gt;第六章：如何用深度学习进行【语音识别】&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;语音识别正在“入侵”我们的生活。它内置在我们的手机，游戏主机和智能手表里。它甚至在自动化我们的家园。只需50美元，你可以买到一个Amazon Echo Dot -
一个能够让你订购比萨，获知天气预报，甚至购买垃圾袋的魔术盒——只要你大声说出你的需求：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-3ffa4aec52021655b172e93e11d88274.jpg" data-rawwidth="1000" data-rawheight="552"&gt;&lt;/h2&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-3ffa4aec52021655b172e93e11d88274.jpg" data-rawwidth="1000" data-rawheight="552"&gt;&lt;p&gt;&lt;i&gt;Alexa，订一个大号的比萨！&lt;/i&gt;&lt;/p&gt;&lt;p&gt;Echo Dot机器人在（2016年圣诞）这个假期太受欢迎了，以至于Amazon似乎都没货了！&lt;/p&gt;&lt;p&gt;然而语音识别已经出现了几十年了，为何它才刚刚成为主流呢？原因是，深度学习，终于让语音识别，能够在非严格可控的环境下也能准确的识别。&lt;/p&gt;&lt;p&gt;吴恩达教授(百度首席科学家，人工智能和机器学习领域国际上最权威的学者之一，也是在线教育平台Coursera的联合创始人)长期以来预测，随着语音识别从95％精确度上升到99％，它将成为我们与计算机交互的主要方式。这个想法是基于，4％的精确度实际就是“太不靠谱”与“极度实用”之间的差别。感谢深度学习，我们终于达到了顶峰。&lt;/p&gt;&lt;p&gt;让我们了解一下如何用深度学习进行语音识别吧！&lt;/p&gt;&lt;p&gt;&lt;b&gt;机器学习并不总是一个黑盒&lt;/b&gt;&lt;/p&gt;&lt;p&gt;如果你知道&lt;a href="https://zhuanlan.zhihu.com/p/24590838" data-editable="true" data-title="神经机器翻译"&gt;神经机器翻译&lt;/a&gt;是如何工作的，那么你可能会猜到，我们可以简单地将声音送入到神经网络中，并训练使之生成文本：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-d347c3fae5f4e2bdc78bfbcd9259cacd.png" data-rawwidth="1000" data-rawheight="285"&gt;&lt;/p&gt;&lt;p&gt;这就是用深度学习进行语音识别的核心，但目前我们还没有完全做到（至少在我写这篇文章的时候没做到——我打赌，在未来的几年我们可以做到）。&lt;/p&gt;&lt;p&gt;最大的问题是言速不同。一个人可能很快的说“hello!”而另一个人可能会非常缓慢说“heeeelllllllllllllooooo!”。这产生了一个更长的声音文件和更多的数据。这两个声音文件都应该被识别为完全相同的文本“hello！”而事实证明，把各种长度的音频文件自动对齐到一个固定长度的文本是很难的一件事情。&lt;/p&gt;&lt;p&gt;为了解决这个问题，我们必须使用一些特殊的技巧和一些除了深度神经网络以外的特殊处理。让我们看看它是如何工作的吧！&lt;/p&gt;&lt;p&gt;&lt;b&gt;将声音转换成“位（&lt;/b&gt;&lt;b&gt;Bit&lt;/b&gt;&lt;b&gt;）”&lt;/b&gt;&lt;/p&gt;&lt;p&gt;语音识别的第一步是很显而易见的——我们需要将声波输入到计算机当中。&lt;/p&gt;&lt;p&gt;在&lt;a href="https://zhuanlan.zhihu.com/p/24524583" data-editable="true" data-title="第3章"&gt;第3章&lt;/a&gt;中，我们学习了如何把图像视为一个数字序列，以便我们直接将其输入进神经网络进行图像识别：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-1a8437a32c108cfe01bfa868d82a380d.jpg" data-rawwidth="581" data-rawheight="580"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;图像只是图片中每个像素深度的数字编码序列&lt;/i&gt;&lt;/p&gt;&lt;p&gt;但声音是作为&lt;b&gt;&lt;i&gt;波&lt;/i&gt;&lt;/b&gt;&lt;b&gt;&lt;i&gt;(Waves)&lt;/i&gt;&lt;/b&gt; 的形式传播的。我们如何将声波转换成数字呢？让我们使用我说的“hello”这个声音片段我们例子：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-6aad3a0f2fac76e461a557346435cbcb.png" data-rawwidth="1250" data-rawheight="379"&gt;&lt;/p&gt;&lt;p&gt;我说“hello”的波形&lt;/p&gt;&lt;p&gt;声波是一维的。（译者注：其实是二维的，有时间，还有振幅）在每个时刻，基于波的高度，它们有一个值(译者注：叫做振幅)。让我们把声波的一小部分放大看看：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-72f469ef60c261b6ba6c51d5b67f7d32.png" data-rawwidth="1250" data-rawheight="370"&gt;&lt;/p&gt;&lt;p&gt;为了将这个声波转换成数字，我们只记录声波在等距点的高度：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-926cf143d810e67eb3614e4318223e72.jpg" data-rawwidth="1250" data-rawheight="482"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;给声波采样&lt;/i&gt;&lt;/p&gt;&lt;p&gt;这被称为&lt;b&gt;&lt;i&gt;采样&lt;/i&gt;&lt;/b&gt;&lt;b&gt;&lt;i&gt;Sampling&lt;/i&gt;&lt;/b&gt;。我们每秒读取数千次，并把声波在该时间点的高度用一个数字记录下来。这基本上就是一个未压缩的.wav音频文件。&lt;/p&gt;&lt;p&gt;“CD音质”的音频是以44.1khz（每秒44,100个读数）进行采样的。但对于语音识别，16khz（每秒16,000个采样）的采样率足以覆盖人类语音的频率范围。&lt;/p&gt;&lt;p&gt;让我们把“Hello”的声波每秒采样16,000次。这是前100个采样：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-f011f9c607f2d99cf05e33e6572649dc.png" data-rawwidth="1250" data-rawheight="79"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;每个数字表示在一秒钟的&lt;/i&gt;&lt;i&gt;16000&lt;/i&gt;&lt;i&gt;分之一处的声波的振幅&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;数字采样小助手&lt;/b&gt;&lt;/p&gt;&lt;p&gt;你可能认为采样只是对原始声波进行粗略近似估计，因为它只是间歇性的读取。我们的读数之间有间距，所以我们会丢失数据，对吗？&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-4381d449423b9e4079e02ebb594219e9.png" data-rawwidth="1250" data-rawheight="535"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;数字采样能否完美重现原始声波？那些间距怎么办？&lt;/i&gt;&lt;/p&gt;&lt;p&gt;但是，由于&lt;b&gt;&lt;i&gt;采样定理&lt;/i&gt;&lt;/b&gt;&lt;b&gt;&lt;i&gt;(Nyquist theorem)&lt;/i&gt;&lt;/b&gt;，我们知道我们可以利用数学，从间隔的采样中完美的重建原始模拟声波——只要以我们希望得到的最高频率的两倍来采样就可以。&lt;/p&gt;&lt;p&gt;我提到这一点，是因为&lt;a href="http://gizmodo.com/dont-buy-what-neil-young-is-selling-1678446860" data-editable="true" data-title="几乎每个人都会犯这个错误"&gt;几乎每个人都会犯这个错误&lt;/a&gt;，并误认为使用更高的采样率总是能获得更好的音频质量。其实并不是。&lt;/p&gt;&lt;p&gt;&lt;b&gt;预处理我们的采样声音数据&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们现在有一个数列，其中每个数字代表16000分之一秒的声波振幅。&lt;/p&gt;&lt;p&gt;我们&lt;i&gt;可以&lt;/i&gt;把这些数字输入到神经网络中，但是试图直接分析这些采样来进行语音识别仍旧是困难的。相反，我们可以通过对音频数据进行一些预处理来使问题变得更容易。&lt;/p&gt;&lt;p&gt;让我们开始吧，首先将我们的采样音频分组为20毫秒长的块儿。这是我们第一个20毫秒的音频（即我们的前320个采样）：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-6378f673fb49bc8b806ae6a7af1aaa15.png" data-rawwidth="1250" data-rawheight="270"&gt;&lt;p&gt;将这些数字绘制为简单折线图，图中给出了20毫秒时间内原始声波的粗略估计：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-a6383b8f598750acd6aa3e473e791603.png" data-rawwidth="1250" data-rawheight="338"&gt;&lt;/p&gt;&lt;p&gt;虽然这段录音只有&lt;i&gt;50&lt;/i&gt;&lt;i&gt;分之一&lt;/i&gt;秒的长度，但即使这样短暂的时长也是由不同频率的声音复杂的组合在一起的。一些低音，中音，甚至高音混在一起。但总的来说，就是这些不同频率的声音混合在一起，才组成了人类的语音。&lt;/p&gt;&lt;p&gt;为了使这个数据更容易被神经网络处理，我们将把这个复杂的声波分解成一个个组件部分。我们将一步步分离低音部分，下一个最低音部分，以此类推。然后通过将（从低到高）每个频带中的能量相加，我们就为各个类别（音调）的音频片段创建了一个&lt;i&gt;指纹&lt;/i&gt;&lt;i&gt;fingerprint&lt;/i&gt;。&lt;/p&gt;&lt;p&gt;想象你有一段某人在钢琴上演奏C大调和弦的录音。这个声音是由三个音符组合而成的 - C，E和G – 他们都混合在一起组成一个复杂的声音。我们想把这个复杂的声音分解成单独的音符，以此来发现它们是C，E和G。这和我们（语音识别）的想法一样。&lt;/p&gt;&lt;p&gt;我们使用被称为&lt;i&gt;傅里叶变换&lt;/i&gt;&lt;i&gt;Fourier Transform&lt;/i&gt;的数学运算来做到这一点。它将复杂的声波分解为简单的声波。一旦我们有了这些单独的声波，我们将每一个包含的能量加在一起。&lt;/p&gt;&lt;p&gt;最终结果是每个频率范围的重要程度，从低音（即低音音符）到高音。下面的每个数字表示我们的20毫秒音频剪辑中每个50Hz频带中有多少能量：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-183c59db1dab03f2470b361502423c69.png" data-rawwidth="1250" data-rawheight="253"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;列表中的每个数字表示在&lt;/i&gt;&lt;i&gt;50Hz&lt;/i&gt;&lt;i&gt;频带中有多少能量&lt;/i&gt;&lt;/p&gt;&lt;p&gt;但是当你绘制一个图表时，你很容易看到这些能量：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-e3b95b07ac52830dbd035e54279eb839.png" data-rawwidth="1250" data-rawheight="178"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;你可以看到，我们的&lt;/i&gt;&lt;i&gt;20&lt;/i&gt;&lt;i&gt;毫秒声音片段中有很多低频率能量，然而在更高的频率中并没有太多的能量。这是典型“男性”的声音。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;如果我们对每20毫秒的音频块重复这个过程，我们最终会得到一个频谱图（每一列从左到右都是一个20ms的块）：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-405c35d00e5e82e30e5dff7fbd39050f.png" data-rawwidth="1250" data-rawheight="442"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;“&lt;/i&gt;&lt;i&gt;hello&lt;/i&gt;&lt;i&gt;”声音剪辑的完整谱图&lt;/i&gt;&lt;/p&gt;&lt;p&gt;频谱图很酷，因为你可以从音频数据中实际&lt;i&gt;看到&lt;/i&gt;音符和其他音高模式。对于神经网络来说，相比于原始声波，它可以更加容易地从这种数据中找到规律。因此，这就是我们将实际输入到神经网络的数据表示方式。&lt;/p&gt;&lt;p&gt;&lt;b&gt;从短声音识别字符&lt;/b&gt;&lt;/p&gt;&lt;p&gt;现在我们有了一个易于处理的格式的音频，我们将把它输入到深度神经网络中去。神经网络的输入将会是20毫秒的音频块。对于每个小的音频切片(Audio Slice)，它将试图找出当前正在说的声音对应的&lt;i&gt;字母（&lt;/i&gt;&lt;i&gt;letter&lt;/i&gt;&lt;i&gt;）&lt;/i&gt;。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-450c92d19922fe3b9f81be163c632cdc.png" data-rawwidth="1000" data-rawheight="602"&gt;&lt;/p&gt;&lt;p&gt;我们将使用一个循环神经网络 - 即一个拥有记忆来影响未来预测的神经网络。这是因为它预测的每个字母都应该能够影响下一个字母的预测可能性。例如，如果我们到目前为止已经说了“HEL”，那么很有可能我们接下来会说“LO”来完成“Hello”。我们不太可能会说“XYZ”之类根本读不出来的东西。因此，具有先前预测的记忆有助于神经网络对未来进行更准确的预测。&lt;/p&gt;&lt;p&gt;当我们通过神经网络运行我们的整个音频剪辑（一次一块）之后，我们将最终得到每个音频块和其最可能被说出的那个字母的一个映射（mapping）。这是一个看起来说”Hello”的映射：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-5740ab153ac140af0d2809d3b0da1b58.png" data-rawwidth="1250" data-rawheight="797"&gt;&lt;/p&gt;&lt;p&gt;我们的神经网络正在预测我说的那个词很有可能是“HHHEE_LL_LLLOOO”。但它同时认为我说的也可能是“HHHUU_LL_LLLOOO”，或者甚至是“AAAUU_LL_LLLOOO”。&lt;/p&gt;&lt;p&gt;我们遵循一些步骤来整理这个输出。首先，我们将用单个字符替换任何重复的字符：&lt;/p&gt;&lt;p&gt;HHHEE_LL_LLLOOO变为HE_L_LO&lt;/p&gt;&lt;p&gt;HHHUU_LL_LLLOOO变为HU_L_LO&lt;/p&gt;&lt;p&gt;AAAUU_LL_LLLOOO变为AU_L_LO&lt;/p&gt;&lt;p&gt;然后，我们将删除所有空白处：&lt;/p&gt;&lt;p&gt;HE_L_LO变为HELLO&lt;/p&gt;&lt;p&gt;HU_L_LO变为HULLO&lt;/p&gt;&lt;p&gt;AU_L_LO变为AULLO&lt;/p&gt;&lt;p&gt;这让我们得到三种可能的转录 - “Hello”，“Hullo”和“Aullo”。如果你大声说出这些词，所有这些声音都类似于“Hello”。因为它每次只预测一个字符，神经网络会得出一些试探性的转录。例如，如果你说“He would not go”，它可能会给一个可能 “He wud net go” 的转录。&lt;/p&gt;&lt;p&gt;解决问题的诀窍是将这些基于发音的预测与基于书面文本（书籍，新闻文章等）大数据库的可能性得分相结合。你抛弃掉最不可能的转录，而保留住最现实的转录。&lt;/p&gt;&lt;p&gt;在我们可能的转录“Hello”，“Hullo”和“Aullo”中，显然“Hello”将更频繁地出现在文本数据库中（更不用说在我们原始的基于音频的训练数据中），因此它可能是正确的。所以我们会选择“Hello” 而不是其他作为我们的最后的转录。完成！&lt;/p&gt;&lt;p&gt;&lt;b&gt;等一下！&lt;/b&gt;&lt;/p&gt;&lt;p&gt;你可能会想“但是如果有人说Hullo”怎么办？这是一个有效的词。也许“Hello”是错误的转录！&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-1b6af94ac603955ad4532f75b2c846e7.jpg" data-rawwidth="700" data-rawheight="467"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;“&lt;/i&gt;&lt;i&gt;Hullo&lt;/i&gt;&lt;i&gt;！&lt;/i&gt;&lt;i&gt;Who dis&lt;/i&gt;&lt;i&gt;？&lt;/i&gt;&lt;/p&gt;&lt;p&gt;当然可能有人实际上说“Hullo”而不是“Hello”。但是这样的语音识别系统（基于美国英语训练）基本上不会产生“Hullo”作为转录。用户说“Hullo”，它总是会认为你在说“Hello”，无论你发“U”的声音有多重。&lt;/p&gt;&lt;p&gt;试试看！如果你的手机被设置为美式英语，尝试让你的手机助手识别单词“Hullo”。这不行！它掀桌子不干了(╯‵□′)╯︵┻━┻！它总是会理解为“Hello”。&lt;/p&gt;&lt;p&gt;不识别“Hullo”是一个合理的行为，但有时你会发现令人讨厌的情况:你的手机就是不能理解你说的有效的语句。这就是为什么这些语音识别模型总是被更多的数据训练来修复这些少数情况。&lt;/p&gt;&lt;p&gt;&lt;b&gt;我能建立自己的语音识别系统吗？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;机器学习最酷炫的事情之一就是它有时看起来十分简单。你得到一堆数据，把它输入到机器学习算法当中去，然后就能神奇的得到一个运行在你的游戏笔记本电脑的显卡上的世界级AI系统...&lt;i&gt;对吧&lt;/i&gt;？&lt;/p&gt;&lt;p&gt;这在某些情况下是真实的，但对于语音识别并不成立。语音识别是一个困难的问题。你必须克服几乎无限的挑战：质量差的麦克风，背景噪音，混响和回声，口音变化，还有很多很多。所有这些问题都需要存在于你的训练数据中，以确保神经网络可以应对它们。&lt;/p&gt;&lt;p&gt;这里有另外一个例子：你知不知道，当你在一个充满噪音的房间里说话时，你不自觉地提高你的音调，以便能够盖过噪音。人类在什么情况下都可以理解你，但神经网络需要训练来处理这种特殊情况。所以你需要人们对着噪音大声说话的训练数据！&lt;/p&gt;&lt;p&gt;要构建一个能在Siri，Google Now！或Alexa等平台上运行的语音识别系统，你将需要&lt;i&gt;大量&lt;/i&gt;的训练数据 -如果你不雇佣数百人为你录制的话，它需要的训练数据比你自己能够获得的数据要多得多。由于用户对低质量语音识别系统的容忍度很低，因此你不能吝啬。没有人想要一个只有80%的时间有效的语音识别系统。&lt;/p&gt;&lt;p&gt;对于像谷歌或亚马逊这样的公司，在现实生活中记录的数十万小时的人声语音就是&lt;i&gt;黄金&lt;/i&gt;。这就是将他们世界级语音识别系统与你自己的系统拉开差距的地方。让你免费使用&lt;i&gt;Google Now!&lt;/i&gt;或Siri或只要50美元购买Alexa而没有订阅费的意义就是：&lt;b&gt;&lt;i&gt;让你尽可能多的使用他们&lt;/i&gt;&lt;/b&gt;。你对这些系统所说的每一句话都会&lt;b&gt;&lt;i&gt;永远记录&lt;/i&gt;&lt;/b&gt;下来，并用作未来版本语音识别算法的训练数据。这才是他们的真实目的！&lt;/p&gt;&lt;p&gt;不相信我？如果你有一部安装了Google Now!的Android手机，请&lt;a href="https://myactivity.google.com/udc/vaa" data-editable="true" data-title="点击这里"&gt;点击这里&lt;/a&gt;收听你自己对它说过的每一句话：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-36f57014e18b8cb9968b9327fc7f0bc7.png" data-rawwidth="1000" data-rawheight="501"&gt;&lt;/p&gt;&lt;p&gt;你可以通过Alexa在Amazon上找到相同的东西。然而，不幸的是，苹果并不让你访问你的Siri语音数据。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;因此，如果你正在寻找一个创业的想法，我不建议你尝试建立自己的语音识别系统来与Google竞争。相反，你应该找出一种能让人们把他们说几个小时话的录音给予你的方法。这种数据可以是你的产品。&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;路在远方&lt;/b&gt;&lt;b&gt;…&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这个用来处理不同长度音频的算法被称为Connectionist Temporal Classification或CTC。&lt;a href="goog_970985545" data-editable="true" data-title="你可以阅读"&gt;你可以阅读&lt;/a&gt;&lt;a href="http://www.cs.toronto.edu/~graves/icml_2006.pdf" data-editable="true" data-title="2006年文章"&gt;2006年文章&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;百度的Adam Coates在湾区深度学习学校做了关于“深度学习语音识别”的精彩演讲。你可以在YouTube上&lt;a href="https://youtu.be/9dXiAecyJrY?t=13874" data-editable="true" data-title="观看这段视频"&gt;观看这段视频&lt;/a&gt;（他的演讲从3分51秒开始）。强烈推荐。&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/24703268&amp;pixel&amp;useReferer"/&gt;</description><author>九五要当学霸</author><pubDate>Wed, 04 Jan 2017 10:22:57 GMT</pubDate></item><item><title>【巡洋舰首发】有趣的机器学习 第五章：使用深度学习进行【语言翻译】 和 序列的魔力</title><link>https://zhuanlan.zhihu.com/p/24590838</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-14ed4f1b20aea7acc67d5ad1aeee408e_r.jpg"&gt;&lt;/p&gt;&lt;p&gt;原文：Adam Geitgey&lt;/p&gt;&lt;p&gt;原文链接：&lt;a href="https://medium.com/@ageitgey/machine-learning-is-fun-part-5-language-translation-with-deep-learning-and-the-magic-of-sequences-2ace0acca0aa#.t5upusfij" class="" data-editable="true" data-title="medium.com 的页面"&gt;https://medium.com/@ageitgey/machine-learning-is-fun-part-5-language-translation-with-deep-learning-and-the-magic-of-sequences-2ace0acca0aa#.t5upusfij&lt;/a&gt;&lt;/p&gt;&lt;p&gt;翻译：巡洋舰科技——赵95&lt;/p&gt;&lt;p&gt;你是不是看烦了各种各样对于深度学习的报导，却不知其所云？我们要来改变这个问题。&lt;/p&gt;&lt;p&gt;有趣的机器学习 前六章已更新！点此查看&lt;a href="https://zhuanlan.zhihu.com/p/24339995" class="" data-editable="true" data-title="第一章：最简明入门指南"&gt;第一章：最简明入门指南&lt;/a&gt;、&lt;a href="https://zhuanlan.zhihu.com/p/24344720" class="" data-editable="true" data-title="第二章：用机器学习制造【超级马里奥】的关卡"&gt;第二章：用机器学习【制造超级马里奥】的关卡&lt;/a&gt;、&lt;a href="https://zhuanlan.zhihu.com/p/24524583" class="" data-editable="true" data-title="第三章：图像识别【鸟or飞机】"&gt;第三章：图像识别【鸟or飞机】&lt;/a&gt;&lt;a href="https://zhuanlan.zhihu.com/p/24567586" class="" data-editable="true" data-title="第四章：用深度进行【人脸识别】"&gt;第四章：用深度进行【人脸识别】&lt;/a&gt;&lt;a href="https://zhuanlan.zhihu.com/p/24590838" class="" data-editable="true" data-title="第五章：使用深度学习进行【语言翻译】和 序列的魔力"&gt;第五章：使用深度学习进行【语言翻译】和 序列的魔力&lt;/a&gt;&lt;a href="https://zhuanlan.zhihu.com/p/24703268" data-title="第六章：如何用深度学习进行【语音识别】" class="" data-editable="true"&gt;第六章：如何用深度学习进行【语音识别】&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;我们都知道并且喜欢使用Google翻译，这个网站可以瞬时翻译100种不同的人类语言，就好像有魔法一样。他甚至存在于我们的手机和智能手表上面：（知乎无法上传太大的GIF，看图请戳原文）&lt;/h2&gt;&lt;p&gt;Google翻译背后的科技被称为机器翻译。它改变了世界，在本来根本不可能的情况下让(不同语言的)人们完成了沟通。&lt;/p&gt;&lt;p&gt;但我们都知道，在过去的15年里，高中学生已经使用Google翻译...额 ...&lt;i&gt;协助&lt;/i&gt;他们完成他们的西班牙语作业。这已经不是新闻了…？&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-a9fcbd775a70567a8d49ea73e42f4358.jpg" data-rawwidth="853" data-rawheight="192"&gt;&lt;/p&gt;&lt;p&gt;事实证明，在过去两年，深度学习已经完全改写了我们的机器翻译方法。那些对语言翻译一无所知的深度学习研究人员正在利用一个个相对简单的机器学习解决方案，来打败世界上最好的专家建造的语言翻译系统。&lt;/p&gt;&lt;p&gt;这一突破背后的技术被称为&lt;b&gt;序列到序列学习&lt;/b&gt;&lt;b&gt;sequence to sequence learnin&lt;/b&gt;g。这是一项非常强大的技术，被用于解决许多种类的问题。在我们看到它如何被用于翻译之后，我们还将学习这个算法是怎样用来编写AI聊天机器人和描述图片的。&lt;/p&gt;&lt;p&gt;我们开始吧！&lt;/p&gt;&lt;p&gt;&lt;b&gt;让计算机翻译&lt;/b&gt;&lt;/p&gt;&lt;p&gt;那么我们该如何编写代码，才能让计算机翻译人类的语言呢？&lt;/p&gt;&lt;p&gt;最简单的方法，就是把句子中的每个单词，都替换成翻译后的目标语言单词。这里有一个简单的例子，把西班牙语逐字翻译成英语：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-db380a8bf032afa9533d358389de99d6.png" data-rawwidth="1000" data-rawheight="180"&gt;&lt;/p&gt;&lt;p&gt;我们只是用匹配的英语单词替换每个西班牙单词。&lt;/p&gt;&lt;p&gt;这很容易实现，因为你所需要是一本字典来查找每个单词的翻译。但结果并不好，因为它忽略了语法和上下文的联系。&lt;/p&gt;&lt;p&gt;因此，下一件你可能要做的事，就是开始添加特定语言规则以改进结果。例如，你可能将两个常用词翻译为词组。你可能互换名词和形容词的顺序，因为他们在西班牙语中以相反的顺序出现：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-bed5ad249e62bea5ac3958c725dd0160.png" data-rawwidth="1000" data-rawheight="250"&gt;&lt;/p&gt;&lt;p&gt;这真的有效！如果我们就继续添加更多的规则，直到我们可以应对每一部分语法，我们的程序应该就能够翻译任何句子了，对吧？&lt;/p&gt;&lt;p&gt;这就是最早的机器翻译系统的工作原理。语言学家提出了许多复杂的规则，并逐一编程实现。一些世界上最聪明的语言学家在冷战期间辛勤努力了多年，才创建出了一些更容易理解俄罗斯人交流的翻译系统。&lt;/p&gt;&lt;p&gt;不幸的是，这种套路只对简单问题适用，比如说像天气预报这样结构简单的文档。它对于真实世界的文字来说并不可靠。&lt;/p&gt;&lt;p&gt;问题是，人类语言并不总是遵循固定的规则。人类语言充满了各种特殊情况，区域差异，或者干脆就不按套路出牌(#‵′)凸。我们说英语的方式更多地受到几百年前入侵的人的影响，而不是由坐下来定义语法规则的人。&lt;/p&gt;&lt;p&gt;&lt;b&gt;利用统计数据使计算机更好地翻译&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在基于规则的系统失效之后，一些新的翻译方法被开发出来了，他们基于概率和统计的模型而不是语法规则。&lt;/p&gt;&lt;p&gt;建造一个基于统计的翻译系统需要大量的训练数据，其中完全相同的文本被翻译成至少两种语言。这种双重翻译的文本称为&lt;b&gt;&lt;i&gt;平行语料库parallel corpora&lt;/i&gt;&lt;/b&gt;。18世纪的科学家以同样的方式在罗塞塔石碑上面从希腊语中找出埃及象形文字。(译者注：罗塞塔石碑，高1.14米，宽0.73米，制作于公元前196年，刻有&lt;a href="http://baike.baidu.com/view/8498.htm" data-editable="true" data-title="古埃及"&gt;古埃及&lt;/a&gt;国王&lt;a href="http://baike.baidu.com/view/192409.htm" data-editable="true" data-title="托勒密五世"&gt;托勒密五世&lt;/a&gt;登基的诏书。石碑上用&lt;a href="http://baike.baidu.com/view/11761660.htm" data-editable="true" data-title="希腊文字"&gt;希腊文字&lt;/a&gt;、&lt;a href="http://baike.baidu.com/view/138248.htm" data-editable="true" data-title="古埃及文字"&gt;古埃及文字&lt;/a&gt;和当时的通俗体文字刻了同样的内容，这使得近代的&lt;a href="http://baike.baidu.com/view/67249.htm" data-editable="true" data-title="考古学家"&gt;考古学家&lt;/a&gt;得以有机会对照各语言版本的内容后，解读出已经失传千余年的埃及象形文之意义与结构，而成为今日研究古埃及历史的重要里程碑)以同样的方式，计算机可以使用平行语料库猜测如何将文本从一种语言转换为另一种语言。&lt;/p&gt;&lt;p&gt;幸运的是，有很多双重翻译的文本已经存在在世界的各个角落。例如，欧洲议会将其诉讼程序翻译成21种语言。因此，研究人员经常使用这些数据来帮助建造翻译系统。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-8405085e2a71fe599a8a0365b8a61596.png" data-rawwidth="1000" data-rawheight="167"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;训练数据通常令人兴奋！但这只是无数条政府文件而已...&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;用概率的思维思考&lt;/b&gt;&lt;/p&gt;&lt;p&gt;统计翻译系统的根本不同，在于它们试图生成不止一个精确的翻译。相反，他们生成成千上万种可能的翻译，然后他们按照可能最正确的给这些翻译排名。他们通过与训练数据的相似性来估计有多“正确”。以下是它的工作原理：&lt;/p&gt;&lt;p&gt;&lt;b&gt;第1步：将原始句子分成块&lt;/b&gt;&lt;/p&gt;&lt;p&gt;首先，我们将我们的句子分成简单的块，每一块都可以轻松翻译：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-ec2cc836a5ae27ee35ed01a912036d31.png" data-rawwidth="1000" data-rawheight="87"&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;第2步：找到每一块的所有可能的翻译&lt;/b&gt;&lt;/p&gt;&lt;p&gt;接下来，我们将翻译每块文字，我们将通过寻找我们数据库中所有人类翻译过的相同词块来完成我们的翻译。&lt;/p&gt;&lt;p&gt;要着重注意的是，我们不只是在一本简简单单的翻译字典中查找这些词块。相反，我们看到是真实的人在真实的句子中如何翻译这些相同的词。这有助于我们捕获到在不同语境中所有不同的表达方式：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-4a56bab19fc10b4fd4f52cc2cf9351b5.png" data-rawwidth="1000" data-rawheight="471"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;即使最常见的短语也有很多种可能的翻译&lt;/i&gt;&lt;/p&gt;&lt;p&gt;这些可能的翻译中的有一些会比其他翻译更频繁地使用。根据我们训练数据中每个翻译出现的频率，我们可以给它设定一个分数。&lt;/p&gt;&lt;p&gt;例如，有人说“Quiero”更多的时候是指“我想要”而不是“我尝试”。所以，我们可以使用我们训练数据中 “Quiero”被翻译成“我想要”的频率，给“我想要”这个翻译更多的权重。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第3步：生成所有可能的句子，找到最有可能的那句&lt;/b&gt;&lt;/p&gt;&lt;p&gt;接下来，我们将使用这些词块的每种可能翻译来组合生成一堆可能的句子。&lt;/p&gt;&lt;p&gt;从第二步中列出的翻译过的词块中，我们可以通过不同组合方式生成将近2,500个不同的句子。下面是一些例子：&lt;/p&gt;&lt;p&gt;&lt;i&gt;I love | to leave | at | the seaside | more tidy.&lt;/i&gt;&lt;i&gt;I mean | to be on | to | the open space | most lovely.I like | to be |on | per the seaside | more lovely.I mean | to go | to | the open space | most tidy.&lt;/i&gt;&lt;/p&gt;&lt;p&gt;但在真实世界中，因为有不同的语序和词块分解方法，所以实际上有更多可能的词块组合：&lt;/p&gt;&lt;p&gt;&lt;i&gt;I try | to run | at | the prettiest | open space.&lt;/i&gt;&lt;i&gt;I want | to run | per | the more tidy | open space.I mean | to forget | at | the tidiest | beach.I try | to go | per | the more tidy | seaside.&lt;/i&gt;&lt;/p&gt;&lt;p&gt;现在需要扫描所有这些生成的句子，找到那个听起来“最像人话”的句子。&lt;/p&gt;&lt;p&gt;为此，我们将每个生成的句子与来自英语书籍和新闻故事的数百万个真实句子进行比较。我们拥有的英语文本越多越好。&lt;/p&gt;&lt;p&gt;我们采用这种可能的翻译：&lt;/p&gt;&lt;p&gt;&lt;i&gt;I try | to leave | per | the most lovely | open space.&lt;/i&gt;&lt;/p&gt;&lt;p&gt;很可能没有人用英语写过这样的句子，所以它不会与我们的数据库任何句子非常相似。我们给这个可能的翻译设定一个低概率的得分。&lt;/p&gt;&lt;p&gt;但看看下面这个可能的翻译：&lt;/p&gt;&lt;p&gt;&lt;i&gt;I want | to go | to | the prettiest | beach.&lt;/i&gt;&lt;/p&gt;&lt;p&gt;这个句子和我们的训练集中的句子很类似，所以它将获得一个高概率的得分。&lt;/p&gt;&lt;p&gt;在尝试过所有可能的句子之后，我们会选择那个，既是最有可能的词块翻译，又与真实英语句子最相似，的句子。&lt;/p&gt;&lt;p&gt;我们最后的翻译将是“&lt;i&gt;I want | to go | to | the prettiest | beach.&lt;/i&gt;&lt;/p&gt;&lt;p&gt;我想去最漂亮的海滩。”不错！&lt;/p&gt;&lt;p&gt;&lt;b&gt;有里程碑意义的统计机器翻译&lt;/b&gt;&lt;/p&gt;&lt;p&gt;当有足够多的训练数据的时候，统计机器翻译系统的性能要优于基于语言规则的系统。 Franz Josef Och基于这些想法并做出了改进，并在21世纪初使用它们构建了Google翻译。机器翻译终于可以被全世界使用。&lt;/p&gt;&lt;p&gt;早期的时候，基于概率翻译的“愚蠢”方法居然比语言学家设计规则系统做的更好，这让每个人都感到惊讶。这导致了80年代的时候，研究人员会(有点刻薄的)说：&lt;/p&gt;&lt;p&gt;“每当我炒了一个语言学家鱿鱼的时候，我的翻译准确度就会上升。” &lt;a href="https://en.wikipedia.org/wiki/Frederick_Jelinek" data-editable="true" data-title="Frederick Jelinek"&gt;&lt;i&gt;Frederick Jelinek&lt;/i&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;统计机器翻译的局限性&lt;/b&gt;&lt;/p&gt;&lt;p&gt;虽然统计机器翻译系统效果还不错，但是他们难于构建和维护。每一对需要翻译的新语言，都需要专业人士对一个全新的多步骤“翻译流水线”进行调试和修整。&lt;/p&gt;&lt;p&gt;因为构建这些不同的流水线需要做太多工作，所以我们必须进行权衡。如果你要用Google翻译把格鲁吉亚语翻译成泰卢固语（印度东部德拉维拉语言），那么作为一个中间步骤，它必须先翻译成英语。因为并没有太多格鲁吉亚到泰卢固语的翻译需求，所以在这一对语言上投入太多并没有太大意义。相比于英语翻译到法语，它可能会使用一个更低级的“翻译流水线”。&lt;/p&gt;&lt;p&gt;如果我们能让计算机为我们做所有令人讨厌的开发工作，这不更好么？&lt;/p&gt;&lt;p&gt;&lt;b&gt;让电脑翻译的更好——无需昂贵的专家们&lt;/b&gt;&lt;/p&gt;&lt;p&gt;机器翻译的核心是一个黑盒系统，它通过查看训练数据，自己就可以学习如何翻译。使用统计机器翻译，人们仍然需要建立和调整多步骤的统计模型。&lt;/p&gt;&lt;p&gt;2014年，KyungHyun Cho的团队取得了突破。他们发现了一种应用深度学习来构建这种黑盒系统的方法。他们的深度学习模型采用平行语料库，并使用它来学习如何在无任何人为干预的情况下在这两种语言之间进行翻译。&lt;/p&gt;&lt;p&gt;两个宏伟的方法使这成为可能 - 循 环神经网络和编码。通过巧妙地结合这两个想法，我们可以建立一个能够自学的翻译系统。&lt;/p&gt;&lt;p&gt;&lt;b&gt;循环神经网络&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们已经在第2章讨论过了循环神经网络，让我们快速回顾一下。&lt;/p&gt;&lt;p&gt;一个常规（非循环）神经网络是泛型机器学习算法，接收一序列数字并计算结果（基于先前的训练）。神经网络可以用作一个黑盒子，来解决很多问题。例如，我们可以基于房子的属性，使用神经网络来计算房屋的近似价格：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-6ea7212dd6e34f5ed60eec35acb7c756.png" data-rawwidth="860" data-rawheight="389"&gt;&lt;/p&gt;&lt;p&gt;但是像大多数机器学习算法一样，神经网络是无状态(Stateless)的。你输入一序列数字，神经网络计算并输出结果。如果再次输入相同的数字，它总是计算出相同的结果。它没有进行过的计算的记忆。换句话说，2 + 2总是等于4。&lt;/p&gt;&lt;p&gt;一个&lt;b&gt;循环神经网络（Recurrent Neural Network或简称RNN）&lt;/b&gt;是一个稍微改进过的神经网络的版本，区别是RNN先前的状态是可以被当做输入，再次带入到下一次计算中去。这意味着之前的计算结果会更改未来计算的结果！&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-d164b6165ed48bef689a837f6a70aca0.png" data-rawwidth="860" data-rawheight="556"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;人类痛恨他：一个黑科技就让机器变得更聪明！&lt;/i&gt;&lt;/p&gt;&lt;p&gt;我们为什么要这样做？无论我们上次计算结果是什么，2 + 2不应该总是等于4么？&lt;/p&gt;&lt;p&gt;这个技巧允许神经网络学习数据序列中的规律。例如，基于句子的前几个词，你可以使用它来预测句子中下一个最有可能的单词是什么：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-4c999bbcdf7e7ce9a691ce76438064de.jpg" data-rawwidth="887" data-rawheight="530"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;实现智能手机输入法的“自动更正”的方法之一&lt;/i&gt;&lt;i&gt;…&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;当你想要学习数据中的规律时，RNN将会非常有用。因为人类语言其实只是一个大而复杂的“规律”，自然语言处理的各个领域越来越多地使用RNN。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;如果你想了解更多关于RNN，你可以阅读第2章，我们使用了RNN来生成一本海明威写作风格的假书，然后使用同一个RNN生成了超级马里奥兄弟的游戏关卡。&lt;/p&gt;&lt;p&gt;&lt;b&gt;编码&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们需要回顾的另一个想法是&lt;b&gt;&lt;i&gt;编码Encoding&lt;/i&gt;&lt;/b&gt;。在第4章中作为脸部识别的一部分，我们谈到了编码。为了解释编码，让我们稍作调整，了解一下如何用电脑区分两个人。&lt;/p&gt;&lt;p&gt;当你试图用电脑区分两张脸时，你从每张脸收集不同的测量值，并与其他脸部比较这些测量值。例如，我们可以测量耳朵的大小或眼间的间距，比较两个图片的测量值以确定他们是否是同一个人。&lt;/p&gt;&lt;p&gt;你可能已经从观看热门影视剧CSI当中对这个想法耳熟能详了（知乎无法上传太大的GIF，看图请戳原文）。&lt;/p&gt;&lt;p&gt;把面部特征转换为一系列测量值的想法就是编码的例子之一。我们获取到原始数据（面部图片），并将其转换为代表这张脸的一系列测量值（编码）。&lt;/p&gt;&lt;p&gt;但是像我们在第4章中看到的，我们不必提出一个具体的面部特征列表来测量我们自己。相反，我们可以使用神经网络，让它自动从面部生成测量值。找出哪些测量值能够区分两个相似的人，计算机在这方面比我们做的更好：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-6e2b5cfcbd33b1105a4d8d40191c162d.png" data-rawwidth="1000" data-rawheight="499"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;这些是由神经网络产生的面部特征测量值，训练后的该神经网络可以保证不同的数字代表了不同人的面部。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;这是我们的&lt;i&gt;编码&lt;/i&gt;。它让我们用简单的东西（128个数字）代表非常复杂的东西（一张脸的图片）。现在比较两张脸更加容易了，因为我们只需要比较这128个数字而不是比较整张脸的图像。&lt;/p&gt;&lt;p&gt;你猜怎么着？我们可以用句子做同样的事情！我们可以把任何一个句子表达成一系列独特的编码：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-4fa1d6823b59d61bc84d290f4cf8adeb.png" data-rawwidth="1000" data-rawheight="479"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;这一序列数字代表的是英语句子“有趣的机器学习！”。不同的句子将由不同的数字集表示。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;为了生成这个编码，我们将句子输入到RNN中，一次一个词。最后一个词处理之后的最终结果，就将是表示整个句子的数值：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-520f649f58b1d522f1c38ff49153c590.jpg" data-rawwidth="877" data-rawheight="395"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;因为RNN具有记忆功能，能够记住处理过得每个词，所以它计算的最终编码表示句子中的所有词。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;棒极了，所以现在我们有一种方法来把一个整个句子表示成一组独特的数字！我们不知道编码中的每个数字是什么意思，但这并不重要。只要每一句话都能由一组独特的数字标识出来，那么我们就不需要准确地知道这些数字是如何生成的。&lt;/p&gt;&lt;p&gt;&lt;b&gt;让我们开始翻译吧！&lt;/b&gt;&lt;/p&gt;&lt;p&gt;好的，所以我们知道怎样使用RNN去个一句话编码并生成一组独特的数字。它有什么用呢？事情从这儿开始变得酷炫了！&lt;/p&gt;&lt;p&gt;如果我们使用两个RNNs并将它们首尾相连呢？第一个RNN可以给句子生成编码。然后，第二RNN遵循相反的逻辑，解码得到原始句子：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-473f0ea39bfa46879f0975c77272b8c8.png" data-rawwidth="1250" data-rawheight="336"&gt;&lt;/p&gt;&lt;p&gt;当然，编码然后再解码并得到原始语句并没有太大用处。但是如果（这里是问题的关键），我们训练第二个RNN，使它解码成西班牙语而不是英语，这会怎样？我们可以使用平行语料库训练数据来训练它：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-04ff81324066f8cc916e3b9773808cc9.png" data-rawwidth="1250" data-rawheight="334"&gt;&lt;/p&gt;&lt;p&gt;就像这样，我们有一个通用的方法，将一序列英语单词转换成同样的西班牙语单词序列！&lt;/p&gt;&lt;p&gt;这是一个强有力的想法：&lt;/p&gt;&lt;p&gt;l 这种方法主要受限于你拥有的训练数据量和你可以投入的计算机生产力。机器学习研究人员仅仅在在两年前发明了这个方法，但它已经表现的和统计机器翻译系统一样好了，而后者花了20年时间才开发完善。&lt;/p&gt;&lt;p&gt;l 这不依赖于任何关于人类语言规则的了解。算法自己计算出这些规则。这意味着你不需要专业人士来调整“翻译流水线”的各个步骤，计算机为你把这个做好了。&lt;/p&gt;&lt;p&gt;l 这种方法适用于几乎任何种类的&lt;b&gt;&lt;i&gt;序列到序列sequence-to-sequence&lt;/i&gt;&lt;/b&gt;问题！而且事实证明，许多有趣的问题都实际上是 序列到序列的问题。继续阅读了解其他你可以做的酷炫的事！&lt;/p&gt;&lt;p&gt;注意，我们忽略了一些处理真实数据会碰到的问题。例如，如何处理不同长度的输入和输出？这还需要一些额外的工作（请参见bucketing和padding）。非常用词翻译也是一个问题。&lt;/p&gt;&lt;p&gt;&lt;b&gt;构建你自己的序列到序列翻译系统&lt;/b&gt;&lt;/p&gt;&lt;p&gt;如果你想建立自己的语言翻译系统，这儿有一个包括可以在英语和法语之间翻译的TensorFlow的demo。然而，这并不是给胆小鬼或预算有限的人准备的。这仍然是一项新技术，并且资源有限。即使你有一台带有高级显卡的高级电脑，可能也需要连续一个月的时间来训练你自己的语言翻译系统。&lt;/p&gt;&lt;p&gt;此外，序列到序列语言翻译技术正在及快速地改进，以至于难以跟上。许多最近的改进（如添加注意机制attention mechanism或上下文跟踪tracking context）显着改善了翻译结果，但这些发展太过前沿，以至于他们甚至还没有维基百科页面。如果你想做认真的去做任何序列到序列学习，随着技术的发展，你需要持续保持更新，。&lt;/p&gt;&lt;p&gt;&lt;b&gt;序列到序列模型的无穷力量&lt;/b&gt;&lt;/p&gt;&lt;p&gt;那么，我们还能用序列到序列模型做什么呢？&lt;/p&gt;&lt;p&gt;大约一年前，Google的研究人员表示，你可以使用序列到序列模型来建造AI机器人。这个想法是如此简单，并且令人震惊的是，它真的有效。&lt;/p&gt;&lt;p&gt;首先，他们获取了一些Google员工和Google技术支持小组之间的聊天记录。然后他们训练了序列到序列模型，其中输入的句子就是雇员的问题，而技术支持团队的回复是该句子的“翻译”。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-b0e96c4e8b2853799ecc52ee39689f1a.png" data-rawwidth="1250" data-rawheight="341"&gt;&lt;/p&gt;&lt;p&gt;当用户与机器人进行交互时，他们将使用该系统“翻译”每个用户的消息以获得机器人的响应。&lt;/p&gt;&lt;p&gt;他们最终得到的是一个半智能机器人，（有时）可以回答真正的技术支持问题。下面是一部分用户和机器人之间的对话示例：&lt;/p&gt;&lt;p&gt;人：连接被拒绝或类似的东西&lt;/p&gt;&lt;p&gt;机器：我可以知道你连接的网络连接的版本吗？&lt;/p&gt;&lt;p&gt;人：我不确定我知不知道&lt;/p&gt;&lt;p&gt;机器：是网络连接提示任何用户证书？&lt;/p&gt;&lt;p&gt;人类：是的&lt;/p&gt;&lt;p&gt;机器：你现在在家还是在工作？办公室？&lt;/p&gt;&lt;p&gt;人：我在家&lt;/p&gt;&lt;p&gt;机器：试试这个。 goto &amp;lt;URL redacted&amp;gt;页面，然后输入您的姓名和密码&lt;/p&gt;&lt;p&gt;人类：完成&lt;/p&gt;&lt;p&gt;机器：尝试使用&amp;lt;NAME redacted&amp;gt;登录，然后检查其是否正常工作&lt;/p&gt;&lt;p&gt;人类：是的，现在它在工作！&lt;/p&gt;&lt;p&gt;机器：棒极了。还有什么我可以帮助你的？&lt;/p&gt;&lt;p&gt;他们还试图建立一个基于数百万部电影字幕的聊天机器人。他们的想法是，使用电影角色之间的对话作为一种训练机器人像人一样说话的方式。输入句子是一名角色的一句话，“翻译”是另一名角色在对话里回应他的内容：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-dffddd0667601ce5600454dfd82b5007.png" data-rawwidth="1250" data-rawheight="340"&gt;&lt;p&gt;他们得到了很有意思的结果。机器人不仅仅像一个人，更是显示出了一点点智能化：&lt;/p&gt;&lt;p&gt;人类：我的名字是david。我的名字是什么？&lt;/p&gt;&lt;p&gt;机器：david。&lt;/p&gt;&lt;p&gt;人：我的名字是约翰。我的名字是什么？&lt;/p&gt;&lt;p&gt;机器：约翰。&lt;/p&gt;&lt;p&gt;人类：你是领导还是追随者？&lt;/p&gt;&lt;p&gt;机器：我是领导者。&lt;/p&gt;&lt;p&gt;人类：你是追随者还是领导者？&lt;/p&gt;&lt;p&gt;机器：我是领导者。&lt;/p&gt;&lt;p&gt;这只是可能性的开始。我们将不局限于将一个句子转换成另一个句子，同样，我们制作一个图像到序列的模型，它可以将图像转换为文本！&lt;/p&gt;&lt;p&gt;Google的另一个团队通过将第一个RNN替换为卷积神经网络（如我们在第3章中所了解的那样）。这允许输入是图片而不是句子，其余的工作基本相同：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-9d899c93bdc3d566e6441d2e2a2f938e.png" data-rawwidth="1250" data-rawheight="341"&gt;&lt;/p&gt;&lt;p&gt;就像这样，（只要我们有很多很多的训练数据）我们就可以把图片变成单词！&lt;/p&gt;&lt;p&gt;Andrej Karpathy把这个想法进行了拓展，以构建一个通过分别处理图像的多个区域，来详细描述图像的系统：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-380c811bf4f9ffc0ebd1fa03427de50d.png" data-rawwidth="1000" data-rawheight="763"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;Andrej Karpathy论文中的图片&lt;/i&gt;&lt;/p&gt;&lt;p&gt;这个想法使得我们可以构建一个，能够按照奇怪的要求找到特定图片的图片搜索引擎：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-80cf134e8142811f9ba5f0f1561012a1.jpg" data-rawwidth="444" data-rawheight="356"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;例子来自&lt;a href="http://cs.stanford.edu/people/karpathy/deepimagesent/rankingdemo/" data-editable="true" data-title="image sentence ranking visualize"&gt;image sentence ranking visualize&lt;/a&gt;&lt;/i&gt;&lt;/p&gt;&lt;p&gt;甚至有研究人员正在研究相反的问题，仅仅基于文本描述产生一个完整的图片！&lt;/p&gt;&lt;p&gt;从这些例子，你可以开始想象的各种可能性。 到目前为止，序列到序列应用在从语音识别到计算机视觉各个领域。 我猜，明年会有更多的应用。&lt;/p&gt;&lt;p&gt;如果您想更深入地了解序列到序列模型和翻译，以下是一些推荐的资源：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=qGlmW2n4s1w" class="" data-editable="true" data-title="Richard Socher’s CS224D Lecture— Fancy Recurrent Neural Networks for Machine Translation"&gt;Richard Socher’s CS224D Lecture— Fancy Recurrent Neural Networks for Machine Translation&lt;/a&gt; (video)&lt;/li&gt;&lt;li&gt;&lt;a href="http://cs224d.stanford.edu/lectures/CS224d-Lecture15.pdf" class="" data-editable="true" data-title="Thang Luong’s CS224D Lecture — Neural Machine Transation"&gt;Thang Luong’s CS224D Lecture — Neural Machine Transation&lt;/a&gt; (PDF)&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.tensorflow.org/versions/r0.10/tutorials/seq2seq/index.html" class="" data-editable="true" data-title="TensorFlow’s description of Seq2Seq modeling"&gt;TensorFlow’s description of Seq2Seq modeling&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="http://www.deeplearningbook.org/contents/rnn.html" class="" data-editable="true" data-title="The Deep Learning Book’s chapter on Sequence to Sequence Learning"&gt;The Deep Learning Book’s chapter on Sequence to Sequence Learning&lt;/a&gt;(PDF)&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-c8693405235197b0a454b2c41cb432d6.png" data-rawwidth="1120" data-rawheight="808"&gt;&lt;/li&gt;&lt;/ul&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/24590838&amp;pixel&amp;useReferer"/&gt;</description><author>九五要当学霸</author><pubDate>Tue, 27 Dec 2016 17:03:08 GMT</pubDate></item><item><title>【巡洋舰首发】有趣的机器学习 第四章：用深度学习进行【人脸识别】</title><link>https://zhuanlan.zhihu.com/p/24567586</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-83f669a67c954c9331e03e5557bfc6eb_r.jpg"&gt;&lt;/p&gt;&lt;p&gt;原文：Adam Geitgey&lt;/p&gt;&lt;p&gt;原文链接：&lt;a href="https://medium.com/@ageitgey/machine-learning-is-fun-part-4-modern-face-recognition-with-deep-learning-c3cffc121d78#.asmzg3vx4" data-editable="true" data-title="medium.com 的页面"&gt;https://medium.com/@ageitgey/machine-learning-is-fun-part-4-modern-face-recognition-with-deep-learning-c3cffc121d78#.asmzg3vx4&lt;/a&gt;&lt;/p&gt;&lt;p&gt;翻译：巡洋舰科技——赵95&lt;/p&gt;&lt;p&gt;你是不是看烦了各种各样对于深度学习的报导，却不知其所云？我们要来改变这个问题。&lt;/p&gt;&lt;p&gt;有趣的机器学习 前六章已更新！点此查看&lt;a href="https://zhuanlan.zhihu.com/p/24339995" class="" data-editable="true" data-title="第一章：最简明入门指南"&gt;第一章：最简明入门指南&lt;/a&gt;、&lt;a href="https://zhuanlan.zhihu.com/p/24344720" class="" data-editable="true" data-title="第二章：用机器学习制造【超级马里奥】的关卡"&gt;第二章：用机器学习【制造超级马里奥】的关卡&lt;/a&gt;、&lt;a href="https://zhuanlan.zhihu.com/p/24524583" class="" data-editable="true" data-title="第三章：图像识别【鸟or飞机】"&gt;第三章：图像识别【鸟or飞机】&lt;/a&gt;&lt;a href="https://zhuanlan.zhihu.com/p/24567586" class="" data-editable="true" data-title="第四章：用深度进行【人脸识别】"&gt;第四章：用深度进行【人脸识别】&lt;/a&gt;&lt;a href="https://zhuanlan.zhihu.com/p/24590838" class="" data-editable="true" data-title="第五章：使用深度学习进行【语言翻译】和 序列的魔力"&gt;第五章：使用深度学习进行【语言翻译】和 序列的魔力&lt;/a&gt;&lt;a href="https://zhuanlan.zhihu.com/p/24703268" data-title="第六章：如何用深度学习进行【语音识别】" class="" data-editable="true"&gt;第六章：如何用深度学习进行【语音识别】&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;你有没有发现Facebook研发出了一种能够在你的照片中识别出你朋友的神之魔力？
之前，Facebook让你在照片里点击你的朋友，并输入他们的名字来标注出你的朋友。现在，只要你上传了一张照片，Facebook就魔力般的为你标注出你的每一个朋友：&lt;/h2&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-b414d836a7612bc12efc932b6a4b90bc.jpg" data-rawwidth="502" data-rawheight="346"&gt;&lt;p&gt;&lt;i&gt;Facebook&lt;/i&gt;&lt;i&gt;基于你之前的标注，自动标注出你照片中的人。我不确定这到底是有帮助性的还是非常阴险恐怖的。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;这种技术被称为人脸识别。你的朋友被标记了几次之后，Facebook的算法就能够识别你朋友的脸。
这是一项非常惊人的黑科技——Facebook的人脸识别准确率达到了98％，几乎与人类做的一样好！让我们来了解一下现代人脸识别是如何工作的！
但是，识别你的朋友这太容易了。
我们可以最大化扩展这项技术，来解决一个更具挑战性的问题——区分Will Ferrell（著名演员）和Chad Smith（著名摇滚音乐家）！&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-967774e47de559f90f39eb821b640f2c.jpg" data-rawwidth="1000" data-rawheight="562"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;一个是Will
Ferrell&lt;/i&gt;&lt;i&gt;，另一个是Chad Smith&lt;/i&gt;&lt;i&gt;。我保证他们不是同一个人！&lt;/i&gt;&lt;/p&gt;&lt;p&gt;如何用机器学习解决复杂问题？&lt;/p&gt;&lt;p&gt;到目前为止，在前三章，我们已经使用机器学习来解决了，一些只用一个步骤就可以解决的孤立问题——&lt;a href="https://zhuanlan.zhihu.com/p/24339995" data-title="第一章：估计房子的价格" class="" data-editable="true"&gt;第一章：估计房子的价格&lt;/a&gt;、&lt;a href="https://zhuanlan.zhihu.com/p/24344720" data-title="第二章：基于现有数据生成新数据" class="" data-editable="true"&gt;第二章：基于现有数据生成新数据&lt;/a&gt;（译者注：根据已有的超级马里奥的关卡生成新的关卡）、以及&lt;a href="https://zhuanlan.zhihu.com/p/24524583" data-title="第三章：判别图像当中是否包含某个物品" class="" data-editable="true"&gt;第三章：判别图像当中是否包含某个物品&lt;/a&gt;。
所有这些问题都可以通过下列步骤解决：选择一个机器学习算法，输入数据，并获得结果。&lt;/p&gt;&lt;p&gt;但是，人脸识别是由一系列的几个相关问题组成的：&lt;/p&gt;&lt;p&gt;首先，找到一张图片中的所有人脸&lt;/p&gt;&lt;p&gt;第二，对于每一张脸来说，无论光线明暗或面朝别处，它依旧能够识别出是同一个人的脸。&lt;/p&gt;&lt;p&gt;第三，能够在每一张脸上找出可用于与他人区分的独特之处，比如说眼睛有多大，脸有多长等等。&lt;/p&gt;&lt;p&gt;最后，将这张脸的特点与已知的所有人脸进行比较，以确定这个人的姓名。&lt;/p&gt;&lt;p&gt;作为人类，你的大脑总是在一瞬间自动做出了这些判断。实际上，人类在识别人脸这方面做得&lt;b&gt;&lt;i&gt;太好了&lt;/i&gt;&lt;/b&gt;，以至于他们会在日常物品中同样去“找脸”：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-ccb4dd22f6905c9825a7f369b3cd37dc.jpg" data-rawwidth="580" data-rawheight="250"&gt;&lt;/p&gt;&lt;p&gt;计算机不能进行这种高级泛化(generalization)（至少现在还不行...），所以我们必须分别教给他们，这个过程中的每一步是怎么做到的。&lt;/p&gt;&lt;p&gt;我们需要构建一个&lt;b&gt;流水线&lt;/b&gt;&lt;b&gt;(pipeline)&lt;/b&gt;，一个单独完成每个步骤并把结果发送给下一个步骤的流水线。换句话说，我们会将好几个机器学习算法连接到一起：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-7647e39242a7f7f7f5f0ec615eee3bf1.jpg" data-rawwidth="1000" data-rawheight="361"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;一个基础的探测人脸的流水线是怎样工作的&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;人脸识别——分步讲解&lt;/b&gt;&lt;/p&gt;&lt;p&gt;让我们一步一步地解决这个问题。
对于每个步骤，我们将学习一个不同的机器学习算法。
我并不会完全解释每一个的算法，否则这篇文章就变成了一本教科书。但你会学到每个步骤的精髓，以及如何在Python中使用&lt;a href="https://cmusatyalab.github.io/openface/" data-editable="true" data-title="OpenFace"&gt;OpenFace&lt;/a&gt;和&lt;a href="http://dlib.net/" data-editable="true" data-title="dlib"&gt;dlib&lt;/a&gt;来构建一个你自己的面部识别系统。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第一步：找出所有的面孔&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们流水线的第一步是面部检测。显然，在我们区分人脸之前，我们必须要照片中找到他们才行！&lt;/p&gt;&lt;p&gt;如果你在过去10年里使用过相机，你可能已经见过正在运行中的面部检测功能：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-bd16d8458af314c441f67c293f051f40.png" data-rawwidth="896" data-rawheight="459"&gt;&lt;/p&gt;&lt;p&gt;面部检测是相机很好的一个功能。
当相机可以自动拾取人脸时，它可以确保相机在拍摄时对焦到所有人脸。
不过，我们使用它另有其因——我们需要找到想要传递到流水线下一步的图像区域。&lt;/p&gt;&lt;p&gt;2000年初的时候， 当Paul
Viola和Michael
Jones 发明了一种能够快速在廉价相机上运行的一种脸部检测方法之后（译者注：这种算法也可以用来训练检测其他的物品，但是最经常还是被用于人脸的检测，其英文名称为Viola–Jones
object detection framework），面部检测在成为了主流。然而现在，更可靠的解决方案出现了。
我们将使用2005年发明的一种称为“&lt;b&gt;方向梯度直方图&lt;/b&gt;&lt;b&gt;(Histogram of Oriented Gradients)&lt;/b&gt;”的方法，或简称HOG。&lt;/p&gt;&lt;p&gt;要在一张图片中找到脸，我们首先将图像转换为黑白，因为我们并不需要颜色数据来找到脸：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-74fd08c6ce2f1c650a09272e7c7f7f57.jpg" data-rawwidth="511" data-rawheight="563"&gt;&lt;/p&gt;&lt;p&gt;然后，我们将查看图片中的每一个像素。
对于单个像素，我们要查看直接围绕着它的像素：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-bdc412d7dbe8c6f94becb144d21d3d1e.jpg" data-rawwidth="800" data-rawheight="282"&gt;&lt;/p&gt;&lt;p&gt;我们的目标是找出并比较当前像素与直接围绕它的像素的深度。
然后我们要画一个箭头来代表图像变暗的方向：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-8003fc861e178c2a4a65386d738e9634.jpg" data-rawwidth="500" data-rawheight="159"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;看这个像素和它周围的像素，图像向右上方变得越来越暗。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;如果你对图片中的&lt;b&gt;每一个像素&lt;/b&gt;重复这个过程，最终每个像素会被一个箭头取代。这些箭头被称为&lt;b&gt;梯度&lt;/b&gt;&lt;b&gt;gradients&lt;/b&gt;，它们能显示出图像上从明亮到黑暗的流动过程：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-a458e794e970703fd355f9a83aacf1ac.jpg" data-rawwidth="1000" data-rawheight="393"&gt;&lt;/p&gt;&lt;p&gt;这可能看起来非常随机，但其实我们有非常好的理由用梯度来代替像素。如果我们直接分析像素，同一个人明暗不同的两张照片将具有完全不同的像素值。但是如果只考虑亮度变化&lt;b&gt;&lt;i&gt;方向&lt;/i&gt;&lt;/b&gt;&lt;b&gt;&lt;i&gt;direction&lt;/i&gt;&lt;/b&gt;的话，明暗图像将会有同样的结果。这使得问题变得更容易解决！&lt;/p&gt;&lt;p&gt;但是保存每个像素的梯度太过细节化了，我们最终很有可能“一叶障目不见泰山missing the forest for the trees”。如果我们能从更高的角度上观察基本的明暗流动，我们就可以看出图像的基本规律，这会比之前更好。&lt;/p&gt;&lt;p&gt;为了做到这一点，我们将图像分割成一些16x16像素的小方块。在每个小方块中，我们将计算出每个主方向上有多少个梯度（有多少指向上，指向右上，指向右等）。然后我们将用指向性最强那个方向的箭头来代替原来的那个小方块。&lt;/p&gt;&lt;p&gt;最终的结果是，我们把原始图像变成了一个非常简单的表达形式，这种表达形式可以用一种简单的方式来捕获面部的基本结构：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-a2f4fde8df3dc047201f9add7850ca6f.jpg" data-rawwidth="800" data-rawheight="295"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;原始图像被表示成了HOG&lt;/i&gt;&lt;i&gt;形式，以捕获图像的主要特征，无论图像明暗度如何。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;为了在这个HOG图像中找到脸部，我们要所需要做的，就是找到我们的图像中，与已知的一些HOG样式中，看起来最相似的部分。这些HOG样式都是从其他面部训练数据中提取出来的：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-35e736853cc413f7d7d595ddb9bc56d9.png" data-rawwidth="1000" data-rawheight="697"&gt;&lt;/p&gt;&lt;p&gt;使用这种技术，我们现在可以轻松地在任何图片中找到脸部：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-83f669a67c954c9331e03e5557bfc6eb.jpg" data-rawwidth="1000" data-rawheight="563"&gt;&lt;/p&gt;&lt;p&gt;如果你想使用Python和dlib尝试这一步，&lt;a href="https://gist.github.com/ageitgey/1c1cb1c60ace321868f7410d48c228e1" data-editable="true" data-title="这些代码"&gt;这些代码&lt;/a&gt;显示了如何生成和查看HOG图像的表示。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第二步：脸部的不同姿势&lt;/b&gt;&lt;/p&gt;&lt;p&gt;哇，我们把图片中的脸部孤立出来了。
但现在，我们要处理的问题就是，对于电脑来说，面朝不同方向的同一张脸，是不同的东西：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-8cc2f0d8e403fa933a022a2d053b62d5.png" data-rawwidth="956" data-rawheight="389"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;人类可以很轻松地识别出到两个图片都是Will Ferrell&lt;/i&gt;&lt;i&gt;，但电脑会认为这两张图片是两个完全不同的人。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;为了解决这一点，我们将试图扭曲每个图片，使得眼睛和嘴唇总是在图像中的样本位置(Sample Place)。
这将使我们在接下来的步骤中，更容易比较脸部之间的不同。&lt;/p&gt;&lt;p&gt;为此，我们将使用一种称为&lt;b&gt;脸部标志点估计（&lt;/b&gt;&lt;b&gt;Face
Landmark Estimation&lt;/b&gt;&lt;b&gt;）&lt;/b&gt;的算法。 很多方法都可以做到这一点，但这次我们会使用由Vahid Kazemi和Josephine Sullivan在2014年发明的方法。&lt;/p&gt;&lt;p&gt;这一算法的基本思想是，我们找到人脸上普遍存在的68个特定点（称为Landmarks）——下巴的顶部，每只眼睛的外部轮廓，每条眉毛的内部轮廓等。接下来我们训练一个机器学习算法，能够在任何脸部找到这68个特定点：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-f7a513f83f2e4978e59f2becf43653a2.png" data-rawwidth="414" data-rawheight="394"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;我们将在每一张脸上定位的68&lt;/i&gt;&lt;i&gt;个Landmarks&lt;/i&gt;&lt;i&gt;。这张照片是由在OpenFace&lt;/i&gt;&lt;i&gt;工作的CMU&lt;/i&gt;&lt;i&gt;的Brandon Amos&lt;/i&gt;&lt;i&gt;创造的。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;这是在测试图片上定位68个标志点的结果：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-06fcc66230ba44b5533bcff134080209.jpg" data-rawwidth="1000" data-rawheight="871"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;友情提示：你也可以使用这一技术来实现自己的Snapchat&lt;/i&gt;&lt;i&gt;实时3D&lt;/i&gt;&lt;i&gt;脸部过滤器！ &lt;/i&gt;&lt;/p&gt;&lt;p&gt;现在，我们知道了眼睛和嘴巴在哪儿，我们将图像进行旋转，缩放和切变，使得眼睛和嘴巴尽可能靠近中心。我们不会做任何花哨的三维扭曲，因为这会让图像失真。我们只会使用那些能够保持图片相对平行的基本图像变换，例如旋转和缩放，（称为仿射变换）：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-962d576949169ea9618b8307fdca513a.png" data-rawwidth="1000" data-rawheight="280"&gt;&lt;/p&gt;&lt;p&gt;现在无论脸部怎样扭曲变形，我们都能将眼睛和嘴巴向中间挪动到大致相同的位置。这将使我们的下一步更加准确。&lt;/p&gt;&lt;p&gt;如果你想自己使用Python和dlib来尝试完成这一步的话，这里有一些代码帮你&lt;a href="https://gist.github.com/ageitgey/ae340db3e493530d5e1f9c15292e5c74" data-editable="true" data-title="寻找脸部标志点"&gt;寻找脸部标志点&lt;/a&gt;和&lt;a href="https://gist.github.com/ageitgey/82d0ea0fdb56dc93cb9b716e7ceb364b" data-editable="true" data-title="图像变形"&gt;图像变形&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第3步：给脸部编码&lt;/b&gt;&lt;/p&gt;&lt;p&gt;现在我们要面临最核心的问题了——如何区分脸部。这才是事情变得非常有趣的地方！&lt;/p&gt;&lt;p&gt;最简单的人脸识别方法，就是直接把我们在步骤2中发现的未知人脸，与我们已经标注了人脸图片作比较。当我们发现未知的面孔与一个以前标注过的面孔看起来及其相似的时候，它必须是同一个人。这似乎是一个很好的主意，对吗？&lt;/p&gt;&lt;p&gt;实际上这种方法有一个巨大的问题。像Facebook这种拥有数十亿用户和数万亿张照片的网站，是不可能去循环比较每张先前标记的脸的，这浪费的时间太长了。他们需要在毫秒内识别人脸，而不是几个小时。&lt;/p&gt;&lt;p&gt;我们需要的是一种从每张人脸上都可以提取一些基本特性的方法。然后，我们可以用同样的方式测量未知的面孔，并找到与已知的脸最相近的测量。例如，我们可以测量每个耳朵的大小，眼睛之间的间距，鼻子的长度等。如果你曾经看过像CSI这样的犯罪类型的电视剧，那么你就知道我在说什么了。&lt;/p&gt;&lt;p&gt;&lt;b&gt;测量人脸的最可靠的方法&lt;/b&gt;&lt;/p&gt;&lt;p&gt;好的，那么我们应该测量面部的哪些数值，来建立我们的已知脸部数据库呢？耳朵的大小？鼻子的长度？眼睛的颜色？还有什么？&lt;/p&gt;&lt;p&gt;事实证明，对于我们人类来说一些显而易见的测量值（比如眼睛颜色），并没有对计算机产生太大的影响。研究人员发现，最准确的方法是让计算机自己找出测量值并自己收集。深度学习比人类更好地了解脸部的哪些部分是重要的测量值。&lt;/p&gt;&lt;p&gt;所以，解决方案是训练一个深度卷积神经网络（就像我们在第3章做的那样）。但是，并不是像上次那样训练我们的网络来识别图片对象，我们将训练它为脸部生成128个测量值。&lt;/p&gt;&lt;p&gt;每次训练要观察3个不同的脸部图像：&lt;/p&gt;&lt;p&gt;1.加载一张已知的人的面部训练图像&lt;/p&gt;&lt;p&gt;2.加载同一个人的另一张照片&lt;/p&gt;&lt;p&gt;3.加载另外一个人的照片&lt;/p&gt;&lt;p&gt;&lt;b&gt;然后，算法查看它自己为这三个图片生成的测量值。再然后，它稍微调整神经网络，以确保它为第1&lt;/b&gt;&lt;b&gt;张和第2&lt;/b&gt;&lt;b&gt;章生成的测量值接近，而第2&lt;/b&gt;&lt;b&gt;张和第3&lt;/b&gt;&lt;b&gt;张生成的测量值略有不同。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-e504e8e72005e8d26b6cdfb89cb1834b.png" data-rawwidth="1000" data-rawheight="827"&gt;&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在为几千个不同的人的数百万图像重复该步骤数百万次之后，神经网络学习了如何可靠地为每个人生成128个测量值。同一个人的任何十张不同的照片应该给出大致相同的测量值。&lt;/p&gt;&lt;p&gt;机器学习专业人士把每个面孔上的128个测量值称为“嵌入（Embedding）”。将复杂的原始数据（如图片）缩减为可由计算机生成的一个数列的方法在机器学习（特别是语言翻译）中出现了很多次。我们正在使用的这种方法是由Google的研究人员在2015年发明的，但其实这是许多类似的方法之一。&lt;/p&gt;&lt;p&gt;&lt;b&gt;给我们的脸部图像编码&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这个通过训练卷积神经网络来输出脸部嵌入的过程，需要大量的数据和计算机应用。即使使用昂贵的Nvidia Telsa显卡，它也需要大约24小时的连续训练，才能获得良好的准确性。&lt;/p&gt;&lt;p&gt;但一旦网络训练完成，它可以生成任何面孔的测量值，即使它从来没有见过这些面孔！所以这种训练只需一次即可。幸运的是，OpenFace上面的大神已经做完了这些，并且他们发布了几个训练过可以直接使用的网络，。谢谢Brandon Amos和他的团队！&lt;/p&gt;&lt;p&gt;所以我们需要做的，就是通过他们的预训练网络来处理我们的脸部图像，以获得128个测量值。这是我们测试图像的一些测量值：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-6e2b5cfcbd33b1105a4d8d40191c162d.png" data-rawwidth="1000" data-rawheight="499"&gt;&lt;/p&gt;&lt;p&gt;那么，这128个数字到底测量了脸部的哪些部分？我们当然不知道，但是这对我们并不重要。我们关心的是，当看到同一个人的两张不同的图片时，我们的网络需要能得到几乎相同的数值。&lt;/p&gt;&lt;p&gt;如果你想自己尝试这个步骤，OpenFace提供了一个&lt;a href="https://github.com/cmusatyalab/openface/blob/master/batch-represent/batch-represent.lua" data-editable="true" data-title="lua脚本"&gt;lua脚本&lt;/a&gt;，它可以生成一个文件夹中所有图像的嵌入，并将它们写入csv文件。&lt;a href="https://gist.github.com/ageitgey/ddbae3b209b6344a458fa41a3cf75719" data-editable="true" data-title="点此查看如何运行"&gt;点此查看如何运行&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第4&lt;/b&gt;&lt;b&gt;步：从编码中找出人的名字&lt;/b&gt;&lt;/p&gt;&lt;p&gt;最后这一步实际上是整个过程中最简单的一步。我们要做的就是找到数据库中，与我们的测试图像的测量值最接近的那个人。&lt;/p&gt;&lt;p&gt;你可以通过任何基本的机器学习分类算法来达成这一目标。我们并不需要太花哨的深度学习技巧。我们将使用一个简单的线性SVM分类器，但实际上还有很多其他的分类算法可以使用。&lt;/p&gt;&lt;p&gt;我们需要做的是训练一个分类器，它可以从一个新的测试图像中获取测量结果，并找出最匹配的是哪个人。分类器运行一次只需要几毫秒，分类器的结果就是人的名字！&lt;/p&gt;&lt;p&gt;所以让我们试一下我们的系统。首先，我使用Will Ferrell, Chad Smith 和 Jimmy Falon每人20张照片的嵌入来训练分类器：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-61b8af810e1cacee40a634312bab6f11.jpg" data-rawwidth="1200" data-rawheight="266"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;嗯…就是这些训练数据！&lt;/i&gt;&lt;/p&gt;&lt;p&gt;接下来，我在YouTube著名的Will Ferrell和Chad Smith的视频的每一帧上运行这个分类器：&lt;/p&gt;&lt;p&gt;它真的有效！它在不同的姿势的脸部依然有效- 甚至是侧脸！&lt;/p&gt;&lt;p&gt;&lt;b&gt;你自己做一遍&lt;/b&gt;&lt;/p&gt;&lt;p&gt;让我们回顾一下我们的步骤：&lt;/p&gt;&lt;p&gt;1.使用HOG算法给图片编码，以创建图片的简化版本。使用这个简化的图像，找到图像中看起来最像通用HOG面部编码的部分。&lt;/p&gt;&lt;p&gt;2.通过找到脸上的主要标志点，找出脸部的姿态。一旦我们找到这些标志点，就利用它们把图像扭曲，使眼睛和嘴巴居中。&lt;/p&gt;&lt;p&gt;3. 把上一步得到的面部图像放入到神经网络中，神经网络知道如何找到128个特征点测量值。保存这128个测量值。&lt;/p&gt;&lt;p&gt;4.看看我们过去测量过得的所有脸部，找出哪个人的测量值和我们的脸部测量值最接近。这就是你要找的匹配的人！&lt;/p&gt;&lt;p&gt;现在你知道这一切都是如何运行的了，&lt;a href="https://cmusatyalab.github.io/openface/" data-editable="true" data-title="这里是如何使用OpenFace在你自己的电脑上运行整个人脸识别系统的说明"&gt;这里是如何使用OpenFace在你自己的电脑上运行整个人脸识别系统的说明&lt;/a&gt;.&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-c8693405235197b0a454b2c41cb432d6.png" data-rawwidth="1120" data-rawheight="808"&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/24567586&amp;pixel&amp;useReferer"/&gt;</description><author>九五要当学霸</author><pubDate>Mon, 26 Dec 2016 15:27:57 GMT</pubDate></item><item><title>【巡洋舰首发】有趣的机器学习 第三章:图像识别【鸟or飞机】？</title><link>https://zhuanlan.zhihu.com/p/24524583</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-598ca7f6c13ae5a99307768183b34bcd_r.jpg"&gt;&lt;/p&gt;&lt;p&gt;原文：Adam Geitgey&lt;/p&gt;&lt;p&gt;原文链接：&lt;a href="https://medium.com/@ageitgey/machine-learning-is-fun-part-3-deep-learning-and-convolutional-neural-networks-f40359318721#.rp9872f79" data-editable="true" data-title="medium.com 的页面" class=""&gt;https://medium.com/@ageitgey/machine-learning-is-fun-part-3-deep-learning-and-convolutional-neural-networks-f40359318721#.rp9872f79&lt;/a&gt;&lt;/p&gt;&lt;p&gt;翻译：巡洋舰科技——赵95&lt;/p&gt;&lt;p&gt;有趣的机器学习 前六章已更新！点此查看&lt;a href="https://zhuanlan.zhihu.com/p/24339995" class="" data-editable="true" data-title="第一章：最简明入门指南"&gt;第一章：最简明入门指南&lt;/a&gt;、&lt;a href="https://zhuanlan.zhihu.com/p/24344720" class="" data-editable="true" data-title="第二章：用机器学习制造【超级马里奥】的关卡"&gt;第二章：用机器学习【制造超级马里奥】的关卡&lt;/a&gt;、&lt;a href="https://zhuanlan.zhihu.com/p/24524583" class="" data-editable="true" data-title="第三章：图像识别【鸟or飞机】"&gt;第三章：图像识别【鸟or飞机】&lt;/a&gt;&lt;a href="https://zhuanlan.zhihu.com/p/24567586" class="" data-editable="true" data-title="第四章：用深度进行【人脸识别】"&gt;第四章：用深度进行【人脸识别】&lt;/a&gt;&lt;a href="https://zhuanlan.zhihu.com/p/24590838" class="" data-editable="true" data-title="第五章：使用深度学习进行【语言翻译】和 序列的魔力"&gt;第五章：使用深度学习进行【语言翻译】和 序列的魔力&lt;/a&gt;&lt;a href="https://zhuanlan.zhihu.com/p/24703268" data-title="第六章：如何用深度学习进行【语音识别】" class="" data-editable="true"&gt;第六章：如何用深度学习进行【语音识别】&lt;/a&gt;&lt;/p&gt;&lt;p&gt;你是不是看烦了各种各样对于深度学习的报导，却不知其所云？我们要来改变这个问题。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-9e224c4885ac2aa9a6514eb215026c8f.jpg" data-rawwidth="2018" data-rawheight="682"&gt;&lt;/p&gt;&lt;h2&gt;这一次我们将一起写一个，可以判别鸟类还是飞机的程序！我们将学习到如何写一个，通过深度学习来识别图像中物体的程序。换个角度来说，我们会解释Google Photos搜索图片和识图所用到的“黑科技”。&lt;/h2&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-cb2e19b132e05461a2c9d9c6276b45b5.jpg" data-rawwidth="800" data-rawheight="380"&gt;&lt;p&gt;&lt;i&gt;Google&lt;/i&gt;&lt;i&gt;现在可以让你在你自己的图片库里面，根据你的描述搜索图片，即使这些图片根本没有被标注任何标签。这是怎么做到的呢？&lt;/i&gt;&lt;/p&gt;&lt;p&gt;和第1 2章一样，这个指南是针对所有对机器学习感兴趣但不知从哪里学起的读者的。本文目标在于平易近人，这意味着文中有大量的概括。但是谁在乎这些呢？只要能让读者对于机器学习更感兴趣，任务也就完成了。&lt;/p&gt;&lt;p&gt;&lt;b&gt;通过深度学习识别物体&lt;/b&gt;&lt;/p&gt;&lt;p&gt;你可能曾经看过这个xkcd漫画。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-220fac60b09462813d82769a2fbd355e.png" data-rawwidth="267" data-rawheight="448"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-9a59cd58177b3ff4db241e32842c5418.png" data-rawwidth="267" data-rawheight="448"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;Xkcd&lt;/i&gt;&lt;i&gt;漫画编号1425&lt;/i&gt;&lt;/p&gt;&lt;p&gt;一个3岁的小孩可以识别出鸟类的照片，然而最顶尖的计算机科学家们已经花了50年时间，来研究如何让电脑识别出不同的问题。漫画里的灵感就是这么来的。&lt;/p&gt;&lt;p&gt;在最近的几年里，我们终于找到了一种通过&lt;b&gt;卷积神经网络（&lt;/b&gt;&lt;b&gt;Convolutional Neural Networks&lt;/b&gt;&lt;b&gt;）&lt;/b&gt;来进行物体识别的好方法。这些个词听起来就像是从威廉·吉布森的科幻小说编造出来的，但是如果你把这个想法逐步分解，你绝对可以理解它。&lt;/p&gt;&lt;p&gt;让我们开始吧，我们一起来写一个识别鸟类的程序。&lt;/p&gt;&lt;p&gt;&lt;b&gt;由浅入深&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在我们在识别鸟类之前，让我们先做个更简单的——识别手写的数字“8”&lt;/p&gt;&lt;p&gt;在第二章中我们了解到，神经网络是如何通过连接无数神经元来解决复杂问题的。我们创造了一个小型神经网络，然后根据各种因素（房屋面积，格局，地段等）来估计房屋的价格：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-1a41f01767489d0113fd22fcafe05f6c.png" data-rawwidth="800" data-rawheight="692"&gt;&lt;/p&gt;&lt;p&gt;在第一章中我们提到了，机器学习，就是关于重复使用同样的泛型算法，来处理不同的数据，解决不同的问题的一种概念。所以这次，我们稍微修改一下同样的神经网络来识别手写文字。但是为了更加简便，我们只会尝试去识别数字“8”。&lt;/p&gt;&lt;p&gt;机器学习只有在你拥有数据的情况下，最好是大量的数据，才能有效。所以，我们需要有大量的手写“8”来开始我们的尝试。幸运的是，恰好有研究人员创造出了“MNIST手写数字数据库”能助我们一臂之力。MNIST提供了60,000张手写数字的图片，每一张都是一个18×18的图片。下列是数据库中的一些例子：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-e74d31dace9cf20b50604c5f2ee84361.jpg" data-rawwidth="1000" data-rawheight="256"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;MNIST&lt;/i&gt;&lt;i&gt;数据库中的数字“8&lt;/i&gt;&lt;i&gt;”&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;万物皆“数”&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在第二章中我们创造的那个神经网络，它只能接受三个数字输入（卧室数，面积，地段），但是现在，我们需要用神经网络来处理图像。所以到底怎样才能把图片，而不是数字，输入到神经网络里呢？&lt;/p&gt;&lt;p&gt;结论其实极其简单。神经网络会把数字当成输入，而对于电脑来说，图片其实恰好就是一连串代表着每个像素颜色的数字：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-e9471074ffb5c85a14a2d6fe4270d6b2.jpg" data-rawwidth="581" data-rawheight="580"&gt;&lt;/p&gt;&lt;p&gt;我们把一副18×18像素的图片当成一串324个数字的数列，就可以把它输入到我们的神经网络里面了：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-edde5a5c71bedaf91a887e801fda38e6.png" data-rawwidth="1250" data-rawheight="194"&gt;&lt;/p&gt;&lt;p&gt;为了更好地操控我们的输入数据，我们把神经网络扩大到拥有324个输入节点：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-e3c4e4a1c5c2cb73f4ee88ec145046af.png" data-rawwidth="977" data-rawheight="556"&gt;&lt;/p&gt;&lt;p&gt;请注意，现在有两个输出了（而不仅仅是一个房子的价格）。第一个输出会预测图片是“8”的概率
而第二个则输出不是“8”的概率。概括地说，我们就可以依靠多种不同的输出，利用神经网络把要识别的物品进行分组。&lt;/p&gt;&lt;p&gt;虽然我们的神经网络要比上次大得多（这次是324，上一次是3！=6），但是现在的计算机一眨眼的功夫就能够对这几百个节点进行运算。当然，你的手机也可以做到。&lt;/p&gt;&lt;p&gt;现在唯一要做的就是训练我们的神经网络了。用各种“8”和非“8”的图片来训练，这样它就能学习怎么去区分了。当我们输入一个“8”的时候，我们会告诉他“是8的概率”是100%而“不是8的概率”是0%，反之亦然。&lt;/p&gt;&lt;p&gt;下面是一些训练数据：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-9905391699c9282bda9b0f423d2c8760.jpg" data-rawwidth="1125" data-rawheight="283"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;嗯…&lt;/i&gt;&lt;i&gt;就是这些训练数据…&lt;/i&gt;&lt;/p&gt;&lt;p&gt;我们能在我们笔记本电脑上面用几分钟的时间来训练这种神经网络。完成之后，我们就可以得到一个有着很高的“8”图片识别率的神经网络。欢迎来到（1980年代末的）图像识别的世界！&lt;/p&gt;&lt;p&gt;&lt;b&gt;短浅的目光&lt;/b&gt;&lt;/p&gt;&lt;p&gt;仅仅把像素输入到神经网络里，就可以做出图像的识别，这很棒！机器学习就像魔法一样！对不对！！&lt;/p&gt;&lt;p&gt;&lt;b&gt;呵呵，当然，不会，这么，简单，呵呵呵。（&lt;/b&gt;&lt;em&gt;Well, of course it’s not that simple.&lt;/em&gt;&lt;b&gt;感受作者的神之鄙视吧哈哈哈）&lt;/b&gt;&lt;/p&gt;&lt;p&gt;首先，好消息是，当我们的数字就在图片的正中间的时候，我们的识别器干得还不错。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-42ffc9d1983334d876162e5c8a95a9cd.png" data-rawwidth="1000" data-rawheight="141"&gt;&lt;/p&gt;&lt;p&gt;坏消息是:&lt;/p&gt;&lt;p&gt;当数字并不是正好在图片中央的时候，我们的识别器就完全不工作了。一点点的位移我们的识别器就掀桌子不干了(╯‵□′)╯︵┻━┻。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-3e4328e85f900c5a3563bb76f885eab1.png" data-rawwidth="1000" data-rawheight="143"&gt;&lt;/p&gt;&lt;p&gt;这是因为我们的网络只学习到了正中央的“8”。它并不知道那些偏离中心的“8”长什么样子。它仅仅知道中间是“8”的规律。&lt;/p&gt;&lt;p&gt;在真实世界中，这好像并没什么卵用。真实世界的问题永远不会如此轻松简单。所以，我们需要知道，怎么才能让我们的神经网络在非中心“8”的情况下识别。&lt;/p&gt;&lt;p&gt;&lt;b&gt;暴力算法(Brute
Force)&lt;/b&gt; 方法1：滑框搜索&lt;/p&gt;&lt;p&gt;我们已经创造出了一个能够很好地识别图片中间“8”的程序。如果我们干脆把整个图片分成一个个小部分，并挨个都识别一遍，直到我们找到“8”，这样能不能行呢？&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-37823f4f0781bc8f09ada71ecd419a6e.jpg" data-rawwidth="950" data-rawheight="405"&gt;&lt;/p&gt;&lt;p&gt;这个叫做
滑框(Sliding Window)法，是暴力算法之一。在有限的情况下，它能够识别的很好。但实际上它并不怎么有效率，你必须在同一张图片里面一遍一遍的识别不同大小的物体。实际上，我们可以做得更好。&lt;/p&gt;&lt;p&gt;&lt;b&gt;暴力算法 &lt;/b&gt;&lt;b&gt;方法2&lt;/b&gt;&lt;b&gt;：更多的数据与一个深度神经网&lt;/b&gt;&lt;/p&gt;&lt;p&gt;刚刚我们提到，经过训练之后，我们只能找出在中间的“8”。如果我们用更多的数据来训练，数据中包括各种不同位置和大小的“8”，会怎样呢？&lt;/p&gt;&lt;p&gt;我们并不需要收集更多的训练数据。实际上，我们可以写一个小脚本来生成各种各样不同位置“8”的新图片：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-b8116c8959576d759bc322dc0be758d7.png" data-rawwidth="1000" data-rawheight="498"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;通过组合不同版本的训练图片，我们创造出了“合成训练数据(Synthetic Training Data)&lt;/i&gt;&lt;i&gt;”。这是一种非常实用的技巧！&lt;/i&gt;&lt;/p&gt;&lt;p&gt;使用这种方法，我们能够轻易地创造出无限量的训练数据。&lt;/p&gt;&lt;p&gt;更多的数据让我们的神经网络更难解决这个问题。但是把神经网络扩大，它就能寻找到更复杂的规律了，以此来弥补解决困难问题的不足。&lt;/p&gt;&lt;p&gt;要扩大我们的网络，我们首先要把把节点一层一层的堆积起来：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-6223ba897029b706a1f942f6c5570fcc.png" data-rawwidth="1000" data-rawheight="245"&gt;&lt;/p&gt;&lt;p&gt;因为它比传统的神经网络层数更多，所以我们把它称作“&lt;b&gt;深度神经网络&lt;/b&gt;&lt;b&gt;(Deep Neural Network)&lt;/b&gt;”。&lt;/p&gt;&lt;p&gt;这个想法在1960年代末就出现了，但直至今日，训练这样一个大型神经网络也是一件不切实际的缓慢的事情。然而，一旦我们知道了如何使用3D显卡（最开始是用来进行快速矩阵乘法运算）来替代普通的电脑处理器，使用大型神经网络的想法就立刻变得可行了。实际上，你用来玩守望先锋的NVIDIA GeForce GTX1080这款显卡，就可以极快速的训练我们的神经网络。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-504a3dfab013dceef59bd48ff3228545.png" data-rawwidth="500" data-rawheight="279"&gt;&lt;/p&gt;&lt;p&gt;但是尽管我们能把我们的神经网络扩张的特别大并使用3D显卡快速训练它，这依然不能让我们一次性得到结论。我们需要更智能的将图片处理后，放入到神经网络里。&lt;/p&gt;&lt;p&gt;仔细想想，如果把图片最上方和最下方的“8”当成两个不同的对象来处理，并写两个不同的网络来识别它们，这件事实在是说不通。&lt;/p&gt;&lt;p&gt;应该有某种方法，使得我们的神经网络，在没有额外的训练数据的基础上，能够非常智能的识别出图片上任何位置的“8”，都是一样是“8”。幸运的是…这就是！&lt;/p&gt;&lt;p&gt;&lt;b&gt;卷积性的解决办法&lt;/b&gt;&lt;/p&gt;&lt;p&gt;作为人类，你能够直观的感知到图片中存在某种&lt;b&gt;层级&lt;/b&gt;&lt;b&gt;(Hierarchy)&lt;/b&gt;或者是&lt;b&gt;概念结构&lt;/b&gt;&lt;b&gt;(Conceptual structure).&lt;/b&gt;参考下面的这个图片：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-918467a4f935da447600dfc43d96c016.jpg" data-rawwidth="1000" data-rawheight="666"&gt;&lt;/p&gt;&lt;p&gt;作为人类，你立刻就能识别出这个图片的层级：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;地面是由草和水泥组成的&lt;/li&gt;&lt;li&gt;有一个小孩在图片中&lt;/li&gt;&lt;li&gt;小孩在骑弹簧木马&lt;/li&gt;&lt;li&gt;弹簧木马在草地上&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;最重要的是，我们识别出了“小孩儿”，无论这个小孩所处的环境是怎样的。当每一次出现不同的环境时，我们人类不需要重新学习“小孩儿”这个概念。&lt;/p&gt;&lt;p&gt;但是现在，我们的神经网络做不到这些。他认为“8”出现在图片的不同位置，就是不一样的东西。它不能理解“物体出现在图片的不同位置还是同一个物体”这个概念。这意味着在每种可能出现的位置上，它必须重新学习识别各种物体。这弱爆了。&lt;/p&gt;&lt;p&gt;我们需要让我们的神经网络理解“平移不变性(Translation invariance)”这个概念——也就是说，“8”无论出现在图片的哪里，它都是“8”。&lt;/p&gt;&lt;p&gt;我们会通过一个叫做卷积(Convolution)的方法来达成这个目标。卷积的灵感是由计算机科学和生物学共同激发的。（有一些疯狂的生物学家，它们用奇怪的针头去戳猫的大脑，来观察猫是怎样处理图像的。 &amp;gt;_&amp;lt;）&lt;/p&gt;&lt;p&gt;&lt;b&gt;卷积是如何工作的&lt;/b&gt;&lt;/p&gt;&lt;p&gt;之前我们提到过，可以把一整张图片当做一串数字输入到神经网络里面。不同的是，这次我们会利用“位移物相同”（译者注：也就是平移不变性）的概念来把这件事做得更智能。&lt;/p&gt;&lt;p&gt;下面就是，它怎样工作的，分步解释——&lt;/p&gt;&lt;p&gt;&lt;b&gt;第一步：把图片分解成部分重合的小图块&lt;/b&gt;&lt;/p&gt;&lt;p&gt;和上述的滑框搜索类似的，我们把滑框在整个图片上滑过，并存储下每一个框里面的小图块：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-5de5f941cc23c28b570d2adfe54b9d05.png" data-rawwidth="1000" data-rawheight="633"&gt;&lt;/p&gt;&lt;p&gt;这么做之后，我们把图片分解成了77块同样大小的小图块。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第二步：把每个小图块输入到小型神经网络中&lt;/b&gt;&lt;/p&gt;&lt;p&gt;之前，我们把一张图片输入到神经网络中来看这张图片是不是一个“8”。这一次我们还做同样的事情，只不过我们输入的是一个个小图块：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-6760f478f3c54659e2c122351b71c475.png" data-rawwidth="758" data-rawheight="274"&gt;&lt;/p&gt;&lt;p&gt;然而，&lt;b&gt;有一个非常重要的不同&lt;/b&gt;：对于每个小图块，我们会&lt;b&gt;使用同样的神经网络权重&lt;/b&gt;。换一句话来说，我们同样对待每一个小图块。如果哪个小图块有任何异常出现，我们就认为这个图块是“异常(Interesting)”的&lt;/p&gt;&lt;p&gt;&lt;b&gt;第三步：把每一个小图块的结果都保存到一个新的数列当中&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们不想并不想打乱小图块的顺序。所以，我们把每个小图片按照图片上的顺序输入并保存结果，就像这样：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-3261c1e1ac226d7afca1767f4bc50df2.png" data-rawwidth="893" data-rawheight="729"&gt;&lt;/p&gt;&lt;p&gt;换一句话来说，我们从一整张图片开始，最后得到一个稍小一点的数列，里面存储着我们图片中的哪一部分有异常。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第四步：缩减像素采样&lt;/b&gt;&lt;/p&gt;&lt;p&gt;第三步的结论是一个数列，这个数列对应着原始图片中哪一部分最异常。但是这个数列依然很大:&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-b65fe37e7aa4743165fb9fca59fff382.png" data-rawwidth="1000" data-rawheight="363"&gt;&lt;/p&gt;&lt;p&gt;为了减小这个数列的大小，我们利用一种叫做最大池化(Max Pooling)的方法来降低采样(Downsample)。它听起来很棒，但这仍旧不够！&lt;/p&gt;&lt;p&gt;让我们先来看每个2×2的方阵数列，并且留住最大的数：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-717d3b1ba75820ab224a38a081476d1e.png" data-rawwidth="887" data-rawheight="370"&gt;&lt;/p&gt;&lt;p&gt;这里，一旦我们找到组成2×2方阵的4个输入中任何异常的部分，我们就只保留这一个数。这样一来就缩减了我们的数列大小，并且保留住了最重要的部分。&lt;/p&gt;&lt;p&gt;&lt;b&gt;最后一步：作出预测&lt;/b&gt;&lt;/p&gt;&lt;p&gt;到现在为止，我们已经把一个很大的图片，缩减到了一个相对较小的数列。&lt;/p&gt;&lt;p&gt;你猜怎么着？数列就是一序列数而已，所以我们我们可以把这个数列输入到另外一个神经网络里面去。最后的这个神经网络会决定这个图片是否匹配。为了区分它和卷积的不同，我们把它称作“完全连接”网络（”Fully Connected” Network）&lt;/p&gt;&lt;p&gt;所以从开始到结束，我们的五步就像管道一样连接起来：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-bb5042915cf0fa1964ff1a7ea4f8d221.png" data-rawwidth="1000" data-rawheight="294"&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;添加更多步骤&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们的图片处理管道是一系列的步骤：卷积，最大池化，还有最后的“完全连接”网络。&lt;/p&gt;&lt;p&gt;你可以把这些步骤组合、堆叠任意多次，来解决真实世界的问题。你可以有2层，3层或者10层卷积层。当你想要缩小你的数据大小的时候，你也随时可以调用最大池化函数。&lt;/p&gt;&lt;p&gt;我们解决问题的基本方法，就是从一整个图片开始，一步一步逐渐的分解它，直到你找到了一个单一的结论。你的卷积层越多，你的网络就越能识别出复杂的特征。&lt;/p&gt;&lt;p&gt;比如说，第一个卷积的步骤可能就是尝试去识别尖锐的东西，而第二个卷积步骤则是通过找到的尖锐物体来找鸟类的喙，最后一步是通过鸟喙来识别整只鸟，以此类推。&lt;/p&gt;&lt;p&gt;下面是一个更实际的深层卷积网络的样子（就是你们能在研究报告里面找到的那种例子一样）：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-541ab8e45aa01936406d5631abff0654.png" data-rawwidth="1000" data-rawheight="303"&gt;&lt;/p&gt;&lt;p&gt;这里，他们从一个224×224像素的图片开始，使用了卷积和最大池化两次，再使用3次卷积，最大池化一次，最后在使用两个完全连接层。最终的结果是这个图片能被分类到1000种不同类别当中的某一种！&lt;/p&gt;&lt;p&gt;&lt;b&gt;建造正确的网络&lt;/b&gt;&lt;/p&gt;&lt;p&gt;所以，你是怎么知道我们需要结合哪些步骤来让我们的图片分类器工作呢？&lt;/p&gt;&lt;p&gt;说句良心话，你必须做许多的实验和检测才能回答这个问题。在为你要解决的问题找到完美的结构和参数之前，你可能需要训练100个网络。机器学习包含了许多的尝试和错误！&lt;/p&gt;&lt;p&gt;&lt;b&gt;建立我们的鸟类分类器&lt;/b&gt;&lt;/p&gt;&lt;p&gt;现在我们已经做够了准备，我们已经可以写一个小程序来判定一个图片是不是一只鸟了。&lt;/p&gt;&lt;p&gt;诚然，我们需要数据来开始。CIFAR10数据库免费提供了6000张鸟类的图片和52000张非鸟类的图片。但是为了获取更多的数据，我们仍需添加Caltech-UCSD Birds-200-2011数据库，这里面包括了另外的12000张鸟类的图片。&lt;/p&gt;&lt;p&gt;这是我们整合后的数据库里面的一些鸟类的图片：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-ca1b3ab3fabad3f85d3c3ca61b9d9222.png" data-rawwidth="1250" data-rawheight="312"&gt;&lt;/p&gt;&lt;p&gt;这是数据库里一些非鸟类图片：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-4cd38a02c717c28cb542148bb1dbf22b.png" data-rawwidth="1250" data-rawheight="312"&gt;&lt;/p&gt;&lt;p&gt;这些数据对于我们这篇文章解释说明的目的来说已经够了，但是对于真实世界的问题来说，72000张低分辨率的图片还是太少了。如果你想要达到Google这种等级的表现的话，你需要上百万张高清无码大图。&lt;b&gt;在机器学习这个领域中，有更多的数据总比一个更好的算法更重要！&lt;/b&gt;现在你知道为什么谷歌总是乐于给你提供无限量免费图片存储了吧？
他们，需要，你的，数据！！&lt;/p&gt;&lt;p&gt;为了简历我们的分类器，我们将会使用TFLearn。TFLearn是Google TensorFlow的一个封装，Google TensorFlow包含了一个拥有简单API的深度学习库。使用它来定义我们网络的层级，建立卷积网络的过程和写几行代码一样简单。&lt;/p&gt;&lt;p&gt;下面是定义并训练我们网络的代码：&lt;/p&gt;&lt;pre&gt;&lt;code lang="python"&gt;# -*- coding: utf-8 -*-

"""
Based on the tflearn example located here:
https://github.com/tflearn/tflearn/blob/master/examples/images/convnet_cifar10.py
"""
from __future__ import division, print_function, absolute_import

# Import tflearn and some helpers
import tflearn
from tflearn.data_utils import shuffle
from tflearn.layers.core import input_data, dropout, fully_connected
from tflearn.layers.conv import conv_2d, max_pool_2d
from tflearn.layers.estimator import regression
from tflearn.data_preprocessing import ImagePreprocessing
from tflearn.data_augmentation import ImageAugmentation
import pickle

# Load the data set
X, Y, X_test, Y_test = pickle.load(open("full_dataset.pkl", "rb"))

# Shuffle the data
X, Y = shuffle(X, Y)

# Make sure the data is normalized
img_prep = ImagePreprocessing()
img_prep.add_featurewise_zero_center()
img_prep.add_featurewise_stdnorm()

# Create extra synthetic training data by flipping, rotating and blurring the
# images on our data set.
img_aug = ImageAugmentation()
img_aug.add_random_flip_leftright()
img_aug.add_random_rotation(max_angle=25.)
img_aug.add_random_blur(sigma_max=3.)

# Define our network architecture:

# Input is a 32x32 image with 3 color channels (red, green and blue)
network = input_data(shape=[None, 32, 32, 3],
                     data_preprocessing=img_prep,
                     data_augmentation=img_aug)

# Step 1: Convolution
network = conv_2d(network, 32, 3, activation='relu')

# Step 2: Max pooling
network = max_pool_2d(network, 2)

# Step 3: Convolution again
network = conv_2d(network, 64, 3, activation='relu')

# Step 4: Convolution yet again
network = conv_2d(network, 64, 3, activation='relu')

# Step 5: Max pooling again
network = max_pool_2d(network, 2)

# Step 6: Fully-connected 512 node neural network
network = fully_connected(network, 512, activation='relu')

# Step 7: Dropout - throw away some data randomly during training to prevent over-fitting
network = dropout(network, 0.5)

# Step 8: Fully-connected neural network with two outputs (0=isn't a bird, 1=is a bird) to make the final prediction
network = fully_connected(network, 2, activation='softmax')

# Tell tflearn how we want to train the network
network = regression(network, optimizer='adam',
                     loss='categorical_crossentropy',
                     learning_rate=0.001)

# Wrap the network in a model object
model = tflearn.DNN(network, tensorboard_verbose=0, checkpoint_path='bird-classifier.tfl.ckpt')

# Train it! We'll do 100 training passes and monitor it as it goes.
model.fit(X, Y, n_epoch=100, shuffle=True, validation_set=(X_test, Y_test),
          show_metric=True, batch_size=96,
          snapshot_epoch=True,
          run_id='bird-classifier')

# Save model when training is complete to a file
model.save("bird-classifier.tfl")
print("Network trained and saved as bird-classifier.tfl!")
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;如果你使用一款非常好的有着足够RAM的游戏显卡（比如说Nvidia GeForce GTX980 Ti）来训练的话，训练一个小时以内就能结束，但是如果你用一般的cpu来训练的话，他可能需要更长的时间。&lt;/p&gt;&lt;p&gt;随着训练的进行，准确度也会增加。在第一遍训练之后，它的准确度是75.4%。10次训练之后，就上升到了91.7%。当训练了至少50次的时候，它的准确率达到了95.5%。继续训练并没有增加他的准确度，所以我停止了。&lt;/p&gt;&lt;p&gt;恭喜！！我们的程序现在能识别鸟类的图片了！&lt;/p&gt;&lt;p&gt;&lt;b&gt;测试我们的网络&lt;/b&gt;&lt;/p&gt;&lt;p&gt;现在我们拥有了一个训练过的神经网络，我们可以开始使用它了！这儿有一个&lt;a href="https://gist.github.com/ageitgey/a40dded08e82e59724c70da23786bbf0" data-editable="true" data-title="简单的脚本"&gt;简单的脚本&lt;/a&gt;，通过接收一个图片来预测他是否是鸟类。&lt;/p&gt;&lt;p&gt;但是为了真正检测我们的神经网络有多有效果，我们需要进行大量的图片测试。我创造的那个数据库里面有15000张用来验证的图片。当我把这15000张图片放到程序里运行的时候，它的预测准确率达到了95%。&lt;/p&gt;&lt;p&gt;看起来还不错，对吧？额…这事儿吧还得辩证的看…&lt;/p&gt;&lt;p&gt;&lt;b&gt;95%&lt;/b&gt;&lt;b&gt;准确是有多准确？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们的网络声称有95%准确。但是细节决定成败(devil is in the detail)，这意味着各种各样问题可能产生。&lt;/p&gt;&lt;p&gt;比如说，如果我们的训练数据有5%是鸟类而剩下95%不是呢？一个程序即使每次都猜“不是鸟”也能达到95%的准确率。这也就意味着这个程序并没有什么作用。&lt;/p&gt;&lt;p&gt;相比于准确度，我们必须更多的关注在数字本身。为了判别一个分类系统有多好，我们需要知道它是怎样出错误的，而不是仅仅关注它错了多少次。&lt;/p&gt;&lt;p&gt;与其只考虑我们预测的对与错，不如把我们的程序分解成四个不同的类别——&lt;/p&gt;&lt;p&gt;首先，对于那些被我们的网络正确辨认为鸟类而且确实是鸟类的，我们叫他们“真正类(True Positives)”&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-d019bbe49a114b8c3f008e9e44642544.png" data-rawwidth="1250" data-rawheight="125"&gt;&lt;/p&gt;&lt;p&gt;第二，被辨认为非鸟类，而且确实是非鸟类的，我们叫“真负类(True Negatives)”&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-5ea61ab8883450df660660ec619f0f7a.png" data-rawwidth="1250" data-rawheight="125"&gt;&lt;/p&gt;&lt;p&gt;第三，被辨认为鸟类，但却是非鸟类的，我们叫“假正类(False Positives)”&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-b61d613f4aed8315410a3f7a0d3a9b3a.png" data-rawwidth="1250" data-rawheight="125"&gt;&lt;/p&gt;&lt;p&gt;第四，被辨认为非鸟类，但却是鸟类的，我们叫“假负类(False Negatives)”&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-866b9c9d43abcf24fe81eef0ccd9318b.png" data-rawwidth="1250" data-rawheight="125"&gt;&lt;/p&gt;&lt;p&gt;下面的数据是使用那15000张验证图片，在每种类别中我们猜测的数量：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-b9367d23b00f75ddc7e416e6f5a83323.png" data-rawwidth="1000" data-rawheight="350"&gt;&lt;/p&gt;&lt;p&gt;为什么我们要把结果做上述分类呢？因为并不是每一个错误产生的几率都是一样的。&lt;/p&gt;&lt;p&gt;设想如果我们写一个通过MRI图像来探测癌症的程序。如果我们探测到了癌症，我们更希望它是“假正类”而不是“假负类”。因为假负类是最可怕的情况——那就是你的程序告诉你，你绝对没有病，但实际上你已经病入膏肓了。&lt;/p&gt;&lt;p&gt;我们需要计算准确和召回指标(Precision and Recall metrics)而并不仅仅关注总体的准确度。准确和召回指标给了我们程序表现的一个清晰的反馈：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-93536c7f034afbacde2aff551544a3ed.png" data-rawwidth="1000" data-rawheight="168"&gt;&lt;/p&gt;&lt;p&gt;这告诉我们，当我们猜“鸟类”的时候，97%的时候是正确的。但是这同时也告诉我们说，我们只找到了真实鸟类里面的90%。换句话说，我们可能不会找到每一只鸟，但是当我们找到一只鸟的时候，我们很确定它就是一只鸟！&lt;/p&gt;&lt;p&gt;&lt;b&gt;路还在远方…&lt;/b&gt;&lt;/p&gt;&lt;p&gt;现在你知道了一些关于深度卷积网络的基本概念了，你可以用TFLearn尝试一下&lt;a href="https://github.com/tflearn/tflearn/tree/master/examples#tflearn-examples" data-editable="true" data-title="各种结构的神经网络的例子"&gt;各种结构的神经网络的例子&lt;/a&gt;。它甚至包括了自带的数据，你根本不用自己去收集图片。&lt;/p&gt;&lt;p&gt;你同时也知道了如何开始创造分支或是学习机器学习的其他领域。接下来为什么不尝试着去学习如何用算法来&lt;a href="http://karpathy.github.io/2016/05/31/rl/" data-editable="true" data-title="训练我们的电脑玩Atari 游戏"&gt;训练我们的电脑玩Atari 游戏&lt;/a&gt;呢？&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/24524583&amp;pixel&amp;useReferer"/&gt;</description><author>九五要当学霸</author><pubDate>Fri, 23 Dec 2016 13:14:52 GMT</pubDate></item></channel></rss>