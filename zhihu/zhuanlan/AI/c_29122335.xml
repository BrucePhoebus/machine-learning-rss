<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>混沌巡洋舰 - 知乎专栏</title><link>https://zhuanlan.zhihu.com/c_29122335</link><description>跨界思考内容供应商，与微信公众号混沌巡洋舰同属于巡洋舰科技公司。</description><lastBuildDate>Tue, 10 Jan 2017 04:17:15 GMT</lastBuildDate><generator>Ricky</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>关于什么是大数据的一点思考</title><link>https://zhuanlan.zhihu.com/p/24773653</link><description>&lt;p&gt;借用三体中一句名言“给岁月以文明，而非给文明以岁月”大数据的本质，不是将生命献给数据，而是给数据以生命。大数据不是一套routine,不应限制了你思考的方向，那里数据多就分析那里，而应是内化的一套价值观及处事方式，用以对抗无常。&lt;/p&gt;&lt;p&gt;科学的进步，商业的发展，得益于数据所统领的疆域的扩展，随着之前越来越不可量化的变得可以计量，但这并不是要我们的丢弃直觉，忽视心智模式的作用，大数据带领我们关注用户购买了什么，也要求我们关注用户没有购买什么，并从用会的行为推测出用户为什么没有购买，亚马逊会根据你点击而未曾购买的记录给你推出个性化的deal，大数据要求我们了解整个行业的趋势，更要求关注每一人个性化的需求，Netflix不止靠大数据拍出《纸牌屋》，还将无数的小众电影准确的推荐给了用户。而你的关注点，应该是能将数据统合的那根线，能使数据产生整体大于局部之和的上层结构。这里的关注点，说的是数据分析前的需求分析，你需要这些数据做什么，你对数据的直觉反应是否可以通过这些数据进行完整全面的验证，没有回答好这些问题，拥有再多的数据也不过是一堆数字，一如果组排列整齐的感光器，而不是一个能分别美丑的眼眸。&lt;/p&gt;&lt;p&gt;数据的扩大不会必然带来视野和格局的扩大，一个朋友说起她分析"降关税"的感悟，她说道，如果逗留在税率本身，思路变死，只能接受竞争对手增多局面；如果挖掘到贸易自由化层面，格局变大，处处即是机遇；格局大小，决定对策，大格局涵盖小格局，小格局看上去不可思议，在大格局下都显得理所当然，她在bloomberge数据端倒弄半小时之后，意识到，相比这些数据库，wind都弱爆了。仅仅有国际化视野是不够的，更需要有国际化数据。而数据来源一旦多元，就一定要有去伪存真的步骤，去除重复，剔除噪音，清洗缺失值，使数据做的同步，准确，完整。这是当前数据处理中最耗时的步骤，而如何避免在数据清洗时过度补偿，如何避免丢弃过多有用数据，则是最需要智慧的。&lt;/p&gt;&lt;p&gt;大数据不是指数据量的大，也不是指数据来源的广（数据的维数大），而是指数据间的关系复杂（复杂网络的涌现），数据中既包含有用的信号，也包含无用的噪音。但不同维度的数据可以互相验证，互为因果，从而带来数据间的有序性。数据在不断的变化中，而变化的趋势又受制于你观察数据之外的环境因素，这环境因素具有自我指称的特性，也许数据之所以变化，就是因为你观察数据这一行为造成的。有序性就是负熵，就满足薛定谔说的生命的特征。&lt;/p&gt;&lt;p&gt;若你能知道何时需要收集数据，何时收集的足够的数据足够做决策了，那么你就孕育了一组数据，如果你能坚持不懈的更新数据，不放过数据间的细微变化，你就养育了一组数据，如果你能让你的数据与大千世界中那些鱼龙混杂的数据对上号，然后会心一笑，或是发现不同维度的数据带来了不同的结论，然后追根追底，那么你的数据就通过成人礼，如果你能及时的发现你拥有的数据已发生了Bifurcation，不可能通过小修小补来描述现实，那么你就可以安排这组数据的葬礼。你若有这样的态度，不论你的数据量有多大，处理数据的模型有多简单，你都拥有了大数据的灵魂。若是你只知道管中窥豹，以偏概全，如盲人摸象一般，那么数据量，数据维数，数据处理能力的增长只能同比扩大你的知识与谬误。&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/24773653&amp;pixel&amp;useReferer"/&gt;</description><author>许铁-巡洋舰科技</author><pubDate>Sun, 08 Jan 2017 08:25:56 GMT</pubDate></item><item><title>如何高效的学习</title><link>https://zhuanlan.zhihu.com/p/24760820</link><description>本文内容来自与一本书 《高效工作的秘密》，作者 Peter&lt;p&gt;既然要高效，首先需要的是&lt;b&gt;避免去做重复的工作&lt;/b&gt;，这意味着要在学习的每一步把基础打结实。而这就牵涉到本文的题目-磨刀不误砍柴工，即通过有意的制造不那么流畅的信息流动来学习。&lt;/p&gt;&lt;p&gt;首先先看14年普林斯顿的Pam Mueller发表了一项研究，比较了UCLA和普林斯顿学生不同的上课记笔记的方式对学习成绩的影响。研究者排除了用传统方法记笔记的学生在课下用功更多等其他因素的影响后发现，使用传统的纸和笔做笔记的学生比用笔记本的学生得A的比例多一倍。&lt;/p&gt;&lt;p&gt;该如何解释这一现象了。一种解释是用电脑记笔记的时候会有更多的干扰，比如弹出的电邮和SMS，但考虑到14年智能手机的普及，这个因素也不能解释全部效应。在论文中，作者给出的解释是，用纸和笔记笔记不如电脑打字快，用电脑记笔记的学生记下的笔记数量会是用笔来记录学生的两倍，然而用笔来记录的学生的笔记是有背景信息的。也就是说，正因为用手写字不如在电脑上打字那么快捷，促使学生主动去思考那些需要做笔记，而正是这些思考使得学生取得了好成绩。&lt;/p&gt;&lt;p&gt;进一步的研究发现，用纸来做笔记的学生的笔记会有更多的问句。他们会记录下学到的概念和知识可以用来回答那些问题。他们的笔记也会包含更多的图，这可能是因为在纸上画图比用电脑画图要方便。这是这些特征使得研究者总结道他们的笔记起到将知识连接起来的作用。&lt;/p&gt;&lt;p&gt;描述这个实验，是为了引出《Smarter Faster Better》这本书提出的高效学习之策，&lt;b&gt;主动的构建一个不那么流畅的信息接收通路&lt;/b&gt;。流畅的信息接收会让学习者以为自己已经学会了，从而不深挖一个概念的内涵。而不那么流畅的信息接收意味着学习者要不时停下来去想想该怎么用自己的话来重述新知，（用电脑记笔记的学生打字速度快，可以完整的写下教授说的话，一字不差。而用笔来做记录的学生却不得不用自己的话对教授所讲的去做缩写。正是这个过程使得学生对知识掌握的更深）&lt;/p&gt;&lt;p&gt;按照这本书提出的建议，高效学习的秘诀是下面几条&lt;/p&gt;&lt;p&gt;1 &lt;b&gt;用自己的话把学到的知识讲出来&lt;/b&gt;，最好用不同的方式和视角，这里是需要头脑风暴和跨界思维的地方。&lt;/p&gt;&lt;p&gt;2 在介绍每个知识点之前，说&lt;b&gt;清楚这个知识点回答了那些问题&lt;/b&gt;，给出的答案是否能将问题完全解决，这里需要清晰的逻辑，避免答非所问&lt;/p&gt;&lt;p&gt;3 强迫自己&lt;b&gt;为所学的知识点找出应用具体的应用场景&lt;/b&gt;，应用的场景可以是真实存在的两难 （dilemma），也可以是虚构的。每个场景需要包含when where who 和what，和所学的知识将用来说明why 或者how。&lt;/p&gt;&lt;p&gt;书中还给出了一种可以用来高效学习的游戏，这个游戏我们也许在聚会玩过的&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-09e7beb0a9ab4310dc688fece045890d.png" data-rawwidth="566" data-rawheight="555"&gt;比如你新学了一些机器学习的算法，你就可以和你小伙伴玩这个游戏，给出一个算法的集合，你们轮流问对方一系列Yes or No 的问题来猜出到底是哪一个算法，这个游戏能帮你理清不同概念间的关系。如果你想用更少的问题就猜出来，你必须掌握一个概念间真正能将其区分开的是什么。只有找到了每个知识最独特的一点，你才能在需要用到知识时快速建立起索引（避免提取不相关的信息）。只有在多个维度上都将知识进行了划分，才能将所需全部的知识点一网打尽。而这正是体现高效学习的成果的时候。最后要指出的是，学习是一个持续不断的过程，将学习的过程可以看成产品的&lt;b&gt;迭代&lt;/b&gt;，如同书中的表格所画，高效的学习如同精益创业一样，也需要造出一些Proof of Concept 的产品。正如记笔记，最好的笔记应该是在课上记下问题，画出概述图，下课后再将笔记补齐。最初的笔记是原型产品，不追求面面俱到，但要求能形成闭环，即包含问题，也包括分析和解决方案。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-b3cd2edd62af70011abdf3dc60377840.png" data-rawwidth="566" data-rawheight="376"&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/24760820&amp;pixel&amp;useReferer"/&gt;</description><author>许铁-巡洋舰科技</author><pubDate>Sat, 07 Jan 2017 08:39:37 GMT</pubDate></item><item><title>大咖征集令，不限学科，用你的Coursera证书实现知识变现</title><link>https://zhuanlan.zhihu.com/p/24760399</link><description>&lt;p&gt;看完罗胖的跨年演讲精华，我越发相信古人的那句话“技多不压身”，有信息过载，却绝对不会有技能过载，智慧过载。罗胖说得到想做最好的内容分发商，而在我眼中，最好的内容提供方却是下面的这三家&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-75a70bf6d900c1604de8e2fe3efc2d23.jpg" data-rawwidth="570" data-rawheight="288"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-47fdb854cfb33a4028733012b7855809.jpg" data-rawwidth="400" data-rawheight="300"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-c9940b499c840ece71a2734423c1c93a.png" data-rawwidth="400" data-rawheight="300"&gt;&lt;p&gt;为什么这么说，不止是因为这里的课程是来自于全球顶尖高校的第一手科学家，更因为最好的东西都不是免费的，不是交钱就能够得到的，而是要你先去花时间和精力去投入。在这方面，每个人都有着相同的起点。 下图是 董飞老师 讲述 MOOC 转化率较低时用到的图。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-3f0d4ad82aef9c94ed7c1262bc7712e1.jpg" data-rawwidth="640" data-rawheight="360"&gt;&lt;p&gt;所以说，每一个在在线教育平台拿到了证书的同学，都是万里挑一的学霸。如果你也是这样一位学霸，那么你可以用你的知识来变现，怎么办，请听我细细说来。&lt;/p&gt;&lt;p&gt;首先请您将您的MOOC证书截图（不管是上述的3个平台，还是其他的MOOC 平台的证书）+ 你对你学过的这门课程（任何专业的课程都可以的）的介绍以及你的学习心得总结成一篇小文 （500 字以上，最好附带一些截图或思维导图） + 你的分答账号或微信号（如果你愿意） + 你的自我介绍 发到邮箱 guoruidong517@126.com 。 在通过基本的资质审核后，我们会在 微信/微博/今日头条/知乎 上发布你的学习心得。之后你会成为这门课的TA， 如果读者觉得你修过的课程足够有趣，也愿意学习，那么Ta 在学习中遇到任何问题，都可以通过分答向你提问，而回答问题，即是温故而知新的过程，也是知识变现的过程。&lt;/p&gt;&lt;p&gt;不过知识分享不止是为了变现，还是为了自我提升。如果你的投稿被接受，你将可以进入巡洋舰的社群 参考&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651380856&amp;amp;idx=1&amp;amp;sn=dab774c3fc102149fe2e4ce7acc0e0f8&amp;amp;scene=21#wechat_redirect" data-editable="true" data-title="巡洋舰群001号体验报告" class=""&gt;巡洋舰群001号体验报告&lt;/a&gt;，如果你的MOOC课程 与数据科学或者计算机编程相关，我们还会推荐你去集智AI学园去做讲师，从而录制视频课程，实现进一步的知识变现。当然，如果你想去找实习，巡洋舰的社群从来都不缺少机会。&lt;/p&gt;&lt;p&gt;好了，就说这么多，有MOOC 证书的伙伴是不是已经跃跃欲试了，哪怕只是向更多人炫耀一下自己的证书，这个动机就足够了。再说一遍投稿邮箱 guoruidong517@126.com 邮件标题请注明 MOOC 证书+学习心得分享。&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/24760399&amp;pixel&amp;useReferer"/&gt;</description><author>许铁-巡洋舰科技</author><pubDate>Sat, 07 Jan 2017 04:48:47 GMT</pubDate></item><item><title>今年，我们一起来做一边做慈善一边做一个知识社群</title><link>https://zhuanlan.zhihu.com/p/24739084</link><description>&lt;p&gt;知识值多钱？无价。既然如此，那知识变现应该很容易吧。可不是吗？罗辑思维得到APP上那么多专栏作者不都做到了吗？更多知乎大牛不也正在做吗？&lt;/p&gt;&lt;p&gt;若你是这么想的，你就没有看清楚事情的本质。信息爆炸的时代，知识作为一种公共商品，本身因为缺少稀缺性是很难变现的。大V们提供的服务，是帮我们甄别信息，从而让我们能够在碎片时间，用更高的性价比得到浓缩后的知识。&lt;/p&gt;&lt;p&gt;然而如果你的认知架构没有给新的观点留出位置，没有搭好相应的框架，那么即使你接受到了高性价比的知识，也无法改变自己的为人做事的习惯。&lt;/p&gt;&lt;p&gt;所以我在过去的一年通过坚持写作来深挖自己的大脑，把那些杂草，那些不符合现代科学研究成果，缺乏逻辑严密性的部分去除掉，从而为自己接受新的观点做好“预实验”，我觉得这就是个人的认知管理的起点。比如 &lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651381741&amp;amp;idx=1&amp;amp;sn=790f0bcd936def79845952693f90f18a&amp;amp;chksm=84f3f1acb38478ba102eafc69810cc3fbd6acc00d6e88ad3b741a65c025eeee1d722ff43489f&amp;amp;scene=21#wechat_redirect" data-editable="true" data-title="当看只干货成为一种本能，你进步了多少" class=""&gt;当看只干货成为一种本能，你进步了多少&lt;/a&gt;&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651381885&amp;amp;idx=1&amp;amp;sn=3a743abefeba751cfb313bb12a27b696&amp;amp;chksm=84f3ce3cb384472afeb791a1973993d6c11f05f0c798147b526783b9e628cee3655f67edc27b&amp;amp;scene=21#wechat_redirect" data-editable="true" data-title="读这本书不会让你变聪明，但会让你避免犯错"&gt;读这本书不会让你变聪明，但会让你避免犯错&lt;/a&gt; 和&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651381838&amp;amp;idx=1&amp;amp;sn=faa997b762fda40415d4c195c590b10a&amp;amp;chksm=84f3ce0fb384471961b7196a07776b7f1ac47fea6f5d6d12cdd6a1891716b0832b6c9a2fb754&amp;amp;scene=21#wechat_redirect" data-editable="true" data-title="绞杀榕，黏鸟树自然界的生存之道能教给我们什么" class=""&gt;绞杀榕，黏鸟树自然界的生存之道能教给我们什么&lt;/a&gt;&lt;/p&gt;&lt;p&gt;将这一过程分享，希望更多的人来参与，这是我做这个公众号的本心。也想搞和读者的互动，比如&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=401961224&amp;amp;idx=1&amp;amp;sn=1654f80860bade4dddae51a8301c5a8c&amp;amp;scene=21#wechat_redirect" data-editable="true" data-title="读好书，要我们不只是说说而已&amp;lt;交叉学科好书读书召集令&amp;gt;"&gt;读好书，要我们不只是说说而已&amp;lt;交叉学科好书读书召集令&amp;gt;&lt;/a&gt; 后来觉得，让读者读完一本书，再写读书笔记，这有些门槛太高。&lt;/p&gt;&lt;p&gt;最近看到了“小密圈“这个工具，又动了做分享知识社群的念头。这个工具操作很方便，你只需要在微信里关注“小密圈” 公众号，就可以看到自己加入圈子的内容，不需要打开额外的应用。&lt;/p&gt;&lt;p&gt;相比于微信群，小密圈除了人数更多，其优点还在于对文件，这种半衰期相比于语音和聊天更长的形式能进行更方便的管理。对于较大一些的文件，也可以在小密圈而不是微信群中分享。使用者可以对群中的文件进行留言，方便针对每一个文件的讨论，还可对文件加入标签，便于索引和搜索。&lt;/p&gt;&lt;p&gt;在我们设想的知识社群中，我们会：&lt;/p&gt;&lt;p&gt;1）不定期分享 混沌巡洋舰群 参考&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651380856&amp;amp;idx=1&amp;amp;sn=dab774c3fc102149fe2e4ce7acc0e0f8&amp;amp;scene=21#wechat_redirect" data-editable="true" data-title="巡洋舰群001号体验报告"&gt;巡洋舰群001号体验报告&lt;/a&gt;中讨论的精华，分享的链接（带标签，介绍），有一些我想发到朋友圈的内容，怕刷屏打扰到别人的，都会发到这，当然少不了铁哥的心灵砒霜 参考&lt;a href="http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651381792&amp;amp;idx=1&amp;amp;sn=f3c1774033999fa8786e0dc7ec977ce0&amp;amp;chksm=84f3ce61b3844777b7abb4bacbae9aa79e63323a2dd6347fe63ad6d5366e35d10abfa90760b7&amp;amp;scene=21#wechat_redirect" data-editable="true" data-title="铁哥行思录"&gt;铁哥行思录&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;2） 每周至少1次分享1组“得到APP或混沌研习社”上的优质音频（选自多个专栏及读书解读，但不限于一个专栏），每组长度1小时以上，争取做到结合一个话题，连接多个专栏的优质内容。&lt;/p&gt;&lt;p&gt;3） 不定期分享电子书或有声书或视频资源。&lt;/p&gt;&lt;p&gt;4） 可能涌现的其他好玩的东东&lt;/p&gt;&lt;p&gt;至于收费，就定在52元，50是这个平台允许的最小的收费值了，而加入一个知识社群，多少是有点2的行为吧，就自嘲一次吧。&lt;/p&gt;&lt;p&gt;这是我一个月之前的想法，然而之后我的想法变化了，我觉得知识社群不该这么搞，不该只有线上的交流，还应该有些落到实处的地方。我很欣赏Better Read 公众号 做的好书漂流活动，但我觉得这样的活动还不够去中心化，我希望在我这里的知识社群中，我希望再加入我自己设计的两个活动。&lt;/p&gt;&lt;p&gt;假设你有一本你打算分享（多本书也可以，省邮费的），你可以在这个社群中分享，之后如果有人对这本书感兴趣，可以留下地址，书的主人会将书以&lt;em&gt;到付&lt;/em&gt;的形式寄给你，想读这本书的人只需要出邮费，就可以得到一本或多本书。不过读者拿到书之后，每本书有两月的阅读时间，需要在两月之内对一本书提交一篇不小于300字的&lt;strong&gt;读书笔记&lt;/strong&gt;，（收到多本书的人可以有更多的时间来写读书笔记，每两月一本书的要求不高）否则会被移除出社群。这里管理员只需要记录什么时候读者收到了书，然后提前以群公告提醒读者写读书笔记就好。至于在这之中产生的读书笔记，如果读者愿意，我们都会发到巡洋舰的公众号和知乎专栏中。&lt;/p&gt;&lt;p&gt;但如果读者不只想写读书笔记，还想对更多人以&lt;strong&gt;群讲座&lt;/strong&gt;的形式讲一讲，那也可以在群里通过公告的形式来做分享，时间不少于10分钟就好。提前2天在社群中通知，分享之后主讲可以贴出自己的微信收钱二维码。这里不止限于读书报告的群讲座，你可以讲讲你所在的行业，讲讲你的见闻，这就是上面所说的可能涌现的其他好玩的东东。巡洋舰也会对群里的分享进行整理，发布在公众号和知乎专栏中。&lt;/p&gt;&lt;p&gt;以上的两件事，都是需要门槛的，所以要收费吗？这个逻辑不是这样的。小额的收费是验证诚意，而上面的活动必须要参与者能做到相互信任，你付过钱的东西，多少会在乎一些。但由于这个社群是要尽可能去中心化的，所以收到的钱将不能分给某一位大牛，所以收到的钱去做慈善，是最公平，也是最体现去中心化意图的选择。既然要做的是知识社群，那怎么能忘记了缺少知识的弱势群体了。所以每一位参与社群的人，我们都会拿出你所付的52元中的49元来&lt;strong&gt;做慈善&lt;/strong&gt;。（为什么是49元，因为小密圈提现时会收管一定比例理费的）。&lt;/p&gt;&lt;p&gt;关于做慈善，这是一件需要说几句的事。不是像罗一笑那样，也不是捐给大的基金会，而是由一群前华为人一对一的捐给山里的孩子，给她们提供书籍和过冬的棉衣。至于这件事，可以在网上查找“前华为人慈善捐助基金”，笔者参与过他们的活动，志愿者做事很认真，一对一的将善款送到当地孩子的手上，该机构还会提供明晰的收据。&lt;/p&gt;&lt;p&gt;好了，就说这么多，最后放上二维码，长按（或扫描）二维码入群，现在群里已有400多小伙伴了。加入后别忘了关注 小密圈 公众号，点击我的圈子，就可以看到每天分享的连接和消息了。或者也可以下载小密圈的APP，也可以参与知识社区的建立。&lt;/p&gt;&lt;p&gt;https://wx.xiaomiquan.com/mweb/views/joingroup/join_group.html?group_id=1484248542&amp;amp;secret=twnncv0z2iipl7c7jbdr192833707f71&amp;amp;extra=2c360470c8b4bac041b74044a9ed1dcfc63ca0730a98c98dd8e3be45862725af (二维码自动识别)&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/24739084&amp;pixel&amp;useReferer"/&gt;</description><author>许铁-巡洋舰科技</author><pubDate>Thu, 05 Jan 2017 22:13:31 GMT</pubDate></item><item><title>【巡洋舰首发】有趣的机器学习 第六章:如何用深度学习进行【语音识别】？</title><link>https://zhuanlan.zhihu.com/p/24703268</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-9852cb5c6c0693428ceb483cd84297dc_r.jpg"&gt;&lt;/p&gt;&lt;p&gt;原文：Adam Geitgey&lt;/p&gt;&lt;p&gt;原文链接：&lt;a href="https://medium.com/@ageitgey/machine-learning-is-fun-part-6-how-to-do-speech-recognition-with-deep-learning-28293c162f7a#.42h1r63ev" data-editable="true" data-title="medium.com 的页面"&gt;https://medium.com/@ageitgey/machine-learning-is-fun-part-6-how-to-do-speech-recognition-with-deep-learning-28293c162f7a#.42h1r63ev&lt;/a&gt;&lt;/p&gt;&lt;p&gt;翻译：巡洋舰科技——赵95&lt;/p&gt;&lt;p&gt;你是不是看烦了各种各样对于深度学习的报导，却不知其所云？我们要来改变这个问题。&lt;/p&gt;&lt;p&gt;有趣的机器学习 前五章已更新！点此查看&lt;a href="https://zhuanlan.zhihu.com/p/24339995" class="" data-editable="true" data-title="第一章：最简明入门指南"&gt;第一章：最简明入门指南&lt;/a&gt;、&lt;a href="https://zhuanlan.zhihu.com/p/24344720" class="" data-editable="true" data-title="第二章：用机器学习制造【超级马里奥】的关卡"&gt;第二章：用机器学习【制造超级马里奥】的关卡&lt;/a&gt;、&lt;a href="https://zhuanlan.zhihu.com/p/24524583" class="" data-editable="true" data-title="第三章：图像识别【鸟or飞机】"&gt;第三章：图像识别【鸟or飞机】&lt;/a&gt;&lt;a href="https://zhuanlan.zhihu.com/p/24567586" class="" data-editable="true" data-title="第四章：用深度进行【人脸识别】"&gt;第四章：用深度进行【人脸识别】&lt;/a&gt;&lt;a href="https://zhuanlan.zhihu.com/p/24590838" class="" data-editable="true" data-title="第五章：使用深度学习进行【语言翻译】和 序列的魔力"&gt;第五章：使用深度学习进行【语言翻译】和 序列的魔力&lt;/a&gt;&lt;a href="https://zhuanlan.zhihu.com/p/24703268" data-title="第六章：如何用深度学习进行【语音识别】" class="" data-editable="true"&gt;第六章：如何用深度学习进行【语音识别】&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;语音识别正在“入侵”我们的生活。它内置在我们的手机，游戏主机和智能手表里。它甚至在自动化我们的家园。只需50美元，你可以买到一个Amazon Echo Dot -
一个能够让你订购比萨，获知天气预报，甚至购买垃圾袋的魔术盒——只要你大声说出你的需求：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-3ffa4aec52021655b172e93e11d88274.jpg" data-rawwidth="1000" data-rawheight="552"&gt;&lt;/h2&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-3ffa4aec52021655b172e93e11d88274.jpg" data-rawwidth="1000" data-rawheight="552"&gt;&lt;p&gt;&lt;i&gt;Alexa，订一个大号的比萨！&lt;/i&gt;&lt;/p&gt;&lt;p&gt;Echo Dot机器人在（2016年圣诞）这个假期太受欢迎了，以至于Amazon似乎都没货了！&lt;/p&gt;&lt;p&gt;然而语音识别已经出现了几十年了，为何它才刚刚成为主流呢？原因是，深度学习，终于让语音识别，能够在非严格可控的环境下也能准确的识别。&lt;/p&gt;&lt;p&gt;吴恩达教授(百度首席科学家，人工智能和机器学习领域国际上最权威的学者之一，也是在线教育平台Coursera的联合创始人)长期以来预测，随着语音识别从95％精确度上升到99％，它将成为我们与计算机交互的主要方式。这个想法是基于，4％的精确度实际就是“太不靠谱”与“极度实用”之间的差别。感谢深度学习，我们终于达到了顶峰。&lt;/p&gt;&lt;p&gt;让我们了解一下如何用深度学习进行语音识别吧！&lt;/p&gt;&lt;p&gt;&lt;b&gt;机器学习并不总是一个黑盒&lt;/b&gt;&lt;/p&gt;&lt;p&gt;如果你知道&lt;a href="https://zhuanlan.zhihu.com/p/24590838" data-editable="true" data-title="神经机器翻译"&gt;神经机器翻译&lt;/a&gt;是如何工作的，那么你可能会猜到，我们可以简单地将声音送入到神经网络中，并训练使之生成文本：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-d347c3fae5f4e2bdc78bfbcd9259cacd.png" data-rawwidth="1000" data-rawheight="285"&gt;&lt;/p&gt;&lt;p&gt;这就是用深度学习进行语音识别的核心，但目前我们还没有完全做到（至少在我写这篇文章的时候没做到——我打赌，在未来的几年我们可以做到）。&lt;/p&gt;&lt;p&gt;最大的问题是言速不同。一个人可能很快的说“hello!”而另一个人可能会非常缓慢说“heeeelllllllllllllooooo!”。这产生了一个更长的声音文件和更多的数据。这两个声音文件都应该被识别为完全相同的文本“hello！”而事实证明，把各种长度的音频文件自动对齐到一个固定长度的文本是很难的一件事情。&lt;/p&gt;&lt;p&gt;为了解决这个问题，我们必须使用一些特殊的技巧和一些除了深度神经网络以外的特殊处理。让我们看看它是如何工作的吧！&lt;/p&gt;&lt;p&gt;&lt;b&gt;将声音转换成“位（&lt;/b&gt;&lt;b&gt;Bit&lt;/b&gt;&lt;b&gt;）”&lt;/b&gt;&lt;/p&gt;&lt;p&gt;语音识别的第一步是很显而易见的——我们需要将声波输入到计算机当中。&lt;/p&gt;&lt;p&gt;在&lt;a href="https://zhuanlan.zhihu.com/p/24524583" data-editable="true" data-title="第3章"&gt;第3章&lt;/a&gt;中，我们学习了如何把图像视为一个数字序列，以便我们直接将其输入进神经网络进行图像识别：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-1a8437a32c108cfe01bfa868d82a380d.jpg" data-rawwidth="581" data-rawheight="580"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;图像只是图片中每个像素深度的数字编码序列&lt;/i&gt;&lt;/p&gt;&lt;p&gt;但声音是作为&lt;b&gt;&lt;i&gt;波&lt;/i&gt;&lt;/b&gt;&lt;b&gt;&lt;i&gt;(Waves)&lt;/i&gt;&lt;/b&gt; 的形式传播的。我们如何将声波转换成数字呢？让我们使用我说的“hello”这个声音片段我们例子：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-6aad3a0f2fac76e461a557346435cbcb.png" data-rawwidth="1250" data-rawheight="379"&gt;&lt;/p&gt;&lt;p&gt;我说“hello”的波形&lt;/p&gt;&lt;p&gt;声波是一维的。（译者注：其实是二维的，有时间，还有振幅）在每个时刻，基于波的高度，它们有一个值(译者注：叫做振幅)。让我们把声波的一小部分放大看看：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-72f469ef60c261b6ba6c51d5b67f7d32.png" data-rawwidth="1250" data-rawheight="370"&gt;&lt;/p&gt;&lt;p&gt;为了将这个声波转换成数字，我们只记录声波在等距点的高度：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-926cf143d810e67eb3614e4318223e72.jpg" data-rawwidth="1250" data-rawheight="482"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;给声波采样&lt;/i&gt;&lt;/p&gt;&lt;p&gt;这被称为&lt;b&gt;&lt;i&gt;采样&lt;/i&gt;&lt;/b&gt;&lt;b&gt;&lt;i&gt;Sampling&lt;/i&gt;&lt;/b&gt;。我们每秒读取数千次，并把声波在该时间点的高度用一个数字记录下来。这基本上就是一个未压缩的.wav音频文件。&lt;/p&gt;&lt;p&gt;“CD音质”的音频是以44.1khz（每秒44,100个读数）进行采样的。但对于语音识别，16khz（每秒16,000个采样）的采样率足以覆盖人类语音的频率范围。&lt;/p&gt;&lt;p&gt;让我们把“Hello”的声波每秒采样16,000次。这是前100个采样：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-f011f9c607f2d99cf05e33e6572649dc.png" data-rawwidth="1250" data-rawheight="79"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;每个数字表示在一秒钟的&lt;/i&gt;&lt;i&gt;16000&lt;/i&gt;&lt;i&gt;分之一处的声波的振幅&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;数字采样小助手&lt;/b&gt;&lt;/p&gt;&lt;p&gt;你可能认为采样只是对原始声波进行粗略近似估计，因为它只是间歇性的读取。我们的读数之间有间距，所以我们会丢失数据，对吗？&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-4381d449423b9e4079e02ebb594219e9.png" data-rawwidth="1250" data-rawheight="535"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;数字采样能否完美重现原始声波？那些间距怎么办？&lt;/i&gt;&lt;/p&gt;&lt;p&gt;但是，由于&lt;b&gt;&lt;i&gt;采样定理&lt;/i&gt;&lt;/b&gt;&lt;b&gt;&lt;i&gt;(Nyquist theorem)&lt;/i&gt;&lt;/b&gt;，我们知道我们可以利用数学，从间隔的采样中完美的重建原始模拟声波——只要以我们希望得到的最高频率的两倍来采样就可以。&lt;/p&gt;&lt;p&gt;我提到这一点，是因为&lt;a href="http://gizmodo.com/dont-buy-what-neil-young-is-selling-1678446860" data-editable="true" data-title="几乎每个人都会犯这个错误"&gt;几乎每个人都会犯这个错误&lt;/a&gt;，并误认为使用更高的采样率总是能获得更好的音频质量。其实并不是。&lt;/p&gt;&lt;p&gt;&lt;b&gt;预处理我们的采样声音数据&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们现在有一个数列，其中每个数字代表16000分之一秒的声波振幅。&lt;/p&gt;&lt;p&gt;我们&lt;i&gt;可以&lt;/i&gt;把这些数字输入到神经网络中，但是试图直接分析这些采样来进行语音识别仍旧是困难的。相反，我们可以通过对音频数据进行一些预处理来使问题变得更容易。&lt;/p&gt;&lt;p&gt;让我们开始吧，首先将我们的采样音频分组为20毫秒长的块儿。这是我们第一个20毫秒的音频（即我们的前320个采样）：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-6378f673fb49bc8b806ae6a7af1aaa15.png" data-rawwidth="1250" data-rawheight="270"&gt;&lt;p&gt;将这些数字绘制为简单折线图，图中给出了20毫秒时间内原始声波的粗略估计：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-a6383b8f598750acd6aa3e473e791603.png" data-rawwidth="1250" data-rawheight="338"&gt;&lt;/p&gt;&lt;p&gt;虽然这段录音只有&lt;i&gt;50&lt;/i&gt;&lt;i&gt;分之一&lt;/i&gt;秒的长度，但即使这样短暂的时长也是由不同频率的声音复杂的组合在一起的。一些低音，中音，甚至高音混在一起。但总的来说，就是这些不同频率的声音混合在一起，才组成了人类的语音。&lt;/p&gt;&lt;p&gt;为了使这个数据更容易被神经网络处理，我们将把这个复杂的声波分解成一个个组件部分。我们将一步步分离低音部分，下一个最低音部分，以此类推。然后通过将（从低到高）每个频带中的能量相加，我们就为各个类别（音调）的音频片段创建了一个&lt;i&gt;指纹&lt;/i&gt;&lt;i&gt;fingerprint&lt;/i&gt;。&lt;/p&gt;&lt;p&gt;想象你有一段某人在钢琴上演奏C大调和弦的录音。这个声音是由三个音符组合而成的 - C，E和G – 他们都混合在一起组成一个复杂的声音。我们想把这个复杂的声音分解成单独的音符，以此来发现它们是C，E和G。这和我们（语音识别）的想法一样。&lt;/p&gt;&lt;p&gt;我们使用被称为&lt;i&gt;傅里叶变换&lt;/i&gt;&lt;i&gt;Fourier Transform&lt;/i&gt;的数学运算来做到这一点。它将复杂的声波分解为简单的声波。一旦我们有了这些单独的声波，我们将每一个包含的能量加在一起。&lt;/p&gt;&lt;p&gt;最终结果是每个频率范围的重要程度，从低音（即低音音符）到高音。下面的每个数字表示我们的20毫秒音频剪辑中每个50Hz频带中有多少能量：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-183c59db1dab03f2470b361502423c69.png" data-rawwidth="1250" data-rawheight="253"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;列表中的每个数字表示在&lt;/i&gt;&lt;i&gt;50Hz&lt;/i&gt;&lt;i&gt;频带中有多少能量&lt;/i&gt;&lt;/p&gt;&lt;p&gt;但是当你绘制一个图表时，你很容易看到这些能量：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-e3b95b07ac52830dbd035e54279eb839.png" data-rawwidth="1250" data-rawheight="178"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;你可以看到，我们的&lt;/i&gt;&lt;i&gt;20&lt;/i&gt;&lt;i&gt;毫秒声音片段中有很多低频率能量，然而在更高的频率中并没有太多的能量。这是典型“男性”的声音。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;如果我们对每20毫秒的音频块重复这个过程，我们最终会得到一个频谱图（每一列从左到右都是一个20ms的块）：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-405c35d00e5e82e30e5dff7fbd39050f.png" data-rawwidth="1250" data-rawheight="442"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;“&lt;/i&gt;&lt;i&gt;hello&lt;/i&gt;&lt;i&gt;”声音剪辑的完整谱图&lt;/i&gt;&lt;/p&gt;&lt;p&gt;频谱图很酷，因为你可以从音频数据中实际&lt;i&gt;看到&lt;/i&gt;音符和其他音高模式。对于神经网络来说，相比于原始声波，它可以更加容易地从这种数据中找到规律。因此，这就是我们将实际输入到神经网络的数据表示方式。&lt;/p&gt;&lt;p&gt;&lt;b&gt;从短声音识别字符&lt;/b&gt;&lt;/p&gt;&lt;p&gt;现在我们有了一个易于处理的格式的音频，我们将把它输入到深度神经网络中去。神经网络的输入将会是20毫秒的音频块。对于每个小的音频切片(Audio Slice)，它将试图找出当前正在说的声音对应的&lt;i&gt;字母（&lt;/i&gt;&lt;i&gt;letter&lt;/i&gt;&lt;i&gt;）&lt;/i&gt;。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-450c92d19922fe3b9f81be163c632cdc.png" data-rawwidth="1000" data-rawheight="602"&gt;&lt;/p&gt;&lt;p&gt;我们将使用一个循环神经网络 - 即一个拥有记忆来影响未来预测的神经网络。这是因为它预测的每个字母都应该能够影响下一个字母的预测可能性。例如，如果我们到目前为止已经说了“HEL”，那么很有可能我们接下来会说“LO”来完成“Hello”。我们不太可能会说“XYZ”之类根本读不出来的东西。因此，具有先前预测的记忆有助于神经网络对未来进行更准确的预测。&lt;/p&gt;&lt;p&gt;当我们通过神经网络运行我们的整个音频剪辑（一次一块）之后，我们将最终得到每个音频块和其最可能被说出的那个字母的一个映射（mapping）。这是一个看起来说”Hello”的映射：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-5740ab153ac140af0d2809d3b0da1b58.png" data-rawwidth="1250" data-rawheight="797"&gt;&lt;/p&gt;&lt;p&gt;我们的神经网络正在预测我说的那个词很有可能是“HHHEE_LL_LLLOOO”。但它同时认为我说的也可能是“HHHUU_LL_LLLOOO”，或者甚至是“AAAUU_LL_LLLOOO”。&lt;/p&gt;&lt;p&gt;我们遵循一些步骤来整理这个输出。首先，我们将用单个字符替换任何重复的字符：&lt;/p&gt;&lt;p&gt;HHHEE_LL_LLLOOO变为HE_L_LO&lt;/p&gt;&lt;p&gt;HHHUU_LL_LLLOOO变为HU_L_LO&lt;/p&gt;&lt;p&gt;AAAUU_LL_LLLOOO变为AU_L_LO&lt;/p&gt;&lt;p&gt;然后，我们将删除所有空白处：&lt;/p&gt;&lt;p&gt;HE_L_LO变为HELLO&lt;/p&gt;&lt;p&gt;HU_L_LO变为HULLO&lt;/p&gt;&lt;p&gt;AU_L_LO变为AULLO&lt;/p&gt;&lt;p&gt;这让我们得到三种可能的转录 - “Hello”，“Hullo”和“Aullo”。如果你大声说出这些词，所有这些声音都类似于“Hello”。因为它每次只预测一个字符，神经网络会得出一些试探性的转录。例如，如果你说“He would not go”，它可能会给一个可能 “He wud net go” 的转录。&lt;/p&gt;&lt;p&gt;解决问题的诀窍是将这些基于发音的预测与基于书面文本（书籍，新闻文章等）大数据库的可能性得分相结合。你抛弃掉最不可能的转录，而保留住最现实的转录。&lt;/p&gt;&lt;p&gt;在我们可能的转录“Hello”，“Hullo”和“Aullo”中，显然“Hello”将更频繁地出现在文本数据库中（更不用说在我们原始的基于音频的训练数据中），因此它可能是正确的。所以我们会选择“Hello” 而不是其他作为我们的最后的转录。完成！&lt;/p&gt;&lt;p&gt;&lt;b&gt;等一下！&lt;/b&gt;&lt;/p&gt;&lt;p&gt;你可能会想“但是如果有人说Hullo”怎么办？这是一个有效的词。也许“Hello”是错误的转录！&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-1b6af94ac603955ad4532f75b2c846e7.jpg" data-rawwidth="700" data-rawheight="467"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;“&lt;/i&gt;&lt;i&gt;Hullo&lt;/i&gt;&lt;i&gt;！&lt;/i&gt;&lt;i&gt;Who dis&lt;/i&gt;&lt;i&gt;？&lt;/i&gt;&lt;/p&gt;&lt;p&gt;当然可能有人实际上说“Hullo”而不是“Hello”。但是这样的语音识别系统（基于美国英语训练）基本上不会产生“Hullo”作为转录。用户说“Hullo”，它总是会认为你在说“Hello”，无论你发“U”的声音有多重。&lt;/p&gt;&lt;p&gt;试试看！如果你的手机被设置为美式英语，尝试让你的手机助手识别单词“Hullo”。这不行！它掀桌子不干了(╯‵□′)╯︵┻━┻！它总是会理解为“Hello”。&lt;/p&gt;&lt;p&gt;不识别“Hullo”是一个合理的行为，但有时你会发现令人讨厌的情况:你的手机就是不能理解你说的有效的语句。这就是为什么这些语音识别模型总是被更多的数据训练来修复这些少数情况。&lt;/p&gt;&lt;p&gt;&lt;b&gt;我能建立自己的语音识别系统吗？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;机器学习最酷炫的事情之一就是它有时看起来十分简单。你得到一堆数据，把它输入到机器学习算法当中去，然后就能神奇的得到一个运行在你的游戏笔记本电脑的显卡上的世界级AI系统...&lt;i&gt;对吧&lt;/i&gt;？&lt;/p&gt;&lt;p&gt;这在某些情况下是真实的，但对于语音识别并不成立。语音识别是一个困难的问题。你必须克服几乎无限的挑战：质量差的麦克风，背景噪音，混响和回声，口音变化，还有很多很多。所有这些问题都需要存在于你的训练数据中，以确保神经网络可以应对它们。&lt;/p&gt;&lt;p&gt;这里有另外一个例子：你知不知道，当你在一个充满噪音的房间里说话时，你不自觉地提高你的音调，以便能够盖过噪音。人类在什么情况下都可以理解你，但神经网络需要训练来处理这种特殊情况。所以你需要人们对着噪音大声说话的训练数据！&lt;/p&gt;&lt;p&gt;要构建一个能在Siri，Google Now！或Alexa等平台上运行的语音识别系统，你将需要&lt;i&gt;大量&lt;/i&gt;的训练数据 -如果你不雇佣数百人为你录制的话，它需要的训练数据比你自己能够获得的数据要多得多。由于用户对低质量语音识别系统的容忍度很低，因此你不能吝啬。没有人想要一个只有80%的时间有效的语音识别系统。&lt;/p&gt;&lt;p&gt;对于像谷歌或亚马逊这样的公司，在现实生活中记录的数十万小时的人声语音就是&lt;i&gt;黄金&lt;/i&gt;。这就是将他们世界级语音识别系统与你自己的系统拉开差距的地方。让你免费使用&lt;i&gt;Google Now!&lt;/i&gt;或Siri或只要50美元购买Alexa而没有订阅费的意义就是：&lt;b&gt;&lt;i&gt;让你尽可能多的使用他们&lt;/i&gt;&lt;/b&gt;。你对这些系统所说的每一句话都会&lt;b&gt;&lt;i&gt;永远记录&lt;/i&gt;&lt;/b&gt;下来，并用作未来版本语音识别算法的训练数据。这才是他们的真实目的！&lt;/p&gt;&lt;p&gt;不相信我？如果你有一部安装了Google Now!的Android手机，请&lt;a href="https://myactivity.google.com/udc/vaa" data-editable="true" data-title="点击这里"&gt;点击这里&lt;/a&gt;收听你自己对它说过的每一句话：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-36f57014e18b8cb9968b9327fc7f0bc7.png" data-rawwidth="1000" data-rawheight="501"&gt;&lt;/p&gt;&lt;p&gt;你可以通过Alexa在Amazon上找到相同的东西。然而，不幸的是，苹果并不让你访问你的Siri语音数据。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;因此，如果你正在寻找一个创业的想法，我不建议你尝试建立自己的语音识别系统来与Google竞争。相反，你应该找出一种能让人们把他们说几个小时话的录音给予你的方法。这种数据可以是你的产品。&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;路在远方&lt;/b&gt;&lt;b&gt;…&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这个用来处理不同长度音频的算法被称为Connectionist Temporal Classification或CTC。&lt;a href="goog_970985545" data-editable="true" data-title="你可以阅读"&gt;你可以阅读&lt;/a&gt;&lt;a href="http://www.cs.toronto.edu/~graves/icml_2006.pdf" data-editable="true" data-title="2006年文章"&gt;2006年文章&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;百度的Adam Coates在湾区深度学习学校做了关于“深度学习语音识别”的精彩演讲。你可以在YouTube上&lt;a href="https://youtu.be/9dXiAecyJrY?t=13874" data-editable="true" data-title="观看这段视频"&gt;观看这段视频&lt;/a&gt;（他的演讲从3分51秒开始）。强烈推荐。&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/24703268&amp;pixel&amp;useReferer"/&gt;</description><author>九五要当学霸</author><pubDate>Wed, 04 Jan 2017 10:22:57 GMT</pubDate></item><item><title>【巡洋舰首发】有趣的机器学习 第五章：使用深度学习进行【语言翻译】 和 序列的魔力</title><link>https://zhuanlan.zhihu.com/p/24590838</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-14ed4f1b20aea7acc67d5ad1aeee408e_r.jpg"&gt;&lt;/p&gt;&lt;p&gt;原文：Adam Geitgey&lt;/p&gt;&lt;p&gt;原文链接：&lt;a href="https://medium.com/@ageitgey/machine-learning-is-fun-part-5-language-translation-with-deep-learning-and-the-magic-of-sequences-2ace0acca0aa#.t5upusfij" class="" data-editable="true" data-title="medium.com 的页面"&gt;https://medium.com/@ageitgey/machine-learning-is-fun-part-5-language-translation-with-deep-learning-and-the-magic-of-sequences-2ace0acca0aa#.t5upusfij&lt;/a&gt;&lt;/p&gt;&lt;p&gt;翻译：巡洋舰科技——赵95&lt;/p&gt;&lt;p&gt;你是不是看烦了各种各样对于深度学习的报导，却不知其所云？我们要来改变这个问题。&lt;/p&gt;&lt;p&gt;有趣的机器学习 前六章已更新！点此查看&lt;a href="https://zhuanlan.zhihu.com/p/24339995" class="" data-editable="true" data-title="第一章：最简明入门指南"&gt;第一章：最简明入门指南&lt;/a&gt;、&lt;a href="https://zhuanlan.zhihu.com/p/24344720" class="" data-editable="true" data-title="第二章：用机器学习制造【超级马里奥】的关卡"&gt;第二章：用机器学习【制造超级马里奥】的关卡&lt;/a&gt;、&lt;a href="https://zhuanlan.zhihu.com/p/24524583" class="" data-editable="true" data-title="第三章：图像识别【鸟or飞机】"&gt;第三章：图像识别【鸟or飞机】&lt;/a&gt;&lt;a href="https://zhuanlan.zhihu.com/p/24567586" class="" data-editable="true" data-title="第四章：用深度进行【人脸识别】"&gt;第四章：用深度进行【人脸识别】&lt;/a&gt;&lt;a href="https://zhuanlan.zhihu.com/p/24590838" class="" data-editable="true" data-title="第五章：使用深度学习进行【语言翻译】和 序列的魔力"&gt;第五章：使用深度学习进行【语言翻译】和 序列的魔力&lt;/a&gt;&lt;a href="https://zhuanlan.zhihu.com/p/24703268" data-title="第六章：如何用深度学习进行【语音识别】" class="" data-editable="true"&gt;第六章：如何用深度学习进行【语音识别】&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;我们都知道并且喜欢使用Google翻译，这个网站可以瞬时翻译100种不同的人类语言，就好像有魔法一样。他甚至存在于我们的手机和智能手表上面：（知乎无法上传太大的GIF，看图请戳原文）&lt;/h2&gt;&lt;p&gt;Google翻译背后的科技被称为机器翻译。它改变了世界，在本来根本不可能的情况下让(不同语言的)人们完成了沟通。&lt;/p&gt;&lt;p&gt;但我们都知道，在过去的15年里，高中学生已经使用Google翻译...额 ...&lt;i&gt;协助&lt;/i&gt;他们完成他们的西班牙语作业。这已经不是新闻了…？&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-a9fcbd775a70567a8d49ea73e42f4358.jpg" data-rawwidth="853" data-rawheight="192"&gt;&lt;/p&gt;&lt;p&gt;事实证明，在过去两年，深度学习已经完全改写了我们的机器翻译方法。那些对语言翻译一无所知的深度学习研究人员正在利用一个个相对简单的机器学习解决方案，来打败世界上最好的专家建造的语言翻译系统。&lt;/p&gt;&lt;p&gt;这一突破背后的技术被称为&lt;b&gt;序列到序列学习&lt;/b&gt;&lt;b&gt;sequence to sequence learnin&lt;/b&gt;g。这是一项非常强大的技术，被用于解决许多种类的问题。在我们看到它如何被用于翻译之后，我们还将学习这个算法是怎样用来编写AI聊天机器人和描述图片的。&lt;/p&gt;&lt;p&gt;我们开始吧！&lt;/p&gt;&lt;p&gt;&lt;b&gt;让计算机翻译&lt;/b&gt;&lt;/p&gt;&lt;p&gt;那么我们该如何编写代码，才能让计算机翻译人类的语言呢？&lt;/p&gt;&lt;p&gt;最简单的方法，就是把句子中的每个单词，都替换成翻译后的目标语言单词。这里有一个简单的例子，把西班牙语逐字翻译成英语：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-db380a8bf032afa9533d358389de99d6.png" data-rawwidth="1000" data-rawheight="180"&gt;&lt;/p&gt;&lt;p&gt;我们只是用匹配的英语单词替换每个西班牙单词。&lt;/p&gt;&lt;p&gt;这很容易实现，因为你所需要是一本字典来查找每个单词的翻译。但结果并不好，因为它忽略了语法和上下文的联系。&lt;/p&gt;&lt;p&gt;因此，下一件你可能要做的事，就是开始添加特定语言规则以改进结果。例如，你可能将两个常用词翻译为词组。你可能互换名词和形容词的顺序，因为他们在西班牙语中以相反的顺序出现：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-bed5ad249e62bea5ac3958c725dd0160.png" data-rawwidth="1000" data-rawheight="250"&gt;&lt;/p&gt;&lt;p&gt;这真的有效！如果我们就继续添加更多的规则，直到我们可以应对每一部分语法，我们的程序应该就能够翻译任何句子了，对吧？&lt;/p&gt;&lt;p&gt;这就是最早的机器翻译系统的工作原理。语言学家提出了许多复杂的规则，并逐一编程实现。一些世界上最聪明的语言学家在冷战期间辛勤努力了多年，才创建出了一些更容易理解俄罗斯人交流的翻译系统。&lt;/p&gt;&lt;p&gt;不幸的是，这种套路只对简单问题适用，比如说像天气预报这样结构简单的文档。它对于真实世界的文字来说并不可靠。&lt;/p&gt;&lt;p&gt;问题是，人类语言并不总是遵循固定的规则。人类语言充满了各种特殊情况，区域差异，或者干脆就不按套路出牌(#‵′)凸。我们说英语的方式更多地受到几百年前入侵的人的影响，而不是由坐下来定义语法规则的人。&lt;/p&gt;&lt;p&gt;&lt;b&gt;利用统计数据使计算机更好地翻译&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在基于规则的系统失效之后，一些新的翻译方法被开发出来了，他们基于概率和统计的模型而不是语法规则。&lt;/p&gt;&lt;p&gt;建造一个基于统计的翻译系统需要大量的训练数据，其中完全相同的文本被翻译成至少两种语言。这种双重翻译的文本称为&lt;b&gt;&lt;i&gt;平行语料库parallel corpora&lt;/i&gt;&lt;/b&gt;。18世纪的科学家以同样的方式在罗塞塔石碑上面从希腊语中找出埃及象形文字。(译者注：罗塞塔石碑，高1.14米，宽0.73米，制作于公元前196年，刻有&lt;a href="http://baike.baidu.com/view/8498.htm" data-editable="true" data-title="古埃及"&gt;古埃及&lt;/a&gt;国王&lt;a href="http://baike.baidu.com/view/192409.htm" data-editable="true" data-title="托勒密五世"&gt;托勒密五世&lt;/a&gt;登基的诏书。石碑上用&lt;a href="http://baike.baidu.com/view/11761660.htm" data-editable="true" data-title="希腊文字"&gt;希腊文字&lt;/a&gt;、&lt;a href="http://baike.baidu.com/view/138248.htm" data-editable="true" data-title="古埃及文字"&gt;古埃及文字&lt;/a&gt;和当时的通俗体文字刻了同样的内容，这使得近代的&lt;a href="http://baike.baidu.com/view/67249.htm" data-editable="true" data-title="考古学家"&gt;考古学家&lt;/a&gt;得以有机会对照各语言版本的内容后，解读出已经失传千余年的埃及象形文之意义与结构，而成为今日研究古埃及历史的重要里程碑)以同样的方式，计算机可以使用平行语料库猜测如何将文本从一种语言转换为另一种语言。&lt;/p&gt;&lt;p&gt;幸运的是，有很多双重翻译的文本已经存在在世界的各个角落。例如，欧洲议会将其诉讼程序翻译成21种语言。因此，研究人员经常使用这些数据来帮助建造翻译系统。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-8405085e2a71fe599a8a0365b8a61596.png" data-rawwidth="1000" data-rawheight="167"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;训练数据通常令人兴奋！但这只是无数条政府文件而已...&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;用概率的思维思考&lt;/b&gt;&lt;/p&gt;&lt;p&gt;统计翻译系统的根本不同，在于它们试图生成不止一个精确的翻译。相反，他们生成成千上万种可能的翻译，然后他们按照可能最正确的给这些翻译排名。他们通过与训练数据的相似性来估计有多“正确”。以下是它的工作原理：&lt;/p&gt;&lt;p&gt;&lt;b&gt;第1步：将原始句子分成块&lt;/b&gt;&lt;/p&gt;&lt;p&gt;首先，我们将我们的句子分成简单的块，每一块都可以轻松翻译：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-ec2cc836a5ae27ee35ed01a912036d31.png" data-rawwidth="1000" data-rawheight="87"&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;第2步：找到每一块的所有可能的翻译&lt;/b&gt;&lt;/p&gt;&lt;p&gt;接下来，我们将翻译每块文字，我们将通过寻找我们数据库中所有人类翻译过的相同词块来完成我们的翻译。&lt;/p&gt;&lt;p&gt;要着重注意的是，我们不只是在一本简简单单的翻译字典中查找这些词块。相反，我们看到是真实的人在真实的句子中如何翻译这些相同的词。这有助于我们捕获到在不同语境中所有不同的表达方式：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-4a56bab19fc10b4fd4f52cc2cf9351b5.png" data-rawwidth="1000" data-rawheight="471"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;即使最常见的短语也有很多种可能的翻译&lt;/i&gt;&lt;/p&gt;&lt;p&gt;这些可能的翻译中的有一些会比其他翻译更频繁地使用。根据我们训练数据中每个翻译出现的频率，我们可以给它设定一个分数。&lt;/p&gt;&lt;p&gt;例如，有人说“Quiero”更多的时候是指“我想要”而不是“我尝试”。所以，我们可以使用我们训练数据中 “Quiero”被翻译成“我想要”的频率，给“我想要”这个翻译更多的权重。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第3步：生成所有可能的句子，找到最有可能的那句&lt;/b&gt;&lt;/p&gt;&lt;p&gt;接下来，我们将使用这些词块的每种可能翻译来组合生成一堆可能的句子。&lt;/p&gt;&lt;p&gt;从第二步中列出的翻译过的词块中，我们可以通过不同组合方式生成将近2,500个不同的句子。下面是一些例子：&lt;/p&gt;&lt;p&gt;&lt;i&gt;I love | to leave | at | the seaside | more tidy.&lt;/i&gt;&lt;i&gt;I mean | to be on | to | the open space | most lovely.I like | to be |on | per the seaside | more lovely.I mean | to go | to | the open space | most tidy.&lt;/i&gt;&lt;/p&gt;&lt;p&gt;但在真实世界中，因为有不同的语序和词块分解方法，所以实际上有更多可能的词块组合：&lt;/p&gt;&lt;p&gt;&lt;i&gt;I try | to run | at | the prettiest | open space.&lt;/i&gt;&lt;i&gt;I want | to run | per | the more tidy | open space.I mean | to forget | at | the tidiest | beach.I try | to go | per | the more tidy | seaside.&lt;/i&gt;&lt;/p&gt;&lt;p&gt;现在需要扫描所有这些生成的句子，找到那个听起来“最像人话”的句子。&lt;/p&gt;&lt;p&gt;为此，我们将每个生成的句子与来自英语书籍和新闻故事的数百万个真实句子进行比较。我们拥有的英语文本越多越好。&lt;/p&gt;&lt;p&gt;我们采用这种可能的翻译：&lt;/p&gt;&lt;p&gt;&lt;i&gt;I try | to leave | per | the most lovely | open space.&lt;/i&gt;&lt;/p&gt;&lt;p&gt;很可能没有人用英语写过这样的句子，所以它不会与我们的数据库任何句子非常相似。我们给这个可能的翻译设定一个低概率的得分。&lt;/p&gt;&lt;p&gt;但看看下面这个可能的翻译：&lt;/p&gt;&lt;p&gt;&lt;i&gt;I want | to go | to | the prettiest | beach.&lt;/i&gt;&lt;/p&gt;&lt;p&gt;这个句子和我们的训练集中的句子很类似，所以它将获得一个高概率的得分。&lt;/p&gt;&lt;p&gt;在尝试过所有可能的句子之后，我们会选择那个，既是最有可能的词块翻译，又与真实英语句子最相似，的句子。&lt;/p&gt;&lt;p&gt;我们最后的翻译将是“&lt;i&gt;I want | to go | to | the prettiest | beach.&lt;/i&gt;&lt;/p&gt;&lt;p&gt;我想去最漂亮的海滩。”不错！&lt;/p&gt;&lt;p&gt;&lt;b&gt;有里程碑意义的统计机器翻译&lt;/b&gt;&lt;/p&gt;&lt;p&gt;当有足够多的训练数据的时候，统计机器翻译系统的性能要优于基于语言规则的系统。 Franz Josef Och基于这些想法并做出了改进，并在21世纪初使用它们构建了Google翻译。机器翻译终于可以被全世界使用。&lt;/p&gt;&lt;p&gt;早期的时候，基于概率翻译的“愚蠢”方法居然比语言学家设计规则系统做的更好，这让每个人都感到惊讶。这导致了80年代的时候，研究人员会(有点刻薄的)说：&lt;/p&gt;&lt;p&gt;“每当我炒了一个语言学家鱿鱼的时候，我的翻译准确度就会上升。” &lt;a href="https://en.wikipedia.org/wiki/Frederick_Jelinek" data-editable="true" data-title="Frederick Jelinek"&gt;&lt;i&gt;Frederick Jelinek&lt;/i&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;统计机器翻译的局限性&lt;/b&gt;&lt;/p&gt;&lt;p&gt;虽然统计机器翻译系统效果还不错，但是他们难于构建和维护。每一对需要翻译的新语言，都需要专业人士对一个全新的多步骤“翻译流水线”进行调试和修整。&lt;/p&gt;&lt;p&gt;因为构建这些不同的流水线需要做太多工作，所以我们必须进行权衡。如果你要用Google翻译把格鲁吉亚语翻译成泰卢固语（印度东部德拉维拉语言），那么作为一个中间步骤，它必须先翻译成英语。因为并没有太多格鲁吉亚到泰卢固语的翻译需求，所以在这一对语言上投入太多并没有太大意义。相比于英语翻译到法语，它可能会使用一个更低级的“翻译流水线”。&lt;/p&gt;&lt;p&gt;如果我们能让计算机为我们做所有令人讨厌的开发工作，这不更好么？&lt;/p&gt;&lt;p&gt;&lt;b&gt;让电脑翻译的更好——无需昂贵的专家们&lt;/b&gt;&lt;/p&gt;&lt;p&gt;机器翻译的核心是一个黑盒系统，它通过查看训练数据，自己就可以学习如何翻译。使用统计机器翻译，人们仍然需要建立和调整多步骤的统计模型。&lt;/p&gt;&lt;p&gt;2014年，KyungHyun Cho的团队取得了突破。他们发现了一种应用深度学习来构建这种黑盒系统的方法。他们的深度学习模型采用平行语料库，并使用它来学习如何在无任何人为干预的情况下在这两种语言之间进行翻译。&lt;/p&gt;&lt;p&gt;两个宏伟的方法使这成为可能 - 循 环神经网络和编码。通过巧妙地结合这两个想法，我们可以建立一个能够自学的翻译系统。&lt;/p&gt;&lt;p&gt;&lt;b&gt;循环神经网络&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们已经在第2章讨论过了循环神经网络，让我们快速回顾一下。&lt;/p&gt;&lt;p&gt;一个常规（非循环）神经网络是泛型机器学习算法，接收一序列数字并计算结果（基于先前的训练）。神经网络可以用作一个黑盒子，来解决很多问题。例如，我们可以基于房子的属性，使用神经网络来计算房屋的近似价格：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-6ea7212dd6e34f5ed60eec35acb7c756.png" data-rawwidth="860" data-rawheight="389"&gt;&lt;/p&gt;&lt;p&gt;但是像大多数机器学习算法一样，神经网络是无状态(Stateless)的。你输入一序列数字，神经网络计算并输出结果。如果再次输入相同的数字，它总是计算出相同的结果。它没有进行过的计算的记忆。换句话说，2 + 2总是等于4。&lt;/p&gt;&lt;p&gt;一个&lt;b&gt;循环神经网络（Recurrent Neural Network或简称RNN）&lt;/b&gt;是一个稍微改进过的神经网络的版本，区别是RNN先前的状态是可以被当做输入，再次带入到下一次计算中去。这意味着之前的计算结果会更改未来计算的结果！&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-d164b6165ed48bef689a837f6a70aca0.png" data-rawwidth="860" data-rawheight="556"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;人类痛恨他：一个黑科技就让机器变得更聪明！&lt;/i&gt;&lt;/p&gt;&lt;p&gt;我们为什么要这样做？无论我们上次计算结果是什么，2 + 2不应该总是等于4么？&lt;/p&gt;&lt;p&gt;这个技巧允许神经网络学习数据序列中的规律。例如，基于句子的前几个词，你可以使用它来预测句子中下一个最有可能的单词是什么：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-4c999bbcdf7e7ce9a691ce76438064de.jpg" data-rawwidth="887" data-rawheight="530"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;实现智能手机输入法的“自动更正”的方法之一&lt;/i&gt;&lt;i&gt;…&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;当你想要学习数据中的规律时，RNN将会非常有用。因为人类语言其实只是一个大而复杂的“规律”，自然语言处理的各个领域越来越多地使用RNN。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;如果你想了解更多关于RNN，你可以阅读第2章，我们使用了RNN来生成一本海明威写作风格的假书，然后使用同一个RNN生成了超级马里奥兄弟的游戏关卡。&lt;/p&gt;&lt;p&gt;&lt;b&gt;编码&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们需要回顾的另一个想法是&lt;b&gt;&lt;i&gt;编码Encoding&lt;/i&gt;&lt;/b&gt;。在第4章中作为脸部识别的一部分，我们谈到了编码。为了解释编码，让我们稍作调整，了解一下如何用电脑区分两个人。&lt;/p&gt;&lt;p&gt;当你试图用电脑区分两张脸时，你从每张脸收集不同的测量值，并与其他脸部比较这些测量值。例如，我们可以测量耳朵的大小或眼间的间距，比较两个图片的测量值以确定他们是否是同一个人。&lt;/p&gt;&lt;p&gt;你可能已经从观看热门影视剧CSI当中对这个想法耳熟能详了（知乎无法上传太大的GIF，看图请戳原文）。&lt;/p&gt;&lt;p&gt;把面部特征转换为一系列测量值的想法就是编码的例子之一。我们获取到原始数据（面部图片），并将其转换为代表这张脸的一系列测量值（编码）。&lt;/p&gt;&lt;p&gt;但是像我们在第4章中看到的，我们不必提出一个具体的面部特征列表来测量我们自己。相反，我们可以使用神经网络，让它自动从面部生成测量值。找出哪些测量值能够区分两个相似的人，计算机在这方面比我们做的更好：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-6e2b5cfcbd33b1105a4d8d40191c162d.png" data-rawwidth="1000" data-rawheight="499"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;这些是由神经网络产生的面部特征测量值，训练后的该神经网络可以保证不同的数字代表了不同人的面部。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;这是我们的&lt;i&gt;编码&lt;/i&gt;。它让我们用简单的东西（128个数字）代表非常复杂的东西（一张脸的图片）。现在比较两张脸更加容易了，因为我们只需要比较这128个数字而不是比较整张脸的图像。&lt;/p&gt;&lt;p&gt;你猜怎么着？我们可以用句子做同样的事情！我们可以把任何一个句子表达成一系列独特的编码：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-4fa1d6823b59d61bc84d290f4cf8adeb.png" data-rawwidth="1000" data-rawheight="479"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;这一序列数字代表的是英语句子“有趣的机器学习！”。不同的句子将由不同的数字集表示。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;为了生成这个编码，我们将句子输入到RNN中，一次一个词。最后一个词处理之后的最终结果，就将是表示整个句子的数值：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-520f649f58b1d522f1c38ff49153c590.jpg" data-rawwidth="877" data-rawheight="395"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;因为RNN具有记忆功能，能够记住处理过得每个词，所以它计算的最终编码表示句子中的所有词。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;棒极了，所以现在我们有一种方法来把一个整个句子表示成一组独特的数字！我们不知道编码中的每个数字是什么意思，但这并不重要。只要每一句话都能由一组独特的数字标识出来，那么我们就不需要准确地知道这些数字是如何生成的。&lt;/p&gt;&lt;p&gt;&lt;b&gt;让我们开始翻译吧！&lt;/b&gt;&lt;/p&gt;&lt;p&gt;好的，所以我们知道怎样使用RNN去个一句话编码并生成一组独特的数字。它有什么用呢？事情从这儿开始变得酷炫了！&lt;/p&gt;&lt;p&gt;如果我们使用两个RNNs并将它们首尾相连呢？第一个RNN可以给句子生成编码。然后，第二RNN遵循相反的逻辑，解码得到原始句子：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-473f0ea39bfa46879f0975c77272b8c8.png" data-rawwidth="1250" data-rawheight="336"&gt;&lt;/p&gt;&lt;p&gt;当然，编码然后再解码并得到原始语句并没有太大用处。但是如果（这里是问题的关键），我们训练第二个RNN，使它解码成西班牙语而不是英语，这会怎样？我们可以使用平行语料库训练数据来训练它：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-04ff81324066f8cc916e3b9773808cc9.png" data-rawwidth="1250" data-rawheight="334"&gt;&lt;/p&gt;&lt;p&gt;就像这样，我们有一个通用的方法，将一序列英语单词转换成同样的西班牙语单词序列！&lt;/p&gt;&lt;p&gt;这是一个强有力的想法：&lt;/p&gt;&lt;p&gt;l 这种方法主要受限于你拥有的训练数据量和你可以投入的计算机生产力。机器学习研究人员仅仅在在两年前发明了这个方法，但它已经表现的和统计机器翻译系统一样好了，而后者花了20年时间才开发完善。&lt;/p&gt;&lt;p&gt;l 这不依赖于任何关于人类语言规则的了解。算法自己计算出这些规则。这意味着你不需要专业人士来调整“翻译流水线”的各个步骤，计算机为你把这个做好了。&lt;/p&gt;&lt;p&gt;l 这种方法适用于几乎任何种类的&lt;b&gt;&lt;i&gt;序列到序列sequence-to-sequence&lt;/i&gt;&lt;/b&gt;问题！而且事实证明，许多有趣的问题都实际上是 序列到序列的问题。继续阅读了解其他你可以做的酷炫的事！&lt;/p&gt;&lt;p&gt;注意，我们忽略了一些处理真实数据会碰到的问题。例如，如何处理不同长度的输入和输出？这还需要一些额外的工作（请参见bucketing和padding）。非常用词翻译也是一个问题。&lt;/p&gt;&lt;p&gt;&lt;b&gt;构建你自己的序列到序列翻译系统&lt;/b&gt;&lt;/p&gt;&lt;p&gt;如果你想建立自己的语言翻译系统，这儿有一个包括可以在英语和法语之间翻译的TensorFlow的demo。然而，这并不是给胆小鬼或预算有限的人准备的。这仍然是一项新技术，并且资源有限。即使你有一台带有高级显卡的高级电脑，可能也需要连续一个月的时间来训练你自己的语言翻译系统。&lt;/p&gt;&lt;p&gt;此外，序列到序列语言翻译技术正在及快速地改进，以至于难以跟上。许多最近的改进（如添加注意机制attention mechanism或上下文跟踪tracking context）显着改善了翻译结果，但这些发展太过前沿，以至于他们甚至还没有维基百科页面。如果你想做认真的去做任何序列到序列学习，随着技术的发展，你需要持续保持更新，。&lt;/p&gt;&lt;p&gt;&lt;b&gt;序列到序列模型的无穷力量&lt;/b&gt;&lt;/p&gt;&lt;p&gt;那么，我们还能用序列到序列模型做什么呢？&lt;/p&gt;&lt;p&gt;大约一年前，Google的研究人员表示，你可以使用序列到序列模型来建造AI机器人。这个想法是如此简单，并且令人震惊的是，它真的有效。&lt;/p&gt;&lt;p&gt;首先，他们获取了一些Google员工和Google技术支持小组之间的聊天记录。然后他们训练了序列到序列模型，其中输入的句子就是雇员的问题，而技术支持团队的回复是该句子的“翻译”。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-b0e96c4e8b2853799ecc52ee39689f1a.png" data-rawwidth="1250" data-rawheight="341"&gt;&lt;/p&gt;&lt;p&gt;当用户与机器人进行交互时，他们将使用该系统“翻译”每个用户的消息以获得机器人的响应。&lt;/p&gt;&lt;p&gt;他们最终得到的是一个半智能机器人，（有时）可以回答真正的技术支持问题。下面是一部分用户和机器人之间的对话示例：&lt;/p&gt;&lt;p&gt;人：连接被拒绝或类似的东西&lt;/p&gt;&lt;p&gt;机器：我可以知道你连接的网络连接的版本吗？&lt;/p&gt;&lt;p&gt;人：我不确定我知不知道&lt;/p&gt;&lt;p&gt;机器：是网络连接提示任何用户证书？&lt;/p&gt;&lt;p&gt;人类：是的&lt;/p&gt;&lt;p&gt;机器：你现在在家还是在工作？办公室？&lt;/p&gt;&lt;p&gt;人：我在家&lt;/p&gt;&lt;p&gt;机器：试试这个。 goto &amp;lt;URL redacted&amp;gt;页面，然后输入您的姓名和密码&lt;/p&gt;&lt;p&gt;人类：完成&lt;/p&gt;&lt;p&gt;机器：尝试使用&amp;lt;NAME redacted&amp;gt;登录，然后检查其是否正常工作&lt;/p&gt;&lt;p&gt;人类：是的，现在它在工作！&lt;/p&gt;&lt;p&gt;机器：棒极了。还有什么我可以帮助你的？&lt;/p&gt;&lt;p&gt;他们还试图建立一个基于数百万部电影字幕的聊天机器人。他们的想法是，使用电影角色之间的对话作为一种训练机器人像人一样说话的方式。输入句子是一名角色的一句话，“翻译”是另一名角色在对话里回应他的内容：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-dffddd0667601ce5600454dfd82b5007.png" data-rawwidth="1250" data-rawheight="340"&gt;&lt;p&gt;他们得到了很有意思的结果。机器人不仅仅像一个人，更是显示出了一点点智能化：&lt;/p&gt;&lt;p&gt;人类：我的名字是david。我的名字是什么？&lt;/p&gt;&lt;p&gt;机器：david。&lt;/p&gt;&lt;p&gt;人：我的名字是约翰。我的名字是什么？&lt;/p&gt;&lt;p&gt;机器：约翰。&lt;/p&gt;&lt;p&gt;人类：你是领导还是追随者？&lt;/p&gt;&lt;p&gt;机器：我是领导者。&lt;/p&gt;&lt;p&gt;人类：你是追随者还是领导者？&lt;/p&gt;&lt;p&gt;机器：我是领导者。&lt;/p&gt;&lt;p&gt;这只是可能性的开始。我们将不局限于将一个句子转换成另一个句子，同样，我们制作一个图像到序列的模型，它可以将图像转换为文本！&lt;/p&gt;&lt;p&gt;Google的另一个团队通过将第一个RNN替换为卷积神经网络（如我们在第3章中所了解的那样）。这允许输入是图片而不是句子，其余的工作基本相同：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-9d899c93bdc3d566e6441d2e2a2f938e.png" data-rawwidth="1250" data-rawheight="341"&gt;&lt;/p&gt;&lt;p&gt;就像这样，（只要我们有很多很多的训练数据）我们就可以把图片变成单词！&lt;/p&gt;&lt;p&gt;Andrej Karpathy把这个想法进行了拓展，以构建一个通过分别处理图像的多个区域，来详细描述图像的系统：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-380c811bf4f9ffc0ebd1fa03427de50d.png" data-rawwidth="1000" data-rawheight="763"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;Andrej Karpathy论文中的图片&lt;/i&gt;&lt;/p&gt;&lt;p&gt;这个想法使得我们可以构建一个，能够按照奇怪的要求找到特定图片的图片搜索引擎：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-80cf134e8142811f9ba5f0f1561012a1.jpg" data-rawwidth="444" data-rawheight="356"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;例子来自&lt;a href="http://cs.stanford.edu/people/karpathy/deepimagesent/rankingdemo/" data-editable="true" data-title="image sentence ranking visualize"&gt;image sentence ranking visualize&lt;/a&gt;&lt;/i&gt;&lt;/p&gt;&lt;p&gt;甚至有研究人员正在研究相反的问题，仅仅基于文本描述产生一个完整的图片！&lt;/p&gt;&lt;p&gt;从这些例子，你可以开始想象的各种可能性。 到目前为止，序列到序列应用在从语音识别到计算机视觉各个领域。 我猜，明年会有更多的应用。&lt;/p&gt;&lt;p&gt;如果您想更深入地了解序列到序列模型和翻译，以下是一些推荐的资源：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=qGlmW2n4s1w" class="" data-editable="true" data-title="Richard Socher’s CS224D Lecture— Fancy Recurrent Neural Networks for Machine Translation"&gt;Richard Socher’s CS224D Lecture— Fancy Recurrent Neural Networks for Machine Translation&lt;/a&gt; (video)&lt;/li&gt;&lt;li&gt;&lt;a href="http://cs224d.stanford.edu/lectures/CS224d-Lecture15.pdf" class="" data-editable="true" data-title="Thang Luong’s CS224D Lecture — Neural Machine Transation"&gt;Thang Luong’s CS224D Lecture — Neural Machine Transation&lt;/a&gt; (PDF)&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.tensorflow.org/versions/r0.10/tutorials/seq2seq/index.html" class="" data-editable="true" data-title="TensorFlow’s description of Seq2Seq modeling"&gt;TensorFlow’s description of Seq2Seq modeling&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="http://www.deeplearningbook.org/contents/rnn.html" class="" data-editable="true" data-title="The Deep Learning Book’s chapter on Sequence to Sequence Learning"&gt;The Deep Learning Book’s chapter on Sequence to Sequence Learning&lt;/a&gt;(PDF)&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-c8693405235197b0a454b2c41cb432d6.png" data-rawwidth="1120" data-rawheight="808"&gt;&lt;/li&gt;&lt;/ul&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/24590838&amp;pixel&amp;useReferer"/&gt;</description><author>九五要当学霸</author><pubDate>Tue, 27 Dec 2016 17:03:08 GMT</pubDate></item><item><title>【巡洋舰首发】有趣的机器学习 第四章：用深度学习进行【人脸识别】</title><link>https://zhuanlan.zhihu.com/p/24567586</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-83f669a67c954c9331e03e5557bfc6eb_r.jpg"&gt;&lt;/p&gt;&lt;p&gt;原文：Adam Geitgey&lt;/p&gt;&lt;p&gt;原文链接：&lt;a href="https://medium.com/@ageitgey/machine-learning-is-fun-part-4-modern-face-recognition-with-deep-learning-c3cffc121d78#.asmzg3vx4" data-editable="true" data-title="medium.com 的页面"&gt;https://medium.com/@ageitgey/machine-learning-is-fun-part-4-modern-face-recognition-with-deep-learning-c3cffc121d78#.asmzg3vx4&lt;/a&gt;&lt;/p&gt;&lt;p&gt;翻译：巡洋舰科技——赵95&lt;/p&gt;&lt;p&gt;你是不是看烦了各种各样对于深度学习的报导，却不知其所云？我们要来改变这个问题。&lt;/p&gt;&lt;p&gt;有趣的机器学习 前六章已更新！点此查看&lt;a href="https://zhuanlan.zhihu.com/p/24339995" class="" data-editable="true" data-title="第一章：最简明入门指南"&gt;第一章：最简明入门指南&lt;/a&gt;、&lt;a href="https://zhuanlan.zhihu.com/p/24344720" class="" data-editable="true" data-title="第二章：用机器学习制造【超级马里奥】的关卡"&gt;第二章：用机器学习【制造超级马里奥】的关卡&lt;/a&gt;、&lt;a href="https://zhuanlan.zhihu.com/p/24524583" class="" data-editable="true" data-title="第三章：图像识别【鸟or飞机】"&gt;第三章：图像识别【鸟or飞机】&lt;/a&gt;&lt;a href="https://zhuanlan.zhihu.com/p/24567586" class="" data-editable="true" data-title="第四章：用深度进行【人脸识别】"&gt;第四章：用深度进行【人脸识别】&lt;/a&gt;&lt;a href="https://zhuanlan.zhihu.com/p/24590838" class="" data-editable="true" data-title="第五章：使用深度学习进行【语言翻译】和 序列的魔力"&gt;第五章：使用深度学习进行【语言翻译】和 序列的魔力&lt;/a&gt;&lt;a href="https://zhuanlan.zhihu.com/p/24703268" data-title="第六章：如何用深度学习进行【语音识别】" class="" data-editable="true"&gt;第六章：如何用深度学习进行【语音识别】&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;你有没有发现Facebook研发出了一种能够在你的照片中识别出你朋友的神之魔力？
之前，Facebook让你在照片里点击你的朋友，并输入他们的名字来标注出你的朋友。现在，只要你上传了一张照片，Facebook就魔力般的为你标注出你的每一个朋友：&lt;/h2&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-b414d836a7612bc12efc932b6a4b90bc.jpg" data-rawwidth="502" data-rawheight="346"&gt;&lt;p&gt;&lt;i&gt;Facebook&lt;/i&gt;&lt;i&gt;基于你之前的标注，自动标注出你照片中的人。我不确定这到底是有帮助性的还是非常阴险恐怖的。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;这种技术被称为人脸识别。你的朋友被标记了几次之后，Facebook的算法就能够识别你朋友的脸。
这是一项非常惊人的黑科技——Facebook的人脸识别准确率达到了98％，几乎与人类做的一样好！让我们来了解一下现代人脸识别是如何工作的！
但是，识别你的朋友这太容易了。
我们可以最大化扩展这项技术，来解决一个更具挑战性的问题——区分Will Ferrell（著名演员）和Chad Smith（著名摇滚音乐家）！&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-967774e47de559f90f39eb821b640f2c.jpg" data-rawwidth="1000" data-rawheight="562"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;一个是Will
Ferrell&lt;/i&gt;&lt;i&gt;，另一个是Chad Smith&lt;/i&gt;&lt;i&gt;。我保证他们不是同一个人！&lt;/i&gt;&lt;/p&gt;&lt;p&gt;如何用机器学习解决复杂问题？&lt;/p&gt;&lt;p&gt;到目前为止，在前三章，我们已经使用机器学习来解决了，一些只用一个步骤就可以解决的孤立问题——&lt;a href="https://zhuanlan.zhihu.com/p/24339995" data-title="第一章：估计房子的价格" class="" data-editable="true"&gt;第一章：估计房子的价格&lt;/a&gt;、&lt;a href="https://zhuanlan.zhihu.com/p/24344720" data-title="第二章：基于现有数据生成新数据" class="" data-editable="true"&gt;第二章：基于现有数据生成新数据&lt;/a&gt;（译者注：根据已有的超级马里奥的关卡生成新的关卡）、以及&lt;a href="https://zhuanlan.zhihu.com/p/24524583" data-title="第三章：判别图像当中是否包含某个物品" class="" data-editable="true"&gt;第三章：判别图像当中是否包含某个物品&lt;/a&gt;。
所有这些问题都可以通过下列步骤解决：选择一个机器学习算法，输入数据，并获得结果。&lt;/p&gt;&lt;p&gt;但是，人脸识别是由一系列的几个相关问题组成的：&lt;/p&gt;&lt;p&gt;首先，找到一张图片中的所有人脸&lt;/p&gt;&lt;p&gt;第二，对于每一张脸来说，无论光线明暗或面朝别处，它依旧能够识别出是同一个人的脸。&lt;/p&gt;&lt;p&gt;第三，能够在每一张脸上找出可用于与他人区分的独特之处，比如说眼睛有多大，脸有多长等等。&lt;/p&gt;&lt;p&gt;最后，将这张脸的特点与已知的所有人脸进行比较，以确定这个人的姓名。&lt;/p&gt;&lt;p&gt;作为人类，你的大脑总是在一瞬间自动做出了这些判断。实际上，人类在识别人脸这方面做得&lt;b&gt;&lt;i&gt;太好了&lt;/i&gt;&lt;/b&gt;，以至于他们会在日常物品中同样去“找脸”：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-ccb4dd22f6905c9825a7f369b3cd37dc.jpg" data-rawwidth="580" data-rawheight="250"&gt;&lt;/p&gt;&lt;p&gt;计算机不能进行这种高级泛化(generalization)（至少现在还不行...），所以我们必须分别教给他们，这个过程中的每一步是怎么做到的。&lt;/p&gt;&lt;p&gt;我们需要构建一个&lt;b&gt;流水线&lt;/b&gt;&lt;b&gt;(pipeline)&lt;/b&gt;，一个单独完成每个步骤并把结果发送给下一个步骤的流水线。换句话说，我们会将好几个机器学习算法连接到一起：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-7647e39242a7f7f7f5f0ec615eee3bf1.jpg" data-rawwidth="1000" data-rawheight="361"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;一个基础的探测人脸的流水线是怎样工作的&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;人脸识别——分步讲解&lt;/b&gt;&lt;/p&gt;&lt;p&gt;让我们一步一步地解决这个问题。
对于每个步骤，我们将学习一个不同的机器学习算法。
我并不会完全解释每一个的算法，否则这篇文章就变成了一本教科书。但你会学到每个步骤的精髓，以及如何在Python中使用&lt;a href="https://cmusatyalab.github.io/openface/" data-editable="true" data-title="OpenFace"&gt;OpenFace&lt;/a&gt;和&lt;a href="http://dlib.net/" data-editable="true" data-title="dlib"&gt;dlib&lt;/a&gt;来构建一个你自己的面部识别系统。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第一步：找出所有的面孔&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们流水线的第一步是面部检测。显然，在我们区分人脸之前，我们必须要照片中找到他们才行！&lt;/p&gt;&lt;p&gt;如果你在过去10年里使用过相机，你可能已经见过正在运行中的面部检测功能：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-bd16d8458af314c441f67c293f051f40.png" data-rawwidth="896" data-rawheight="459"&gt;&lt;/p&gt;&lt;p&gt;面部检测是相机很好的一个功能。
当相机可以自动拾取人脸时，它可以确保相机在拍摄时对焦到所有人脸。
不过，我们使用它另有其因——我们需要找到想要传递到流水线下一步的图像区域。&lt;/p&gt;&lt;p&gt;2000年初的时候， 当Paul
Viola和Michael
Jones 发明了一种能够快速在廉价相机上运行的一种脸部检测方法之后（译者注：这种算法也可以用来训练检测其他的物品，但是最经常还是被用于人脸的检测，其英文名称为Viola–Jones
object detection framework），面部检测在成为了主流。然而现在，更可靠的解决方案出现了。
我们将使用2005年发明的一种称为“&lt;b&gt;方向梯度直方图&lt;/b&gt;&lt;b&gt;(Histogram of Oriented Gradients)&lt;/b&gt;”的方法，或简称HOG。&lt;/p&gt;&lt;p&gt;要在一张图片中找到脸，我们首先将图像转换为黑白，因为我们并不需要颜色数据来找到脸：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-74fd08c6ce2f1c650a09272e7c7f7f57.jpg" data-rawwidth="511" data-rawheight="563"&gt;&lt;/p&gt;&lt;p&gt;然后，我们将查看图片中的每一个像素。
对于单个像素，我们要查看直接围绕着它的像素：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-bdc412d7dbe8c6f94becb144d21d3d1e.jpg" data-rawwidth="800" data-rawheight="282"&gt;&lt;/p&gt;&lt;p&gt;我们的目标是找出并比较当前像素与直接围绕它的像素的深度。
然后我们要画一个箭头来代表图像变暗的方向：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-8003fc861e178c2a4a65386d738e9634.jpg" data-rawwidth="500" data-rawheight="159"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;看这个像素和它周围的像素，图像向右上方变得越来越暗。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;如果你对图片中的&lt;b&gt;每一个像素&lt;/b&gt;重复这个过程，最终每个像素会被一个箭头取代。这些箭头被称为&lt;b&gt;梯度&lt;/b&gt;&lt;b&gt;gradients&lt;/b&gt;，它们能显示出图像上从明亮到黑暗的流动过程：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-a458e794e970703fd355f9a83aacf1ac.jpg" data-rawwidth="1000" data-rawheight="393"&gt;&lt;/p&gt;&lt;p&gt;这可能看起来非常随机，但其实我们有非常好的理由用梯度来代替像素。如果我们直接分析像素，同一个人明暗不同的两张照片将具有完全不同的像素值。但是如果只考虑亮度变化&lt;b&gt;&lt;i&gt;方向&lt;/i&gt;&lt;/b&gt;&lt;b&gt;&lt;i&gt;direction&lt;/i&gt;&lt;/b&gt;的话，明暗图像将会有同样的结果。这使得问题变得更容易解决！&lt;/p&gt;&lt;p&gt;但是保存每个像素的梯度太过细节化了，我们最终很有可能“一叶障目不见泰山missing the forest for the trees”。如果我们能从更高的角度上观察基本的明暗流动，我们就可以看出图像的基本规律，这会比之前更好。&lt;/p&gt;&lt;p&gt;为了做到这一点，我们将图像分割成一些16x16像素的小方块。在每个小方块中，我们将计算出每个主方向上有多少个梯度（有多少指向上，指向右上，指向右等）。然后我们将用指向性最强那个方向的箭头来代替原来的那个小方块。&lt;/p&gt;&lt;p&gt;最终的结果是，我们把原始图像变成了一个非常简单的表达形式，这种表达形式可以用一种简单的方式来捕获面部的基本结构：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-a2f4fde8df3dc047201f9add7850ca6f.jpg" data-rawwidth="800" data-rawheight="295"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;原始图像被表示成了HOG&lt;/i&gt;&lt;i&gt;形式，以捕获图像的主要特征，无论图像明暗度如何。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;为了在这个HOG图像中找到脸部，我们要所需要做的，就是找到我们的图像中，与已知的一些HOG样式中，看起来最相似的部分。这些HOG样式都是从其他面部训练数据中提取出来的：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-35e736853cc413f7d7d595ddb9bc56d9.png" data-rawwidth="1000" data-rawheight="697"&gt;&lt;/p&gt;&lt;p&gt;使用这种技术，我们现在可以轻松地在任何图片中找到脸部：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-83f669a67c954c9331e03e5557bfc6eb.jpg" data-rawwidth="1000" data-rawheight="563"&gt;&lt;/p&gt;&lt;p&gt;如果你想使用Python和dlib尝试这一步，&lt;a href="https://gist.github.com/ageitgey/1c1cb1c60ace321868f7410d48c228e1" data-editable="true" data-title="这些代码"&gt;这些代码&lt;/a&gt;显示了如何生成和查看HOG图像的表示。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第二步：脸部的不同姿势&lt;/b&gt;&lt;/p&gt;&lt;p&gt;哇，我们把图片中的脸部孤立出来了。
但现在，我们要处理的问题就是，对于电脑来说，面朝不同方向的同一张脸，是不同的东西：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-8cc2f0d8e403fa933a022a2d053b62d5.png" data-rawwidth="956" data-rawheight="389"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;人类可以很轻松地识别出到两个图片都是Will Ferrell&lt;/i&gt;&lt;i&gt;，但电脑会认为这两张图片是两个完全不同的人。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;为了解决这一点，我们将试图扭曲每个图片，使得眼睛和嘴唇总是在图像中的样本位置(Sample Place)。
这将使我们在接下来的步骤中，更容易比较脸部之间的不同。&lt;/p&gt;&lt;p&gt;为此，我们将使用一种称为&lt;b&gt;脸部标志点估计（&lt;/b&gt;&lt;b&gt;Face
Landmark Estimation&lt;/b&gt;&lt;b&gt;）&lt;/b&gt;的算法。 很多方法都可以做到这一点，但这次我们会使用由Vahid Kazemi和Josephine Sullivan在2014年发明的方法。&lt;/p&gt;&lt;p&gt;这一算法的基本思想是，我们找到人脸上普遍存在的68个特定点（称为Landmarks）——下巴的顶部，每只眼睛的外部轮廓，每条眉毛的内部轮廓等。接下来我们训练一个机器学习算法，能够在任何脸部找到这68个特定点：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-f7a513f83f2e4978e59f2becf43653a2.png" data-rawwidth="414" data-rawheight="394"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;我们将在每一张脸上定位的68&lt;/i&gt;&lt;i&gt;个Landmarks&lt;/i&gt;&lt;i&gt;。这张照片是由在OpenFace&lt;/i&gt;&lt;i&gt;工作的CMU&lt;/i&gt;&lt;i&gt;的Brandon Amos&lt;/i&gt;&lt;i&gt;创造的。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;这是在测试图片上定位68个标志点的结果：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-06fcc66230ba44b5533bcff134080209.jpg" data-rawwidth="1000" data-rawheight="871"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;友情提示：你也可以使用这一技术来实现自己的Snapchat&lt;/i&gt;&lt;i&gt;实时3D&lt;/i&gt;&lt;i&gt;脸部过滤器！ &lt;/i&gt;&lt;/p&gt;&lt;p&gt;现在，我们知道了眼睛和嘴巴在哪儿，我们将图像进行旋转，缩放和切变，使得眼睛和嘴巴尽可能靠近中心。我们不会做任何花哨的三维扭曲，因为这会让图像失真。我们只会使用那些能够保持图片相对平行的基本图像变换，例如旋转和缩放，（称为仿射变换）：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-962d576949169ea9618b8307fdca513a.png" data-rawwidth="1000" data-rawheight="280"&gt;&lt;/p&gt;&lt;p&gt;现在无论脸部怎样扭曲变形，我们都能将眼睛和嘴巴向中间挪动到大致相同的位置。这将使我们的下一步更加准确。&lt;/p&gt;&lt;p&gt;如果你想自己使用Python和dlib来尝试完成这一步的话，这里有一些代码帮你&lt;a href="https://gist.github.com/ageitgey/ae340db3e493530d5e1f9c15292e5c74" data-editable="true" data-title="寻找脸部标志点"&gt;寻找脸部标志点&lt;/a&gt;和&lt;a href="https://gist.github.com/ageitgey/82d0ea0fdb56dc93cb9b716e7ceb364b" data-editable="true" data-title="图像变形"&gt;图像变形&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第3步：给脸部编码&lt;/b&gt;&lt;/p&gt;&lt;p&gt;现在我们要面临最核心的问题了——如何区分脸部。这才是事情变得非常有趣的地方！&lt;/p&gt;&lt;p&gt;最简单的人脸识别方法，就是直接把我们在步骤2中发现的未知人脸，与我们已经标注了人脸图片作比较。当我们发现未知的面孔与一个以前标注过的面孔看起来及其相似的时候，它必须是同一个人。这似乎是一个很好的主意，对吗？&lt;/p&gt;&lt;p&gt;实际上这种方法有一个巨大的问题。像Facebook这种拥有数十亿用户和数万亿张照片的网站，是不可能去循环比较每张先前标记的脸的，这浪费的时间太长了。他们需要在毫秒内识别人脸，而不是几个小时。&lt;/p&gt;&lt;p&gt;我们需要的是一种从每张人脸上都可以提取一些基本特性的方法。然后，我们可以用同样的方式测量未知的面孔，并找到与已知的脸最相近的测量。例如，我们可以测量每个耳朵的大小，眼睛之间的间距，鼻子的长度等。如果你曾经看过像CSI这样的犯罪类型的电视剧，那么你就知道我在说什么了。&lt;/p&gt;&lt;p&gt;&lt;b&gt;测量人脸的最可靠的方法&lt;/b&gt;&lt;/p&gt;&lt;p&gt;好的，那么我们应该测量面部的哪些数值，来建立我们的已知脸部数据库呢？耳朵的大小？鼻子的长度？眼睛的颜色？还有什么？&lt;/p&gt;&lt;p&gt;事实证明，对于我们人类来说一些显而易见的测量值（比如眼睛颜色），并没有对计算机产生太大的影响。研究人员发现，最准确的方法是让计算机自己找出测量值并自己收集。深度学习比人类更好地了解脸部的哪些部分是重要的测量值。&lt;/p&gt;&lt;p&gt;所以，解决方案是训练一个深度卷积神经网络（就像我们在第3章做的那样）。但是，并不是像上次那样训练我们的网络来识别图片对象，我们将训练它为脸部生成128个测量值。&lt;/p&gt;&lt;p&gt;每次训练要观察3个不同的脸部图像：&lt;/p&gt;&lt;p&gt;1.加载一张已知的人的面部训练图像&lt;/p&gt;&lt;p&gt;2.加载同一个人的另一张照片&lt;/p&gt;&lt;p&gt;3.加载另外一个人的照片&lt;/p&gt;&lt;p&gt;&lt;b&gt;然后，算法查看它自己为这三个图片生成的测量值。再然后，它稍微调整神经网络，以确保它为第1&lt;/b&gt;&lt;b&gt;张和第2&lt;/b&gt;&lt;b&gt;章生成的测量值接近，而第2&lt;/b&gt;&lt;b&gt;张和第3&lt;/b&gt;&lt;b&gt;张生成的测量值略有不同。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-e504e8e72005e8d26b6cdfb89cb1834b.png" data-rawwidth="1000" data-rawheight="827"&gt;&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在为几千个不同的人的数百万图像重复该步骤数百万次之后，神经网络学习了如何可靠地为每个人生成128个测量值。同一个人的任何十张不同的照片应该给出大致相同的测量值。&lt;/p&gt;&lt;p&gt;机器学习专业人士把每个面孔上的128个测量值称为“嵌入（Embedding）”。将复杂的原始数据（如图片）缩减为可由计算机生成的一个数列的方法在机器学习（特别是语言翻译）中出现了很多次。我们正在使用的这种方法是由Google的研究人员在2015年发明的，但其实这是许多类似的方法之一。&lt;/p&gt;&lt;p&gt;&lt;b&gt;给我们的脸部图像编码&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这个通过训练卷积神经网络来输出脸部嵌入的过程，需要大量的数据和计算机应用。即使使用昂贵的Nvidia Telsa显卡，它也需要大约24小时的连续训练，才能获得良好的准确性。&lt;/p&gt;&lt;p&gt;但一旦网络训练完成，它可以生成任何面孔的测量值，即使它从来没有见过这些面孔！所以这种训练只需一次即可。幸运的是，OpenFace上面的大神已经做完了这些，并且他们发布了几个训练过可以直接使用的网络，。谢谢Brandon Amos和他的团队！&lt;/p&gt;&lt;p&gt;所以我们需要做的，就是通过他们的预训练网络来处理我们的脸部图像，以获得128个测量值。这是我们测试图像的一些测量值：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-6e2b5cfcbd33b1105a4d8d40191c162d.png" data-rawwidth="1000" data-rawheight="499"&gt;&lt;/p&gt;&lt;p&gt;那么，这128个数字到底测量了脸部的哪些部分？我们当然不知道，但是这对我们并不重要。我们关心的是，当看到同一个人的两张不同的图片时，我们的网络需要能得到几乎相同的数值。&lt;/p&gt;&lt;p&gt;如果你想自己尝试这个步骤，OpenFace提供了一个&lt;a href="https://github.com/cmusatyalab/openface/blob/master/batch-represent/batch-represent.lua" data-editable="true" data-title="lua脚本"&gt;lua脚本&lt;/a&gt;，它可以生成一个文件夹中所有图像的嵌入，并将它们写入csv文件。&lt;a href="https://gist.github.com/ageitgey/ddbae3b209b6344a458fa41a3cf75719" data-editable="true" data-title="点此查看如何运行"&gt;点此查看如何运行&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第4&lt;/b&gt;&lt;b&gt;步：从编码中找出人的名字&lt;/b&gt;&lt;/p&gt;&lt;p&gt;最后这一步实际上是整个过程中最简单的一步。我们要做的就是找到数据库中，与我们的测试图像的测量值最接近的那个人。&lt;/p&gt;&lt;p&gt;你可以通过任何基本的机器学习分类算法来达成这一目标。我们并不需要太花哨的深度学习技巧。我们将使用一个简单的线性SVM分类器，但实际上还有很多其他的分类算法可以使用。&lt;/p&gt;&lt;p&gt;我们需要做的是训练一个分类器，它可以从一个新的测试图像中获取测量结果，并找出最匹配的是哪个人。分类器运行一次只需要几毫秒，分类器的结果就是人的名字！&lt;/p&gt;&lt;p&gt;所以让我们试一下我们的系统。首先，我使用Will Ferrell, Chad Smith 和 Jimmy Falon每人20张照片的嵌入来训练分类器：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-61b8af810e1cacee40a634312bab6f11.jpg" data-rawwidth="1200" data-rawheight="266"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;嗯…就是这些训练数据！&lt;/i&gt;&lt;/p&gt;&lt;p&gt;接下来，我在YouTube著名的Will Ferrell和Chad Smith的视频的每一帧上运行这个分类器：&lt;/p&gt;&lt;p&gt;它真的有效！它在不同的姿势的脸部依然有效- 甚至是侧脸！&lt;/p&gt;&lt;p&gt;&lt;b&gt;你自己做一遍&lt;/b&gt;&lt;/p&gt;&lt;p&gt;让我们回顾一下我们的步骤：&lt;/p&gt;&lt;p&gt;1.使用HOG算法给图片编码，以创建图片的简化版本。使用这个简化的图像，找到图像中看起来最像通用HOG面部编码的部分。&lt;/p&gt;&lt;p&gt;2.通过找到脸上的主要标志点，找出脸部的姿态。一旦我们找到这些标志点，就利用它们把图像扭曲，使眼睛和嘴巴居中。&lt;/p&gt;&lt;p&gt;3. 把上一步得到的面部图像放入到神经网络中，神经网络知道如何找到128个特征点测量值。保存这128个测量值。&lt;/p&gt;&lt;p&gt;4.看看我们过去测量过得的所有脸部，找出哪个人的测量值和我们的脸部测量值最接近。这就是你要找的匹配的人！&lt;/p&gt;&lt;p&gt;现在你知道这一切都是如何运行的了，&lt;a href="https://cmusatyalab.github.io/openface/" data-editable="true" data-title="这里是如何使用OpenFace在你自己的电脑上运行整个人脸识别系统的说明"&gt;这里是如何使用OpenFace在你自己的电脑上运行整个人脸识别系统的说明&lt;/a&gt;.&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-c8693405235197b0a454b2c41cb432d6.png" data-rawwidth="1120" data-rawheight="808"&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/24567586&amp;pixel&amp;useReferer"/&gt;</description><author>九五要当学霸</author><pubDate>Mon, 26 Dec 2016 15:27:57 GMT</pubDate></item><item><title>【巡洋舰首发】有趣的机器学习 第三章:图像识别【鸟or飞机】？</title><link>https://zhuanlan.zhihu.com/p/24524583</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-598ca7f6c13ae5a99307768183b34bcd_r.jpg"&gt;&lt;/p&gt;&lt;p&gt;原文：Adam Geitgey&lt;/p&gt;&lt;p&gt;原文链接：&lt;a href="https://medium.com/@ageitgey/machine-learning-is-fun-part-3-deep-learning-and-convolutional-neural-networks-f40359318721#.rp9872f79" data-editable="true" data-title="medium.com 的页面" class=""&gt;https://medium.com/@ageitgey/machine-learning-is-fun-part-3-deep-learning-and-convolutional-neural-networks-f40359318721#.rp9872f79&lt;/a&gt;&lt;/p&gt;&lt;p&gt;翻译：巡洋舰科技——赵95&lt;/p&gt;&lt;p&gt;有趣的机器学习 前六章已更新！点此查看&lt;a href="https://zhuanlan.zhihu.com/p/24339995" class="" data-editable="true" data-title="第一章：最简明入门指南"&gt;第一章：最简明入门指南&lt;/a&gt;、&lt;a href="https://zhuanlan.zhihu.com/p/24344720" class="" data-editable="true" data-title="第二章：用机器学习制造【超级马里奥】的关卡"&gt;第二章：用机器学习【制造超级马里奥】的关卡&lt;/a&gt;、&lt;a href="https://zhuanlan.zhihu.com/p/24524583" class="" data-editable="true" data-title="第三章：图像识别【鸟or飞机】"&gt;第三章：图像识别【鸟or飞机】&lt;/a&gt;&lt;a href="https://zhuanlan.zhihu.com/p/24567586" class="" data-editable="true" data-title="第四章：用深度进行【人脸识别】"&gt;第四章：用深度进行【人脸识别】&lt;/a&gt;&lt;a href="https://zhuanlan.zhihu.com/p/24590838" class="" data-editable="true" data-title="第五章：使用深度学习进行【语言翻译】和 序列的魔力"&gt;第五章：使用深度学习进行【语言翻译】和 序列的魔力&lt;/a&gt;&lt;a href="https://zhuanlan.zhihu.com/p/24703268" data-title="第六章：如何用深度学习进行【语音识别】" class="" data-editable="true"&gt;第六章：如何用深度学习进行【语音识别】&lt;/a&gt;&lt;/p&gt;&lt;p&gt;你是不是看烦了各种各样对于深度学习的报导，却不知其所云？我们要来改变这个问题。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-9e224c4885ac2aa9a6514eb215026c8f.jpg" data-rawwidth="2018" data-rawheight="682"&gt;&lt;/p&gt;&lt;h2&gt;这一次我们将一起写一个，可以判别鸟类还是飞机的程序！我们将学习到如何写一个，通过深度学习来识别图像中物体的程序。换个角度来说，我们会解释Google Photos搜索图片和识图所用到的“黑科技”。&lt;/h2&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-cb2e19b132e05461a2c9d9c6276b45b5.jpg" data-rawwidth="800" data-rawheight="380"&gt;&lt;p&gt;&lt;i&gt;Google&lt;/i&gt;&lt;i&gt;现在可以让你在你自己的图片库里面，根据你的描述搜索图片，即使这些图片根本没有被标注任何标签。这是怎么做到的呢？&lt;/i&gt;&lt;/p&gt;&lt;p&gt;和第1 2章一样，这个指南是针对所有对机器学习感兴趣但不知从哪里学起的读者的。本文目标在于平易近人，这意味着文中有大量的概括。但是谁在乎这些呢？只要能让读者对于机器学习更感兴趣，任务也就完成了。&lt;/p&gt;&lt;p&gt;&lt;b&gt;通过深度学习识别物体&lt;/b&gt;&lt;/p&gt;&lt;p&gt;你可能曾经看过这个xkcd漫画。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-220fac60b09462813d82769a2fbd355e.png" data-rawwidth="267" data-rawheight="448"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-9a59cd58177b3ff4db241e32842c5418.png" data-rawwidth="267" data-rawheight="448"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;Xkcd&lt;/i&gt;&lt;i&gt;漫画编号1425&lt;/i&gt;&lt;/p&gt;&lt;p&gt;一个3岁的小孩可以识别出鸟类的照片，然而最顶尖的计算机科学家们已经花了50年时间，来研究如何让电脑识别出不同的问题。漫画里的灵感就是这么来的。&lt;/p&gt;&lt;p&gt;在最近的几年里，我们终于找到了一种通过&lt;b&gt;卷积神经网络（&lt;/b&gt;&lt;b&gt;Convolutional Neural Networks&lt;/b&gt;&lt;b&gt;）&lt;/b&gt;来进行物体识别的好方法。这些个词听起来就像是从威廉·吉布森的科幻小说编造出来的，但是如果你把这个想法逐步分解，你绝对可以理解它。&lt;/p&gt;&lt;p&gt;让我们开始吧，我们一起来写一个识别鸟类的程序。&lt;/p&gt;&lt;p&gt;&lt;b&gt;由浅入深&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在我们在识别鸟类之前，让我们先做个更简单的——识别手写的数字“8”&lt;/p&gt;&lt;p&gt;在第二章中我们了解到，神经网络是如何通过连接无数神经元来解决复杂问题的。我们创造了一个小型神经网络，然后根据各种因素（房屋面积，格局，地段等）来估计房屋的价格：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-1a41f01767489d0113fd22fcafe05f6c.png" data-rawwidth="800" data-rawheight="692"&gt;&lt;/p&gt;&lt;p&gt;在第一章中我们提到了，机器学习，就是关于重复使用同样的泛型算法，来处理不同的数据，解决不同的问题的一种概念。所以这次，我们稍微修改一下同样的神经网络来识别手写文字。但是为了更加简便，我们只会尝试去识别数字“8”。&lt;/p&gt;&lt;p&gt;机器学习只有在你拥有数据的情况下，最好是大量的数据，才能有效。所以，我们需要有大量的手写“8”来开始我们的尝试。幸运的是，恰好有研究人员创造出了“MNIST手写数字数据库”能助我们一臂之力。MNIST提供了60,000张手写数字的图片，每一张都是一个18×18的图片。下列是数据库中的一些例子：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-e74d31dace9cf20b50604c5f2ee84361.jpg" data-rawwidth="1000" data-rawheight="256"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;MNIST&lt;/i&gt;&lt;i&gt;数据库中的数字“8&lt;/i&gt;&lt;i&gt;”&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;万物皆“数”&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在第二章中我们创造的那个神经网络，它只能接受三个数字输入（卧室数，面积，地段），但是现在，我们需要用神经网络来处理图像。所以到底怎样才能把图片，而不是数字，输入到神经网络里呢？&lt;/p&gt;&lt;p&gt;结论其实极其简单。神经网络会把数字当成输入，而对于电脑来说，图片其实恰好就是一连串代表着每个像素颜色的数字：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-e9471074ffb5c85a14a2d6fe4270d6b2.jpg" data-rawwidth="581" data-rawheight="580"&gt;&lt;/p&gt;&lt;p&gt;我们把一副18×18像素的图片当成一串324个数字的数列，就可以把它输入到我们的神经网络里面了：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-edde5a5c71bedaf91a887e801fda38e6.png" data-rawwidth="1250" data-rawheight="194"&gt;&lt;/p&gt;&lt;p&gt;为了更好地操控我们的输入数据，我们把神经网络扩大到拥有324个输入节点：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-e3c4e4a1c5c2cb73f4ee88ec145046af.png" data-rawwidth="977" data-rawheight="556"&gt;&lt;/p&gt;&lt;p&gt;请注意，现在有两个输出了（而不仅仅是一个房子的价格）。第一个输出会预测图片是“8”的概率
而第二个则输出不是“8”的概率。概括地说，我们就可以依靠多种不同的输出，利用神经网络把要识别的物品进行分组。&lt;/p&gt;&lt;p&gt;虽然我们的神经网络要比上次大得多（这次是324，上一次是3！=6），但是现在的计算机一眨眼的功夫就能够对这几百个节点进行运算。当然，你的手机也可以做到。&lt;/p&gt;&lt;p&gt;现在唯一要做的就是训练我们的神经网络了。用各种“8”和非“8”的图片来训练，这样它就能学习怎么去区分了。当我们输入一个“8”的时候，我们会告诉他“是8的概率”是100%而“不是8的概率”是0%，反之亦然。&lt;/p&gt;&lt;p&gt;下面是一些训练数据：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-9905391699c9282bda9b0f423d2c8760.jpg" data-rawwidth="1125" data-rawheight="283"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;嗯…&lt;/i&gt;&lt;i&gt;就是这些训练数据…&lt;/i&gt;&lt;/p&gt;&lt;p&gt;我们能在我们笔记本电脑上面用几分钟的时间来训练这种神经网络。完成之后，我们就可以得到一个有着很高的“8”图片识别率的神经网络。欢迎来到（1980年代末的）图像识别的世界！&lt;/p&gt;&lt;p&gt;&lt;b&gt;短浅的目光&lt;/b&gt;&lt;/p&gt;&lt;p&gt;仅仅把像素输入到神经网络里，就可以做出图像的识别，这很棒！机器学习就像魔法一样！对不对！！&lt;/p&gt;&lt;p&gt;&lt;b&gt;呵呵，当然，不会，这么，简单，呵呵呵。（&lt;/b&gt;&lt;em&gt;Well, of course it’s not that simple.&lt;/em&gt;&lt;b&gt;感受作者的神之鄙视吧哈哈哈）&lt;/b&gt;&lt;/p&gt;&lt;p&gt;首先，好消息是，当我们的数字就在图片的正中间的时候，我们的识别器干得还不错。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-42ffc9d1983334d876162e5c8a95a9cd.png" data-rawwidth="1000" data-rawheight="141"&gt;&lt;/p&gt;&lt;p&gt;坏消息是:&lt;/p&gt;&lt;p&gt;当数字并不是正好在图片中央的时候，我们的识别器就完全不工作了。一点点的位移我们的识别器就掀桌子不干了(╯‵□′)╯︵┻━┻。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-3e4328e85f900c5a3563bb76f885eab1.png" data-rawwidth="1000" data-rawheight="143"&gt;&lt;/p&gt;&lt;p&gt;这是因为我们的网络只学习到了正中央的“8”。它并不知道那些偏离中心的“8”长什么样子。它仅仅知道中间是“8”的规律。&lt;/p&gt;&lt;p&gt;在真实世界中，这好像并没什么卵用。真实世界的问题永远不会如此轻松简单。所以，我们需要知道，怎么才能让我们的神经网络在非中心“8”的情况下识别。&lt;/p&gt;&lt;p&gt;&lt;b&gt;暴力算法(Brute
Force)&lt;/b&gt; 方法1：滑框搜索&lt;/p&gt;&lt;p&gt;我们已经创造出了一个能够很好地识别图片中间“8”的程序。如果我们干脆把整个图片分成一个个小部分，并挨个都识别一遍，直到我们找到“8”，这样能不能行呢？&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-37823f4f0781bc8f09ada71ecd419a6e.jpg" data-rawwidth="950" data-rawheight="405"&gt;&lt;/p&gt;&lt;p&gt;这个叫做
滑框(Sliding Window)法，是暴力算法之一。在有限的情况下，它能够识别的很好。但实际上它并不怎么有效率，你必须在同一张图片里面一遍一遍的识别不同大小的物体。实际上，我们可以做得更好。&lt;/p&gt;&lt;p&gt;&lt;b&gt;暴力算法 &lt;/b&gt;&lt;b&gt;方法2&lt;/b&gt;&lt;b&gt;：更多的数据与一个深度神经网&lt;/b&gt;&lt;/p&gt;&lt;p&gt;刚刚我们提到，经过训练之后，我们只能找出在中间的“8”。如果我们用更多的数据来训练，数据中包括各种不同位置和大小的“8”，会怎样呢？&lt;/p&gt;&lt;p&gt;我们并不需要收集更多的训练数据。实际上，我们可以写一个小脚本来生成各种各样不同位置“8”的新图片：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-b8116c8959576d759bc322dc0be758d7.png" data-rawwidth="1000" data-rawheight="498"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;通过组合不同版本的训练图片，我们创造出了“合成训练数据(Synthetic Training Data)&lt;/i&gt;&lt;i&gt;”。这是一种非常实用的技巧！&lt;/i&gt;&lt;/p&gt;&lt;p&gt;使用这种方法，我们能够轻易地创造出无限量的训练数据。&lt;/p&gt;&lt;p&gt;更多的数据让我们的神经网络更难解决这个问题。但是把神经网络扩大，它就能寻找到更复杂的规律了，以此来弥补解决困难问题的不足。&lt;/p&gt;&lt;p&gt;要扩大我们的网络，我们首先要把把节点一层一层的堆积起来：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-6223ba897029b706a1f942f6c5570fcc.png" data-rawwidth="1000" data-rawheight="245"&gt;&lt;/p&gt;&lt;p&gt;因为它比传统的神经网络层数更多，所以我们把它称作“&lt;b&gt;深度神经网络&lt;/b&gt;&lt;b&gt;(Deep Neural Network)&lt;/b&gt;”。&lt;/p&gt;&lt;p&gt;这个想法在1960年代末就出现了，但直至今日，训练这样一个大型神经网络也是一件不切实际的缓慢的事情。然而，一旦我们知道了如何使用3D显卡（最开始是用来进行快速矩阵乘法运算）来替代普通的电脑处理器，使用大型神经网络的想法就立刻变得可行了。实际上，你用来玩守望先锋的NVIDIA GeForce GTX1080这款显卡，就可以极快速的训练我们的神经网络。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-504a3dfab013dceef59bd48ff3228545.png" data-rawwidth="500" data-rawheight="279"&gt;&lt;/p&gt;&lt;p&gt;但是尽管我们能把我们的神经网络扩张的特别大并使用3D显卡快速训练它，这依然不能让我们一次性得到结论。我们需要更智能的将图片处理后，放入到神经网络里。&lt;/p&gt;&lt;p&gt;仔细想想，如果把图片最上方和最下方的“8”当成两个不同的对象来处理，并写两个不同的网络来识别它们，这件事实在是说不通。&lt;/p&gt;&lt;p&gt;应该有某种方法，使得我们的神经网络，在没有额外的训练数据的基础上，能够非常智能的识别出图片上任何位置的“8”，都是一样是“8”。幸运的是…这就是！&lt;/p&gt;&lt;p&gt;&lt;b&gt;卷积性的解决办法&lt;/b&gt;&lt;/p&gt;&lt;p&gt;作为人类，你能够直观的感知到图片中存在某种&lt;b&gt;层级&lt;/b&gt;&lt;b&gt;(Hierarchy)&lt;/b&gt;或者是&lt;b&gt;概念结构&lt;/b&gt;&lt;b&gt;(Conceptual structure).&lt;/b&gt;参考下面的这个图片：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-918467a4f935da447600dfc43d96c016.jpg" data-rawwidth="1000" data-rawheight="666"&gt;&lt;/p&gt;&lt;p&gt;作为人类，你立刻就能识别出这个图片的层级：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;地面是由草和水泥组成的&lt;/li&gt;&lt;li&gt;有一个小孩在图片中&lt;/li&gt;&lt;li&gt;小孩在骑弹簧木马&lt;/li&gt;&lt;li&gt;弹簧木马在草地上&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;最重要的是，我们识别出了“小孩儿”，无论这个小孩所处的环境是怎样的。当每一次出现不同的环境时，我们人类不需要重新学习“小孩儿”这个概念。&lt;/p&gt;&lt;p&gt;但是现在，我们的神经网络做不到这些。他认为“8”出现在图片的不同位置，就是不一样的东西。它不能理解“物体出现在图片的不同位置还是同一个物体”这个概念。这意味着在每种可能出现的位置上，它必须重新学习识别各种物体。这弱爆了。&lt;/p&gt;&lt;p&gt;我们需要让我们的神经网络理解“平移不变性(Translation invariance)”这个概念——也就是说，“8”无论出现在图片的哪里，它都是“8”。&lt;/p&gt;&lt;p&gt;我们会通过一个叫做卷积(Convolution)的方法来达成这个目标。卷积的灵感是由计算机科学和生物学共同激发的。（有一些疯狂的生物学家，它们用奇怪的针头去戳猫的大脑，来观察猫是怎样处理图像的。 &amp;gt;_&amp;lt;）&lt;/p&gt;&lt;p&gt;&lt;b&gt;卷积是如何工作的&lt;/b&gt;&lt;/p&gt;&lt;p&gt;之前我们提到过，可以把一整张图片当做一串数字输入到神经网络里面。不同的是，这次我们会利用“位移物相同”（译者注：也就是平移不变性）的概念来把这件事做得更智能。&lt;/p&gt;&lt;p&gt;下面就是，它怎样工作的，分步解释——&lt;/p&gt;&lt;p&gt;&lt;b&gt;第一步：把图片分解成部分重合的小图块&lt;/b&gt;&lt;/p&gt;&lt;p&gt;和上述的滑框搜索类似的，我们把滑框在整个图片上滑过，并存储下每一个框里面的小图块：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-5de5f941cc23c28b570d2adfe54b9d05.png" data-rawwidth="1000" data-rawheight="633"&gt;&lt;/p&gt;&lt;p&gt;这么做之后，我们把图片分解成了77块同样大小的小图块。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第二步：把每个小图块输入到小型神经网络中&lt;/b&gt;&lt;/p&gt;&lt;p&gt;之前，我们把一张图片输入到神经网络中来看这张图片是不是一个“8”。这一次我们还做同样的事情，只不过我们输入的是一个个小图块：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-6760f478f3c54659e2c122351b71c475.png" data-rawwidth="758" data-rawheight="274"&gt;&lt;/p&gt;&lt;p&gt;然而，&lt;b&gt;有一个非常重要的不同&lt;/b&gt;：对于每个小图块，我们会&lt;b&gt;使用同样的神经网络权重&lt;/b&gt;。换一句话来说，我们同样对待每一个小图块。如果哪个小图块有任何异常出现，我们就认为这个图块是“异常(Interesting)”的&lt;/p&gt;&lt;p&gt;&lt;b&gt;第三步：把每一个小图块的结果都保存到一个新的数列当中&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们不想并不想打乱小图块的顺序。所以，我们把每个小图片按照图片上的顺序输入并保存结果，就像这样：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-3261c1e1ac226d7afca1767f4bc50df2.png" data-rawwidth="893" data-rawheight="729"&gt;&lt;/p&gt;&lt;p&gt;换一句话来说，我们从一整张图片开始，最后得到一个稍小一点的数列，里面存储着我们图片中的哪一部分有异常。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第四步：缩减像素采样&lt;/b&gt;&lt;/p&gt;&lt;p&gt;第三步的结论是一个数列，这个数列对应着原始图片中哪一部分最异常。但是这个数列依然很大:&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-b65fe37e7aa4743165fb9fca59fff382.png" data-rawwidth="1000" data-rawheight="363"&gt;&lt;/p&gt;&lt;p&gt;为了减小这个数列的大小，我们利用一种叫做最大池化(Max Pooling)的方法来降低采样(Downsample)。它听起来很棒，但这仍旧不够！&lt;/p&gt;&lt;p&gt;让我们先来看每个2×2的方阵数列，并且留住最大的数：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-717d3b1ba75820ab224a38a081476d1e.png" data-rawwidth="887" data-rawheight="370"&gt;&lt;/p&gt;&lt;p&gt;这里，一旦我们找到组成2×2方阵的4个输入中任何异常的部分，我们就只保留这一个数。这样一来就缩减了我们的数列大小，并且保留住了最重要的部分。&lt;/p&gt;&lt;p&gt;&lt;b&gt;最后一步：作出预测&lt;/b&gt;&lt;/p&gt;&lt;p&gt;到现在为止，我们已经把一个很大的图片，缩减到了一个相对较小的数列。&lt;/p&gt;&lt;p&gt;你猜怎么着？数列就是一序列数而已，所以我们我们可以把这个数列输入到另外一个神经网络里面去。最后的这个神经网络会决定这个图片是否匹配。为了区分它和卷积的不同，我们把它称作“完全连接”网络（”Fully Connected” Network）&lt;/p&gt;&lt;p&gt;所以从开始到结束，我们的五步就像管道一样连接起来：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-bb5042915cf0fa1964ff1a7ea4f8d221.png" data-rawwidth="1000" data-rawheight="294"&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;添加更多步骤&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们的图片处理管道是一系列的步骤：卷积，最大池化，还有最后的“完全连接”网络。&lt;/p&gt;&lt;p&gt;你可以把这些步骤组合、堆叠任意多次，来解决真实世界的问题。你可以有2层，3层或者10层卷积层。当你想要缩小你的数据大小的时候，你也随时可以调用最大池化函数。&lt;/p&gt;&lt;p&gt;我们解决问题的基本方法，就是从一整个图片开始，一步一步逐渐的分解它，直到你找到了一个单一的结论。你的卷积层越多，你的网络就越能识别出复杂的特征。&lt;/p&gt;&lt;p&gt;比如说，第一个卷积的步骤可能就是尝试去识别尖锐的东西，而第二个卷积步骤则是通过找到的尖锐物体来找鸟类的喙，最后一步是通过鸟喙来识别整只鸟，以此类推。&lt;/p&gt;&lt;p&gt;下面是一个更实际的深层卷积网络的样子（就是你们能在研究报告里面找到的那种例子一样）：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-541ab8e45aa01936406d5631abff0654.png" data-rawwidth="1000" data-rawheight="303"&gt;&lt;/p&gt;&lt;p&gt;这里，他们从一个224×224像素的图片开始，使用了卷积和最大池化两次，再使用3次卷积，最大池化一次，最后在使用两个完全连接层。最终的结果是这个图片能被分类到1000种不同类别当中的某一种！&lt;/p&gt;&lt;p&gt;&lt;b&gt;建造正确的网络&lt;/b&gt;&lt;/p&gt;&lt;p&gt;所以，你是怎么知道我们需要结合哪些步骤来让我们的图片分类器工作呢？&lt;/p&gt;&lt;p&gt;说句良心话，你必须做许多的实验和检测才能回答这个问题。在为你要解决的问题找到完美的结构和参数之前，你可能需要训练100个网络。机器学习包含了许多的尝试和错误！&lt;/p&gt;&lt;p&gt;&lt;b&gt;建立我们的鸟类分类器&lt;/b&gt;&lt;/p&gt;&lt;p&gt;现在我们已经做够了准备，我们已经可以写一个小程序来判定一个图片是不是一只鸟了。&lt;/p&gt;&lt;p&gt;诚然，我们需要数据来开始。CIFAR10数据库免费提供了6000张鸟类的图片和52000张非鸟类的图片。但是为了获取更多的数据，我们仍需添加Caltech-UCSD Birds-200-2011数据库，这里面包括了另外的12000张鸟类的图片。&lt;/p&gt;&lt;p&gt;这是我们整合后的数据库里面的一些鸟类的图片：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-ca1b3ab3fabad3f85d3c3ca61b9d9222.png" data-rawwidth="1250" data-rawheight="312"&gt;&lt;/p&gt;&lt;p&gt;这是数据库里一些非鸟类图片：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-4cd38a02c717c28cb542148bb1dbf22b.png" data-rawwidth="1250" data-rawheight="312"&gt;&lt;/p&gt;&lt;p&gt;这些数据对于我们这篇文章解释说明的目的来说已经够了，但是对于真实世界的问题来说，72000张低分辨率的图片还是太少了。如果你想要达到Google这种等级的表现的话，你需要上百万张高清无码大图。&lt;b&gt;在机器学习这个领域中，有更多的数据总比一个更好的算法更重要！&lt;/b&gt;现在你知道为什么谷歌总是乐于给你提供无限量免费图片存储了吧？
他们，需要，你的，数据！！&lt;/p&gt;&lt;p&gt;为了简历我们的分类器，我们将会使用TFLearn。TFLearn是Google TensorFlow的一个封装，Google TensorFlow包含了一个拥有简单API的深度学习库。使用它来定义我们网络的层级，建立卷积网络的过程和写几行代码一样简单。&lt;/p&gt;&lt;p&gt;下面是定义并训练我们网络的代码：&lt;/p&gt;&lt;pre&gt;&lt;code lang="python"&gt;# -*- coding: utf-8 -*-

"""
Based on the tflearn example located here:
https://github.com/tflearn/tflearn/blob/master/examples/images/convnet_cifar10.py
"""
from __future__ import division, print_function, absolute_import

# Import tflearn and some helpers
import tflearn
from tflearn.data_utils import shuffle
from tflearn.layers.core import input_data, dropout, fully_connected
from tflearn.layers.conv import conv_2d, max_pool_2d
from tflearn.layers.estimator import regression
from tflearn.data_preprocessing import ImagePreprocessing
from tflearn.data_augmentation import ImageAugmentation
import pickle

# Load the data set
X, Y, X_test, Y_test = pickle.load(open("full_dataset.pkl", "rb"))

# Shuffle the data
X, Y = shuffle(X, Y)

# Make sure the data is normalized
img_prep = ImagePreprocessing()
img_prep.add_featurewise_zero_center()
img_prep.add_featurewise_stdnorm()

# Create extra synthetic training data by flipping, rotating and blurring the
# images on our data set.
img_aug = ImageAugmentation()
img_aug.add_random_flip_leftright()
img_aug.add_random_rotation(max_angle=25.)
img_aug.add_random_blur(sigma_max=3.)

# Define our network architecture:

# Input is a 32x32 image with 3 color channels (red, green and blue)
network = input_data(shape=[None, 32, 32, 3],
                     data_preprocessing=img_prep,
                     data_augmentation=img_aug)

# Step 1: Convolution
network = conv_2d(network, 32, 3, activation='relu')

# Step 2: Max pooling
network = max_pool_2d(network, 2)

# Step 3: Convolution again
network = conv_2d(network, 64, 3, activation='relu')

# Step 4: Convolution yet again
network = conv_2d(network, 64, 3, activation='relu')

# Step 5: Max pooling again
network = max_pool_2d(network, 2)

# Step 6: Fully-connected 512 node neural network
network = fully_connected(network, 512, activation='relu')

# Step 7: Dropout - throw away some data randomly during training to prevent over-fitting
network = dropout(network, 0.5)

# Step 8: Fully-connected neural network with two outputs (0=isn't a bird, 1=is a bird) to make the final prediction
network = fully_connected(network, 2, activation='softmax')

# Tell tflearn how we want to train the network
network = regression(network, optimizer='adam',
                     loss='categorical_crossentropy',
                     learning_rate=0.001)

# Wrap the network in a model object
model = tflearn.DNN(network, tensorboard_verbose=0, checkpoint_path='bird-classifier.tfl.ckpt')

# Train it! We'll do 100 training passes and monitor it as it goes.
model.fit(X, Y, n_epoch=100, shuffle=True, validation_set=(X_test, Y_test),
          show_metric=True, batch_size=96,
          snapshot_epoch=True,
          run_id='bird-classifier')

# Save model when training is complete to a file
model.save("bird-classifier.tfl")
print("Network trained and saved as bird-classifier.tfl!")
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;如果你使用一款非常好的有着足够RAM的游戏显卡（比如说Nvidia GeForce GTX980 Ti）来训练的话，训练一个小时以内就能结束，但是如果你用一般的cpu来训练的话，他可能需要更长的时间。&lt;/p&gt;&lt;p&gt;随着训练的进行，准确度也会增加。在第一遍训练之后，它的准确度是75.4%。10次训练之后，就上升到了91.7%。当训练了至少50次的时候，它的准确率达到了95.5%。继续训练并没有增加他的准确度，所以我停止了。&lt;/p&gt;&lt;p&gt;恭喜！！我们的程序现在能识别鸟类的图片了！&lt;/p&gt;&lt;p&gt;&lt;b&gt;测试我们的网络&lt;/b&gt;&lt;/p&gt;&lt;p&gt;现在我们拥有了一个训练过的神经网络，我们可以开始使用它了！这儿有一个&lt;a href="https://gist.github.com/ageitgey/a40dded08e82e59724c70da23786bbf0" data-editable="true" data-title="简单的脚本"&gt;简单的脚本&lt;/a&gt;，通过接收一个图片来预测他是否是鸟类。&lt;/p&gt;&lt;p&gt;但是为了真正检测我们的神经网络有多有效果，我们需要进行大量的图片测试。我创造的那个数据库里面有15000张用来验证的图片。当我把这15000张图片放到程序里运行的时候，它的预测准确率达到了95%。&lt;/p&gt;&lt;p&gt;看起来还不错，对吧？额…这事儿吧还得辩证的看…&lt;/p&gt;&lt;p&gt;&lt;b&gt;95%&lt;/b&gt;&lt;b&gt;准确是有多准确？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们的网络声称有95%准确。但是细节决定成败(devil is in the detail)，这意味着各种各样问题可能产生。&lt;/p&gt;&lt;p&gt;比如说，如果我们的训练数据有5%是鸟类而剩下95%不是呢？一个程序即使每次都猜“不是鸟”也能达到95%的准确率。这也就意味着这个程序并没有什么作用。&lt;/p&gt;&lt;p&gt;相比于准确度，我们必须更多的关注在数字本身。为了判别一个分类系统有多好，我们需要知道它是怎样出错误的，而不是仅仅关注它错了多少次。&lt;/p&gt;&lt;p&gt;与其只考虑我们预测的对与错，不如把我们的程序分解成四个不同的类别——&lt;/p&gt;&lt;p&gt;首先，对于那些被我们的网络正确辨认为鸟类而且确实是鸟类的，我们叫他们“真正类(True Positives)”&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-d019bbe49a114b8c3f008e9e44642544.png" data-rawwidth="1250" data-rawheight="125"&gt;&lt;/p&gt;&lt;p&gt;第二，被辨认为非鸟类，而且确实是非鸟类的，我们叫“真负类(True Negatives)”&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-5ea61ab8883450df660660ec619f0f7a.png" data-rawwidth="1250" data-rawheight="125"&gt;&lt;/p&gt;&lt;p&gt;第三，被辨认为鸟类，但却是非鸟类的，我们叫“假正类(False Positives)”&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-b61d613f4aed8315410a3f7a0d3a9b3a.png" data-rawwidth="1250" data-rawheight="125"&gt;&lt;/p&gt;&lt;p&gt;第四，被辨认为非鸟类，但却是鸟类的，我们叫“假负类(False Negatives)”&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-866b9c9d43abcf24fe81eef0ccd9318b.png" data-rawwidth="1250" data-rawheight="125"&gt;&lt;/p&gt;&lt;p&gt;下面的数据是使用那15000张验证图片，在每种类别中我们猜测的数量：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-b9367d23b00f75ddc7e416e6f5a83323.png" data-rawwidth="1000" data-rawheight="350"&gt;&lt;/p&gt;&lt;p&gt;为什么我们要把结果做上述分类呢？因为并不是每一个错误产生的几率都是一样的。&lt;/p&gt;&lt;p&gt;设想如果我们写一个通过MRI图像来探测癌症的程序。如果我们探测到了癌症，我们更希望它是“假正类”而不是“假负类”。因为假负类是最可怕的情况——那就是你的程序告诉你，你绝对没有病，但实际上你已经病入膏肓了。&lt;/p&gt;&lt;p&gt;我们需要计算准确和召回指标(Precision and Recall metrics)而并不仅仅关注总体的准确度。准确和召回指标给了我们程序表现的一个清晰的反馈：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-93536c7f034afbacde2aff551544a3ed.png" data-rawwidth="1000" data-rawheight="168"&gt;&lt;/p&gt;&lt;p&gt;这告诉我们，当我们猜“鸟类”的时候，97%的时候是正确的。但是这同时也告诉我们说，我们只找到了真实鸟类里面的90%。换句话说，我们可能不会找到每一只鸟，但是当我们找到一只鸟的时候，我们很确定它就是一只鸟！&lt;/p&gt;&lt;p&gt;&lt;b&gt;路还在远方…&lt;/b&gt;&lt;/p&gt;&lt;p&gt;现在你知道了一些关于深度卷积网络的基本概念了，你可以用TFLearn尝试一下&lt;a href="https://github.com/tflearn/tflearn/tree/master/examples#tflearn-examples" data-editable="true" data-title="各种结构的神经网络的例子"&gt;各种结构的神经网络的例子&lt;/a&gt;。它甚至包括了自带的数据，你根本不用自己去收集图片。&lt;/p&gt;&lt;p&gt;你同时也知道了如何开始创造分支或是学习机器学习的其他领域。接下来为什么不尝试着去学习如何用算法来&lt;a href="http://karpathy.github.io/2016/05/31/rl/" data-editable="true" data-title="训练我们的电脑玩Atari 游戏"&gt;训练我们的电脑玩Atari 游戏&lt;/a&gt;呢？&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/24524583&amp;pixel&amp;useReferer"/&gt;</description><author>九五要当学霸</author><pubDate>Fri, 23 Dec 2016 13:14:52 GMT</pubDate></item><item><title>【巡洋舰首发】有趣的机器学习第二章：用机器学习【制作超级马里奥】的关卡</title><link>https://zhuanlan.zhihu.com/p/24344720</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-2b8995376574c6537b5c668ed251bdca_r.jpg"&gt;&lt;/p&gt;&lt;p&gt;原文：Adam Geitgey&lt;/p&gt;&lt;p&gt;原文链接：&lt;a href="https://medium.com/@ageitgey/machine-learning-is-fun-part-2-a26a10b68df3#.s43q4kh6d" class="" data-editable="true" data-title="medium.com 的页面"&gt;https://medium.com/@ageitgey/machine-learning-is-fun-part-2-a26a10b68df3#.s43q4kh6d&lt;/a&gt;&lt;/p&gt;&lt;p&gt;翻译：巡洋舰科技——赵95&lt;/p&gt;&lt;p&gt;有趣的机器学习 前六章已更新！点此查看&lt;a href="https://zhuanlan.zhihu.com/p/24339995" class="" data-editable="true" data-title="第一章：最简明入门指南"&gt;第一章：最简明入门指南&lt;/a&gt;、&lt;a href="https://zhuanlan.zhihu.com/p/24344720" class="" data-editable="true" data-title="第二章：用机器学习制造【超级马里奥】的关卡"&gt;第二章：用机器学习【制造超级马里奥】的关卡&lt;/a&gt;、&lt;a href="https://zhuanlan.zhihu.com/p/24524583" class="" data-editable="true" data-title="第三章：图像识别【鸟or飞机】"&gt;第三章：图像识别【鸟or飞机】&lt;/a&gt;&lt;a href="https://zhuanlan.zhihu.com/p/24567586" class="" data-editable="true" data-title="第四章：用深度进行【人脸识别】"&gt;第四章：用深度进行【人脸识别】&lt;/a&gt;&lt;a href="https://zhuanlan.zhihu.com/p/24590838" class="" data-editable="true" data-title="第五章：使用深度学习进行【语言翻译】和 序列的魔力"&gt;第五章：使用深度学习进行【语言翻译】和 序列的魔力&lt;/a&gt;&lt;a href="https://zhuanlan.zhihu.com/p/24703268" data-title="第六章：如何用深度学习进行【语音识别】" class="" data-editable="true"&gt;第六章：如何用深度学习进行【语音识别】&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;在开始之前，先来看看机器学习制作的关卡成果吧~&lt;/h2&gt;&lt;video id="77165" data-swfurl="" poster="" data-sourceurl="http://v.youku.com/v_show/id_XMTg2NTg1MTk5Ng==.html?spm=a2hzp.8253869.0.0&amp;amp;amp;amp;from=y1.7-2" data-name="有趣的机器学习 第二章：用机器学习制作超级马里奥的关卡—在线播放—优酷网，视频高清在线观看"&gt;&lt;/video&gt;&lt;p&gt;在第一章中我们谈到了，即使不用编写具体的程序，我们也能用机器学习的泛型算法告诉你一些有趣的结论。&lt;/p&gt;&lt;p&gt;这一次，我们要来用泛型算法之一来做一件很酷炫的事情。创造一个看起来像是人类设计的电子游戏关卡！我们会构造一个神经网络，并提供给它已存在的超级马里奥的关卡设计，然后就可以等它自己创造出新的关卡了！&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-0a4ae56dfcd98cc64154ef16e6e09276.jpg" data-rawwidth="600" data-rawheight="337"&gt;&lt;p&gt;&lt;i&gt;使用这种泛型算法可以创造出来关卡之一&lt;/i&gt;&lt;/p&gt;&lt;p&gt;和第一章类似的是，这份指南是针对所有对机器学习感兴趣但不知从哪里学起的读者的。本文目标在于平易近人，这意味着文中有大量的概括。但是谁在乎这些呢？只要能让读者对于机器学习更感兴趣，我的任务也就完成了。&lt;/p&gt;&lt;p&gt;&lt;b&gt;做出更智能更准确的预测&lt;/b&gt;&lt;/p&gt;&lt;p&gt;回到第一章，我们根据房屋各种特征属性创造了一个来估计房屋价格的简单算法。我们给出了一所房子的如下数据：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-b7337731932718c8c05f9f461a7b0f31.png" data-rawwidth="800" data-rawheight="150"&gt;&lt;p&gt;我们得到了这个简单的预估函数：&lt;/p&gt;&lt;pre&gt;&lt;code lang="python"&gt;def estimate_house_sales_price(num_of_bedrooms, sqft, neighborhood):
 price = 0
# a little pinch of this
 price += num_of_bedrooms * 0.123
# and a big pinch of that
 price += sqft * 0.41
# maybe a handful of this
 price += neighborhood * 0.57
return price
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;换一个角度来说，我们把决定房屋价格的因素乘以它的&lt;b&gt;权重&lt;/b&gt;，再把这些乘积求和，就可以得到房子的预估价格了。&lt;/p&gt;&lt;p&gt;或者不使用代码，我们直接用一个图片来概括这个函数：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-777a49815c5a643ba8fb0d1fe39fe873.png" data-rawwidth="883" data-rawheight="589"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;箭头表示了函数中的权重&lt;/i&gt;&lt;/p&gt;&lt;p&gt;然而，这个算法仅仅能用于处理一些简单的问题，就是那些输入和输出有着&lt;b&gt;线性关系（&lt;/b&gt;&lt;b&gt;Linear Relationship&lt;/b&gt;&lt;b&gt;）&lt;/b&gt;的问题。但如果真实价格和决定因素的关系并不是如此简单，那我们该怎么办？ 比如说，地段对于大户型和小户型的房屋有很大影响，然而对中等户型的房屋并没有太大影响。那我们该怎么在我们的模型中收集这种复杂的信息呢？&lt;/p&gt;&lt;p&gt;所以为了更加的智能化，我们可以利用不同的权重来多次运行这个算法，收集各种不同情况下的价格估计。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-383139fb2b9737064866fef83b904b06.png" data-rawwidth="1000" data-rawheight="812"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;我们来尝试用&lt;/i&gt;&lt;i&gt;4&lt;/i&gt;&lt;i&gt;中不同的算法来解决该问题&lt;/i&gt;&lt;/p&gt;&lt;p&gt;现在，我们有了4种不同的价格估计。我们将这4种价格估计汇总到一个最终估计当中。我们再把们放到同样的算法当中再算一遍（当然这次我们使用的权重不同）。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-cedaedbe05067c45c4752940a032b257.png" data-rawwidth="777" data-rawheight="725"&gt;&lt;/p&gt;&lt;p&gt;我们现在就结合了解决同一问题的方法4种不同方法，得到的一个“&lt;b&gt;超级答案&lt;/b&gt;”。正是由于此，我们才能够用它来模拟更多不同的情况。&lt;/p&gt;&lt;p&gt;&lt;b&gt;神经网络是什么？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们来把4种不同的预测方法概括到一个图当中：&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-7196900d3c4537240c98b127acfa80c0.png" data-rawwidth="895" data-rawheight="775"&gt;这就是一张神经网络！每一个节点都知道如何收集一组收据，找到他们的权重，做出对应的输出值（价格预测）。把这些节点连接到一起，我们就可以模拟更复杂的函数了！&lt;/p&gt;&lt;p&gt;当然了，为了保持简洁性，我跳过了许多内容（例如数据规范化Feature Scaling和激活函数Activation Function）。但是最重要的是下面的这些内容：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;我们制造了一个 &lt;b&gt;权重&lt;/b&gt;&lt;b&gt;*&lt;/b&gt;&lt;b&gt;因素&lt;/b&gt;简单算法，我们把这个算法叫做神经元。&lt;/li&gt;&lt;li&gt;通关连接神经元，我们能模拟那些不能被一个简单神经元所模拟的函数。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这就好像乐高积木一样！ 我们不能用一个乐高积木搭成摩天大楼，但是如果有足够多的乐高积木的话，我们能够搭建成任何东西。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-9c2f64e007b92e528190df5afb707e02.png" data-rawwidth="623" data-rawheight="267"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;也许未来的动物都是由积木搭成的？ &lt;/i&gt;&lt;i&gt;那只能去未来一探究竟了…&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;让我们的神经网络拥有记忆的能力&lt;/b&gt;&lt;/p&gt;&lt;p&gt;如果输入相同的数据，我们刚刚看到的那个神经网络总是有着一样的输出。这是因为他没有记忆能力。用编程的语言来说，他是一个&lt;b&gt;无状态算法（&lt;/b&gt;&lt;b&gt;Stateless Algorithms&lt;/b&gt;&lt;b&gt;）。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在许多情况下（例如说预估房子价格），这正是你所需要的算法。但是随着时间的增加，这种算法无法在数据中找出规律。（译者注：因为没有记忆能力）。&lt;/p&gt;&lt;p&gt;假设我现在让你在电脑上写一个故事。在你开始之前，我需要猜测你最先敲击键盘上的哪个字母。我应该猜哪个呢？&lt;/p&gt;&lt;p&gt;我可以使用我的语言（英语）知识来增加我猜对的概率。比如说，你可能会先打单词常见的第一个字母。如果我查看一下你过去写过的故事，我能够根据你过去的用词选择来缩小我猜测的范围。一旦我拥有这些数据，我能够用他们来构建一个神经网络，并能计算出你用任意一个字母来开头的概率。&lt;/p&gt;&lt;p&gt;我们的模型就像这样：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-65c65ff3af1b7a2dcc06c3fe97dd32ec.png" data-rawwidth="860" data-rawheight="241"&gt;&lt;/p&gt;&lt;p&gt;让我们把这个问题变得更难。现在我们假设在整个故事当中的任何一个点，我们要猜测你要敲击的第下一个字母是什么。这是一个更有趣的问题。&lt;/p&gt;&lt;p&gt;让我们把海明威的著作“太阳照常升起”的前几个单词当成一个例子：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;i&gt;&lt;b&gt;“Robert Cohn was once middleweight boxi”&lt;/b&gt;&lt;/i&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;所以，下一个字母是什么？&lt;/p&gt;&lt;p&gt;你可能会猜是“n”，这个词有可能是“boxing”。我们是通过观察还有语言常识来猜测这个词的。同时，“middleweight”这个词也给了我们猜测的额外线索。&lt;/p&gt;&lt;p&gt;换一个角度来说，如果我们知道了在这之前出现的字母并和我们的语言常识相结合，我们对下一个字母的猜测就会变得更加简单。&lt;/p&gt;&lt;p&gt;为了用神经网络的方法来解决这个问题，我们需要把&lt;b&gt;状态（&lt;/b&gt;&lt;b&gt;state&lt;/b&gt;&lt;b&gt;）&lt;/b&gt;加入到我们的模型当中。每次通过神经网络来解决问题的时候，我们将中间的计算结果也保存下来，并作为下次的输入的一部分再次使用。这样一来，我们的模型就能根据以往的输入数据来调整他的猜测。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-f7810f283373bc053447811c0b183760.png" data-rawwidth="860" data-rawheight="458"&gt;&lt;/p&gt;&lt;p&gt;跟踪模型中的每一个状态（state），不仅能够让我们更好预测第一个字母，更能让我们更好的预测到任意位置的下一个字母。&lt;/p&gt;&lt;p&gt;这就是一个关于&lt;b&gt;“循环神经网络”（&lt;/b&gt;&lt;b&gt;Recurrent Neural Network，简称RNN&lt;/b&gt;&lt;b&gt;）&lt;/b&gt;的基本概念。我们每次使用神经网络的时候都会对他进行升级。这使得让它能跟根据最近浏览的信息更新它的预测。如果数据记忆足够大的话，他甚至能够模拟出长期的规律。&lt;/p&gt;&lt;p&gt;&lt;b&gt;猜字母有什么意义？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;猜下一个字母看上去并没有什么卵用。这么做的意义是什么呢？&lt;/p&gt;&lt;p&gt;根据你的输入，自动预测你想输入的单词，就是一个比较酷炫的应用。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-9ca77fca470312f1f6f4a4b8dfa37b7c.png" data-rawwidth="1000" data-rawheight="562"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;下一个最有可能的字母是“t”&lt;/i&gt;&lt;/p&gt;&lt;p&gt;但是如果我们最大程度的拓展我们的概念会怎样？如果我们让我们的模型一直去预测下一个字母，永远不停止，那会怎样？ 会不会机器自己写出一个完整的故事？&lt;/p&gt;&lt;p&gt;&lt;b&gt;生成一个故事&lt;/b&gt;&lt;/p&gt;&lt;p&gt;刚刚我们看到了如何猜测海明威的“太阳照常升起”中的下一个字母的。现在让我们来试一试写一个海明威式（写作风格）的故事吧！&lt;/p&gt;&lt;p&gt;我们会通过“Andrej Karpathy”写到的&lt;b&gt;“循环神经网络实现”（&lt;/b&gt;&lt;b&gt;Recurrent Neural Network implementation&lt;/b&gt;&lt;b&gt;）&lt;/b&gt;来达成我们的目标。Adrej是斯坦福的一位深度学习研究者。他写过一篇非常棒的关于 “通过RNNs来进行创作”的指南。&lt;a href="goog_903441770" data-editable="true" data-title="你可以在"&gt;你可以在&lt;/a&gt;&lt;a href="https://github.com/karpathy/char-rnn" data-editable="true" data-title="GitHub上来查看这个指南。"&gt;GitHub上来查看这个指南。&lt;/a&gt;&lt;/p&gt;&lt;p&gt;我们会用这本“太阳照常升起”，来创造我们的模型。这本书里包括362,239个字，一共是84个不同的字母（包括标点符号和大小写字母等）。相对于真实世界的问题来说，这组数据其实已经非常小了。为了尽可能好的创作出类似于海明威的风格，我们可能会需要比这本小说内容多出数倍的样例文本。但是这本“太阳照常升起”已经足够展示制作我们模型的过程了。&lt;/p&gt;&lt;p&gt;当我们刚开始训练RNN的时候，他猜测的并不准确。这是它经过100个循环训练之后的结果：&lt;/p&gt;&lt;p&gt;&lt;i&gt;hjCTCnhoofeoxelif edElobe negnk e iohehasenoldndAmdaI ayio pe e h’e btentmuhgehi bcgdltt. gey heho grpiahe.&lt;/i&gt;&lt;i&gt;Ddelnss.eelaishaner” cot AAfhB ht ltnyehbih a”on bhnte ectrsnae abeahngyamo k ns aeo?cdse nh a taei.rairrhelardr er deffijha&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;（译者注：上面这些只是一堆字母而已 并拼不成任何单词）&lt;/i&gt;&lt;/p&gt;&lt;p&gt;你可以看到的是机器已经知道单词之间应该有空格，这正是我们想要的。&lt;/p&gt;&lt;p&gt;1000个循环之后：&lt;/p&gt;&lt;p&gt;&lt;i&gt;hing soor ither. And the caraos, and the crowebel for figttier and ale the room of me? Streat was not to him Bill-stook of the momansbed mig out ust on the bull, out here. I been soms&lt;/i&gt;&lt;i&gt;inick stalling that aid.“Hon’t me and acrained on .Hw’s don’t you for the roed,” In’s pair.”“Alough marith him.”&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;（译者注：一半儿还只是字母，另一半被拼成了有实际含义的单词，但意思并不通顺）&lt;/i&gt;&lt;/p&gt;&lt;p&gt;我们的模型已经开始识别出句子的基本构成模式了。他已经学会给句子加上句号，甚至学会了用引号。还成功的拼出了一些单词，但依然大部分都在胡扯。&lt;/p&gt;&lt;p&gt;经过几千次交互训练之后，他看起来很棒：&lt;/p&gt;&lt;p&gt;&lt;i&gt;He went over to the gate of the café. It was like a country bed.&lt;/i&gt;&lt;i&gt;“Do you know it’s been me.”“Damned us,” Bill said.“I was dangerous,” I said. “You were she did it and think I would a fine cape you,” I said.“I can’t look strange in the cab.”“You know I was this is though,” Brett said.“It’s a fights no matter?”“It makes to do it.”“You make it?”“Sit down,” I said. “I wish I wasn’t do a little with the man.”“You found it.”“I don’t know.”“You see, I’m sorry of chatches,” Bill said. “You think it’s a friend off back and make you really drunk.”&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;（译者注：翻译一下上面的这段话&lt;/i&gt;&lt;i&gt;虽然词语都正确了&lt;/i&gt;&lt;i&gt;但是句子根本不通顺：&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;他跑到了咖啡厅的门口。它像是一个乡下的床一样。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;“你知道那是我。”&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;“诅咒我们”比尔说。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;“我曾经很危险，”我说“你是她做了它并且认为我会一个好的海角你”&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;我说。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;“我不能在出租车里看起来奇怪”&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;“你知道我是这个虽然”，布拉特说。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;“他是一个打架不重要？”&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;“它让去做它”&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;“你做的？”&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;“坐下，”我说。“我希望我没有和那个男人做一点。”&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;“你找到了它。”&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;“我不知道。”&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;“你看，我对&lt;/i&gt;&lt;i&gt;chatches&lt;/i&gt;&lt;i&gt;（英文中没有&lt;/i&gt;&lt;i&gt;chatches&lt;/i&gt;&lt;i&gt;这个词）感到抱歉”比尔说道“你认为它是一个朋友后面并且它真的让你醉”）&lt;/i&gt;&lt;/p&gt;&lt;p&gt;到此时，算法已经收集到了海明威写作的基本风格——简短而直接的对话形式。甚至有一些话语开始被人类理解。&lt;/p&gt;&lt;p&gt;和原文中的句子作比较：&lt;/p&gt;&lt;p&gt;&lt;i&gt;There were a few people inside at the bar, and outside, alone, sat Harvey Stone. He had a pile of saucers in front of him, and he needed a shave.&lt;/i&gt;&lt;i&gt;“Sit down,” said Harvey, “I’ve been looking for you.”“What’s the matter?”“Nothing. Just looking for you.”“Been out to the races?”“No. Not since Sunday.”“What do you hear from the States?”“Nothing. Absolutely nothing.”“What’s the matter?”&lt;/i&gt;&lt;/p&gt;&lt;p&gt;即使我们每一个单词都做比较，我们的算法也已经用恰当的格式重新出一篇看起来可信的文章。这非常厉害！&lt;/p&gt;&lt;p&gt;当然，我们再也不用写文章之前打草稿了。我们可以把前几个字母放到算法当中去，让算法找到后面的几个字母。&lt;/p&gt;&lt;p&gt;为了好玩，我们一起来模仿海明威著作的封面，并通过我们的算法，生成一个假书名和假作者吧！&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-007e260960031fe3f56eb3b3227b5d7a.png" data-rawwidth="1000" data-rawheight="722"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;真书在左，看起来傻乎乎的假书在右（译者注：右边的书名意思是：肉用公牛的秘密）&lt;/i&gt;&lt;/p&gt;&lt;p&gt;看起来不错呀！&lt;/p&gt;&lt;p&gt;但是&lt;b&gt;真正让人脑洞大开的部分&lt;/b&gt;是这个算法能够找出任何数据序列中的规律。他可以轻松创作出&lt;a href="https://gist.github.com/nylki/1efbaa36635956d35bcc" data-editable="true" data-title="食谱"&gt;食谱&lt;/a&gt;或者是&lt;a href="https://medium.com/@samim/obama-rnn-machine-generated-political-speeches-c8abd18a2ea0#.b4clxzrgf" data-editable="true" data-title="假的奥巴马的演讲"&gt;假的奥巴马的演讲&lt;/a&gt;。为什么一定要限定是人类的语言呢？我们也可以用这个想法来处理任何有规律可循的数据。&lt;/p&gt;&lt;p&gt;&lt;b&gt;不用马里奥，智造马里奥&lt;/b&gt;&lt;/p&gt;&lt;p&gt;2015年，任天堂在Wii平台上发布了“超级马里奥编辑器”。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-913935b9ad31bb4d88c366137d278667.png" data-rawwidth="779" data-rawheight="438"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;每个孩子的梦想。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;你能够用这个编辑器创造出你自己的超级马里奥关卡并把它们上传到互联网上，和朋友们一起玩。你可以使用游戏中所有经典的道具和敌人来创造你自己的关卡。这就像是一个为成年人设计的乐高积木玩具一样。&lt;/p&gt;&lt;p&gt;所以问题来了，我们能够使用创作海明威的模型来制作马里奥么？&lt;/p&gt;&lt;p&gt;首先，我们需要一组数据来训练我们的模型。我们会使用马里奥兄弟1985年版所有的室外关卡的数据（译者注：就是最经典的那一版本）。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-a971a9e71cc4951313c6e7cdf4305f96.png" data-rawwidth="1000" data-rawheight="1368"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;这个圣诞节棒极了！谢谢粑粑麻麻！&lt;/i&gt;&lt;/p&gt;&lt;p&gt;这个游戏共包含32关而其中70%是都有类似的户外场景。所以我们将会使用这些数据。&lt;/p&gt;&lt;p&gt;我设计了一个小程序，把原版游戏中所有的关卡设计都提取了出来。超级马里奥兄弟是一个有着30年历史的游戏，网上有着丰富的资源来帮助你找出关卡设计在游戏代码中的存储位置。从一个老游戏中提取关卡数据，是一个很有趣的编程练习，你有空可以试一下！&lt;/p&gt;&lt;p&gt;这个就是游戏的第一关（如果你玩过超级马里奥，你应该会记得）&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-63074bcbd30b1a66a57e881ac8f22589.jpg" data-rawwidth="2000" data-rawheight="132"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;超级马里奥关卡1-1&lt;/i&gt;&lt;/p&gt;&lt;p&gt;如果我们仔细观察，我们会发现这一关是由一个个简单的小网格类型的物品构成的。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-d437440a7c79e8a934470652413e2622.png" data-rawwidth="1000" data-rawheight="543"&gt;&lt;p&gt;我们可以简单的把这些网格表示成一序列字符，每一个字符都代表着一个物品：&lt;/p&gt;&lt;pre&gt;&lt;code lang="text"&gt;--------------------------
--------------------------
--------------------------
#??#----------------------
--------------------------
--------------------------
--------------------------
-##------=--=----------==-
--------==--==--------===-
-------===--===------====-
------====--====----=====-
=========================-&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;我们把物品换成了下列字母：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;“_”代表没有物品&lt;/li&gt;&lt;li&gt;“=”代表砖块&lt;/li&gt;&lt;li&gt;“#”代表可以打碎的砖块&lt;/li&gt;&lt;li&gt;“？”代表金币砖块&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;…就类似于这样，用不同的字字符代表关卡里的不同的物品。&lt;/p&gt;&lt;p&gt;最后就得到了如下的文本文档：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-a320bb57b644fa39d82007082d6a2f6d.png" data-rawwidth="1250" data-rawheight="420"&gt;&lt;/p&gt;&lt;p&gt;仔细观察这个文本文档，你会发现如果以“行”的顺序观察，并没有什么规律可循：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-9636079742d98113c162d2f4f04e9bc1.png" data-rawwidth="648" data-rawheight="212"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;一行一行寻找，并找不到什么规律。你会发现很多行就是空白的。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;当你把关卡理解为连续的“列（Column）”的时候，规律就浮现出来了：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-426f187efeb773f286233651ece9a60b.png" data-rawwidth="638" data-rawheight="222"&gt;&lt;/p&gt;&lt;p&gt;一列一列寻找，规律就显现出来了。比如说每一列都以“=”结尾。&lt;/p&gt;&lt;p&gt;为了让算法能找出我们数据中的规律，我们需要把数据以列的形式输入。找出你数据的最有效的表达方法（这个方法也叫作&lt;b&gt;特征选择&lt;/b&gt;&lt;b&gt;Feature Selection&lt;/b&gt;），是使用机器学习算法的重要技巧之一。&lt;/p&gt;&lt;p&gt;为了训练模型，我需要把这个文本文档旋转90度。这样一来就保证了这些字符被输入进模型之后，模型能够更容易找到其中的规律。&lt;/p&gt;&lt;pre&gt;&lt;code lang="text"&gt;-----------=
-------#---=
-------#---=
-------?---=
-------#---=
-----------=
-----------=
----------@=
----------@=
-----------=
-----------=
-----------=
---------PP=
---------PP=
----------==
---------===
--------====
-------=====
------======
-----=======
---=========
---=========
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;b&gt;训练我们的模型&lt;/b&gt;&lt;/p&gt;&lt;p&gt;就好像我们刚刚看到的创作海明威风格的那个模型一样，经过训练之后，一个模型会得到提升。&lt;/p&gt;&lt;p&gt;经过一点点的训练，我们的模型生成了并没有什么卵用的东西：&lt;/p&gt;&lt;pre&gt;&lt;code lang="text"&gt;--------------------------
LL+&amp;lt;&amp;amp;=------P-------------
--------
---------------------T--#--
-----
-=--=-=------------=-&amp;amp;--T--------------
--------------------
--=------$-=#-=-_
--------------=----=&amp;lt;----
-------b
-
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;它好像理解了应该有很多的“_”和“=”的思路，这已经很好了。但是还没有找到规律。&lt;/p&gt;&lt;p&gt;经过几千个循环之后，它开始变得有模有样了：&lt;/p&gt;&lt;pre&gt;&lt;code lang="text"&gt;--
-----------=
----------=
--------PP=
--------PP=
-----------=
-----------=
-----------=
-------?---=
-----------=
-----------=
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;模型几乎已经知道每一行应该有相同的长度。它甚至开始找出马里奥的一些逻辑：管道（绿色的管子）经常是两个砖块那么宽，并且至少有两个砖块那么高，所以数据里面的“P”应该以一种2×2的方格形式出现。这非常酷炫！&lt;/p&gt;&lt;p&gt;经过大量的训练之后，模型开始达到一种创造出完美的可用的数据的阶段：&lt;/p&gt;&lt;pre&gt;&lt;code lang="text"&gt;--------PP=
--------PP=
----------=
----------=
----------=
---PPP=---=
---PPP=---=
----------=
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;让我们用我们的模型来创造一整个关卡，并把它们横过来：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-f494d170951a538be7e203655135c3ab.png" data-rawwidth="1250" data-rawheight="193"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;用我们的模型创造的一整关&lt;/i&gt;&lt;/p&gt;&lt;p&gt;数据看起来棒棒哒！并且有以下几个优点值得关注：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;他把那个虫子（译者注：那个虫子叫做Lakitu）放在了关卡的一开始的天上，就像真实的超级马里奥关卡一样。&lt;/li&gt;&lt;li&gt;他知道管道是压在砖块上面的，而不是仅仅漂浮在天上。&lt;/li&gt;&lt;li&gt;他把敌人放在了恰当的位置&lt;/li&gt;&lt;li&gt;它看上去就超级马里奥的一关一样，因为它是在游戏里存在的原版关卡的基础上创造出来的。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;最终，我们把这一个关放到超级马里奥编辑器里面，来创造出这一关。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-9b1ee49e9eb54b93f8a93cff51273e04.jpg" data-rawwidth="546" data-rawheight="81"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;我们的把关卡数据输入到编辑器以后得到的关卡&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;（Youtube视频）&lt;/i&gt;&lt;/p&gt;&lt;p&gt;自己玩吧！&lt;/p&gt;&lt;p&gt;如果你有超级马里奥编辑器，你可以在线试玩或者是通过关卡代码4AC9–0000–0157-F3C3来找到这一关。&lt;/p&gt;&lt;p&gt;&lt;b&gt;玩具&lt;/b&gt;&lt;b&gt;或是&lt;/b&gt;&lt;b&gt;真实世界的应用？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们所使用的用来训练我们模型的循环神经网络算法，就是一些真实的公司用来解决难题的算法。这些难题包括语音识别和文字翻译。解决难题和创造一个游戏关卡的区别，就在于数据量，我们的模型是由极少量的数据生成的。对于创造一个非常好的模型来说，原版超级马里奥兄弟里面的关卡数量还不够多。&lt;/p&gt;&lt;p&gt;如果我们像任天堂一样拥有成千上万玩家自己创作的马里奥关卡的数据，我们可以制作出一个令人震惊的模型。但是我们不能，因为任天堂并不让我们拥有他们。天下没有免费的午餐，大公司的数据不免费给你。&lt;/p&gt;&lt;p&gt;&lt;b&gt;随着机器学习在许多领域越来越重要，好程序与坏程序的区别就在于你需要多少的数据来训练你的模型。这就是为什么像谷歌和Facebook这样的公司如此需要你的数据。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;打个比方，谷歌最近对TensorFlow进行了开源，公布了它用来建立大规模机器学习的Toolkit。谷歌把如此重要，如此实用的科技免费公布出来，这还是一个很重量级的决定。你要知道，这可是和谷歌翻译使用的原理是相同的。&lt;/p&gt;&lt;p&gt;但是离开了谷歌在各种语言里面收集到的信息，你没有办法创办一个谷歌翻译的竞争对手。数据是使谷歌处在行业顶端的源泉。想一想你打开谷歌地图历史记录或者是Facebook地点记录的时候，你会发现它们记录下来了你去过的每一个地方。&lt;/p&gt;&lt;p&gt;&lt;b&gt;延伸阅读&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在机器学习中，绝不会有单一的解决问题方法。对于如何预处理数据和算法的使用，你总是有无限种选择。综合各种方法经常会比使用单一方法能得到更好的结果。&lt;/p&gt;&lt;p&gt;读者们发给了我许多其他的生成马里奥兄弟关卡的有趣的方法：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Amy K. Hoover’s 的团队把游戏中的每一种物品表示成交响乐中的一种声音。然后再使用一种叫做“&lt;b&gt;功能性架构（Functional Scaffolding）&lt;/b&gt;”的方法，系统能够把每一种物品添加到关卡里去。比如说，你可以自己制作出你想要的关卡基本样式，然后再去添加水管或者是问号砖块，来完成你的创作。&lt;/li&gt;&lt;li&gt;Steve Dahlskog的团队展示了一种模型。这种模型能够把每一列游戏关卡数据表示成一序列的有n个元的“单词”（modeling each column of level data as a series of n-gram “words” ），相比于循环神经网络算法，这种方法这使得他们能够以一种更简单的方法来生成关卡。&lt;/li&gt;&lt;/ul&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/24344720&amp;pixel&amp;useReferer"/&gt;</description><author>九五要当学霸</author><pubDate>Thu, 15 Dec 2016 12:35:51 GMT</pubDate></item><item><title>【巡洋舰首发】有趣的机器学习 第一章:最简明入门指南</title><link>https://zhuanlan.zhihu.com/p/24450104</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-f13966dab9da121fc05307b3e18e085c_r.jpg"&gt;&lt;/p&gt;作者：九五要当学霸链接：&lt;a href="https://zhuanlan.zhihu.com/p/24339995" data-editable="true" data-title="知乎专栏"&gt;知乎专栏&lt;/a&gt;来源：知乎著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。&lt;p&gt;原文：Adam Geitgey&lt;/p&gt;&lt;p&gt;原文链接：&lt;a href="https://link.zhihu.com/?target=https%3A//medium.com/%40ageitgey/machine-learning-is-fun-80ea3ec3c471%23.d5u0e8dii" class="" data-editable="true" data-title="https://medium.com/@ageitgey/machine-learning-is-fun-80ea3ec3c471#.d5u0e8dii"&gt;https://medium.com/@ageitgey/machine-learning-is-fun-80ea3ec3c471#.d5u0e8dii&lt;/a&gt;&lt;/p&gt;&lt;p&gt;原译：toolate &lt;/p&gt;&lt;p&gt;更正&amp;amp;校对：巡洋舰科技——赵95&lt;/p&gt;&lt;p&gt;注：这篇译文最早是Adam Geitgey在medium上发表的，后由伯乐在线的toolate翻译。但是翻译中有&lt;b&gt;部分关键概念错误翻译&lt;/b&gt;，顾重新校对发表。——巡洋舰科技 赵95&lt;/p&gt;在接下来的一个月时间里，巡洋舰科技会陆续发布【有趣的机器学习】全五章，请持续关注！&lt;h1&gt;在听到人们谈论机器学习的时候，你是不是对它的涵义只有几个模糊的认识呢？你是不是已经厌倦了在和同事交谈时只能一直点头？让我们改变一下吧！&lt;/h1&gt;&lt;p&gt;本文目标在于平易近人，这意味着文中有大量的概括。但是谁在乎这些呢？只要能让读者对于机器学习更感兴趣，任务也就完成了。&lt;/p&gt;&lt;p&gt;本文已经更新第二章，&lt;a href="https://zhuanlan.zhihu.com/p/24344720" class="" data-editable="true" data-title="点此阅读"&gt;点此阅读&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;&lt;b&gt;何为机器学习？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;机器学习是一种概念。对于待解问题，你无需针对这个问题编写任何专门的代码，&lt;b&gt;泛型算法（Generic Algorithms）&lt;/b&gt;能够在输入的数据集上为你得出相应的答案。泛型算法是指，不用编码，而是将数据输入，它将在数据之上建立起它自己的逻辑。&lt;/p&gt;&lt;p&gt;&lt;i&gt;译者注：泛型，即没有特定类型，泛型算法是一种对很多不同问题都适用的算法，也叫作通用算法。如果你现在还对这个概念一知半解没关系，相信你读过这篇文章之后会对“泛型算法”有一个更深入的理解。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;举个例子，有一类算法称为分类算法，它可以将数据划分为不同的组别。一个用来识别手写数字的分类算法，不用修改一行代码，就可以把这个算法用来将电子邮件分为垃圾邮件和普通邮件。算法没变，但是输入的训练数据变了，因此它得出了不同的分类逻辑。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-c5ad0a1b15ef74c634ed5a7b17cd375f.png" data-rawwidth="800" data-rawheight="743"&gt;&lt;p&gt;&lt;i&gt;机器学习算法是个黑盒，可以重用来解决很多不同的分类问题。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;“机器学习”是一个涵盖性术语，覆盖了大量类似的泛型算法。&lt;/p&gt;&lt;p&gt;&lt;b&gt;两类机器学习算法&lt;/b&gt;&lt;/p&gt;&lt;p&gt;你可以认为机器学习算法分为两大类：&lt;b&gt;监督式学习（Supervised Learning）&lt;/b&gt;和&lt;b&gt;非监督式学习（Unsupervised Learning）&lt;/b&gt;。两者区别很简单，但却非常重要。&lt;/p&gt;&lt;p&gt;&lt;b&gt;监督式学习&lt;/b&gt;&lt;/p&gt;&lt;p&gt;假设你是一名房地产经纪人，生意越做越大，因此你雇了一批新员工来帮你。但是问题来了——你可以看一眼房子就知道它到底值多少钱，新员工没有经验，不知道如何估价。&lt;/p&gt;&lt;p&gt;为了帮助你的新员工（也许就是为了给自己放个假嘻嘻），你决定写个小软件，可以根据房屋大小、地段以及类似房屋的成交价等因素来评估一间房屋的价格。&lt;/p&gt;&lt;p&gt;你把3个月来城里每笔房屋交易都写了下来，每一单你都记录了一长串的细节——卧室数量、房屋大小、地段等等。&lt;b&gt;但最重要的是，你写下了最终的成交价&lt;/b&gt;：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-2339493405f1e8cc2dd36f96f1c6bfe1.png" data-rawwidth="800" data-rawheight="437"&gt;&lt;p&gt;&lt;i&gt;这是我们的“训练数据”&lt;/i&gt;&lt;/p&gt;&lt;p&gt;我们要利用这些训练数据来编写一个程序来估算该地区其他房屋的价值：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-b7337731932718c8c05f9f461a7b0f31.png" data-rawwidth="800" data-rawheight="150"&gt;&lt;p&gt;这就称为&lt;b&gt;监督式学习&lt;/b&gt;。你已经知道每一栋房屋的售价，换句话说，你知道问题的答案，并可以反向找出解题的逻辑。&lt;/p&gt;&lt;p&gt;为了编写软件，你将包含每一套房产的训练数据输入你的机器学习算法。算法尝试找出应该使用何种运算来得出价格数字。&lt;/p&gt;&lt;p&gt;这就像是算术练习题，算式中的运算符号都被擦去了：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-b0b8b2ee80ea3202cd9dd297af6418cb.png" data-rawwidth="800" data-rawheight="388"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;天哪！一个阴险的学生将老师答案上的算术符号全擦去了。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;看了这些题，你能明白这些测验里面是什么样的数学问题吗？你知道，你应该对算式左边的数字“做些什么”以得出算式右边的答案。&lt;/p&gt;&lt;p&gt;在监督式学习中，你是让计算机为你算出数字间的关系。而一旦你知道了解决这类特定问题所需要的数学方法后，你就可以解答同类的其它问题了。&lt;/p&gt;&lt;p&gt;&lt;b&gt;非监督式学习&lt;/b&gt;&lt;/p&gt;&lt;p&gt;让我们回到开头那个房地产经纪人的例子。要是你不知道每栋房子的售价怎么办？即使你所知道的只是房屋的大小、位置等信息，你也可以搞出很酷炫的花样。这就是所谓的&lt;b&gt;非监督式学习&lt;/b&gt;。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-27add9b9c67ce1077e6fea698a038a03.png" data-rawwidth="616" data-rawheight="432"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;即使你不是想去预测未知的数据（如价格），你也可以运用机器学习完成一些有意思的事。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;这就有点像有人给你一张纸，上面列出了很多数字，然后对你说:“我不知道这些数字有什么意义，也许你能从中找出规律或是能将它们分类，或是其它什么-祝你好运！”&lt;/p&gt;&lt;p&gt;你该怎么处理这些数据呢？首先，你可以用个算法自动地从数据中划分出不同的细分市场。也许你会发现大学附近的买房者喜欢户型小但卧室多的房子，而郊区的买房者偏好三卧室的大户型。这些信息可以直接帮助你的营销。&lt;/p&gt;&lt;p&gt;你还可以作件很酷炫的事，自动找出房价的奇异数据，即与其它数据迥异的值。这些特立独行的房产也许是奢华的豪宅，而你可以将最优秀的推销员集中在这些地区，因为他们的佣金更高。&lt;/p&gt;&lt;p&gt;本文余下部分我们主要讨论监督式学习，但这并不是因为非监督式学习用处不大或是索然无味。实际上，随着算法改良，不用将数据和正确答案联系在一起，因此非监督式学习正变得越来越重要。&lt;/p&gt;&lt;p&gt;&lt;i&gt;编者注:还有很多其它种类的机器学习算法。但从这里开始讲起是一个不错的选择。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;太酷炫了，但是评估房价真能被看作“学习”吗？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;作为人类的一员，你的大脑可以应付绝大多数情况，并且没有任何明确指令也能够学习如何处理这些情况。如果你做房产经纪时间足够长，你对于房产的合适定价、它的最佳营销方式以及哪些客户会感兴趣等等都会有一种本能般的“感觉”。强人工智能（Strong AI）研究的目标就是要能够用计算机复制这种能力。&lt;/p&gt;&lt;p&gt;但是目前的机器学习算法还没有那么好——它们只能专注于非常特定的、有限的问题。也许在这种情况下，“学习”更贴切的定义是“在少量范例数据的基础上找出一个等式来解决特定的问题”（&lt;em&gt;Figuring out an equation to solve a specific problem based on
some example data&lt;/em&gt;）。&lt;/p&gt;&lt;p&gt;不幸的是，“机器在少量范例数据的基础上找出一个等式来解决特定的问题”这个名字太烂了。所以最后我们用“机器学习”取而代之。&lt;/p&gt;&lt;p&gt;当然，要是你是在50年之后来读这篇文章，那时我们已经得出了强人工智能算法，而本文看起来就像个老古董。所以，未来的人类，你还是别读了，叫你的机器人佣人给你做份三明治吧。&lt;/p&gt;&lt;p&gt;&lt;b&gt;让我们愉快的写代码吧!&lt;/b&gt;&lt;/p&gt;&lt;p&gt;前面例子中评估房价的程序，你打算怎么写呢？往下看之前，先思考一下吧。&lt;/p&gt;&lt;p&gt;如果你对机器学习一无所知，很有可能你会尝试写出一些基本规则来评估房价，如下：&lt;/p&gt;&lt;pre&gt;&lt;code lang="text"&gt;def estimate_house_sales_price(num_of_bedrooms, sqft, neighborhood):
  price = 0

  # In my area, the average house costs $200 per sqft
  price_per_sqft = 200

  if neighborhood == "hipsterton":
    # but some areas cost a bit more
    price_per_sqft = 400

  elif neighborhood == "skid row":
    # and some areas cost less
    price_per_sqft = 100

  # start with a base price estimate based on how big the place is
  price = price_per_sqft * sqft

  # now adjust our estimate based on the number of bedrooms
  if num_of_bedrooms == 0:
    # Studio apartments are cheap
    price = price — 20000
  else:
    # places with more bedrooms are usually
    # more valuable
    price = price + (num_of_bedrooms * 1000)

 return price
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;假如你像这样瞎忙几个小时，也许会取得一点成效，但是你的程序永不会完美，而且当价格变化时很难维护。&lt;/p&gt;&lt;p&gt;如果能让计算机找出实现上述函数功能的办法，这样岂不更好？只要返回的房价数字正确，谁会在乎函数具体干了些什么呢？&lt;/p&gt;&lt;pre&gt;&lt;code lang="text"&gt;def estimate_house_sales_price(num_of_bedrooms, sqft, neighborhood):
  price = &amp;lt;computer, plz do some math for me&amp;gt;
 
  return price
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;考虑这个问题的一种角度是将房价看做一碗美味的汤，而汤中成分就是卧室数、面积和地段。如果你能算出每种成分对最终的价格有多大影响，也许就能得到各种成分混合起来形成最终价格的具体比例。&lt;/p&gt;&lt;p&gt;这样可以将你最初的程序（全是疯狂的if else语句）简化成类似如下的样子：&lt;/p&gt;&lt;pre&gt;&lt;code lang="text"&gt;def estimate_house_sales_price(num_of_bedrooms, sqft, neighborhood):
 price = 0
 
 # a little pinch of this
 price += num_of_bedrooms * .841231951398213
 
 # and a big pinch of that
 price += sqft * 1231.1231231
 
 # maybe a handful of this
 price += neighborhood * 2.3242341421
 
 # and finally, just a little extra salt for good measure
 price += 201.23432095
 
 return price
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;请注意那些用粗体标注的神奇数字——&lt;b&gt;.841231951398213&lt;/b&gt;,&lt;b&gt; 1231.1231231&lt;/b&gt;,&lt;b&gt;2.3242341421&lt;/b&gt;,和&lt;b&gt;201.23432095&lt;/b&gt;。它们称为&lt;b&gt;权重（weight）&lt;/b&gt;。如果我们能找出对每栋房子都适用的完美权重，我们的函数就能预测所有的房价！&lt;/p&gt;&lt;p&gt;&lt;i&gt;译者注：权重可能有很多种不同的组合，每一种权重最后给出的房价预测也不同，我们的目标就是要找出一组最终价格最接近真实值的权重。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;找出最佳权重的一种笨办法如下所示：&lt;/p&gt;&lt;p&gt;&lt;b&gt;步骤1：&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;首先，将每个权重都设为1.0：&lt;/b&gt;&lt;/p&gt;&lt;pre&gt;&lt;code lang="text"&gt;def estimate_house_sales_price(num_of_bedrooms, sqft, neighborhood):
  price = 0
 
  # a little pinch of this
  price += num_of_bedrooms * 1.0
 
  # and a big pinch of that
  price += sqft * 1.0
 
  # maybe a handful of this
  price += neighborhood * 1.0
 
  # and finally, just a little extra salt for good measure
  price += 1.0
 
  return price
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;b&gt;步骤&lt;/b&gt;&lt;b&gt;2&lt;/b&gt;&lt;b&gt;：&lt;/b&gt;&lt;/p&gt;&lt;p&gt;将每栋房产带入你的函数运算，检验估算值与正确价格的偏离程度：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-7e2c801505c04a737c1ebdc317ea3559.png" data-rawwidth="800" data-rawheight="346"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;运用你的程序预测房屋价格。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;例如：上表中第一套房产实际成交价为25万美元，你的函数估价为17.8万，这一套房产你就差了7.2万。&lt;/p&gt;&lt;p&gt;再将你的数据集中的每套房产估价偏离值平方后求和。假设数据集中有500套房产交易，估价偏离值平方求和总计为86,123,373美元。这就反映了你的函数现在的“正确”程度。&lt;/p&gt;&lt;p&gt;现在，将总计值除以500，得到每套房产的估价偏离平均值。将这个平均误差值称为你函数的&lt;b&gt;代价（Cost）&lt;/b&gt;。&lt;/p&gt;&lt;p&gt;如果你能调整权重使得这个代价变为0，你的函数就完美了。它意味着，根据输入的数据，你的程序对每一笔房产交易的估价都是分毫不差。而这就是我们的目标——&lt;b&gt;尝试不同的权重值以使代价尽可能的低&lt;/b&gt;。&lt;/p&gt;&lt;p&gt;&lt;b&gt;步骤3：&lt;/b&gt;&lt;/p&gt;&lt;p&gt;不断重复步骤2，尝试&lt;b&gt;所有可能的权重值组合&lt;/b&gt;。哪一个组合使得代价最接近于0，它就是你要使用的，你只要找到了这样的组合，问题就得到了解决!&lt;/p&gt;&lt;p&gt;&lt;b&gt;打乱你内心想法的时候到了！&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这太简单了，对吧？想一想刚才你做了些什么。你取得了一些数据，将它们输入至三个通用的简单步骤中，最后你得到了一个可以对你所在区域的房屋进行估价的函数。房价网，要当心咯！但是下面的事实可能会扰乱你的思想：&lt;/p&gt;&lt;p&gt;1.过去40年来，很多领域（如语言学/翻译学）的研究表明，这种通用的“搅动数据汤”（我编造的词）式的学习算法已经胜过了需要利用真人明确规则的方法。机器学习的“笨”办法最终打败了人类专家。&lt;/p&gt;&lt;p&gt;2.你最后写出的函数真是笨，它甚至不知道什么是“面积”和“卧室数”。它知道的只是搅动，改变数字来得到正确的答案。&lt;/p&gt;&lt;p&gt;3.很可能你都不知道为何一组特殊的权重值能起效。所以你只是写出了一个你实际上并不理解却能证明的函数。
4.试想一下，你的程序里没有类似“面积”和“卧室数”这样的参数，而是接受了一组数字。假设每个数字代表了你车顶安装的摄像头捕捉的画面中的一个像素，再将预测的输出不称为“价格”而是叫做“方向盘转动度数”，&lt;b&gt;这样你就得到了一个程序可以自动操纵你的汽车了！&lt;/b&gt;&lt;/p&gt;&lt;p&gt;太疯狂了，对吧？&lt;/p&gt;&lt;p&gt;&lt;i&gt;译者注：到这里，你应该对泛型算法有一个更深刻的理解了&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;步骤3中的“尝试每个数字”怎么回事？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;好吧，当然你不可能尝试所有可能的权重值来找到效果最好的组合。那可真要花很长时间，因为要尝试的数字可能无穷无尽。为避免这种情况，数学家们找到了很多聪明的办法来快速找到优秀的权重值，而不需要尝试过多。下面是其中一种：首先，写出一个简单的等式表示前述步骤2：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-6dd383cb197529942f16580f2e2d5e0f.png" data-rawwidth="800" data-rawheight="262"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;这是你的&lt;b&gt;代价函数（Cost Function）&lt;/b&gt;。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;接着，让我们将这同一个等式用机器学习的数学术语（现在你可以忽略它们）进行重写：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-84c72ecfe324af130aed7bb395bdacdf.png" data-rawwidth="800" data-rawheight="200"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt; θ表示当前的权重值。 J(θ) 意为“当前权重值对应的代价”。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;这个等式表示我们的估价程序在当前权重值下偏离程度的大小。如果将所有赋给卧室数和面积的可能权重值以图形形式显示，我们会得到类似下图的图表：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-e3efd7884625d25fcca9987dc24a1059.png" data-rawwidth="800" data-rawheight="557"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;代价函数的图形像一个碗。纵轴表示代价。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;图中蓝色的最低点就是代价最低的地方——即我们的程序偏离最小。最高点意味着偏离最大。所以，如果我们能找到一组权重值带领我们到达图中的最低点，我们就找到了答案！&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-e0281b4149b134267400c6ce0512adc9.jpg" data-rawwidth="861" data-rawheight="599"&gt;&lt;/p&gt;&lt;p&gt;因此，我们只需要调整权重值使我们在图上能向着最低点“走下坡路”。如果对于权重的细小调节能一直使我们保持向最低点移动，那么最终我们不用尝试太多权重值就能到达那里。&lt;/p&gt;&lt;p&gt;如果你还记得一点微积分的话，你也许记得如果你对一个函数求导，结果会告诉你函数在任一点的斜率。换句话说，对于图上给定一点，它告诉我们那条路是下坡路。我们可以利用这一点朝底部进发。&lt;/p&gt;&lt;p&gt;&lt;i&gt;译者注：如果你还记得微积分当中，一个点他求出的导数是0的话，那么这个点就是最低点。所以返回到刚刚的代价函数里面，代价函数就等于0，也就意味着，你的预估和真实值没有任何差别。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;所以，如果我们对代价函数关于每一个权重求偏导，那么我们就可以从每一个权重中减去该值。这样可以让我们更加接近山底。一直这样做，最终我们将到达底部，得到权重的最优值。（读不懂？不用担心，接着往下读）。&lt;/p&gt;&lt;p&gt;这种找出最佳权重的办法被称为&lt;b&gt;批量梯度下降（Batch Gradient Descent）&lt;/b&gt;，上面是对它的高度概括。如果想搞懂细节，不要害怕，继续深入下去吧。&lt;/p&gt;&lt;p&gt;当你使用机器学习算法库来解决实际问题，所有这些都已经为你准备好了。但明白一些具体细节总是有用的。&lt;/p&gt;&lt;p&gt;&lt;b&gt;还有什么本篇文章略过的内容？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;上面我描述的三步算法被称为&lt;b&gt;多元线性回归(&lt;/b&gt;&lt;strong&gt;multivariate linear regression&lt;/strong&gt;&lt;b&gt;)&lt;/b&gt;。你估算等式是在求一条能够拟合所有房价数据点的直线。然后，你再根据房价在你的直线上可能出现的位置用这个等式来估算从未见过的房屋的价格。这个想法威力强大，可以用它来解决“实际”问题。&lt;/p&gt;&lt;p&gt;但是，我为你展示的这种方法可能在简单的情况下有效，它不会在所有情况下都有用。原因之一是因为房价不会一直那么简单地跟随一条连续直线。&lt;/p&gt;&lt;p&gt;但是，幸运的是，有很多办法来处理这种情况。对于非线性数据，很多其他类型的机器学习算法可以处理（如神经网络或有核向量机）。还有很多方法运用线性回归更灵活，想到了用更复杂的线条来拟合。在所有的情况中，寻找最优权重值这一基本思路依然适用。&lt;/p&gt;&lt;p&gt;还有，我忽略了&lt;b&gt;过拟合（Overfitting）&lt;/b&gt;的概念。很容易碰上这样一组权重值，它们对于你原始数据集中的房价都能完美预测，但对于原始数据集之外的任何新房屋都预测不准。这种情况的解决之道也有不少（如正则化以及使用交叉验证数据集）。学会如何处理这一问题对于顺利应用机器学习至关重要。&lt;/p&gt;&lt;p&gt;换言之，基本概念非常简单，要想运用机器学习得到有用的结果还需要一些技巧和经验。但是，这是每个开发者都能学会的技巧。&lt;/p&gt;&lt;p&gt;&lt;b&gt;机器学习法力无边吗？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;一旦你开始明白机器学习技术很容易应用于解决貌似很困难的问题（如手写识别），你心中会有一种感觉，只要有足够的数据，你就能够用机器学习解决任何问题。只需要将数据输入进去，就能看到计算机变戏法一样找出拟合数据的等式。&lt;/p&gt;&lt;p&gt;但是很重要的一点你要记住，机器学习只能对用你占有的数据实际可解的问题才适用。&lt;/p&gt;&lt;p&gt;例如，如果你建立了一个模型来根据每套房屋内盆栽数量来预测房价，它就永远不会成功。房屋内盆栽数量和房价之间没有任何的关系。所以，无论它怎么去尝试，计算机也推导不出两者之间的关系。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-6205e65e181bdb21f0678d237ebb363d.png" data-rawwidth="800" data-rawheight="255"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;你只能对实际存在的关系建模&lt;/i&gt;。&lt;/p&gt;&lt;p&gt;&lt;b&gt;怎样深入学习机器学习&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我认为，当前机器学习的最大问题是它主要活跃于学术界和商业研究组织中。对于圈外想要有个大体了解而不是想成为专家的人们，简单易懂的学习资料不多。但是这一情况每一天都在改善。&lt;/p&gt;&lt;p&gt;吴恩达教授（Andrew Ng）在Coursera上的机器学习免费课程非常不错。我强烈建议由此入门。任何拥有计算机科学学位、还能记住一点点数学的人应该都能理解。&lt;/p&gt;&lt;p&gt;另外，你还可以下载安装SciKit-Learn，用它来试验成千上万的机器学习算法。它是一个python框架，对于所有的标准算法都有“黑盒”版本。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-29cc4af3dbe6eb6294f932ec2e10c342.png" data-rawwidth="991" data-rawheight="524"&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/24450104&amp;pixel&amp;useReferer"/&gt;</description><author>许铁-巡洋舰科技</author><pubDate>Mon, 19 Dec 2016 17:12:58 GMT</pubDate></item></channel></rss>