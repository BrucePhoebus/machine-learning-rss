<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>炼丹实验室 - 知乎专栏</title><link>https://zhuanlan.zhihu.com/easyml</link><description>长期更新一些深度学习的实践性经验</description><lastBuildDate>Tue, 28 Feb 2017 19:15:53 GMT</lastBuildDate><generator>Ricky</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>当AI邂逅艺术：机器写诗综述</title><link>https://zhuanlan.zhihu.com/p/25084737</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-7f063d18605b7d9fcb79e30c407520b9_r.jpg"&gt;&lt;/p&gt;&lt;h1&gt;&lt;b&gt;引言&lt;/b&gt;&lt;/h1&gt;&lt;p&gt;什么是艺术？机器的作品能否叫艺术？机器能否取代艺术家？&lt;/p&gt;&lt;p&gt;这些问题，相信不同的人，会有不同的答案。很多人认为机器生成的作品只是简单的模仿人类，没有创造性可言，但是人类艺术家，不也是从模仿和学习开始的吗？本文是为PaperWeekly写的一篇机器诗歌生成的综述文章，希望能增进大家对这个领域的了解。&lt;/p&gt;&lt;p&gt;诗歌是人类文学皇冠上的明珠。我国自《诗经》以后，两千年来的诗篇灿若繁星。让机器自动生成诗歌，一直是人工智能领域一个有挑战性的工作。&lt;/p&gt;&lt;h1&gt;&lt;b&gt;基于传统方法的诗歌生成&lt;/b&gt;&lt;/h1&gt;&lt;p&gt;机器诗歌生成的工作，始于20世纪70年代。传统的诗歌生成方法，主要有以下几种：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Word Salada（词语沙拉）&lt;/strong&gt;：是最早期的诗歌生成模型，被称作只是简单将词语进行随机组合和堆砌而不考虑语义语法要求。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;基于模板和模式的方法&lt;/strong&gt;：基于模板的方法类似于完形填空，将一首现有诗歌挖去一些词，作为模板，再用一些其他词进行替换，产生新的诗歌。这种方法生成的诗歌在语法上有所提升，但是灵活性太差。因此后来出现了基于模式的方法，通过对每个位置词的词性，韵律平仄进行限制，来进行诗歌生成。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;基于遗传算法的方法&lt;/strong&gt;：周昌乐等[1]提出并应用到宋词生成上。这里将诗歌生成看成状态空间搜索问题。先从随机诗句开始，然后借助人工定义的诗句评估函数，不断进行评估，进化的迭代，最终得到诗歌。这种方法在单句上有较好的结果，但是句子之间缺乏语义连贯性。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;基于摘要生成的方法&lt;/strong&gt;：严睿等[2]将诗歌生成看成给定写作意图的摘要生成问题，同时加入了诗歌相关的一些优化约束。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;基于统计机器翻译的方法&lt;/strong&gt;：MSRA的何晶和周明[3]将诗歌生成看成一个机器翻译问题，将上一句看成源语言，下一句看成目标语言，用统计机器翻译模型进行翻译，并加上平仄押韵等约束，得到下一句。通过不断重复这个过程，得到一首完整的诗歌。&lt;/li&gt;&lt;/ul&gt;&lt;h1&gt;&lt;b&gt;基于深度学习技术的诗歌生成&lt;/b&gt;&lt;/h1&gt;&lt;p&gt;传统方法非常依赖于诗词领域的专业知识，需要专家设计大量的人工规则，对生成诗词的格律和质量进行约束。同时迁移能力也比较差，难以直接应用到其他文体（唐诗，宋词等）和语言（英文，日文等）。随着深度学习技术的发展，诗歌生成的研究进入了一个新的阶段。&lt;/p&gt;&lt;h2&gt;RNNLM&lt;/h2&gt;&lt;p&gt;基于RNN语言模型[4]的方法，将诗歌的整体内容，作为训练语料送给RNN语言模型进行训练。训练完成后，先给定一些初始内容，然后就可以按照语言模型输出的概率分布进行采样得到下一个词，不断重复这个过程就产生完整的诗歌。Karpathy有一篇文章，非常详细的介绍这个：&lt;a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/" data-title="The Unreasonable Effectiveness of Recurrent Neural Networks" class=""&gt;The Unreasonable Effectiveness of Recurrent Neural Networks&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;Chinese Poetry Generation with Recurrent Neural Networks&lt;/h2&gt;&lt;p&gt;RNNPG模型[5]，首先由用户给定的关键词生成第一句，然后由第一句话生成第二句话，由一，二句话生成第三句话，重复这个过程，直到诗歌生成完成。模型的模型由三部分组成：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Convolutional Sentence Model（CSM）&lt;/strong&gt;：CNN模型，用于获取一句话的向量表示。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Recurrent Context Model (RCM)&lt;/strong&gt;：句子级别的RNN，根据历史生成句子的向量，输出下一个要生成句子的Context向量。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Recurrent Generation Model (RGM)&lt;/strong&gt;：字符级别RNN，根据RCM输出的Context向量和该句之前已经生成的字符，输出下一个字符的概率分布。解码的时候根据RGM模型输出的概率和语言模型概率加权以后，生成下一句诗歌，由人工规则保证押韵。&lt;/p&gt;&lt;p&gt;模型结构如下图：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-fcce3662664f633e19967f0d6d7145f6.png" data-rawwidth="632" data-rawheight="207"&gt;&lt;p&gt;模型生成例子如下图：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-065cc4e88f919e47b4d0e27832187eed.png" data-rawwidth="692" data-rawheight="213"&gt;&lt;p&gt;Chinese Song Iambics Generation with Neural Attention-based Model&lt;/p&gt;&lt;p&gt;模型[6]是基于attention的encoder-decoder框架，将历史已经生成的内容作为源语言，将下一句话作为目标语言进行翻译。需要用户提供第一句话，然后由第一句生成第二句，第一，二句生成第三句，并不断重复这个过程，直到生成完整诗歌。基于Attention机制配合LSTM，可以学习更长的诗歌，同时在一定程度上，可以保证前后语义的连贯性。&lt;/p&gt;&lt;p&gt;模型结构如下图：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-dce6622f6c1de7d39fefdc7c37777f40.png" data-rawwidth="469" data-rawheight="372"&gt;&lt;p&gt;模型生成例子如下图：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-66c14159287d17f513a81891329a16c9.png" data-rawwidth="329" data-rawheight="348"&gt;&lt;h2&gt;Chinese Poetry Generation with Planning based Neural Network&lt;/h2&gt;&lt;p&gt;模型[8]不需要专家知识，是一个端到端的模型。它试图模仿人类开始写作前，先规划一个写作大纲的过程。整个诗歌生成框架由两部分组成：规划模型和生成模型。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;规划模型&lt;/strong&gt;：将代表用户写作意图的Query作为输入，生成一个写作大纲。写作大纲是一个由主题词组成的序列，第i个主题词代表第i句的主题。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;生成模型&lt;/strong&gt;：基于encoder-decoder框架。有两个encoder,其中一个encoder将主题词作为输入，另外一个encoder将历史生成的句子拼在一起作为输入，由decoder生成下一句话。decoder生成的时候，利用Attention机制，对主题词和历史生成内容的向量一起做打分，由模型来决定生成的过程中各部分的重要性。&lt;/p&gt;&lt;p&gt;前面介绍的几个模型，用户的写作意图，基本只能反映在第一句，随着生成过程往后进行，后面句子和用户写作意图的关系越来越弱，就有可能发生主题漂移问题。而规划模型可以使用户的写作意图直接影响整首诗的生成，因此在一定程度上，避免了主题漂移问题，使整首诗的逻辑语义更为连贯。&lt;/p&gt;&lt;p&gt;总体框架图如下：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-0fbee3690fb37ebb4ca5b1bae260f7c1.png" data-rawwidth="878" data-rawheight="397"&gt;&lt;p&gt;生成模型框架图如下：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-906de5e1f5dccac46b1f317cb805c9c8.png" data-rawwidth="891" data-rawheight="404"&gt;&lt;p&gt;&lt;b&gt;诗歌图灵测试&lt;/b&gt;：给定一个题目，让机器和人分别做一首诗 ，由人来区分哪首诗是人写的。实验结果也很有意思，对普通人来说，已经无法区分诗是由机器生成的还是人生成的，下面是一组测试的例子：&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-d41f35870592ab327bd90e16d791c6ec.png" data-rawwidth="988" data-rawheight="333"&gt;现代概念诗歌生成例子：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-7bcd91238ca223a3bdd701770bc93196.png" data-rawwidth="980" data-rawheight="327"&gt;&lt;h2&gt;i, Poet: Automatic Poetry Composition through Recurrent Neural Networks with Iterative Polishing Schema&lt;/h2&gt;&lt;p&gt;模型[7]基于encoder-decoder框架。encoder阶段，用户提供一个Query作为自己的写作意图,由CNN模型获取Query的向量表示。decoder阶段，使用了hierarchical的RNN生成框架，由句子级别和词级别两个RNN组成。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;句子级别RNN&lt;/strong&gt;：输入句子向量表示，输出下一个句子的Context向量。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;字符级别RNN&lt;/strong&gt;：输入Context向量和历史生成字符，输出下一个字符的概率分布。当一句生成结束的时候，字符级别RNN的最后一个向量，作为表示这个句子的向量，送给句子级别RNN。&lt;/p&gt;&lt;p&gt;这篇文章一个比较有意思的地方，是想模拟人类写诗反复修改的过程，加入了打磨机制。反复迭代来提高诗歌生成质量。&lt;/p&gt;&lt;p&gt;总体框架图如下：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-6d89bc240a7b79f8ca934af493b8ec86.png" data-rawwidth="856" data-rawheight="471"&gt;&lt;h2&gt;Generating Topical Poetry&lt;/h2&gt;&lt;p&gt;模型[9]基于encoder-decoder框架，分为两步。先根据用户输入的关键词得到每句话的最后一个词，这些词都押韵且与用户输入相关。再将这些押韵词作为一个序列，送给encoder,由decoder生成整个诗歌。这种机制一方面保证了押韵，另外一方面，和之前提到的规划模型类似，在一定程度上避免了主题漂移问题。&lt;/p&gt;&lt;p&gt;模型框架图如下：&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-dd229344b12cb194e0ce1fb74073bdac.png" data-rawwidth="434" data-rawheight="734"&gt;生成例子如下：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-f92e829d8a1f266c624ee50eab7a16de.png" data-rawwidth="450" data-rawheight="423"&gt;&lt;h2&gt;SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient&lt;/h2&gt;&lt;p&gt;模型[10]将图像中的对抗生成网络，用到文本生成上。生成网络是一个RNN，直接生成整首诗歌。而判别网络是一个CNN。用于判断这首诗歌是人写的，还是机器生成的，并通过强化学习的方式，将梯度回传给生成网络。模型框架图如下：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-3b5e126f03fcee1b671093f81d598797.png" data-rawwidth="605" data-rawheight="234"&gt;&lt;h1&gt;&lt;b&gt;总结&lt;/b&gt;&lt;/h1&gt;&lt;p&gt;从传统方法到深度学习，诗歌生成技术有了很大发展，甚至在一定程度上，已经可以产生普通人真假难辨的诗歌。但是目前诗歌生成技术，学习到的仍然只是知识的概率分布，即诗句内，诗句间的搭配规律。而没有学到诗歌蕴含思想感情。因此尽管生成的诗歌看起来有模有样，但是仍然感觉只是徒有其表，缺乏一丝人的灵性。另外一方面，诗歌不像机器翻译有BLEU作为评价指标，目前仍然依赖人工的主观评价，缺乏可靠的自动评估方法，因此模型优化的目标函数和主观的诗歌评价指标之间，存在较大的gap，也影响了诗歌生成质量的提高。在围棋博弈上，以AlphaGo为代表的机器已经超过了人类顶尖选手，但是在诗歌生成上，离人类顶尖诗人水平，尚有很长的路要走。&lt;/p&gt;&lt;h1&gt;&lt;b&gt;参考文献&lt;/b&gt;&lt;/h1&gt;&lt;p&gt;[1] &lt;a href="http://www.swarma.org/files/%E8%AE%A1%E7%AE%97%E5%A3%AB2010518131655.pdf"&gt;一种宋词自动生成的遗传算法及其机器实现&lt;/a&gt;[2] &lt;a href="http://homepages.inf.ed.ac.uk/mlap/Papers/IJCAI13-324-1.pdf"&gt;i,Poet: Automatic Chinese Poetry Composition through a Generative Summarization Framework under Constrained Optimization&lt;/a&gt;[3] &lt;a href="https://pdfs.semanticscholar.org/acd4/cd5e964faafa59d063704d99360dfe290525.pdf"&gt;Generating Chinese Classical Poems with Statistical Machine Translation Models&lt;/a&gt;[4] &lt;a href="https://pdfs.semanticscholar.org/47a8/7c2cbdd928bb081974d308b3d9cf678d257e.pdf"&gt;Recurrent neural network based language model&lt;/a&gt;[5] &lt;a href="http://www.aclweb.org/anthology/D14-1074"&gt;Chinese Poetry Generation with Recurrent Neural Networks&lt;/a&gt;[6] &lt;a href="http://%5B1604.06274%5D%20Chinese%20Song%20Iambics%20Generation%20with%20Neural%20Attention-based%20Model"&gt;Chinese Song Iambics Generation with Neural Attention-based Model&lt;/a&gt;[7] &lt;a href="https://www.ijcai.org/Proceedings/16/Papers/319.pdf" data-title="i, Poet: Automatic Poetry Composition through Recurrent Neural Networks with Iterative Polishing Schema" class=""&gt;i, Poet: Automatic Poetry Composition through Recurrent Neural Networks with Iterative Polishing Schema&lt;/a&gt;[8] &lt;a href="http://%5B1610.09889%5D%20Chinese%20Poetry%20Generation%20with%20Planning%20based%20Neural%20Network"&gt;Chinese Poetry Generation with Planning based Neural Network&lt;/a&gt;[9] &lt;a href="http://xingshi.me/data/pdf/EMNLP2016poem-slides.pdf"&gt;Generating Topical Poetry&lt;/a&gt;[10] &lt;a href="http://Sequence%20Generative%20Adversarial%20Nets%20with%20Policy%20Gradient" data-title="SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient" class=""&gt;SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient&lt;/a&gt;&lt;/p&gt;​&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/25084737&amp;pixel&amp;useReferer"/&gt;</description><author>萧瑟</author><pubDate>Sat, 04 Feb 2017 17:50:26 GMT</pubDate></item><item><title>如何获取最新的深度学习资源</title><link>https://zhuanlan.zhihu.com/p/24887133</link><description>&lt;p&gt;很多刚入门深度学习的朋友，往往不知道该如何获取最新的深度学习资源，包括资讯，论文，学习资料等等，有问题也不知道该与谁交流。因此这里分享一些相关途径，希望对大家的学习有所帮助。&lt;/p&gt;&lt;h1&gt;微信公众号&lt;/h1&gt;&lt;p&gt;有很多和深度学习相关的公众号，对学术相关进展的跟进都很及时，可以考虑有选择的关注：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;机器之心&lt;/li&gt;&lt;li&gt;智能立方:&lt;/li&gt;&lt;li&gt;paperweekly&lt;/li&gt;&lt;li&gt;哈工大scir&lt;/li&gt;&lt;li&gt;将门创投&lt;/li&gt;&lt;li&gt;炼丹实验室&lt;/li&gt;&lt;li&gt;机器学习研究会&lt;/li&gt;&lt;li&gt;AI科技评论&lt;/li&gt;&lt;li&gt;全球人工智能&lt;/li&gt;&lt;li&gt;深度学习大讲堂&lt;/li&gt;&lt;/ul&gt;&lt;h1&gt;邮箱订阅&lt;/h1&gt;&lt;p&gt;通过邮箱，订阅一些资源的推送，是很有必要的：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Arxiv：计算机领域，特别是深度学习领域的最新论文，一般都会先出现在Arxiv上，除了天天到Arxiv相关类别刷论文之外，也可以通过邮箱订阅自己感兴趣的类别：&lt;a href="https://arxiv.org/help/subscribe"&gt;To Subscribe to the E-Mail Alerting Service&lt;/a&gt;&lt;/li&gt;&lt;li&gt;好东西传送门：包含机器学习日报，NLP日报，大数据日报，Python日报等很实用的内容，建议订阅：&lt;a href="http://memect.com/"&gt;Memory Connected&lt;/a&gt;&lt;/li&gt;&lt;li&gt;大牛的最新Paper：可以通过Google学术，订阅一些深度学习领域大牛的论文，这样一旦他们有新论文，有可以通过邮件及时得到通知,下面是我的一些订阅，不全，仅供参考：&lt;ul&gt;&lt;li&gt;Geoffrey Hinton&lt;/li&gt;&lt;li&gt;Yann LeCun&lt;/li&gt;&lt;li&gt;Yoshua Bengio&lt;/li&gt;&lt;li&gt;Andrej Karpathy&lt;/li&gt;&lt;li&gt;andrew Y ng&lt;/li&gt;&lt;li&gt;Richard Socher&lt;/li&gt;&lt;li&gt;Tomas Mikolov&lt;/li&gt;&lt;li&gt;Oriol Vinyals&lt;/li&gt;&lt;li&gt;Percy Liang&lt;/li&gt;&lt;li&gt;Jason Weston&lt;/li&gt;&lt;li&gt;Hang Li&lt;/li&gt;&lt;li&gt;Tie-Yan Liu&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h1&gt;知乎专栏&lt;/h1&gt;&lt;p&gt;知乎上有很多和深度学习相关的专栏，而且在知乎上可以很方便的和作者进行互动交流，也是一个很方便的方式，下面是一些我订阅的专栏：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;炼丹实验室&lt;/li&gt;&lt;li&gt;机器之心&lt;/li&gt;&lt;li&gt;超智能体&lt;/li&gt;&lt;li&gt;PaperWeekly&lt;/li&gt;&lt;li&gt;深度学习：从入门到放弃&lt;/li&gt;&lt;li&gt;智能单元&lt;/li&gt;&lt;li&gt;深度学习大讲堂&lt;/li&gt;&lt;/ul&gt;&lt;h1&gt;网站&lt;/h1&gt;&lt;p&gt;这里收藏了一些不错的和深度学习相关的资源网站，可以参考：&lt;a href="http://rsarxiv.github.io%2C/"&gt;http://rsarxiv.github.io,&lt;/a&gt; 经常包含一些最新的Deep Learning in NLP论文中文简介&lt;a href="http://nlp.hivefire.com"&gt;Natural Language Processing (NLP) News&lt;/a&gt; ，包含最新的NLP资讯和论文&lt;a href="https://github.com/dennybritz/deeplearning-papernotes"&gt;dennybritz/deeplearning-papernotes&lt;/a&gt; ，作者在Google Brain，会经常更新一些自己读论文的笔记。&lt;a href="https://www.reddit.com/r/MachineLearning/"&gt;Machine Learning • /r/MachineLearning&lt;/a&gt; ,Reddit的机器学习版，氛围活跃，大牛云集。&lt;/p&gt;&lt;h1&gt;微信交流群&lt;/h1&gt;&lt;ul&gt;&lt;li&gt;PaperWeekly: 想加群，请联系微信号：zhangjun168305, 群里的交流活跃，学术氛围很好。&lt;/li&gt;&lt;li&gt;将门微信群： 里面大牛云集，想加群，请加群请关注&lt;strong&gt;将门创投&lt;/strong&gt;的订阅号，里面有入群方式。&lt;/li&gt;&lt;/ul&gt;&lt;h1&gt;社交网络&lt;/h1&gt;&lt;p&gt;国内大牛一般是微博，国外大牛一般是Twitter,关注一下他们，可以了解到很多第一手的消息。&lt;/p&gt;&lt;p&gt;上面是我平时收集深度学习论文和资讯的方式总结。我觉得更容易面临的问题，不是信息匮乏，而是信息负载，因此在有限的时间里，学会选择适合的阅读内容，更为重要。&lt;/p&gt;​&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/24887133&amp;pixel&amp;useReferer"/&gt;</description><author>萧瑟</author><pubDate>Sun, 15 Jan 2017 11:46:29 GMT</pubDate></item><item><title>Theano调试技巧</title><link>https://zhuanlan.zhihu.com/p/24857032</link><description>&lt;p&gt;转载请注明：&lt;a href="https://zhuanlan.zhihu.com/easyml" data-title="炼丹实验室"&gt;炼丹实验室&lt;/a&gt;Theano是最老牌的深度学习库之一。它灵活的特点使其非常适合学术研究和快速实验，但是它难以调试的问题也遭到过无数吐槽。其实Theano本身提供了很多辅助调试的手段，下面就介绍一些Theano的调试技巧，让Theano调试不再难。而关于深度学习的通用调试技巧，请参见我之前的文章：&lt;a href="https://zhuanlan.zhihu.com/p/20792837"&gt;深度学习网络调试技巧&lt;/a&gt; 。 &lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;以下的技巧和代码均在Theano 0.8.2 上测试通过，不保证在更低的版本上也可以适用。&lt;/p&gt;&lt;/blockquote&gt;&lt;h1&gt;如何定位出错位置&lt;/h1&gt;&lt;p&gt;Theano的网络在出错的时候，往往会提供一些出错信息。但是出错信息往往非常模糊，让人难以直接看出具体是哪一行代码出现了问题。大家看下面的例子：&lt;/p&gt;&lt;pre&gt;&lt;code lang="text"&gt;import theano
import theano.tensor as T
import numpy as np
x = T.vector()
y = T.vector()
z = x + x
z = z + y
f = theano.function([x, y], z)
f(
np.array([1,2],dtype=theano.config.floatX), np.array([3,4,5],dtype=theano.config.floatX))
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;将代码保存到test.py文件中，在命令行中执行：&lt;/p&gt;&lt;pre&gt;&lt;code lang="text"&gt;THEANO_FLAGS="device=gpu0,floatX=float32" python test.py
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;输出结果如下：&lt;/p&gt;&lt;pre&gt;&lt;code lang="text"&gt;Traceback (most recent call last):
  File "test.py", line 10, in &amp;lt;module&amp;gt;    print f(np.array([1,2],dtype='float32'), np.array([3,4,5],dtype='float32'))
  File "/home/wangzhe/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.py", line 871, in __call__
    storage_map=getattr(self.fn, 'storage_map', None))  File "/home/wangzhe/anaconda2/lib/python2.7/site-packages/theano/gof/link.py", line 314, in raise_with_op    reraise(exc_type, exc_value, exc_trace)
  File "/home/wangzhe/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.py", line 859, in __call__
    outputs = self.fn()
ValueError: GpuElemwise. Input dimension mis-match. Input 1 (indices start at 0) has shape[0] == 2, but the output size on that axis is 3.
Apply node that caused the error: GpuElemwise{Composite{((i0 + i1) + i0)}}[(0, 0)](GpuFromHost.0, GpuFromHost.0)
Toposort index: 2
Inputs types: [CudaNdarrayType(float32, vector), CudaNdarrayType(float32, vector)]
Inputs shapes: [(3,), (2,)]
Inputs strides: [(1,), (1,)]
Inputs values: [CudaNdarray([ 3.  4.  5.]), CudaNdarray([ 1.  2.])]
Outputs clients: [[HostFromGpu(GpuElemwise{Composite{((i0 + i1) + i0)}}[(0, 0)].0)]]

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;比较有用的信息是：Input dimension mis-match，但是具体出问题在哪里，仍然让人一头雾水。因为Theano的计算图进行了一些优化，导致出错的时候难以与原始代码对应起来。想解决这个也很简单，就是关闭计算图的优化功能。可以通过THEANO_FLAGS的optimizer,它的默认值是”fast_run”，代表最大程度的优化，我们平时一般就使用这个，但是如果想让调试信息更详细，我们就需要关闭一部分优化:fast_compile或者关闭全部优化：None，这里我们将optimizer设置成”None”，执行如下命令：&lt;/p&gt;&lt;pre&gt;&lt;code lang="text"&gt;THEANO_FLAGS="device=gpu0,floatX=float32,optimizer=None" python test.py
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;结果如下：&lt;/p&gt;&lt;pre&gt;&lt;code lang="text"&gt;Traceback (most recent call last):
  File "test.py", line 10, in &amp;lt;module&amp;gt;
    print f(np.array([1,2],dtype='float32'), np.array([3,4,5],dtype='float32'))
  File "/home/wangzhe/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.py", line 871, in __call__
    storage_map=getattr(self.fn, 'storage_map', None))
  File "/home/wangzhe/anaconda2/lib/python2.7/site-packages/theano/gof/link.py", line 314, in raise_with_op
    reraise(exc_type, exc_value, exc_trace)
  File "/home/wangzhe/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.py", line 859, in __call__
    outputs = self.fn()
ValueError: Input dimension mis-match. (input[0].shape[0] = 3, input[1].shape[0] = 2)
Apply node that caused the error: Elemwise{add,no_inplace}(&amp;lt;TensorType(float32, vector)&amp;gt;, &amp;lt;TensorType(float32, vector)&amp;gt;)
Toposort index: 0
Inputs types: [TensorType(float32, vector), TensorType(float32, vector)]
Inputs shapes: [(3,), (2,)]
Inputs strides: [(4,), (4,)]
Inputs values: [array([ 3.,  4.,  5.], dtype=float32), array([ 1.,  2.], dtype=float32)]
Outputs clients: [[Elemwise{add,no_inplace}(Elemwise{add,no_inplace}.0, &amp;lt;TensorType(float32, vector)&amp;gt;)]]

Backtrace when the node is created(use Theano flag traceback.limit=N to make it longer):
  File "test.py", line 7, in &amp;lt;module&amp;gt;
    z = y + x

HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;可以看到，这次直接提示出错的位置在代码的第7行：z = y + x，这个是不是方便很多了呢？&lt;/p&gt;&lt;h1&gt;如何打印中间结果&lt;/h1&gt;&lt;p&gt;下面分别介绍Test Values和Print两种方法。&lt;/p&gt;&lt;h2&gt;使用Test Values&lt;/h2&gt;&lt;p&gt;我曾见过有人为了保证中间运算的实现没有问题，先用numpy实现了一遍，检查每一步运算结果符合预期以后，再移值改成Theano版的，其实大可不必这么折腾。Theano在0.4.0以后，加入了test values机制，简单来说，就是在计算图编译之前，我们可以给symbolic提供一个具体的值，即test_value，这样Theano就可以将这些数据，代入到symbolic表达式的计算过程中，从而完成计算过程的验证，并可以打印出中间过程的运算结果。大家看下面的例子：&lt;/p&gt;&lt;pre&gt;&lt;code lang="text"&gt;import theano
import theano.tensor as T
import numpy as np
x = T.vector()
x.tag.test_value = np.array([1,2],dtype=theano.config.floatX)

y = T.vector()                                      y.tag.test_value = np.array([3,4,5],dtype=theano.config.floatX)
z = x + x
print z.tag.test_value
z = z + y
print z.tag.test_value
f = theano.function([x, y], z)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;运行的时候，需要注意，如果需要使用test_value,那么需要设置一下compute_test_value的标记，有以下几种&lt;/p&gt;&lt;ul&gt;&lt;li&gt;off: 关闭，建议在调试没有问题以后，使用off，以提高程序速度。&lt;/li&gt;&lt;li&gt;ignore: test_value计算出错，不会报错&lt;/li&gt;&lt;li&gt;warn: test_value计算出错，进行警告&lt;/li&gt;&lt;li&gt;raise: test_value计算出错，会产出错误&lt;/li&gt;&lt;li&gt;pdb: test_value计算出错，会进入pdb调试。pdb是python自带的调试工具，在pdb里面可以单步查看各变量的值，甚至执行任意python代码，非常强大，如果想看中间过程，又懒得打太多print，那么可以import pdb然后在你想设断点的地方加上：pdb.set_trace()，后面可以用指令n单步，c继续执行。更详细的介绍可以参考这里：&lt;a href="https://docs.python.org/2/library/pdb.html"&gt;26.2. pdb - The Python Debugger - Python 2.7.13 documentation&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;下面继续回到test_value，我们将test_value值修改成warn，执行：&lt;/p&gt;&lt;pre&gt;&lt;code lang="text"&gt;THEANO_FLAGS="device=gpu0,floatX=float32,compute_test_value=warn" python test.py
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;结果如下：&lt;/p&gt;&lt;pre&gt;&lt;code lang="text"&gt;[ 2.  4.]
log_thunk_trace: There was a problem executing an Op.
Traceback (most recent call last):
  File "test.py", line 12, in &amp;lt;module&amp;gt;
    z = z + y
  File "/home/wangzhe/anaconda2/lib/python2.7/site-packages/theano/tensor/var.py", line 135, in __add__
    return theano.tensor.basic.add(self, other)
  File "/home/wangzhe/anaconda2/lib/python2.7/site-packages/theano/gof/op.py", line 668, in __call__
    required = thunk()
  File "/home/wangzhe/anaconda2/lib/python2.7/site-packages/theano/gof/op.py", line 883, in rval
    fill_storage()
  File "/home/wangzhe/anaconda2/lib/python2.7/site-packages/theano/gof/cc.py", line 1707, in __call__
    reraise(exc_type, exc_value, exc_trace)
  File "&amp;lt;string&amp;gt;", line 2, in reraiseValueError: Input dimension mis-match. (input[0].shape[0] = 2, input[1].shape[0] = 3)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;可以看到，第一个z的值[2,4]被print了出来，同时在test_value的帮助下，错误信息还告诉我们在执行z = z + y 这一行的时候有问题。因此test_value也可以起到，检测哪一行出错的功能。&lt;b&gt;小技巧: &lt;/b&gt;人工一个个构造test_value,实在太麻烦，因此可以考虑在训练开始前，从训练数据中随机选一条，作为test_value,这样还能辅助检测，训练数据有没有问题。&lt;/p&gt;&lt;h2&gt;使用Print&lt;/h2&gt;&lt;p&gt;不过test_value对scan支持的不好，而如果网络包含RNN的话，scan一般是不可或缺的。那么如何打印出scan在循环过程中的中间结果呢？这里我们可以使用theano.printing.Print()，代码如下：&lt;/p&gt;&lt;pre&gt;&lt;code lang="text"&gt;import theano
import theano.tensor as T
import numpy as np
x = T.vector()
y = T.vector()
z = x + x
z = theano.printing.Print('z1')(z)
z = z + y
z = theano.printing.Print('z2')(z)
f = theano.function([x, y], z)
f(np.array([1,2],dtype=theano.config.floatX),np.array([1,2],dtype=theano.config.floatX))
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;执行：&lt;/p&gt;&lt;pre&gt;&lt;code lang="text"&gt;THEANO_FLAGS="device=gpu0,floatX=float32" python test.py
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;结果如下：&lt;/p&gt;&lt;pre&gt;&lt;code lang="text"&gt;z1 __str__ = [ 2.  4.]
z2 __str__ = [ 3.  6.]
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;不过下面有几点需要注意一下：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;因为theano是基于计算图的，因此各变量在计算图中被调用执行的顺序，不一定和原代码的顺序一样，因此变量Print出来的顺序也是无法保证的。&lt;/li&gt;&lt;li&gt;Print方法，会比较严重的拖慢训练的速度，因此最终用于训练的代码，最好把Print去除。&lt;/li&gt;&lt;li&gt;Print方法会阻止一些计算图的优化，包括一些结果稳定性的优化，因此如果程序出现Nan问题，可以考虑把Print去除，再看看。&lt;/li&gt;&lt;/ul&gt;&lt;h1&gt;如何处理Nan&lt;/h1&gt;&lt;p&gt;Nan是我们经常遇到的一个问题，我之前的文章：&lt;a href="http://%E7%9F%A5%E4%B9%8E%E4%B8%93%E6%A0%8F"&gt;深度学习网络调试技巧&lt;/a&gt; 提到了如何处理Nan问题，其中最重要的步骤，是确定Nan最开始出现的位置。一个比较暴力的方法，是打印出变量的中间结果，看看Nan是从哪里开始的，不过这样工作量有点太大了。所以这里介绍另外一个比较省事的方法：NanGuardMode。NanGuardMode会监测指定的function，是否在计算过程中出现nan,inf。如果出现，会立刻报错，这时配合前面提到的optimizer=None，我们就可以直接定位到，具体是哪一行代码最先出现了Nan问题。代码如下：&lt;/p&gt;&lt;pre&gt;&lt;code lang="text"&gt;import theano
import theano.tensor as T
import numpy as np
from theano.compile.nanguardmode import NanGuardMode
x = T.matrix()
w = theano.shared(np.random.randn(5, 7).astype(theano.config.floatX))
y = T.dot(x, w)
fun = theano.function(
            [x], y,
mode=NanGuardMode(nan_is_error=True,inf_is_error=True, big_is_error=True)
)
infa = np.tile(
            (np.asarray(100.) ** 1000000).astype(theano.config.floatX), (3, 5))
fun(infa)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;执行：&lt;/p&gt;&lt;pre&gt;&lt;code lang="text"&gt;THEANO_FLAGS="device=gpu0,floatX=float32,optimizer=None" python test.py
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;结果如下：&lt;/p&gt;&lt;pre&gt;&lt;code lang="text"&gt;Traceback (most recent call last):
  File "test.py", line 12, in &amp;lt;module&amp;gt;
    f(np.array([1,2],dtype='float32'),np.array([0,0],dtype='float32'))
  File "/home/wangzhe/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.py", line 859, in __call__
    outputs = self.fn()
Backtrace when the node is created(use Theano flag traceback.limit=N to make it longer):
  File "/home/wangzhe/anaconda2/lib/python2.7/site-packages/theano/gof/link.py", line 1014, in f
    raise_with_op(node, *thunks)
  File "/home/wangzhe/anaconda2/lib/python2.7/site-packages/theano/gof/link.py", line 314, in raise_with_op
    reraise(exc_type, exc_value, exc_trace)
  File "/home/wangzhe/anaconda2/lib/python2.7/site-packages/theano/gof/link.py", line 1012, in f
    wrapper(i, node, *thunks)
  File "/home/wangzhe/anaconda2/lib/python2.7/site-packages/theano/compile/nanguardmode.py", line 307, in nan_check
  File "/home/wangzhe/anaconda2/lib/python2.7/site-packages/theano/gof/link.py", line 1012, in f
    wrapper(i, node, *thunks)
  File "/home/wangzhe/anaconda2/lib/python2.7/site-packages/theano/compile/nanguardmode.py", line 302, in nan_check
    do_check_on(x[0], node, fn, True)
  File "/home/wangzhe/anaconda2/lib/python2.7/site-packages/theano/compile/nanguardmode.py", line 272, in do_check_on
    raise AssertionError(msg)
AssertionError: Inf detected
Big value detected
NanGuardMode found an error in an input of this node.
Node:
dot(&amp;lt;TensorType(float32, matrix)&amp;gt;, HostFromGpu.0)
The input variable that cause problem:
dot [id A] ''   
 |&amp;lt;TensorType(float32, matrix)&amp;gt; [id B]
 |HostFromGpu [id C] ''   
   |&amp;lt;CudaNdarrayType(float32, matrix)&amp;gt; [id D]

Apply node that caused the error: dot(&amp;lt;TensorType(float32, matrix)&amp;gt;, HostFromGpu.0)
Toposort index: 1
Inputs types: [TensorType(float32, matrix), TensorType(float32, matrix)]
Inputs shapes: [(3, 5), (5, 7)]
Inputs strides: [(20, 4), (28, 4)]
Inputs values: ['not shown', 'not shown']
Outputs clients: [['output']]

Backtrace when the node is created(use Theano flag traceback.limit=N to make it longer):
  File "test.py", line 8, in &amp;lt;module&amp;gt;
    y = T.dot(x, w)

HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;可以看到，是y = T.dot(x, w)这一行，产生的Nan.&lt;/p&gt;&lt;h1&gt;其他&lt;/h1&gt;&lt;p&gt;上面的几个技巧，相信可以解决大部分Theano调试中遇到的问题. 同时我们在用Theano实现一些网络结构，例如LSTM的时候，除了直接参考论文之外，这里强烈推荐参考keras进行实现。keras是一个更顶层的库，同时支持Theano和Tensorflow作为后台，里面大部分模型的实现都很可靠，可以学习和参考。&lt;/p&gt;&lt;h1&gt;参考资料&lt;/h1&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="http://deeplearning.net/software/theano/library/compile/nanguardmode.html#nanguardmode"&gt;nanguardmode - Theano 0.8.2 documentation&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="http://deeplearning.net/software/theano/tutorial/debug_faq.html"&gt;Debugging Theano: FAQ and Troubleshooting&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;​&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/24857032&amp;pixel&amp;useReferer"/&gt;</description><author>萧瑟</author><pubDate>Fri, 13 Jan 2017 01:43:41 GMT</pubDate></item><item><title>深度学习网络调参技巧</title><link>https://zhuanlan.zhihu.com/p/24720954</link><description>&lt;p&gt;转载请注明：&lt;a href="https://zhuanlan.zhihu.com/easyml" data-editable="true" data-title="知乎专栏" class=""&gt;炼丹实验室&lt;/a&gt;&lt;/p&gt;&lt;p&gt;之前曾经写过一篇文章，讲了一些深度学习训练的技巧，其中包含了部分调参心得：&lt;a href="https://zhuanlan.zhihu.com/p/20767428" data-editable="true" data-title="深度学习训练心得"&gt;深度学习训练心得&lt;/a&gt;。不过由于一般深度学习实验，相比普通机器学习任务，时间较长，因此调参技巧就显得尤为重要。同时个人实践中，又有一些新的调参心得，因此这里单独写一篇文章，谈一下自己对深度学习调参的理解，大家如果有其他技巧，也欢迎多多交流。&lt;/p&gt;&lt;h1&gt;好的实验环境是成功的一半&lt;/h1&gt;&lt;p&gt;由于深度学习实验超参众多，代码风格良好的实验环境，可以让你的人工或者自动调参更加省力，有以下几点可能需要注意：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;将各个参数的设置部分集中在一起。如果参数的设置分布在代码的各个地方，那么修改的过程想必会非常痛苦。&lt;/li&gt;&lt;li&gt;可以输出模型的损失函数值以及训练集和验证集上的准确率。&lt;/li&gt;&lt;li&gt;可以考虑设计一个子程序，可以根据给定的参数，启动训练并监控和周期性保存评估结果。再由一个主程序，分配参数以及并行启动一系列子程序。&lt;/li&gt;&lt;/ul&gt;&lt;h1&gt;画图&lt;/h1&gt;&lt;p&gt;画图是一个很好的习惯，一般是训练数据遍历一轮以后，就输出一下训练集和验证集准确率。同时画到一张图上。这样训练一段时间以后，如果模型一直没有收敛，那么就可以停止训练，尝试其他参数了，以节省时间。 如果训练到最后，训练集，测试集准确率都很低，那么说明模型有可能欠拟合。那么后续调节参数方向，就是增强模型的拟合能力。例如增加网络层数，增加节点数，减少dropout值，减少L2正则值等等。 如果训练集准确率较高，测试集准确率比较低，那么模型有可能过拟合，这个时候就需要向提高模型泛化能力的方向，调节参数。&lt;/p&gt;&lt;h1&gt;从粗到细分阶段调参&lt;/h1&gt;&lt;p&gt;实践中，一般先进行初步范围搜索，然后根据好结果出现的地方，再缩小范围进行更精细的搜索。&lt;/p&gt;&lt;ol&gt;&lt;li&gt;建议先参考相关论文，以论文中给出的参数作为初始参数。至少论文中的参数，是个不差的结果。&lt;/li&gt;&lt;li&gt;如果找不到参考，那么只能自己尝试了。可以先从比较重要，对实验结果影响比较大的参数开始，同时固定其他参数，得到一个差不多的结果以后，在这个结果的基础上，再调其他参数。例如学习率一般就比正则值，dropout值重要的话，学习率设置的不合适，不仅结果可能变差，模型甚至会无法收敛。&lt;/li&gt;&lt;li&gt;如果实在找不到一组参数，可以让模型收敛。那么就需要检查，是不是其他地方出了问题，例如模型实现，数据等等。可以参考我写的&lt;a href="https://zhuanlan.zhihu.com/p/20792837" data-editable="true" data-title="深度学习网络调试技巧"&gt;深度学习网络调试技巧&lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h1&gt;提高速度&lt;/h1&gt;&lt;p&gt;调参只是为了寻找合适的参数，而不是产出最终模型。一般在小数据集上合适的参数，在大数据集上效果也不会太差。因此可以尝试对数据进行精简，以提高速度，在有限的时间内可以尝试更多参数。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;对训练数据进行采样。例如原来100W条数据，先采样成1W，进行实验看看。&lt;/li&gt;&lt;li&gt;减少训练类别。例如手写数字识别任务，原来是10个类别，那么我们可以先在2个类别上训练，看看结果如何。&lt;/li&gt;&lt;/ul&gt;&lt;h1&gt;超参数范围&lt;/h1&gt;&lt;p&gt;建议优先在对数尺度上进行超参数搜索。比较典型的是学习率和正则化项，我们可以从诸如0.001 0.01 0.1 1 10，以10为阶数进行尝试。因为他们对训练的影响是相乘的效果。不过有些参数，还是建议在原始尺度上进行搜索，例如dropout值: 0.3 0.5 0.7)。&lt;/p&gt;&lt;h1&gt;经验参数&lt;/h1&gt;&lt;p&gt;这里给出一些参数的经验值，避免大家调参的时候，毫无头绪。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;learning rate: 1 0.1 0.01 0.001, 一般从1开始尝试。很少见learning rate大于10的。学习率一般要随着训练进行衰减。衰减系数一般是0.5。 衰减时机，可以是验证集准确率不再上升时，或固定训练多少个周期以后。 不过更建议使用自适应梯度的办法，例如adam,adadelta,rmsprop等，这些一般使用相关论文提供的默认值即可，可以避免再费劲调节学习率。对RNN来说，有个经验，如果RNN要处理的序列比较长，或者RNN层数比较多，那么learning rate一般小一些比较好，否则有可能出现结果不收敛，甚至Nan等问题。&lt;/li&gt;&lt;li&gt;网络层数： 先从1层开始。&lt;/li&gt;&lt;li&gt;每层结点数： 16 32 128，超过1000的情况比较少见。超过1W的从来没有见过。&lt;/li&gt;&lt;li&gt;batch size: 128上下开始。batch size值增加，的确能提高训练速度。但是有可能收敛结果变差。如果显存大小允许，可以考虑从一个比较大的值开始尝试。因为batch size太大，一般不会对结果有太大的影响，而batch size太小的话，结果有可能很差。&lt;/li&gt;&lt;li&gt;clip c(梯度裁剪): 限制最大梯度,其实是value = sqrt(w1^2+w2^2….),如果value超过了阈值，就算一个衰减系系数,让value的值等于阈值: 5,10,15&lt;/li&gt;&lt;li&gt;dropout： 0.5&lt;/li&gt;&lt;li&gt;L2正则：1.0，超过10的很少见。&lt;/li&gt;&lt;li&gt;词向量embedding大小：128，256&lt;/li&gt;&lt;li&gt;正负样本比例： 这个是非常忽视，但是在很多分类问题上，又非常重要的参数。很多人往往习惯使用训练数据中默认的正负类别比例，当训练数据非常不平衡的时候，模型很有可能会偏向数目较大的类别，从而影响最终训练结果。除了尝试训练数据默认的正负类别比例之外，建议对数目较小的样本做过采样，例如进行复制。提高他们的比例，看看效果如何，这个对多分类问题同样适用。 在使用mini-batch方法进行训练的时候，尽量让一个batch内，各类别的比例平衡，这个在图像识别等多分类任务上非常重要。&lt;/li&gt;&lt;/ul&gt;&lt;h1&gt;自动调参&lt;/h1&gt;&lt;p&gt;人工一直盯着实验，毕竟太累。自动调参当前也有不少研究。下面介绍几种比较实用的办法：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Gird Search. 这个是最常见的。具体说，就是每种参数确定好几个要尝试的值，然后像一个网格一样，把所有参数值的组合遍历一下。优点是实现简单暴力，如果能全部遍历的话，结果比较可靠。缺点是太费时间了，特别像神经网络，一般尝试不了太多的参数组合。&lt;/li&gt;&lt;li&gt;Random Search。Bengio在&lt;a href="http://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf" data-editable="true" data-title="Random Search for Hyper-Parameter Optimization"&gt;Random Search for Hyper-Parameter Optimization&lt;/a&gt;中指出，Random Search比Gird Search更有效。实际操作的时候，一般也是先用Gird Search的方法，得到所有候选参数，然后每次从中随机选择进行训练。&lt;/li&gt;&lt;li&gt;Bayesian Optimization. 贝叶斯优化，考虑到了不同参数对应的实验结果值，因此更节省时间。和网络搜索相比简直就是老牛和跑车的区别。具体原理可以参考这个论文： &lt;a href="http://papers.nips.cc/paper/4522-practical-bayesian-optimization-of-machine-learning-algorithms.pdf" data-editable="true" data-title="Practical Bayesian Optimization of Machine Learning Algorithms"&gt;Practical Bayesian Optimization of Machine Learning Algorithms&lt;/a&gt; ，这里同时推荐两个实现了贝叶斯调参的Python库，可以上手即用：&lt;ul&gt;&lt;li&gt;&lt;a href="https://github.com/jaberg/hyperopt" data-editable="true" data-title="jaberg/hyperopt"&gt;jaberg/hyperopt&lt;/a&gt;, 比较简单。&lt;/li&gt;&lt;li&gt;&lt;a href="https://github.com/fmfn/BayesianOptimization" data-editable="true" data-title="fmfn/BayesianOptimization"&gt;fmfn/BayesianOptimization&lt;/a&gt;， 比较复杂，支持并行调参。&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h1&gt;总结&lt;/h1&gt;&lt;ul&gt;&lt;li&gt;合理性检查，确定模型，数据和其他地方没有问题。&lt;/li&gt;&lt;li&gt;训练时跟踪损失函数值，训练集和验证集准确率。&lt;/li&gt;&lt;li&gt;使用Random Search来搜索最优超参数，分阶段从粗（较大超参数范围训练较少周期）到细（较小超参数范围训练较长周期）进行搜索。&lt;/li&gt;&lt;/ul&gt;&lt;h1&gt;参考资料&lt;/h1&gt;&lt;p&gt;这里列了一些参数资料，大家有时间，可以进一步阅读。 &lt;a href="https://arxiv.org/abs/1206.5533" data-editable="true" data-title="Practical recommendations for gradient-based training of deep architectures by Yoshua Bengio (2012)"&gt;Practical recommendations for gradient-based training of deep architectures by Yoshua Bengio (2012)&lt;/a&gt;&lt;a href="http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf" data-editable="true" data-title="Efficient BackProp, by Yann LeCun, Léon Bottou, Genevieve Orr and Klaus-Robert Müller"&gt;Efficient BackProp, by Yann LeCun, Léon Bottou, Genevieve Orr and Klaus-Robert Müller&lt;/a&gt;&lt;a href="http://www.springer.com/computer/theoretical+computer+science/book/978-3-642-35288-1" data-editable="true" data-title="Neural Networks: Tricks of the Trade, edited by Grégoire Montavon, Geneviève Orr, and Klaus-Robert Müller."&gt;Neural Networks: Tricks of the Trade, edited by Grégoire Montavon, Geneviève Orr, and Klaus-Robert Müller.&lt;/a&gt;&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/24720954&amp;pixel&amp;useReferer"/&gt;</description><author>萧瑟</author><pubDate>Thu, 05 Jan 2017 00:56:47 GMT</pubDate></item><item><title>深度学习模型使用word2vec向量的方法总结</title><link>https://zhuanlan.zhihu.com/p/22018256</link><description>&lt;p&gt;转载请注明：&lt;a href="https://zhuanlan.zhihu.com/easyml" data-editable="true" data-title="知乎专栏" class=""&gt;炼丹实验室&lt;/a&gt;&lt;/p&gt;&lt;p&gt;使用word2vec工具在大规模外部文本语料上训练得到的向量，可以比较精确的衡量词之间的相关程度。一个比较简单的应用，就是利用词之间的向量的cos得分，来找相关词。同时word2vec向量，也可以用于深度学习模型的训练，使深度学习模型可以利用这种相关性，从而提高收敛速度和最终结果。但是实际使用的时候，有很多方式可供选择。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;直接用word2vec向量初始化模型embedding,训练的时候允许embedding向量更新。 这个方法最为常用，但是遇到不在训练语料中的词，就不能借助外部word2vec向量了。&lt;/li&gt;&lt;li&gt;word2vec向量，先连接全连接层（可以是多层），转化后的向量再作为模型的embedding,训练的时候，word2vec向量保持不变，允许全连接层的参数更新。 这个方法，哪怕遇到不在训练语料中的词，只要这个词在外部大规模语料中，能得到word2vec向量，那么就没问题。同时因为word2vec向量在训练的时候固定，因此模型训练涉及的参数会大大减少。 因为word2vec向量的分布，和模型实际需要的向量分布，可能存在差异，因此这个全连接层的作用，就是对word2vec向量的分布进行调整，让他尽可能接近模型需要的向量分布。&lt;/li&gt;&lt;li&gt;将word2vec向量拷贝，得到向量A和向量B，训练的时候，向量A保持不变，允许向量B的参数更新，最终embedding向量是A和B的平均。 具体请参考&lt;a href="https://arxiv.org/abs/1408.5882"&gt;https://arxiv.org/abs/1408.5882&lt;/a&gt;这个idea的想法，其实是限制word2vec向量的调整，避免调整的时候，太偏离原始向量。&lt;/li&gt;&lt;li&gt;&lt;ol&gt;&lt;li&gt;第一轮训练，用word2vec向量初始化embedding,对未知词随机初始化embedding,在训练的时候,固定住word2vec初始化的embedding,而允许未知词的embedding进行调整&lt;/li&gt;&lt;li&gt;第二轮训练，允许所有embedding调整,继续训练 这个idea也可以很好的处理未知词，第一轮的时候，因为固定了word2vec向量，因此模型会尽可能基于word2vec向量的分布来调整自己的参数。但是可能分布差异太大，导致模型参数无论怎么调整，都得不到最好结果。因此第二轮的时候，允许word2vec向量进行适当调整。具体请参考&lt;a href="https://arxiv.org/abs/1507.04808"&gt;https://arxiv.org/abs/1507.04808&lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;参考论文&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;a href="https://arxiv.org/abs/1507.04808" data-title="2016-AAAI-Building End-to-End Dialogue Systems Using Generative Hierarchical Neural Network Models" class="" data-editable="true"&gt;2016-AAAI-Building End-to-End Dialogue Systems Using Generative Hierarchical Neural Network Models&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://arxiv.org/abs/1408.5882" data-title="2014-EMNLP-Convolutional Neural Networks for Sentence Classification" class="" data-editable="true"&gt;2014-EMNLP-Convolutional Neural Networks for Sentence Classification&lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ul&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/22018256&amp;pixel&amp;useReferer"/&gt;</description><author>萧瑟</author><pubDate>Mon, 15 Aug 2016 12:52:55 GMT</pubDate></item><item><title>深度学习网络调试技巧</title><link>https://zhuanlan.zhihu.com/p/20792837</link><description>&lt;p&gt;转载请注明：&lt;a href="https://zhuanlan.zhihu.com/easyml" data-editable="true" data-title="知乎专栏" class=""&gt;炼丹实验室&lt;/a&gt;&lt;/p&gt;&lt;p&gt;神经网络的代码，比一般的代码要难调试不少，和编译错误以及运行时程序崩溃相比，神经网络比较棘手的地方，往往在于程序运行正常，但是结果无法收敛，这个检查起来可要麻烦多了。下面是根据我平时调试神经网络的经验，总结的一些比较通用的调试技巧，后续会再写一篇文章，专门介绍一下theano如何进行调试，希望能对大家调试神经网络有所帮助。&lt;/p&gt;&lt;h1&gt;遇到Nan怎么办？&lt;/h1&gt;&lt;p&gt;Nan问题，我相信大部分人都遇到过，一般可能是下面几个原因造成的：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;除0问题。这里实际上有两种可能，一种是被除数的值是无穷大，即Nan，另一种就是除数的值是0。之前产生的Nan或者0，有可能会被传递下去，造成后面都是Nan。请先检查一下神经网络中有可能会有除法的地方，例如softmax层，再认真的检查一下数据。我有一次帮别人调试代码，甚至还遇到过，训练数据文件中，有些值就是Nan。。。这样读进来以后，开始训练，只要遇到Nan的数据，后面也就Nan了。可以尝试加一些日志，把神经网络的中间结果输出出来，看看哪一步开始出现Nan。后面会介绍Theano的处理办法。&lt;/li&gt;&lt;li&gt;梯度过大，造成更新后的值为Nan。特别是RNN，在序列比较长的时候，很容易出现梯度爆炸的问题。一般有以下几个解决办法。&lt;ol&gt;&lt;li&gt;对梯度做clip(梯度裁剪），限制最大梯度,其实是value = sqrt(w1^2+w2^2….),如果value超过了阈值,就算一个衰减系系数,让value的值等于阈值: 5,10,15。&lt;/li&gt;&lt;li&gt;减少学习率。初始学习率过大，也有可能造成这个问题。需要注意的是，即使使用adam之类的自适应学习率算法进行训练，也有可能遇到学习率过大问题，而这类算法，一般也有一个学习率的超参，可以把这个参数改的小一些。&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;初始参数值过大，也有可能出现Nan问题。输入和输出的值，最好也做一下归一化。具体方法可以参考我之前的一篇文章：&lt;a href="http://zhuanlan.zhihu.com/p/20767428" class="" data-editable="true" data-title="深度学习个人炼丹心得 - 炼丹实验室 - 知乎专栏"&gt;深度学习个人炼丹心得 - 炼丹实验室 - 知乎专栏&lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h1&gt;神经网络学不出东西怎么办？&lt;/h1&gt;&lt;p&gt;可能我们并没有遇到，或者解决了Nan等问题，网络一直在正常的训练，但是cost降不下来，预测的时候，结果不正常。&lt;/p&gt;&lt;ol&gt;&lt;li&gt;请打印出训练集的cost值和测试集上cost值的变化趋势，正常情况应该是训练集的cost值不断下降，最后趋于平缓，或者小范围震荡，测试集的cost值先下降，然后开始震荡或者慢慢上升。如果训练集cost值不下降，有可能是代码有bug，有可能是数据有问题（本身有问题，数据处理有问题等等），有可能是超参（网络大小，层数，学习率等）设置的不合理。 请人工构造10条数据，用神经网络反复训练，看看cost是否下降，如果还不下降，那么可能网络的代码有bug，需要认真检查了。如果cost值下降，在这10条数据上做预测，看看结果是不是符合预期。那么很大可能网络本身是正常的。那么可以试着检查一下超参和数据是不是有问题。&lt;/li&gt;&lt;li&gt;如果神经网络代码，全部是自己实现的，那么强烈建议做梯度检查。确保梯度计算没有错误。&lt;/li&gt;&lt;li&gt;先从最简单的网络开始实验，不要仅仅看cost值，还要看一看神经网络的预测输出是什么样子，确保能跑出预期结果。例如做语言模型实验的时候，先用一层RNN，如果一层RNN正常，再尝试LSTM，再进一步尝试多层LSTM。&lt;/li&gt;&lt;li&gt;如果可能的话，可以输入一条指定数据，然后自己计算出每一步正确的输出结果，再检查一下神经网络每一步的结果，是不是一样的。&lt;/li&gt;&lt;/ol&gt;&lt;h1&gt;参考资料&lt;/h1&gt;&lt;p&gt;&lt;a href="http://russellsstewart.com/notes/0.html" data-editable="true" data-title="russellsstewart.com 的页面"&gt;http://russellsstewart.com/notes/0.html&lt;/a&gt;&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/20792837&amp;pixel&amp;useReferer"/&gt;</description><author>萧瑟</author><pubDate>Sat, 23 Apr 2016 13:26:14 GMT</pubDate></item><item><title>深度学习网络训练技巧汇总</title><link>https://zhuanlan.zhihu.com/p/20767428</link><description>&lt;p&gt;转载请注明：&lt;a href="https://zhuanlan.zhihu.com/easyml" data-editable="true" data-title="知乎专栏" class=""&gt;炼丹实验室&lt;/a&gt;&lt;/p&gt;&lt;p&gt;新开了一个专栏，为什么叫炼丹实验室呢，因为以后会在这个专栏里分享一些关于深度学习相关的实战心得，而深度学习很多人称它为玄学，犹如炼丹一般。不过即使是炼丹也是可以摸索出一些经验规律的，希望和各位炼丹术士一起多多交流。&lt;/p&gt;训练技巧对深度学习来说是非常重要的，作为一门实验性质很强的科学，同样的网络结构使用不同的训练方法训练，结果可能会有很大的差异。这里我总结了近一年来的炼丹心得，分享给大家，也欢迎大家补充指正。&lt;ol&gt;&lt;li&gt;&lt;p&gt;参数初始化,下面几种方式,随便选一个,结果基本都差不多。但是一定要做。否则可能会减慢收敛速度，影响收敛结果，甚至造成Nan等一系列问题。&lt;/p&gt;&lt;/li&gt;&lt;ol&gt;&lt;li&gt;uniform W = np.random.uniform(low=-scale, high=scale, size=shape)&lt;/li&gt;&lt;li&gt;glorot_uniform scale = np.sqrt(6. / (shape[0] + shape[1])) np.random.uniform(low=-scale, high=scale, size=shape)&lt;/li&gt;&lt;li&gt;高斯初始化: w = np.random.randn(n) / sqrt(n),n为参数数目 激活函数为relu的话,推荐 w = np.random.randn(n) * sqrt(2.0/n)&lt;/li&gt;&lt;li&gt;svd ,对RNN效果比较好,可以有效提高收敛速度.&lt;/li&gt;&lt;/ol&gt;&lt;li&gt;&lt;p&gt;数据预处理方式&lt;/p&gt;&lt;ol&gt;&lt;li&gt;zero-center ,这个挺常用的.X -= np.mean(X, axis = 0) # zero-center X /= np.std(X, axis = 0) # normalize&lt;/li&gt;&lt;li&gt;PCA whitening,这个用的比较少.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;训练技巧&lt;/p&gt;&lt;ol&gt;&lt;li&gt;要做梯度归一化,即算出来的梯度除以minibatch size&lt;/li&gt;&lt;li&gt;clip c(梯度裁剪): 限制最大梯度,其实是value = sqrt(w1^2+w2^2….),如果value超过了阈值,就算一个衰减系系数,让value的值等于阈值: 5,10,15&lt;/li&gt;&lt;li&gt;dropout对小数据防止过拟合有很好的效果,值一般设为0.5,小数据上dropout+sgd在我的大部分实验中，效果提升都非常明显.因此可能的话，建议一定要尝试一下。 dropout的位置比较有讲究, 对于RNN,建议放到输入-&amp;gt;RNN与RNN-&amp;gt;输出的位置.关于RNN如何用dropout,可以参考这篇论文:&lt;a href="https://link.zhihu.com/?target=http%3A//arxiv.org/abs/1409.2329" class="" data-editable="true" data-title="http://arxiv.org/abs/1409.2329"&gt;http://arxiv.org/abs/1409.2329&lt;/a&gt;&lt;/li&gt;&lt;li&gt;adam,adadelta等,在小数据上,我这里实验的效果不如sgd, sgd收敛速度会慢一些，但是最终收敛后的结果，一般都比较好。如果使用sgd的话,可以选择从1.0或者0.1的学习率开始,隔一段时间,在验证集上检查一下,如果cost没有下降,就对学习率减半. 我看过很多论文都这么搞,我自己实验的结果也很好. 当然,也可以先用ada系列先跑,最后快收敛的时候,更换成sgd继续训练.同样也会有提升.据说adadelta一般在分类问题上效果比较好，adam在生成问题上效果比较好。&lt;/li&gt;&lt;li&gt;除了gate之类的地方,需要把输出限制成0-1之外,尽量不要用sigmoid,可以用tanh或者relu之类的激活函数.1. sigmoid函数在-4到4的区间里，才有较大的梯度。之外的区间，梯度接近0，很容易造成梯度消失问题。2. 输入0均值，sigmoid函数的输出不是0均值的。&lt;/li&gt;&lt;li&gt;rnn的dim和embdding size,一般从128上下开始调整. batch size,一般从128左右开始调整.batch size合适最重要,并不是越大越好.&lt;/li&gt;&lt;li&gt;word2vec初始化,在小数据上,不仅可以有效提高收敛速度,也可以可以提高结果.&lt;/li&gt;&lt;li&gt;尽量对数据做shuffle&lt;/li&gt;&lt;li&gt;LSTM 的forget gate的bias,用1.0或者更大的值做初始化,可以取得更好的结果,来自这篇论文:&lt;a href="https://link.zhihu.com/?target=http%3A//jmlr.org/proceedings/papers/v37/jozefowicz15.pdf" class="" data-editable="true" data-title="http://jmlr.org/proceedings/papers/v37/jozefowicz15.pdf"&gt;http://jmlr.org/proceedings/papers/v37/jozefowicz15.pdf&lt;/a&gt;, 我这里实验设成1.0,可以提高收敛速度.实际使用中,不同的任务,可能需要尝试不同的值.&lt;/li&gt;&lt;li&gt;Batch Normalization据说可以提升效果，不过我没有尝试过，建议作为最后提升模型的手段，参考论文：&lt;a href="http://arxiv.org/abs/1502.03167" class="" data-editable="true" data-title="Accelerating Deep Network Training by Reducing Internal Covariate Shift"&gt;Accelerating Deep Network Training by Reducing Internal Covariate Shift&lt;/a&gt;&lt;/li&gt;&lt;li&gt;如果你的模型包含全连接层（MLP），并且输入和输出大小一样，可以考虑将MLP替换成Highway Network,我尝试对结果有一点提升，建议作为最后提升模型的手段，原理很简单，就是给输出加了一个gate来控制信息的流动，详细介绍请参考论文: &lt;a href="http://arxiv.org/abs/1505.00387" data-editable="true" data-title="arxiv.org 的页面"&gt;http://arxiv.org/abs/1505.00387&lt;/a&gt;&lt;/li&gt;&lt;li&gt;来自&lt;a href="https://www.zhihu.com/people/00c38786ac1d4d806996ee10e8b2912a" data-hash="00c38786ac1d4d806996ee10e8b2912a" class="member_mention" data-editable="true" data-title="@张馨宇" data-hovercard="p$b$00c38786ac1d4d806996ee10e8b2912a"&gt;@张馨宇&lt;/a&gt;的技巧：一轮加正则，一轮不加正则，反复进行。&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Ensemble: 论文刷结果的终极核武器,深度学习中一般有以下几种方式&lt;/p&gt;&lt;ol&gt;&lt;li&gt;同样的参数,不同的初始化方式&lt;/li&gt;&lt;li&gt;不同的参数,通过cross-validation,选取最好的几组&lt;/li&gt;&lt;li&gt;同样的参数,模型训练的不同阶段，即不同迭代次数的模型。&lt;/li&gt;&lt;li&gt;不同的模型,进行线性融合. 例如RNN和传统模型.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/20767428&amp;pixel&amp;useReferer"/&gt;</description><author>萧瑟</author><pubDate>Mon, 18 Apr 2016 15:45:37 GMT</pubDate></item></channel></rss>