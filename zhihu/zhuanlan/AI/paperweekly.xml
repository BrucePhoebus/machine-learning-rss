<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PaperWeekly - 知乎专栏</title><link>https://zhuanlan.zhihu.com/paperweekly</link><description>每周会分享N篇nlp领域好玩的paper，旨在用最少的话说明白paper的贡献。同时也运营一个公众号，PaperWeekly，欢迎大家关注。</description><lastBuildDate>Sun, 29 Jan 2017 04:16:27 GMT</lastBuildDate><generator>Ricky</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>cs.CL weekly 2016.10.10-2016.10.14</title><link>https://zhuanlan.zhihu.com/p/22966490</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-ea9f4f4503d2ed9e15a56fe56e26e98d_r.jpg"&gt;&lt;/p&gt;&lt;p&gt;本周分享了10篇值得读的文章，其中3篇与对话系统有关，包括迁移学习和上下文处理；3篇与seq2seq方法的改进有关。分享了3个高质量资源，其中包括CCL的论文集和北大万小军老师组开源的文本摘要工具。&lt;/p&gt;&lt;h1&gt;一周值得读&lt;/h1&gt;&lt;h2&gt;&lt;a href="https://arxiv.org/pdf/1610.02891v1.pdf" data-editable="true" data-title="Personalizing a Dialogue System with Transfer Learning"&gt;Personalizing a Dialogue System with Transfer Learning&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;【对话系统】【迁移学习】面向具体任务的对话系统由于数据不充分，面临难以训练的尴尬境地。解决这一问题的方法之一是用迁移学习来做，本文提出了一种基于POMDP的迁移学习框架。并且在购买咖啡的实际场景中得到了应用，取得了不错的效果。港科大杨强老师是迁移学习领域的专家，而迁移学习是解决机器学习中领域数据过小问题的一种有效方法，现有的特有对话系统面临着这个问题，尤其是要求对话系统具有个性化的特点时。本文对于研究语音对话系统和聊天机器人都有一定的启发性。&lt;/p&gt;&lt;h2&gt;&lt;a href="https://arxiv.org/pdf/1610.03955v1.pdf" data-editable="true" data-title="Dialogue Session Segmentation by Embedding-Enhanced TextTiling" class=""&gt;Dialogue Session Segmentation by Embedding-Enhanced TextTiling&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;【chatbot】【上下文处理】本文研究的内容是开放域聊天机器人context处理的问题，当前聊天的内容很大程度上都会与之前的聊天内容有相关，但并不是每一句都相关，因此算好相关度很有必要。&lt;/p&gt;&lt;h2&gt;&lt;a href="https://arxiv.org/pdf/1610.04120v1.pdf" data-editable="true" data-title="Exploiting Sentence and Context Representations in Deep Neural Models for Spoken Language Understanding" class=""&gt;Exploiting Sentence and Context Representations in Deep Neural Models for Spoken Language Understanding&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;【对话系统】【深度学习】本文是steve young组的一篇新文，旨在探索CNN表示对话句子和LSTM表示上下文信息在对话理解问题上的效果，相比于传统方法，DNN方法鲁棒性更强。&lt;/p&gt;&lt;h2&gt;&lt;a href="https://arxiv.org/pdf/1610.03035v1.pdf" data-editable="true" data-title="Latent Sequence Decompositions" class=""&gt;Latent Sequence Decompositions&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;【seq2seq】本文研究的内容是对seq2seq框架中输入和输出序列进行有意义分解的问题，而不是简单地分解为char，提出了一种Latent Sequence Decompositions框架，在语音识别问题上取得了不错的效果。其实不仅仅是语音识别问题，在用seq2seq框架时总会遇到OOV的问题，char是一种方法，但信息量太少，如果能够将word sequence分解为更加有意义的子序列，既兼顾了信息量，又降低了词表维度。对英文系的语言效果好一些，中文效果应该不会那么明显。&lt;/p&gt;&lt;h2&gt;&lt;a href="https://arxiv.org/pdf/1610.02424v1.pdf" data-editable="true" data-title="Diverse Beam Search: Decoding Diverse Solutions from Neural Sequence Models"&gt;Diverse Beam Search: Decoding Diverse Solutions from Neural Sequence Models&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;【seq2seq】seq2seq框架中在解码阶段，常常会用beam search来从左至右、贪心地生成N个最好的输出，不仅仅效率低下，而且在很多复杂任务中效果不好。本文提出了一种新的搜索算法。算法会在解空间内exploration和exploitation，通过设定diverse的目标进行训练，得到结果。相比之下，本文的方法更加高效。并且在image caption、VQA和MT等任务中进行了验证。&lt;/p&gt;&lt;h2&gt;&lt;a href="https://arxiv.org/pdf/1610.04211v1.pdf" data-editable="true" data-title="Gated End-to-End Memory Networks"&gt;Gated End-to-End Memory Networks&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;【seq2seq】【memory networks】端到端的记忆网络在简单的机器阅读理解任务上取得了不错的效果，但复杂的事实问答和对话理解相关的任务处理的并不好，原因在于记忆单元与模型之间交互复杂。本文针对该问题，提出了一种Gated记忆网络，取得了不错的效果。本文模型在机器阅读理解bAbI dataset和task-oriented 对话系统任务DSTC2中均取得了非常好的结果。&lt;/p&gt;&lt;h2&gt;&lt;a href="https://arxiv.org/pdf/1610.03098v3.pdf" data-editable="true" data-title="Neural Paraphrase Generation with Stacked Residual LSTM Networks"&gt;Neural Paraphrase Generation with Stacked Residual LSTM Networks&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;【paraphrase】本文提出用多层残差LSTM网络来做paraphrase的任务，得到了比之前seq2seq以及seq2seq+attention更好的效果。转述在某个角度上和标题生成（句子level摘要）类似，方法可借鉴。&lt;/p&gt;&lt;h2&gt;&lt;a href="https://arxiv.org/pdf/1610.03771v1.pdf" data-editable="true" data-title="SentiHood: Targeted Aspect Based Sentiment Analysis Dataset for Urban Neighbourhoods" class=""&gt;SentiHood: Targeted Aspect Based Sentiment Analysis Dataset for Urban Neighbourhoods&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;【观点挖掘】【数据集】本文给出了一个观点挖掘的数据集，数据源来自Yahoo问答中与London相关的提问。这个数据集适合这样的场景，一段评论中包含了多个entity的多个aspect的观点，相互之间有一些比较。&lt;/p&gt;&lt;h2&gt;&lt;a href="https://arxiv.org/pdf/1610.03807v1.pdf" data-editable="true" data-title="Domain-specific Question Generation from a Knowledge Base" class=""&gt;Domain-specific Question Generation from a Knowledge Base&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;【问题生成】问答系统是一个热门研究领域，其关注点在于如何理解问题然后选择或者生成相应的答案。而本文研究的问题是如何根据知识图谱生成高质量的问题。提出高质量的问题难度很大，且看本文内容。&lt;/p&gt;&lt;h2&gt;&lt;a href="https://arxiv.org/pdf/1610.03950v1.pdf" data-editable="true" data-title="Compressing Neural Language Models by Sparse Word Representations" class=""&gt;Compressing Neural Language Models by Sparse Word Representations&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;【语言模型】【提升效率】本文解决的是在学习语言模型时输出层词表过大的问题，词表过大导致效率过低，本文针对这一问题，提出了一种压缩方法，常见词用dense向量来表示，而罕见词用常见词的线性组合来表示。&lt;/p&gt;&lt;h1&gt;一周资源&lt;/h1&gt;&lt;h2&gt;&lt;a href="http://www.cips-cl.org/static/CCL2016/index.html" data-editable="true" data-title="CCL &amp;amp; NLP-NABD 2016论文集"&gt;CCL &amp;amp; NLP-NABD 2016论文集&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;由Springer出版的CCL &amp;amp; NLP-NABD 2016论文集已经公布，并在10月10日-11月10日期间可以免费下载。免费下载方式如下：（1）访问会议首页；（2）点击该页面最新“会议论文下载”中的链接；（3）点击新页面的“Download Book (PDF, 35547KB)”按钮。&lt;/p&gt;&lt;h2&gt;&lt;a href="http://www.icst.pku.edu.cn/lcwm/wanxj/pkusumsum.htm" data-editable="true" data-title="北京大学万小军老师组开源自动摘要小工具PKUSUMSUM"&gt;北京大学万小军老师组开源自动摘要小工具PKUSUMSUM&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;本组推出文档自动摘要小工具PKUSUMSUM，集成多种无监督摘要提取算法，支持多种摘要任务与多种语言，采用Java编写，代码完全开源，欢迎批评指正，也欢迎同行一起完善该工具。&lt;/p&gt;&lt;h2&gt;&lt;a href="http://nlp.stanford.edu/read/" data-editable="true" data-title="斯坦福大学NLP组2016年秋季paper阅读周计划"&gt;斯坦福大学NLP组2016年秋季paper阅读周计划&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;斯坦福大学NLP组2016年秋季paper阅读周计划，挺多篇都是对话系统相关的。&lt;/p&gt;&lt;h1&gt;广告时间&lt;/h1&gt;&lt;p&gt;PaperWeekly是一个分享知识和交流学问的民间组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。&lt;/p&gt;&lt;p&gt;微信公众号：PaperWeekly微博账号：PaperWeekly（&lt;a href="http://weibo.com/u/2678093863" data-editable="true" data-title="PaperWeekly的微博"&gt;PaperWeekly的微博&lt;/a&gt; ）知乎专栏：PaperWeekly（&lt;a href="https://zhuanlan.zhihu.com/paperweekly" data-editable="true" data-title="PaperWeekly - 知乎专栏"&gt;PaperWeekly - 知乎专栏&lt;/a&gt; ）微信交流群：微信+ zhangjun168305（请备注：加群 or 加入paperweekly）&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/22966490&amp;pixel&amp;useReferer"/&gt;</description><author>张俊</author><pubDate>Sat, 15 Oct 2016 11:07:14 GMT</pubDate></item><item><title>PaperWeekly 第九期 -- 浅谈GAN</title><link>https://zhuanlan.zhihu.com/p/22936163</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-ea9f4f4503d2ed9e15a56fe56e26e98d_r.jpg"&gt;&lt;/p&gt;&lt;h1&gt;引言&lt;/h1&gt;&lt;p&gt;深度生成模型基本都是以某种方式寻找并表达（多变量）数据的概率分布。有基于无向图模型（马尔可夫模型）的联合概率分布模型，另外就是基于有向图模型（贝叶斯模型）的条件概率分布。前者的模型是构建隐含层(latent)和显示层（visible)的联合概率，然后去采样。基于有向图的则是寻找latent和visible之间的条件概率分布，也就是给定一个随机采样的隐含层，模型可以生成数据。&lt;/p&gt;&lt;p&gt;生成模型的训练是一个非监督过程，输入只需要无标签的数据。除了可以生成数据，还可以用于半监督的学习。比如，先利用大量无标签数据训练好模型，然后利用模型去提取数据特征（即从数据层到隐含层的编码过程），之后用数据特征结合标签去训练最终的网络模型。另一种方法是利用生成模型网络中的参数去初始化监督训练中的网络模型，当然，两个模型需要结构一致。&lt;/p&gt;&lt;p&gt;由于实际中，更多的数据是无标签的，因此非监督和半监督学习非常重要，因此生成模型也非常重要。本篇主要介绍一种基于对抗模式的生成模型，GAN － 从第一篇提出此模型的论文开始，之后紧接着两篇基于它的实现以及改进。三篇文章一脉相承，可以看到结合这种模型的研究进展及方向。&lt;/p&gt;&lt;h1&gt;&lt;a href="https://arxiv.org/abs/1406.2661" data-editable="true" data-title="Generative Adversarial Nets"&gt;Generative Adversarial Nets&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;作者&lt;/h2&gt;&lt;p&gt;Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, Yoshua Bengio&lt;/p&gt;&lt;h2&gt;单位&lt;/h2&gt;&lt;p&gt;Universite of Montreal&lt;/p&gt;&lt;h2&gt;关键词&lt;/h2&gt;&lt;p&gt;生成模型 （Generative model）&lt;/p&gt;&lt;h2&gt;文章来源&lt;/h2&gt;&lt;p&gt;NIPS 2014&lt;/p&gt;&lt;h2&gt;问题&lt;/h2&gt;&lt;p&gt;通过模拟对抗过程，提出一种新的生成模型框架&lt;/p&gt;&lt;h2&gt;模型&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;建模&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在对抗生成模型中，同时训练两个网络，第一个网络是生成网络，G(z)，输入z一般是来自常见概率分布函数的样本向量，维度一般比较低，比如100。生成网络输入向量z，输出图片样例，如果使用卷机网实现的话，整个网络可以看过一个反向的CNN，其中的卷积层替换成 transposed convolution layer。第二个网络是识别网络discriminator net - D(x)，输入为一张图片x，而输出为一个标量，用来代表x来自真实图片的概率。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;训练&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;整个网络的loss定义为&lt;/p&gt;&lt;p&gt;V = E’[log D(x)] + E’’[log (1 - D(G(z)) )]E’ - 当x来自真实数据的期望E’’ - 当x来自生成网络的期望&lt;/p&gt;&lt;p&gt;很显然，在对抗网络中，生成模型希望能够增大D(G(z))，即，希望生成的图片越真实而让识别模型“误以为”是来自真实的图片集。&lt;/p&gt;&lt;p&gt;如果生成网络G的参数用theta表示，识别模型的参数用theta_d表示，在使用SGD训练的时候，两组参数分别进行训练，对于D来说，需要对上面的公式求Gradient，但是只更新自己的参数。对G来说，只有第二项是相关的，而且可以等效的转换为maximize log D(G(z))。两个网络的参数更新交替进行。&lt;/p&gt;&lt;h2&gt;资源&lt;/h2&gt;&lt;p&gt;网上有很多实现，比如:&lt;/p&gt;&lt;p&gt;&lt;a href="https://github.com/goodfeli/adversarial" data-editable="true" data-title="goodfeli/adversarial"&gt;goodfeli/adversarial&lt;/a&gt;: Theano GAN implementation released by the authors of the GAN paper.&lt;a href="https://github.com/Newmu/dcgan_code" data-editable="true" data-title="Newmu/dcgan_code"&gt;Newmu/dcgan_code&lt;/a&gt;: Theano DCGAN implementation released by the authors of the DCGAN paper.&lt;a href="https://github.com/carpedm20/DCGAN-tensorflow" data-editable="true" data-title="carpedm20/DCGAN-tensorflow"&gt;carpedm20/DCGAN-tensorflow&lt;/a&gt;: Unofficial TensorFlow DCGAN implementation.&lt;/p&gt;&lt;p&gt;这些实现一般都会包含MNIST测试集。&lt;/p&gt;&lt;h2&gt;相关工作&lt;/h2&gt;&lt;p&gt;其他的生成模型包括restricted Boltzmann machine (RBM), deep Boltzmann machine (DBM) 以及 variational autoencoder&lt;/p&gt;&lt;h2&gt;简评&lt;/h2&gt;&lt;p&gt;其他生成模型中训练过程涉及intractable的计算，在实际实现时往往采取马尔可夫链模特卡洛采样(MCMC)。对抗生成模型(GAN)则不需要，整个网络的训练可以使用backpropagation来实现。&lt;/p&gt;&lt;p&gt;缺点包括训练不稳定，生成网络会塌陷到某些数据点（比如这些数据点目前看最像真实数据，生成网络会不停生成这些数据点），接下来的几篇中将提及如何改进。&lt;/p&gt;&lt;h1&gt;[Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks] (&lt;a href="https://arxiv.org/abs/1511.06434" class=""&gt;https://arxiv.org/abs/1511.06434&lt;/a&gt;)&lt;/h1&gt;&lt;h2&gt;作者&lt;/h2&gt;&lt;p&gt;Alec Radford, Luke Metz, Soumith Chintala&lt;/p&gt;&lt;h2&gt;单位&lt;/h2&gt;&lt;p&gt;facebook&lt;/p&gt;&lt;h2&gt;关键词&lt;/h2&gt;&lt;p&gt;DCGAN, Representation Learning&lt;/p&gt;&lt;h2&gt;文章来源&lt;/h2&gt;&lt;p&gt;ICLR 2016&lt;/p&gt;&lt;h2&gt;问题&lt;/h2&gt;&lt;p&gt;基于深度卷积网络的生成对抗模型(DCGAN)实现&lt;/p&gt;&lt;h2&gt;模型&lt;/h2&gt;&lt;p&gt;在GAN的论文中提出的对抗模型的原型，但是对抗模型是一个大的框架，并不局限于某种网络实现。本文给出了基于卷机网的实现。&lt;/p&gt;&lt;p&gt;生成网络&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-c26e080dd30e8a07d31173578c52ae07.png" data-rawwidth="815" data-rawheight="336"&gt;&lt;/p&gt;&lt;p&gt;其中反卷积的过程是&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-a2afa892b7b37c37871701f374e4b5ad.jpg" data-rawwidth="395" data-rawheight="449"&gt;&lt;/p&gt;&lt;p&gt;识别网络是传统的CNN&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-80e12e427ea09caf1fa69040a1797ae2.png" data-rawwidth="525" data-rawheight="250"&gt;&lt;/p&gt;&lt;h2&gt;简评&lt;/h2&gt;&lt;p&gt;本文紧密承接上篇论文，描述了实现过程中的细节，比如参数设置。也提到了解决GAN中训练不稳定的措施，但是并非完全解决。文中还提到利用对抗生成网络来做半监督学习。在训练结束后，识别网络可以用来提取图片特征，输入有标签的训练图片，可以将卷基层的输出特征作为X，标签作为y做训练。&lt;/p&gt;&lt;h1&gt;&lt;a href="https://arxiv.org/abs/1606.03498" data-editable="true" data-title="Improved Techniques for Training GANs" class=""&gt;Improved Techniques for Training GANs&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;作者&lt;/h2&gt;&lt;p&gt;Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, Xi Chen&lt;/p&gt;&lt;h2&gt;单位&lt;/h2&gt;&lt;p&gt;OpenAI&lt;/p&gt;&lt;h2&gt;关键词&lt;/h2&gt;&lt;p&gt;DCGAN&lt;/p&gt;&lt;h2&gt;文章来源&lt;/h2&gt;&lt;p&gt;ICLR 2016&lt;/p&gt;&lt;h2&gt;问题&lt;/h2&gt;&lt;p&gt;提出改进DCGAN的措施&lt;/p&gt;&lt;h2&gt;模型&lt;/h2&gt;&lt;p&gt;这篇论文同样跟前文非常紧密，具体针对DCGAN中的问题，提出了改进方法。具体有&lt;/p&gt;&lt;ul&gt;&lt;li&gt;feature matching 解决训练不稳定instability的问题&lt;/li&gt;&lt;li&gt;minibatch discrimination 解决生成网络生成图片集中的问题，原理是让识别网络一次看一组图片，而不是一张图片&lt;/li&gt;&lt;li&gt;如果对实现感兴趣，其他改进细节可以参见论文&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;简评&lt;/h2&gt;&lt;p&gt;对抗生成网络的模型很有意思，Bengio, Hinton等都表达了很高的评价。相对其他生成模式而言，对抗生成模式模型清晰简单，目前来看效果也比较不错。但是目前对抗生成网络也有很多问题，比如生成模型是通过来自概率分布的向量生成样本，而不是直接表示输入的概率分布，因此，生成的图片可能不稳定之类。此外，希望能看到GAN在语言模型中的应用。&lt;/p&gt;&lt;h1&gt;总结&lt;/h1&gt;&lt;p&gt;GAN这种模型非常新颖，从论文中的结果来看，在图像生成上取得了不错的效果，对于MNIST这种简单的图形数据集，生成的图片已经可以“以假乱真”。对于另外的图片，比如在第二篇论文中的LSUN bedroom图片集以及人脸图片集上，生成的图片效果也不错（分辨率64×64）。GAN目前来看已经卷积网络图像生成中取得了不错的效果，但是还有很多问题需要继续研究改进， 比如如何生成高像素高质量的图片。目前一般像素不超过64。如何提高复杂图片的质量。目前在CIFAR，ILSVRC等图片集上训练生成的图片还是很糟糕。如何提高整个模型的稳定性。在实际中，尤其对于复杂图形，生成器经常很快收敛到某些单个数据集，使得整个模型的训练陷入僵局。如何在其他领域，比如NLP使用GAN，如何将GAN和LSTM结合的。目前来看，还没有成功的应用。原文作者在reddit上回答内容来看，由于GAN的输入是采样自连续分布，而NLP中，每个单词的表达往往是离散的，作者提到NLP可以用增强训练的方法替代。但是也不排除可以有其他方法将GAN和LSTM结合起来的，这也是以后的一个研究点。&lt;/p&gt;&lt;h1&gt;广告时间&lt;/h1&gt;&lt;p&gt;PaperWeekly是一个分享知识和交流学问的民间组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。&lt;/p&gt;&lt;p&gt;微信公众号：PaperWeekly&lt;/p&gt;&lt;p&gt;微博账号：PaperWeekly（&lt;a href="http://weibo.com/u/2678093863"&gt;http://weibo.com/u/2678093863&lt;/a&gt; ）知乎专栏：PaperWeekly（&lt;a href="https://zhuanlan.zhihu.com/paperweekly"&gt;https://zhuanlan.zhihu.com/paperweekly&lt;/a&gt; ）微信交流群：微信+ zhangjun168305（请备注：加群 or 加入paperweekly）&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/22936163&amp;pixel&amp;useReferer"/&gt;</description><author>张俊</author><pubDate>Fri, 14 Oct 2016 08:57:55 GMT</pubDate></item><item><title>cs.CL weekly 2016.10.03-2016.10.07</title><link>https://zhuanlan.zhihu.com/p/22807616</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-ea9f4f4503d2ed9e15a56fe56e26e98d_r.jpg"&gt;&lt;/p&gt;&lt;p&gt;本周一共推荐7篇paper，其中5篇偏学术，2篇偏应用，3个优质资源。paper中包括一个超大型MRC dataset，两篇综述（VQA和多模态），一篇介绍TensorFlow原理，资源中包括王威廉老师关于如何做科研的一些建议。&lt;/p&gt;&lt;h1&gt;一周值得读（偏学术）&lt;/h1&gt;&lt;h2&gt;&lt;a href="https://arxiv.org/pdf/1609.09552v1.pdf" data-editable="true" data-title="Controlling Output Length in Neural Encoder-Decoders"&gt;Controlling Output Length in Neural Encoder-Decoders&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;本文针对encoder-decoder框架在应用时无法控制生成序列长度（比如文本摘要）的问题，作者提出了一种基于学习的模型来解决这个问题。encoder-decoder框架已经被成功应用于各大任务中，加上attention，不同变种的attention，研究的人很多。本文也是属于变种之一，考虑了在实际应用中文本摘要长度需要被控制的问题，提出了本文的模型。&lt;/p&gt;&lt;h2&gt;&lt;a href="https://arxiv.org/pdf/1610.00956v1.pdf" data-editable="true" data-title="Embracing data abundance: BookTest Dataset for Reading Comprehension" class=""&gt;Embracing data abundance: BookTest Dataset for Reading Comprehension&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;【数据福利】本文发布了一个新的机器阅读理解数据集BookTest，该数据集最大的亮点是规模大，是Facebook发布的Children’s Book Test的60倍之大。&lt;/p&gt;&lt;h2&gt;&lt;a href="https://arxiv.org/pdf/1610.01465v1.pdf" data-editable="true" data-title="Visual Question Answering: Datasets, Algorithms, and Future Challenges" class=""&gt;Visual Question Answering: Datasets, Algorithms, and Future Challenges&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;【综述】这是一篇Visual Question Answer任务的综述性文章，系统地总结、讨论和对比了近几年该领域的数据集和算法，并给出了一些该领域未来的研究方向。&lt;/p&gt;&lt;h2&gt;&lt;a href="https://arxiv.org/pdf/1610.01206v1.pdf" data-editable="true" data-title="Multi-View Representation Learning: A Survey from Shallow Methods to Deep Methods" class=""&gt;Multi-View Representation Learning: A Survey from Shallow Methods to Deep Methods&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;【综述】本文是一篇2015年出版的多模态表示学习的综述文章，非常适合刚刚了解或者准备进入这个领域的童鞋来读。&lt;/p&gt;&lt;h2&gt;&lt;a href="https://arxiv.org/pdf/1610.01874v1.pdf" data-editable="true" data-title="Neural-based Noise Filtering from Word Embeddings"&gt;Neural-based Noise Filtering from Word Embeddings&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;词向量已经是NLP中各任务的基础部件，对词向量的研究工作也非常多。本文研究的切入点是从语料中的噪声入手，提出了两种无监督去噪模型，取得了不错的效果。&lt;/p&gt;&lt;h1&gt;一周值得读（偏应用）&lt;/h1&gt;&lt;h2&gt;&lt;a href="https://arxiv.org/pdf/1610.00388v2.pdf" data-editable="true" data-title="Learning to Translate in Real-time with Neural Machine Translation"&gt;Learning to Translate in Real-time with Neural Machine Translation&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;本文研究的内容实时机器翻译，与传统的翻译问题不同，该任务需要在翻译质量和速度两个方面寻找一个平衡点，NMT已经证明了其强大的实力，在此基础上用增强学习做训练，以满足两个方面的需求。&lt;/p&gt;&lt;h2&gt;&lt;a href="https://arxiv.org/pdf/1610.01178v1.pdf" data-editable="true" data-title="A Tour of TensorFlow"&gt;A Tour of TensorFlow&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;本文系统的剖析了TensorFlow的计算图架构和分布式执行模型，并且系统地对比了TF和其他框架的性能。本文的结论对于框架选择困难的童鞋有一定参考意义，内容对于有志于深挖TF原理和想开发框架的童鞋具有较强的指导意义。对于立志于成为一名TFBoys（TensorFlow）的童鞋，本文是一篇不错的文章。&lt;/p&gt;&lt;h1&gt;一周资源&lt;/h1&gt;&lt;h2&gt;&lt;a href="https://pan.baidu.com/s/1nuT9qnZ" data-editable="true" data-title="Chatbots – Conversational UI and the Future of Online Interaction | Swat.io Blog"&gt;Chatbots – Conversational UI and the Future of Online Interaction | Swat.io Blog&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;研究chatbot的童鞋，这本电子书值得一看，或许会有一些思考和启发！&lt;/p&gt;&lt;h2&gt;&lt;a href="http://weibo.com/1657470871/EbJnqBBJ5?type=comment#_rnd1475892970397" data-editable="true" data-title="王威廉老师关于如何做科研的微博" class=""&gt;王威廉老师关于如何做科研的微博&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;“什么是研究？本科生如何做好研究？我今天在组会上简单地给组里的本科生介绍了一点个人做研究的经验，与大家分享一下。”&lt;/p&gt;&lt;h2&gt;&lt;a href="http://www.lighting-torch.com/2015/07/27/configuring-eclipse-with-torch/" data-editable="true" data-title="Configuring Eclipse with Torch – Lighting Torch"&gt;Configuring Eclipse with Torch – Lighting Torch&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;将Torch配置到Eclipse中进行开发和调试。&lt;/p&gt;&lt;h1&gt;广告时间&lt;/h1&gt;&lt;p&gt;PaperWeekly是一个分享知识和交流学问的民间组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。&lt;/p&gt;&lt;p&gt;微信公众号：PaperWeekly&lt;/p&gt;&lt;p&gt;微博账号：PaperWeekly（&lt;a href="http://weibo.com/u/2678093863" data-editable="true" data-title="PaperWeekly的微博"&gt;PaperWeekly的微博&lt;/a&gt; ）知乎专栏：PaperWeekly（&lt;a href="https://zhuanlan.zhihu.com/paperweekly" data-editable="true" data-title="PaperWeekly - 知乎专栏"&gt;PaperWeekly - 知乎专栏&lt;/a&gt; ）微信交流群：微信+ zhangjun168305（请备注：加群 or 加入paperweekly）&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/22807616&amp;pixel&amp;useReferer"/&gt;</description><author>张俊</author><pubDate>Sat, 08 Oct 2016 07:24:21 GMT</pubDate></item><item><title>PaperWeekly 第八期------Sigdial2016文章精选（对话系统最新研究成果）</title><link>https://zhuanlan.zhihu.com/p/22795635</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-ea9f4f4503d2ed9e15a56fe56e26e98d_r.jpg"&gt;&lt;/p&gt;&lt;h1&gt;引言&lt;/h1&gt;&lt;p&gt;SIGDIAL是ACL所属的关于对话系统的兴趣小组，SIG的文章针对性比较强，但文章的质量良莠不齐，本期给大家精心挑选了4篇SIGDIAL 2016的文章，带着大家一起来看看对话系统最新的研究成果。4篇文章分别是：&lt;/p&gt;&lt;p&gt;1、Joint Online Spoken Language Understanding and Language Modeling with Recurrent Neural Networks, 20162、Neural Utterance Ranking Model for Conversational Dialogue Systems, 20163、A Context-aware Natural Language Generator for Dialogue Systems, 20164、Task Lineages: Dialog State Tracking for Flexible Interaction, 2016&lt;/p&gt;&lt;h1&gt;&lt;a href="http://arxiv.org/pdf/1609.01462v1.pdf" data-editable="true" data-title="Joint Online Spoken Language Understanding and Language Modeling with Recurrent Neural Networks" class=""&gt;Joint Online Spoken Language Understanding and Language Modeling with Recurrent Neural Networks&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;作者&lt;/h2&gt;&lt;p&gt;Bing Liu, Ian Lane&lt;/p&gt;&lt;h2&gt;单位&lt;/h2&gt;&lt;p&gt;Carnegie Mellon University, Electrical and Computer Engineering&lt;/p&gt;&lt;h2&gt;关键词&lt;/h2&gt;&lt;p&gt;Spoken Language Understanding, RNN&lt;/p&gt;&lt;h2&gt;文章来源&lt;/h2&gt;&lt;p&gt;SIGDIAL 2016&lt;/p&gt;&lt;h2&gt;问题&lt;/h2&gt;&lt;p&gt;如何将自然语言理解的两大问题和语言模型结合在同一个模型中进行训练，以达到实时理解语言的目的？&lt;/p&gt;&lt;h2&gt;模型&lt;/h2&gt;&lt;p&gt;特定任务下的Chatbot在理解人类语言时需要重点解决好两个问题：意图识别(Intent Detection)和槽填充(Slot Filling)，本文提出一种融合Intent Detection、Slot Filling和Language Model的模型，相比于之前的模型，本文模型的一大优势在于做自然语言理解的时候不需要等待整个word sequence完整展现，而是可以在线处理每一个arrived word。如下图：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-c506051f5357822f9dff9bf91026bf8e.png" data-rawwidth="749" data-rawheight="269"&gt;&lt;/p&gt;&lt;p&gt;意图识别是个典型的多分类任务，而槽填充是个典型的序列标注任务。RNN的每个step都以当前word作为输入，输出是意图class、该word的label和下一个word，每个step的隐层都包含了之前所有的word、class、label信息。此模型为基本模型，在此基础上做了一些变形，得到下面四个变种：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-8dd2dc9d683030f9a40b4446dd0e9b9d.png" data-rawwidth="735" data-rawheight="285"&gt;&lt;/p&gt;&lt;p&gt;文章在Airline Travel Information Systems(ATIS)数据集上进行了实验，在语言模型评测指标和意图识别分类准确率上相比之前的模型都得到了一定地提升。&lt;/p&gt;&lt;h2&gt;资源&lt;/h2&gt;&lt;p&gt;本文Code: &lt;a href="http://speech.sv.cmu.edu/software.html" data-editable="true" data-title="CMU SPEECH Team"&gt;CMU SPEECH Team&lt;/a&gt;ATIS Dataset: &lt;a href="https://github.com/mesnilgr/is13" data-editable="true" data-title="GitHub - mesnilgr/is13: RNN for Spoken Language Understanding"&gt;GitHub - mesnilgr/is13: RNN for Spoken Language Understanding&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;简评&lt;/h2&gt;&lt;p&gt;本文的创新点在于将意图分类、槽填充和语言模型三者合一，相比之前的独立模型来说，每一步产生的信息更多，在预测下一步的时候context内容更加丰富，从而提高了识别的准确率和降低了语言模型的混乱度。&lt;/p&gt;&lt;p&gt;NLP中的很多任务都可以归纳为根据context来预测某一个word、label或者class这种范式，解决的思路也都基本类似，RNN或者GRU、LSTM作为encoder和decoder，配上attention机制来提升结果，context的信息量和质量直接影响着预测的效果，user information、user profile等等都可能作为context来构建模型，得到更好的结果。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://www.sigdial.org/workshops/conference17/proceedings/pdf/SIGDIAL48.pdf" data-editable="true" data-title="Neural Utterance Ranking Model for Conversational Dialogue Systems" class=""&gt;Neural Utterance Ranking Model for Conversational Dialogue Systems&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;作者&lt;/h2&gt;&lt;p&gt;Michimasa Inaba, Kenichi Takahashi&lt;/p&gt;&lt;h2&gt;单位&lt;/h2&gt;&lt;p&gt;Hiroshima City University, 3-4-1 Ozukahigashi, Asaminami-ku&lt;/p&gt;&lt;h2&gt;关键词&lt;/h2&gt;&lt;p&gt;Ranking Model, Utterance Selection&lt;/p&gt;&lt;h2&gt;文章来源&lt;/h2&gt;&lt;p&gt;SIGDIAL 2016&lt;/p&gt;&lt;h2&gt;问题&lt;/h2&gt;&lt;p&gt;在做检索式对话时，对话语句该怎样表示，context信息该怎样引入到模型中？&lt;/p&gt;&lt;h2&gt;模型&lt;/h2&gt;&lt;p&gt;本文实现的是一个检索式的对话模型，模型分为两部分，分别是：1、Utterance Encoding检索式对话，对话语句的encoding是很重要的一部分，文中使用了RNN encoder模型来实现对语句的encoding。在训练过程中，作者把encoder生成的向量，在decode成一个目标语句，即通过一个完整的seq2seq模型来训练encoder。2、Ranking Candidate Utterances在对候选语句排序时，作者考虑到了context的问题，他把前几次说的语句分别encode成向量，并依次输入到LSTM。如下图所示：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-b81ae5251b5467208ea25e91a92e7e5c.png" data-rawwidth="838" data-rawheight="546"&gt;&lt;/p&gt;&lt;p&gt;图中u1到un是整个对话中的前n句话，ai是第i个候选语句。模型中，分别把u1…un以及ai分成用户说的和系统本身输出的，在输入到各自的RNN encoder中，得到向量vu1…vu和vai。最后将向量依次输入到RNN中，得到yai作为候选语句ai在当前context中的得分。&lt;/p&gt;&lt;p&gt;因为本文是一个ranking model，更关注的是候选语句的排序，最后候选集分数列表会转换成TOP 1的概率分布。并使用cross-entropy作为loss function。&lt;/p&gt;&lt;h2&gt;简评&lt;/h2&gt;&lt;p&gt;本文有两个创新点，首先通过单独训练seq2seq模型，来学习对话语句的encoder，从而降低了整个模型的学习成本，减少了需要标注的数据量。然后在排序模型中将对话的前几句语句有序输入到LSTM，达到融入了context信息的目的。&lt;/p&gt;&lt;h1&gt;&lt;a href="https://arxiv.org/pdf/1608.07076" data-editable="true" data-title="A Context-aware Natural Language Generator for Dialogue Systems" class=""&gt;A Context-aware Natural Language Generator for Dialogue Systems&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;作者&lt;/h2&gt;&lt;p&gt;Ondrej Dusek, Filip Jurcicek&lt;/p&gt;&lt;h2&gt;单位&lt;/h2&gt;&lt;p&gt;Charles University&lt;/p&gt;&lt;h2&gt;关键词&lt;/h2&gt;&lt;p&gt;Context-aware, Seq2seq&lt;/p&gt;&lt;h2&gt;文章来源&lt;/h2&gt;&lt;p&gt;SIGDIAL 2016&lt;/p&gt;&lt;h2&gt;问题&lt;/h2&gt;&lt;p&gt;如何使得task-oriented的对话生成系统中生成更加自然的回复？&lt;/p&gt;&lt;h2&gt;模型&lt;/h2&gt;&lt;p&gt;本文是ACL2016 short paper Sequence-to-Sequence Generation for Spoken Dialogue via Deep Syntax Trees and Strings一文的拓展。原文提出基于seq2seq模型的将DA(dialogue acts)生成response的方案，其中输入是三元组(DA type,slot,value)的one-hot representation，输出是对应的response。如下图：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-dfa55ab221341eb804a43c377891573d.png" data-rawwidth="893" data-rawheight="210"&gt;&lt;/p&gt;&lt;p&gt;延续原文的工作，作者为了使得生成的回复更加自然，将前面用户的提问也encode进来，具体是在原来模型的基础上加了两个encode的部分。Prepending context是把用户的问题和DA三元组前后拼接成新的表示再feed into encoder（这里要注意问题的dictionary和DA是不一样的）。Context encoder则是把单独把问题encode成和Prepending context相同大小的向量，再将两个encoder得到的向量拼接就得到最后的hidden states。最后decode部分仍然沿用lstm+attention的方法。如下图：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-e0e29748876d4c8ccc53b9d51e746410.png" data-rawwidth="1078" data-rawheight="279"&gt;&lt;/p&gt;&lt;p&gt;文章在Alex Context NLG Dataset数据集上进行了实验，在BLEU/NIST scores和人工评价两方面成绩都得到了一定地提升。&lt;/p&gt;&lt;h2&gt;资源&lt;/h2&gt;&lt;p&gt;本文Code: &lt;a href="https://github.com/UFAL-DSG/tgen" data-editable="true" data-title="github.com 的页面"&gt;https://github.com/UFAL-DSG/tgen&lt;/a&gt;Alex Context NLG Dataset: &lt;a href="https://lindat.mff.cuni.cz/repository/xmlui/handle/11234/1-1675"&gt;https://lindat.mff.cuni.cz/repository/xmlui/handle/11234/1-1675&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;简评&lt;/h2&gt;&lt;p&gt;本文的创新点在于将用户的问题也就是context显式的加入到模型中，相比之前的模型来说，生成的回复会更符合语境。先前的工作旨在将rule-based符号和seq2seq模型结合自动生成回复，本文的改进让一部分context得到保留，使得生成的回复内容更加丰富，从而显得自然不突兀。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://aclweb.org/anthology/W16-3602" data-editable="true" data-title="Task Lineages: Dialog State Tracking for Flexible Interaction"&gt;Task Lineages: Dialog State Tracking for Flexible Interaction&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;作者&lt;/h2&gt;&lt;p&gt;Sungjin Lee, Amanda Stent&lt;/p&gt;&lt;h2&gt;单位&lt;/h2&gt;&lt;p&gt;Yahoo Research&lt;/p&gt;&lt;h2&gt;文章来源&lt;/h2&gt;&lt;p&gt;SIGDIAL 2016&lt;/p&gt;&lt;h2&gt;关键词&lt;/h2&gt;&lt;p&gt;complex interactions in spoken dialog system, Task Lineage-based Dialog State Tracking&lt;/p&gt;&lt;h2&gt;问题&lt;/h2&gt;&lt;p&gt;​如何将复杂的判别式模型来做DST，并且应用于复杂场景对话系统？&lt;/p&gt;&lt;h2&gt;模型&lt;/h2&gt;&lt;p&gt;本文在之前Dialog State Tracking方法的基础上提出了Task Lineage-based Dialog State Tracking（TL—DST）。本模型包括三个组成部分：1、Task Frame Parsing，返回K-best task frame parses， task frame parses结构如下图：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-4cc929de3a70862bcb5a872b508b0dc5.png" data-rawwidth="360" data-rawheight="142"&gt;&lt;/p&gt;&lt;p&gt;2、Context Fetching，在不同的phenomena中，根据不同的conversation history返回不同的相关信息。3、Task State Update，可以通过调节context window参数选择使用不同的dialog state tracking方法。&lt;/p&gt;&lt;p&gt;本文模型（TL-DST）处理流程如下图所示：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-be0efc9c96259a88905fed0c0996c471.png" data-rawwidth="423" data-rawheight="525"&gt;&lt;/p&gt;&lt;p&gt;在t轮，给定句子u，利用task frame parsing生成K-best task frame parses H，给定task frame f，task lineage l， agent output m，利用context features返回相关信息c。&lt;/p&gt;&lt;p&gt;本文在Dialog State Tracking Challenge 的DSTC2和DSTC3数据集上进行了实验，均取得了较baseline好的结果。&lt;/p&gt;&lt;h2&gt;资源&lt;/h2&gt;&lt;p&gt;Dialog State Tracking Challenge比赛介绍: &lt;a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/06/williams2016dstc_overview-1.pdf" data-editable="true" data-title="microsoft.com 的页面" class=""&gt;https://www.microsoft.com/en-us/research/wp-content/uploads/2016/06/williams2016dstc_overview-1.pdf&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;简评&lt;/h2&gt;&lt;p&gt;本文基于DST的方法来处理口语对话系统中的多任务，跨领域，复杂目标的问题，由于缺乏多任务，跨领域，复杂目标的口语对话系统的数据集，本文实验在DSTC2和DSTC3上进行， 并取得了比baseline好的效果。将来的工作是要将TL-DST方法应用于真实环境中的多领域对话评估。&lt;/p&gt;&lt;h1&gt;总结&lt;/h1&gt;&lt;p&gt;对话系统(Dialogue Systems)是当前工业界最热门的方向之一，去掉语音部分，该问题退化为聊天机器人(chatbot)问题，两者虽然在输入处理中存在一定的差异，但自然语言理解、对话管理和自然语言生成等核心部件都是一样的，面临的很多问题都是共同的，所以相关的研究或多或少都会有参考意义。上下文(context)的理解和处理是一个重要的环节，直接决定了该bot是智能还是智障，挺多的paper都是针对这一问题进行研究的，但在实际应用当中，context的处理仍然不尽如人意，过多依赖人工设置，更像是一种触发开关，存在大量的if…else…。&lt;/p&gt;&lt;p&gt;seq2seq生成式的解决方案初见效果，但离真正应用还有很长的路要走，template-based和rule-based仍是主流解决方案，尤其是在面向具体任务的bot情景中。那么，直接生成回答很难的话，退一步来想这个问题，能否将seq2seq用在template或者rule的自动生成上？能否将paper中多信息融合（比如：user profile、dialogue context）的成果应用在当前bot的某一个阶段？能否训练一个bot simulator来丰富训练数据？每一篇paper都会有一些创新点，可能有的创新点是为了创新而创新，但总归会带来一定的思考和借鉴，尤其是针对某一个细节问题，我想这是paper对于工业界的参考意义，而不是说从paper中完全抠出一个成熟的解决方案来套，甚至把dataset和code都release出来，典型的“拿来主义”。&lt;/p&gt;&lt;p&gt;以上为本期Paperweekly的主要内容，感谢lshowway、zhangjun、zhangboyu和suhui四位同学的整理。&lt;/p&gt;&lt;h1&gt;广告时间&lt;/h1&gt;&lt;p&gt;PaperWeekly是一个分享知识和交流学问的民间组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。&lt;/p&gt;&lt;p&gt;微信公众号：PaperWeekly&lt;/p&gt;&lt;p&gt;微博账号：PaperWeekly（&lt;a href="http://weibo.com/u/2678093863" data-editable="true" data-title="PaperWeekly的微博"&gt;PaperWeekly的微博&lt;/a&gt; ）知乎专栏：PaperWeekly（&lt;a href="https://zhuanlan.zhihu.com/paperweekly" data-editable="true" data-title="PaperWeekly - 知乎专栏"&gt;PaperWeekly - 知乎专栏&lt;/a&gt; ）微信交流群：微信+ zhangjun168305（请备注：加群 or 加入paperweekly）&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/22795635&amp;pixel&amp;useReferer"/&gt;</description><author>张俊</author><pubDate>Fri, 07 Oct 2016 12:09:38 GMT</pubDate></item><item><title>cs.CL weekly 2016.09.26-2016.09.30</title><link>https://zhuanlan.zhihu.com/p/22723620</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-ea9f4f4503d2ed9e15a56fe56e26e98d_r.jpg"&gt;&lt;/p&gt;&lt;h1&gt;一周值得读（偏学术）&lt;/h1&gt;&lt;h2&gt;&lt;a href="http://rsarxiv.github.io/#HyperNetworks" class="" data-editable="true" data-title="PaperWeekly"&gt;PaperWeekly&lt;/a&gt;&lt;a href="https://arxiv.org/pdf/1609.09106v1.pdf" data-editable="true" data-title="HyperNetworks"&gt;HyperNetworks&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;an approach of using a small network, also known as a hypernetwork, to generate the weights for a larger network. 工作来自Google Brain。介绍HyperNetworks的博客：&lt;a href="http://blog.otoro.net/2016/09/28/hyper-networks/" data-editable="true" data-title="otoro.net 的页面"&gt;http://blog.otoro.net/2016/09/28/hyper-networks/&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;&lt;a href="http://rsarxiv.github.io/#Incorporating-Relation-Paths-in-Neural-Relation-Extraction" class="" data-editable="true" data-title="PaperWeekly"&gt;PaperWeekly&lt;/a&gt;&lt;a href="https://arxiv.org/pdf/1609.07479v1.pdf" data-editable="true" data-title="Incorporating Relation Paths in Neural Relation Extraction"&gt;Incorporating Relation Paths in Neural Relation Extraction&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;本文研究内容为实体关系抽取，传统方法往往只利用同时包含两个目标实体的句子，而忽略包含单目标实体的句子，本文针对这一问题，在俩目标实体之间构建了一个用于推理的中间实体，并提出一种基于路径的关系抽取模型，实验结果表明该模型很好地利用了包含单目标实体的句子信息。本工作来自于刘知远老师组里。&lt;/p&gt;&lt;h2&gt;&lt;a href="http://rsarxiv.github.io/#Language-as-a-Latent-Variable-Discrete-Generative-Models-for-Sentence-Compression" class="" data-editable="true" data-title="PaperWeekly"&gt;PaperWeekly&lt;/a&gt;&lt;a href="https://arxiv.org/pdf/1609.07317v1.pdf" data-editable="true" data-title="Language as a Latent Variable: Discrete Generative Models for Sentence Compression"&gt;Language as a Latent Variable: Discrete Generative Models for Sentence Compression&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;本文研究内容为句子压缩，作者提出了一种VAE模型，先根据背景语言模型生成一个latent摘要句子，然后根据latent句子生成目标句子。实验中用到了抽取式和摘要式两种监督方法，并在最后探索出半监督方法的效果可能会好于监督学习的方法。句子压缩任务可以看做是sentence-level的文本摘要任务，本文的方法同样可以启发文本摘要任务的研究。本文工作来自deepmind，并且是EMNLP 2016 Accepted。&lt;/p&gt;&lt;h2&gt;&lt;a href="http://rsarxiv.github.io/#Annotating-Derivations-A-New-Evaluation-Strategy-and-Dataset-for-Algebra-Word-Problems" class="" data-editable="true" data-title="PaperWeekly"&gt;PaperWeekly&lt;/a&gt;&lt;a href="https://arxiv.org/pdf/1609.07197v1.pdf" data-editable="true" data-title="Annotating Derivations: A New Evaluation Strategy and Dataset for Algebra Word Problems"&gt;Annotating Derivations: A New Evaluation Strategy and Dataset for Algebra Word Problems&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;本文研究的内容很有意思，是algebra word problems，是自动求解代数问题的基础，这个问题可以等同为一个semantic parsing的问题，模型通过读入一段文本，理解其意思，然后构造出一个方程，最后给出方程的解。作者还给出了一个新的dataset和评价标准，本文工作来自伊大香槟分校和微软研究院。这个task本身非常有意思，也很有难度。&lt;/p&gt;&lt;h2&gt;&lt;a href="http://rsarxiv.github.io/#Online-Segment-to-Segment-Neural-Transduction" class="" data-editable="true" data-title="PaperWeekly"&gt;PaperWeekly&lt;/a&gt;&lt;a href="https://arxiv.org/pdf/1609.08194v1.pdf" data-editable="true" data-title="Online Segment to Segment Neural Transduction"&gt;Online Segment to Segment Neural Transduction&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;本文针对之前encoder-decoder模型面临的一个瓶颈，即将输入全部读入并保存为一个固定大小的hidden states，作者提出了一种新的attention机制，将attention权重作为一种隐变量，在句子摘要上证明了效果，本文工作来自deepmind。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://rsarxiv.github.io/#%E4%B8%80%E5%91%A8%E5%80%BC%E5%BE%97%E8%AF%BB%EF%BC%88%E5%81%8F%E5%BA%94%E7%94%A8%EF%BC%89" class="" data-editable="true" data-title="PaperWeekly"&gt;PaperWeekly&lt;/a&gt;一周值得读（偏应用）&lt;/h1&gt;&lt;h2&gt;&lt;a href="http://rsarxiv.github.io/#Google%E2%80%99s-Neural-Machine-Translation-System-Bridging-the-Gap-between-Human-and-Machine-Translation" class="" data-editable="true" data-title="PaperWeekly"&gt;PaperWeekly&lt;/a&gt;&lt;a href="https://arxiv.org/pdf/1609.08144.pdf" data-editable="true" data-title="Google’s Neural Machine Translation System: Bridging the Gap between Human and Machine Translation"&gt;Google’s Neural Machine Translation System: Bridging the Gap between Human and Machine Translation&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;本周最受关注，也备受争议的一篇paper，Google放出了他们最新一代的机器翻译系统，一种神经网络翻译系统。指标上的提升，说明了效果确实有提升，但不代表具体到每一句话都能令人满意。&lt;/p&gt;&lt;h2&gt;&lt;a href="http://rsarxiv.github.io/#UbuntuWorld-1-0-LTS-A-Platform-for-Automated-Problem-Solving-amp-Troubleshooting-in-the-Ubuntu-OS" class="" data-editable="true" data-title="PaperWeekly"&gt;PaperWeekly&lt;/a&gt;&lt;a href="https://arxiv.org/pdf/1609.08524v1.pdf" data-editable="true" data-title="UbuntuWorld 1.0 LTS - A Platform for Automated Problem Solving &amp;amp; Troubleshooting in the Ubuntu OS"&gt;UbuntuWorld 1.0 LTS - A Platform for Automated Problem Solving &amp;amp; Troubleshooting in the Ubuntu OS&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;本文给出了一个Ubuntu系统问题咨询和错误排查的bot，可以在bash terminal中运行，通过增强学习进行训练，可以回答一些基本的问题和错误排查。demo bot被封装成一个python package，即插即用。回答问题的数据来自于Ask Ubuntu。测试了DQN在特定领域bot中的效果，定义了几组简单的命令作为action，open/close，install/remove等等，technical support是客户服务中难度非常大的一类，本文尝试了用一种完全端到端+增强学习的方案来探索解决此类问题。&lt;/p&gt;&lt;h2&gt;&lt;a href="http://rsarxiv.github.io/#Character-Sequence-Models-for-ColorfulWords" class="" data-editable="true" data-title="PaperWeekly"&gt;PaperWeekly&lt;/a&gt;&lt;a href="https://arxiv.org/pdf/1609.08777v1.pdf" data-editable="true" data-title="Character Sequence Models for ColorfulWords"&gt;Character Sequence Models for ColorfulWords&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;本文研究的内容非常有意思，输入一个word，输出这个word对应的color并着色。作者构建了一组大型的color-name对数据集，来做一个color图灵测试。该系统的demo地址：&lt;a href="http://colorlab.us./" data-editable="true" data-title="colorlab.us. 的页面"&gt;http://colorlab.us./&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;&lt;a href="http://rsarxiv.github.io/#Equation-Parsing-Mapping-Sentences-to-Grounded-Equations" class="" data-editable="true" data-title="PaperWeekly"&gt;PaperWeekly&lt;/a&gt;&lt;a href="https://arxiv.org/pdf/1609.08824v1.pdf" data-editable="true" data-title="Equation Parsing: Mapping Sentences to Grounded Equations"&gt;Equation Parsing: Mapping Sentences to Grounded Equations&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;本文研究的内容非常有趣也很有实际意义，即从文本中抽取出数学关系，作者将该任务定义如下：给定一句话，抽取出其中的变量和数学关系，并用方程表示。这个研究可以被应用在新闻机器人上，财经、体育等。&lt;/p&gt;&lt;h2&gt;&lt;a href="http://rsarxiv.github.io/#Inducing-Multilingual-Text-Analysis-Tools-Using-Bidirectional-Recurrent-Neural-Networks" class="" data-editable="true" data-title="PaperWeekly"&gt;PaperWeekly&lt;/a&gt;&lt;a href="https://arxiv.org/pdf/1609.09382v1.pdf" data-editable="true" data-title="Inducing Multilingual Text Analysis Tools Using Bidirectional Recurrent Neural Networks"&gt;Inducing Multilingual Text Analysis Tools Using Bidirectional Recurrent Neural Networks&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;资源稀缺语言的标注问题是一个经典的问题，一般的做法是将资源丰富的语音对齐映射过去进行标注，自动词对齐的错误会影响最终的效果。本文针对这个问题，提出了一种BiRNN模型，并且融合外部信息解决问题。该模型具有以下特点：1、不需要词对齐信息；2、不限定语言，可用于多种资源少的语言；3、提供一种真正的多语言tagger。&lt;/p&gt;&lt;h1&gt;一周资源&lt;/h1&gt;&lt;h2&gt;&lt;a href="http://rsarxiv.github.io/#THULAC" class="" data-editable="true" data-title="PaperWeekly"&gt;PaperWeekly&lt;/a&gt;&lt;a href="https://github.com/thunlp/THULAC.so" data-editable="true" data-title="THULAC"&gt;THULAC&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;THULAC.so：一个高效的中文词法分析工具包，为了满足Python下分词对速度的要求，发布了一个产生.so文件的THULAC版本，并且提供Python调用的示例代码。这样THULAC在Python下的分词速度得到大幅度提高。&lt;/p&gt;&lt;h2&gt;&lt;a href="http://rsarxiv.github.io/#tinyflow" class="" data-editable="true" data-title="PaperWeekly"&gt;PaperWeekly&lt;/a&gt;&lt;a href="https://github.com/tqchen/tinyflow" data-editable="true" data-title="tinyflow"&gt;tinyflow&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;DMLC陈天奇开放了一个两千行代码的样例项目，教你如何从头开始打造一个和TensorFlow一样API的深度学习系统。其中涉及到一个非常重要的开源库NNVM，地址： &lt;a href="https://github.com/dmlc/nnvm" data-editable="true" data-title="GitHub - dmlc/nnvm: Intermediate Computational Graph Representation  for Deep Learning Systems"&gt;GitHub - dmlc/nnvm: Intermediate Computational Graph Representation  for Deep Learning Systems&lt;/a&gt; 。博客介绍：&lt;a href="http://dmlc.ml/2016/09/30/build-your-own-tensorflow-with-nnvm-and-torch.html" data-editable="true" data-title="Build your own TensorFlow with NNVM and Torch"&gt;Build your own TensorFlow with NNVM and Torch&lt;/a&gt; ，中文版：&lt;a href="http://weibo.com/ttarticle/p/show?id=2309404025388832575825#_0" data-editable="true" data-title="NNVM打造模块化深度学习系统"&gt;NNVM打造模块化深度学习系统&lt;/a&gt;&lt;/p&gt;&lt;h1&gt;&lt;a href="http://rsarxiv.github.io/#%E5%B9%BF%E5%91%8A%E6%97%B6%E9%97%B4" class="" data-editable="true" data-title="PaperWeekly"&gt;PaperWeekly&lt;/a&gt;广告时间&lt;/h1&gt;&lt;p&gt;PaperWeekly是一个分享知识和交流学问的民间组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。&lt;/p&gt;&lt;p&gt;微信公众号：PaperWeekly微博账号：PaperWeekly（&lt;a href="http://weibo.com/u/paperweekly" data-editable="true" data-title="weibo.com 的页面"&gt;http://weibo.com/u/paperweekly&lt;/a&gt; ）知乎专栏：PaperWeekly（&lt;a href="https://zhuanlan.zhihu.com/paperweekly" data-editable="true" data-title="PaperWeekly - 知乎专栏"&gt;PaperWeekly - 知乎专栏&lt;/a&gt; ）微信交流群：微信+ zhangjun168305（请备注：加群 or 加入paperweekly）&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/22723620&amp;pixel&amp;useReferer"/&gt;</description><author>张俊</author><pubDate>Sat, 01 Oct 2016 10:58:39 GMT</pubDate></item><item><title>PaperWeekly 第七期 -- 基于Char-level的NMT OOV解决方案</title><link>https://zhuanlan.zhihu.com/p/22700538</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-ea9f4f4503d2ed9e15a56fe56e26e98d_r.jpg"&gt;&lt;/p&gt;&lt;h1&gt;引言&lt;/h1&gt;&lt;p&gt;神经网络机器翻译(NMT)是seq2seq模型的典型应用，从2014年提出开始，其性能就接近于传统的基于词组的机器翻译方法，随后，研究人员不断改进seq2seq模型，包括引入注意力模型、使用外部记忆机制、使用半监督学习和修改训练准则等方法，在短短2年时间内使得NMT的性能超过了传统的基于词组的机器翻译方法。在27号谷歌宣布推出谷歌神经网络机器翻译系统，实现了NMT的首个商业化部署，使得NMT真正从高校实验室走向了实际应用。本期Paperweekly的主题是神经网络机器翻译下的字符级方法，主要用来解决NMT中的out-of-vocabulary词问题，分别是：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;A Character-Level Decoder without Explicit Segmentation for Neural Machine Translation，2016&lt;/li&gt;&lt;li&gt;Achieving Open Vocabulary Neural Machine Translation with Hybrid Word-Character Models，2016&lt;/li&gt;&lt;li&gt;Character-based Neural Machine Translation，Costa-Jussa, 2016&lt;/li&gt;&lt;li&gt;Character-based Neural Machine Translation，Ling, 2016&lt;/li&gt;&lt;li&gt;Neural Machine Translation of Rare Words with Subword Units，2016&lt;/li&gt;&lt;/ol&gt;&lt;h1&gt;&lt;a href="https://arxiv.org/abs/1603.06147" data-editable="true" data-title="A Character-Level Decoder without Explicit Segmentation for Neural Machine Translation" class=""&gt;A Character-Level Decoder without Explicit Segmentation for Neural Machine Translation&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;作者&lt;/h2&gt;&lt;p&gt;Junyoung Chung, Kyunghyun Cho, Yoshua Bengio&lt;/p&gt;&lt;h2&gt;单位&lt;/h2&gt;&lt;p&gt;Universite de Montreal&lt;/p&gt;&lt;h2&gt;关键词&lt;/h2&gt;&lt;p&gt;Segmentation, Character-level, Bi-scale recurrent network&lt;/p&gt;&lt;h2&gt;文章来源&lt;/h2&gt;&lt;p&gt;ACL 2016&lt;/p&gt;&lt;h2&gt;问题&lt;/h2&gt;&lt;p&gt;能否在不需要分词的前提下直接在字符级进行神经机器翻译。&lt;/p&gt;&lt;h2&gt;模型&lt;/h2&gt;&lt;p&gt;在讲模型之前，本文花了大量篇幅论证为何需要在不分词的前提下进行字符级翻译，首先作者总结了词级翻译的缺点。&lt;/p&gt;&lt;p&gt;词级翻译的缺点包括：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;任何一个语言都没有完美的分词算法，完美的分词算法应该能够将任意句子划分为lexemes和morphemes组成的序列&lt;/li&gt;&lt;li&gt;导致的问题就是在词典中经常充斥着许多共享一个lexeme但有着不同morphology的词，比如run,runs,ran,running可能都存在于词典中，每个词都对应一个词向量，但是它们明显共享相同的lexeme——run&lt;/li&gt;&lt;li&gt;存在unknown word问题和rare word问题，rare word问题是指某些词典中词在训练集中出现次数过少，导致无法训练得到很好的词向量；unknown word问题是指不在词典中的词被标记为UNK（OOV词）&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;接着作者指出使用字符集翻译可以解决上述问题：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;使用LSTM或GRU可以解决长时依赖问题&lt;/li&gt;&lt;li&gt;使用字符级建模可以避免许多词态变形词出现在词典中&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;然而上述字符级方法依然需要进行分词，然后对每个词的字符序列进行编码，因此引出了本文的motivation，即是否能直接在不分词的字符序列上进行翻译。&lt;/p&gt;&lt;p&gt;本文使用的模型同样是经典的seq2seq模型，其创新点主要在decoder端，引入了一种新的网络结构biscale RNN，来捕获字符和词两个timescale上的信息。具体来说，主要分为faster层和slower层，faster层的gated激活值取决于上一步的faster和slower层的激活值，faster层要想影响slower层，则必须要是faster层处理完当前数据，并且进行重置。换句话说，slower层无法接受faster层输入，直到faster层处理完其数据，因此比faster层要慢，而这样的层次结构也对应字符和词在timescale上的关系。下图为网络结构示意图。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-bfe8f04b9da6af7bcb2d69c4ea4772c9.png" data-rawwidth="1224" data-rawheight="742"&gt;&lt;/p&gt;&lt;p&gt;在4种语言翻译任务上的实验显示完全可以在不分词的情况下进行字符级翻译，性能优于state-of-the-art的非神经翻译系统&lt;/p&gt;&lt;h2&gt;相关工作&lt;/h2&gt;&lt;p&gt;Sennrich ACL2016提出使用BPE算法对subword建模。Kim AAAI2016中提出直接对字符进行encode，Costa-jussa ICLR2016中将该模型用在了NMT任务中。Ling ICLR2016的工作中使用Bi-RNN来编码字符序列。以上工作基于字符级展开，但它们都依赖于知道如何将字符分为词，即分词。本文研究能否在不分词的情况下进行字符级翻译。&lt;/p&gt;&lt;h2&gt;简评&lt;/h2&gt;&lt;p&gt;本文是Bengio组工作，Bi-scale RNN受启发于该组之前提出的GF-RNN，本文创新点主要是提出了一种新的RNN结构，可以在字符和词两个timescales上进行处理，输出字符序列不需要进行分词。不足是未考虑encoder端是否也可以直接使用未分词的字符序列，而是仅仅使用了分词后的BPE序列。&lt;/p&gt;&lt;h1&gt;&lt;a href="https://arxiv.org/pdf/1604.00788v2.pdf" data-editable="true" data-title="Achieving Open Vocabulary Neural Machine Translation with Hybrid Word-Character Models" class=""&gt;Achieving Open Vocabulary Neural Machine Translation with Hybrid Word-Character Models&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;作者&lt;/h2&gt;&lt;p&gt;Minh-Thang Luong and Christopher D. Manning&lt;/p&gt;&lt;h2&gt;单位&lt;/h2&gt;&lt;p&gt;Stanford University&lt;/p&gt;&lt;h2&gt;关键词&lt;/h2&gt;&lt;p&gt;OOV, hybrid word-character models, NMT&lt;/p&gt;&lt;h2&gt;文章来源&lt;/h2&gt;&lt;p&gt;ACL 2016&lt;/p&gt;&lt;h2&gt;问题&lt;/h2&gt;&lt;p&gt;机器翻译里面的OOV问题, 如何处理UNK&lt;/p&gt;&lt;h2&gt;模型&lt;/h2&gt;&lt;p&gt;提出了一种混合word-character的NMT模型.在训练难度和复杂度不是很高的情况下,同时解决源语言和目标语言的OOV问题.&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-c6266b642821032437d60e65989dee7a.png" data-rawwidth="372" data-rawheight="414"&gt;&lt;/p&gt;&lt;p&gt;这个图表达了模型的整体思路. 大多数情况下,模型在word-level进行translation. 当出现unk的时候,则会启用character-level的模型. 对source unk, 由character-level模型来得到它的representation; 对target unk, 用character-level模型来产生word.&lt;/p&gt;&lt;ol&gt;&lt;li&gt;整体上采用他们组以前提出的基于global attention的encoder-decoder模型. RNN采用的是deep LSTM.&lt;/li&gt;&lt;li&gt;源语言端和目标语言端的character-level模型都是基于character的deep LSTM. 对源语言端来说, 它的character-level模型是context independent的. 隐层状态全部初始化为0, 因此在训练时可以预先计算mini-batch里的每一个rare word的representation. 而对于目标语言端来说, 它的character-level模型是context dependent的.它的第一层的hidden state要根据当前context来初始化, 其它部分都初始化为0.训练时, 在目标语言的decoder阶段, 首先用word-level的decoder产生句子, 这时句子里包含了一些unk. 接着对这些unk, 用character-level模型以batch mode来产生rare word.&lt;/li&gt;&lt;li&gt;对于目标语言端character-level模型的初始化问题, 作者提出了两种方法来表示当前的context. 一种叫做same-path, 用预测的softmax层之前的ht来表达. 但是因为ht是用来预测的, 所以所有ht的值都会比较相似,这样很难用来产生不同的目标rare word. 因此作者提出了第二种表达叫做separate-path, 用ht’来表达context. ht’不用预测unk, 是专门作为context在character-level的输入的. 它的计算方法和ht’相同,只是用了一个不一样的矩阵.&lt;/li&gt;&lt;li&gt;模型训练的目标函数是cross-entropy loss, 同时考虑了word level和character level的loss.&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;相关工作&lt;/h2&gt;&lt;p&gt;NMT的模型分为word-level和character-level的. 对于word-level模型,要解决OOV问题, 之前的工作提出了unk replacement (Luong et al. 2015b), 使用大字典并在softmax时进行采样(Jean et al. 2015), 对unk进行Huffman编码(Chitnis et al. 2015)等方法. 而对于character-level的模型, 本身可以处理OOV词, 但是训练难度和复杂度会增加.&lt;/p&gt;&lt;h2&gt;简评&lt;/h2&gt;&lt;p&gt;本文的创新之处在于提出了混合word-character model的NMT模型. 这个混合模型结合了二者的优点, 在保证模型复杂度较低的同时,实现了很好的效果.因为加入了character, 特别适合单词有丰富变形的语言.&lt;/p&gt;&lt;h1&gt;&lt;a href="http://arxiv.org/abs/1511.04586" data-editable="true" data-title="Character-based Neural Machine Translation" class=""&gt;Character-based Neural Machine Translation&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;作者&lt;/h2&gt;&lt;p&gt;Marta R. Costa-jussa and Jose A. R. Fonollosa&lt;/p&gt;&lt;h2&gt;单位&lt;/h2&gt;&lt;p&gt;TALP Research CenterUniversitat Politecnica de Catalunya, Barcelona&lt;/p&gt;&lt;h2&gt;关键词&lt;/h2&gt;&lt;p&gt;NMT，character-based word embeddings，CNN&lt;/p&gt;&lt;h2&gt;文章来源&lt;/h2&gt;&lt;p&gt;ICLR2016&lt;/p&gt;&lt;h2&gt;问题&lt;/h2&gt;&lt;p&gt;本文提出使用character-based word embeddings的NMT，可以在一定程度上克服机器翻译中OOV问题。&lt;/p&gt;&lt;h2&gt;模型&lt;/h2&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-4de6daed90818f0e6905912ded052c25.png" data-rawwidth="484" data-rawheight="656"&gt;&lt;p&gt;如上图所示，这篇论文使用的基本模型架构是一个带attention机制的seq2seq的encoder-decoder的架构，使用的神经网络单元是GRU。encoder把源句子转化成一个向量（双向），使用attention的机制来捕获context信息，decoder把context解码成目标句子。网络的输入仍然使用word embedding，但是作者在获取word embedding的时候使用的方法不同。本文是基于词中的character来生成word embedding的，具体方法如下图所示。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-709e2b33e1f6486d4a5ce1786431f223.png" data-rawwidth="968" data-rawheight="886"&gt;&lt;/p&gt;&lt;p&gt;上图中，最底层是一个character-based embedding组成的序列，对应的是每个词中的字母。然后这个序列被送入一个由不同长度的一维卷积过滤器组成的集合中进行处理，不同的长度对应单词中不同数量的字母（从1到7）。对于每个卷积过滤器，只取最大的值作为输出。然后把每个卷积过滤器输出的最大值连接起来组成一个向量。最后这个向量再通过两层Highway layer的处理作为最终的word embeddings。这个方法的详细信息可以参考Kim的论文&lt;a href="http://arxiv.org/abs/1508.06615" data-editable="true" data-title="Character-Aware Neural Language Models"&gt;Character-Aware Neural Language Models&lt;/a&gt;(2016)。&lt;/p&gt;&lt;h2&gt;资源&lt;/h2&gt;&lt;ol&gt;&lt;li&gt;本文数据集[German-English WMT data] (&lt;a href="http://www.statmt.org/wmt15/translation-task.html" data-editable="true" data-title="Translation Task"&gt;Translation Task&lt;/a&gt;) &lt;/li&gt;&lt;li&gt;建立对比模型使用的软件包&lt;a href="http://dl4mt.computing.dcu.ie/" data-editable="true" data-title="DL4MT"&gt;DL4MT&lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;相关工作&lt;/h2&gt;&lt;p&gt;（1）2003年，基于短语的统计机器翻译模型。Statistical Phrase-Based Translation （2）2013年，基于神经网络的机器翻译模型。Recurrent continuous translation models （3）2014年，seq2seq的神经网络模型用于机器翻译。Sequence to sequence learning with neural networks&lt;/p&gt;&lt;h2&gt;简评&lt;/h2&gt;&lt;p&gt;本文作者将基于character来产生word embedding的方法应用于机器翻译，可以在一定程度上克服OOV的问题。同时，由于利用了单词内部的信息，这篇论文提出的方法对于词形变化丰富的语言的翻译也产生了更好的效果。但是，作者只是在source side使用了上述方法，对于target side，仍然面临词典大小的限制。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://arxiv.org/abs/1511.04586" data-editable="true" data-title="CHARACTER-BASED NEURAL MACHINE TRANSLATION" class=""&gt;CHARACTER-BASED NEURAL MACHINE TRANSLATION&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;作者&lt;/h2&gt;&lt;p&gt;Wang Ling, Isabel Trancoso, Chris Dyer, Alan W Black&lt;/p&gt;&lt;h2&gt;单位&lt;/h2&gt;&lt;ol&gt;&lt;li&gt;LF Spoken Systems Lab,Instituto Superior Tecnico Lisbon, Portugal&lt;/li&gt;&lt;li&gt;Language Technologies Institute, Carnegie Mellon University Pittsburga, PA 15213, USA&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;关键词&lt;/h2&gt;&lt;p&gt;NMT, Character-Based&lt;/p&gt;&lt;h2&gt;文章来源&lt;/h2&gt;&lt;p&gt;ICLR 2016&lt;/p&gt;&lt;h2&gt;问题&lt;/h2&gt;&lt;p&gt;尝试在字符级别上应用神经机器学习方法&lt;/p&gt;&lt;h2&gt;模型&lt;/h2&gt;&lt;p&gt;在带注意力机制的神经机器学习模型的前后端增加字符到词（C2W)和词向量到字符（V2C）的模块。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-5dc8bd622f6638c5da5250dedbdbb68e.png" data-rawwidth="918" data-rawheight="463"&gt;&lt;/p&gt;&lt;p&gt;图中，小矩形是一个双向LSTM，双向LSTM的前向和后向的最终状态以及bias之和为词的向量表示。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-7f72e5c3da4a5795865c07ecf0404c60.png" data-rawwidth="901" data-rawheight="395"&gt;&lt;p&gt;这个模块主要由三个步骤组成：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;将字符转换为向量表示。&lt;/li&gt;&lt;li&gt;将字符向量和之前模型产生注意力向量的a和目标词在前向LSTM中产生的向量表示做拼接并输入到LSTM。&lt;/li&gt;&lt;li&gt;将得到的向量输入到softmax层得到结果。&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;相关工作&lt;/h2&gt;&lt;ol&gt;&lt;li&gt;Neural machine translation by jointly learning to align and translate.&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;简评&lt;/h2&gt;&lt;p&gt;这篇文章在基于注意力机制的机器翻译模型上增加了两个模块。由于是基于字符集别的模型，该模型自然可以学得一些语言中的前后缀在翻译中的关系。此外，基于字符级别的模型在翻译未知词时有灵活性。可是，文中也提到，该模型为能够准确的翻译未知词。并且该文也没有明确表明该模型和其他模型相比具有哪些明显的优势。从实际上来说，该模型在V2C部分的训练速度慢是一个很大的弱点，因此若仅根据文章的表述，该模型的实际应用价值应该有限。&lt;/p&gt;&lt;h1&gt;&lt;a href="https://arxiv.org/abs/1508.07909" data-editable="true" data-title="Neural Machine Translation of Rare Words with Subword Units"&gt;Neural Machine Translation of Rare Words with Subword Units&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;作者&lt;/h2&gt;&lt;p&gt;Rico Sennrich and Barry Haddow and Alexandra Birch&lt;/p&gt;&lt;h2&gt;单位&lt;/h2&gt;&lt;p&gt;School of Informatics, University of Edinburgh&lt;/p&gt;&lt;h2&gt;关键词&lt;/h2&gt;&lt;p&gt;NMT;Rare Words;Subword Units;BPE&lt;/p&gt;&lt;h2&gt;文章来源&lt;/h2&gt;&lt;p&gt;ACL 2016&lt;/p&gt;&lt;h2&gt;问题&lt;/h2&gt;&lt;p&gt;NMT中的OOV（集外词）和罕见词（Rare Words）问题通常用back-off 词典的方式来解决，本文尝试用一种更简单有效的方式（Subword Units）来表示开放词表。&lt;/p&gt;&lt;h2&gt;模型&lt;/h2&gt;&lt;p&gt;本文从命名实体、同根词、外来语、组合词（罕见词有相当大比例是上述几种）的翻译策略中得到启发，认为把这些罕见词拆分为“子词单元”(subword units)的组合，可以有效的缓解NMT的OOV和罕见词翻译的问题。子词单元的拆分策略，则是借鉴了一种数据压缩算法：Byte Pair Encoding(BPE)(Gage,1994)算法。该算法的操作过程和示例如Figure1所示。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-062443ab5a0364552b0deba26fdee66c.jpg" data-rawwidth="371" data-rawheight="559"&gt;&lt;/p&gt;&lt;p&gt;不同于(Chitnis and DeNero,2015)提出的霍夫曼编码，这里的压缩算法不是针对于词做变长编码，而是对于子词来操作。这样，即使是训练语料里未见过的新词，也可以通过子词的拼接来生成翻译。本文还探讨了BPE的两种编码方式：一种是源语言词汇和目标语言词汇分别编码，另一种是双语词汇联合编码。前者的优势是让词表和文本的表示更紧凑，后者则可以尽可能保证原文和译文的子词切分方式统一。从实验结果来看，在音译或简单复制较多的情形下（比如英德）翻译，联合编码的效果更佳。实验结果分别在WMT15英德和英俄的任务上得到1.1和1.3个BLEU值的提升。&lt;/p&gt;&lt;h2&gt;资源&lt;/h2&gt;&lt;p&gt;本文提出的子词拆分算法代码在 &lt;a href="https://github.com/rsennrich/subword-nmt" data-editable="true" data-title="GitHub - rsennrich/subword-nmt: Subword Neural Machine Translation"&gt;GitHub - rsennrich/subword-nmt: Subword Neural Machine Translation&lt;/a&gt;实验所用的NMT系统为Groundhog: github.com/sebastien-j/LV_groundhog实验数据来自WMT 2015&lt;/p&gt;&lt;h2&gt;相关工作&lt;/h2&gt;&lt;p&gt;OOV的处理一直是机器翻译研究的重点。基于字符的翻译在短语SMT模型中就已被提出，并在紧密相关的语种对上验证是成功的(Vilar et al., 2007; Tiedemann,2009; Neubig et al., 2012)。 此外还有各种形态素切分方法应用于短语模型，(Nießen and Ney,2000; Koehn and Knight, 2003; Virpioja et al.,2007; Stallard et al., 2012)。对于NMT，也有很多基于字符或形态素的方法用于生成定长连续词向量(Luong et al., 2013; Botha and Blunsom, 2014; Ling et al., 2015a; Kim et al., 2015)。与本文类似的一项工作 (Ling et al., 2015b)发现在基于词的方法上没有明显提升。其与本文的一个区别在于，attention机制仍然在词层级进行操作，而本文在子词层级上。&lt;/p&gt;&lt;h2&gt;简评&lt;/h2&gt;&lt;p&gt;这篇文章的创新点在于提出了一种介乎字符和单词之间，也不同于字符n-gram的文本表示单元，并借鉴BPE压缩算法，在词表大小和文本长度两个方面取得一个较为平衡的状态。应用在非同源/近源的语言对（如英汉）是否可以有类似的效果，尚待研究。在NMT模型的优化上，也还有探讨的空间。本文的实验评价方法值得学习，单看BLEU值并不觉得有惊艳之处，但加上CHR F3和(对所有词、罕见词和集外词分别统计的)unigram F1这两个评价指标，尤其是Figure2和3画出来的效果，还是让人比较信服的。&lt;/p&gt;&lt;h1&gt;总结&lt;/h1&gt;&lt;p&gt;OOV词对于翻译性能和实用性的影响非常巨大，如何处理OOV词并达到open vocabulary一直是NMT的主要研究方向。传统方法基于单词级别来处理该问题，比如使用UNK替换、扩大词典规模等方法，往往治标不治本。因此最近一些研究者提出基于字符的NMT模型，取得了不错的成绩，字符级方法的主要优势包括不受语言的形态变化、能预测出词典中未出现的单词并降低词典大小等。值得一提的是，基于字符的模型不仅局限于NMT上，任何生成模型都面临OOV词问题，因此是否能够将字符级方法用在其他NLP任务，比如阅读理解或文本摘要上，让我们拭目以待。&lt;/p&gt;&lt;p&gt;以上为本期Paperweekly的主要内容，感谢EdwardHux、Mygod9、Jaylee1992、Susie和AllenCai五位同学的整理。&lt;/p&gt;&lt;h1&gt;广告时间&lt;/h1&gt;&lt;p&gt;PaperWeekly是一个分享知识和交流学问的民间组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。&lt;/p&gt;&lt;p&gt;微信公众号：PaperWeekly&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-ea9f4f4503d2ed9e15a56fe56e26e98d.jpg" data-rawwidth="430" data-rawheight="430"&gt;微博账号：PaperWeekly（&lt;a href="http://weibo.com/u/2678093863" data-editable="true" data-title="PaperWeekly的微博" class=""&gt;PaperWeekly的微博&lt;/a&gt; ）知乎专栏：PaperWeekly（&lt;a href="https://zhuanlan.zhihu.com/paperweekly" data-editable="true" data-title="PaperWeekly - 知乎专栏"&gt;PaperWeekly - 知乎专栏&lt;/a&gt; ）微信交流群：微信+ zhangjun168305（请备注：加群 or 加入paperweekly）&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/22700538&amp;pixel&amp;useReferer"/&gt;</description><author>张俊</author><pubDate>Fri, 30 Sep 2016 11:39:50 GMT</pubDate></item><item><title>cs.CL weekly 2016.09.19-2016.09.23</title><link>https://zhuanlan.zhihu.com/p/22602959</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-ea9f4f4503d2ed9e15a56fe56e26e98d_r.jpg"&gt;&lt;/p&gt;&lt;h1&gt;一周值得读&lt;/h1&gt;&lt;h2&gt;&lt;a href="http://120.52.73.80/arxiv.org/pdf/1609.04904v1.pdf" data-editable="true" data-title="Long-Term Trends in the Public Perception of Artificial Intelligence"&gt;Long-Term Trends in the Public Perception of Artificial Intelligence&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;本文研究了30年来纽约时报对AI的报道，研究了人们这30年来对AI的兴趣、关注度和各种各样的讨论。是一篇很有意思的文章，是一种长时间段内的舆情监测和分析。&lt;/p&gt;&lt;h2&gt;&lt;a href="http://120.52.73.77/arxiv.org/pdf/1609.04873v1.pdf" data-editable="true" data-title="Distant Supervision for Relation Extraction beyond the Sentence Boundary"&gt;Distant Supervision for Relation Extraction beyond the Sentence Boundary&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;本文研究的问题是非结构化文本中的关系抽取问题，针对传统方法在抽取关系时仅限于单个句子，本文提出了一种新的方法，从多个句子中进行关系抽取。&lt;/p&gt;&lt;h2&gt;&lt;a href="http://120.52.73.79/arxiv.org/pdf/1609.04938v1.pdf" data-editable="true" data-title="What You Get Is What You See: A Visual Markup Decompiler"&gt;What You Get Is What You See: A Visual Markup Decompiler&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;【转发较多】本文研究的问题是如何从web页面中生成html代码，以及如何从公式图片中生成latex代码，为此作者构造了两个相关的大型数据集，用了完全数据驱动的端到端训练方法得到了不错的效果。本文工作来自Harvard。&lt;/p&gt;&lt;p&gt;Demo|Dataset|Code: &lt;a href="http://lstm.seas.harvard.edu/latex/"&gt;http://lstm.seas.harvard.edu/latex/&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;&lt;a href="http://120.52.73.80/arxiv.org/pdf/1609.05244v1.pdf" data-editable="true" data-title="Select-Additive Learning: Improving Cross-individual Generalization in Multimodal Sentiment Analysis"&gt;Select-Additive Learning: Improving Cross-individual Generalization in Multimodal Sentiment Analysis&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;本文研究的内容是多模态情感分析，针对当前相关高质量数据集规模太小造成的情感依赖于个体特征的问题，提出了一种Select-Additive学习方法提高通用性。&lt;/p&gt;&lt;h2&gt;&lt;a href="http://120.52.73.78/arxiv.org/pdf/1609.05234v1.pdf" data-editable="true" data-title="Interactive Spoken Content Retrieval by Deep Reinforcement Learning"&gt;Interactive Spoken Content Retrieval by Deep Reinforcement Learning&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;本文研究的内容是DQN算法来做语音内容检索，通过人机交互来完成内容检索。DQN相比传统的RL模型明显的优势在于不依赖hand-crafted features。本文被Interspeech 2016录用。&lt;/p&gt;&lt;h2&gt;&lt;a href="http://arxiv.org/pdf/1609.05600v1.pdf" data-editable="true" data-title="Graph-Structured Representations for Visual Question Answering"&gt;Graph-Structured Representations for Visual Question Answering&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;本文研究内容为VQA，VQA的主要挑战在于对visual和text两个领域都需要理解。传统的模型中常常忽略场景中的结构和问题中的语言结构，本文针对这两个问题提出了一种图模型，取得了不错的效果。&lt;/p&gt;&lt;h2&gt;&lt;a href="http://arxiv.org/pdf/1609.05787v1.pdf" data-editable="true" data-title="Context-aware Sequential Recommendation"&gt;Context-aware Sequential Recommendation&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;用户行为建模是推荐系统中的一个关键部件，行为数据是序列数据，天然适合用RNN来建模。但实际应用中context信息(time,location,weahter)也很重要，本文针对这个问题提出了一种CA-RNN模型将context考虑在内，取得了不错效果。&lt;/p&gt;&lt;h2&gt;&lt;a href="http://120.52.73.78/arxiv.org/pdf/1609.05284v1.pdf" data-editable="true" data-title="ReasoNet: Learning to Stop Reading in Machine Comprehension"&gt;ReasoNet: Learning to Stop Reading in Machine Comprehension&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;本文研究内容为机器阅读理解，之前效果不错的方法大多数停留在有限的几轮reasoning，本文用增强学习来动态地决定是否继续读下去或者停下来进行答案选择。本文工作来自微软研究院。&lt;/p&gt;&lt;h2&gt;&lt;a href="http://120.52.73.76/arxiv.org/pdf/1609.06038v1.pdf" data-editable="true" data-title="Enhancing and Combining Sequential and Tree LSTM for Natural Language Inference"&gt;Enhancing and Combining Sequential and Tree LSTM for Natural Language Inference&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;本文研究内容为自然语言推理，作者认为LSTM类的模型潜力并没有被充分挖掘，基于此，本文在传统LSTM模型的基础上增加了syntactic parse信息，得到了更好的效果。&lt;/p&gt;&lt;h2&gt;&lt;a href="http://120.52.73.80/arxiv.org/pdf/1609.06127v1.pdf" data-editable="true" data-title="A framework for mining process models from emails logs"&gt;A framework for mining process models from emails logs&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;本文研究的内容是邮件日志的挖掘，作者提出了一种无监督的挖掘方法，并且提出了一种半自动化的邮件标注方法。&lt;/p&gt;&lt;h2&gt;&lt;a href="http://120.52.73.79/arxiv.org/pdf/1609.06686v1.pdf" data-editable="true" data-title="Character-level and Multi-channel Convolutional Neural Networks for Large-scale Authorship Attribution"&gt;Character-level and Multi-channel Convolutional Neural Networks for Large-scale Authorship Attribution&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;本文研究内容为authorship attribution，是一个典型的多分类任务。作者利用字符级别的多通道CNN模型对大规模dataset进行了建模，取得了不错的结果。作者之一来自aylien.com 公司，一家非常出色的NLP SaaS 公司。&lt;/p&gt;&lt;h2&gt;&lt;a href="http://120.52.73.76/arxiv.org/pdf/1609.06649v1.pdf" data-editable="true" data-title="Minimally Supervised Written-to-Spoken Text Normalization"&gt;Minimally Supervised Written-to-Spoken Text Normalization&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;本文研究的内容是特定语言领域知识在构建text normalization system的时候应该如何做trade-off，本文作者来自Google。&lt;/p&gt;&lt;h2&gt;&lt;a href="http://120.52.73.76/arxiv.org/pdf/1609.06380v1.pdf" data-editable="true" data-title="Recognizing Implicit Discourse Relations via Repeated Reading: Neural Networks with Multi-Level Attention"&gt;Recognizing Implicit Discourse Relations via Repeated Reading: Neural Networks with Multi-Level Attention&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;本文研究内容是如何识别隐式的discourse关系，作者提出了一种多层注意力模型，联合注意力机制和外部memory来做关系识别。本文是EMNLP2016的长文。&lt;/p&gt;&lt;h2&gt;&lt;a href="http://120.52.73.79/arxiv.org/pdf/1609.06693v2.pdf" data-editable="true" data-title="SoftTarget Regularization: An Effective Technique to Reduce Over-Fitting in Neural Networks"&gt;SoftTarget Regularization: An Effective Technique to Reduce Over-Fitting in Neural Networks&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;【转发较多】本文提出了一种新的正则化方法，通过在训练过程中调整label来实现，达到了和Dropout接近的效果。&lt;/p&gt;&lt;h2&gt;&lt;a href="http://120.52.73.77/arxiv.org/pdf/1609.06657v1.pdf" data-editable="true" data-title="The Color of the Cat is Gray: 1 Million Full-Sentences Visual Question Answering (FSVQA)"&gt;The Color of the Cat is Gray: 1 Million Full-Sentences Visual Question Answering (FSVQA)&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;本文提出了一个1 million的Visual Question Answer Dataset，数据地址：&lt;a href="http://www.mi.t.u-tokyo.ac.jp/static/projects/fsvqa/" data-editable="true" data-title="Projects - Full-Sentence Visual Question Answering"&gt;Projects - Full-Sentence Visual Question Answering&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;&lt;a href="http://arxiv.org/pdf/1609.07075v1.pdf" data-editable="true" data-title="Knowledge Representation via Joint Learning of Sequential Text and Knowledge Graphs"&gt;Knowledge Representation via Joint Learning of Sequential Text and Knowledge Graphs&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;【转发较多】当前知识表示存在两个挑战：1、如何更好地利用entity的context；2、如何发现与entity相关的句子；针对这两个问题，本文提出了一种从多个句子中学习表示的模型。给定每个entity的参考句子，首先用带池化的RNN或LSTM来encode与该entity相关的句子，然后用attention模型来衡量每个句子的信息量，最后得到entity的表示。模型在triple classification和link prediction两个任务上都取得了满意的结果。本文工作来自@刘知远THU组。&lt;/p&gt;&lt;p&gt;刘知远：我觉得这个工作的最有意思的地方是，能够为实体找到最有信息量的句子，这些句子往往是该实体的定义或描述。这样，在构建知识图谱时，我们就可以自动为新增的实体构建对应的文本描述信息了。&lt;/p&gt;&lt;h2&gt;&lt;a href="http://120.52.73.80/arxiv.org/pdf/1609.07053v1.pdf" data-editable="true" data-title="Semantic Tagging with Deep Residual Networks"&gt;Semantic Tagging with Deep Residual Networks&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;本文提出一种多语言智能tagger，模型采用了char-level和word-level的深度残差网络，在词性标注任务中取得了不错的效果，本文COLING 2016在审。&lt;/p&gt;&lt;h2&gt;&lt;a href="http://arxiv.org/pdf/1609.07028v1.pdf" data-editable="true" data-title="Image-embodied Knowledge Representation Learning"&gt;Image-embodied Knowledge Representation Learning&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;【转发较多】entity图像中包含丰富的信息，大多数传统方法并没有利用这一点，本文提出了一种知识表示模型，利用了triples和image信息，并在知识图谱补全和triple分类两个任务中取得了不错的效果。本文是一篇典型的多信息融合的文章，非常值得思考！工作同样来自@刘知远THU老师组。&lt;/p&gt;&lt;h2&gt;&lt;a href="http://120.52.73.80/arxiv.org/pdf/1609.06791v1.pdf" data-editable="true" data-title="Twitter-Network Topic Model: A Full Bayesian Treatment for Social Network and Text Modeling"&gt;Twitter-Network Topic Model: A Full Bayesian Treatment for Social Network and Text Modeling&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;推特上的推对于topic建模有以下缺点：1、短；2、非结构化；3、口语化；也有优点：1、作者；2、hashtags；3、粉丝网络。本文结合推特信息的优点提出了一种新模型。topic model是个老话题了，多源信息的融合是突破研究瓶颈一个不错的方向，本文的方法同样可借鉴于微博和其他社交网络。&lt;/p&gt;&lt;h2&gt;&lt;a href="http://120.52.73.78/arxiv.org/pdf/1609.06773v1.pdf" data-editable="true" data-title="Joint CTC-Attention based End-to-End Speech Recognition using Multi-task Learning"&gt;Joint CTC-Attention based End-to-End Speech Recognition using Multi-task Learning&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;【转发较多】Attention类模型在端到端语音识别领域取得了不错的效果，但当输入噪声非常大的的时候，识别长句子效果不是很好。CTC是另外一种不错的端到端模型，本文结合两者的优势构建模型。构建了联合模型之后，克服了之前的问题。大家都在用Attention，都说Attention好，但终究还是有些情境下attention并不能如人意。那么问题来了，到底哪些场景下attention表现不好，原因是什么？想清楚这个到底之后，改进的方法大概也就在路上了。#Attention Model的缺点#&lt;/p&gt;&lt;h1&gt;资源分享&lt;/h1&gt;&lt;h2&gt;&lt;a href="https://www.producthunt.com/topics/bots" data-editable="true" data-title="Bots - Product Hunt"&gt;Bots - Product Hunt&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;一个分享和点评各种好玩product的站点，其中一个栏目有各种各样的bot。&lt;/p&gt;&lt;h2&gt;&lt;a href="https://github.com/chewxy/gorgonia" data-editable="true" data-title="Gorgonia is a library that helps facilitate machine learning in Go"&gt;Gorgonia is a library that helps facilitate machine learning in Go&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;用Go写的机器学习开源框架。&lt;/p&gt;&lt;h2&gt;&lt;a href="https://github.com/danqi/rc-cnn-dailymail" data-editable="true" data-title="A Thorough Examination of the CNN/Daily Mail Reading Comprehension Task"&gt;A Thorough Examination of the CNN/Daily Mail Reading Comprehension Task&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;这篇paper的代码放出来了，同时包括CNN和Daily Mail的数据集。来自斯坦福Danqi Chen的工作。&lt;/p&gt;&lt;h1&gt;业界新闻&lt;/h1&gt;&lt;h2&gt;&lt;a href="https://api.ai/blog/2016/09/19/api-ai-joining-google/" data-editable="true" data-title="API.AI is joining Google!"&gt;API.AI is joining Google!&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;chatbot构建平台api.ai被Google收购了&lt;/p&gt;&lt;h2&gt;&lt;a href="https://techcrunch.com/2016/09/20/angel-ai-a-company-that-builds-chat-bots-acqui-hired-by-amazon/" data-editable="true" data-title="Angel.ai, a company that builds chat bots, acqui-hired by Amazon | TechCrunch"&gt;Angel.ai, a company that builds chat bots, acqui-hired by Amazon | TechCrunch&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;TechCrunch报道称，继api.ai被google收购之后，一家做自然语言理解的公司angel.ai也几乎被Amazon收购。&lt;/p&gt;&lt;h1&gt;广告时间&lt;/h1&gt;&lt;p&gt;PaperWeekly是一个分享知识和交流学问的民间组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。&lt;/p&gt;&lt;p&gt;微信公众号：PaperWeekly&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-ea9f4f4503d2ed9e15a56fe56e26e98d.jpg" data-rawwidth="430" data-rawheight="430"&gt;微博账号：PaperWeekly（&lt;a href="http://weibo.com/u/2678093863" data-editable="true" data-title="PaperWeekly的微博" class=""&gt;PaperWeekly的微博&lt;/a&gt; ）每天都会分享当天arXiv cs.CL板块刷新的高质量paper&lt;/p&gt;&lt;p&gt;知乎专栏：PaperWeekly（&lt;a href="https://zhuanlan.zhihu.com/paperweekly" data-editable="true" data-title="PaperWeekly - 知乎专栏"&gt;PaperWeekly - 知乎专栏&lt;/a&gt; ）微信交流群：微信+ zhangjun168305（请备注：加群 or 加入paperweekly）&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/22602959&amp;pixel&amp;useReferer"/&gt;</description><author>张俊</author><pubDate>Sat, 24 Sep 2016 11:51:43 GMT</pubDate></item><item><title>PaperWeekly 第六期------机器阅读理解</title><link>https://zhuanlan.zhihu.com/p/22577648</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-ea9f4f4503d2ed9e15a56fe56e26e98d_r.jpg"&gt;&lt;/p&gt;&lt;h1&gt;引&lt;/h1&gt;&lt;p&gt;本期paperweekly的主题是Question Answering Models，解决这一类问题可以很好地展现AI理解人类自然语言的能力，通过解决此类dataset可以给AI理解人类语言很好的insights。问题的定义大致是，给定较长一段话的context和一个较短的问题，以及一些candidate answers，训练一些可以准确预测正确答案的模型。&lt;/p&gt;&lt;p&gt;此问题也存在一些变种，例如context可以是非常大块的knowledge base，可以不提供candidate answers而是在所有的vocabulary中搜索答案，或者是在context中提取答案。&lt;/p&gt;&lt;p&gt;基于(Recurrent) Neural Network的一些模型在这一类问题上给出了state of the art models，本期paperweekly就带领大家欣赏这一领域有趣的工作。&lt;/p&gt;&lt;h1&gt;&lt;a href="https://arxiv.org/abs/1607.04423" data-editable="true" data-title="Attention-over-Attention Neural Networks for Reading Comprehension" class=""&gt;Attention-over-Attention Neural Networks for Reading Comprehension&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;作者&lt;/h2&gt;&lt;p&gt;Yiming Cui, Zhipeng Chen, Si Wei, Shijin Wang, Ting Liu and Guoping Hu&lt;/p&gt;&lt;h2&gt;单位&lt;/h2&gt;&lt;p&gt;iFLYTEK Research, ChinaResearch Center for Social Computing and Information Retrieval, Harbin Institute of Technology, China&lt;/p&gt;&lt;h2&gt;关键词&lt;/h2&gt;&lt;p&gt;Question Answering, Attentive Readers&lt;/p&gt;&lt;h2&gt;来源&lt;/h2&gt;&lt;p&gt;arXiv, 201608&lt;/p&gt;&lt;h2&gt;问题&lt;/h2&gt;&lt;p&gt;本文优化了attention机制，同时apply question-to-document and document-to-question attention，提升了已有模型在Cloze-Style Question Answering Task上的准确率。&lt;/p&gt;&lt;h2&gt;模型&lt;/h2&gt;&lt;p&gt;本文解决的是Cloze-style question answering的问题，给定一个Document和一个Query，以及一个list的candidate answers，模型需要给出一个正确答案。&lt;/p&gt;&lt;p&gt;已有的模型大都通过比较每一个Query + candidate answer和context document的相似性来找出正确答案，这种相似性measure大都通过把query 投射到context document每个单词及所在context的相似性来获得。本文的不同之处在于模型还计算了context投射到每个query单词的相似度，进一步丰富了context和query相似度的计算。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-af08e8e9fb96b8ae0927bdc4f6b2ea8c.png" data-rawwidth="694" data-rawheight="482"&gt;&lt;/p&gt;&lt;p&gt;首先，document和query都会被model成biGRU。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-854674cf407253946e97d634e72803a4.png" data-rawwidth="468" data-rawheight="153"&gt;&lt;/p&gt;&lt;p&gt;然后使用document biGRU和query biGRU的每一个position做inner product计算，可以得到一个similarity matrix。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-293c440a77d4023981ba9375ac3d7d28.png" data-rawwidth="356" data-rawheight="58"&gt;&lt;/p&gt;&lt;p&gt;对这个matrix做一个column-wise softmax，可以得到每个query单词在每个document单词上的similarity。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-1e3f420c54d62e837a00253fe5a892d2.png" data-rawwidth="450" data-rawheight="97"&gt;&lt;/p&gt;&lt;p&gt;similarly，对这个matrix做一个row-wise softmax，可以得到每个document单词在每个query单词上的similarity。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-59b0db8160a066f9049c8da726f94fc5.png" data-rawwidth="508" data-rawheight="78"&gt;&lt;/p&gt;&lt;p&gt;取个平均就得到了每个query单词在整个context document上的similarity。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-256ea139cfabd3b6d4ca824916a352c2.png" data-rawwidth="187" data-rawheight="89"&gt;&lt;/p&gt;&lt;p&gt;然后把alpha和beta做个inner product就得到了每个context document word的probability。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-1f2f0e78e26abe31b627ed55a78b5fef.png" data-rawwidth="206" data-rawheight="62"&gt;&lt;/p&gt;&lt;p&gt;每个candidate answer的probability就是它出现在上述s中的probability之和。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-0b0e8959a461212fd2ccde576250d151.png" data-rawwidth="285" data-rawheight="79"&gt;&lt;/p&gt;&lt;p&gt;Loss Function可以定义为正确答案的log probability之和。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-6794ef52d8e7d4bb716707baacddb1a1.png" data-rawwidth="225" data-rawheight="57"&gt;&lt;/p&gt;&lt;h2&gt;资源&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="https://github.com/deepmind/rc-data" data-editable="true" data-title="cnn和daily mail datasets"&gt;cnn和daily mail datasets&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://research.facebook.com/research/babi/" data-editable="true" data-title="Children’s book test"&gt;Children’s book test&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;相关工作&lt;/h2&gt;&lt;p&gt;利用attentive readers解决question answering问题最早出自deep mind: teaching machines to read and comprehend。后来又有Bhuwan Dhingra: Gated-Attention Readers for Text Comprehension和Danqi Chen: A Thorough Examination of the CNN/Daily Mail Reading Comprehension Task，以及其他相关工作，在此不一一赘述。&lt;/p&gt;&lt;h2&gt;简评&lt;/h2&gt;&lt;p&gt;本文很好地完善了attentive reader的工作，同时考虑了query to document and document to query attentions，在几个data set上都取得了state of the art效果，思路非常清晰，在question answering问题上很有参考价值。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.76/arxiv.org/pdf/1608.07905v1.pdf" data-editable="true" data-title="MACHINE COMPREHENSION USING MATCH-LSTM AND ANSWER POINTER"&gt;MACHINE COMPREHENSION USING MATCH-LSTM AND ANSWER POINTER&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;作者&lt;/h2&gt;&lt;p&gt;Shuohang Wang, Jing Jiang&lt;/p&gt;&lt;h2&gt;单位&lt;/h2&gt;&lt;p&gt;Singapore Management University&lt;/p&gt;&lt;h2&gt;关键词&lt;/h2&gt;&lt;p&gt;Machine comprehension, Match-LSTM, Pointer Net&lt;/p&gt;&lt;h2&gt;来源&lt;/h2&gt;&lt;p&gt;arXiv，201608&lt;/p&gt;&lt;h2&gt;问题&lt;/h2&gt;&lt;p&gt;提出一种结合match-LSTM和Pointer Net的端到端神经网络结构，来解决SQuAD数据集这类没有候选项且答案可能是多个词的machine comprehension问题。&lt;/p&gt;&lt;h2&gt;模型&lt;/h2&gt;&lt;p&gt;本文提出的模型结合了match-LSTM(mLSTM)和Pointer Net(Ptr-Net)两种网络结构。&lt;/p&gt;&lt;p&gt;1、match-LSTM&lt;/p&gt;&lt;p&gt;mLSTM是由Wang和Jiang提出的一种解决文本蕴含识别（RTE）问题的一种神经网络结构。模型结构见下图，该模型首先将premise和hypothesis两句话分别输入到两个LSTM中，用对应LSTM的隐层输出作为premise和hypothesis中每个位置对应上下文信息的一种表示（分别对应图中的Hs和Ht）。对于hypothesis中的某个词的表示ht_i，与premise中的每个词的表示Hs计算得到一个权重向量，然后再对premise中的词表示进行加权求和，得到hti对应的上下文向量a_i（attention过程）。最后把hypothesis中该词的表示ht_i和其对应的context向量a_i拼接在一起，输入到一个新的LSTM中。该模型将两个句子的文本蕴含任务拆分成词和短语级别的蕴含识别，因此可以更好地识别词之间的匹配关系。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-721234392c72ee01ab06f67edf1b6318.png" data-rawwidth="1156" data-rawheight="520"&gt;&lt;/p&gt;&lt;p&gt;2、 Pointer networks&lt;/p&gt;&lt;p&gt;该模型与基于attention的生成模型类似。区别之处在于，pointer networks生成的结果都在输入序列中，因此pointer networks可以直接将attention得到的align向量中的每个权重直接作为预测下一个词对应的概率值。&lt;/p&gt;&lt;p&gt;3、 Sequence Model &amp;amp; Boundary Model&lt;/p&gt;&lt;p&gt;本文提出的模型结构见下图，具体到本文的神经网络结构，可以简单分为下面两部分：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-dad87a89d1400f1b400bbc2361c780fb.png" data-rawwidth="1513" data-rawheight="840"&gt;（1）Match-LSTM层：该部分将machine comprehension任务中的question作为premise，而passage作为hypothesis。直接套用上述的mLSTM模型得到关于passage每个位置的一种表示。为了将前后方向的上下文信息全部编码进来，还用相同的方法得到一个反向mLSTM表示，将两个正反方向的表示拼接在一起作为最终passage的表示。&lt;/p&gt;&lt;p&gt;（2）生成答案序列部分，论文中提出了两种生成方法：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Sequence方法与Pointer Net相同，即根据每一个时刻attention的align向量生成一个词位置，直到生成终止符为止。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Boundary方法则是利用SQuAD数据集的答案均是出现在passage中连续的序列这一特点，该方法仅生成首尾两个位置，依据起始位置和终止位置来截取passage的一部分作为最终的答案。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;本文在SQuAD数据集上进行实验，两种方法实验结果较之传统LR方法均有大幅度提升。其中Boundary方法比Sequence方法效果更好。&lt;/p&gt;&lt;h2&gt;资源&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="https://rajpurkar.github.io/SQuAD-explorer/" data-editable="true" data-title="SQuAD"&gt;SQuAD&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;相关工作&lt;/h2&gt;&lt;p&gt;数据集相关论文SQuAD: 100,000+ Questions for Machine Comprehension of Text模型相关论文Learning Natural Language Inference with LSTMPointer networks&lt;/p&gt;&lt;h2&gt;简评&lt;/h2&gt;&lt;p&gt;本篇论文提出的模型是第一个在SQuAD语料上应用端到端神经网络的模型，该模型将Match-LSTM和Pointer Networks结合在一起，利用了文本之间的蕴含关系更好地预测答案。本文提出了两种方法来生成答案，其中Boundary方法巧妙地利用SQuAD数据集的答案均是文本中出现过的连续序列这一特点，只生成答案的起始和终止位置，有效地提升了模型的效果。&lt;/p&gt;&lt;h1&gt;&lt;a href="https://arxiv.org/pdf/1607.06275v2.pdf" data-editable="true" data-title="Dataset and Neural Recurrent Sequence Labeling Model for Open-Domain Factoid Question Answering" class=""&gt;Dataset and Neural Recurrent Sequence Labeling Model for Open-Domain Factoid Question Answering&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;作者&lt;/h2&gt;&lt;p&gt;Peng Li, Wei Li, Zhengyan He, Xuguang Wang, Ying Cao, Jie Zhou, Wei Xu&lt;/p&gt;&lt;h2&gt;单位&lt;/h2&gt;&lt;p&gt;Baidu IDL&lt;/p&gt;&lt;h2&gt;关键词&lt;/h2&gt;&lt;p&gt;Question Answering, Sequence Labeling, CRF&lt;/p&gt;&lt;h2&gt;来源&lt;/h2&gt;&lt;p&gt;arXiv, 201609&lt;/p&gt;&lt;h2&gt;问题&lt;/h2&gt;&lt;p&gt;作者给出了一个新的中文的QA数据集, 并且提出了一个非常有意思的baseline model.&lt;/p&gt;&lt;h2&gt;模型&lt;/h2&gt;&lt;p&gt;1、WebQA Dataset&lt;/p&gt;&lt;p&gt;作者来自百度IDL, 他们利用百度知道和一些其他的资源, 构建了这个中文的QA数据集. 这个数据集里所有的问题都是factoid类型的问题, 并且问题的答案都只包含一个entity (但是一个entity可能会包含多个单词). 对于每个问题, 数据集提供了若干个’evidence’, 这些evidence是利用搜索引擎在网络中检索的.&lt;/p&gt;&lt;p&gt;2、Recurrent Sequence Labeling Model&lt;/p&gt;&lt;p&gt;作者把QA类型的问题看做sequence labeling问题, 给出的模型大概分三部分:&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-4382b4020263b01609342f3b296e46ad.png" data-rawwidth="741" data-rawheight="385"&gt;&lt;/p&gt;&lt;p&gt;（1）Question LSTM这部分很简单, 就是普通的单向LSTM, 对整个Question sequence进行encoding, 之后计算self-attention, 并用attention对question encoding求加权平均作为问题的representation.&lt;/p&gt;&lt;p&gt;（2）Evidence LSTMs这部分比较有意思, 首先, 作者从数据中提取出两种feature: 每个词是否在question和evidence中共同出现, 以及每个词是否同时在多个evidence中出现. 之后, 模型用一个三层的单向LSTM对evidence/quesiton/feature进行编码.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;第一层: 将evidence/question representation/feature进行连接, 放进一个正向LSTM.&lt;/li&gt;&lt;li&gt;第二层: 将第一层的结果放入一个反向LSTM.&lt;/li&gt;&lt;li&gt;第三层: 将第一层和第二层的结果进行连接, 放进一个正向LSTM.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;（3）CRF经过evidence LSTMs, question和evidence的representation已经揉在一起, 所以并不需要其他QA模型(主要是Attention Sum Reader)广泛用的, 用question representation和story representation进行dot product, 求cosine similarity. 这时候只需要对evidence representation的每一个time step进行分类就可以了, 这也是为什么作者将数据标注成IOB tagging的格式, 我们可以直接用一个CRF层对数据进行预测. 在一些实验中, 作者将答案之前的词用O1, 答案之后的词用O2进行标注, 这又给了模型关于非答案词的位置信息(正确答案是在这个词的前面还是后面).&lt;/p&gt;&lt;h2&gt;资源&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="http://idl.baidu.com/webqa.html" data-editable="true" data-title="WebQA dataset"&gt;WebQA dataset&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://github.com/baidu/Paddle" data-editable="true" data-title="Baidu Paddle"&gt;Baidu Paddle&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;相关工作&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;关于CRF进行序列标注的问题, 可以参考这篇文章.Zhiheng Huang, Wei Xu, and Kai Yu. 2015. Bidirectional LSTM-CRF models for sequence tagging. arXiv:1508.01991v1.&lt;/li&gt;&lt;li&gt;关于multi-word答案选择在SQuAD dataset上的模型, 可以参考这篇.Shuohang Wang, Jing Jiang. 2016. Machine Comprehension Using Match_LSTM and Answer Pointer. arXiv: 1608.07905v1.&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;简评&lt;/h2&gt;&lt;p&gt;首先对所有release数据集的人表示感谢.关于dataset部分, 百度利用了自己庞大的资源收集数据. 第一, 百度知道里的问题都是人类问的问题, 这一点相比于今年前半年比较流行的CNN/CBT等等cloze style的问题, 要强很多. 第二, 数据集中包含了很多由多个词组成的答案, 这也使数据集的难度大于CNN/CBT这种单个词作为答案的数据. 第三, 对于每个问题, 并没有给出备选答案, 这使得对于答案的搜索空间变大(可以把整个evidence看做是备选答案). 第四, 对于每一个问题, dataset中可能有多个supporting evidence, 这也迎合了最近multi-supporting story的趋势, 因为对于有些问题, 答案并不只在某一个单一的文章中(对于百度来说, 如果搜索一个问题, 那么答案并不一定在单一的搜索结果网页中), 那么一个好的model需要在有限的时间内对尽可能多的搜索结果进行检索.&lt;/p&gt;&lt;p&gt;关于model部分, 本文尝试将QA问题看做是序列标注问题, 某种意义上解决了multiword answer的难点. 熟悉前半年QA paper的人都会对Attention Sum Reader以及延伸出来的诸多模型比较熟悉, 由于用了类似Pointer Network的机制, 一般的模型只能从文中选择story和question的cosine similarity最高的词作为答案, 这使得multiple word answer很难处理, 尤其是当multiple answer word不连续的时候, 更难处理. 而CRF是大家都熟知的简单高效的序列标注工具, 把它做成可训练的, 并且放在end to end模型中, 看起来是非常实用的. 在Evidence LSTM的部分, 加入的两个feature据作者说非常有帮助, 看起来在deep learning 模型中加入一些精心设计的feature, 或者IR的要素, 有可能能够对模型的performance给予一定的提升. 在entropy的角度, 虽然不一定是entropy reduction, 因为这些信息其实本来已经包含在question/evidence中了, 但是有可能因为你提供给模型这些信息, 它就可以把更多精力用在一些其他的特征上?&lt;/p&gt;&lt;p&gt;另外值得一提的是, 最近Singapore Management University的Wang and Jiang也有所突破, 在SQuAD dataset(也是multiple word answer)上一度取得了state of the art的结果, 他们用的mLSTM模型也十分有趣.&lt;/p&gt;&lt;h1&gt;总结&lt;/h1&gt;&lt;p&gt;这一类model都大量使用了Recurrent Neural Network(LSTM或者GRU)对text进行encoding，得到一个sequence的hidden state vector。然后通过inner product或者bilinear term比较不同位置hidden state vector之间的similarity来计算它们是正确答案的可能性。可见Recurrent Neural Network以及对于Similarity的定义依旧是解决此类问题的关键所在，更好地改良这一类模型也是提升准确率的主流方法。笔者认为，similarity的计算给了模型从原文中搜索答案的能力，然而模型非常缺乏的是推理和思考的能力（其实也有相关工作&lt;a href="http://arxiv.org/abs/1508.05508" data-editable="true" data-title="Towards Neural Network-based Reasoning"&gt;Towards Neural Network-based Reasoning&lt;/a&gt;），如果模型能够配备逻辑思考能力，那么解决问题的能力会大大增强。非常期待有新的思路能够出现在这一领域中，令AI能够更好地理解人类语言。&lt;/p&gt;&lt;p&gt;以上为本期PaperWeekly的主要内容，感谢&lt;strong&gt;eric yuan&lt;/strong&gt;、&lt;strong&gt;destinwang&lt;/strong&gt;、&lt;strong&gt;zewei chu&lt;/strong&gt;、&lt;strong&gt;韩晓伟&lt;/strong&gt;四位同学的整理。 &lt;/p&gt;&lt;h1&gt;广告时间&lt;/h1&gt;&lt;p&gt;PaperWeekly是一个分享知识和交流学问的民间组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。&lt;/p&gt;&lt;p&gt;微信公众号：PaperWeekly&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-ea9f4f4503d2ed9e15a56fe56e26e98d.jpg" data-rawwidth="430" data-rawheight="430"&gt;&lt;/p&gt;&lt;p&gt;微博账号：PaperWeekly（&lt;a href="http://weibo.com/u/2678093863" data-editable="true" data-title="PaperWeekly的微博"&gt;PaperWeekly的微博&lt;/a&gt; ）知乎专栏：PaperWeekly（&lt;a href="https://zhuanlan.zhihu.com/paperweekly" data-editable="true" data-title="PaperWeekly - 知乎专栏"&gt;PaperWeekly - 知乎专栏&lt;/a&gt; ）微信交流群：微信+ zhangjun168305（请备注：加群 or 加入paperweekly）&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/22577648&amp;pixel&amp;useReferer"/&gt;</description><author>张俊</author><pubDate>Fri, 23 Sep 2016 09:30:09 GMT</pubDate></item><item><title>cs.CL weekly 2016.09.12-2016.09.16</title><link>https://zhuanlan.zhihu.com/p/22471808</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/ea9f4f4503d2ed9e15a56fe56e26e98d_r.jpg"&gt;&lt;/p&gt;&lt;p&gt;本周（2016.09.12-2016.09.16）质量较高的arXiv cs.CL的paper如下：（点击标题可看原文）&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.75/arxiv.org/pdf/1609.02846v1.pdf" data-editable="true" data-title="Dialogue manager domain adaptation using Gaussian process reinforcement learning" class=""&gt;Dialogue manager domain adaptation using Gaussian process reinforcement learning&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;本文是Steve Young组的一篇大作，文中详细介绍了Gaussian process reinforcement learning框架的思路和优势，并且在多个对话领域中进行了实验并得到更好的结果。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.79/arxiv.org/pdf/1609.02745v1.pdf" data-editable="true" data-title="A Hierarchical Model of Reviews for Aspect-based Sentiment Analysis" class=""&gt;A Hierarchical Model of Reviews for Aspect-based Sentiment Analysis&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;本文提出用分层双向LSTM模型对网站评论数据进行观点挖掘，发表在EMNLP 2016。该作者今天在arxiv上提交了三篇同类问题不同解决方案的paper，对评论观点和情感挖掘的童鞋可作参考。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.79/arxiv.org/pdf/1609.03286v1.pdf" data-editable="true" data-title="Knowledge as a Teacher: Knowledge-Guided Structural Attention Networks" class=""&gt;Knowledge as a Teacher: Knowledge-Guided Structural Attention Networks&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;本文提出了用先验知识+attention network的模型，用来解决了自然语言理解存在问题：通过从少量训练数据中捕获重要子结构，来缓解测试集中的unseen data问题，同时提高理解能力。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.79/arxiv.org/pdf/1609.03193v2.pdf" data-editable="true" data-title="Wav2Letter: an End-to-End ConvNet-based Speech Recognition System"&gt;Wav2Letter: an End-to-End ConvNet-based Speech Recognition System&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;本文提出了一种语音识别的端到端模型，基于CNN和graph decoding，在不依赖因素对齐的前提下，输出letters。本文工作来自Facebook AI。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.78/arxiv.org/pdf/1609.03976v1.pdf" data-editable="true" data-title="Multimodal Attention for Neural Machine Translation"&gt;Multimodal Attention for Neural Machine Translation&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;本文通过利用image caption的多模态、多语言数据构建了一个NMT模型，模型的输入不仅是source language，还有所描述的图像，输出是target language。通过输入更多的信息，得到了更好的效果。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.78/arxiv.org/pdf/1609.03632v1.pdf" data-editable="true" data-title="Joint Extraction of Events and Entities within a Document Context"&gt;Joint Extraction of Events and Entities within a Document Context&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;本文针对传统信息抽取方法将event和entity分开考虑的问题，提出了在docuemnt-level context下考虑event和entity之间关系进行信息抽取的新方法，取得了非常好的结果。本文发表在NAACL2016.&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.75/arxiv.org/pdf/1609.03777v1.pdf" data-editable="true" data-title="Character-Level Language Modeling with Hierarchical Recurrent Neural Networks" class=""&gt;Character-Level Language Modeling with Hierarchical Recurrent Neural Networks&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;语言模型问题上，char-level可以很好地解决OOV的问题，但效果不如word-level，本文针对该问题提出了一种分层模型，同时兼顾word-level和char-level的优势。本文发表在nips2016。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.78/arxiv.org/pdf/1609.04186v1.pdf" data-editable="true" data-title="Neural Machine Translation with Supervised Attention" class=""&gt;Neural Machine Translation with Supervised Attention&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;attention机制可以动态地对齐source和target words，但准确率不如传统方法。本文提出了用传统方法作为teacher，来“教”model学习alignment，模型称为supervised attention。本文已投稿COLING2016，在审。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.76/arxiv.org/pdf/1609.04309v1.pdf" data-editable="true" data-title="Efficient softmax approximation for GPUs" class=""&gt;Efficient softmax approximation for GPUs&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;本文提出了一种高效的softmax近似方法，并且可以方便地进行并行计算。本文称之为adaptive softmax，根据词分布进行聚类，极大地提高了计算效率并保证了不错的准确率。本文工作来自Facebook AI Research。&lt;/p&gt;&lt;p&gt;在自然语言生成任务中常常面临word vocabulary size太大的困境，softmax的效率非常低，本文给出了一种快速计算的方法。Tomas Mikolov之前也提到过类似的思路。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.78/arxiv.org/pdf/1609.04779v1.pdf" data-editable="true" data-title="Characterizing the Language of Online Communities and its Relation to Community Reception"&gt;Characterizing the Language of Online Communities and its Relation to Community Reception&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;本文研究了在线社区语言的style和topic哪个更具代表性，这里style用复合语言模型来表示，topic用LDA来表示，通过Reddit Forum实验得到style比topic更有代表性。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.79/arxiv.org/pdf/1609.04621v1.pdf" data-editable="true" data-title="Factored Neural Machine Translation"&gt;Factored Neural Machine Translation&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;针对机器翻译领域中两个常见的问题：1、目标语言词汇表过大；2、OOV问题；利用了单词的词形和语法分解，提出了一种新的NMT模型，并取得了满意的效果。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.78/arxiv.org/pdf/1609.04628v1.pdf" data-editable="true" data-title="Context Aware Nonnegative Matrix Factorization Clustering"&gt;Context Aware Nonnegative Matrix Factorization Clustering&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;大多数paper都在研究NMF在聚类中的初始化和优化部分，而本文关注的点在于最后的聚类分配上。本文被 ICPR 2016全文收录。&lt;/p&gt;&lt;p&gt;以下内容为arXiv外的优质内容：&lt;/p&gt;&lt;h1&gt;&lt;a href="http://www.sigdial.org/workshops/conference17/proceedings/SIGDIAL-2016.pdf" data-editable="true" data-title="SIGDIAL 2016 Accepted Paper"&gt;SIGDIAL 2016 Accepted Paper&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;SIGdial是ACL下面的一个关于对话系统地特别兴趣小组，每年开一次会。今年的会议最近正在开，会议录用的所有paper都已经放出。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://speech.sv.cmu.edu/software.html" data-editable="true" data-title="CMU SPEECH Team Homepage" class=""&gt;CMU SPEECH Team Homepage&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;CMU SPEECH Team的主页，包括他们的开源软件Yoda和publication及其开源实现。&lt;/p&gt;&lt;h1&gt;&lt;a href="https://www.reddit.com/r/MachineLearning/comments/4zcyvk/machine_learning_wayr_what_are_you_reading_week_6/?st=ISZ6YT6D&amp;amp;sh=02bd0722" data-editable="true" data-title="Machine Learning - WAYR (What Are You Reading)" class=""&gt;Machine Learning - WAYR (What Are You Reading)&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;reddit上的这个帖子很有意思，和paperweekly想做的一个事情非常像，就是可以让读类似或者同一篇paper的童鞋得到充分交流。&lt;/p&gt;&lt;h1&gt;广告时间&lt;/h1&gt;&lt;p&gt;PaperWeekly是一个分享知识和交流学问的民间组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。&lt;/p&gt;&lt;p&gt;微信公众号：PaperWeekly微博账号：PaperWeekly（&lt;a href="http://weibo.com/u/2678093863" data-editable="true" data-title="PaperWeekly的微博"&gt;PaperWeekly的微博&lt;/a&gt; ）每天都会分享当天arXiv cs.CL板块刷新的高质量paper知乎专栏：PaperWeekly（&lt;a href="https://zhuanlan.zhihu.com/paperweekly" data-editable="true" data-title="PaperWeekly - 知乎专栏"&gt;PaperWeekly - 知乎专栏&lt;/a&gt; ）微信交流群：微信+ zhangjun168305（请备注：加群 or 加入paperweekly）&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/22471808&amp;pixel&amp;useReferer"/&gt;</description><author>张俊</author><pubDate>Sat, 17 Sep 2016 08:28:05 GMT</pubDate></item><item><title>PaperWeekly 第五期------从Word2Vec到FastText</title><link>https://zhuanlan.zhihu.com/p/22466665</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/ded3556dca46e452ac525a5b7beecf3c_r.png"&gt;&lt;/p&gt;&lt;h1&gt;引&lt;/h1&gt;&lt;p&gt;Word2Vec从提出至今，已经成为了深度学习在自然语言处理中的基础部件，大大小小、形形色色的DL模型在表示词、短语、句子、段落等文本要素时都需要用word2vec来做word-level的embedding。Word2Vec的作者Tomas Mikolov是一位产出多篇高质量paper的学者，从RNNLM、Word2Vec再到最近流行的FastText都与他息息相关。一个人对同一个问题的研究可能会持续很多年，而每一年的研究成果都可能会给同行带来新的启发，本期的PaperWeekly将会分享其中三篇代表作，分别是：&lt;/p&gt;&lt;p&gt;1、Efficient Estimation of Word Representation in Vector Space, 20132、Distributed Representations of Sentences and Documents, 20143、Enriching Word Vectors with Subword Information, 2016&lt;/p&gt;&lt;h1&gt;&lt;a href="https://arxiv.org/pdf/1301.3781.pdf" data-editable="true" data-title="Efficient Estimation of Word Representation in Vector Space" class=""&gt;Efficient Estimation of Word Representation in Vector Space&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;作者&lt;/h2&gt;&lt;p&gt;Tomas Mikolov, Kai Chen, Greg Corrado, Jeffrey Dean&lt;/p&gt;&lt;h2&gt;单位&lt;/h2&gt;&lt;p&gt;Google Inc., Mountain View, CA&lt;/p&gt;&lt;h2&gt;关键词&lt;/h2&gt;&lt;p&gt;Word Representation, Word Embedding, Neural Network, Syntactic Similarity, and Semantic Similarity&lt;/p&gt;&lt;h2&gt;来源&lt;/h2&gt;&lt;p&gt;arXiv, 201309&lt;/p&gt;&lt;h2&gt;问题&lt;/h2&gt;&lt;p&gt;如何在一个大型数据集上快速、准确地学习出词表示？&lt;/p&gt;&lt;h2&gt;模型&lt;/h2&gt;&lt;p&gt;传统的NNLM模型包含四层，即输入层、映射层、隐含层和输出层，计算复杂度很大程度上依赖于映射层到隐含层之间的计算，而且需要指定上下文的长度。RNNLM模型被提出用来改进NNLM模型，去掉了映射层，只有输入层、隐含层和输出层，计算复杂度来源于上一层的隐含层到下一层隐含层之间的计算。&lt;/p&gt;&lt;p&gt;本文提出的两个模型CBOW (Continuous Bag-of-Words Model)和Skip-gram (Continuous Skip-gram Model)结合了上面两个模型的特点，都是只有三层，即输入层、映射层和输出层。CBOW模型与NNLM模型类似，用上下文的词向量作为输入，映射层在所有的词间共享，输出层为一个分类器，目标是使当前词的概率最大。Skip-gram模型与CBOW的输入跟输出恰好相反，输入层为当前词向量，输出层是使得上下文的预测概率最大，如下图所示。训练采用SGD。&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/3b94982780b22466c499eaff3e04df65.jpg" data-rawwidth="362" data-rawheight="223"&gt;&lt;/p&gt;&lt;h2&gt;资源&lt;/h2&gt;&lt;p&gt;Code: &lt;a href="https://code.google.com/archive/p/word2vec/" data-editable="true" data-title="C++代码"&gt;C++代码&lt;/a&gt;Dataset: &lt;a href="https://sites.google.com/site/semeval2012task2/" data-editable="true" data-title="SemEval-2012"&gt;SemEval-2012&lt;/a&gt;,用来评估语义相关性。&lt;/p&gt;&lt;h2&gt;相关工作&lt;/h2&gt;&lt;p&gt;Bengio[1]在2003年就提出了language model的思路，同样是三层（输入层，隐含层和输出层）用上下文的词向量来预测中间词，但是计算复杂度较高，对于较大的数据集运行效率低；实验中也发现将上下文的n-gram出现的频率结合进去会提高性能，这个优点体现在CBOW和Skip-gram模型的输出层中，用hierarchical softmax（with huffman trees）来计算词概率。&lt;/p&gt;&lt;h2&gt;简评&lt;/h2&gt;&lt;p&gt;本文的实验结果显示CBOW比NNLM在syntactic和semantic上的预测都要好，而Skip-gram在semantic上的性能要优于CBOW，但是其计算速度要低于CBOW。结果显示用较大的数据集和较少的epoch，可以取得较好的效果，并且在速度上有所提升。与LSI和LDA相比，word2vec利用了词的上下文，语义信息更加丰富。基于word2vec，出现了phrase2vec, sentence2vec和doc2vec，仿佛一下子进入了embedding的世界。NLP的这些思想也在用于recommendation等方面，并且与image结合，将image跟text之间进行转换。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.76/arxiv.org/pdf/1405.4053v2.pdf" data-editable="true" data-title="Distributed Representations of Sentences and Documents" class=""&gt;Distributed Representations of Sentences and Documents&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;作者&lt;/h2&gt;&lt;p&gt;Quoc V. Le, Tomas Mikolov&lt;/p&gt;&lt;h2&gt;单位&lt;/h2&gt;&lt;p&gt;Google Inc, Mountain View, CA&lt;/p&gt;&lt;h2&gt;关键词&lt;/h2&gt;&lt;p&gt;sentence representation&lt;/p&gt;&lt;h2&gt;来源&lt;/h2&gt;&lt;p&gt;ICML 2014&lt;/p&gt;&lt;h2&gt;问题&lt;/h2&gt;&lt;p&gt;基于word2vec的思路，如何表示sentence和document？&lt;/p&gt;&lt;h2&gt;模型&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/c6dac075c8ed2bb00718673967777bb1.jpg" data-rawwidth="418" data-rawheight="245"&gt;&lt;/h2&gt;&lt;p&gt;利用one-hot的表示方法作为网络的输入，乘以词矩阵W，然后将得到的每个向量通过平均或者拼接的方法得到整个句子的表示，最后根据任务要求做一分类，而这过程中得到的W就是词向量矩阵，基本上还是word2vec的思路。&lt;/p&gt;&lt;p&gt;接下来是段落的向量表示方法：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/ef7668051ab7f574ab1e41a0f8d3f0eb.jpg" data-rawwidth="400" data-rawheight="225"&gt;依旧是相同的方法，只是在这里加上了一个段落矩阵，用以表示每个段落，当这些词输入第i个段落时，通过段落id就可以从这个矩阵中得到相对应的段落表示方法。需要说明的是，在相同的段落中，段落的表示是相同的。文中这样表示的动机就是段落矩阵D可以作为一个memory记住在词的context中遗失的东西，相当于增加了一个额外的信息。这样经过训练之后，我们的就得到了段落表示D，当然这个段落就可以是一段或者一篇文章。&lt;/p&gt;&lt;p&gt;最后一种就是没有词序的段落向量表示方法：&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/a9781307fe0c25097e3674bc72d6d372.jpg" data-rawwidth="400" data-rawheight="261"&gt;从图中就可以感觉到这个方法明显和skip-gram非常相似，这里只是把重点放在了段落的表示中，通过段落的表示，来预测相应的context 词的表示。最后我们依然可以得到段落矩阵D，这样就可以对段落进行向量化表示了。但是输入起码是句子级别的表示，而输出则是词的向量表示，因此个人比较怀疑这种方法的合理性。&lt;/p&gt;&lt;h2&gt;简评&lt;/h2&gt;&lt;p&gt;这篇文章是word2vec的方法提出一年后提出的方法，因此本文并没有使用目前非常流行的word2vec的训练方法来训练词向量，而是利用word2vec的思路，提出了一种更加简单的网络结构来训练任意长度的文本表示方法。这样一方面好训练，另一方面减少了参数，避免模型过拟合。优点就是在训练paragraph vector的时候加入了一个paragraph matrix，这样在训练过程中保留了一部分段落或者文档信息。这点在目前看来也是有一定优势的。但是目前深度学习发展迅速，可以处理非常大的计算量，同时word2vec以及其变种被应用得非常普遍，因此该文章提出的方法思路大于模型，思路我们可以借鉴，模型就不具有优势了。&lt;/p&gt;&lt;h1&gt;&lt;a href="http://120.52.73.80/arxiv.org/pdf/1607.04606v1.pdf" data-editable="true" data-title="Enriching Word Vectors with Subword Information"&gt;Enriching Word Vectors with Subword Information&lt;/a&gt;&lt;/h1&gt;&lt;h2&gt;作者&lt;/h2&gt;&lt;p&gt;Piotr Bojanowski, Edouard Grave, Armand Joulin, Tomas Mikolov&lt;/p&gt;&lt;h2&gt;单位&lt;/h2&gt;&lt;p&gt;Facebook AI Research&lt;/p&gt;&lt;h2&gt;关键词&lt;/h2&gt;&lt;p&gt;Word embedding, morphological, character n-gram&lt;/p&gt;&lt;h2&gt;来源&lt;/h2&gt;&lt;p&gt;arXiv, 201607&lt;/p&gt;&lt;h2&gt;问题&lt;/h2&gt;&lt;p&gt;如何解决word2vec方法中罕见词效果不佳的问题，以及如何提升词形态丰富语言的性能？&lt;/p&gt;&lt;h2&gt;模型&lt;/h2&gt;&lt;p&gt;word2vec在词汇建模方面产生了巨大的贡献，然而其依赖于大量的文本数据进行学习，如果一个word出现次数较少那么学到的vector质量也不理想。针对这一问题作者提出使用subword信息来弥补这一问题，简单来说就是通过词缀的vector来表示词。比如unofficial是个低频词，其数据量不足以训练出高质量的vector，但是可以通过un+official这两个高频的词缀学习到不错的vector。&lt;/p&gt;&lt;p&gt;方法上，本文沿用了word2vec的skip-gram模型，主要区别体现在特征上。word2vec使用word作为最基本的单位，即通过中心词预测其上下文中的其他词汇。而subword model使用字母n-gram作为单位，本文n取值为3~6。这样每个词汇就可以表示成一串字母n-gram，一个词的embedding表示为其所有n-gram的和。这样我们训练也从用中心词的embedding预测目标词，转变成用中心词的n-gram embedding预测目标词。&lt;/p&gt;&lt;p&gt;实验分为三个部分，分别是（1）计算两个词之间的语义相似度，与人类标注的相似度进行相关性比较；（2）与word2vec一样的词类比实验；（3）与其他考虑morphology的方法比较。结果是本文方法在语言形态丰富的语言（土耳其语，法语等）及小数据集上表现优异，与预期一致。&lt;/p&gt;&lt;h2&gt;资源&lt;/h2&gt;&lt;p&gt;源码公布在Facebook的fastText项目中：&lt;a href="https://github.com/facebookresearch/fastText" data-editable="true" data-title="GitHub - facebookresearch/fastText: Library for fast text representation and classification."&gt;GitHub - facebookresearch/fastText: Library for fast text representation and classification.&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;相关工作&lt;/h2&gt;&lt;p&gt;利用语言形态学来改进nlp的研究源远流长，本文提及的许多关于character-level和morphology的有趣工作值得参考。&lt;/p&gt;&lt;h2&gt;简评&lt;/h2&gt;&lt;p&gt;文章中提出的思路对于morphologically rich languages（例如土耳其语，词缀的使用极为普遍而有趣）来说十分有意义。词缀作为字母与单词之间的中层单位，本身具有一定的语义信息。通过充分利用这种中层语义来表征罕见词汇，直观上讲思路十分合理，也是应用了compositionality的思想。&lt;/p&gt;&lt;p&gt;利用形态学改进word embedding的工作十分丰富，但中文NLP似乎很难利用这一思路。其实个人感觉中文中也有类似于词缀的单位，比如偏旁部首等等，只不过不像使用字母系统的语言那样容易处理。期待今后也有闪光的工作出现在中文环境中。&lt;/p&gt;&lt;h1&gt;总结&lt;/h1&gt;&lt;p&gt;从Word2Vec到FastText，从word representation到sentence classification，Tomas Mikolov的工作影响了很多人。虽然有个别模型和实验结果曾遭受质疑，但终究瑕不掩瑜。word2vec对NLP的研究起到了极大地推动作用，其实不仅仅是在NLP领域中，在其他很多领域中都可以看到word2vec的思想和作用，也正是从word2vec开始，这个世界变得都被vector化了，person2vec，sentence2vec，paragraph2vec，anything2vec，world2vec。&lt;/p&gt;&lt;p&gt;以上为本期Paperweekly的主要内容，感谢memray、zhkun、gcyydxf、jell四位同学的整理。&lt;/p&gt;&lt;h1&gt;广告时间&lt;/h1&gt;&lt;p&gt;PaperWeekly是一个分享知识和交流学问的民间组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。&lt;/p&gt;&lt;p&gt;微信公众号：PaperWeekly&lt;p&gt;http://weixin.qq.com/r/OUW0rA3ExVC6rUnP9xAr (二维码自动识别)&lt;/p&gt;微博账号：PaperWeekly（&lt;a href="http://weibo.com/u/2678093863" data-editable="true" data-title="PaperWeekly的微博"&gt;PaperWeekly的微博&lt;/a&gt; ）知乎专栏：PaperWeekly（&lt;a href="https://zhuanlan.zhihu.com/paperweekly" data-editable="true" data-title="PaperWeekly - 知乎专栏"&gt;PaperWeekly - 知乎专栏&lt;/a&gt; ）微信交流群：微信+ zhangjun168305（请备注：加群 or 加入paperweekly）&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/22466665&amp;pixel&amp;useReferer"/&gt;</description><author>张俊</author><pubDate>Fri, 16 Sep 2016 12:49:32 GMT</pubDate></item></channel></rss>