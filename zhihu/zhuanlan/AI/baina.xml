<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>黑斑马笔记 - 知乎专栏</title><link>https://zhuanlan.zhihu.com/baina</link><description>黑斑马是百纳（武汉）信息技术有限公司（海豚浏览器）的游戏团队。
百纳致力于研究人工智能和计算机视觉。我们大量招聘上述领域专家和技术人员。</description><lastBuildDate>Fri, 13 Jan 2017 13:16:53 GMT</lastBuildDate><generator>Ricky</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>博弈延伸形式的虚拟自我对局</title><link>https://zhuanlan.zhihu.com/p/22831435</link><description>Johannes Heinrich 伦敦大学学院

&lt;p&gt;Marc Lanctot，David Silver 谷歌DeepMind&lt;/p&gt;&lt;p&gt;~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~&lt;/p&gt;&lt;p&gt;翻译：  &lt;a href="mailto:%E5%8D%A2%E6%99%93%E8%96%87@%E7%99%BE%E7%BA%B3.%E6%B5%B7%E8%B1%9A%E6%B5%8F%E8%A7%88%E5%99%A8"&gt;&lt;u&gt;卢晓薇@百纳.海豚浏览器&lt;/u&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;校对：  &lt;a href="mailto:%E6%9C%B1%E8%87%BB@%E7%99%BE%E7%BA%B3.%E6%B5%B7%E8%B1%9A%E6%B5%8F%E8%A7%88%E5%99%A8"&gt;&lt;u&gt;朱臻@百纳.海豚浏览器&lt;/u&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;微信公众号： zero_zebra&lt;/p&gt;&lt;p&gt;QQ交流群：   142961883&lt;/p&gt;&lt;p&gt;大量职位虚位以待！详情请见公众号.职位列表&lt;/p&gt;&lt;p&gt;~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~&lt;/p&gt;&lt;h1&gt;&lt;b&gt;摘要&lt;/b&gt;&lt;/h1&gt;&lt;p&gt;虚拟博弈是博弈论中受欢迎的学习模型。然而，在对大问题的实际应用上，虚拟博弈受到的关注太少了。这篇论文介绍了虚拟博弈的两个变种，这里的虚拟博弈是实施在博弈延伸形式上的行为策略（behavioral strategies）（&lt;b&gt;&lt;i&gt;行为战略&lt;/i&gt;&lt;/b&gt;&lt;i&gt;是指参与人在每个信息集上随机地选择行动，即一个行为战略规定了对应的每个信息集的行动集合上的概率分布，且不同信息集上的概率分布是独立的&lt;/i&gt;）。第一个变种是一个全宽的过程（full-width process），就等于匹配其正常形态的实现，因此继承了它的保证收敛的特性。然而，它的计算在时间和空间上必须是线性的，而不是指数级的。第二个变种，虚拟自我对局，是一个机器学习框架，实施在基于抽样方式的虚拟博弈中。不完全信息扑克游戏的实验和我们的方法相似，且他们也收敛到近似纳什均衡。&lt;/p&gt;&lt;h1&gt;&lt;b&gt;1.引言&lt;/b&gt;&lt;/h1&gt;&lt;p&gt;虚拟博弈，由Brown提出（1951），是受欢迎的博弈论的学习模型，在虚拟博弈中，玩家重复地玩一个游戏，在每次迭代，根据他们对手的平均策略，选择一个最好的回应。在某些类别的博弈中，虚拟玩家的平均策略组合收敛到纳什均衡。比如，二人零和博弈和潜在博弈（potential games）。虚拟博弈是博弈论的标准工具，也激发了大量的讨论和研究纳什均衡怎么可以在现实中实现（Brown, 1951; Fudenberg, 1998; Hofbauer &amp;amp; Sandholm, 2002; Leslie
&amp;amp; Collins,2006）。虚拟博弈是从经验中学习的自我对局的经典例子，激发了博弈论里的人工智能算法。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-230c4b3cf184d9bc8859ea0d08e405df.png" data-rawwidth="1654" data-rawheight="2339"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-f9fb0163d671ec0789a99cf44aee6967.png" data-rawwidth="1654" data-rawheight="2339"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-e050fced19779b36602048eb5874c3b5.png" data-rawwidth="1654" data-rawheight="2339"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-f8af9b5ed7f93f6929f83a6f308df2f8.png" data-rawwidth="1654" data-rawheight="2339"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-f869c78f3c765c745c96819bb376c962.png" data-rawwidth="1654" data-rawheight="2339"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-e4a030d3545bc7992a104cfee9855539.png" data-rawwidth="1654" data-rawheight="2339"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-1f30b61899f248b20cb34ad814ac0db4.png" data-rawwidth="1654" data-rawheight="2339"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-0a427f17ef6aae7903f7aef8691e4e6e.png" data-rawwidth="1654" data-rawheight="2339"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-6f1808338efc08b0629ea45b7fb934b8.png" data-rawwidth="1654" data-rawheight="2339"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-1f811282c277868fd94c31afa8f924e8.png" data-rawwidth="1654" data-rawheight="2339"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-208a427545a0bb14515232d855116991.png" data-rawwidth="1654" data-rawheight="2339"&gt;&lt;p&gt;图3  比较XFP和FSP：河牌的FQI。该插图使用对数的表度为两个轴呈现结果。&lt;/p&gt;&lt;h1&gt;&lt;b&gt;6. 结论&lt;/b&gt;&lt;/h1&gt;&lt;p&gt;我们为延伸形式博弈介绍了两个虚拟博弈的变体。XFP是第一个虚拟博弈算法，完全实施在行为策略上，当在有虚拟博弈特质的博弈中保存收敛保证特性。FSP是基于取样方法，实施在机器学习框架的概括削弱虚拟博弈。当在每次迭代时，渐进收敛到正确更新时，是否在有限的计算预算下每次迭代能够保证收敛，这仍然是一个开放性的问题。然而，我们展示了我们感觉为什么是这样，我们的实验提供了首个实证经验上的证据。&lt;/p&gt;&lt;p&gt;FSP是一个灵活机器学习框架。它的经验的和效用最大化的特性，即提供很多技术从连续的经验中有效率地学习，使它成为增强学习的完美域。函数近似可能提供自动化抽象和大型延伸形式博弈的概括。连续作用的增强学习可以在连续行为空间中学习最佳回应。因此，FSP有很多潜力扩展到大型，甚至连续动作博弈论的应用程序之中。&lt;/p&gt;&lt;h1&gt;&lt;b&gt;致谢&lt;/b&gt;&lt;/h1&gt;&lt;p&gt;我们想要谢谢Georg
Ostrovski, Peter Dayan, Remi Munos和Joel Veness，谢谢他们深刻的讨论和反馈。这项研究被the UK Centre for Doctoral Training in Financial Computing和Google DeepMind所支持。&lt;/p&gt;&lt;p&gt;~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~&lt;/p&gt;&lt;p&gt;翻译：  &lt;a href="mailto:%E5%8D%A2%E6%99%93%E8%96%87@%E7%99%BE%E7%BA%B3.%E6%B5%B7%E8%B1%9A%E6%B5%8F%E8%A7%88%E5%99%A8"&gt;&lt;u&gt;卢晓薇@百纳.海豚浏览器&lt;/u&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;校对：  &lt;a href="mailto:%E6%9C%B1%E8%87%BB@%E7%99%BE%E7%BA%B3.%E6%B5%B7%E8%B1%9A%E6%B5%8F%E8%A7%88%E5%99%A8"&gt;&lt;u&gt;朱臻@百纳.海豚浏览器&lt;/u&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;微信公众号： zero_zebra&lt;/p&gt;&lt;p&gt;QQ交流群：   142961883&lt;/p&gt;&lt;p&gt;大量职位虚位以待！详情请见公众号.职位列表&lt;/p&gt;&lt;p&gt;~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~&lt;/p&gt;&lt;h1&gt;&lt;b&gt;参考文献&lt;/b&gt;&lt;/h1&gt;&lt;p&gt;Bena¨ ım, Michel, Hofbauer, Josef, and Sorin, Sylvain. Stochastic
approximations and differential inclusions. &lt;i&gt;SIAM
Journal on
Control and Optimization&lt;/i&gt;, 44(1):328–348, 2005.&lt;/p&gt;&lt;p&gt;Bosansky, B, Kiekintveld, Christopher, Lisy, V, and Pechoucek,
Michal. An exact double-oracle algorithm for zero-sum
extensive-form games with imperfect information. &lt;i&gt;Journal
of
Artificial Intelligence Research&lt;/i&gt;, pp. 829–866,
2014.&lt;/p&gt;&lt;p&gt;
Bowling, Michael, Burch, Neil, Johanson, Michael, and Tammelin, Oskari.
Heads-up limit holdem poker is solved. &lt;i&gt;Science&lt;/i&gt;,
347(6218):145–149, 2015.&lt;/p&gt;&lt;p&gt;
Brown, George W. Iterative solution of games by fictitious play.&lt;i&gt;Activity analysis of production and allocation&lt;/i&gt;, 13(1):374–376,
1951.&lt;/p&gt;&lt;p&gt;
Daskalakis, Constantinos and Pan, Qinxuan. A counter-example
to Karlin’s strong conjecture for fictitious play. In &lt;i&gt;Foundations
of Computer Science (FOCS), 2014 IEEE 55th Annual Symposium on&lt;/i&gt;, pp. 11–20. IEEE, 2014.
Ernst, Damien, Geurts, Pierre, and Wehenkel, Louis. Tree-based
batch mode reinforcement learning. In &lt;i&gt;Journal
of Machine
Learning Research&lt;/i&gt;, pp. 503–556, 2005.&lt;/p&gt;&lt;p&gt;
Fudenberg, Drew. &lt;i&gt;The theory of learning in games&lt;/i&gt;, volume 2.
MIT press, 1998.&lt;/p&gt;&lt;p&gt;
Ganzfried, Sam and Sandholm, Tuomas. Computing equilibria in
multiplayer stochastic games of imperfect information. In &lt;i&gt;Proceedings of the 21st International Joint Conference on
Artifical
Intelligence&lt;/i&gt;, pp. 140–146, 2009.&lt;/p&gt;&lt;p&gt;
Gilpin, Andrew, Hoda, Samid, Pena, Javier, and Sandholm, Tuomas. Gradient-based
algorithms for finding Nash equilibria in
extensive form games. In &lt;i&gt;Internet and Network
Economics&lt;/i&gt;, pp.
57–69. Springer, 2007.&lt;/p&gt;&lt;p&gt;
Greenwald, Amy, Li, Jiacui, Sodomka, Eric, and Littman,
Michael. Solving for best responses in extensive-form games
using reinforcement learning methods. &lt;i&gt;The
1st Multidisciplinary Conference on Reinforcement Learning and Decision
Making (RLDM)&lt;/i&gt;, 2013.&lt;/p&gt;&lt;p&gt;
Heinrich, Johannes and Silver, David. Smooth UCT search in
computer poker. In &lt;i&gt;Proceedings of the
24th International Joint
Conference on Artifical Intelligence&lt;/i&gt;,
2015. In press.&lt;/p&gt;&lt;p&gt;
Hendon, Ebbe, Jacobsen, Hans Jørgen, and Sloth, Birgitte. Fictitious play in
extensive form games. &lt;i&gt;Games and Economic
Behavior&lt;/i&gt;, 15(2):177–202, 1996.&lt;/p&gt;&lt;p&gt;
Hofbauer, Josef and Sandholm, William H. On the global convergence of
stochastic fictitious play. &lt;i&gt;Econometrica&lt;/i&gt;, 70(6):2265–
2294, 2002.&lt;/p&gt;&lt;p&gt;Karlin, Samuel. &lt;i&gt;Mathematical methods
and theory in games, programming and economics&lt;/i&gt;.
Addison-Wesley, 1959.&lt;/p&gt;&lt;p&gt;
Koller, Daphne, Megiddo, Nimrod, and Von Stengel, Bernhard.
Fast algorithms for finding randomized strategies in game
trees. In &lt;i&gt;Proceedings of the 26th ACM Symposium on Theory
of Computing&lt;/i&gt;, pp. 750–759. ACM, 1994.&lt;/p&gt;&lt;p&gt;
Koller, Daphne, Megiddo, Nimrod, and Von Stengel, Bernhard.
Efficient computation of equilibria for extensive two-person
games. &lt;i&gt;Games and Economic Behavior&lt;/i&gt;,
14(2):247–259, 1996.&lt;/p&gt;&lt;p&gt;
Kuhn, Harold W. Extensive games and the problem of information. &lt;i&gt;Contributions to the Theory of Games&lt;/i&gt;,
2(28):193–216,
1953.&lt;/p&gt;&lt;p&gt;
Lambert III, Theodore J, Epelman, Marina A, and Smith,
Robert L. A fictitious play approach to large-scale optimization. &lt;i&gt;Operations Research&lt;/i&gt;, 53(3):477–489,
2005.&lt;/p&gt;&lt;p&gt;
Lanctot, Marc, Waugh, Kevin, Zinkevich, Martin, and Bowling,
Michael. Monte Carlo sampling for regret minimization in extensive games. In &lt;i&gt;Advances in Neural Information Processing
Systems 22&lt;/i&gt;, pp. 1078–1086, 2009.&lt;/p&gt;&lt;p&gt;
Leslie, David S and Collins, Edmund J. Generalised weakened
fictitious play. &lt;i&gt;Games and Economic Behavior&lt;/i&gt;, 56(2):285–298,
2006.&lt;/p&gt;&lt;p&gt;
McMahan, H Brendan and Gordon, Geoffrey J. A fast bundlebased anytime algorithm
for poker and other convex games. In&lt;i&gt;International Conference on Artificial Intelligence and Statistics&lt;/i&gt;, pp. 323–330, 2007.&lt;/p&gt;&lt;p&gt;
Miltersen, Peter Bro and Sørensen, Troels Bjerre. Computing
a quasi-perfect equilibrium of a two-player game. &lt;i&gt;Economic
Theory&lt;/i&gt;, 42(1):175–192, 2010.&lt;/p&gt;&lt;p&gt;
Myerson, Roger B. &lt;i&gt;Game Theory: Analysis of Conflict&lt;/i&gt;. Harvard
University Press, 1991.&lt;/p&gt;&lt;p&gt;
Robinson, Julia. An iterative method of solving a game. &lt;i&gt;Annals
of Mathematics&lt;/i&gt;, pp. 296–301, 1951.&lt;/p&gt;&lt;p&gt;
Sandholm, Tuomas. The state of solving large incompleteinformation games, and
application to poker. &lt;i&gt;AI Magazine&lt;/i&gt;,
31(4):13–32, 2010.&lt;/p&gt;&lt;p&gt;
Silver, David and Veness, Joel. Monte-Carlo planning in large
POMDPs. In &lt;i&gt;Advances in Neural Information Processing Systems&lt;/i&gt;, pp. 2164–2172, 2010.&lt;/p&gt;&lt;p&gt;
Southey, Finnegan, Bowling, Michael, Larson, Bryce, Piccione,
Carmelo, Burch, Neil, Billings, Darse, and Rayner, Chris.
Bayes bluff: Opponent modelling in poker. In &lt;i&gt;In
Proceedings of the 21st Annual Conference on Uncertainty in Artificial
Intelligence (UAI&lt;/i&gt;, pp. 550–558, 2005.
Sutton, Richard S and Barto, Andrew G. &lt;i&gt;Reinforcement
learning:
An introduction&lt;/i&gt;, volume 1. Cambridge Univ Press,
1998.&lt;/p&gt;&lt;p&gt;
Von Stengel, Bernhard. Efficient computation of behavior strategies. &lt;i&gt;Games and Economic Behavior&lt;/i&gt;,
14(2):220–246, 1996.&lt;/p&gt;&lt;p&gt;
Watkins, Christopher JCH and Dayan, Peter. Q-learning. &lt;i&gt;Machine
learning&lt;/i&gt;, 8(3-4):279–292, 1992.&lt;/p&gt;&lt;p&gt;
Zinkevich, Martin, Johanson, Michael, Bowling, Michael, and
Piccione, Carmelo. Regret minimization in games with incomplete information. In
&lt;i&gt;Advances in Neural Information Processing Systems&lt;/i&gt;, pp. 1729–1736, 2007&lt;/p&gt;&lt;p&gt;~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~&lt;/p&gt;&lt;p&gt;翻译：  &lt;a href="mailto:%E5%8D%A2%E6%99%93%E8%96%87@%E7%99%BE%E7%BA%B3.%E6%B5%B7%E8%B1%9A%E6%B5%8F%E8%A7%88%E5%99%A8"&gt;&lt;u&gt;卢晓薇@百纳.海豚浏览器&lt;/u&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;校对：  &lt;a href="mailto:%E6%9C%B1%E8%87%BB@%E7%99%BE%E7%BA%B3.%E6%B5%B7%E8%B1%9A%E6%B5%8F%E8%A7%88%E5%99%A8"&gt;&lt;u&gt;朱臻@百纳.海豚浏览器&lt;/u&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;微信公众号： zero_zebra&lt;/p&gt;&lt;p&gt;QQ交流群：   142961883&lt;/p&gt;&lt;p&gt;大量职位虚位以待！详情请见公众号.职位列表&lt;/p&gt;&lt;p&gt;~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/22831435&amp;pixel&amp;useReferer"/&gt;</description><author>喵的熊爪饼</author><pubDate>Sun, 09 Oct 2016 14:09:06 GMT</pubDate></item><item><title>自然场景下脸部检测、姿态估计和特征点定位</title><link>https://zhuanlan.zhihu.com/p/22578841</link><description>本文译自Xiangxin Zhu  Deva Ramanan的《Face Detection,Pose Estimation,and Landmark Localization in the Wild》，有翻译不当的地方敬请指出。&lt;p&gt;~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~翻译：  &lt;a class="" data-title="刘畅@百纳.海豚浏览器" href="mailto:xxx@xn--bxy08o.xn--m7rv64cod312j7xc"&gt;刘畅@百纳.海豚浏览器&lt;/a&gt;校对：  &lt;a class="" data-title="吴刚@百纳.海豚浏览器" href="mailto:xxx@%E7%99%BE%E7%BA%B3.%E6%B5%B7%E8%B1%9A%E6%B5%8F%E8%A7%88%E5%99%A8"&gt;吴刚@百纳.海豚浏览器&lt;/a&gt;微信公众号： zero_zebraQQ交流群：   142961883大量职位虚位以待！详情请见公众号.职位列表~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~&lt;/p&gt;&lt;h1&gt;&lt;b&gt;摘要&lt;/b&gt;&lt;/h1&gt;&lt;p&gt;我们提出了一个用于现实世界复杂背景图片中人脸检测、姿态估计和特征点估计的统一模型。我们的模型是基于树和shared pool of parts（译者注：parts共享池）混合模型；我们将每个面部特征点作为一个部分，利用全局混合来捕捉由于视点变化引起的拓扑结构变化。我们证明树结构的模型在捕捉全局弹性形变上是非常有效的，并且和dense graph structures（译者注：密集图形结构）相比，是非常易于优化。我们提出了在标准的脸部benchmark和一个新的“in the wild”（译者注：自然场景）带注释的数据集上的扩展结果，显示出对于所有的三项任务，我们的系统达到了先进的水准。即使我们的模型是用上百张脸进行适当训练，但是优于用数十亿样例训练的的商业系统（比如Google Picasa和face.com）。&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-643eefc523114026ccef49c863f7bd10.jpg" data-rawwidth="2481" data-rawheight="3508"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-123c520dbe285b22e48d78a2d1c80d62.jpg" data-rawwidth="2481" data-rawheight="3508"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-487e229446ce9eb67ae7bfec64272842.jpg" data-rawwidth="2481" data-rawheight="3508"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-bfc88c2b72da7bf9dc80ba796b1d3db0.jpg" data-rawwidth="2481" data-rawheight="3508"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-b7a950bcabc5b81e15328b3310360885.jpg" data-rawwidth="2481" data-rawheight="3508"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-d21223d949e36f3053a710d77f0c1946.jpg" data-rawwidth="2481" data-rawheight="3508"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-45b18657b4302c253c77f2931a7bdb63.jpg" data-rawwidth="2481" data-rawheight="3508"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-5a23555056ff5c27fa841c70f05faa34.jpg" data-rawwidth="2481" data-rawheight="3508"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-a63e59dedd7762a4dc8072c6345d0323.jpg" data-rawwidth="2481" data-rawheight="3508"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-30400729de27fc8b6d97bf8de4890d98.jpg" data-rawwidth="2481" data-rawheight="3508"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-16231dfe23bec2b7d78d3c92e530ddec.jpg" data-rawwidth="2481" data-rawheight="3508"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-56044327bb64ec1cad8719fde39dd8b0.jpg" data-rawwidth="2481" data-rawheight="3508"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-088cc7b11d94a10824cc837140dd3d7f.jpg" data-rawwidth="2481" data-rawheight="3508"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-b6e3f9b6c5d76f776cf368d47e83d7c1.jpg" data-rawwidth="2481" data-rawheight="3508"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-1ae52587ea30c8fa64cb7cdc89bd61cf.jpg" data-rawwidth="2481" data-rawheight="3508"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-19b403f061650025c34214a6d3513b8c.jpg" data-rawwidth="2481" data-rawheight="3508"&gt;译者注：由于翻译水平有限，难免有些地方翻译不妥，有问题的欢迎提出来，大家共同学习，谢谢~&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/22578841&amp;pixel&amp;useReferer"/&gt;</description><author>海雅古慕</author><pubDate>Thu, 22 Sep 2016 23:12:31 GMT</pubDate></item><item><title>调整3D形变模型适应边缘：
强联系和弱联系的比较</title><link>https://zhuanlan.zhihu.com/p/22507938</link><description>&lt;h2&gt;作者&lt;/h2&gt;&lt;p&gt;Anil Bas        William A. P. Smith           Timo Bolkarty            Stefanie Wuhrer&lt;/p&gt;&lt;p&gt;Department of
Computer Science, University of York, UK&lt;/p&gt;&lt;p&gt;Multimodal
Computing and Interaction, Saarland University, Germany&lt;/p&gt;&lt;p&gt;Morpheo Team,
INRIA Grenoble Rhˆone-Alpes, France&lt;/p&gt;&lt;h2&gt;译者&lt;/h2&gt;&lt;p&gt;翻译：  &lt;a href="mailto:%E5%90%B4%E5%88%9A@%E7%99%BE%E7%BA%B3.%E6%B5%B7%E8%B1%9A%E6%B5%8F%E8%A7%88%E5%99%A8"&gt;吴刚@百纳.海豚浏览器&lt;/a&gt;&lt;/p&gt;&lt;p&gt;校对：  &lt;a href="mailto:%E5%88%98%E7%95%85@%E7%99%BE%E7%BA%B3.%E6%B5%B7%E8%B1%9A%E6%B5%8F%E8%A7%88%E5%99%A8"&gt;刘畅@百纳.海豚浏览器&lt;/a&gt;&lt;/p&gt;&lt;p&gt;微信公众号： zero_zebra&lt;/p&gt;&lt;p&gt;QQ交流群：   142961883&lt;/p&gt;&lt;p&gt;大量职位虚位以待！详情请见公众号.职位列表&lt;/p&gt;&lt;h2&gt;摘要&lt;/h2&gt;&lt;p&gt;我们提出了一个全自动的方法，可以用来调整3D形变模型去适应任意角度和光照的单个人脸。我们的方法依赖于几何特征（边缘和特征点），启发于迭代最近点算法，基于计算模型顶点和边缘像素的强联系。之前的工作是利用弱联系来形成一个edge-derived cost surface，这个代价函数通过非线性优化来最小化。我们证明了我们的方法是优于这个方法的。&lt;/p&gt;&lt;p&gt;&lt;b&gt;索引项&lt;/b&gt;——3D morphable model，edge detection，iterated closest point，face shape estimation。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-39361b3e0fc29d9853b15c72c47e4f08.jpeg" data-rawwidth="826" data-rawheight="1169"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-caa7b684110b8f548be959197048f73a.jpeg" data-rawwidth="826" data-rawheight="1169"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-d7e8c6e757059fedf57f99638b42cf2a.jpeg" data-rawwidth="826" data-rawheight="1169"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-0f484ea5b2c14271c3d6d58134fa7a2b.jpeg" data-rawwidth="826" data-rawheight="1169"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-e5fbe57304159fc0e6134c7a4905ee49.jpeg" data-rawwidth="826" data-rawheight="1169"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-bf4f23b8a8afb40332cbef4dd9b67a3d.jpeg" data-rawwidth="826" data-rawheight="1169"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-3fbd01f199a4ad59c956f8750c1f2063.jpeg" data-rawwidth="826" data-rawheight="1169"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/v2-a1d10f95552c4fe4ee254e7b651653a0.jpeg" data-rawwidth="826" data-rawheight="1169"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/v2-78212584781bfe552255bd3359159ff1.jpeg" data-rawwidth="826" data-rawheight="1169"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/v2-5bb344f45bb0a14a12faae894028a312.jpeg" data-rawwidth="826" data-rawheight="1169"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/v2-0bd2098fdb3958a9ed6aedabd66210cc.jpeg" data-rawwidth="826" data-rawheight="1169"&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/22507938&amp;pixel&amp;useReferer"/&gt;</description><author>kiukotsu</author><pubDate>Mon, 19 Sep 2016 14:51:41 GMT</pubDate></item><item><title>Tensorflow的GPU支持模式下的安装要点</title><link>https://zhuanlan.zhihu.com/p/22410507</link><description>&lt;p&gt;其实Tensorflow在GPU支持模式下的安装并不困难，严格按照其官方文档就可以了。但整个 过程比较长，中间一些步骤注意不到也可能出错。这里列出要点和排错指南。&lt;/p&gt;&lt;h2&gt;确保Ecosystem一致性&lt;/h2&gt;&lt;p&gt;要确保Tensorflow能真正利用GPU的算力，就需要保证驱动、CUDA库和Tensorflow的版本相兼容。首先要确定你的硬件支持到哪一个版本的cuda和cudnn。比如我们一个比较初级的机器使用的GPU的是GeForce GTX 1070，这个机器不是Pascal架构的，所以安装Cuda的版本到7.5就ok了，最新的8.0则不是必须的。实际在安装中我们还发现了一个安装了8.0以后的问题，这个会在后面提到。&lt;/p&gt;&lt;h2&gt;安装完成后的测试&lt;/h2&gt;&lt;p&gt;安装完成后，需要运行一小段tensorflow脚本来测试安装是否正确。Tensorflow的官方教程里给出了两个阶段的测试，第一个是hello world性质的：&lt;/p&gt;&lt;pre&gt;&lt;code lang="python"&gt;$ python
...
&amp;gt;&amp;gt;&amp;gt; import tensorflow as tf
&amp;gt;&amp;gt;&amp;gt; hello = tf.constant('Hello, TensorFlow!')
&amp;gt;&amp;gt;&amp;gt; sess = tf.Session()
&amp;gt;&amp;gt;&amp;gt; print(sess.run(hello))
Hello, TensorFlow!
&amp;gt;&amp;gt;&amp;gt; a = tf.constant(10)
&amp;gt;&amp;gt;&amp;gt; b = tf.constant(32)
&amp;gt;&amp;gt;&amp;gt; print(sess.run(a + b))
42
&amp;gt;&amp;gt;&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code lang="pytb"&gt;                                           
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally                               
I tensorflow/stream_executor/dso_loader.cc:102] Couldn't open CUDA library libcudnn.so. LD_LIBRARY_PATH:                               
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally                                
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally                               
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;在这一步可能报的错误有libcudart.so.(x.x) cannot open share object file。这意味着CUDA并未正确安装（*1），或者未配置路径（*2），或者cuda的版本不正确（*3）。&lt;/p&gt;&lt;p&gt; 第二个阶段的检查是cudnn是否正确安装了，以及tensorflow在运算时，是否真正将计算分配到了GPU上。注意在上面的hello world中，尽管cudnn并未安装正确，程序只会报一个libcudnn并未找到的警告，程序还会继续正常去行。要检查cudnn是否正确安装，需要使用用到cudnn的库，可以用下面的代码来检查：&lt;/p&gt;&lt;pre&gt;&lt;code lang="python"&gt;import tensorflow as tf

input = tf.Variable(tf.random_normal([100, 28, 28, 1]))
filter = tf.Variable(tf.random_normal([5, 5, 1, 6]))

sess = tf.Session()
sess.run(tf.initialize_all_variables())

op = tf.nn.conv2d(input, filter, strides = [1, 1, 1, 1], padding = 'VALID')
out = sess.run(op)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;在前面通过了“hello world”测试的环境下运行上面的代码，会导致程序崩溃：&lt;/p&gt;&lt;pre&gt;&lt;code lang="python"&gt;I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:102] Couldn't open CUDA library libcudnn.so. LD_LIBRARY_PATH: 
...
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: 
name: GeForce GTX 1070
major: 6 minor: 1 memoryClockRate (GHz) 1.759
pciBusID 0000:01:00.0
Total memory: 7.92GiB
Free memory: 7.84GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating ...
...
F tensorflow/stream_executor/cuda/cuda_dnn.cc:208] could not find cudnnCreate in cudnn DSO; dlerror: /home/yyang/tensorflow/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow.so: undefined symbol: cudnnCreate
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;在我的环境里是由于LD_LIBRARY_PATH未配置好。&lt;/p&gt;&lt;p&gt;&lt;i&gt;注：由于运行在一个多人共享的环境上，所以我使用了screen jupter notebook来创建一个可以从browser上远程运行桌面命令和ipynb会话的环境。但是，screen并没有一开始完全继承我的环境设置，所以导致libcuda.so可以加载，而libcudnn.so不能加载。而这种情况，刚好可以通过hello world测试，如果你忽略警告的话。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;实际上你还应该运行第三个阶段的测试--确保当你的tensorflow运行时，它是真正运行在GPU上，这需要在创建session时就加上配置信息：&lt;/p&gt;&lt;pre&gt;&lt;code lang="python"&gt;import tensorflow as tf

input = tf.Variable(tf.random_normal([100, 28, 28, 1]))
filter = tf.Variable(tf.random_normal([5, 5, 1, 6]))

sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))
sess.run(tf.initialize_all_variables())

op = tf.nn.conv2d(input, filter, strides = [1, 1, 1, 1], padding = 'VALID')
out = sess.run(op)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;重点在第四行，我们加上了log_device_placement信息。&lt;/p&gt;&lt;p&gt;现在运行上面的命令，会得到：&lt;/p&gt;&lt;pre&gt;&lt;code lang="pytb"&gt;I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally
...
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: 
name: GeForce GTX 1070
major: 6 minor: 1 memoryClockRate (GHz) 1.759
pciBusID 0000:01:00.0
Total memory: 7.92GiB
Free memory: 7.84GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:0) -&amp;gt; (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0)
Device mapping:
/job:localhost/replica:0/task:0/gpu:0 -&amp;gt; device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0
I tensorflow/core/common_runtime/direct_session.cc:175] Device mapping:
/job:localhost/replica:0/task:0/gpu:0 -&amp;gt; device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0

Variable_1: /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:818] Variable_1: /job:localhost/replica:0/task:0/gpu:0
Variable_1/read: /job:localhost/replica:0/task:0/gpu:0
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;从上面的输出可以看出，执行任务已经和gpu绑定了。&lt;/p&gt;&lt;h2&gt;查错&lt;/h2&gt;&lt;p&gt;&lt;b&gt;检查显卡设备、驱动是否安装正确&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们使用lspic | grep -i nvidia来检查显卡安装是否正确，以及驱动是否加载：&lt;/p&gt;&lt;pre&gt;&lt;code lang="bash"&gt;01:00.0 VGA compatible controller: NVIDIA Corporation Device 1b81 (rev a1) (prog-if 00 [VGA controller])
	Subsystem: Device 7377:0000
	Flags: bus master, fast devsel, latency 0, IRQ 16
	Memory at f6000000 (32-bit, non-prefetchable) [size=16M]
	Memory at e0000000 (64-bit, prefetchable) [size=256M]
	Memory at f0000000 (64-bit, prefetchable) [size=32M]
	I/O ports at e000 [size=128]
	[virtual] Expansion ROM at f7000000 [disabled] [size=512K]
	Capabilities: [60] Power Management version 3
	Capabilities: [68] MSI: Enable- Count=1/1 Maskable- 64bit+
	Capabilities: [78] Express Legacy Endpoint, MSI 00
	Capabilities: [100] Virtual Channel
	Capabilities: [250] Latency Tolerance Reporting
	Capabilities: [128] Power Budgeting &amp;lt;?&amp;gt;
	Capabilities: [420] Advanced Error Reporting
	Capabilities: [600] Vendor Specific Information: ID=0001 Rev=1 Len=024 &amp;lt;?&amp;gt;
	Capabilities: [900] #19
	Kernel driver in use: nvidia
	Kernel modules: nvidiafb, nouveau, nvidia_drm, nvidia
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;从最后两行来看，这块显卡使用的是nvidia的驱动，且驱动已加载到内核。&lt;/p&gt;&lt;p&gt;驱动版本可以通过下面的语句查询到：&lt;/p&gt;&lt;pre&gt;&lt;code lang="bash"&gt;cat /proc/driver/nvidia/version 
NVRM version: NVIDIA UNIX x86_64 Kernel Module  367.44  Wed Aug 17 22:24:07 PDT 2016
GCC version:  gcc version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.2) 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;看上去完全正确，因为显卡的驱动就是367.44。&lt;/p&gt;&lt;p&gt;&lt;b&gt;检查cuda是否安装正确&lt;/b&gt;&lt;/p&gt;&lt;p&gt;要检查cuda库是否安装正确，可以使用cuda编译后产生的deviceQuery工具。同时，你还要检查LD_LIBRARY_PATH是否正确设置：&lt;/p&gt;&lt;p&gt;echo $LD_LIBRARY_PATH&lt;/p&gt;&lt;p&gt;输出中应该包括/usr/local/cuda-x-x/lib64。如果没有，你需要编辑/etc/profile或者~/.bashrc，加入export LD_LIBRARY_PATH=xx。&lt;/p&gt;&lt;p&gt;在我的环境里还出现过上述配置都正确，但tensorflow还是报找不到cuda库的错误，即上文中提到的错误*3。最后发现错误是因为cuda安装了8.0的版本，但tensorflow的0.10版本，如果不是自己编译的话，它的发行版是链接的7.5的版本，所以会出错。最后的解决方案是将cuda版本回退到7.5（因为硬件并不支持8.0所需要的pascal架构）。&lt;/p&gt;&lt;h2&gt;其它&lt;/h2&gt;&lt;p&gt;我使用了一台多人共享的机器，通过远程连接访问。为了访问更方便快捷，我设置了以下环境：&lt;/p&gt;&lt;p&gt;1） virtualenv。以保证不跟其它人冲突。 &lt;/p&gt;&lt;pre&gt;&lt;code lang="python"&gt;pip3 install virtualenv
virtualenv --system-site-packages tensorflow_pyenv
#激活virtualenv环境后，再继续tensorflow安装
source tensorflow_pyenv/bin/activate
pip3 install --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.10.0-cp35-cp35m-linux_x86_64.whl
pip3 install jupyer notebook
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;2）配置jupyter，启用远程服务&lt;/p&gt;&lt;p&gt; 为了使jupyter启动的服务能够在远程浏览器中打开，需要配置jupter:&lt;/p&gt;&lt;pre&gt;&lt;code lang="python"&gt;jupyter notebook --generate-config&lt;/code&gt;&lt;/pre&gt;&lt;p&gt; 这样会在当前目标下生成.jupyter的目标，里面有jupyter_notebook_config.py文件，打开并编辑：&lt;/p&gt;&lt;pre&gt;&lt;code lang="python"&gt;c.NotebookApp.password=u''
c.NotebookApp.ip = '*'
c.NotebookApp.open_browser = False

# It is a good idea to set a known, fixed port for server access
c.NotebookApp.port = 9999&lt;/code&gt;&lt;/pre&gt;&lt;p&gt; 其中password可以使用下面的程序生成：&lt;/p&gt;&lt;pre&gt;&lt;code lang="python"&gt;In [1]: from notebook.auth import passwd
In [2]: passwd()
Enter password:
Verify password:
Out[2]: 'sha1:67c9e60bb8b6:9ffede0825894254b2e042ea597d771089e11aed'&lt;/code&gt;&lt;/pre&gt;&lt;p&gt; 将out[2]中的字符串完整地输入到c.NotebookApp.password=u''中的引号中去。&lt;/p&gt;&lt;p&gt;3）通过screen来运行jupyter，使之象一个服务。&lt;/p&gt;&lt;p&gt;安装完成jupter和notebook以后，使用screen来运行jupyter。使用screen的好处是它能将程序放在后台运行，这样终端连接退出也不影响程序运行。在我的环境下，需要在用户目标~下创建一个.screenrc，加上这样的内容：&lt;/p&gt;&lt;pre&gt;&lt;code lang="bash"&gt;setenv LD_LIBRARY_PATH /usr/local/cuda-7.5/lib64:$LD_LIBRARY_PATH
source /etc/screenrc&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;现在启动程序：&lt;/p&gt;&lt;pre&gt;&lt;code lang="bash"&gt;screen jupyter notebook&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;现在可以打开浏览器，输入ip:端口来访问notebook了。&lt;/p&gt;&lt;p&gt;注意，你需要有64bit的screen来运行jupyter。如果使用了32bit的screen，在对一些稍大的一点数据集进行训练时，会因内存不足挂掉。另一个办法是将jupyter notebook的运行daemonize化。你可以修改&lt;a href="https://github.com/hbaaron/code_snippets/blob/master/daemonize/daemon.sh"&gt;这个脚本&lt;/a&gt;，使得jupyter可以以类似服务的方式来运行。&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/22410507&amp;pixel&amp;useReferer"/&gt;</description><author>杨勇</author><pubDate>Mon, 12 Sep 2016 17:56:18 GMT</pubDate></item><item><title>多玩家随机不完全信息博弈的均衡计算</title><link>https://zhuanlan.zhihu.com/p/22378565</link><description>&lt;p&gt;本文译自卡内基梅隆的Sam Ganzfried 和Tuomas W. Sandholm 的论文《Computing Equilibria in Multiplayer Stochastic Games of Imperfect Information 
》
&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/898c18eb66fae759f307bf6d1d79bebc.jpg" data-rawheight="2339" data-rawwidth="1654"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/7bea4bfbb46da1d12c450c3043731da6.jpg" data-rawheight="2339" data-rawwidth="1654"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/6d379975ba2d4007fe0c3d1879f23a9c.jpg" data-rawheight="2339" data-rawwidth="1654"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/53483b6a75ee55d930842a560b93fa62.jpg" data-rawheight="2339" data-rawwidth="1654"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/08ef1cf89676cff6e97b8fc4b408e8e3.jpg" data-rawheight="2339" data-rawwidth="1654"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/235f453c8efeaa6c9c5d3d53c97c0bb5.jpg" data-rawheight="2339" data-rawwidth="1654"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/a12f62c4b9d5989276107b8ebc71f09a.jpg" data-rawheight="2234" data-rawwidth="1580"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/9371f737ffc5d3d7fd4934ae78aeaa1b.jpg" data-rawheight="1497" data-rawwidth="1059"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/e4a0a49a5e163219847e6daedb9940cc.jpg" data-rawheight="2339" data-rawwidth="1654"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/619db6fd28ffcf290bfc28a8a6c77484.jpg" data-rawheight="2000" data-rawwidth="1414"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/e703bd69fe1826c15329c5779dc099d4.jpg" data-rawheight="2339" data-rawwidth="1654"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/12dfaca291e32e578d0395cb7b6c49b9.jpg" data-rawheight="2339" data-rawwidth="1654"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/601e098c74820812dc97fdf123798843.jpg" data-rawheight="2339" data-rawwidth="1654"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/7e86e73a40c25b89a891730b922edac3.jpg" data-rawheight="2339" data-rawwidth="1654"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/1b7aa28988e42a7e6aecee2f55dd4a6c.jpg" data-rawheight="2339" data-rawwidth="1654"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/25903d79b66f03347dd2aedeac447c8e.jpg" data-rawheight="2339" data-rawwidth="1654"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/2b1cd43db683c15df92886812637cc8f.jpg" data-rawheight="2339" data-rawwidth="1654"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/e9a7cedbd0d26d5bdccfcaa011bb1308.jpg" data-rawheight="2339" data-rawwidth="1654"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/245234ef14c6935708a97c3b605a6378.jpg" data-rawheight="1486" data-rawwidth="1051"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/1c48cb6a49756e2182364352434c8e4c.jpg" data-rawheight="2339" data-rawwidth="1654"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/ce8c5a8cb4de84240d331bb169601558.jpg" data-rawheight="2339" data-rawwidth="1654"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/baa153a0198b2cabcf86334643741139.jpg" data-rawheight="2339" data-rawwidth="1654"&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/22378565&amp;pixel&amp;useReferer"/&gt;</description><author>喵的熊爪饼</author><pubDate>Fri, 09 Sep 2016 14:23:05 GMT</pubDate></item><item><title>用于语义分割的全卷积网络</title><link>https://zhuanlan.zhihu.com/p/22280115</link><description>&lt;p&gt;      本文译自UC Berkeley的Jonathan Long、Evan Shelhamer、Trevor Darrell的《Fully Convolutional Networks for Semantic Segmentation》，2015 CVPR best paper。~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~翻译：  &lt;a class="" data-title="刘畅@百纳.海豚浏览器" href="mailto:xxx@xn--bxy08o.xn--m7rv64cod312j7xc"&gt;刘畅@百纳.海豚浏览器&lt;/a&gt;校对：  &lt;a class="" data-title="吴刚@百纳.海豚浏览器" href="mailto:xxx@%E7%99%BE%E7%BA%B3.%E6%B5%B7%E8%B1%9A%E6%B5%8F%E8%A7%88%E5%99%A8"&gt;吴刚@百纳.海豚浏览器&lt;/a&gt;微信公众号： zero_zebraQQ交流群：   142961883大量职位虚位以待！详情请见公众号.职位列表~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~&lt;/p&gt;&lt;p&gt;摘要： 卷积网络在特征分层领域是非常强大的视觉模型。在语义分割中，我们证明了经过端到端、像素到像素训练的卷积网络胜过目前最先进的技术。我们的核心观点是建立“全卷积”网络，输入任意尺寸，经过有效的推理和学习产生相应尺寸的输出。我们定义并指定全卷积网络的空间，解释它们在空间范围内dense prediction task(译者注：预测每个像素所属的类别)中的应用并联系之前的模型。我们修改了当前的分类网络(AlexNet [&lt;a data-title="22" data-editable="true" href="https://zhuanlan.zhihu.com/#%E6%96%87%E7%8C%AE22"&gt;22&lt;/a&gt;],the VGG net [&lt;a data-title="34" data-editable="true" href="https://zhuanlan.zhihu.com/#%E6%96%87%E7%8C%AE34"&gt;34&lt;/a&gt;], and GoogLeNet [&lt;a data-title="35" data-editable="true" href="https://zhuanlan.zhihu.com/#%E6%96%87%E7%8C%AE35"&gt;35&lt;/a&gt;])到全卷积网络和通过fine-tuning（译者注：精调）[&lt;a data-title="5" data-editable="true" href="https://zhuanlan.zhihu.com/#%E6%96%87%E7%8C%AE5"&gt;5&lt;/a&gt;] 将learned representation 迁移到分割任务中。然后我们定义了一个skip architecture(译者注：跨层架构)，结合来自深、粗层的语义信息和来自浅、细层的表征信息来产生准确和精细的分割。我们的全卷积网络在PASCAL VOC， NYUDv2以及SIFT Flow等测试集中均达到了顶尖的分割结果，同时对于一个特定图片的推理花费时间少于0.2秒。&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" data-rawheight="1169" data-rawwidth="826" src="41e94d11f0c384a9fdfabbecad058b0c.jpg"&gt;&lt;img rel="noreferrer" data-rawheight="1169" data-rawwidth="826" src="d87349b2b02221f70f495a6c743c9b00.jpg"&gt;&lt;img rel="noreferrer" data-rawheight="1169" data-rawwidth="826" src="ad88e6d17a70a0f1099b6b3d07657b04.jpg"&gt;&lt;img rel="noreferrer" data-rawheight="1169" data-rawwidth="826" src="7cf9a2b6bfa1ee619ddfc48b7a76474a.jpg"&gt;&lt;img rel="noreferrer" data-rawheight="1169" data-rawwidth="826" src="210f65b4cc3d29001853d7300790d6b9.jpg"&gt;&lt;img rel="noreferrer" data-rawheight="1169" data-rawwidth="826" src="f4915f737fe720f396d25c06116bb968.jpg"&gt;&lt;img rel="noreferrer" data-rawheight="1169" data-rawwidth="826" src="d7b77c1d084b6196705609c06dc56729.jpg"&gt;&lt;img rel="noreferrer" data-rawheight="1169" data-rawwidth="826" src="24946a0d3cfe0a021599a73d84f57093.jpg"&gt;&lt;img rel="noreferrer" data-rawheight="1169" data-rawwidth="826" src="32a1eb93e53f4fccfb77c22cb719368c.jpg"&gt;&lt;img rel="noreferrer" data-rawheight="1169" data-rawwidth="826" src="74de566ac034d5aefe14ece2e105712f.jpg"&gt;&lt;img rel="noreferrer" data-rawheight="1169" data-rawwidth="826" src="51006ca633addeea18fbb49bf4dd47ea.jpg"&gt;&lt;img rel="noreferrer" data-rawheight="1169" data-rawwidth="826" src="63cd4d5ff806d62216be1dba87655b57.jpg"&gt;&lt;img rel="noreferrer" data-rawheight="1169" data-rawwidth="826" src="a4d539725a767ae3cc4f14ed23a298b4.jpg"&gt;&lt;img rel="noreferrer" data-rawheight="1169" data-rawwidth="826" src="879a3e787cf2a41c05717f15b340ca38.jpg"&gt;&lt;img rel="noreferrer" data-rawheight="1169" data-rawwidth="826" src="51188d9f6538bb50cd60b1cdc7d7cf95.jpg"&gt;&lt;img rel="noreferrer" data-rawheight="1169" data-rawwidth="826" src="c72edc634b80a87edbaa3c356a155832.jpg"&gt;&lt;img rel="noreferrer" data-rawheight="159" data-rawwidth="789" src="0dbf74ab2bb4da90f6b4888851611c9c.jpg"&gt;译者注：由于翻译水平有限，难免有些地方翻译不妥，有问题的欢迎提出来，大家共同学习，谢谢~&lt;/p&gt;&lt;p&gt;最后，再贴个广告~~&lt;/p&gt;&lt;p&gt;~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~翻译：  &lt;a class="" data-title="刘畅@百纳.海豚浏览器" href="mailto:xxx@xn--bxy08o.xn--m7rv64cod312j7xc"&gt;刘畅@百纳.海豚浏览器&lt;/a&gt;校对：  &lt;a class="" data-title="吴刚@百纳.海豚浏览器" href="mailto:xxx@%E7%99%BE%E7%BA%B3.%E6%B5%B7%E8%B1%9A%E6%B5%8F%E8%A7%88%E5%99%A8"&gt;吴刚@百纳.海豚浏览器&lt;/a&gt;微信公众号： zero_zebraQQ交流群：   142961883大量职位虚位以待！详情请见公众号.职位列表~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/22280115&amp;pixel&amp;useReferer"/&gt;</description><author>海雅古慕</author><pubDate>Fri, 02 Sep 2016 12:04:50 GMT</pubDate></item><item><title>基于R-FCN的物体检测</title><link>https://zhuanlan.zhihu.com/p/22261216</link><description>&lt;h1&gt;基于R-FCN的物体检测&lt;/h1&gt;&lt;h2&gt;作者&lt;/h2&gt;&lt;p&gt;     Jifeng
Dai               Yi Li                        Kaiming He                   Jian Sun&lt;/p&gt;&lt;p&gt;Microsoft Research    Tsinghua University      Microsoft Research       Microsoft Research&lt;/p&gt;&lt;h2&gt;译者&lt;/h2&gt;&lt;p&gt;~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~&lt;/p&gt;&lt;p&gt;翻译：  &lt;a href="mailto:%E5%90%B4%E5%88%9A@%E7%99%BE%E7%BA%B3.%E6%B5%B7%E8%B1%9A%E6%B5%8F%E8%A7%88%E5%99%A8"&gt;吴刚@百纳.海豚浏览器&lt;/a&gt;&lt;/p&gt;&lt;p&gt;校对：  &lt;a href="mailto:%E5%88%98%E7%95%85@%E7%99%BE%E7%BA%B3.%E6%B5%B7%E8%B1%9A%E6%B5%8F%E8%A7%88%E5%99%A8"&gt;刘畅@百纳.海豚浏览器&lt;/a&gt;&lt;/p&gt;&lt;p&gt;微信公众号： zero_zebra&lt;/p&gt;&lt;p&gt;QQ交流群：   142961883&lt;/p&gt;&lt;p&gt;大量职位虚位以待！详情请见公众号.职位列表&lt;/p&gt;&lt;p&gt;~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~&lt;/p&gt;&lt;h2&gt;摘要&lt;/h2&gt;&lt;p&gt;我们使用R-FCN
（region-based，fully convolutional networks）进行精确和有效的物体检测。对比之前的区域检测（Fast/Faster R-CNN [6&lt;b&gt;&lt;u&gt;]&lt;/u&gt;&lt;/b&gt;[&lt;b&gt;&lt;u&gt;18&lt;/u&gt;&lt;/b&gt;]应用于每一个区域子网格要花费数百次），我们的区域检测是基于整幅图片的全卷积计算。为了达到这个目标，我们使用了一个“位敏得分地图”（position-sensitive score maps）来处理在图像分类中的平移不变性和在目标检测中的平移变换性这样一种两难境地。因此我们的方法采用了全卷积图片分类主干部分，例如最新的残差网络（Residual Networks） (ResNets）[9&lt;b&gt;&lt;u&gt;]&lt;/u&gt;&lt;/b&gt;，用于目标检测。在PASCAL
VOC（e.g.，83.6% mAP on the 2007 set） 数据集的实验上，我们使用了101层ResNet达到了很好的效果。同时，我们仅仅使用了170ms/每张图片，比Faster R-CNN匹配快了2.5~20倍左右。公开的代码可以在此网站中访问到：&lt;a href="https://github.com/daijifeng001/r-fcn" data-editable="true" data-title="GitHub - daijifeng001/R-FCN: R-FCN: Object Detection via Region-based Fully Convolutional Networks"&gt;GitHub - daijifeng001/R-FCN: R-FCN: Object Detection via Region-based Fully Convolutional Networks&lt;/a&gt;&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/33e545ad67231323b08453bcd7b8f256.jpg" data-rawwidth="1654" data-rawheight="2339"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/3dac54033df74414ced74a891401251c.jpg" data-rawwidth="1654" data-rawheight="2339"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/fa28ab2ae2cbedc35518ea6fc4fa3e99.jpg" data-rawwidth="1654" data-rawheight="2339"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/053c673e81f89eb0ba846026f479eb1e.jpg" data-rawwidth="1654" data-rawheight="2339"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/ce8d31c9bfc9fb9dfa42b468aa0c5606.jpg" data-rawwidth="1654" data-rawheight="2339"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/9d333508c45b450bd87bb43806bc94c8.jpg" data-rawwidth="1654" data-rawheight="2339"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/f7665d8232f85de06081168f852e8f5e.jpg" data-rawwidth="1654" data-rawheight="2339"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/d333329c145d244d7ed40ec978eb2b2a.jpg" data-rawwidth="1654" data-rawheight="2339"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/4f57d21f461eb112f699e9ccd1fb6922.jpg" data-rawwidth="1654" data-rawheight="2339"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/ca5569d6c9d8f4f0b7fab9e5fd56bee1.jpg" data-rawwidth="1654" data-rawheight="2339"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/474ed25af3b0676d6b28465992135bbe.jpg" data-rawwidth="1654" data-rawheight="2339"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/d623c25c8457f9c7f2a073bd0a7ac51f.jpg" data-rawwidth="877" data-rawheight="1240"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/f18e4b3471a885885b562a55511c5299.jpg" data-rawwidth="877" data-rawheight="1240"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/6fd371fe4b69d17f41efe6d6154b2eba.jpg" data-rawwidth="885" data-rawheight="1252"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/031761fd5e986908d205400fa195d294.jpg" data-rawwidth="1654" data-rawheight="2339"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/73bb5421fd91b61bd2926259816ac075.jpg" data-rawwidth="1654" data-rawheight="2339"&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/22261216&amp;pixel&amp;useReferer"/&gt;</description><author>kiukotsu</author><pubDate>Wed, 31 Aug 2016 23:16:52 GMT</pubDate></item><item><title>不完全信息博弈中自我博弈的深度增强学习</title><link>https://zhuanlan.zhihu.com/p/22203823</link><description>本文译自伦敦大学Johannes Heinrich 和 David Silver 发表的论文《不完全信息博弈中自我博弈的深度增强学习》。&lt;p&gt;由于对论文重新排版实在有些麻烦，需要重新录入大量公式，以及调整段落图片版式。在这里直接上传的图片版本。请善用缩放功能，以获得最佳的阅读体验（注，刚打开文章时，图片可能比较模糊，可以通过点击图片来查看清晰版本，可以进行适当缩放）。&lt;/p&gt;&lt;p&gt;文章中的图表可以参见文末附注的图片， 给出了一些中文注释，希望能够起到一些帮助作用。&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/a838439c15c9541b13cd0295b4b5bdc3.jpg" data-rawwidth="2484" data-rawheight="3513"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/5a16c0b974f648ed8755577ae1b92c93.jpg" data-rawwidth="2484" data-rawheight="3513"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/ff1b6c1d636dd56bd861935f16fd0224.jpg" data-rawwidth="2484" data-rawheight="3513"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/4fd5fc3e2f37f6770ff48a03bd87be23.jpg" data-rawwidth="2484" data-rawheight="3513"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/b4a858e22aeb323192ec4017a47c9fce.jpg" data-rawwidth="2484" data-rawheight="3513"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/a10420bb6e4bfb93d223cbe980a07ecc.jpg" data-rawwidth="2484" data-rawheight="3513"&gt;&lt;p&gt;文章中的一些图表：&lt;/p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic4.zhimg.com/70139626a76e141bc22f287a61a88de7.png" data-rawwidth="1239" data-rawheight="445"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic1.zhimg.com/b2900f99b62aa14c6f5dd99bf5c65b5e.png" data-rawwidth="1242" data-rawheight="575"&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic2.zhimg.com/6be678ea7fb8650332cb133714e0b99c.png" data-rawwidth="1244" data-rawheight="567"&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/22203823&amp;pixel&amp;useReferer"/&gt;</description><author>平衡木</author><pubDate>Sat, 27 Aug 2016 17:21:28 GMT</pubDate></item><item><title>DeepMind的Neural Stack Machine及其代码实现（二）</title><link>https://zhuanlan.zhihu.com/p/22099077</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/3d3055c10ba737164b445d6935604cbe_r.jpg"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;本文译自Trask的&lt;a class="" data-title="博客文章" data-editable="true" href="https://iamtrask.github.io/2016/02/25/deepminds-neural-stack-machine/"&gt;博客文章&lt;/a&gt;，为原文中的Part II部分。Andrew Trask是Digital Reasoning的Product Manager，著有《Modeling Order in Neural Word Embeddings at Scale》和《Modeling Order in Neural Word Embeddings at ScalPredicting Stock Change using Twitter and Artificial Neural Networks》。本文翻译未获授权，不保证正确性。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;如篇头所述，我将就如何实现学术论文中的方法对元学习（meta-learning，如何学会学习）作一点讨论。现在，请点击打开&lt;a data-title="这篇论文" data-editable="true" href="http://papers.nips.cc/paper/5648-learning-to-transduce-with-unbounded-memory.pdf"&gt;这篇论文&lt;/a&gt;（《Learning to Transduce with Unbounded Memory》），粗略地看看。&lt;b&gt;声明：并不存在该如何阅读论文的正确打开方式！&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;初轮：&lt;/b&gt;我认识的很多人在这一轮会从头到尾把论文看一遍。不要强迫自己能理解所有的内容。只要对这些内容有一个概要性的理解就可以了：这篇论文的成就何在，有哪些关键术语，对使用的方法有一个基本观念。不要过于担心公式。花点时间多看看图表。这篇论文有相当多的图表，这对读者帮助颇大。如果这篇论文是关于造车的，那么初论阅读应该理解到这样的概念：”我们将制造一个可驾驶的机器，它将能在一个弯曲的道路上以60KPM的速度移动和转弯。它有轮子，使用汽油作燃料。应该由人来控制。"。在这一轮不要去管什么引擎，变速箱，和火花塞，更不要说什么最佳燃烧温度了。只要得到一般化的思想即可。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第二轮：&lt;/b&gt;这一轮中，如果你觉得已经理解了论文背景（通常是最前面几节，贴着简介或者相关工作的标签），那么就可以跳到方法一节。在这篇论文中，方法一节从第2页底部的”3 Models"开始。在这一节中，要逐句细读。这些章节一般总是内容极为饱满。每一句都是精心雕琢，如果不理解上一句，那么通常下一句读起来就全无意义。在这一轮中，仍然不要太过关注公式，相反，只要理解算法中的“主要动作部件”就好。关注“什么”而不是”怎么“。同样，如果我们要是造一辆车，那么这一轮是要弄理出一个部件清单，并且载明每个部件叫什么，看上去象什么，如下所示：&lt;/p&gt;&lt;p&gt;&lt;img rel="noreferrer" data-rawheight="199" data-rawwidth="865" src="4aa16bcba572514279adfc43bcc4c971.png"&gt;作为一个附注，这一时段你需要创造一些助记符（metal pneumonics)来帮助记住这些变量谁是谁。比如，u_t中的u是向上开口的， 就象它是被"弹”开的一样。（译注：这一段没有往下译。主要是讲如何通过一些记忆钩子帮助你迅速记住各个变量的用法和含义。这种方法并非阅读论文必须）。&lt;/p&gt;&lt;p&gt;&lt;b&gt;更多轮阅读&lt;/b&gt;。现在反复阅读方法一节，直到你有一个可行的实现。（你可以在下一篇验证你的成果）。&lt;/p&gt;&lt;p&gt;上一篇： &lt;a data-editable="true" data-title="DeepMind的Neural Stack Machine及其代码实现（一）" class="" href="https://zhuanlan.zhihu.com/p/22090568"&gt;DeepMind的Neural Stack Machine及其代码实现（一）&lt;/a&gt;&lt;/p&gt;&lt;p&gt;下一篇：&lt;a data-title="eepMind的Neural Stack Machine及其代码实现（三）" class="" href="https://zhuanlan.zhihu.com/p/22102144"&gt;DeepMind的Neural Stack Machine及其代码实现（三）&lt;/a&gt;&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/22099077&amp;pixel&amp;useReferer"/&gt;</description><author>杨勇</author><pubDate>Sat, 20 Aug 2016 16:53:36 GMT</pubDate></item><item><title>DeepMind的Neural Stack Machine及其代码实现（一）</title><link>https://zhuanlan.zhihu.com/p/22090568</link><description>&lt;p&gt;&lt;img rel="noreferrer" src="https://images.weserv.nl/?url=ssl:pic3.zhimg.com/3d3055c10ba737164b445d6935604cbe_r.jpg"&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;本文译自Trask的&lt;a class="" data-title="博客文章" data-editable="true" href="https://iamtrask.github.io/2016/02/25/deepminds-neural-stack-machine/"&gt;博客文章&lt;/a&gt;，
为原文中的Part II部分。Andrew Trask是Digital Reasoning的Product 
Manager，著有《Modeling Order in Neural Word Embeddings at Scale》和《Modeling 
Order in Neural Word Embeddings at ScalPredicting Stock Change using 
Twitter and Artificial Neural Networks》。本文翻译未获授权，不保证正确性。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;这篇文章不仅帮助读者理解DeepMind的Neural Stack Machine的结果，还以这篇&lt;a data-title="论文" data-editable="true" href="http://papers.nips.cc/paper/5648-learning-to-transduce-with-unbounded-memory.pdf"&gt;论文&lt;/a&gt;为例，详细地讲述了如何从论文出发，完成其代码实现。文中的方法可以当成将论文转化为代码实现的经典的套路。&lt;/p&gt;&lt;h2&gt;（一）什么是Neural Stack？&lt;/h2&gt;&lt;p&gt;&lt;b&gt;一个简单的堆栈&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在接触神经元堆栈前，让我们先从一个常规的栈定义开始。在计算机科学中，堆栈是数据结构的一种。在下面的代码中，我们把一些哈利.波特的书“摞”在一张（通过字符艺术画出的）桌子上。&lt;/p&gt;&lt;pre&gt;&lt;code lang="python"&gt;class VerySimpleStack:
    
    def __init__(self):
        self.contents = list()
        
    def push(self,item):
        self.contents.append(item)
    
    def pop(self):
        item = self.contents[-1]
        self.contents = self.contents[:-1]
        return item
    
    def pretty_print(self):
      i = 1
      print "\n--------TOP---------"
      for item in (self.contents):
          if(i != 1):
              print "--------------------"            
          print self.contents[-i]
          i+=1

      print  "-----------------------"
      print  "---------(table)-------"
      print  "-----------------------"
      print  "-- --             -- --"            
      print  "-- --             -- --"            
      print  "-- --             -- --"            
      print  "-- --             -- --"            
      print  "--                --"            
      print  "--                --\n\n"            
      
        
print "1) Creating an empty stack of books..."
stack = VerySimpleStack()

print "2) Pushing two books onto our stack..."
stack.push("Harry Potter and the Sorcerer's Stone")
stack.push("Harry Potter and the Chamber of Secrets")

print "3) Let's look at our stack..."
stack.pretty_print() # what order will this print?

print "4)Let's Pop a few...\n"
print "POP: " + stack.pop() # which one does this remove?
print "POP: " + stack.pop() # how bout this one?

print "\n5)Let's push a few more!"

stack.push("Harry Potter and the Prisoner of Azkaban")
stack.push("Harry Potter and the Goblet of Fire")
stack.push("Harry Potter and the Order of the Phoenix")
stack.push("Harry Potter and the Half-Blood Prince")
stack.push("Harry Potter and the Deathly Hallows")


print "\n6)Let's look at our stack again..."
stack.pretty_print()

&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;想象一下你在桌子上摞了一堆哈利.波特的书。堆栈与列表极其相似，但有一点不同：你只能堆栈的顶部增加或者移除一本书。所以，你可以增加另一本书到栈顶（stack.push(book))，或者从栈顶移除一本书(stack.pop())，然而你无法操作这堆书中间的任何一本。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Neural Stack&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Neural Stack也是一种堆栈。但是，我们将要实现的Neural Stack，将能够学习到如何使用堆栈来实现一个算法。它将学习到根据输入数据，在何时进行压栈和出栈操作，以正确地模态化输出数据。&lt;/p&gt;&lt;p&gt;神经网络如何学习到何时压栈，何时出栈？&lt;/p&gt;&lt;p&gt;神经网络将使用反向传播来学习。因此在读这篇文章前，必须要对神经网络和反向传播有一个直觉性的理解。读完这篇&lt;a data-title="博文" data-editable="true" href="http://iamtrask.github.io/2015/07/12/basic-python-network/"&gt;博文&lt;/a&gt;应该足够了。&lt;/p&gt;&lt;p&gt;因此，要回答神经网络如何学习何时做压栈和出栈操作的问题，我们需要理解一个正确的压栈和出栈序列看起来应该长什么样儿。因此，我们的输入数据和输出数据都是序列。那么，哪种数据序列是堆栈易于建模的呢？&lt;/p&gt;&lt;pre&gt;&lt;code lang="python"&gt;class VerySimpleStack:
    
    def __init__(self):
        self.contents = list()
        
    def push(self,item):
        self.contents.append(item)
    
    def pop(self):
        item = self.contents[-1]
        self.contents = self.contents[:-1]
        return item
    
    def pretty_print(self):
      i = 1
      print "\n--------TOP---------"
      for item in (self.contents):
          if(i != 1):
              print "--------------------"            
          print self.contents[-i]
          i+=1

      print  "-----------------------"
      print  "---------(table)-------"
      print  "-----------------------"
      print  "-- --             -- --"            
      print  "-- --             -- --"            
      print  "-- --             -- --"            
      print  "-- --             -- --"            
      print  "--                --"            
      print  "--                --\n\n"            
      
        

print "1) Creating an empty stack of numbers..."
stack = VerySimpleStack()

print "\n2) Create an ordered sequence... "
sequence = [0,1,2,3,4,5]
print "sequence = " + str(sequence)

print "\n3) Push sequence onto my stack"
stack.push(sequence[0])
stack.push(sequence[1])
stack.push(sequence[2])
stack.push(sequence[3])
stack.push(sequence[4])
stack.push(sequence[5])
stack.pretty_print()

print "\n4) Create New Sequence By Popping From Stack"
new_sequence = list()
new_sequence.append(stack.pop())
new_sequence.append(stack.pop())
new_sequence.append(stack.pop())
new_sequence.append(stack.pop())
new_sequence.append(stack.pop())
new_sequence.append(stack.pop())

print "\n5) Print new sequence... notice anything?"
print "new_sequence = " + str(new_sequence)

&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;输出结果如下：&lt;/p&gt;&lt;pre&gt;&lt;code lang="pytb"&gt;1) Creating an empty stack of numbers...

2) Create an ordered sequence... 
sequence = [0, 1, 2, 3, 4, 5]

3) Push sequence onto my stack

--------TOP---------
5
--------------------
4
--------------------
3
--------------------
2
--------------------
1
--------------------
0
-----------------------
---------(table)-------
-----------------------
-- --             -- --
-- --             -- --
-- --             -- --
-- --             -- --
--                --
--                --

4) Create New Sequence By Popping From Stack

5) Print new sequence... notice anything?
new_sequence = [5, 4, 3, 2, 1, 0]&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;b&gt;究竟什么是Neural Stack？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;Neural Stack&lt;/b&gt;是一种通过学习，能记忆输入序列并根据从数据中学习到的pattern来做出正确变换的栈。&lt;/p&gt;&lt;p&gt;&lt;b&gt;如何学习？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Neural Stack通过以下方式进行学习：&lt;/p&gt;&lt;p&gt;1） 接收输入数据，根据神经网络的指令进行出栈和入栈。这样生成了输出数据序列（预测）。&lt;/p&gt;&lt;p&gt;2） 将输出数据与输入数据进行比较，看有多少数据是Neural Stack漏掉的。&lt;/p&gt;&lt;p&gt;3） 使用反向传播算法更新神经网络，以使得下次入栈和出栈操作能更加正确。&lt;/p&gt;&lt;p&gt;问题：如果错误发生在栈的输出上，而神经网络作用在栈的输入上，反向传播如何能学习到该如何入栈和出栈？一般来说我们将网络输出端的错误反向传播到权重值，从而我们可以更新权重。这里看起来neural stack正好阻塞了神经网络（正是神经网络控制着入栈和出栈)的决策。&lt;/p&gt;&lt;p&gt;回答：要使得neural stack是可微分的。如果我们能找出只使用加、减、乘法就能模拟栈的行为的工具，那么我们就能够象在神经网络里那样将错误反向传播通过隐藏层一样，将错误反向传播通过堆栈。而这些对我们来讲很熟悉。我们已经做过使用加、减、乘的序列来做反向传播，现在最难的部分只是要如何以一个完全可微分的方式来模拟栈的操作--Edward Grefenstette, Karl Moritz Hermann, Mustafa Suleyman和Phil Blunsom做到了，这也正是他们如此光芒夺目的原因！&lt;/p&gt;&lt;p&gt;下一篇：&lt;a data-title="DeepMind的Neural Stack Machine及其代码实现（二）" class="" href="https://zhuanlan.zhihu.com/p/22099077"&gt;DeepMind的Neural Stack Machine及其代码实现（二）&lt;/a&gt;&lt;/p&gt;&lt;img rel="noreferrer" src="https://ga-beacon.appspot.com/UA-41015557-4/page-name?dt=https://zhuanlan.zhihu.com/p/22090568&amp;pixel&amp;useReferer"/&gt;</description><author>杨勇</author><pubDate>Sat, 20 Aug 2016 12:08:17 GMT</pubDate></item></channel></rss>